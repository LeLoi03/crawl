input:
1. VLSID_3 conference:
Home | Contact Us 
  Archives | VLSID 2024 
  VLSID 2023 
  VLSID 2022 
    Home | Contact Us 
  Archives | VLSID 2024 
  VLSID 2023 
  VLSID 2022 
 Tata Electronics  
 VLSID Committee  
 Steering Committee Chair  
 VLSID Conference  
 With its global footprints VLSID is recognized as a ‘Sister Conference’ of Design Automation Conference. This conference is sponsored by VLSI Society of India (VSI)  
 Contact Us     
 Few glimpses of previous VLSID conferences..  
  Accomodation 
 VLSID 2024 
  VLSID 2023 
 VLSID 2022 
 Powered by Confispace Technologies LLP   
 Subscribe to VLSID Newsletter  
 Subscription Form
2. VMCAI_0 conference:
POPL 2023   Sun 15 - Sat 21 January 2023 Boston, Massachusetts, United States    
 Toggle navigation        
  Program | POPL Program 
  Your Program 
   Filter by Day | Sun 15 Jan 
  Mon 16 Jan 
  Tue 17 Jan 
  Wed 18 Jan 
  Thu 19 Jan 
  Fri 20 Jan 
  Sat 21 Jan 
  Tracks | POPL 2023 
  POPL 
  Session Previews 
   Co-hosted Conferences 
  CPP 
  VMCAI 
  Workshops 
  CoqPL 
  Co-hosted Symposia 
  PADL 
  Organization | POPL 2023 Committees 
  Organizing Committee 
  Track Committees 
  Program Committee 
  Steering Committee 
  VMCAI | Organizing Committee 
  Program Committee 
  Artifact Evaluation Committee 
  POPL 2024 
  POPL 2023 
  POPL 2022 
  Sign up 
  POPL 2023  ( series  ) /  VMCAI 2023 ( series  ) /  VMCAI 2023  
 About 
  Call for Artifacts 
  Call for Papers 
  Camera-ready instructions 
  Sponsorship 
  Welcome to the website of the 24th International Conference on Verification, Model Checking, and Abstract Interpretation (VMCAI 2023).  
 VMCAI provides a forum for researchers from the communities of Verification, Model Checking, and Abstract Interpretation, facilitating interaction, cross-fertilization, and advancement of hybrid methods that combine these and related areas. VMCAI 2023 will be the 24th edition in the series.  
 VMCAI will take place during January 16-17, 2023.  
 Proceedings and Recordings  
 The full conference proceedings is available from Springer  .  
   The GMT offsets shown reflect the offsets at the moment of the conference  .     
 Time Band   
 ×    You're viewing the program in a time zone which is different from your device's time zone change time zone     
 Mon 16 Jan   
 Displayed time zone: Eastern Time (US & Canada)  change      
 Keynote | Towards a Theoretical Understanding of Property-Directed Reachability   VMCAI   
 Sharon Shoham  Tel Aviv University 
 30m    
 Talk | Distributing and Parallelizing Non-canonical Loops   VMCAI   
 30m    
 Talk | Efficient Interprocedural Data-Flow Analysis using Treedepth and Treewidth   VMCAI   
 Amir Kafshdar Goharshady  IST Austria, Austria  , Ahmed Khaled Zaher  HKUST 
 30m    
 Talk | Result Invalidation for Incremental Modular Analyses   VMCAI   
 Jens Van der Plas  Software Languages Lab, Vrije Universiteit Brussel  , Quentin Stiévenart  Vrije Universiteit Brussel  , Coen De Roover  Vrije Universiteit Brussel 
 30m    
 Talk | Symbolic Abstract Heaps for Polymorphic Information-flow Guard Inference   VMCAI   
 Nicolas Berthier  OCamlPro  , Narges Khakpour  Linnaeus University 
 Keynote | What Can Program Analysis Say About Data Bias?   VMCAI   
 Aws Albarghouthi  University of Wisconsin-Madison 
 30m    
 Talk | Bayesian parameter estimation with guarantees via interval analysis and simulation   VMCAI   
 Luisa Collodi  University of Florence 
 30m    
 Talk | Solving Constrained Horn Clauses over Algebraic Data Types   VMCAI   
 Lucas Zavalia  Florida State University Tallahassee  , Lidiia Chernigovskaia   , Grigory Fedyukovich  Florida State University 
 30m    
 Talk | Satisfiability Modulo Custom Theories in Z3 (Tool Paper)   VMCAI   
 Nikolaj Bjørner  Microsoft Research  , Clemens Eisenhofer   , Laura Kovács  TU Wien 
 30m    
 Talk | CosySEL: Improving SAT Solving Using Local Symmetries   VMCAI   
 Sabrine Saouli   , Souheib Baarir   , Claude Dutheillet   , Jo Devriendt 
 Tue 17 Jan   
 Displayed time zone: Eastern Time (US & Canada)  change      
 Keynote | Differential Verification of Deep Neural Networks   VMCAI   
 Chao Wang  University of Southern California 
 30m    
 Talk | ARENA: Enhancing Abstract Refinement for Neural Network Verification   VMCAI   
 Yuyi Zhong   , Quang-Trung Ta  National University of Singapore  , Siau-Cheng Khoo  National University of Singapore 
 15m    
 Talk | Maximal Robust Neural Network Specifications via Oracle-guided Numerical Optimization Recorded      VMCAI   
 Anan Kabaha  Technion, Israel Institute of Technology  , Dana Drachsler Cohen  Technion 
 15m    
 Talk | SMT-Based Modeling and Verification of Spiking Neural Networks: A Case Study Recorded      VMCAI   
 Sumana Ghosh   , Soham Banerjee   , Swarup Mohalik   , Ansuman Banerjee 
 30m    
 Talk | A generic framework to coarse-grain stochastic reaction networks by Abstract Interpretation   VMCAI   
 Jerome Feret  INRIA Paris  , Albin Salazar  INRIA/CNRS/ENS/PSL* 
 30m    
 Talk | Sound Symbolic Execution via Abstract Interpretation and its Application to Security   VMCAI   
 Xavier Rival  Inria; ENS; CNRS; PSL University  , Ignacio Tiraboschi  Inria, France / ENS, France  , Tamara Rezk  INRIA 
 Keynote | Verifying, Inferring and Exploiting Code Commutativity   VMCAI   
 Eric Koskinen  Stevens Institute of Technology 
 15m    
 Talk | A Pragmatic Approach to Stateful Partial Order Reduction Recorded      VMCAI   
 Berk Cirisci  IRIF, University Paris Diderot and CNRS, France  , Constantin Enea  Ecole Polytechnique / LIX / CNRS  , Azadeh Farzan  University of Toronto  , Suha Orhun Mutluergil  Sabanci University, Turkey 
 15m    
 Talk | StaticPersist : Compiler Support for PMEM Programming Recorded      VMCAI   
 Sorav Bansal  IIT Delhi and CompilerAI Labs 
 30m    
 Talk | Compositional Verification of Stigmergic Collective Systems   VMCAI   
 Luca Di Stefano  University of Gothenburg, Sweden  , Frederic Lang 
 30m    
 Talk | Synthesizing History and Prophecy Variables for Symbolic Model Checking   VMCAI   
 Cole Vick   , Kenneth L. McMillan  University of Texas at Austin 
 Title 
 A generic framework to coarse-grain stochastic reaction networks by Abstract Interpretation  VMCAI   
 Jerome Feret  , Albin Salazar 
 A Pragmatic Approach to Stateful Partial Order Reduction Recorded     VMCAI   
 Berk Cirisci  , Constantin Enea  , Azadeh Farzan  , Suha Orhun Mutluergil 
 ARENA: Enhancing Abstract Refinement for Neural Network Verification  VMCAI   
 Yuyi Zhong  , Quang-Trung Ta  , Siau-Cheng Khoo 
 Bayesian parameter estimation with guarantees via interval analysis and simulation  VMCAI   
 Luisa Collodi 
 Compositional Verification of Stigmergic Collective Systems  VMCAI   
 Luca Di Stefano  , Frederic Lang 
 CosySEL: Improving SAT Solving Using Local Symmetries  VMCAI   
 Sabrine Saouli  , Souheib Baarir  , Claude Dutheillet  , Jo Devriendt 
 Distributing and Parallelizing Non-canonical Loops  VMCAI   
 Clément Aubert  , Thomas Rubiano  , Neea Rusch  , Thomas Seiller 
 Efficient Interprocedural Data-Flow Analysis using Treedepth and Treewidth  VMCAI   
 Amir Kafshdar Goharshady  , Ahmed Khaled Zaher 
 Maximal Robust Neural Network Specifications via Oracle-guided Numerical Optimization Recorded     VMCAI   
 Anan Kabaha  , Dana Drachsler Cohen 
 Result Invalidation for Incremental Modular Analyses  VMCAI   
 Jens Van der Plas  , Quentin Stiévenart  , Coen De Roover 
 Satisfiability Modulo Custom Theories in Z3 (Tool Paper)  VMCAI   
 Nikolaj Bjørner  , Clemens Eisenhofer  , Laura Kovács 
 SMT-Based Modeling and Verification of Spiking Neural Networks: A Case Study Recorded     VMCAI   
 Sumana Ghosh  , Soham Banerjee  , Swarup Mohalik  , Ansuman Banerjee 
 Solving Constrained Horn Clauses over Algebraic Data Types  VMCAI   
 Lucas Zavalia  , Lidiia Chernigovskaia  , Grigory Fedyukovich 
 Sound Symbolic Execution via Abstract Interpretation and its Application to Security  VMCAI   
 Xavier Rival  , Ignacio Tiraboschi  , Tamara Rezk 
 StaticPersist : Compiler Support for PMEM Programming Recorded     VMCAI   
 Sorav Bansal 
 Symbolic Abstract Heaps for Polymorphic Information-flow Guard Inference  VMCAI   
 Nicolas Berthier  , Narges Khakpour 
 Synthesizing History and Prophecy Variables for Symbolic Model Checking  VMCAI   
 Cole Vick  , Kenneth L. McMillan 
 Camera-ready instructions  
 Badge placement: Please use the following code snippet to including the badges that you were awarded, after the abstract:  
 Sponsorship  
 VMCAI is welcoming diamond, silver and bronze sponsors.  
 Call for Papers  
 VMCAI 2023 is the 24th International Conference on Verification, Model Checking, and Abstract Interpretation. The conference will be held during January 15-17, 2023. VMCAI provides a forum for researchers from the communities of Verification, Model Checking, and Abstract Interpretation, facilitating interaction, cross-fertilization, and advancement of hybrid methods that combine these and related areas.  
 Scope   
 The program will consist of refereed research papers as well as invited lectures and tutorials. Research contributions can report new results as well as experimental evaluations and comparisons of existing techniques.  
  Submissions can address any programming paradigm, including concurrent, constraint, functional, imperative, logic, and object-oriented programming.  
 Important Dates AoE (UTC-12)   
 September 8th, 2022  September 15, 2022: Paper submission  
 October 13th, 2022  October 20, 2022: Notification  
 November 10th, 2022: Camera-ready version due  
 Submissions   
 Submissions are required to follow Springer’s LNCS format. The page limit depends on the paper’s category (see below). In each category, additional material beyond the page limit may be placed in a clearly marked appendix, to be read at the discretion of the reviewers and to be omitted in the final version. Formatting style files and further guidelines for formatting can be found at the Springer website  . Submission is via EasyChair  .  
 Submissions will undergo a single-blind review process. Accepted papers will be published in Springer’s Lecture Notes in Computer Science series. There will be three categories of papers: regular papers, tool papers and case studies. Papers in each category have a different page limit and will be evaluated differently.  
 Regular papers  clearly identify and justify an advance to the field of verification, abstract interpretation, or model checking. Where applicable, they are supported by experimental validation. Regular papers are restricted to 20 pages in LNCS format, not counting references.  
 Tool papers  present a new tool, a new tool component, or novel extensions to an existing tool. They should provide a short description of the theoretical foundations with relevant citations, and emphasize the design and implementation concerns, including software architecture and core data structures. A regular tool paper should give a clear account of the tool’s functionality, discuss the tool’s practical capabilities with reference to the type and size of problems it can handle, describe experience with realistic case studies, and where applicable, provide a rigorous experimental evaluation. Papers that present extensions to existing tools should clearly focus on the improvements or extensions with respect to previously published versions of the tool, preferably substantiated by data on enhancements in terms of resources and capabilities. Authors are strongly encouraged to make their tools publicly available and submit an artifact. Tool papers are restricted to 12 pages in LNCS format, not counting references.  
 Case studies  are expected to describe the use of verification, model checking, and abstract interpretation techniques in new application domains or industrial settings. Papers in this category do not necessarily need to present original research results but are expected to contain novel applications of formal methods techniques as well as an evaluation of these techniques in the chosen application domain. Such papers are encouraged to discuss the unique challenges of transferring research ideas to a real-world setting and reflect on any lessons learned from this technology transfer experience. Case study papers are restricted to 20 pages in LNCS format, not counting references. (Shorter case study papers are also welcome.)  
 Call for Artifacts  
 VMCAI 2023 makes available the option to submit an artifact along with a paper. Artifacts are any additional material that substantiates the claims made in the paper, and ideally makes them fully replicable. For some papers, these artifacts are as important as the paper itself because they provide crucial evidence for the quality of the results. The goal of artifact evaluation is twofold. On the one hand, we want to encourage authors to provide more substantial evidence to their papers and to reward authors who create artifacts. On the other hand, we want to simplify the independent replication of results presented in the paper and to ease future comparison with existing approaches. Artifacts of interest include (but are not limited to):  
 Software, Tools, or Frameworks 
  Data sets 
  Machine checkable proofs 
  Any combination of them 
  Any other artifact described in the paper 
  Artifact submission is optional  . However, we highly encourage all authors to also submit an artifact. A successfully evaluated artifact can increase your chance of being accepted since the evaluation result of your artifact is taken into account during paper reviewing. Additionally, badges shown on the title page of the corresponding paper give you credit for good artifact submissions. We award one of three types of badges. For artifacts that are successfully evaluated by the artifact evaluation committee we grant the available badge. Artifacts that are publically available under a DOI receive an availability badge. Authors may use all granted badges on the title page of the respective paper.  
 Important Dates   
 The artifact evaluation will be done in parallel with the evaluation of the submitted paper. The artifacts submission deadline is 1 week after the paper submission.  
 September 9, 2022: Artifact submission opens  
 September 15, 2022  September 22, 2022: Artifact submission  
 October 3, 2022  October 16, 2022: Artifact test phase notification  
 October 4–7, 2022  October 16–20, 2022: Artifact clarification period  
 October 30, 2022: Artifact notification  
 All artifacts are evaluated by the artifact evaluation committee. Each artifact will be reviewed by at least two committee members. Reviewers will read the paper and explore the artifact to evaluate how well the artifact supports the claims and results of the paper. The evaluation is based on the following questions.  
 Is the artifact consistent with the paper and the claims made by the paper? 
  Are the results of the paper replicable through the artifact? 
  Is the artifact complete, i.e., how many of the results of the paper are replicable? 
  Is the artifact well-documented? 
  Is the artifact easy to use? 
 In the test phase, reviewers check if the artifact is functional, i.e., they look for setup problems (e.g., corrupted, missing files, crashes on simple examples, etc.). If any problems are detected, the authors are informed of the outcome and asked for clarification. The authors will get 3 days to respond to the reviews in case problems are encountered. 
  In the assessment phase, reviewers will try to reproduce any experiments or activities and evaluate the artifact w.r.t the questions detailed above. 
  Artifacts Submission   
 An artifact submission should consist of  
 an abstract that summarizes the artifact and explains its relation to the paper including: 
  a URL from which a .zip or .tar.gz archive file containing the artifact can be downloaded - we encourage you to provide a DOI 
  a .pdf file of the submitted paper contained within the archive file. 
  If you cannot submit the artifact as requested or encounter any other difficulties in the submission process, please contact the artifact evaluation chairs prior to submission.  
 Artifact Packaging Guidelines   
 There are two acceptable ways to submit your artifact. You may either package the artifact as an archive file and write their instructions such that the artifact evaluation committee can evaluate the artifact within a virtual machine provided by us. In this case, only submit the required files to replicate your results in the provided virtual machine. If you submit in this way, you would not submit a virtual machine image in the archive file. AEC members will copy your archive file into the provided virtual machine.  
 The second option is to modify the given VM and reupload the VM to a hosting platform of your choice. We will check the hash of the image, then load the VM to test your artifact. In this case, a README should be contained in the home directory of the VM.  
 We recommend preparing your artifact in such a way that any computer science expert without dedicated expertise in your field can use your artifact, especially to replicate your results. For example, provide easy-to-use scripts and a detailed README document.  
 VMCAI 2022 Virtual Machine   
 An initial version of the virtual machine is available here  . The user name is vmcai  and the password is vmcai-2023  . If you have any questions regarding the VM or in case you think the VM is improper for evaluation of your artifact, please contact the artifact evaluation chair.  
 Submission Contents   
 Your virtual machine must contain the following elements.  
 The main artifact, i.e., data, software, libraries, scripts, etc. required to replicate the results of your paper. ◦ The review will be singly blind. Please make sure that you do not (accidentally) learn the identify of the reviewers (e.g., through analytics, logging). 
  A license file. Your license needs to allow the artifact evaluation chairs to download and distribute the artifact to the artifact evaluation committee members and the artifact evaluation committee members must be allowed to evaluate the artifact, e.g., use, execute, and modify the artifact for the purpose of artifact evaluation. 
  A README text file that introduces the artifact to the user and guides the user through replication of your results. Ideally, it should describe the structure and content of your artifact. It should also describe the steps to set up your artifact within the VM. To simplify the reviewing process, we recommend providing an installation script (if necessary). We would appreciate it if you would support the reviewers not only for the main review phase but also for the testing phase. To this end, it would be helpful if you would provide instructions that allow installation and rudimentary testing (i.e., in such a way that technical difficulties would pop up) in as little time as possible. Document in detail how to replicate your results of the paper: 
  Please document which claims or results of the paper can be replicated with the artifact and how (e.g., which experiment must be performed). Please also explain which claims and results cannot be replicated and why.  
 Describe in detail how to replicate the results in the paper, especially describe the steps that need to be performed to replicate the results in the paper. To simplify the reviewing process, we recommend providing evaluation scripts (where applicable). Precisely state the resource requirements (RAM, number of cores, CPU frequency, etc.), which you used to test your artifact. In most cases, your resource requirements should be modest and allow replication of results even on laptops. If your tool demands a more specialized resource requirement than would be appropriate for a laptop, make a note of this in your README. 
  Please provide for each task/step of the replication (an estimate) how long it will take to perform it or how long it took for you and what exact machine(s) you used. 
  For tasks that require a large amount of resources (hardware or time), we recommend to provide a possibility to replicate a subset of the results with reasonably modest resource and time limits, e.g., within 8 hours on a reasonable personal computer. In this case, please also include a script to replicate only a subset of the results. If this is not possible, please contact the artifact evaluation chairs early, but no later than before submission. 
  Publication of Artifacts   
 The artifact evaluation committee uses the submitted artifact only for the artifact evaluation. It may not publicize the artifact or any parts of it during or after completing evaluation. Artifacts and all associated data will be deleted at the end of the evaluation process. We encourage the authors of artifacts to make their artifacts also permanently available, e.g., on Zenodo  or figshare  , and refer to them in their papers via a DOI. All artifacts for which a DOI exists that is known to the artifact evaluation committee are granted the availability badge.  
 Important Dates   AoE (UTC-12h)     
 Thu 10 Nov 2022  
  Camera-ready version due 
 Fri 21 Oct 2022  
  Notification 
 Thu 22 Sep 2022  
  Artifact submission deadline 
 Thu 15 Sep 2022  
  Paper submission deadline 
 Organizing Committee    
  POPL 2023   
  contact form    
  Workshops and Co-located Events    
 Co-hosted Conferences  
 CPP 2023   
  VMCAI 2023   
  Workshops  
 CoqPL 2023   
  LAFI 2023   
  PEPM 2023   
  PLMW @ POPL 2023   
  PriSC 2023   
  ProLaLa 2023   
  Co-hosted Symposia  
 PADL 2023    
 Attending
3. VMCAI_1 conference:
VMCAI 2024 
  VMCAI 2023 
  VMCAI 2022 
  VMCAI 
  Sign in 
  Sign up 
 VMCAI  
 All Editions   
 Mon 15 - Tue 16 January 2024 London, United Kingdom  VMCAI 2024  with POPL 2024    
 Welcome to the website of the 25th International Conference on Verification, Model Checking, and Abstract Interpretation (VMCAI 2024). VMCAI provides a forum for researchers from the communities of Verification, Model Checking, and Abstract Interpretation, facilitating interaction, cross-fertilization, and advancement of hybrid methods that combine these and related areas. VMCAI 2024 will be the 25th edition in ... 
 Mon 16 - Tue 17 January 2023 Boston, Massachusetts, United States  VMCAI 2023  with POPL 2023    
 Welcome to the website of the 24th International Conference on Verification, Model Checking, and Abstract Interpretation (VMCAI 2023). VMCAI provides a forum for researchers from the communities of Verification, Model Checking, and Abstract Interpretation, facilitating interaction, cross-fertilization, and advancement of hybrid methods that combine these and related areas. VMCAI 2023 will be the 24th edition in ... 
 Sun 16 - Tue 18 January 2022 Philadelphia, Pennsylvania, United States  VMCAI 2022  with POPL 2022    
 Welcome to the website of the 23rd International Conference on Verification, Model Checking, and Abstract Interpretation (VMCAI 2022). VMCAI provides a forum for researchers from the communities of Verification, Model Checking, and Abstract Interpretation, facilitating interaction, cross-fertilization, and advancement of hybrid methods that combine these and related areas. VMCAI 2022 will be the 23rd edition in ...
4. VMCAI_2 conference:
nach oben    
 2023 | Buch  
 Kapitel lesen  Erstes Kapitel lesen     
 Verification, Model Checking, and Abstract Interpretation  
 24th International Conference, VMCAI 2023, Boston, MA, USA, January 16–17, 2023, Proceedings  
 herausgegeben von: Cezara Dragoi, Michael Emmi, Jingbo Wang   
 SMT-Based Modeling and Verification of Spiking Neural Networks: A Case Study  
  Abstract   
 In this paper, we present a case study on modeling and verification of Spiking Neural Networks (SNN) using Satisfiability Modulo Theory (SMT) solvers. SNN are special neural networks that have great similarity in their architecture and operation with the human brain. These networks have shown similar performance when compared to traditional networks with comparatively lesser energy requirement. We discuss different properties of SNNs and their functioning. We then use Z3, a popular SMT solver to encode the network and its properties. Specifically, we use the theory of Linear Real Arithmetic (LRA). Finally, we present a framework for verification and adversarial robustness analysis and demonstrate it on the Iris and MNIST benchmarks.   
 Soham Banerjee, Sumana Ghosh, Ansuman Banerjee, Swarup K. Mohalik   
  Abstract   
 In the last decades, logical or discrete models have emerged as a successful paradigm for capturing and predicting the behaviors of systems of molecular interactions. Intuitively, they consist in sampling the abundance of each kind of biochemical entity within finite sets of intervals and deriving transitions accordingly. On one hand, formally-proven sound derivation from more precise descriptions (such as from reaction networks) may include many fictitious behaviors. On the other hand, direct modeling usually favors dominant interactions with no guarantee on the behaviors that are neglected.   
 In this paper, we formalize a sound coarse-graining approach for stochastic reaction networks. Its originality relies on two main ingredients. Firstly, we abstract values by intervals that overlap in order to introduce a minimal effort for the system to go back to the previous interval, hence limiting fictitious oscillations in the coarse-grained models. Secondly, we compute for pairs of transitions (in the coarse-grained model) bounds on the probabilities on which one will occur first.   
 We illustrate our ideas on two case studies and demonstrate how techniques from Abstract Interpretation can be used to design more precise discretization methods, while providing a framework to further investigate the underlying structure of logical and discrete models.   
  Abstract   
 Many satisfiability problems exhibit symmetry properties. Thus, the development of symmetry exploitation techniques seems a natural way to try to improve the efficiency of solvers by preventing them from exploring isomorphic parts of the search space. These techniques can be classified into two categories: dynamic and static symmetry breaking. Static approaches have often appeared to be more effective than dynamic ones. But although these approaches can be considered as complementary, very few works have tried to combine them.   
 In this paper, we present a new tool, CosySEL  , that implements a composition of the static Effective Symmetry Breaking Predicates ( esbp  ) technique with the dynamic Symmetric Explanation Learning ( sel  ). esbp  exploits symmetries to prune the search tree and sel  uses symmetries to speed up the tree traversal. These two accelerations are complementary and their combination was made possible by the introduction of Local symmetries  .   
 We conduct our experiments on instances issued from the last ten sat  competitions and the results show that our tool outperforms the existing tools on highly symmetrical problems.   
  Abstract   
 Symbolic execution is a program analysis technique commonly utilized to determine whether programs violate properties and, in case violations are found, to generate inputs that can trigger them. Used in the context of security properties such as noninterference, symbolic execution is precise when looking for counter-example pairs of traces when insecure information flows are found, however it is sound only up to a bound thus it does not allow to prove the correctness of programs with executions beyond the given bound. By contrast, abstract interpretation-based static analysis guarantees soundness but generally lacks the ability to provide counter-example pairs of traces.   
 In this paper, we propose to weave both to obtain the best of two worlds. We demonstrate this with a series of static analyses, including a static analysis called RedSoundRSE  aimed at verifying noninterference. RedSoundRSE  provides both semantically sound results and the ability to derive counter-example pairs of traces up to a bound. It relies on a combination of symbolic execution and abstract domains inspired by the well known notion of reduced product. We formalize RedSoundRSE  and prove its soundness as well as its relative precision up to a bound. We also provide a prototype implementation of RedSoundRSE  and evaluate it on a sample of challenging examples.   
 Ignacio Tiraboschi, Tamara Rezk, Xavier Rival   
 ARENA: Enhancing Abstract Refinement for Neural Network Verification  
  Abstract   
 As neural networks have taken on a critical role in real-world applications, formal verification is earnestly needed to guarantee the safety properties of the networks. However, it remains challenging to balance the trade-off between precision and efficiency in abstract interpretation based verification methods. In this paper, we propose an abstract refinement process that leverages the convex hull techniques to improve the analysis efficiency. Specifically, we introduce the double description method in the convex polytope domain to detect and eliminate multiple spurious  adversarial labels simultaneously. We also combine the new activation relaxation technique with the iterative abstract refinement method to compensate for the precision loss during abstract interpretation. We have implemented our proposal into a verification framework named ARENA, and assessed its effectiveness by conducting a series of experiments. These experiments show that ARENA yields significantly better verification precision compared to the existing abstract-refinement-based tool DeepSRGR. It also identifies falsification by detecting adversarial examples, with reasonable execution efficiency. Lastly, it verifies more images than the state-of-the-art verifier PRIMA.   
 Yuyi Zhong, Quang-Trung Ta, Siau-Cheng Khoo   
  Jingbo Wang  
 Copyright-Jahr  2023    
 Verlag  Springer Nature Switzerland
5. VRST_0 conference:
COMMITTEE 
 9-11 October 2023 / Christchurch, New Zealand / In-person only  
 The 29th ACM Symposium on Virtual Reality Software and Technology (VRST) will be held in Christchurch, New Zealand, from Monday-Wednesday, 9-11 October 2023. The event is sponsored by ACM SIGCHI and SIGGRAPH.  
 VRST is a premier international symposium for the presentation of new research results, systems, and techniques among researchers and developers on virtual, augmented and mixed reality (VR/AR/MR, XR for short) software and technology.   
 VRST brings together the main international research groups working on XR, along with many of the world’s leading companies that provide or utilise XR systems.  
 Awards:  
 To maximize the benefit of your travel, we are coordinating with similar major conferences happening within the same two-week period, and calling it "Southern Hemisphere (SoHem) XR Weeks."   
 Three XR Conferences in one trip! 
  Coordinated submission deadlines! 
  Direct flights from Christchurch to Sydney! 
 9-11 October 2023  
  In-person only  
  Christchurch  
 13-15 October 2023  
   In-person only  
  Sydney   
 16-20 October 2023   
  Hybrid   
  Sydney
6. VRST_1 conference:
Advanced Search…    
  Home  /  Conferences  /   ACM VRST 2023 - 29th Sympostium on Virtual Reality Software and Technology     
 Document Actions  
 ACM VRST 2023 - 29th Sympostium on Virtual Reality Software and Technology  
 What | Conference 
 When | 2023-10-09  to   
  2023-10-11 
 Where | Christchurch, New Zealand 
 Contact Name | Rob Lindeman, Hemi Whaanga 
 Contact Email | chairs2023@vrst.acm.org 
 Add event to calendar | vCal    
   iCal 
  About JVRB 
  Editorial Board & Guest Editors 
  Submission 
  Peer Review 
  Imprint 
  Contact 
  Datenschutz 
  Conferences | ACM VRST 2023 - 29th Sympostium on Virtual Reality Software and Technology 
 « | November 2024 | » 
 Su | Mo | Tu | We | Th | Fr | Sa 
 1 | 2
7. VRST_2 conference:
Submit item for ISPR Presence News 
 Call: ACM Symposium on Virtual Reality Software and Technology (VRST 2023)  
 Published:  
 May 19, 2023     
 —  
 in  Calls    
 Call for Papers/Posters/Demos   
 VRST 2023  
  ACM Symposium on Virtual Reality Software and Technology  
   Christchurch, New Zealand / In-person only  
  October 9-11, 2023  
 Submission deadlines:  
 Abstracts: June 12, 2023 
  Papers: June 19, 2023 
  Posters and demos: July 2, 2023 
  The 29th ACM Symposium on Virtual Reality Software and Technology (VRST) will be held in Christchurch, New Zealand, from Monday-Wednesday, 9-11 October 2023. The event is sponsored by ACM SIGCHI and SIGGRAPH.  
 VRST is a premier international symposium for the presentation of new research results, systems, and techniques among researchers and developers on virtual, augmented and mixed reality (VR/AR/MR, XR for short) software and technology.  
 VRST brings together the main international research groups working on XR, along with many of the world’s leading companies that provide or utilise XR systems.  
 TOPICS:  
 VRST 2023 welcomes paper submissions relating (but not limited) to the following XR areas:  
 Display technology and interaction devices 
  Low-latency and high-performance software and applications 
  Conference: 09-11 October 2023 (Monday-Wednesday) 
 PCS Submission Management System:  
 Please use the Precision Conferences System (PCS) to submit your work. After clicking the link below, please choose “SIGCHI” from the “Society” drop-down list, then “VRST 2023” from the “Conference/Journal” drop-down list.  
 Submission Guidelines:  
 All accepted papers will be published in the ACM Digital Library in the VRST collection.  
 Paper Format:  
 Paper submissions must be anonymous for a double-blind review process (see website for more details). By contrast, Poster and Demo submissions do NOT have to be anonymous, and these submissions will be juried by committee members and receive light feedback (up to a few paragraphs in length).  
  For LaTeX authors, submissions should be made using the double-column format using \documentclass[sigconf,review,anonymous]{acmart}. 
  Authors should prepare their materials using numbered citations and references. See the TAPS webpage for guidance on how content length corresponds to the page limits for the final version. 
  Submission Lengths:  
 Paper: 4 to 9 pages double column excluding references. 
  Poster / Demo: Up to a maximum of 2 pages double columns including references. 
  CONTACTS:  
 Programme Chairs: papers2023@vrst.acm.org   
 Gerd Bruder, University of Central Florida (USA) 
  Tabitha Peck, Davidson University (USA) 
  Stefania Serafin, Aalborg University (Denmark) 
  Poster and Demo Chairs: posters2023@vrst.acm.org   
 Christoph Borst, University of Louisiana at Lafayette (USA) 
  Bhuvan Sarupuri, Topdesk (Hungary) 
  May 2024 | (24) 
  April 2024 | (27) 
  December 2022 | (24) 
  Recent Posts  
 Call: Real and Imagined Spaces in Film Conference | November 22, 2024 
  Study: VR and presence boost police officer empathy with people in mental health crisis | November 22, 2024 
  Jobs: Faculty positions at Northeastern U. in Extended Reality, AI and Design (Boston & Oakland) | November 21, 2024 
  Minecraft AI may represent the future of real-time video generation | November 21, 2024 
  The future of ADHD treatment? LSU’s VR research aims to help students focus and succeed | November 20, 2024 
  Recent Comments  
 Ali Alajmi  on Presence Picture #12: ‘Virtual Bowie Coupe’ on train to exhibit in Grongen, Netherlands 
  Ali Alajmi  on Presence Pictures: Robots at Work and Play 
  Jackson Neill  on Living in “third person view” with VR and a backpack-mounted camera 
  Jackson Neill  on Presence after death: Deepak Chopra made a digital clone of himself, and other celebs could soon follow 
  Jackson Neill  on Extend Robotics launches R:O:B:, a teleoperated “robotically optimised bartender”
8. VRST_3 conference:
Education  Best Online Masters in Education  Doctorate Degree in Education  Master's Degree in Education  Educational Leadership Doctoral Programs Online  Best Online Physical Education Degree    
 Social Work  Accelerated MSW Programs  Best Online Social Work Degree  LCSW Online Programs  Online MSW Programs No GRE Required  Masters Degree in Social Work Online    
 Best Online MBA Programs  Best Accelerated MBA Programs  Online MBA Programs Cost  Best MBA Acceptance Rates  How Hard is it to Get an MBA  MBA in Information Technology  Is an Online MBA Worth It?  Best Accelerated MBA Programs Online  Best Online Executive MBA Programs  Easiest Online MBA Programs    
 Popular Degree Programs  Best Doctorate Degree Online no Dissertation  Best Degrees That Make the Most Money  Best Online Certificate Programs That Pay Well  Best Online Degree Programs  Accelerated Online Degree Programs for Working Adults  Accredited Self-Paced Online Colleges?  Easiest Online Degrees That Pay Well  Easiest College Majors  Best Associate Degrees    
 Additional Degrees  Library Science Degree  Supply Chain Management Degree  Finance Degree  Accredited Online Counseling Programs  Cyber Security Degree  Best Online Graphic Design Degree  History Degree  Human Resources Degree  Best Online Nutrition Degree  Nutrition Degree  Logistics Degree  Best Library Science Degree Online  Human Services Degree  Bookkeeping Certification  Masters in Forensic Accounting    
 Home 
  Best Conferences - Computer Science 
  29th ACM Symposium on Virtual Reality Software and Technology (VRST) 
 29th ACM Symposium on Virtual Reality Software and Technology (VRST)  
   Christchurch, New Zealand  
   Submission Deadline: Monday 12 Jun 2023   
   Conference Dates: Oct 09, 2023 - Oct 11, 2023   
 Research  
  Impact Score 2.30   
 OFFICIAL WEBSITE  Conference Organizers: Deadline extended?  
  Click here to edit   
   Conference Call for Papers  
 VRST 2023 welcomes paper submissions relating (but not limited) to the following XR areas:  
  Display technology and interaction devices  
  The topics of Virtual reality, Artificial intelligence, Computer vision, Human–computer interaction and Computer graphics (images) are the focal point of discussions in the conference. The conference holds forums on Virtual reality that merges themes from other disciplines such as Virtual machine, Multimedia and Simulation, Haptic technology. Many of the studies tackled connect Multimedia with a similar field of study like Metaverse.  
 The in-depth study on Artificial intelligence also explores topics in the intersecting field of Animation. While work presented in the event provided substantial information on Computer vision, it also covered topics in Perception and Position (vector). While Human–computer interaction is the focus of Virtual Reality Software and Technology, it also provided insights into the studies of Visualization, Interface (computing) and Gesture.  
 Rendering (computer graphics) works presented in Virtual Reality Software and Technology have a specific focus on Real-time rendering. The conference features studies on Mixed reality, including topics such as Computer-mediated reality.  
 What are the most cited papers published at the conference?  
  Research areas of the most cited articles at Virtual Reality Software and Technology:  
 The conference articles mainly deal with areas of study such as Virtual reality, Artificial intelligence, Human–computer interaction, Computer vision and Computer graphics (images). The published articles focus on Virtual reality but the discussions also offer insight into other areas such as Augmented reality, Orientation (computer vision), Immersion (virtual reality) and Simulation, Haptic technology. The conference articles explore topics in Human–computer interaction which can be helpful for research in disciplines like Object (computer science), Virtual machine, Multimedia and Interface (computing).  
 Papers citation over time  
 A key indicator for each conference is its effectiveness in reaching other researchers with the papers published at that venue.  
  Tobias Hollerer | (13 papers) | published 3 papers at the last edition, 1 more than at the previous edition, 
  Anthony Steed | (10 papers) | published 4 papers at the last edition, 3 more than at the previous edition. 
  The overall trend for top authors publishing at this conference is outlined below. The chart shows the number of publications at each edition of the conference for top authors.  
 Research.com  
 French Institute for Research in Computer Science and Automation | (23 papers) | absent at the last edition, 
  University of Tokyo | (21 papers) | published 6 papers at the last edition, 3 more than at the previous edition, 
  University of Würzburg | (17 papers) | published 1 paper at the last edition, 1 less than at the previous edition, 
  Korea University | (16 papers) | published 2 papers at the last edition, 2 less than at the previous edition, 
  Chinese Academy of Sciences | (15 papers) | absent at the last edition. 
  The overall trend for top affiliations publishing at this conference is outlined below. The chart shows the number of publications at each edition of the conference for top affiliations.  
 Research.com  
 Publication chance based on affiliation  
 The publication chance index shows the ratio of articles published by the best research institutions at the conference edition to all articles published within that conference. The best research institutions were selected based on the largest number of articles published during all editions of the conference.  
 Returning Authors Index  
 A very common phenomenon observed among researchers publishing scientific articles is the intentional selection of conferences they have already attended in the past. In particular, it is worth analyzing the case when the authors participate in the same conference from year to year.  
 The Returning Authors Index presented below illustrates the ratio of authors who participated in both a given as well as the previous edition of the conference in relation to all participants in a given year.  
 Research.com  
 Returning Institution Index  
 The graph below shows the Returning Institution Index, illustrating the ratio of institutions that participated in both a given and the previous edition of the conference in relation to all affiliations present in a given year.  
 Research.com  
 The experience to innovation index  
 Our experience to innovation index was created to show a cross-section of the experience level of authors publishing at a conference. The index includes the authors publishing at the last edition of a conference  , grouped by total number of publications throughout their academic career (P) and the total number of citations of these publications ever received (C).  
 The group intervals were selected empirically to best show the diversity of the authors' experiences, their labels were selected as a convenience, not as judgment. The authors were divided into the following groups:  
 Novice - P < 5 or C < 25 (the number of publications less than 5 or the number of citations less than 25), 
 Symposium on Virtual Reality Software and Technology   
 Nov 29, 2022 - Dec 01, 2022  
 Tsukuba, Japan  
 29th ACM Symposium on Virtual Reality Software and Technology (VRST)   
 Oct 09, 2023 - Oct 11, 2023  
 Christchurch, New Zealand  
  Best Online Master’s Program in Forensic Psychology: Guide to Online Programs for 2024   
 Edit Submission Deadline  
 29th ACM Symposium on Virtual Reality Software and Technology (VRST)  
     Your email address      
  New submission deadline      
  Further information      
 SEND MESSAGE
9. VR_1 conference:
IEEE VR Conference    
 About 
  Past Conferences 
  VR VGTC Awards 
  Committees 
 Welcome to IEEE VR  
 The Premier International Conference on Virtual Reality and 3D User Interfaces  
 About the IEEE VR Conference  
  University of North Carolina, USA   
 © IEEE VR Conference | Design by Andrew Nolan
10. VR_2 conference:
About the Award  
 The IEEE VGTC Virtual Reality Best Dissertation Award is presented each year to the author of the most outstanding Ph.D. dissertation, defended during the preceding two calendar years, in the broad areas of virtual and augmented reality. The award is presented at the IEEE VR Conference  , where the winner is also invited to give a short talk about the dissertation work. The award is sponsored by the IEEE Visualization and Graphics Technical Committee (VGTC)  and the IEEE VR Steering Committee.  
 Eligibility  
  July 1st  August 31st, 2024  
 Submit a nomination    
 Praneeth Kumar Chakravarthula  
 2023 award winner  
  University of North Carolina Chapel Hill  
  2022 Katherina Krösl  
  2023 Hugo Brument, Jonathan Sutton  
  2024 Fangcheng Zhong

output:1. VLSID_3 information:
2. VMCAI_0 information:
3. VMCAI_1 information:
4. VMCAI_2 information:
5. VRST_0 information:
6. VRST_1 information:
7. VRST_2 information:
8. VRST_3 information:
9. VR_1 information:
10. VR_2 information:
