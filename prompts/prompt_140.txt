input:
1. ICML_2 conference:
Skip to yearly menu bar  Skip to main content  Main Navigation  
   ICML | Help/FAQ 
  Contact ICML 
  Downloads 
  Code of Conduct 
  2024 
  2023 
  2022 
 Showing papers for  . ×     
  ×   title   author   topic   session    
 shuffle  by   
  Mastering the Unsupervised Reinforcement Learning Benchmark from Pixels 
  Fair Neighbor Embedding 
  Robust Camera Pose Refinement for Multi-Resolution Hash Encoding 
  Effective and Efficient Structural Inference with Reservoir Computing 
  Ewald-based Long-Range Message Passing for Molecular Graphs 
  Automatically Auditing Large Language Models via Discrete Optimization 
  Efficient Transformed Gaussian Processes for Non-Stationary Dependent Multi-class Classification 
  Learning to Initiate and Reason in Event-Driven Cascading Processes 
  Robust and Scalable Bayesian Online Changepoint Detection 
  In Search of Insights, Not Magic Bullets: Towards Demystification of the Model Selection Dilemma in Heterogeneous Treatment Effect Estimation 
  Learning Neural PDE Solvers with Parameter-Guided Channel Attention 
  Margin-based sampling in high dimensions: When being active is less efficient than staying passive 
  MonoNeRF: Learning Generalizable NeRFs from Monocular Videos without Camera Poses 
  Stochastic Gradient Descent-Induced Drift of Representation in a Two-Layer Neural Network 
  Large Language Models Struggle to Learn Long-Tail Knowledge 
  Opponent-Limited Online Search for Imperfect Information Games 
  Fair Densities via Boosting the Sufficient Statistics of Exponential Families 
  User-defined Event Sampling and Uncertainty Quantification in Diffusion Models for Physical Dynamical Systems 
  Matrix Estimation for Individual Fairness 
  Better Diffusion Models Further Improve Adversarial Training 
 Successful Page Load   
 ICML uses cookies for essential functions only. We do not sell your personal information. Our Privacy Policy » | Accept Cookies 
 We use cookies to store which papers have been visited. I agree
2. ICML_3 conference:
Skip to yearly menu bar  Skip to main content  Main Navigation  
   ICML | Help/FAQ 
  Contact ICML 
  Downloads 
  Code of Conduct 
  2024 
  2023 
  2022 
  Dates 
  Calls | Call for Papers 
  Author Instructions 
  Paper Guidelines 
  Call for Tutorials 
  Accessibility Guidelines 
  Invitation Letter 
  Visa Information 
  Organizers | ICML Board 
  Organizing Committee 
  Reviewers 
  About ICML 
  Conference Site 
  ICML 2023 Call For Papers  
 We invite submissions of papers on all topics related to machine learning for the main conference proceedings. All papers will be reviewed in a double-blind process and accepted papers will be presented at the conference. As with last year, papers need to be prepared and submitted as a single file: 8 pages as main paper, with unlimited pages for references and appendix. There will be no separate deadline for the submission of supplementary material. In addition, we require that, barring exceptional circumstances (such as visa problems) upon the acceptance of their papers, at least one of the authors must attend the conference, in person.  
 Important Dates:   
 As noted above, this year, ICML will use a single paper submission deadline with a single review cycle, as follows.  
 Submissions open Jan 9th, 2023.              
 Full paper submission deadline Jan 26th, 2023 3pm EST.              
 Topics of interest include (but are not limited to):              
  Trustworthy Machine Learning (accountability, causality, fairness, privacy, robustness, etc.) 
  Applications (computational biology, crowdsourcing, healthcare, neuroscience, social good, climate science, etc.) 
  Papers published at ICML are indexed in the    Proceedings of Machine Learning Research       through the Journal of Machine Learning Research.              
 Policies               
 Deadlines:               
 Abstract and paper submission deadlines are strict. In no circumstances will extensions be given.              
 Changes of title/abstract/authorship:               
 Authors should include a full title for their paper, as well as a complete paper by the paper submission deadline. Submission titles should not be modified after the paper submission deadline. Submissions violating these rules may be deleted after the paper submission deadline without reviewing. The author list at the paper submission deadline will be considered final, and no changes in authorship will be permitted for accepted papers.              
 Double-Blind Review:               
 All submissions must be anonymized and may not contain any information with the intention or consequence of violating the double-blind reviewing policy, including (but not limited to) citing previous works of the authors or sharing links in a way that can infer any author’s identity or institution, actions that reveal the identities of the authors to potential reviewers.              
 Authors are allowed to post versions of their work on preprint servers such as arXiv. They are also allowed to give talks to restricted audiences on the work(s) submitted to ICML during the review. If you have posted or plan to post a non-anonymized version of your paper online before the ICML decisions are made, the submitted version must not refer to the non-anonymized version.              
 ICML strongly discourages advertising the preprint on social media or in the press while under submission to ICML. Under no circumstances should your work be explicitly identified as ICML submission at any time during the review period, i.e., from the time you submit the paper to the communication of the accept/reject decisions.              
 Dual Submission:               
 It is not appropriate to submit papers that are identical (or substantially similar) to versions that have been previously published, accepted for publication, or submitted in parallel to other conferences or journals. Such submissions violate our dual submission policy, and the organizers have the right to reject such submissions, or to remove them from the proceedings. Note that submissions that have been or are being presented at workshops do not violate the dual-submission policy, as long as there’s no associated archival publication.              
 Reviewing Criteria:               
 Accepted papers must be based on original research and must contain novel results of significant interest to the machine learning community. Results can be either theoretical or empirical. Results will be judged on the degree to which they have been objectively established and/or their potential for scientific and technological impact. Reproducibility of results and easy availability of code will be taken into account in the decision-making process whenever appropriate.              
 Ethics:               
 Authors and members of the program committee, including reviewers, are expected to follow standard ethical guidelines. Plagiarism in any form is strictly forbidden as is unethical use of privileged information by reviewers, ACs, and SACs, such as sharing this information or using it for any other purpose than the reviewing process. Papers that include text generated from a large-scale language model (LLM) such as ChatGPT are prohibited unless these produced text is presented as a part of the paper’s experimental analysis. All suspected unethical behaviors will be investigated by an ethics board and individuals found violating the rules may face sanctions. This year, we will collect names of individuals that have been found to have violated these standards; if individuals representing conferences, journals, or other organizations request this list for decision making purposes, we may make this information available to them.          
 Details of the LLM guideline are now available here  .          
 Financial aid:               
 E    ach paper submission may, by providing a corresponding icml.cc account email address, designate up to one student author who, should the paper be accepted, would not be able to present the work unless partially supported by a grant from the conference. Doing so confirms (1) financial need, (2) intention to attend and present in person and (3) willingness to volunteer at the conference for two 4 hour shifts. ICML aims to provide free conference registration and hotel registration for at least part of the week. The number of such awards are limited.                
 OpenReview and Rankings:               
 This year we will use OpenReview and we will require that authors of multiple submissions, upon submission confirmation, submit a rank ordering of their papers from their own perspective. For this year, we seek this information to assess consistency of self-perception with respect to review outcomes. We will not share rankings with co-authors, reviewers, ACs, or SACs. Rankings will not be used in decision-making processes.  
 Author Instructions                ,      Style Files                and an    Example Paper       . Submitted papers that do not conform to these policies will be rejected without review. Authors are kindly asked to make their submissions as accessible as possible for everyone including people with disabilities and sensory or neurological differences.              
 Successful Page Load   
 ICML uses cookies for essential functions only. We do not sell your personal information. Our Privacy Policy » | Accept Cookies 
 The ICML Logo above may be used on presentations. Right-click and choose download. It is a vector graphic and may be used at any scale.  
 Useful links  
 About ICML   
 ICML Proceedings at PMLR   
 Code of Conduct   
  Email   
 ICML Proceedings at PMLR
3. ICMR_0 conference:
Workshop Proposals 
  Authors | Menu Toggle | Presentation Instructions 
  Paper submissions 
  Attendees | Menu Toggle | Registration 
  Travel Grants 
 Main Menu            
 ICMR 2023  
 12 - 15 June  
 Thessaloniki, Greece  
 News and Updates  
 Here you can find the latest news. Keep checking back for all the updates. 13/06/2023: | Best paper award of ICMR 2023 goes to | Giacomo Nebbia | and | Adriana Kovashka | for the paper “ | Hypernymization of Named Entity-rich captions for grounding-based multi-modal pretraining | “ 
  24/05/2023: | Detailed program is | announced | . 
  17/05/2023: | Draft program is | announced | . 
  08/05/2023 | : Accepted papers are | announced | . 
  25/04/2023 | : As announced, | ICMR 2023 | will be a physical first event providing online participation as a secondary option. More specifically, we will be streaming the physical presentations in real-time, but we will not support questions and discussion with remote participants. For those unable to attend in person, we will be providing dedicated online sessions where remote presenters can share their presentations and answer questions from the physically present audience. 
  19/04/2023 | : The (extended) deadline for submitting the camera ready papers is April 25. 
  13/04/2023 | : Registration is open! Bank transfer and credit card payment options are available. To complete your registration use this | link | . 
  10/04/2023 | : Registration fees are | announced | . Payments options will be soon available. 
  07/04/2023 | : Electra Palace Hotel will be the | venue | for ICMR2023 
  14/03/2023 | : ICMR2023 offers | student travel grants 
  22/02/2023 | : 3 Keynote speakers are | announced | . 
  18/01/2023: | Given the current pandemic situation, the conference is planned as a physical-first event. That means that it is highly recommended and preferred for paper authors to attend in person and present their papers. If that turns out impossible, special exceptions may be considered. 
 Welcome to ACM ICMR 2023  
 Following its tradition, the ACM International Conference on Multimedia Retrieval in 2023 will present significant and innovative research in multimedia retrieval and related fields. The scope of the conference includes core topics in multimedia retrieval and recommendation, as well as the broader set of topics that must be addressed to ensure that multimedia retrieval technologies are of practical use in real-world use cases. Special emphasis will be placed on topics related to large-scale indexing, mixed reality user interaction, exploiting diverse and multimodal data, and domain-specific challenges.  
 Sponsored by  
  Workshop Proposals 
  Authors | Menu Toggle | Presentation Instructions 
  Paper submissions 
  Attendees | Menu Toggle | Registration 
  Travel Grants 
  Sponsor and Supporters 
 ICMR 2023  
 12 – 15 June  
  Thessaloniki, Greece
4. ICMR_1 conference:
You are here  
 Home    
  ACM International Conference on Multimedia Retrieval (ICMR)  
 Date:   
  Research Archives Section 
  Constitution 
  Executive Board | Executive Board elections | Election 2023 
  Previous Board members 
  History 
 Looking for a place to buy large size stylus (4-8 mil) in EU 
  Aviary issues 
  2023 ASRA conference call for papers 
 More
5. ICMR_3 conference:
2022   
 MAD@ICMR 2022: Proceedings of the 1st International Workshop on Multimedia AI against Disinformation, Newark, NJ, USA, June 27 - 30, 2022 | 13 papers 
  ICDAR@ICMR 2022: Proceedings of the 3rd ACM Workshop on Intelligent Cross-Data Analysis and Retrieval, Newark, NJ, USA, June 27 - 30, 2022 | 12 papers 
  LSC@ICMR 2022: Proceedings of the 5th Annual on Lifelog Search Challenge, Newark, NJ, USA, June 27 - 30, 2022 | 11 papers 
 Credits  • Contribute   ©2023 Webis Group  •       • Contact  • Impressum / Terms / Privacy
6. ICMV_0 conference:
Home | Welcome Letter 
  The 17th  ICMV+ | Programme 
  Conference Venue 
  VISA 
  Committee+ | Organizing Committee 
  Technical Committee 
  Keynote+ | ICMV 2024 Speakers 
  Keynote Gallery 
  Special Session+ | Call for Special Sessions 
  Special Sessions 
  Submission+ | Call for Paper 
  Submission Guidance 
  Key Dates 
  Registration+ | Instruction 
  Registration Fee 
  ICMV 2023 Yerevan 
  ICMV 2022 Rome Hybrid Conf. 
  Contact Us 
 About The 16th ICMV 2023, Yerevan, Armenia   
 It was on occasion of the 15th ICMV in Rome where we discussed the next topics and location for the forthcoming 2023 conference. Among the conference chairs there was an agreement to put stronger attention to recent findings in tomography and to use as conference place the Russian Armenian University in Yerevan where important contributions to the field were delivered. Thus we had 3 interesting days in Armenia filled with nice presentations and stimulating discussions during Nov. 15-18, 2023   
  - Camera-Based and Mobile Recognition (chaired by Konstantin Bulatov)  
  - Advanced Imaging and Tomography (chaired by Ehrenfried Zschech)  
  - Document Analysis, Recognition, and Forgery Detection: Pioneering Solutions for the Digital Age (chaired by Vladimir Artazarov)  
  - a Poster Session (chaired by Marina Chukalina)   
  The conference ended as usual with an award ceremony for the best papers given in all sessions. 7 awardees could be recognized for their outstanding presentations.   
 If you need more presentation photo, please contact with secretary@icmv.org   
 "We sincerely invite you and your colleagues immediately mark this event on your calendar and make your plans to Edinburgh, UK   !"   
 Copyright © 2024 17th International Conference on Machine Vision (www.icmv.org)
7. ICMV_1 conference:
Contact us 
 (ICMV 2023) 2023 The 16th International Conference on Machine Vision  
 artificial intelligence  Computer Science and Technologies   
  Conference Date  
  Nov 15-Nov 18, 2023  
  Place  
  Yerevan, Armenia  
  Submission Deadline  
  Oct 05, 2023  
  E-mail  
  secretary@icmv.org  
  Website  
 Description  
 Full name: SPIE--2023 The 16th International Conference on Machine Vision (ICMV 2023)  
  Abbreviation: ICMV 2023  
  ★2023 The 16th International Conference on Machine Vision (ICMV 2023)★  
  2023 The 16th International Conference on Machine Vision (ICMV 2023) is going to be held at Yerevan, Armenia.  
  Accepted and presented papers of ICMV 2023 will be published by SPIE, to be included in SPIE Digital Library, provided to the Web of Science Conference Proceedings Citation Index-Science, Scopus, Ei Compendex, etc, to ensure maximum awareness of the Proceedings.  
  ◆ICMV History:  
  …  
  ◆Call for Paper:  
  SPECIAL SESSION I: Camera Based and Mobile Recognition  
  SPECIAL SESSION II: Advanced Imaging and Tomography  
  SPECIAL SESSION III: Machine Vision for Autonomous Driven Cars under Harsh Environmental Conditions  
  via Easychair System:  
  For any inquires, please contact us via email: secretary@icmv.org;  
  ◆Contact:
8. ICMV_2 conference:
Home | Welcome Letter 
  The 17th  ICMV+ | Programme 
  Conference Venue 
  VISA 
  Committee+ | Organizing Committee 
  Technical Committee 
  Keynote+ | ICMV 2024 Speakers 
  Keynote Gallery 
  Special Session+ | Call for Special Sessions 
  Special Sessions 
  Submission+ | Call for Paper 
  Submission Guidance 
  Key Dates 
  Registration+ | Instruction 
  Registration Fee 
  ICMV 2023 Yerevan 
  ICMV 2022 Rome Hybrid Conf. 
  Contact Us 
 ICMV Conference Proceedings   
 ICMV 2023-SPIE   
 Yerevan, Armenia | Nov. 15-18, 2023  
  Proceedings, online here.  successfully indexed by Web of SCI-ISI  , EI Compendex  and SCOPUS  . | ICMV 2022-SPIE   
 Rome, Italy | Nov. 18-20, 2022  
  Proceedings, online here   
 "We sincerely invite you and your colleagues immediately mark this event on your calendar and make your plans to Edinburgh, UK   !"   
 Copyright © 2024 17th International Conference on Machine Vision (www.icmv.org)
9. ICMV_3 conference:
Individual Subscriptions 
  Conference Proceedings | Conference Content Publication Services 
  SPIE Press Books | Book Author Information 
  Book Manuscript Guidelines 
  Submit a Book Proposal 
  Spotlights Call for Authors 
  Field Guide Author Guidelines 
  New Books from SPIE Press | Titles include "Optics using Python" and "Designing Optics Using Zemax OpticStudio" | Visit the Bookstore | Home 
  Publications Home 
  SPIE Press Books | SPIE Press Books | Publications 
  SPIE Press Books 
  Book Author Information 
  Book Manuscript Guidelines 
  Submit a Book Proposal 
  Spotlights Call for Authors 
  Field Guide Author Guidelines 
   New Books from SPIE Press  Titles include "Optics using Python" and "Designing Optics Using Zemax OpticStudio"  Visit the Bookstore 
  Membership | Membership | Membership Home 
  Photonics Focus 
  Optics.org 
  Latest Issue of Photonics Focus | Nov/Dec issue examines the past, present, and future of the laser. | Nov-Dec 2024 | Home 
  News Home | News Home | News 
  News Home 
  Photonics Focus 
  Optics.org 
   Latest Issue of Photonics Focus  Nov/Dec issue examines the past, present, and future of the laser.  Nov-Dec 2024 
  About | About | About SPIE Home 
  About the Society | Mission and Vision 
  SPIE Press Books | Publications 
  SPIE Press Books 
  Book Author Information 
  Book Manuscript Guidelines 
  Submit a Book Proposal 
  Spotlights Call for Authors 
  Field Guide Author Guidelines 
 Publications    Bookstore    Conference Proceedings    
 Sixteenth International Conference on Machine Vision (ICMV 2023)  
 Wolfgang Osten     
 Sixteenth International Conference on Machine Vision (ICMV 2023)  
 Wolfgang Osten     
 Date Published: 4 April 2024   
 Conference: Sixteenth International Conference on Machine Vision (ICMV 2023) 2023   
 Quantization method for bipolar morphological neural networks  Elena Limonova  ,  Michael Zingerenko  ,  Dmitry Nikolaev  ,  et al.    
 Show abstract   
 In the paper, we present a quantization method for bipolar morphological neural networks. Bipolar morphological neural networks use only addition, subtraction, and maximum operations inside the neuron and exponent and logarithm as activation functions of the layers. These operations allow fast and compact gate implementation for FPGA and ASIC, which makes these networks a promising solution for embedded devices. Quantization allows us to reach an additional increase in computational efficiency and reduce the complexity of hardware implementation by using integer values of low bitwidth for computations. We propose an 8-bit quantization scheme based on integer maximum, addition, and lookup tables for non-linear functions and experimentally demonstrate that basic models for image classification can be quantized without noticeable accuracy loss. More advanced models still provide high recognition accuracy but would benefit from further fine-tuning.   
 Fast keypoint filtering for feature-based identity documents classification on complex background  Nargiza Z. Valishina  ,  Alexander V. Gayer  ,  Natalya S. Skoryukina  ,  et al.    
 Segmentation of human olfactory bulb glomeruli on its phase-contrast tomographic images with neural networks  Aleksandr Smolin  ,  Marina Chukalina  ,  Inna Bukreeva  ,  et al.    
 Show abstract   
 The human olfactory bulb (OB), an important part of the brain responsible for the sense of smell, is a complex structure composed of multiple layers and cell types. Studying the OB morphological structure is essential for understanding the decline in olfactory function related to aging, neurodegenerative disorders, and other pathologies. Traditional microscopy methods in which slices are stained with solutions to contrast individual elements of the morphological structure are destructive. Non-destructive high-resolution technique is the X-ray phase-contrast tomography. However, manual segmentation of the reconstructed images are time-consuming due to large amount of data and prone to errors. U-Net-based model to optimize the segmentation of OB morphological structures, focusing specifically on glomeruli, in tomographic images of the human OB is proposed. The strategy to address overfitting and enhance the model's accuracy is described. This method addresses the challenges posed by complex limited data containing abundant details, similar grayscale levels between soft tissues, and blurry image details. Additionally, it successfully overcomes the limitations of a small dataset containing images with extremely dense point clouds, preventing the models from overfitting.   
 CattleDeSegNet: a joint approach to cattle denoising and interpretable segmentation  Sivaji Retta  ,  Ramarajulu Srinivasan  ,  Shawn Tan     
 Show abstract   
 In modern agriculture, livestock monitoring plays a vital role in ensuring animal health, welfare, and production efficiency. Leveraging computer vision and deep learning, this paper presents an innovative framework aimed at enhancing livestock monitoring. Specifically, we address two crucial challenges: denoising and segmentation of cattle in livestock images. The denoising task is fundamental in preprocessing noisy images affected by adverse environmental conditions and equipment limitations. To tackle this, we introduce an encoder-decoder model that effectively denoises cattle images while preserving critical anatomical details. Our framework incorporates a segmentation module inspired by the U-Net architecture. Notably, both denoising and segmentation tasks share a common encoder, optimizing computational efficiency. The segmentation model employs hybrid loss functions and leverages the Grad-CAM technique to provide interpretable insights into the decision-making process. Our approach stands as one of the pioneering joint solutions for cattle denoising and segmentation, particularly focusing on top-view cattle images.   
 Pattern Recognition   
 Building an optimal document authentication system  A. D. Bursikov  ,  S. A. Usilin  ,  I. A. Kunina     
 Show abstract   
 In this work, a probabilistic approach to assessing the quality of a system for determining the authenticity of documents in the images is considered. The considered system is based on the aggregation of responses of various checks of the security elements of the document. We propose a probabilistic model of the document authentication system and the functional for evaluating the quality of the system. Based on them, we offer an approach for assessing the quality of the separate part and the whole system. Finally, the approach to constructing an optimal function of making a final decision is obtained.   
 Multilanguage ID document images synthesis for testing recognition pipelines  Yulia S. Chernyshova  ,  Konstantin K. Suloev  ,  Vladimir V. Arlazarov     
 Enhanced multiple-instance pruning for learning soft cascade detectors  Daniil P. Matalov  ,  Vladimir V. Arlazarov     
 Show abstract   
 Object detection is one of the most common problems solved by computer vision systems. Even though neural network methods have become a standard tool for solving the problems, these methods have many disadvantages, which include high computational power requirements both for training and inference stages and tremendous training sets. This paper considers such a classical method for object detection as the Viola and Jones method and proposes an enhanced soft cascade calibration method based on Multiple-Instance Pruning to increase detection performance. The proposed method considers a response of the classifier to an image region as a random variable and follows a statistical approach to provide robust detectors. In addition, the paper addresses the problem of non-conformity of detection parameters at training and inference stages and studies performance decline. The performance of the proposed methods is demonstrated in a variety of practical tasks, including identity document detection and document fraud detection.   
 Limitations of anomaly detection: beyond which size defects can be reliably recognized  Jan Lehr  ,  Martin Pape  ,  Jan Philipps  ,  et al.    
 L-shape fitting algorithm for 3D object detection in bird’s-eye-view in an autonomous driving system  Mikhail O. Chekanov  ,  Oleg S. Shipitko     
 Show abstract   
 The ability of autonomous vehicles (AVs) to detect three-dimensional objects is crucial for motion planning, object tracking and safe driving. This task is especially challenging for systems using only monocular cameras, for which depth estimation presents special difficulties. In this paper, we discuss the subsystem of 3D object detection in bird’s-eye-view (BEV) for a single camera in an AV system. The subsystem consists of two parts. First, it estimates the contour of the object’s projection polygon in BEV based on 2D detection and drivable area segmentation (a planar ground model is used). Second, it simplifies the object’s projection by fitting the obtained polygon to a rotated bounding box. For this part we propose a new L-shape model-based fitting algorithm. It assumes that the vertices of the input polygon belong to two adjacent sides of the fitted bounding box. We compared this algorithm with a naive approach which minimizes the bounding box’s area and with adaptations of algorithms from a paper solving a similar problem with LiDAR point clouds. The L-shape algorithm outperformed the alternatives.   
 False positive elimination in object detection methods for videos  Shubham Kumar Dubey  ,  J. V. Satyanarayana  ,  C. Krishna Mohan     
 Incremental one-class learning using regularized null-space training for industrial defect detection  Matthias Hermann  ,  Georg Umlauf  ,  Bastian Goldlücke  ,  et al.    
 Show abstract   
 One-class incremental learning is a special case of class-incremental learning, where only a single novel class is incrementally added to an existing classifier instead of multiple classes. This case is relevant in industrial defect detection scenarios, where novel defects usually appear during operation. Existing rolled-out classifiers must be updated incrementally in this scenario with only a few novel examples. In addition, it is often required that the base classifier must not be altered due to approval and warranty restrictions. While simple finetuning often gives the best performance across old and new classes, it comes with the drawback of potentially losing performance on the base classes (catastrophic forgetting [1]). Simple prototype approaches [2] work without changing existing weights and perform very well when the classes are well separated but fail dramatically when not. In theory, null-space training (NSCL) [3] should retain the basis classifier entirely, as parameter updates are restricted to the null space of the network with respect to existing classes. However, as we show, this technique promotes overfitting in the case of one-class incremental learning. In our experiments, we found that unconstrained weight growth in null space is the underlying issue, leading us to propose a regularization term (R-NSCL) that penalizes the magnitude of amplification. The regularization term is added to the standard classification loss and stabilizes null-space training in the one-class scenario by counteracting overfitting. We test the method’s capabilities on two industrial datasets, namely AITEX and MVTec, and compare the performance to state-of-the-art algorithms for class-incremental learning.   
 Detection of fingers in document images captured in uncontrolled environment  L. S. Tolstenko  ,  I. A. Kunina     
 Methods for non-intrusive out-of-distribution images detection  Anastasiia V. Vlasova  ,  Aleksandr Yu. Shkanaev  ,  Dmitry L. Sholomov     
 Show abstract   
 Selecting representative data is a key factor in improving the performance of machine learning algorithms. In this paper we focus on out-of-distribution (OoD) methods evaluation, which can be integrated into ML project lifecycle in a nonintrusive way, without changing a model architecture. Considered methods are applicable to image classification datasets analysis. In addition to commonly used AUROC metric, we evaluate the number of out-of-distribution samples misclassified with high confidence. Case studies were conducted on benchmark and production datasets. As a result, we provide practical guidance for data evaluation and recommendations on which method to use to detect different types of OoD images.   
 Image edge detection using pseudo-Boolean polynomials  Tendai Mapungwana Chikake  ,  Boris Goldengorin     
 Show abstract   
 We introduce a novel approach for image edge detection based on calculating pseudo-Boolean polynomials on image patches whose resulting polynomial degrees determine whether a patch lies over an edge or a blob. In this paper we show that patches covering edge regions  within the image result in pseudo-Boolean polynomials of higher degrees compared to patches that cover blob  regions. The proposed approach is based on reduction  of polynomial degree and equivalence  properties of penalty-based pseudo-Boolean polynomials.   
 Specialized indoor and outdoor scene-specific object detection models  Mahtab Jamali  ,  Paul Davidsson  ,  Reza Khoshkangini  ,  et al.    
 Point scene understanding via points-to-mesh reconstruction and multi-level utilization of proposals  Mengxiang Hao  ,  Hang Wu  ,  Ruchong Fu  ,  et al.    
 Show abstract   
 Semantic scene reconstruction from sparse and incomplete point clouds is a critical task for point scene understanding. It aims to recognize semantic labels for objects and recover their complete shapes as meshes. Existing methods often fail to realize high-quality instance reconstruction due to inadequate shape representation and underutilization of proposal point clouds. To address these issues, we optimize the previous BSP/occupancy-to-mesh reconstruction framework to points-to-mesh and accomplish multi-level utilization of proposals. We chose point cloud as the representation of completion to reduce the difficulty of restoring curved shallow parts. Benefiting from the optimization, we can match and merge proposal point clouds with the restored ones, avoiding missing parts existing in inputs. We design an effective pose normalization module to extract point-based features from normalized proposals, which are fused with features extracted from voxelized proposals, avoiding the detailed geometry lost in voxelization and enhancing the reconstruction's robustness to different input postures. The suitable points-to-mesh reconstruction framework and full utilization of proposals make our method improve reconstruction results efficiently. Detailed experiments on the challenging ScanNet dataset of the semantic scene reconstruction benchmark show that our network outperforms state-of-the-art methods in both completion and mapping metrics.   
 Search for image quality metrics suitable for assessing images specially precompensated for users with refractive errors  Nafe B. Alkzir  ,  Ilya P. Nikolaev  ,  Dmitry P. Nikolaev     
 Spectral filters design for a better hyperspectral reconstruction  Daniil Reutskii  ,  Egor Ershov     
 Show abstract   
 Spectral reconstruction (recovering spectra from RGB measurements) is a vital problem of computational photography. As a matter of curiosity, modern mobile devices open a new opportunity to improve the quality of spectral reconstruction by utilizing images from several cameras at once. This leads to the idea of creating a mobile hyperspectral camera for the general public. In this paper we investigate the achievable accuracy when using several identical cameras simultaneously in combination with different spectral filters. To find optimal filters, two algorithms are proposed: one learns spectral transmittance functions simultaneously with spectral reconstruction, the other learns only spectral transmittances by information loss minimization. As a result of numerical experiments, 4 cameras and 4 filters allow us to perform spectral reconstruction two times accurately than from a single RGB image.   
 Method of color image formation taking into account the human perception features  N. A. Obukhova  ,  A. A. Motyko  ,  A. A. Pozdeev  ,  et al.    
 Distortion-aware super-resolution for planetary exploration images  N. Landro  ,  I. Gallo  ,  F. Pelosi  ,  et al.    
 Show abstract   
 Super-resolution is crucial in computer vision and digital image processing, aiming to enhance low-quality images’ resolution and visual quality. This paper focuses on correcting the distortion introduced by fisheye lenses and improving the resolution of images for better detail representation. Specifically, we propose an evaluation approach that benchmarks three state-of-the-art models in different categories: Real-ESRGAN (convolutions), SwinIR (transformers), and SR3 (diffusion). We evaluate their performance in super-resolution and distortion correction tasks using metrics such as PSNR and SSIM. To facilitate this evaluation, we create and release a new dataset of lunar surface images with fisheye distortion applied. Our experiments demonstrate the effectiveness of each model in handling distortion and improving image resolution. The results show that large models generally outperform medium models, and PSNR models achieve higher PSNR and SSIM scores than GAN models. Additionally, we evaluate the distortion correction by comparing the corrected images with ground truth. Our findings contribute to understanding different model categories and their performance in super-resolution and distortion correction tasks. The proposed dataset and evaluation approach can be valuable resources for future research.   
 Robust automatic rotation axis alignment mean projection image method in cone-beam and parallel-beam CT  Danil Kazimirov  ,  Anastasia Ingacheva  ,  Alexey Buzmakov  ,  et al.    
 Show abstract   
 The rotation axis position is an important parameter of classical reconstruction algorithms in X-ray computed tomography (CT). The use of incorrect values of the axis position parameters during the reconstruction leads to the appearance of various artifacts distorting the reconstructed image. Therefore, to obtain a reconstruction of better quality, automatic rotation axis position determination and misalignment correction methods are of use. Most of the existing high-precision automatic rotation axis position determination methods are either fast, but suitable only within a parallel-beam geometric scheme, or indifferent to the geometric scheme, but computationally laborious. In this paper, we propose a method for auto-detection of two scalar parameters of rotation axis position — axis shift and tilt in the plane parallel to the detector window plane — using a pixel-wise arithmetically averaged projection image. The described method is highly accurate within both parallel-beam and cone-beam geometric schemes whereas it is characterized by robustness to noise in projection data. The method has performed an increase in reconstruction quality when compared with some well-known and still used in practice methods both on synthetic data and on real data obtained in real laboratory conditions.   
 StereoYolo+DeepSORT: a framework to track fish from underwater stereo camera in situ  Aya Saad  ,  Stian Jakobsen  ,  Morten Bondø  ,  et al.    
 Show abstract   
 This paper presents a 3D multiple object detection and tracking framework for identifying and quantifying changes in fish behaviour through tracking the 3D position, distance and speed of fish with respect to an underwater stereo camera. The framework consists of six essential modules based on 3D object detection to identify fish and multiple object tracking algorithms to track the fish in sequential frames. In particular, the latest version of Yolo (Yolov7) is utilised for object detection and the deep SORT algorithm is used for multiple object tracking. The framework was tested using videos captured from an underwater stereo camera in an industrial-scale sea-based fish farm. The results showed that the framework was able to accurately detect and track multiple fish in 3D. The fish position, distance and speed relative to the camera were also successfully detected. The results of this study demonstrate the effectiveness of this framework in identifying and quantifying changes in fish behaviour. The proposed novel framework has the potential to greatly enhance our understanding of fish behaviour in their natural habitats, leading to new insights into fish ecology and behaviour, while at the same time, it can enable researchers to study fish behaviour in a more detailed and accurate way.   
 CADCP: a method for chromatic haze compensation on remotely sensed images  D. S. Sidorchuk  ,  M. A. Pavlova  ,  D. O. Kushchev  ,  et al.    
 Show abstract   
 Remote sensing images often suffer from different types of haze. Its presence significantly complicates remotely sensed image analysis that is crucial for monitoring of land state and precision agriculture. Currently existing remote sensing dehazing methods are designed for achromatic haze, but in cases such as smoke from fires or sandstorms, the haze may have its own pronounced coloration. In this paper we propose a new hazed image formation model that considers chromatic haze. Using this model we propose a new single image dehazing method CADCP that is based on color attenuation and dark channel priors. For quality assessment of the proposed method we generated a dataset of remotely sensed images with simulated chromatic haze. The generated dataset includes data with various haze spatial distribution and density. Quality evaluation results including qualitative and quantitative approaches demonstrated better results of the proposed method comparing with other existing methods.   
 Data-Based Intelligent Computing and Algorithm   
 A data parallel approach for distributed neural networks to achieve faster convergence  Nagaraju C.  ,  Yenda Ramesh  ,  C. Krishna Mohan     
 Show abstract   
 The availability of large datasets has significantly contributed to recent advancements in deep Convolutional Neural Network (CNN) models. However, training a large CNN model using such datasets is a time-consuming task. This issue has been addressed by the parallelization and distribution of data/model during the training process. There are two ways to implement distributed deep learning processes: data parallelism and model parallelism. Data parallelism involves distributing the dataset across multiple workers, allowing them to process different portions simultaneously. While increasing the number of workers can reduce computation time, it also introduces additional communication time. In some cases, the increased communication time can outweigh the benefits gained from reduced computation time. In this paper, our focus is on reducing the overall computation time of data parallel approach by employing two strategies. First, we emphasize the preservation of dataset distribution across all workers, ensuring that each worker has access to representative data. Second, we explore the localization of parameters and the quantization of gradients to three levels: {-1, 0, 1} to reduce communication delays between the server and workers, as well as between workers themselves. By adopting these two strategies, we aim to enhance the performance of data parallel approach in the distributed deep learning processes. As a result of preserving the distribution of the data while sampling the entire data, each partition retains a similar mean and variance (capturing important first and second-order statistics). This approach guarantees that all worker machines train their local models on uniformly distributed data instead of random distribution. Additionally, localizing parameters limits the communication between the server and workers to gradients only. Furthermore, by quantizing gradients to 2-bits, we successfully achieve our objective of reducing computation time by enabling faster convergence without compromising test or validation accuracy. The experimental results demonstrate that employing these strategies in distributed deep learning effectively reduces communication overhead and leads to faster convergence when compared to methods that utilize random data sampling. These improvements were observed across multiple datasets such as MNIST, CIFAR-10, and Tiny ImageNet.   
 Quantum time series forecasting  Prashant Gohel  ,  Manjunath Joshi     
 CG-MER: a card game-based multimodal dataset for emotion recognition  Nisrine Farhat  ,  Amine Bohi  ,  Leila Ben Letaifa  ,  et al.    
 Show abstract   
 The field of affective computing has seen significant advancements in exploring the relationship between emotions and emerging technologies. This paper presents a novel and valuable contribution to this field with the introduction of a comprehensive French multimodal dataset designed specifically for emotion recognition. The dataset encompasses three primary modalities: facial expressions, speech, and gestures, providing a holistic perspective on emotions. Moreover, the dataset has the potential to incorporate additional modalities, such as Natural Language Processing (NLP) to expand the scope of emotion recognition research. The dataset was curated through engaging participants in card game sessions, where they were prompted to express a range of emotions while responding to diverse questions. The study included 10 sessions with 20 participants (9 females and 11 males). The dataset serves as a valuable resource for furthering research in emotion recognition and provides an avenue for exploring the intricate connections between human emotions and digital technologies.   
 ABOUT
10. ICNC_1 conference:
Home 
 The 2023 14th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD 2023) will be held from 28-30 July 2023 in Huangshan, China.  Huangshan (literal meaning: Yellow Mountain) is a UNESCO World Heritage Site, and one of China's major tourist destinations. It is well known for its scenery, sunsets, peculiarly-shaped granite peaks, Huangshan pine trees, hot springs, winter snow, and views of the clouds from above. Huangshan is a frequent subject of traditional Chinese paintings and literature, as well as modern photography. A famous saying goes: "You don't need to see any more mountains after seeing 'the Five Mountains', and you don't need to see the other four mountains after seeing Huangshan."  
 ICNC-FSKD is a premier international forum for scientists and researchers to present the state of the art of data mining and intelligent methods inspired from nature, particularly biological, linguistic, and physical systems with applications to computers, circuits, systems, control, communications  , and more. This is an exciting and emerging interdisciplinary area in which a wide range of theory and methodologies are being investigated and developed to tackle complex and challenging problems. The registration fee includes proceedings, lunches, dinners banquet, coffee breaks, and all technical sessions.  
 Prospective authors are invited to submit manuscripts written in English. All submissions will be peer-reviewed by experts in the field based on originality, significance, quality and clarity. Authors should use the Latex style files or MS-Word templates obtained from the conference site to format their papers. Authors should submit PDF files of their manuscripts via the online submission system. Submissions imply that the papers have not been submitted elsewhere and will not be submitted elsewhere for publications before the review decisions of this conference. 
 JOURNAL SPECIAL ISSUE 
 The International Journal of Fuzzy Systems (IJFS) is an official journal of Taiwan Fuzzy Systems Association (TFSA) and is published quarterly. IJFS will consider high quality papers that deal with the theory, design, and application of fuzzy systems, soft computing systems, grey systems, and extension theory systems ranging from hardware to software. Survey and expository submissions are also welcome.  
 ICNC-FSKD is a premier international forum for scientists and researchers to present the state of the art of data mining and intelligent methods inspired from nature, particularly biological, linguistic, and physical systems with applications to computers, circuits, systems, control, communications  , and more. This is an exciting and emerging interdisciplinary area in which a wide range of theory and methodologies are being investigated and developed to tackle complex and challenging problems. The registration fee includes proceedings, lunches, dinners banquet, coffee breaks, and all technical sessions.  
 Prospective authors are invited to submit manuscripts written in English. All submissions will be peer-reviewed by experts in the field based on originality, significance, quality and clarity. Authors should use the Latex style files or MS-Word templates obtained from the conference site to format their papers. Authors should submit PDF files of their manuscripts via the online submission system. Submissions imply that the papers have not been submitted elsewhere and will not be submitted elsewhere for publications before the review decisions of this conference. | JOURNAL SPECIAL ISSUE | The International Journal of Fuzzy Systems (IJFS) is an official journal of Taiwan Fuzzy Systems Association (TFSA) and is published quarterly. IJFS will consider high quality papers that deal with the theory, design, and application of fuzzy systems, soft computing systems, grey systems, and extension theory systems ranging from hardware to software. Survey and expository submissions are also welcome.  
 Home 
 The 2023 14th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD 2023) will be held from 28-30 July 2023 in Huangshan, China.  Huangshan (literal meaning: Yellow Mountain) is a UNESCO World Heritage Site, and one of China's major tourist destinations. It is well known for its scenery, sunsets, peculiarly-shaped granite peaks, Huangshan pine trees, hot springs, winter snow, and views of the clouds from above. Huangshan is a frequent subject of traditional Chinese paintings and literature, as well as modern photography. A famous saying goes: "You don't need to see any more mountains after seeing 'the Five Mountains', and you don't need to see the other four mountains after seeing Huangshan."  
 ICNC-FSKD is a premier international forum for scientists and researchers to present the state of the art of data mining and intelligent methods inspired from nature, particularly biological, linguistic, and physical systems with applications to computers, circuits, systems, control, communications  , and more. This is an exciting and emerging interdisciplinary area in which a wide range of theory and methodologies are being investigated and developed to tackle complex and challenging problems. The registration fee includes proceedings, lunches, dinners banquet, coffee breaks, and all technical sessions.  
 Prospective authors are invited to submit manuscripts written in English. All submissions will be peer-reviewed by experts in the field based on originality, significance, quality and clarity. Authors should use the Latex style files or MS-Word templates obtained from the conference site to format their papers. Authors should submit PDF files of their manuscripts via the online submission system. Submissions imply that the papers have not been submitted elsewhere and will not be submitted elsewhere for publications before the review decisions of this conference. 
 JOURNAL SPECIAL ISSUE 
 The International Journal of Fuzzy Systems (IJFS) is an official journal of Taiwan Fuzzy Systems Association (TFSA) and is published quarterly. IJFS will consider high quality papers that deal with the theory, design, and application of fuzzy systems, soft computing systems, grey systems, and extension theory systems ranging from hardware to software. Survey and expository submissions are also welcome.

output:1. ICML_2 information:
2. ICML_3 information:
3. ICMR_0 information:
4. ICMR_1 information:
5. ICMR_3 information:
6. ICMV_0 information:
7. ICMV_1 information:
8. ICMV_2 information:
9. ICMV_3 information:
10. ICNC_1 information:
