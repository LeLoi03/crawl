input:
1. WSCG_1 conference:
Eurographics PhD Award 
  EuroVis PhD Award 
  Best Paper Awards 
  PUBLICATIONS | open dropdown menu | Eurographics Publications 
  Computer Graphics Forum 
 This event has passed. 
 WSCG 2023 International Conferences in Central Europe on Computer Graphics, Visualization and Computer Vision  
 May 15, 2023  - May 19, 2023   
 «  EUROGRAPHICS 2023 
  EuroVis 2023 » 
 31. International Conference on Computer Graphics, Visualization and Computer Vision 2023   
 The WSCG 2023 event is expected to be held physically with a virtual presentation option  
  Workshops/ Special sessions proposals are expected   
 in cooperation with Eurographics Association, ACM and SIGGRAPH listed  
 + Google Calendar  + iCal Export    
 Details  
 Start:  May 15, 2023   End:  May 19, 2023   Event Category:  In cooperation event      
 Venue  
 Plzen  Univerzitni 8   
 «  EUROGRAPHICS 2023 
  EuroVis 2023 » 
 Sidebar  
 Upcoming Events  
 ICAT-EGVE2024: International Conference on Artificial Reality and Telexistence & Eurographics Symposium on Virtual Environments | December 1  - December 3
2. WSCG_2 conference:
Home    Categories    About    Call for Papers     
 WSCG 2023 : 31. International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision 2023   
  Prague/Pilsen 
 Event Date: | May 15, 2023 - May 19, 2023 
 Submission Deadline: | January 30, 2023 
 Notification of Acceptance: | March 30, 2023 
 Camera Ready Version Due: | April 15, 2023 
  GO TO WEBSITE        
 Call for Papers 
 31.Int.Conf. on Computer Graphics, Visualization and Computer Vision 2023  
  =========================================================================  
 Summary 
 WSCG 2023 : 31. International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision 2023  will take place in Prague/Pilsen  . It’s a 5  days event starting on May 15, 2023 (Monday)  and will be winded up on May 19, 2023 (Friday)  .  
 WSCG 2023  falls under the following areas: COMPUTER GRAPHICS, VISUALIZATION, COMPUTER VISION, ALGORITHMS,  etc. Submissions for this Conference  can be made by Jan 30, 2023  . Authors can expect the result of submission by Mar 30, 2023  . Upon acceptance, authors should submit the final version of the manuscript on or before Apr 15, 2023  to the official website of the Conference  .  
 Please check the official event website for possible changes before you make any travelling arrangements. Generally, events are strict with their deadlines. It is advisable to check the official website for all the deadlines.  
 Other Details of the WSCG 2023   
 Short Name: | WSCG 2023 
  Full Name: | 31. International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision 2023 
  Fees: | Check the official website of | WSCG 2023 
  Event Type: | Conference 
 Credits and Sources 
 [1] WSCG 2023 : 31. International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision 2023 
  Check other Conferences, Workshops, Seminars, and Events  Search Here    
 ADIP--EI 2024:   2024 6th Asia Digital Image Processing Conference (ADIP 2024)  
  Tokyo, Japan   
  Dec 14, 2024 
 XR for the Metaverse 2024:   IEEE MetroXRAINE 2024 - Special Session on Extended Reality as a gateway to the Metaverse  
  St Albans, London, UK   
  Oct 21, 2024 
 ICVIP--EI 2024:   2024 The 8th International Conference on Video and Image Processing (ICVIP 2024)  
  Kuala Lumpur, Malaysia   
  Dec 13, 2024 
 ISVC 2024:   19th International Symposium on Visual Computing  
  Lake Tahoe, Nevada, USA   
  Oct 21, 2024 
 ICBSP 2024:   ACM--2024 9th International Conference on Biomedical Imaging, Signal Processing (ICBSP 2024)  
  Hong Kong   
  Oct 18, 2024 
 SHOW ALL 
 ISVC 2024:   19th International Symposium on Visual Computing  
  Lake Tahoe, Nevada, USA   
  Oct 21, 2024 
  University of Salford, Manchester   
 MODA 2024:   5th ISC HPC International Workshop on Monitoring and Operational Data Analytics  
  Hamburg, Germany   
  May 16, 2024 
 DMBDA 2023:   6th International Conference on Data Mining and Big Data Analytics  
  Shanghai, China   
  Jul 28, 2023 
 InCM 2024:   The 6th International Workshop on Intelligent Computing and Measurements  
  Kitakyushu, Japan   
  Apr 17, 2024 
 SHOW ALL 
 ADIP 2024:   2024 6th Asia Digital Image Processing Conference (ADIP 2024)  
  Tokyo, Japan   
  Dec 14, 2024 
 NLPAI--EI 2024:   2024 5th International Conference on Natural Language Processing and Artificial Intelligence (NLPAI 2024)  
  Chongqing, China   
  Jul 12, 2024 
 NovelIQA 2024:   Novel Approaches to Image Quality Assessment  
  MDPI Journal of Imaging   
  Mar 1, 2024 
 WiCV @ CVPR 2024:   12th Women in Computer Vision workshop at CVPR 2024  
  Seattle, USA   
  Jun 18, 2024 
 ICVIP--EI 2024:   2024 The 8th International Conference on Video and Image Processing (ICVIP 2024)  
  Kuala Lumpur, Malaysia   
  Dec 13, 2024 
 SHOW ALL 
 CIS 2024:   5th Congress on Intelligent Systems  
  Bengaluru, India   
  Sep 4, 2024 
 EAAMO 2024:   ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization  
  San Luis Potosi, Mexico   
  Oct 29, 2024 
 DeSeRe 2024:   The 1st Workshop on Decentralised Search and Recommendation  
  Singapore   
  May 13, 2024 
 CIAA 2024:   The 28th International Conference on Implementation and Application of Automata  
  Akita, Japan   
  Sep 3, 2024 
 CCCG 2024:   Canadian Conference on Computational Geometry  
  St. Catharines, Ontario, Canada   
  Jul 17, 2024 
 SHOW ALL
3. WSCG_3 conference:
(Subscribe) | (I forgot my password) 
 WSCG 2023 - 31. Int.Conf. on Computer Graphics, Visualization and Computer Vision 2023   
  Conference   
  online and in-person   
  15th to 19th May 2023   
  Organized by:  University of West Bohemia   
  Deadline for abstracts/proposals:  30th January 2023   
  Check the event website  for more details.
4. WSC_0 conference:
Register 
  Paper Submission | Call for Papers 
  Author/Submission 
  Organizing Committee 
  Program | Schedule 
  Data Farming Workshop 
  Simulation Challenge 2023 
  Modeling and Analysis of Semiconductor Manufacturing 
  Vendor Workshops 
  Past Conferences 
  Future Conferences 
  WSC Foundation 
  Computer Simulation Archive 
  Venue & Travel 
 View the Online Program     
 Access the WSC 2023 Virtual Platform & Full Papers     
 2023 Winter Simulation Conference  
 Simulation for Resilient Systems  
 December 10-13, 2023  
   San Antonio Marriott Rivercenter  
  San Antonio, TX   
 WSC 2023 will focus on the use of simulation to improve resiliency for a wide range of systems.   
 The Winter Simulation Conference 2023 highlights the vital role that simulation plays in designing, planning, and operating resilient systems under uncertainty. In an increasingly inter-connected world, it is more critical than ever to ensure that systems quickly recover from and adapt to major disruptions. With its uncertainty modeling and explainable analytics capabilities, simulation is one of the key technologies that lie at the heart of building resilient systems. We invite papers that emphasize the latest advances in simulation theory and applications showcasing the integrated use of simulation with technologies ranging from the Internet of Things and statistics to AI/ML and optimization. We particularly encourage applications of simulation to improve resiliency in a wide range of domains, including but not limited to aviation, disaster response, education, energy, finance, healthcare, infrastructure, manufacturing, national security, space systems, and supply chains.  
 The Winter Simulation Conference 2023 will continue the tradition of including pre-conference workshops, introductory and advanced tutorials, commercial case studies, poster sessions, and the Ph.D. Colloquium. It will also host the 19 th  International Conference on Modeling & Analysis of Semiconductor Manufacturing (MASM). WSC 2023 will showcase professional development opportunities and a Simulation Challenge for teams to compete on an industrial case study.  
 The Winter Simulation Conference 2023 will be held in San Antonio, Texas from December 10 to 13 in 2023. The San Antonio Marriott Rivercenter is located on the beautiful waterfront within walking distance of historical sites. Join us in San Antonio for the leading conference in the field of simulation!  
 2023 Keynote Speaker  
 Ann Dunkin   
  Chief Information Officer  
 Program  
 WSC 2023 will feature a comprehensive program ranging from introductory tutorials to state-of-the-art research and practice. The planned tracks are as follows:  
 Education and Outreach  
 Back to Top   
 © Winter Simulation Conference 2023  2024   
 Powered by WordPress  • Themify WordPress Themes
5. WSC_2 conference:
WSC Archive   
 Winter Simulation Conference  
  Archive 
 WSC Programs with Full Papers     
 WSC 2023    
   WSC 2022    
 To Download Adobe Acrobat Reader | Return to the Informs Simulation Society Web Site  . | Winter Simulation Conference  
  Archive | WSC 2023    
   WSC 2022    
 Winter Simulation Conference  
  Archive 
 WSC 2023    
   WSC 2022
6. WSC_3 conference:
WSC 2023 Proceedings    
  Overview   | By Program Track  | Author Index    
 Advanced Tutorials | Logistics Supply Chains Transportation | Simulation and Artificial Intelligence 
 pdf   
   WSC 2023 Titan of Simulation - John Fowler  from INFORMS  on Vimeo  .  
 Plenary  ·  Plenary   
 pdf   
   WSC 2023 Titan of Simulation - Enver Yucesan  from INFORMS  on Vimeo  .  
 Return to Top    
  Jose Blanchet (Stanford University) and Alexander Shapiro (Georgia Institute of Technology)   
  Abstract    Abstract   The goal of this paper is to develop a methodology for the systematic analysis of asymptotic statistical properties of data-driven DRO formulations based on their corresponding non-DRO counterparts. We illustrate our approach in various settings, including both phi-divergence and Wasserstein uncertainty sets. Different types of asymptotic behaviors are obtained depending on the rate at which the uncertainty radius decreases to zero as a function of the sample size and the geometry of the uncertainty sets.  
 pdf   
  Importance Sampling Strategy for Heavy-Tailed Systems with Catastrophe Principle    
 Xingyu Wang and Chang-Han Rhee (Northwestern University)   
  Abstract    Abstract   Large deviations theory has a long history of providing powerful machinery for designing efficient rare-event simulation techniques. However, traditional large deviations theory fails to provide useful bounds in heavy-tailed contexts, and designing efficient rare-event simulation algorithms for heavy-tailed systems has been considered challenging. Recent developments in the theory of heavy-tailed large deviations enable designing a strongly efficient importance sampling scheme that is universally applicable to a wide range of rare events. This tutorial aims to provide an accessible overview of the recent developments in the large deviations theory for heavy-tailed stochastic processes, which is followed by a detailed account of the design principle behind the strongly efficient importance sampling scheme for such processes. The implementations of the general principle are demonstrated through a few specific heavy-tailed rare events that arise in stochastic approximation, finance, and queueing theory contexts.  
 pdf   
  Squashing Bugs and Improving Design: Using Data Farming to Support Verification and Validation of Military Agent-Based Simulations    
 Susan K. Aros and Mary L. McDonald (Naval Postgraduate School)   
  Abstract    Abstract   Verification and validation of complex agent-based human behavior simulation models is a challenging endeavor, particularly since a dearth of real-world data makes it impossible to use most traditional validation methods. Data farming techniques have stepped up to the challenge, proving to be a valuable tool for verification and validation of complex models. In this paper we demonstrate how data farming and analysis aids in the verification and validation of complex models by presenting specific examples pertaining to WRENCH, an agent-based simulation model that represents complex interactions between security forces and civilians during civil security stability operations. We first provide an overview of data farming and its relevance for verification and validation of military agent-based simulation models, then give an overview of WRENCH, and finally demonstrate with examples how we have used data farming to aid in the verification and validation of WRENCH.  
 pdf   
  Supporting Emergency Department Risk Mitigation with a Modular and Reusable Agent-Based Simulation Infrastructure    
 Thomas Godfrey (King's College London); Rahul Batra, Sam Douthwaite, and Jonathan Edgeworth (Guy's and St Thomas' NHS Foundation Trust); Matthew Edwards (King's College Hospital NHS Foundation Trust); Simon Miles (Aerogility Ltd); and Steffen Zschaler (King's College London)   
  Abstract    Abstract   For emergency departments (EDs) to maintain sustainable care of patients, hospital management must continually explore potential interventions to clinical practice. Agent-based modelling (ABM) can be a valuable tool to support this planning in a controlled environment. Existing approaches to ABM development are best suited for one-off models. However, conditions in EDs can change frequently, making the use of one-off models infeasible. Decision-makers must be able to trust simulations appropriately for them to be effective in intervention exploration. Domain-specific modelling languages (DSMLs) can address these challenges by offering a reusable library of appropriately-abstract domain-familiar, modelling concepts across case studies and automatic translation of these concepts into executable models. In this paper we present a DSML to support repeated modelling exercises in the ED domain and illustrate the use and reuse of this DSML across two concrete case studies in London-based NHS emergency departments.  
 pdf   
  Simulating Interaction Behaviors in Bi-directional Shared Corridor with Real Case Study    
 Yun-Pang Flötteröd, Jakob Erdmann, and Daniel Krajzewicz (German Aerospace Center (DLR)) and Johan Olstam (The Swedish National Road and Transport Research Institute)   
  Abstract    Abstract   Microscopic traffic simulation tools are able to evaluate possible impacts induced by automated shuttles under various conditions. However automated shuttles operate more and more often in shared space areas and few microscopic traffic simulation tools are able to handle networks with shared space infrastructure. Interaction behaviors between road users and automated shuttles are addressed only seldom as well. In this paper, we propose the concept of bi-directional edges in the open source microscopic traffic simulation suite SUMO to simulate road users’ interactions in a bi-directional shared-space corridor. A case study, where automated shuttles and cyclists share the bike path, and the related data collection were conducted to examine the performance of the proposed concept and understand the usage of the shared corridor. The simulation results are promising. Further refinement of the proposed concept is planned for properly reflecting complex interaction behaviors among diverse road users, and their surrounding environment.  
 pdf   
  Rebalancing Integrated, Demand-responsive Passenger and Freight Transport – An Agent-based Simulation Approach    
 Johannes Staritz, Julia Kütemeier, Helen Sand Christoph von Viebahn, and Maylin Wartenberg (Hochschule Hannover)   
  Abstract    Abstract   Integrated, demand-responsive passenger and freight transport (IDRT) potentially provides flexibility and higher service frequency in areas of low demand due to economies of scale while reducing negative traffic-related externalities such as pollutant emissions, noise emissions or accidents. However, to allow for efficient operations in terms of minimum travel distances, short customer waiting times, and high vehicle utilization rates, IDRT requires effective rebalancing strategies that balance supply and demand capacities by strategically positioning vehicle resources in the operational area. Therefore, we propose a rebalancing strategy for IDRT and measure its effectiveness through an agent-based simulation model. To evaluate our approach, we compare the rebalanced IDRT with a static scenario with backhauls to a central depot. Our results indicate that the proposed rebalancing approach can outperform a system without rebalancing by up to 15.1% in terms of total fleet kilometers and 30% in terms of passenger waiting time.  
 pdf   
  A Simulation Model for Bio-Inspired Charging Strategies for Electric Vehicles in Industrial Areas    
 Berry Gerrits and Martijn Mes (University of Twente) and Robert Andringa (Distribute)   
  Abstract    Abstract   This paper presents an open-source agent-based simulation model to study bio-inspired charging policies for local sustainable energy systems in an industrial setting where electric vehicles (EVs) perform transportation jobs. Within this context, we focus on a system that allows to control the charging-schemes of individual EVs. To this end, we develop an agent-based simulation model in NetLogo. We present and implement a bio-inspired approach based on the foraging behavior of honeybees and our approach results in simple, yet effective decision-making logic. Our approach provides the necessary parameters to control and balance sustainable energy systems in terms of EV productivity and the consumption of locally generated energy. Our simulation results look promising: the balance between EV productivity and the use of sustainable energy can be efficiently tweaked in a predictable manner using the parameters and thresholds of the model, yielding close-to-optimal performance.  
 pdf   
  Modeling Reactive Game Agents Using the Cell-DEVS Modeling Formalism    
 Alvi Jawad, Cristina Ruiz-Martín, and Gabriel Wainer (Carleton University)   
  Abstract    Abstract   Intelligent game agents are a vital part of modern games as they add life, story, and immersion to the game environment. The requests in the gaming industry for more realism have made intelligent agents more important than ever before. Modeling and simulation of game agents and their surrounding environment provide an alternate setting to study dynamic agent behavior before integration into the game engine. The Cell-DEVS formalism, an extension of Cellular Automata, allows modeling such behaviors using the rigorously formalized Discrete Event Systems Specification (DEVS) formalism. In this paper, we explain how to model and test reactive game agents using the Cell-DEVS formalism and the CD++ toolkit. To analyze the dynamic behavior of such agents, we perform several experiments in varying system configurations. Our experimental results confirm the versatility of Cell-DEVS and the functionalities in the CD++ toolkit to model comfort-driven, exploratory, and desire-driven game agents.  
 pdf   
  Feature Importance for Uncertainty Quantification in Agent-based Modeling    
 Gayane Grigoryan and Andrew J. Collins (Old Dominion University)   
  Abstract    Abstract   Simulation models are subject to uncertainty and sensitivity, meaning that even small variations of input can cause considerable fluctuations in the output results. Consequently, this can amplify the uncertainty associated with the simulation, thereby limiting the confidence one can have in its outcomes. To mitigate these effects, this paper suggests using a cooperative game theory-based feature importance method which can identify uncertainty in a dataset, and provide additional insights that could be used in the development or analysis of a simulation model. A predator-prey scenario was considered demonstrating its usefulness in identifying important parameters or features. By identifying the most influential parameters or features this approach can help improve the accuracy explainability, and reliability of simulation models as well as other models with highly variable input parameters.  
 pdf   
  A Simulation-Based Method for Analyzing Supply Chain Vulnerability Under Pandemic: A Special Focus on the Covid-19    
 Xinglu Xu and Bochi Liu (Dalian University of Technology) and Weihong Grace Guo (Rutgers, The State University of New Jersey)   
  Abstract    Abstract   This paper develops a simulation-based quantitative method to investigate the joint impact of multiple risks on the supply chain system during the pandemic. A hybrid simulation method that combines the susceptible-infected-recovered (SIR) model and the agent-based simulation method is proposed to simulate the risk propagation along the supply chain and the interactions between distribution centers and retailers. By analyzing the results of scenarios with different interventions under COVID-19, results show that the impact of interventions is diminishing along the supply chain. For intervention deployment, adding testing capacity is of great importance. For stakeholder management strategies, diversifying the upstream partners is helpful. Against the backdrop of a multi-wave global pandemic, this paper takes the COVID-19 pandemic as an example to provide a paradigm for modeling the risk propagation in supply chain systems. Also, the study demonstrates how to estimate possible time-varying risk scenarios in face of the data shortage challenge.  
 pdf   
  Matchmaking in Crowd-shipping Platforms: The Effects of Mediator Control    
 Preetam Kulkarni and Caroline C. Krejci (University of Texas at Arlington)   
  Abstract    Abstract   A critical design decision for crowdsourcing platforms is the degree to which the platform mediator controls participant interactions. Platforms having a centralized model of mediation optimize for convenience, speed, and security in participant interactions, while platforms operating under decentralized control require greater user effort but offer them greater control and agency. The research described in this paper is a preliminary study using agent-based modeling to evaluate and compare the performance of crowd-shipping platforms with centralized/decentralized control over matchmaking of carriers and senders. Results indicate that centralized matchmaking protects the platform from premature failure when initial carrier/sender participation is low. Furthermore, when the platform’s assignment algorithm is designed to maximize platform revenue, subject to meeting carriers’ profit expectations, centralized matchmaking will tend to outperform decentralized matchmaking for both the mediator and the carriers.  
 pdf   
  Real-Time Estimations for the Waiting-Time Distribution in Time-Varying Queues    
 Kurtis Konrad and Yunan Liu (North Carolina State University)   
  Abstract    Abstract   Customers’ waiting times are the most commonly used performance data to measure the quality of service in service systems such as call centers and healthcare. Unlike stationary queueing models where customers’ waiting times are statistically similar, the prediction of waiting times is far less straightforward in time-varying queues having nonstationary demand (i.e., arrival rate) and supply (i.e., number of servers). In this paper, we develop a novel methodology for more accurately computing the wait time distribution in a time-varying queueing system. We design extensive simulation experiments to evaluate our prediction methods. In addition, we discover that the waiting-time prediction is highly sensitive to the work-releasing policy of the staffing plan i.e., the rule under which the number of servers changes in time.  
 pdf   
  Achieving Stable Service-Level Targets in Time-Varying Queueing Systems: A Simulation-Based Offline Learning Staffing Algorithm    
 Kurtis Konrad and Yunan Liu (North Carolina State University)   
  Abstract    Abstract   In this paper, we develop a new staffing algorithm for achieving stable service-level targets in queues with time-varying arrivals. Specifically, we aim to stabilize the tail probability of delay, which is the probability that the waiting time exceeds a designated target τ > 0. We integrate reinforcement learning into the decision making in queueing models; our new method recursively evolve the staffing decision by alternating between two phases: (i) we generate simulated queueing data by operating the system under the present staffing function (exploration), and (ii) we utilize the newly generated data to devise improved staffing decision (exploitation). We demonstrate the effectiveness of our new method using various numerical examples.  
 pdf   
  Estimating Spline-based Nonhomogeneous Poisson Intensities Using Constrained Quadratic Programming    
 Siqi Chen, Jing Yang (Sunny) Xi, and Wai Kin (Victor) Chan (Tsinghua-Berkeley Shenzhen Institute, Shenzhen International Graduate School, Tsinghua University)   
  Abstract    Abstract   This paper estimates the intensity function of a nonhomogeneous Poisson process (NHPP) using a spline-based method with constrained quadratic programming (CQP). Based on the property of B-splines, we transform the estimation problem into an optimization problem and apply CQP to obtain the estimated intensity function with low computational expense. Numerical experiments are conducted to verify the performance of our method. In addition, the impacts of the number of intervals from event-count data and the number of knots in B-splines are also discussed to explore the properties of spline-based models.  
 pdf   
 Technical Session  ·  Analysis Methodology   
  Advances in Rare-event Simulation   
 Chair: Linyun He (Georgia Institute of Technology)  
  Efficiency of Estimating Functions of Means in Rare-Event Contexts    
 Marvin Nakayama (New Jersey Institute of Technology) and Bruno Tuffin (INRIA, University of Rennes)   
  Abstract    Abstract   When estimating a function of means, where some but not necessarily all of them correspond to rare events, we provide conditions under which having efficient estimators of each individual mean leads to an efficient estimator of the function of the means. We illustrate this setting through several examples, and numerical results complement the theory.  
  Conditional Importance Sampling for Convex Rare-Event Sets    
 Dohyun Ahn and Lewen Zheng (The Chinese University of Hong Kong)   
  Abstract    Abstract   This paper studies the efficient estimation of expectations defined on convex rare-event sets using importance sampling. Classical importance sampling methods often neglect the geometry of the target set, resulting in a significant number of samples falling outside the target set. This can lead to an increase in the relative error of the estimator as the target event becomes rarer. To address this issue, we develop a conditional importance sampling scheme that achieves bounded relative error by changing the sampling distribution to ensure that a majority of samples lie inside the target set. The proposed method is easy to implement and significantly outperforms the existing approaches in various numerical experiments.  
 pdf   
  Curse of Dimensionality in Rare-Event Simulation    
 Best Contributed Theoretical Paper - Finalist    
 Yuanlu Bai, Antonius B. Dieker, and Henry Lam (Columbia University)   
  Abstract    Abstract   In rare-event simulation, importance sampling (IS) is widely used to improve the efficiency of probability estimation. Asymptotic optimality is a common efficiency criterion, which requires that the relative error of the estimator only grows subexponentially in the rarity parameter. Most studies, however, consider low-dimensional problems and the effect of dimensionality is seldom analyzed. Motivated by recent AI-related applications, we take a first step towards high-dimensional rare-event simulation and demonstrate that for very simple examples, IS proposals that utilize exponential tilting arguably the most common IS approach, can suffer from the "curse of dimensionality". That is while the growth rate of the relative error is polynomial in the rarity parameter thus leading to asymptotic optimality, the degree of the polynomial depends on the problem dimensionality. Therefore, when the dimension is high, the relative error can be huge even in the rarity parameter regime where IS is conventionally believed to work well.  
 pdf   
  Efficient Input Uncertainty Quantification for Regenerative Simulation    
 Best Contributed Theoretical Paper - Finalist    
 Linyun He (Georgia Institute of Technology), Mingbin Ben Feng (University of Waterloo), and Eunhye Song (Georgia Institute of Technology)   
  Bootstrap Confidence Intervals for Simulation Output Parameters    
 Russell R. Barton (The Pennsylvania State University) and Luke A. Rhodes-Leader (Lancaster University)   
  Abstract    Abstract   Bootstrapping has been used to characterize the impact on discrete-event simulation output arising from input model uncertainty for thirty years. The distribution of simulation output statistics can be very non-normal, especially in simulation of heavily loaded queueing systems and systems operating at a near optimal value of the output measure. This paper presents issues facing simulationists in using bootstrapping to provide confidence intervals for parameters related to the distribution of simulation output statistics, and identifies appropriate alternatives to the basic and percentile bootstrap methods. Both input uncertainty and ordinary output analysis settings are included.  
 pdf   
  Fast Approximation to Discrete-Event Simulation of Markovian Queueing Networks    
 Tan Wang (Fudan University), Yingda Song (Shanghai Jiaotong University), and Jeff Hong (Fudan University)   
  Abstract    Abstract   Simulation of queueing networks is generally carried out by discrete-event simulation (DES), in which the simulation time is driven by the occurrence of the next event. However, for large-scale queueing networks, especially when the network is very busy, keeping track of all events is computationally inefficient. Moreover as the traditional DES is inherently sequential it is difficult to harness the capability of parallel computing. In this paper, we propose a parallel fast simulation approximation framework for large-scale Markovian queueing networks where the simulation horizon is discretized into small time intervals and the system state is updated according to the events happening in each time interval. The computational complexity analysis demonstrates that our method is more efficient for large-scale networks compared with traditional DES. We also show its relative error converges to zero. The experimental results show that our framework can be much faster than the state-of-the-art DES tools.  
 pdf   
  Tracking and Detecting Systematic Errors in Digital Twins    
 Luke A. Rhodes-Leader (Lancaster University) and Barry L. Nelson (Northwestern University)   
  Abstract    Abstract   Digital Twins (DTs) have immense promise for exploiting the power of computer simulation to control large-scale real-world systems. The key idea is to evaluate or optimize decisions using the DT, and then implement them in the real-world system. Even with best practices, the DT and the real-world system may become misaligned over time. In this paper we provide a statistical method to detect such misalignment even though both the simulation and the real-world system are inherently stochastic. An empirical evaluation and a realistic illustration are provided.  
 pdf   
  The Variability in Design Quality Measures for Multiple Types of Space-filling Designs Created by Leading Software Packages    
 Thomas W. Lucas (Naval Postgraduate School) and Jeffrey D. Parker (United States Marine Corps)   
  Abstract    Abstract   Space-filling designs (SFDs) underpin many large-scale simulation studies. The algorithms that construct SFDs are mostly stochastic and cannot guarantee that optimal solutions can be found within a practical amount of time. This paper uses massive experimentation to find the empirical distributions of a diverse set of design-quality measures in highly-used classes of SFDs constructed by leading software packages. The objective is to provide simulation practitioners with a better understanding of what they can expect from different SFD choices. The results show substantial variability in measures of correlation and space-fillingness in the design classes and dimensions investigated. Therefore, computer experimenters should generate and assess several candidate designs using different random-number-generator seeds to reduce the risk of using a poor design simply due to random chance. We also find that in the largest designs investigated, the uniform designs generally perform best for both our correlation and uniformity measures.  
 pdf   
  Efficient Bandwidth Selection for Kernel Density Estimation    
 Haidong Li (University of Chinese Academy of Sciences), Long Wang and Yijie Peng (Peking University), and Di Wang (Shanghai Jiao Tong University)   
  Abstract    Abstract   We consider bandwidth selection for kernel density estimation. The performance of kernel density estimator heavily relies on the quality of the bandwidth. In this paper, we propose an efficient plug-in kernel density estimator which first perturbs the bandwidth to estimate the optimal bandwidth, followed by applying a kernel density estimator with the estimated optimal bandwidth. The proposed method utilizes the zeroth-order information of kernel function and has a faster convergence rate than other plug-in methods in existing literature. Simulation results demonstrate superior finite sample performance and robustness of the proposed method.  
 pdf   
  CGPT: A Conditional Gaussian Process Tree for Grey-Box Bayesian Optimization    
 Mengrui (Mina) Jiang, Tanmay Khandait, and Giulia Pedrielli (Arizona State University)   
  Abstract    Abstract   In black-box optimization problems, Bayesian optimization algorithms are often applied by generating inputs and measure values to discover hidden structure and determine where to sample sequentially. However, information about system properties can be available. In different learning tasks, we may know that the objective is the minimum of functions, or a network. In this paper we consider the case where the structure of the objective function can be encoded as a tree. We propose the new Conditional Gaussian Process tree (CGPT) model for "tree functions'' to embed the function structure and improving the prediction power of the Gaussian process. We utilize the intermediate information at the tree nodes, to formulate a novel likelihood for the estimation of the CGPT parameters. We formulate the learning and investigate the performance of the proposed approach. Our study shows that CGPT always outperforms a single Gaussian process model.  
 pdf   
  Mean-Variance Portfolio Optimization with Nonlinear Derivative Securities    
 Shiyu Wang and Guowei Cai (Lingnan College, Sun Yat-sen University); Peiwen Yu (Soochow University); Guangwu Liu (City University of Hong Kong); and Jun Luo (Shanghai Jiao Tong University)   
  Abstract    Abstract   In this paper, we propose a simulation approach to mean-variance optimization for portfolios comprised of derivative securities. The key of the proposed method is on the development of an unbiased and consistent estimator of the covariance matrix of asset returns which do not admit closed-form formulas but require Monte Carlo estimation, leading to a sample-based optimization problem that is easy to solve. We characterize the asymptotic properties of the proposed covariance estimator, and the solution to and the objective value of the sample-based optimization problem. Performance of the proposed approach is demonstrated via numerical experiments.  
 pdf   
  Tactical Minimization of the Environmental Impact of Holding in the Terminal Airspace and an Associated Economic Model    
 Aditya Paranjape and Anwesha Basu (Tata Consultancy Services Ltd)   
  Abstract    Abstract   Minimization of the carbon footprint of aviation is an active area of interest to the industry and policy makers alike. Optimization of the individual flight phases is an important step in that direction. This paper considers the holding phase, wherein aircraft hold in the terminal airspace of airports prior to approach and landing during times of busy operation or when the arrival capacity is reduced due to factors such as bad weather. We propose a tactical method to allocate landing slots while minimizing the environmental impact of holds. An environmentally-driven policy can be perceived as unfair, particularly by airlines whose environmentally friendly aircraft which might need to hold longer than they would under a fair first-come-first-served policy. To alleviate this challenge, we propose a number of economic reward schemes, including one based on a linear programming problem obtained by applying complementary slackness to the dual of the assignment problem.  
 pdf   
  Use of Variable Sized Entities to Model Airport Passenger Flow with Pedestrian Dynamics    
 Erich Deines and Tanuj Babele (TransSolutions LLC) and Gary Gardner (InControl)   
  Abstract    Abstract   This paper describes the use of variable-sized entities within the framework of the InControl simulation software product Pedestrian Dynamics to rapidly model passenger flow and congestion for a series of check-in hall lobby designs for a US domestic airline terminal. Note that the airline and airport will remain anonymous for this presentation due to confidentiality.  
 pdf   
  Aircraft Line Maintenance Scheduling using Simulation and Reinforcement Learning    
 Simon Widmer, Syed Shaukat, and Cheng-Lung Wu (UNSW)   
  Abstract    Abstract   This paper presents a reinforcement learning (RL) algorithm prototype to solve the aircraft line maintenance scheduling problem. The Line Maintenance Scheduling Problem (LMSP) is concerned with scheduling a set of maintenance tasks during an aircraft's ground time. To address this problem, we introduce a novel LMSP method combining a hybrid simulation model and reinforcement learning to schedule maintenance tasks at multiple airports. Initially, this paper briefly reviews the existing literature on optimization-based and AI-enhanced aircraft maintenance scheduling. Secondly, the novel reinforcement learning LMSP method is introduced, evaluated using industry data, and compared with optimization-based LMSP solutions. Our experiments demonstrate that the LMSP method using reinforcement learning is capable of identifying near-optimal policies for scheduling line maintenance jobs when compared to the exact and heuristics-based methods. The proposed model provides an excellent foundation for future studies on AI-enhanced scheduling problems.  
 pdf   
  A Mathematical Theory to Quantify Cyber-Resilience in IT/OT Networks    
 Ranjan Pal (Massachusetts Institute of Technology), Rohan Sequeira (University of Southern California), and Michael Siegel (Massachusetts Institute of Technology)   
  Abstract    Abstract   Modern enterprise infrastructures (EIs) including those of industrial control systems (ICSs) are becoming increasingly crucial to businesses in a wide range of sectors spanning multiple end-user verticals (e.g., energy chemical, manufacturing, biotechnology). These EIs improve the (real-time) decision support productivity, and efficiency of business processes, but necessarily reliant upon the cyber-resilience of complex infrastructures for sustainable business continuity. We are interested in the long-standing open question in the cyber-resilience domain: how can managers formally quantify cyber-resilience for any complex networked EI (sub-)system in the event of a cyber-attack affecting its multiple (inter-dependent) components? We propose a simulation-backed framework derived from probabilistic graph theory to answer this question. We pioneer the derivation and analysis of a quantifiable, closed-form manager friendly expression exhibiting the degree of cyber-resilience (dependent upon individual EI component functionality quality and the varying extents of functional dependencies across networked components) within the (sub-)system post cyber-attack(s) affecting an EI.  
 pdf   
  A Mathematical Theory to Price Cyber-Cat Bonds Boosting IT/OT Security    
 Ranjan Pal (MIT Sloan School of Management) and Bodhibrata Nag (Indian Institute of Management Calcutta)   
  Abstract    Abstract   The density of enterprise cyber (re-)insurance markets to manage (aggregate) enterprise cyber-risk has been low enough to realize their potential to significantly improve cyber-security and consequently the cyber-reliability of (ICS) enterprise ecosystems. In this paper, we propose the use of catastrophic (CAT) bonds as a radical and alternative residual cyber-risk management methodology to alleviate the big supply demand gap in the current cyber (re-)insurance industry, by boosting capital injection in the latter industry. Two important follow up questions arise: (i) when is it feasible for cyber (re-)insurers to invest in CAT bonds? and (ii) how can we price cyber-CAT bonds conditioned on the feasibility condition(s)? We focus on answering the second question pivoted upon an existential answer to the first. We propose a novel practically motivated information asymmetry (IA) driven cyber-CAT bond pricing model, built upon theories of financial stochastic processes and Monte Carlo simulations, in realistic arbitraged incomplete markets.  
 pdf   
  Resilience and Complexity in Socio-Cyber-Physical Systems    
 Claudia Szabo (University of Adelaide), Rodrigo Castro (CIFASIS-CONICET), Joachim Denil (University of Antwerp), and Susan M. Sanchez (Naval Postgraduate School)   
  Abstract    Abstract   Socio-Cyber-Physical Systems are ubiquitous in today’s world. They are inherently complex systems built out of many large-scale systems that encompass different perspectives and numerous stakeholders. This leads to several challenges in managing their complexity and emergent behavior. In addition, these systems tend to include many adaptive and autonomous systems with different goals and different adaptations to environment changes or failures. The design, analysis, and testing of such systems is inherently challenging but is becoming critical due to their wide adoption. In this panel, we aim to discuss some of these challenges and potential solutions.  
 pdf   
  Symbiotic Use of Digital Twin, Simulation and Design Thinking Approach for Resilient Enterprise    
 Souvik Barat, Sylvan Lobo, Reshma Korabu, Himabindu Thogaru, and Ravi Mahamuni (Tata Consultancy Services Research)   
  Abstract    Abstract   Enterprises are increasingly facing the need to be resilient in the face of uncertainty and dynamism. Simulatable digital twins have become critical aids for analyzing and adapting complex systems. Design thinking and service design methodologies, in contrast, are gaining momentum for ideation, subjective evaluation, and innovation. A systematic application of these methodologies to explore innovative ideas and a faithful virtual environment to test and fine-tune those ideas without impacting real systems could be transformational. This paper presents an approach that establishes a symbiotic relationship between these two approaches to introduce precision and innovativeness to make enterprises resilient. We describe the key characteristics of resilient enterprises, present our approach, and illustrate its effectiveness with a case study focusing on a transformation toward a new normal to address the Covid-19 pandemic induced disruptions in the IT industry.  
 pdf   
  Markov Process Simulations of Service Systems with Concurrent Hawkes Service Interactions    
 Andrew Daw (University of Southern California) and Galit B. Yom-Tov (Technion - Israel Institute of Technology)   
  Abstract    Abstract   In multi-tasked services such as in messaging-based contact centers, parallel service interactions share a mutual dependence through the agent's concurrency. Here, we introduce Markov process simulation methods for bivariate Hawkes cluster service models that are not Markovian by default due to their concurrency dependence. To do so, we propose an alternate construction that maintains extra "shadow" variables for how the process would be under other concurrency levels. We prove that this construction yields an equivalent Markov process, and we show through numerical experiments that its corresponding simulation algorithm is significantly more efficient than the non-Markovian alternatives.  
 pdf   
  Cascading Transformer Failure Probability Model Under Geomagnetic Disturbances    
 Pratishtha Shukla, James Nutaro, and Srikanth Yoginath (Oak Ridge National Laboratory)   
  Abstract    Abstract   This paper develops a probabilistic model to assess the cascading failure of transformers in an electric power grid experiencing geomagnetic disturbances caused by a solar storm. We propose a model in which the probability of failure is a function of the intensity of the solar storm the physical properties of the transformer, the geographical location of the transformer, and the flow of electrical power. We demonstrate the proposed model using the IEEE 14-bus system and several notional solar storms. The model quickly computes the initial and cascading failure probabilities of the transformers in the system as a first step towards quantifying the risks posed by future solar storms.  
 pdf   
  Causal Dynamic Bayesian Networks for Simulation Metamodeling    
 Best Contributed Theoretical Paper - Finalist    
 Pracheta Boddavaram Amaranath (University of Massachusetts Amherst), Sam Witty (Basis Research Institute), and Peter J. Haas and David Jensen (University of Massachusetts Amherst)   
  Abstract    Abstract   A traditional metamodel for a discrete-event simulation approximates a real-valued performance measure as a function of the input-parameter values. We introduce a novel class of metamodels based on modular dynamic Bayesian networks (MDBNs), a subclass of probabilistic graphical models which can be used to efficiently answer a rich class of probabilistic and causal queries (PCQs). Such queries represent the joint probability distribution of the system state at multiple time points, given observations of, and interventions on, other state variables and input parameters. This paper is a first demonstration of how the extensive theory and technology of causal graphical models can be used to enhance simulation metamodeling. We demonstrate this potential by showing how a single MDBN for an M/M/1 queue can be learned from simulation data and then be used to quickly and accurately answer a variety of PCQs, most of which are out-of-scope for existing metamodels.  
 pdf   
  Deep-learning-assisted Cardiac Electrophysiology Simulation    
 Weixuan Dong, Yifu Li, and Rui Zhu (The University of Oklahoma)   
  Abstract    Abstract   Simulation built upon partial and ordinary differential equations has been a classic approach to modeling cardiac electrophysiological dynamics. However mitigating the computational burden of differential equations is still a challenging problem. This paper provides a novel alternative utilizing data-driven recurrent neural networks for cardiac electrophysiological dynamic simulation. Specifically, we develop a long short-term memory (LSTM)-assisted simulation to capture the underlying dynamics of cardiac electrophysiology while preserving computational efficiency. Experimental results demonstrate the efficiency and effectiveness of the proposed method, which outperforms the differential equation-based simulation approach while significantly reducing the computational cost. The proposed method offers a promising alternative to traditional simulation and may contribute to the development of more efficient and accurate approaches for simulating cardiac electrophysiology.  
 pdf   
  Inferring Epidemic Dynamics Using Gaussian Process Emulation of Agent-Based Simulations    
 Abdulrahman Ahmed, M. Amin Rahimian, and Mark Roberts (University of Pittsburgh)   
  Abstract    Abstract   Computational models help decision makers understand epidemic dynamics to optimize public health interventions. Agent-based simulation of disease spread in synthetic populations allows us to compare and contrast different effects across identical populations or to investigate the effect of interventions keeping every other factor constant between "digital twins." FRED (A Framework for Reconstructing Epidemiological Dynamics) is an agent-based modeling system with a geo-spatial perspective using a synthetic population that is constructed based on the U.S. Census data. In this paper, we show how Gaussian process regression can be used on FRED-synthesized data to infer the differing spatial dispersion of the epidemic dynamics for two disease conditions that start from the same initial conditions and spread among identical populations. Our results showcase the utility of agent-based simulation frameworks such as FRED for inferring differences between conditions where controlling for all confounding factors for such comparisons is next to impossible without synthetic data.  
 pdf   
  Uncovering Competitor Pricing Patterns in the Danish Pharmaceutical Market via Subsequence Time Series Clustering: A Case Study    
 Ruhollah Jamali (University of Southern Denmark) and Sanja Lazarova-Molnar (Karlsruhe Institute of Technology)   
  Abstract    Abstract   Adopting data-driven decision-making approaches can significantly enhance profitability and foster growth in economic situations through quantitative analysis of market dynamics. One intriguing market that warrants examination is the price competition observed within the Danish pharmaceutical sector, where numerous companies are vying for a larger market share through the offering of diverse pharmaceutical products. This paper aims to shed light on this market by employing subsequence time series clustering techniques to identify pricing patterns among the players involved in the Danish pharmaceutical industry. The data analysis pipeline performed in this study allows for the identification of price patterns for clustering and discovering different agent groups, as well as providing a foundation for expanding the current agent-based model of the European pharmaceutical parallel trade market by analyzing the pricing behavior and patterns of players, facilitating the utilization of historical data to model agent behavior and advancing research in this area.  
 pdf   
  Using Simulation to Assess the Reliability of Forecasts in High-tech Industry    
 Bhoomica Mysore Nataraja (Eindhoven University of Technology); Tanmay Aggarwal (Lambda Function Inc); and Nitish Singh, Koen Herps, and Ivo Adan (Eindhoven University of Technology)   
  Abstract    Abstract   In a high-tech production environment, capacity investment and production planning are often based on the demand information from manufacturers within a supply chain. A supplier solicits forecast information from a manufacturer, and the manufacturer provides demand forecasts that are updated on a rolling horizon basis. Problems arise with this setup if the manufacturer provides volatile forecast quantities due to the market's fluctuating demand or internal bias. As a result, suppliers' mistrust regarding forecast quantities grows leading to adjusted production plans based on planners' anecdotal experience. The paper presents a decision model to determine the reliability of forecasts provided by manufacturers to facilitate better production planning. The study also suggests alternate forecasting techniques in case of low reliability. To evaluate the effectiveness of the proposed approach, a simulation study is conducted for different manufacturers and scenarios. Our experiments showed an average cost reduction of 14% across all instances.  
 pdf   
  A Network Theory to Quantify and Bound Cyber-risk in IT/OT Systems    
 Best Contributed Applied Paper - Finalist    
 Ranjan Pal (MIT Sloan School of Management), Rohan Xavier Sequeira (University of Southern California), and Sander Zeijlemaker and Michael Siegel (MIT Sloan School of Management)   
  Abstract    Abstract   IT/OT driven industrial control systems (ICSs) such as water/power/transportation networks are increasingly meeting the daily functional needs of civilian society around the globe. This alongside making societal businesses more automated, efficient, productive, and profitable. However, often poorly configured IoT security settings increase the chances of occurrence of (nation-sponsored) stealthy spread-based APT malware attacks in ICSs that might go undetected over a considerable period of time. The ICS enterprise management is often keen to get apriori statistical estimates of cyber-loss impact post any cyber-attack event such that it can plan ahead on its cyber-resilience budget. In this paper, we propose the first mathematical theory, based upon stochastic processes and concentration inequalities, to (a) statistically quantify apriori the cyber-loss impact (distribution) on an ICS infrastructure network post an APT cyber-attack event, and subsequently (b) bound the tail of such a cyber-risk distribution, for arbitrary impact distributions.  
 pdf   
  Modeling of Circular Economy Strategies for CFRP-made Aircrafts    
 Arnd Schirrmann and Uwe Beier (Airbus)   
  Abstract    Abstract   In a circular economy, recycling of materials at the end of a product's life cycle is a key issue. This paper discusses the sustainability impacts of different recycling strategies for CFPR-made aircraft and how they weigh up against alternative measures such as waste reduction and lower material consumption in the manufacture of the product. The analysis includes environmental and cost impacts for different strategies and market scenarios. A quantitative system dynamic simulation of the life cycle of an aircraft program is used. The subject of the life cycle simulation model is the CFRP mass flow, CO2 emissions and associated costs. In addition, the effects of R&T investments in new technologies for recycling and waste prevention as well as the reduction of material consumption were investigated.  
 pdf   
  An Agent-Based Model of Agricultural Land Use in Support of Local Food Systems    
 Poojan Patel and Caroline Krejci (University of Texas at Arlington), Nicholas Schwab (University of Northern Iowa), and Michael Dorneich (Iowa State University)   
  Abstract    Abstract   Local food systems, in which consumers source food from nearby farmers, offer a sustainable alternative to the modern industrial food supply system. However, scaling up local food production to meet consumer demand will require farmers to allocate more land to this purpose. This paper describes an agent-based model that represents commodity-producing Iowa farmers and their decisions about converting some of their acreage to specialty crop production for local consumption. Farmer agents’ land-use decisions are informed by messages passed to them via their social connections with other farmers in their communities and messages from agricultural extension agents. Preliminary experimentation revealed that leveraging extension agents to increase the frequency and strength of messages to farmers in support of local food production has a modest positive impact on adoption. By itself, however, this intervention is unlikely to yield significant improvements to food system sustainability.  
 pdf   
  Sustainability Assessment Through Simulation: The Case Of Fashion Renting    
 Virginia Fani and Romeo Bandinelli (University of Florence)   
  Abstract    Abstract   The fashion industry is widely known as one of the most environmentally impacting. To address the overconsumption issue, the fashion renting business model allows renting clothes or accessories instead of buying them, extending the useful life of products. However, concerns about the sustainability of fashion renting supply chains are arisen, especially due to reverse logistics. In this context, a hybrid simulation model is developed to support fashion companies in the design and evaluation of renting supply chain configurations. Through Discrete Event Simulation (DES) logistics flows are represented, while Agent-Based Modeling (ABM) integrated with Geographic Information System (GIS) allow to represent supply chain’s nodes in the real environment. GIS concurs to estimate the sustainability of the supply chain importing effective data related to the covered distances. The proposed parametric model will enable performing scenario analyses to assess the best configuration in terms of environmental impact.  
 pdf   
  Simulative Analysis of the Sustainability Driven Transformation of Casting Plants    
 Johannes Dettelbacher, Wolfgang Schlüter, and Alexander Buchele (Ansbach University of Applied Sciences)   
  Abstract    Abstract   The current energy crisis and high fossil fuel costs are challenging energy intensive industries such as non-ferrous foundries. It is therefore important to promote the transition to renewable energy sources with the electrification of melting units. This pilot study is the first to simulate the transition of conventional foundries to sustainable technologies. For this purpose, a simulation model based on a selected example company is developed. It takes into account the energy consumption and the logistical effects of a converted operation. The simulation model is implemented as a hybrid simulation combining a discrete event simulation at the plant level and a process simulation within the furnaces. The study shows how a sustainable energy supply can be achieved in foundries. The effects of efficiency as well as energy costs and emissions are also taken into account.  
 pdf   
  Simulation, Optimization and Control of Trajectories of ASVs Performing HACBS Monitoring Missions in Lentic Waters    
 Alfredo Gonzalez-Calvin, Lía García-Perez José Luis Risco-Martín, and Eva Besada-Portas (Complutense University of Madrid)   
  Abstract    Abstract   Harmful Algae and Cyanobacteria Blooms (HACBs) are dangerous dynamic processes for the users/inhabitants of the hydric resources. Their development and contingency plans can be anticipated by using Autonomous Surface Vehicles (ASVs) equipped with a self-driven system capable of deciding how to displace the ASV and its multi-parametric probe to take measurements in the 3D locations of the water body where the HACB is likely to occur. This paper presents a new self-driven system for that purpose consistent on 1) an offline trajectory planner for the ASV that exploits the information provided by a commercial HACBs simulator to optimize, in turn, the ASV horizontal and probe vertical displacements; and 2) a guidance and control system specially designed for making the ASV follow the planned trajectories. The paper also presents a comprehensive set of simulations to evaluate our proposal's performance and adjust its parameters.  
 pdf   
  Anand Deo (Indian Institute of Management Bangalore) and Karthyek Murthy (Singapore University of Technology and Design)   
  Abstract    Abstract   This paper provides an introductory overview of how one may employ importance sampling (IS) effectively as a tool for solving stochastic optimization formulations incorporating tail risk measures such as Conditional Value-at-Risk. Approximating the tail risk measure by its sample average approximation, while appealing due to its simplicity and universality in use requires a large number of samples to be able to arrive at risk-minimizing decisions with high confidence. In simulation, IS is among the most prominent methods for substantially reducing the sample requirement while estimating probabilities of rare tail events. Can IS be similarly effective for optimization as well? This tutorial aims to provide an overview of the two key ingredients in this regard, namely, (i) how one may arrive at an effective importance sampling change of measure prescription at every decision, and (ii) the prominent techniques available for integrating such a prescription within a solution paradigm for stochastic optimization.  
 pdf   
  Henry Lam (Columbia University)   
  Abstract    Abstract   This tutorial reviews methodologies for quantifying statistical uncertainty in computationally expensive black-box models which arise frequently in data-driven simulation analyses under input uncertainty. When facing these models, it can be difficult to run repeated evaluations due to computation cost and also to obtain auxiliary information such as gradients due to analytical intractability, thus rendering many traditional statistical approaches challenging to apply. We describe several lines of approaches to resolve these challenges, including data-splitting methods based on batching variants, a recent so-called cheap bootstrap approach, and subsampling schemes. We discuss the applications of these approaches to simulation, including problems suffering from both aleatory error exhibited via Monte Carlo noises and epistemic error stemming from the input uncertainty.  
 pdf   
  Russell Barton (The Pennsylvania State University)   
  Abstract    Abstract   Metamodels are fast-to-compute mathematical models that are designed to mimic the input-output behavior of discrete-event or other complex simulation models. Linear regression metamodels have the longest history, but other model forms include Gaussian process regression and neural networks. This introductory tutorial highlights basic issues in choosing a metamodel type and specific form, and making simulation runs to fit the metamodel. The tutorial ends with a warning on potential pitfalls, and suggestions on further reading to expand your knowledge of metamodeling.  
 pdf   
  Using Simulation to Study the Impact of Covid-19 Policies on the Availability of Childcare    
 Adam Cahall, Jasmine Eng, Jane Gao, Ben Hilbert, and Jamol Pender (Cornell University)   
  Abstract    Abstract   The COVID-19 pandemic has had a profound impact on the lives of working parents, who are struggling to balance their responsibilities at work and at home, as well as childcare providers who are working hard to keep their doors open. In this paper, we examine the effect of childcare policies on the availability of childcare. Specifically, we investigate how classroom size, the likelihood of COVID-19 infection, and the number of days a classroom may need to close affect the amount of time parents will need to stay at home with their children. Our results show that even low probabilities of infection combined with stringent policies can have a large impact on the duration of a child's exclusion from childcare services.  
 pdf   
  A Multi-Team Multi-Model Collaborative COVID-19 Forecasting Hub for India    
 Aniruddha Adiga (University of Virginia); Siva Athreya (International Centre for Theoretical Sciences-TIFR Indian Statistical Institute); Kantha Rao Bhimala (CSIR Fourth Paradigm Institute); Ambedkar Dukkipati and Tony Gracious (Indian Institute of Science); Shubham Gupta (IBM Research Europe); Benjamin Hurt, Gursharn Kaur Bryan Lewis, and Madhav Marathe (University of Virginia); Vidyadhar Mudkavi and Gopal Krishna Patra (CSIR Fourth Paradigm Institute); Przemyslaw Porebski (University of Virginia); Nihesh Rathod and Rajesh Sundaresan (Indian Institute of Science); Srinivasan Venkataramanan (University of Virginia); and Sarath Yasodharan (Indian Institute of Science)   
  Abstract    Abstract   During the COVID-19 pandemic, India has seen some of the highest number of cases and deaths. Quality of data, continuously changing policy and public health response made forecasting extremely difficult. Given the challenges in real-time forecasting, several countries had started a multi-team collaborative effort. Inspired by these works, academic partners from India and the United States setup a repository for aggregating India-specific forecasts from multiple teams. In this paper, we describe the effort and the challenges in setting up the repository. We discuss the development of simulations of compartmental models to model specific waves of the pandemic and show that the simulation model designed specifically for the Omicron wave was able to predict the onset and peak sizes accurately. We employed a median-based ensemble model to aggregate the individual forecasts. We observed that median-based ensemble was relatively stable compared to the constituent models and was one of better performing models.  
 pdf   
  Multi-criteria Simulation Optimization for COVID-19 Testing in Schools    
 Yiwei Zhang, Maria Mayorga, Julie Ivy, and Julie Swann (North Carolina State University)   
  Abstract    Abstract   Evidence has shown that random screening tests are effective in reducing COVID-19 infections in schools. However, test administration may be hindered due to a limited budget or low participation caused by pandemic fatigue. Thus we seek to balance the number of tests administered with end-of-semester infections. To do this we use an SEIR model to simulate SARS-CoV-2 transmissions within K-12 schools design a multi-objective simulation optimization problem, and tune an NSGA-II algorithm to find the best testing schedules. We find the Pareto front of optimal schedules of screening tests which can be used by stakeholders to inform test administration strategies. We discuss insights about the characteristics of optimal strategies for example, when there are limited number of tests available or a desire to use few tests the optimal plan is to perform the tests earlier in the semester and at higher intensity.  
 pdf   
  Measuring Emergency Department Resilience to Demand Surge: A Discrete-Event Simulation Framework    
 Eman Ouda, Andrei Sleptchenko, and Mecit Can Emre Simsekler (Khalifa University) and Ghada R. El-Eid (Sheikh Shakhbout Medical City)   
  Abstract    Abstract   This research explores the resilience components in emergency departments (EDs) during surges through discrete-event simulation (DES). By focusing on the resistance and recoverability components, the resilience of the ED is analyzed, as well as the flow of the patient and the resources required at each step. A simulation is developed to model an ED in the UAE and validated through collected timestamps. The results demonstrate the ordinary conditions of the ED and its calculated resilience recoverability, and resistance, as well as its strength under conditions of surge demand. To investigate the impact of resources on the ED’s resilience, the resilience triangle is analyzed, and different interventions are applied by adding physicians, nurses, and beds and their effects. The methodology and simulation model provides significant insights to ED managers to evaluate and improve their department’s resilience during surges and emergencies.  
 pdf   
  A Generalized Symbiotic Simulation Model of an Emergency Department for Real-Time Operational Decision-Making    
 Alexander R. Heib, Christine S. M. Currie, Bhakti Stephan Onggo, and Honora K. Smith (University of Southampton) and James Kerr (Hampshire Hospitals NHS Foundation Trust)   
  Abstract    Abstract   We describe the design of a generalizable simulation model of an emergency department (ED) that forms part of a symbiotic simulation tool designed to improve short-term decision-making. While the paper will give an overview of the planned symbiotic simulation tool, our focus here is on the generalizability of the simulation model. The model is coded such that the routing logic of patient pathways are not explicitly defined but are instead included as an input parameter. By structuring the model this way, the pathways can instead be discovered through process mining methods on standard healthcare transactions data. This enables the simulation model to be applied to other EDs without redesigning all of the logical flows within the model. As symbiotic simulation tools are designed for ongoing use within the system they model, utilizing process mining also allows for automating recalibration of the patient pathways if changes occur in the physical system.  
 pdf   
  Measuring the Operational Impacts of Right-Sizing Prenatal Care Using Simulation    
 Leena Ghrayeb, Timothy Bryan, Meghana Kandiraju, Tejas Maire, Yuanbo Zhang, Amy Cohn, and Alex Peahl (University of Michigan)   
  Abstract    Abstract   Despite high levels of spending on prenatal care, the U.S. has the worst maternal mortality outcomes amongst peer high-income nations. In response to a growing need for modernized prenatal care policies, national prenatal care stakeholders have developed a new model of prenatal care, which moves away from a “one-size-fits-all” model of prenatal care delivery, and instead tailors care to patients’ specific needs. In this article, we develop a data-driven discrete event simulation model to quantify the operational impacts of adopting this new care paradigm. We consider a case study of a large academic health center, and derive input parameters for the model from historical data. Our results suggest that when compared with the “one-size-fits-all” model of care the new tailored care policy leads to reduced patient delays, as well as a reduction in overbooking, implying increased flexibility in the system.  
 pdf   
  Open-Source Modeling for Orthopedic Elective Capacity Planning Using Discrete-Event Simulation    
 Alison Harper, Martin Pitt, and Thomas Monks (University of Exeter)   
  Abstract    Abstract   The increase in elective surgical waiting lists as a result of the COVID-19 pandemic is creating significant consequences for health services worldwide. In the UK, the allocation of capital funds to increase capacity for managing elective waits has created planning and operational challenges for health services. This paper reports on the development and deployment of an interactive web-based discrete-event simulation model for supporting capacity planning of surgical activity and ward stay in a proposed new ring-fenced orthopedic facility in a UK health service. The model is free and open-source and developed to be generic and applicable for new capacity planning of elective recovery in orthopedics in other regions. With minor adaptations it can also be readily modified for application to other specialties. Given the current relevance of managing record elective waiting lists, there is potential widespread applicability of the simulation model which is supported by our open approach to modeling.  
 pdf   
  Evaluating Parallelization Strategies for Large-Scale Individual-Based Infectious Disease Simulations    
 Johannes Ponge (University of Münster), Lukas Bayer (RPTU Kaiserslautern-Landau), Dennis Horstkemper (University of Münster), Wolfgang Bock (RPTU Kaiserslautern-Landau), and Bernd Hellingrath and André Karch (University of Münster)   
  Abstract    Abstract   Individual-based models (IBMs) of infectious disease dynamics with full-country populations often suffer from high runtimes. While there are approaches to parallelize simulations, many prominent epidemic models exhibit single-core implementations, suggesting a lack of consensus among the research community on whether parallelization is desirable or achievable. Rising demands in model scope and complexity however, imply that performance will continue to be a bottleneck. In this paper, we discuss the requirements and challenges of parallel IBMs in general and the German Epidemic Micro-Simulation System (GEMS) in particular. While the exploitation of unique model characteristics can yield significant performance improvement potential, parallelization strategies generally necessitate trade-offs in either hardware requirements, model fidelity, or implementation complexity. Therefore, the selection of parallelization strategies requires a comprehensive assessment. We present a point-based evaluation scheme to assess the potential of parallelization strategies as our main contribution and exemplify its application in the context of GEMS.  
 pdf   
  Determining the Impact of Facility Layout Methods on Walk-in Covid-19 Vaccine Clinics: A Theoretical Exploration    
 S. Yasaman Ahmadi and Jennifer Lather (University of Nebraska Lincoln)   
  Abstract    Abstract   Ensuring safety and public health is a paramount concern in mass vaccination against contagious respiratory infections. This study examines the effects of layout methods and path routing decisions on average patient travel distance (TD) and time-in-system (TIS) within the context of a theoretical mass vaccination clinic. Two distinct layout methods, Perimeter and Serpentine, are evaluated in conjunction with two path routing conditions, Cyclical and Unidirectional. Employing discrete-event simulation, the study investigates multiple patient turnouts and clinic operational hours. The results reveal the significant impact of layout on average TD, underscoring the heightened efficiency of the Perimeter layout and Unidirectional path. Furthermore, the findings highlight the significant effect of layout method on TIS when considering optimal staffing configurations. Conversely, the analysis indicates that path directionality does not exert a statistically significant effect. This study emphasizes the critical role of layout design in optimizing vaccination clinics for efficiency and effectiveness.  
 pdf   
  Continuous-Time Survival Model Study Designs for Heart Recovery Applications    
 Jason Bodnar (ABIOMED, Inc.)   
  Abstract    Abstract   Due to the aging global population, the science of heart recovery is an essential area for research to improve patient health, reduce time-to-discharge, and delay overall mortality. New medical device technology is needed to advance these goals. For the medical community to gain trust in and use these technologies in their hospital environments, optimal study design and proper execution of randomized controlled trials is necessary. Such RCTs will result in the collection of valid scientific evidence for establishing the new device’s risk and benefit profile in targeted patient populations. Continuous time-to-event survival models are commonly used to determine the amount of data needed to demonstrate an improvement in these profiles over current standard-of-care therapies. This paper will compare simulated power functions and sample size requirements for a variety of survival methods in a two-sample RCT setting. Simulation scenarios will encompass various effect sizes, survival distribution forms, and time-to-event density functions.  
 pdf   
  KSIM 2.0: A Simulation of Kidney Allocation Using OPTN Records    
 Masoud Barah (Northwestern University), Vikram Kilambi (RAND Corporation), and Sanjay Mehrotra (Northwestern University)   
  Abstract    Abstract   The Organ Procurement and Transplantation Network (OPTN) in the US allocates kidneys for transplantation, but nearly one fifth of kidneys from deceased donors are not utilized due to the avoidance of transplantation for kidneys that have been removed from a donor for too long. To be able to provide clinically relevant recommendations to the OPTN contractor, we updated the KSIM discrete event simulation of kidney allocation in the academic literature using actual OPTN individual-level records for patients and donors. As a case study, we simulated offering kidneys at high risk of discard to the first accepting transplant center after 10 hours of accumulated cold time and found increased utilization. The updated model allows for greater clinical fidelity and can be embedded in medical decision support systems.  
 pdf   
  Modeling and Simulation of the SARS-CoV-2 Lung Infection and Immune Response with Cell-DEVS    
 Ali Ayadi (University of Strasbourg, ICube laboratory); Claudia Frydman (Aix Marseille Université); and Quy Thanh Le (Da Nang University of Science and Technology)   
  Abstract    Abstract   Understanding why patients' viral loads vary dramatically across individuals is a critical challenge in addressing respiratory infections especially the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The spatial-temporal dynamics of viral infection in the respiratory system and the immune system's response remain difficult to study. Using modelling and simulation (M&S) techniques may address this problem. In this paper, we present a novel modelling approach using the Cell-DEVS formalism (a combination of Cellular Automata and DEVS), to simulate the spatial-temporal dynamics of viral spread in the lungs. Using a two-dimensional cellular space that mimics a lung, the proposed approach focuses also on the immune system response, viral infection spread state of lung epithelial tissue damage, and immune cells' state. We demonstrate the pertinence of our proposal on three different scenarios representing three types of patients. Qualitative evaluation by expert biologists confirms that the produced simulations match the observations made on patients.  
 pdf   
  Hybrid Models with Real-Time Data in Healthcare: A Focus on Data Synchronization and Experimentation    
 Navonil Mustafee and Alison Harper (University of Exeter, The Business School) and Joe Viana (BI Norwegian Business School)   
  Abstract    Abstract   Conventional simulation models used in Operations Research and Management Science (OR/MS) use historical data. With the increasing availability of real-time data, technologies commonly associated with applied computing, such as Data Acquisition Systems (DAS), may need to be integrated with conventional OR/MS models to develop Hybrid Models (HMs). We distinguish between HMs that use only real-time data – we refer to them as Digital Twins (DTs) – and those using a combination of historical and real-time data – called Real-time Simulation (RtS). Our previous contribution focused on the challenges of such integration, a concept referred to as information fusion, and presented a conceptualization of DT/RtS. This paper focuses on DT/RtS data synchronization and methods that could be employed from Parallel and Distributed Simulation (PADS). The conceptualizations and discussions reflect on the authors' experience implementing an RtS of a network of Emergency Departments and Urgent Care Centers in the UK.  
 pdf   
  Modeling and Simulation of Genomic Sequencing Platform Operations    
 Jules Le Lay (Centre Léon Bérard), Vincent Augusto and Xavier Boucher (Mines Saint-Etienne), Lionel Perrier (Centre Léon Bérard), and Xiaolan Xie (Mines Saint-Etienne)   
  Abstract    Abstract   This paper focuses on the healthcare application field of Genomic Sequencing and addresses the challenge of efficient organization and ramp-up of sequencing platforms. High-throughput sequencing platforms are currently in an industrial prototyping phase in France for large national deployment afterwards. In the current state of our knowledge, there is no scientifically established generic model nor decision-making support at the operational level which could guide the medical authorities in designing organizational rules, then managing the deployment of such platforms at the national level. After analyzing the state of the art, a simulation model of a genome sequencing platform is presented, then used as a decision-making support to manage a ramp-up situation for an application case of a French sequencing platform. These first results are discussed together with the perspective to develop a generic model and decision-aid approach.  
 pdf   
  Conceptual Modeling for Perishable Inventory: A Case Study in Human Milk Banking    
 Marta Staff and Navonil Mustafee (University of Exeter) and Natalie Shenker (Imperial College London)   
  Abstract    Abstract   The Conceptual Modeling (CM) stage of an M&S study focuses on developing an abstraction of the real world for subsequent implementation as a computer model. Several studies have acknowledged the importance of CM in the success of simulation projects. Yet, there is a lack of literature on applying CM frameworks to real-world case studies, which arguably impedes the translation of CM research into practice. In this paper, we present the development of a conceptual model, using Robinson’s CM framework, for our case study investigating the perishable product of human milk within the milk banking supply chain. We present the application of the various stages of the framework reporting on stakeholder engagement, which has allowed us to develop a shared view of the CM. The paper adds to the literature on CM in practice, providing a detailed narrative on developing a conceptual model for perishable inventory management.  
 pdf   
  A Simulation Model and Dashboard for Predicting Covid-19 Bed Requirements    
 Best Contributed Applied Paper - Finalist    
 Yin-Chi Chan, Kaya Dreesbeimdiek, Ajith Kumar Parlikad and Tom Ridgman (University of Cambridge); Nicholas J. Matheson and Ben Warne (University of Cambridge Cambridge University Hospitals NHS Foundation Trust); and Denise Franks (Cambridge University Hospitals NHS Foundation Trust)   
  Abstract    Abstract   The Covid-19 pandemic has placed extraordinary amounts of stress upon public hospitals globally. This paper describes a simulation model for estimating hospital bed demand based on generated scenarios. Statistical tools were also developed for generating these scenarios in particular, for fitting distributions to patients' lengths-of-stay and for predicting the number of daily arrivals of Covid-19 patients. A web dashboard has been created for ease of use. The simulation model and statistical tools have been used to estimate Covid-related bed demand at an NHS hospital in the East of England.  
 pdf   
  Design of a Serious Game for Safety in Manufacturing Industry Using Hybrid Simulation Modeling: Towards Eliciting Risk Preferences    
 Hanane El Raoui and John Quigley (University of Strathclyde), Ayse Aslan and Gokula Vasantha (Edinburgh Napier University), Jack Hanson and Jonathan Corney (Edinburgh University), and Andrew Sherlock (National Manufacturing Institute Scotland/ University of Strathclyde)   
  Abstract    Abstract   Conventional methods used to elicit risk-taking preferences have demonstrated significant disparities with real-world behaviours compromising the validity of the data collected. Serious gaming (SG) provides a high potential to bridge this gap. This paper presents a serious game as a novel approach to elicit risk-preference in an industrial manufacturing context, focusing on the game-design and implementation using hybrid simulation modelling. The developed SG serves as a tool for conducting incentivized experiments aimed at assessing human behaviour towards risk, to inform policy recommendations. The game incorporates two influential factors in shaping risk-taking behaviour in a manufacturing environment, namely the social learning and production pressure, and use a variety of game mechanics to promote the players’ motivation and engagement. A usability study was conducted with 10 participants using the Usability Scale System (SUS), to identify problems in the usability of the game. Results have shown that our game has a good usability.  
 pdf   
  Virtual Planning of a Metal Additive Manufacturing Factory Using Techno-Economic Hybrid Simulation Models    
 Eldar Shakirov, Haden Quinlan, and A. John Hart (Massachusetts Institute of Technology)   
  Abstract    Abstract   Factory simulation can guide leaner production operations and resilient supply chains by informing capital allocation and real-time decision-making. This is especially true for emerging production methods, like additive manufacturing (AM), where a lack of expertise and relative technological novelty make it difficult to quantitatively assess technology economics across applications. While reported cost models provide detailed analysis on the AM printing process, accurate modeling requires specific evaluation of process-level and production-level considerations that significantly impact factory dynamics and cost. Advances in factory simulation modeling therefore promise the development of comprehensive and actionable cost models. This paper reviews progress in simulation-based costing, hybrid simulation, and automated model generation, and proposes an integrated approach for cost modeling using an AM-based factory. We demonstrate the feasibility of this approach by simulating the production of two common AM part geometries, and evaluate the associated cost and time performances of different factory configurations.  
 pdf   
 Chair: Steffen Strassburger (Technische Universität Ilmenau)  
  Choosing the Right Entity Size to Minimize Discretization Error in Discrete Event Simulation Models    
 Leonardo Chwif (IMT), Wilson Pereira (Simulate), and José Arnaldo Barra Montevechi (Federal University of Itajubá)   
  Abstract    Abstract   In discrete-event simulation models, the way we establish the relationship between a real-world object and the model entity (a single indivisible object flowing through the model) is crucial to some classes of problems due to possible computational unfeasibility. In addition, the entity size also relates to results accuracy and simulation running time - a subject barely explored in the literature. In this paper, these questions were investigated through case studies which supported our initial hypothesis about the general relationships involved. Then, a simple algorithm was developed for correctly choosing the best entity size to provide the desired accuracy, measured as a discretization error, with promising results. The limitations of the algorithm are addressed and some directions for future research are pointed.  
 pdf   
  How Not to Visualize Your Simulation Output Data    
 Jonas Genath (Ilmenau University of Technology) and Steffen Strassburger (Technische Universität Ilmenau)   
  Abstract    Abstract   Hybrid modeling and simulation studies combine well-defined methods from other disciplines with a simulation technique. Especially in the area of output data analysis of simulation studies there is great potential for hybrid approaches that incorporate methods from machine learning and AI. For their successful application, the analytical capabilities of machine learning and AI must be combined with the interpretive capabilities of humans. In most cases, this connection is achieved through visualizations. As methods become more complicated, the demands on visualizations are increasing. In this paper we conduct a data farming study and delve into the analysis of the result data. In doing so, we uncover typical errors in visualizations making the interpretation and evaluation of the data difficult or misleading. We then apply the concepts of visual analytics to these visualizations and derive general guidelines to help simulation users to analyze their simulation studies and present results unambiguously and clearly.  
 pdf   
  Simulation Model to Forecast Gender Pension Wealth Gap in the Light of Demographic Changes    
 Bożena Mielczarek (Wroclaw University of Science and Technology)   
  Abstract    Abstract   The ageing of the population has forced changes in many areas of social policy, including pension systems. Countries are reforming their retirement policies in such a way that the size of pension benefits depends on the total period of employment, contributions made, and life expectancy. Due to the fact that in these types of system, employment plays a significant role in the accumulation of pension capital, a gender pay gap translates into a gender pension gap. In this article, we propose a hybrid simulation model to analyze the impact of long-term economic and demographic changes on the level of pension benefits when a worker retires, with a special focus on gender wealth pension gaps. The model combines demographic simulation conducted using a systems dynamics approach with discrete stochastic simulation by means of which we model the employment history of men and women. The model uses data from Polish statistical databases.  
 pdf   
  πHyFlow: A Modular Process Interaction Worldview    
 Fernando Barros (University of Coimbra)   
  Abstract    Abstract   Worldviews play a central role in M&S providing the basic constructs to describe simulation models. Three main worldviews have been defined: event scheduling, activity scanning, and process interaction (PI). The latter has been described in two flavors, one centered in the network of resources and other in the transitory transactions that flow in the network. In this paper we present a new M&S approach based on the πHYFLOW formalism that combines network and transaction PI, while keeping the support for modular and hierarchical models. We demonstrate πHYFLOW expressiveness by representing a hybrid production unit with a variable number of machines subjected to breakdowns. The hybrid model combines a fluid queue describing the work-in-progress, with discrete events modeling machines arrivals, departures, and breakdowns. Arrivals and departures of machines are achieved through modular communication, enabling model composition with other πHYFLOW components.  
 pdf   
  Simulating and Evaluating Internal Logistics Strategies for Suppliers in Just-in-Sequence Supply Systems in the Automotive Industry    
 Helen Christina Sand, Marvin Auf der Landwehr, and Christoph von Viebahn (Hochschule Hannover)   
  Abstract    Abstract   The reliability of just-in-sequence supply systems depends to a large extent on the efficiency of a supplier’s internal logistics distribution system. Thus, improving the logistics efficiency is a major objective for many suppliers in the automotive industry. In this paper, a discrete event simulation model is developed to evaluate the operational implications of different logistics strategies in just-in-sequence supply systems. Building upon the case of a major automotive supplier from Germany, the implications of various transportation resources and routing approaches are investigated and analyzed when it comes to the supply of components from an internal warehouse to the assembly lines. Experimental results show that the combined load-carrier-specific use of forklifts, pallet trucks and tugger trains holds a high potential to achieve more efficient supply operations and meet different operational performance criteria such as downsizing the vehicle fleet, improving supply reliability and punctuality at the assembly lines, or minimizing warehouse traffic.  
 pdf   
  Route Selection in Mixed Fleet Warehouses    
 Anna Rotondo (Irish Manufacturing Research)   
  Abstract    Abstract   Warehouse systems are progressively shifting towards mixed fleet models where automated and manually operated vehicles work together sharing the same floorspace. This is posing communication and co-ordination challenges from both a design and an operational perspective. Mixed fleet co-ordination is particularly challenging from a traffic control viewpoint due to the erratic behavior that human drivers may exhibit. In this work, an optimisation framework that aims at selecting the optimal route among candidate ones in a mixed fleet warehouse environment is developed. More specifically, the foundational deterministic components of the framework are described and an interactive dashboard used for verification purposes is presented. The development work of the stochastic component and the simulator is still ongoing. Initial feedback based on virtual testing conducted by an industrial partner suggests that a static optimisation approach based on historical traffic information may not lead to optimal choices when the human behavior is neglected.  
 pdf   
  Modeling Autonomous Vehicle-Targeted Aggressive Merging Behaviors in Mixed Traffic Environment    
 JongIn Bae (Georgia Institute of Technology), Abhilasha Jairam Saroj (Oak Ridge National Laboratory), Wonho Suh (Hanyang University), and Michael P. Hunter and Angshuman Guin (Georgia Institute of Technology)   
  Abstract    Abstract   Advances in Autonomous Vehicle (AV) technology has fueled industry and research fields to dedicate significant effort to the study of the integration of AVs into the traffic network. This study focuses on the transition phase between all Human Driven Vehicles (HDVs) in the network to all AVs, where these different vehicle types coexist in a mixed traffic environment. This paper investigates the potential impacts of aggressive merging behaviors by human drivers on traffic performance in a mixed environment. For this three vehicle types – AVs, HDVs, and Aggressive HDVs (AHDVs) are modeled in an open-source microscopic traffic simulation model, SUMO. In the developed simulation, the AHDVs are modeled to emulate aggressive merging behaviors in front of AVs at a merge section of a freeway exit ramp. Several experiments are used to study the impact of such behavior. Results show travel-time gains by AHDVs at the expense of AVs and HDVs.  
 pdf   
  Estimating Parameters with Data Farming for Condition-Based Maintenance in a Digital Twin    
 Alexander Wuttke, Joachim Hunker, and Markus Rabe (TU Dortmund University) and Jan-Philipp Diepenbrock (IVA Schmetz GmbH)   
  Abstract    Abstract   Nowadays, vast amounts of data can be collected by sensors and used for data-driven approaches. Digital twins provide a framework to exploit these data for solving various issues. For many companies in the industrial sector, machine maintenance is a significant issue. Maintenance is essential for high overall equipment efficiency, but it can also be costly. Therefore, it should only be performed when necessary, based on the machine’s condition. Condition monitoring is used to assess a machine’s condition periodically allowing for condition-based maintenance. In this paper, a simulation-based approach for parameter estimation is presented that contributes to condition-based maintenance. It introduces condition indicators for certain features of machines and demonstrates how to evaluate them using data farming, which employs simulation models as data generators. Additionally, the implementation of this approach in digital twins is discussed.  
 pdf   
  A Simulation-Based TDABC Model to Manage Supply Chain Costing: A Case Study    
 Siham Rahoui, John Crowe, and Amr Mahfouz (Technological University Dublin)   
  Abstract    Abstract   Effective management of supply chain costing is crucial for decision-making during times of disruption. It provides accurate cost indicators, enabling organizations to adapt to the risks of disruptions and mitigate their adverse effects. Supply chain costing literature has shown that traditional cost accounting approaches are inadequate in addressing the dynamic and complex nature of supply chain performance and the nonlinear behavior of the involved processes. Consequently, this paper presents a simulation-based supply chain costing framework that integrates discrete event simulation and time-driven activity-based costing to explore the dynamics of management accounting tools in a real context with all their complexities and interdependencies. The framework will be applied to the logistics function of an automotive supply chain to demonstrate the applicability of a static versus a dynamic time-driven activity-based costing model, their suitability to reflect the real operational performance of the supply chain and suggest ways to improve it.  
 pdf   
  A Deep Q-Network Based on Radial Basis Functions for Multi-Echelon Inventory Management    
 Liqiang Cheng and Jun Luo (Shanghai Jiao Tong University), Weiwei Fan (Tongji University), and Yidong Zhang and Yuan Li (Alibaba)   
  Abstract    Abstract   This paper addresses a multi-echelon inventory management problem with a complex network topology where deriving optimal ordering decisions is difficult. Deep reinforcement learning (DRL) has recently shown potential in solving such problems, while designing the neural networks in DRL remains a challenge. In order to address this, a DRL model is developed whose Q-network is based on radial basis functions. The approach can be more easily constructed compared to classic DRL models based on neural networks, thus alleviating the computational burden of hyperparameter tuning. Through a series of simulation experiments, the superior performance of this approach is demonstrated compared to the simple base-stock policy, producing a better policy in the multi-echelon system and competitive performance in the serial system where the base-stock policy is optimal. In addition, the approach outperforms current DRL approaches.  
 pdf   
  Simulation-based Cost Modeling to Measure the Effect of Automated Trucks in Inter-terminal Container Transportation    
 Ann-Kathrin Lange, Johannes Hinckeldeyn, Hendrik Rose Nicole Nellen, and Michaela Grafelmann (Hamburg University of Technology)   
  Abstract    Abstract   Container transports within ports are characterized by mostly manual trucks and many handling operations in relatively small areas. Accordingly, they incur a disproportionately large cost in maritime transport chains. One way to reduce these costs is to use automated trucks in a port-internal transport system. Such systems have only been used on terminals, but not within whole ports. Thus, it is important to determine the design parameters of such transport systems. Discrete-event simulation is particularly suitable for investigating planned systems and controls in logistics. However, the costs of such systems are usually neglected. Therefore, a simulation-based cost model is used in this study to determine the cost-effectiveness of automated trucking systems. It is shown which factors possess the greatest influence on the cost-effectiveness of port-internal container transports. Furthermore it can be estimated for the first time which cost savings can be achieved by using automated trucks for port-internal container transports.  
 pdf   
  An Integrated System Dynamics and Discrete Event Supply Chain Simulation Framework for Supply Chain Resilience with Non-stationary Pandemic Demand    
 Mustafa Camur (GE Research); Chin-Yuan Tseng (Georgia Institute of Technology); Aristotelis E. Thanos (GE Research); Chelsea C. White (Georgia Institute of Technology); Walter Yund (GE Research); and Eleftherios Iakovou (Texas A&M University, Texas A&M Energy Institute)   
  Abstract    Abstract   COVID-19 resulted in some of the largest supply chain disruptions in recent history. To mitigate the impact of future disruptions, we propose an integrated hybrid simulation framework to couple nonstationary demand signals from an event like COVID-19 with a model of an end-to-end supply chain. We first create a system dynamics susceptible-infected-recovered (SIR) model augmenting a classic epidemiological model to create a realistic portrayal of demand patterns for oxygen concentrators (OC). Informed by this granular demand signal, we then create a supply chain discrete event simulation model of OC sourcing, manufacturing, and distribution to test production augmentation policies to satisfy this increased demand. This model utilizes publicly available data, engineering teardowns of OCs, and a supply chain illumination to identify suppliers. Our findings indicate that this coupled approach can use realistic demand during a disruptive event to enable rapid recommendations of policies for increased supply chain resilience with controlled cost.  
 pdf   
  Integrating a Mode Choice Model into Agent-based Simulation for Freight Transport Planning and Decarbonization Analysis    
 Senlei Wang, Dhanan Sarwo Utomo, and Philip Greening (Heriot-Watt University)   
  Abstract    Abstract   This paper presents a framework for integrating a discrete mode choice model with agent-based simulation. The integrated framework provides a more realistic representation of long-haul freight transport and is applied to the real-world scenarios of moving freight from ports to inland destinations via road, rail, and inland waterways. It incorporates a mode choice component that captures demand shifts between modes in response to different different policy and vehicle technology interventions. The objective is to investigate the financial and environmental impacts of introducing new vehicle technologies and associated energy sources under different future scenarios in a UK multimodal freight system.  
 pdf   
  Improving Buffer Storage Performance in Ceramic Tile Industry via Simulation    
 Marco Taccini (University of Modena and Reggio Emilia); Giulia Dotti (University of Modena and Reggio Emilia Marco Biagi Foundation); Manuel Iori (University of Modena and Reggio Emilia); and Anand Subramanian (Universidade Federal da Paraíba)   
  Abstract    Abstract   This study aims at identifying the best strategy to temporarily store products within a buffer area in an Italian ceramic tile company. The storage policy is analyzed to maximize the storage capacity, facilitate operators' activities, and, consequently, improve the warehouse logistics performance. A discrete event simulation was conducted using Salabim, a Python based open-source software, in order to determine the best policy. We compare the performance of the current storage policy, based on technical production properties of products and a newly proposed one, based on products' downstream destination. The results suggested that the proposed strategy significantly improves the performance of the buffer area management. The approach can be applied to different applications, contributing to the literature on simulation-based decision-making in material management. Furthermore, the study provides a functional case study showing the potential and achievable results of Salabim for modeling complex systems.  
 pdf   
  Simulating the Impact of Forecast related Overbooking and Underbooking Behavior on MRP Planning and a Reorder Point System    
 Wolfgang Seiringer and Klaus Altendorfer (University of Applied Sciences Upper Austria) and Thomas Felberbauer (University of Applied Sciences St. Pölten)   
  Abstract    Abstract   Production Planning and its parameterization is critical to fulfil customer demands and to successfully react on changes in high volatile markets. Therefore, demand updates should be considered to improve production planning. In this paper the performance of two production planning methods MRP (Material Requirements Planning) and RPS (Reorder Point System) are compared in a multi-item single stage system where customer orders are updated in a rolling horizon manner. Applying a simulation study, we investigate the performance of MRP and RPS for biased and unbiased forecast information and discuss the difference in the optimal planning parameters. The study shows that for a production system with underbooking and low demand uncertainty, RPS method is superior, in all other scenarios MRP outperforms RPS. For overbooking scenarios, the results show that MRP leads to overall cost improvements ranging from 8% to 30%.  
 pdf   
  Optimizing Arterial Traffic Signal Settings: Shotgun Version for Simultaneous Perturbation Stochastic Approximation Approach    
 Yen-Hsiang Chen and Michael Franciudi Hartono (National Taiwan University)   
  Abstract    Abstract   The recent advancement in hardware computation speed has allowed stochastic microscopic traffic simulators to be embedded in signal optimization systems. In this study, stochastic perturbation simulation approximations (SPSA), an efficient difference-typed gradient-based searching, has been applied in the signal solver of a signal optimization system due to (i) its lower required total number of replications and (ii) the capability to conduct variance reduction technique (VRT). The case study has shown that the objective value, in terms of road users’ delay, indeed improves over iterations. Since the gradient-based method may be trapped in the local optimal, this study has further applied the shotgun mechanism that allows better solutions in the subject stage to proceed to the next stage. By further offering the shotgun process, the quality of the solution can be further improved.  
 pdf   
  Cloud-Based Hybrid Simulation Model For Optimizing Warehouse Yard Operations    
 Mohammed Farhan, Pascalin Ngoko, Farouq Halawa, and Raashid Mohammed (Amazon)   
  Abstract    Abstract   Fulfillment centers in the E-commerce industry are highly complex systems that houses inventory and fulfill customer orders. One of the key processes at these centers involves translating customer demands into trucks and yard operations. Truck yards with operational issues can create delays in customer orders. In this paper, we show how a scalable cloud-based hybrid simulation model is used to improve yard operations, optimize flow and design, and forecast yard congestion. Cloud experimentation along with automated database connectivity allows any user to run simulation analyses to derive data driven operational decisions. We tested the model on two real world case studies which results in cost savings for the organization. This paper also proposes a robust automated framework for setting simulation validation benchmarks and measuring model accuracy.  
 pdf   
  Simulation-Based Analysis of Improvements in Vehicle Routing with Time Windows Using a One-sided VCG Mechanism for the Reallocation of Unfavorable Time Windows    
 Felix Roeper and Ralf Elbert (Technische Universität Darmstadt)   
  Abstract    Abstract   In road freight transport, booking unfavorable time windows (TW) through time window management systems (TWMS) for loading or unloading trucks at the loading dock often leads to avoidable long tours. Therefore, this paper investigates based on an agent-based simulation framework the efficiency gains and improvements in vehicle routing with TW constraints that can be achieved by a reallocation of unfavorable TWs using a one-sided Vickrey-Clarke-Groves mechanism. A branch-and-cut algorithm is used to evaluate the value of a TW in the context of a pickup and delivery problem with time windows and to generate a bid for the auction. A winner determination problem is solved for conducting the auction. We show that a reallocation of unfavorable TWs leads to distance savings for the considered tours of the auction winners of 13% on average. Further, we can show that the TWMS provider can benefit by operating the mechanism on an electronic marketplace.  
 pdf   
  Multi-Agent Proximal Policy Optimization for a Deadlock Capable Transport System in a Simulation-Based Learning Environment    
 Marcel Müller (Otto von Guericke University Magdeburg); Lorena Silvana Reyes Rubiano (RWTH Aachen University, Universidad de La Sabana); and Tobias Reggelin and Hartmut Zadek (Otto von Guericke University Magdeburg)   
  Abstract    Abstract   In this paper, we explore the potential of multi-agent reinforcement learning (MARL) for managing the driving behavior of autonomous guided vehicles (AGVs) in production logistics environments with single-lane tracks, where deadlocks pose a significant challenge. We build upon previous work and adopt a MARL approach using the Proximal Policy Optimization (PPO) algorithm. We conduct a thorough hyperparameter search and investigate the impact of varying numbers of agents on the performance of the AGVs. Our results demonstrate the effectiveness of the MARL approach in addressing deadlocks and coordinating AGV behavior, as well as the scalability of the learned policy to different numbers of agents. The Bayesian optimization process and increased iteration count contribute to improved performance and more stable learning curves.  
 pdf   
  Simulation Analysis of a Reinforcement-Learning-Based Warehouse Dispatching Method Considering Due Date and Travel Distance    
 Sriparvathi Shaji Bhattathiri, Ankita Tondwalkar Michael E. Kuhl, and Andres Kwasinski (Rochester Institute of Technology)   
  Abstract    Abstract   As the adoption of autonomous mobile robots in warehouses and other industrial environments continues to increase, there is a need for methods that can effectively dispatch robots to meet system demand. Real-time dispatching of autonomous mobile robots can be very complex but simple rule-based methods are typically used for this task. In this paper, a reinforcement-learning-based dispatching method for intralogistics (RLDI) is proposed. RLDI is warehouse layout independent and takes into consideration task due dates and the travel distance. The algorithm is trained and tested in a simulation environment that represents a small warehouse. Monte Carlo simulation analysis is used to explore the capabilities and limitations of the established RLDI. The performance of the method is compared to the shortest distance dispatching rule in single and multi-agent environments under various levels of due date tightness. Experimental results demonstrate the potential for using reinforcement learning methods for warehouse dispatching.  
 pdf   
  Solving the Multi-Allocation p-Hub Median Problem with Stochastic Travel Times: A Simheuristic Approach    
 Niklas Jost (TU Dortmund), Majsa Ammouriova (Universitat Oberta de Catalunya), Aleksandra Grochala (TU Dortmund), Angel Juan (Universitat Polit`ecnica de Val`encia), and Christin Schumacher (TU Dortmund)   
  Abstract    Abstract   The p-hub median problems (pHMPs) are a well-researched topic within the fields of Operations Research and Industrial Engineering. These problems have been found to have a wide range of practical applications in various areas such as logistics, retailing, and Internet computing. These applications have made pHMPs an important area of study, leading to numerous research efforts aimed at solving different variations of the problem. This paper presents a simheuristic algorithm for solving the uncapacitated version of the pHMP with stochastic travel times. The proposed approach combines simulation with biased-randomized heuristics to generate high-quality solutions quickly. The proposed method is validated by testing it on huge benchmark instances, which include stochastic travel times. The results demonstrate the efficiency of the proposed approach for this particular problem variation. The simulation-optimization approach provides a promising solution to a practical problem that arises in many real-world applications.  
 pdf   
  A Two-Stage Stochastic Model for Drone Delivery System with Uncertainty in Customer Demands    
 Xudong Wang, Gerald Jones, and Xueping Li (University of Tennessee, Knoxville)   
  Abstract    Abstract   Drone delivery is a popular logistics method for e-commerce businesses due to its efficiency and convenience, especially for last-mile delivery and emergency situations in areas with poor infrastructure. However, the uncertainty of customer demands can affect transportation costs in the long run, making it vital to design an effective delivery system. To tackle this issue we propose a two-stage stochastic model that minimizes the sum of fixed and expected operating costs. The first stage minimizes the total cost of the delivery system, including the facilities fixed costs and expected operating costs, while the second stage arranges drones' routes according to simulated demands to estimate the minimal expected transportation cost and penalty cost. Since this stochastic programming has infinite scenarios, we deploy a sample average approximation method to estimate its bounds. Additionally, we use a heuristic simulation framework to find a satisfactory solution in an acceptable time.  
 pdf   
  Maintenance and Operations of Manufacturing Digital Twins    
 Alp Akcay (Eindhoven University of Technology), Stephan Biller (Purdue University), Boon Ping Gan (D-SIMLAB Technologies Pte Ltd), Christoph Laroque (University of Applied Sciences Zwickau), and Guodong Shao (National Institute of Standards and Technology)   
  Abstract    Abstract   Digital twins have become an important element in smart manufacturing. As any other product digital twins also have a lifecycle, starting from specifying the requirements of the digital twins until their decommissioning. As part of the Manufacturing and Industry 4.0 track of the Winter Simulation Conference (WSC), the purpose of this panel is to discuss the state of the art in digital twins with a special emphasis on the operations and maintenance of manufacturing digital twins during their lifecycles. The panelists come from academia, industry, and government with experience in the digital-twin landscape of the manufacturing industry in the United States, Europe, and Asia. This paper provides a collection of the statements from each panelist with the objective of initiating a deeper discussion during the panel session and inspiring researchers in the simulation community with their perspectives on the use of digital twins for smart manufacturing.  
 pdf   
  Stochastic Molecular Reaction Queueing Network Modeling for In Vitro Transcription Process    
 Keqi Wang, Wei Xie, and Hua Zheng (Northeastern University)   
  Abstract    Abstract   To facilitate a rapid response to pandemic threats, this paper focuses on developing a mechanistic simulation model for in vitro transcription (IVT) process, a crucial step in mRNA vaccine manufacturing. To enhance production and support industry 4.0, this model is proposed to improve the prediction and analysis of IVT enzymatic reaction network. It incorporates a novel stochastic molecular reaction queueing network with a regulatory kinetic model characterizing the effect of bioprocess state variables on reaction rates. The empirical study demonstrates that the proposed model has a promising performance under different production conditions and it could offer potential improvements in mRNA product quality and yield.  
 pdf   
  From Simulation To Real-Time Digital Twin and AI - Implementation in a Food Manufacturing Plant    
 Hosni Adra (CreateASoft, Inc)   
  Abstract    Abstract   Data-Driven simulation models are valuable tools to improve the accuracy of the models and enable them to transition to real-time predictive analytics tools. Adding AI (Artificial Intelligence) and ML (Machine Learning) enables those model to provide feedback and real-time optimization in un-attended environment. This paper details the steps and benefits that were used to implement such system in a large filling and packaging manufacturing setting, from initial randomized models to full real-time digital twin systems. Final models were used to optimize (real-time and offline) changeover, CIP (Clean in Place), production, filling lines, and material handling.  
 pdf   
  Semiconductor Fab Scheduling with Self-Supervised and Reinforcement Learning    
 Best Contributed Applied Paper - Finalist    
 Pierre Tassel and Benjamin Kovács (Alpen-Adria-Universität Klagenfurt); Martin Gebser (Alpen-Adria-Universität Klagenfurt, Graz University of Technology); Konstantin Schekotihin (Alpen-Adria-Universität Klagenfurt); and Patrick Stöckermann and Georg Seidel (Infineon Technologies AG)   
  Abstract    Abstract   Semiconductor manufacturing is a complex, costly process involving a long sequence of operations on limited, expensive equipment. Recent chip shortages and their impacts have highlighted the importance of semiconductors in the global supply chains and how reliant on those our daily lives are. Due to the investment cost environmental impact, and time scale needed to build new factories, it is difficult to ramp up production when demand spikes. This work introduces a method to successfully learn to schedule a semiconductor manufacturing facility more efficiently using deep reinforcement and self-supervised learning. We propose the first adaptive scheduling approach to handle complex continuous, stochastic, dynamic, modern semiconductor manufacturing models. Our method outperforms the traditional hierarchical dispatching strategies typically used in semiconductor manufacturing plants substantially reducing each order’s tardiness and time until completion. Consequently, our method yields a better allocation of resources in the semiconductor manufacturing process.  
 pdf   
  Digital Twins and Deep Reinforcement Learning for Online Optimization of Scheduling Problems    
 Bulent Soykan and Ghaith Rabadi (University of Central Florida)   
  Abstract    Abstract   This paper presents an approach that combines data-driven digital twins (DTs) and deep reinforcement learning (DRL) to address the challenges of online optimization of scheduling problems, focusing specifically on the classic job shop scheduling problem. Traditional approaches to solving such problems often encounter limitations in handling uncertainties and dynamic environments. In this study, we explore the integration of DTs and DRL to enhance decision-making in scheduling problems. We investigate the adaptability of a Graph Neural Network model within the DRL framework enabling the agent to learn optimal scheduling policies through interactions with the DT. The potential of this convergence to tackle modern scheduling complexities offers insights into the future of operations management.  
 pdf   
  Modeling and Simulation for the Operative Service Delivery Planning in the Context of Product-Service Systems    
 Enes Alp (Ruhr-Universität Bochum); Michael Herzog (Centre for the Engineering of Smart Product-Service Systems (ZESS)); Furkan Ercan (Ruhr-Universität Bochum); and Bernd Kuhlenkötter (Ruhr-Universität Bochum, Centre for the Engineering of Smart Product-Service Systems (ZESS))   
  Abstract    Abstract   Accelerated with the developments in the context of Industry 4.0, a new trend has established itself in the manufacturing industry within the last two decades. Companies started to offer integrated solutions such as Product-Service Systems (PSS). While the provision of PSS enables benefits like business model innovation or strengthening competitiveness, the exploitation of these benefits depends heavily on the decisions in the operative service delivery planning. This, however, is a complex task due to the huge solution space. Analytical methods reach their limitations when trying to find the optimal solution. Though different optimization algorithms were elaborated for this problem, the evaluation of their solutions is overly simplified, and thus, their expressiveness for the uncertain and dynamic reality remains questionable. This paper addresses these issues by demonstrating the modeling of an adaptive simulation model that can be used to gain a realistic evaluation of operative service delivery plans in PSS.  
 pdf   
  Simulation-Based AGV Management with a Linear Dispatching Rule    
 Nitish Singh, Jeroen B.H.C. Didden, Alp Akcay, Tugce Martagan, and Ivo J.B.F. Adan (Eindhoven University of Technology)   
  Abstract    Abstract   This paper considers the problem of real-time dispatching of a fleet of heterogeneous automated guided vehicles (AGVs) with battery constraints. The AGV fleet is heterogeneous in terms of material handling capabilities; some can tow loads, some can lift loads while others manipulate loads with the assistance of a robotic arm. Transport requests arrive in real-time and include a soft time window, with late delivery incurring tardiness costs. Transport requests need to be assigned to a capable AGV based on required material handling capabilities with the objective to minimize a weighted sum of tardiness costs of transport requests and travel costs of AGVs. In this paper, an AGV-specific linear dispatching rule (LDR) learning approach is proposed to assign AGVs to randomly arriving transport requests in real time over a finite horizon. The proposed approach is compared with a heuristic policy from practice by using real-world data provided by our industry partner.  
 pdf   
  Simulating the Material Delivery Process for an Automotive Body Shop    
 Joseph Hugan (TriMech, LLC)   
  Abstract    Abstract   Increasing product customization and a continual need for higher productivity has led to more complex automotive vehicles being built in more compressed spaces. The material delivery networks supporting these processes have also had to adapt to deliver a wider variety of parts in smaller packaging at an increasing frequency. The author will discuss the development and analysis of an automotive delivery network simulation with a focus on delivery times, the resources required, the data model used to drive the simulation and the analytical techniques used during the project. The presentation will also include a discussion on the model construction, the time required to construct the model, and the challenges encountered in the project.  
 pdf   
  Data-Driven Smart Maintenance Decision Analysis: A Drone Factory Demonstrator Combining Digital Twins and Adapted AHP    
 Paulo Victor Lopes (Aeronautics Institute of Technology) and Siyuan Chen, Juan Pablo González Sánchez Ebru Turanoglu Bekar, Jon Bokrantz, and Anders Skoogh (Chalmers University of Technology)   
  Abstract    Abstract   The concept of Digital Twins has gained significant attention in recent years due to its potential for improving the performance of production systems. One promising area for Digital Twins is Smart Maintenance, enabling the simulation of different strategies without disrupting operations in the real system. This study proposes a high-level framework to integrate Digital Twins to support Smart Maintenance data-driven decision making in production lines. We implement, then, a case study of a lab scale drone factory to demonstrate how the production line performance evaluation is made under different what-if maintenance scenarios. The effects of this Smart Maintenance decision analysis approach were evaluated according to Key Performance Indicators from literature. The identified contributions are: (i) Digital Twin demonstrator focused on smart maintenance; (ii) implementation of smart maintenance data-driven decision analysis concepts; (iii) design and evaluation of what-if maintenance scenarios.  
 pdf   
  Understanding Stakeholder Requirements for Digital Twins in Manufacturing Maintenance    
 Siyuan Chen (Chalmers University of Technology); Paulo Victor Lopes (Aeronautics Institute of Technology Federal University of Sao Paulo); and Juan Pablo González Sánchez, Ebru Turanoglu Bekar, Jon Bokrantz, and Anders Skoogh (Chalmers University of Technology)   
  Abstract    Abstract   Digital twin has emerged as a key technology in the era of smart manufacturing and holds significant potential for maintenance. However gaps remain in understanding stakeholders' requirements and how this technology support maintenance-related decisions. This paper aims to identify stakeholders' requirements for digital twin implementation and examine the role of digital twin in supporting maintenance actions and decision-making process. Semi-structured interviews and a workshop involving manufacturing practitioners and researchers were conducted to attain these goals. Furthermore, an in-depth qualitative analysis of the interview data was carried out. The results shed light on the current state of digital twin adoption, implementation challenges, requirements, supported decisions and actions, and future demand characteristics. By integrating the findings from the literature review and interview analysis, this study outlines the requirements for the digital twins as expressed by industry stakeholders that will be used and tested in the drone factory digital twin model.  
 pdf   
  A Simulation-Based Approach for Line Balancing under Demand Uncertainty in Production Environment    
 S. M. Atikur Rahman and Md Fashiar Rahman (The University of Texas at El Paso), Tamanna Kamal (NC State University), and Tzu-Liang (Bill) Tseng (The University of Texas at El Paso)   
  Abstract    Abstract   The management of production line is a challenging task due to the high level of uncertainty in demand, which can lead to unbalanced utilization of resources. This may result in a potential deterioration of management satisfaction in terms of cost-effectiveness. Therefore, it requires efficient tools to optimize resource utilization. With such inherent needs, this paper presents a simulation-based decision support framework for garments industries. The Discrete Event Simulation (DES) is used to model different scenarios for the operational processes. The procedure focuses on the line balancing technique, which aims to eliminate bottlenecks and optimize the production process by balancing the workload. The results of this study demonstrate the effectiveness of the line balancing technique in improving line efficiency, reducing the idle time of the operators, and increasing productivity. The simulation was developed using AnyLogic simulation software. The outcome of the process is thoroughly evaluated and justified using a case study.  
 pdf   
  Digital Twin Architecture for a Flow Shop Assembly System    
 Gihan Lee and Seunghwan Chang (Ajou University), Onyu Yu and Jungik Yoon (LG Production and Research Institute), and Sangchul Park (Ajou University)   
  Abstract    Abstract   This paper proposes a digital twin architecture for a flow shop assembly line to maximize productivity and reduce quality costs. The proposed digital twin architecture consists of five major modules; Synchronization module to synchronize a real factory and the digital twin Monitoring module to provide intuitive information visualization, Event calendar initialization module to initialize the factory state at any given time to the starting point of the CPS (Cyber-Physical System) simulation, CPS simulation module to identify potential production losses, and Decision-making module to take proactive actions to avoid anticipated production losses. The proposed digital twin architecture has been implemented for a home appliance factory of LG Electronics Co., Ltd. In South Korea, and shows significant improvements in terms of productivity, quality cost, and energy efficiency.  
 pdf   
  Using Kubernetes to Improve Data Farming Capabilities    
 Falk Stefan Pappert, Daniel Seufferth, Heiderose Stein and Oliver Rose (University of the Bundeswehr Munich)   
  Abstract    Abstract   Simulation can reach computational limits especially when running large-scale experiments. One possibility to counter this issue is distributed simulation. Recent developments in containerization and container orchestration technologies, such as Kubernetes, provide a stable and scalable infrastructure, that can serve distributed simulation. Although these solutions exist, applications within the simulation community remain scarce. Thus, in this paper, we present the general setup of such an infrastructure and discuss the application of an example case. Adding to the existing literature, we present our path forward and insights with different versions, as well as the efforts needed to construct similar implementations. As a result, we showcase the speed-up of simulation experimentation. We aim to provide a helpful foundation for others in our community to weigh the effort and benefit of such a system for their own projects.  
 pdf   
  Optimizing Production System Configurations across a Broad Design Space: A Case Study    
 Scott Nill and Larissa Nietner (LineLab, MIT)   
  Abstract    Abstract   This paper presents a case study demonstrating the application of LineLab, a mathematical production system modeling tool, to optimize production system configurations and the ramp-up trajectory for novel mass timber building modules. The modeling tool can efficiently co-optimize a large number of variables, such as machine count, work-in-progress (WIP) count average wait times, and throughput, thus helping to narrow down a broad design space. Sidewalk Labs, a Google company, faced unique challenges related to new product development, high-mix production, and phased ramp-up. This case study highlights the use of this mathematical optimization tool, and its integration with other simulation methodologies, resulting in an optimized digital pipeline for modeling the production scale-up for mass timber buildings. The insights provided contribute to the advancement of production optimization techniques and their applications across various industries.  
 pdf   
  Modeling Risk Prioritization of a Manufacturing Supply Chain using Discrete Event Simulation    
 Arpita Chari and Silvan Marti (Chalmers University of Technology); Paulo Victor Lopes (Aeronautics Institute of Technology (ITA), Chalmers University of Technology); and Björn Johansson, Mélanie Despeisse, and Johan Stahre (Chalmers University of Technology)   
  Abstract    Abstract   Supply chains face a myriad of adverse risks that impact their daily operations and make them vulnerable. In addition, supply chains continue to grow in size and complexity which further sophisticates the problem. Lack of a structured approach and limitations in existing risk management methods contribute towards effective mitigation strategies not being properly developed. In this paper, we develop a discrete event simulation modelling approach to quantify the performance and risk assessment of a manufacturing supply chain in Sweden which is under the impact of risks. This approach could support decision makers by prioritizing risks according to their performance impact and facilitating the development of mitigation strategies to enhance the resilience of the supply chain. The conceptual digital model can also be used to generate synthetic data to build an artificial intelligence-enhanced predictive demonstrator model to showcase capabilities for building data-driven resilience of the supply chain.  
 pdf   
  Digital Twins for Supply Chains: Main Functions Existing Applications, and Research Opportunities    
 Giovanni Lugaresi (KU Leuven); Zied Jemai (CentraleSupelec, Ecole Nationale d'Ingénieurs de Tunis); and Evren Sahin (CentraleSupelec)   
  Abstract    Abstract   In recent times, manufacturing industries and their related supply chains have faced growing internal and external pressures. Due to the complex nature of global supply chain networks and the increased frequency of disruptive events, there is a pressing need to implement digital tools to support these industries. Digital twins have gained significant interest from industry and research communities due to their ability to provide valuable services in the short term. While there have been many contributions on digital twin-based methodologies for system design and production planning and control, the use of digital twins in supply chain management still needs to be improved. This paper presents an overview of the existing contributions on digital twins for supply chains. Starting from a preliminary literature review on the topic, relevant works are selected and used to identify insights on the current development level and future research opportunities.  
 pdf   
  Investigating Production Yield Effect on Inventory Control Through a Hybrid Simulation Approach    
 Marina Materikina, Atefeh Shoomal, Linh Ho Manh, and Yuan Zhou (University of Texas Arlington)   
  Abstract    Abstract   Production Planning and Control (PPC) plays a key role in stabilizing and improving manufacturing processes under external and internal uncertainties by providing transparency in the whole system. This study focuses on PPC with internal uncertainties such as losses of work-in-process products during a contact lens manufacturing process. Although such losses are expected, the yield rates are uncertain and vary at different production stages. A hybrid agent-based simulation (ABS) and discrete-event simulation (DES) approach was utilized to resemble the underlying dynamics of the manufacturing system with uncertain yield rates. The results of the simulation experiments demonstrated that a simple average yield approach for production planning would cause potential backlogs and extra holding costs for the excess inventory. The proposed hybrid simulation could be used to support the decision-making process on a weekly basis to help a production planning team make a schedule that would improve efficiency and customer satisfaction.  
 pdf   
  Stick to the Plan or Adjust Dynamically? Combining Order Release and Overtime Planning for Varying Demand and Process Uncertainty    
 Julian Fodor and Stefan Haeussler (University of Innsbruck)   
  Abstract    Abstract   Within the area of manufacturing planning and control there is a long ongoing debate on when and if decisions should be integrated to a centralized model or split to separate planning levels. While a centralized monolithic model is capable of solving separate decisions simultaneously, a hierarchical approach offers more degrees of freedom since a local planner always has more accurate information. The focus of this paper is on the design and mathematical assumptions of optimization models for overtime and order release decisions in order to cope with different degree of demand and process uncertainty. We execute the optimal decisions within a simulation model of a multi-stage multi-product stylized flow shop. Our results show that a fully centralized is outperformed by a hierarchical design and that planning order release quantities centrally in combination with flexible overtime planning yields the lowest costs for high process uncertainty on the shop floor.  
 pdf   
  An MDP Model-Based Reinforcement Learning Approach for the Nesting Problem: A Case Study in Ship Design    
 SookYoung Son (Seoul National University, HD KSOE); YounHyun Kim and KiSun Kim (HD KSOE); and JongHun Woo (Seoul National University, Research Institute of Marine Systems Engineering)   
  Abstract    Abstract   The nesting problem in the shipbuilding industry calls for an increase in the utilization rates of plates and a decrease in the scrap ratio. To improve the efficiency of part nesting in ship design, this paper proposes an approach that uses a reinforcement learning algorithm to determine an efficient arrangement of parts. We frame the ship nesting problem as a Markov Decision Process (MDP) to apply the Proximal Policy Optimization (PPO) model, a reinforcement learning algorithm. A case study on a real-life nesting design is provided to validate and compare the proposed approach.  
 pdf   
  Integrating Scheduling of Logistic Support Processes in Agent-Based Industry 4.0 Assembly Simulation    
 Adrian Freiter (Fraunhofer Institute for Software and Systems Engineering ISST) and Christian Schwede (University of Applied Sciences and Arts Bielefeld)   
  Abstract    Abstract   The upcoming decentralized production systems seem to be promising in Industry 4.0 assembly to handle the challenges of highly individual products. Matrix production characterized by freely linked workstations and an advanced automation level are highly flexible. That is why many efforts have already been made to explore the advantages compared to existing flow shop production systems, but also the additional challenges arising from this new paradigm. One of these challenges is the synchronization of main product and supply part flow at the individual workstations during order scheduling. This paper presents a new approach of integrating logistics support processes into the scheduling of the main product flow to consider the part supply in the decisions taken during scheduling avoiding waiting times. We compare our integrated approach with the existing decoupled scheduling approach, based on a “bicycle assembly” scenario. The results are promising particularly when part supply is a bottleneck.  
 pdf   
  A Reinforcement Learning Approach for Improved Photolithography Schedules    
 Tao Zhang (Universität der Bundeswehr München), Kamil Erkan Kabak (Izmir University of Economics), Cathal Heavey (University of Limerick), and Oliver Rose (Universität der Bundeswehr München)   
  Abstract    Abstract   A Reinforcement Learning (RL) model is applied for photolithography schedules with direct consideration of reentrant visits. The photolithography process is mainly regarded as a bottleneck process in semiconductor manufacturing, and improving its schedules would result in better performances. Most RL-based research do not consider revisits directly or guarantee convergence. A simplified discrete event simulation model of a fabrication facility is built, and a tabular Q-learning agent is embedded into the model to learn through scheduling. The learning environment considers states and actions consisting of information on reentrant flows. The agent dynamically chooses one rule from a pre-defined rule set to dispatch lots. The set includes the earliest stage first the latest stage first, and 8 more composite rules. Finally, the proposed RL approach is compared with 7 single and 8 hybrid rules. The method presents a validated approach in terms of overall average cycle times.  
 pdf   
  Optimization of Timelinks in Semiconductor Manufacturing    
 Nina Dybowski, Maria Sander, and Ralf Sprenger (Infineon Technologies Dresden GmbH)   
  Abstract    Abstract   Impact of timelinks to semiconductor manufacturing has risen due to shrinking technology sizes. Their operational control defines on the one hand how good the time restrictions are met and on the other the impact to fab capacity. This paper discusses both aspects and the influencing factors like uptime stability, length of the timelink etc. A control approach is proposed, evaluated, and discussed. Furthermore, a monitoring system is introduced that enables for fast decision making and optimization of the control parameters. Finally a simulation study is done for evaluating different parameters and impact of influencing factors.  
 pdf   
  Queue Time Prediction Methodology in Semiconductor Fab    
 Donguk Kim, Byeongseon Lee, and Sangchul Park (Ajou University)   
  Abstract    Abstract   This paper presents a methodology for predicting queue times in semiconductor fabrication, where numerous complex and costly pieces of equipment are utilized. Queue time, occurring between continuous single or multi-processes, is a crucial factor affecting the quality of wafers which can significantly impact costs. While most semiconductor fabrications use queue time limits as a key dispatching factor, some wafers may still be scrapped or reworked. By predicting queue times, we can reduce unnecessary waste by blocking or re-dispatching wafers. Two approximations are proposed and compared based on accuracy and prediction time: a machine learning model trained using experimental results and a multi-resolution simulation model with varying fidelity levels. The simulation model is validated using the SMAT2022 data set.  
 pdf   
  Assessing Delivery Commitments in Supply Chains: A Matrix-Based Framework    
 Madhurima Vangeepuram (Hochschule Neu-Ulm), Hans Ehm and Marco Ratusny (Infineon Technologies AG), Stefan Faußer (Hochschule Neu-Ulm), and Stefan Heilmayer and Tobias Leander Welling (Infineon Technologies AG)   
  Abstract    Abstract   Ensuring reliable and timely customer deliveries is crucial to supply chain management. The ability to meet delivery commitments is essential for maintaining customer satisfaction. Despite the importance of delivery commitments there is a lack of standard measurement techniques for evaluating their quality. Therefore, this paper introduces the term Commitment Quality (CQ) and develops a CQ matrix that can be used to measure the quality of delivery commitments. The CQ matrix provides a comprehensive set of quantitative measures to evaluate different aspects of delivery commitments. Finally, a numerical example based on an order data sample from a semiconductor manufacturer is presented and discussed. The proposed framework aims to standardize the CQ enhancing transparency in delivery commitments.  
 pdf   
  Decentralized Decision-making Framework for Managing Product Rollovers in the Semiconductor Manufacturing    
 Carlos Leca (North Carolina State University), Karl Kempf (Intel Corporation), and Reha Uzsoy (North Carolina State University)   
  Abstract    Abstract   Competitiveness in the semiconductor industry requires continuous management of product rollovers, the process of introducing new products and retiring older ones to maintain market share. This paper presents a decentralized decision-making framework to coordinate product rollover decisions using Lagrangian decomposition of a centralized model using quadratic coordination errors in the subproblem objectives, and a decentralized heuristic that recovers the feasible solutions from the relaxed ones obtained from the Lagrangian procedure. Experimental results show that this decentralized framework delivers promising results, obtaining near-optimal solutions in modest CPU times.  
 pdf   
  Data-driven Production Planning Formulations with Inventory Considerations    
 Tobias Voelker and Lars Moench (University of Hagen)   
  Abstract    Abstract   Data-driven (DD) production planning formulations for semiconductor wafer fabrication facilities (wafer fabs) are studied in this paper. These formulations are based on a set of system states representing the congestion behavior of the wafer fab with work in process and resulting output levels. We establish two DD formulations with inventory considerations. The first variant is a shortfall-based chance-constrained formulation that considers safety stocks at the finished goods inventory level. The second variant is a simple scenario-based stochastic program where the objective function reflects the expected inventory holding and backlog cost under uncertainty. The two variants are compared with the conventional DD formulation in a rolling horizon environment using a simulation model of a large-scaled wafer fab. The simulation experiments demonstrate that the stochastic program achieves the largest profit under all experimental conditions.  
 pdf   
  Component Redesigns and the Impact of their Implementation Policy    
 Best Contributed Applied Paper - Finalist    
 Steffi Neefs and Douniel Lamghari-Idrissi (ASML Netherlands B.V., Eindhoven University of Technology) and Rob Basten and Geert-Jan van Houtum (Eindhoven University of Technology)   
  Abstract    Abstract   An OEM who maintains a fleet of complex systems strives for high system availability for its customers. Frequently failing components lead to system unavailability and high maintenance costs. Consequently, the OEM might decide to upgrade components. We develop a model that quantifies the impact of the introduction of an upgraded component on the OEM's costs and number of failures to define the best implementation strategy. Using a Markov process, we evaluate four policies differing in the roll-out strategy of new parts, either immediate or corrective and the phase-out strategy of old parts, either rework or salvage. The model is used in a case study at ASML. We conclude that, in the case study, reworking is preferred over salvaging as the phase-out strategy and corrective replacements are generally preferred over immediate replacements for the roll-out strategy.  
  Digital Twin for Design and Analysis of Cluster Tool in Wafer Fabrication    
 Joonick Hwang and Sang Do Noh (Sungkyunkwan University)   
  Abstract    Abstract   In the semiconductor industry, many retrofits are being made to improve the production efficiency of manufacturing facilities. However due to the nature of the data provided by the cluster tool, which is a semiconductor manufacturing facility, engineers have some limitations in utilizing it. To address this issue, it is necessary to introduce a digital twin model that can verify the performance of the semiconductor process cluster tool in a virtual environment, and to apply optimal mass production conditions based on this predictive data in the operational stage. In this study, we propose a digital twin model that visualize congestion factors during wafer transfer and evaluate the productivity of cluster tools.  
 pdf   
  Backward Simulation: A Customer-Focused Diversification of Fab Simulation Applications in a Highly Automated Semiconductor Production Line    
 Wolfgang Scholl and Patrick Preuß (Infineon Technologies Dresden GmbH) and Christoph Laroque and Madlene Leissau (University of Applied Sciences Zwickau)   
  Abstract    Abstract   In modern manufacturing environments, the digital transformation to smart factories cannot be achieved without data-driven methods like discrete, event-driven simulation. This paper provides an overview of existing current simulation applications at Infineon Dresden in this area, especially on short-term simulation for production control and long-term simulations to forecast process flows in the wafer fabrication facilities. Furthermore, it illustrates the current status of research activities in the area of backward simulation for operational decision support for order scheduling by some latest research results.  
 pdf   
  Reusable Ontology Generation and Matching from Simulation Models    
 Ming-Yu Tu, Hans Ehm, Abdelgafar Ismail, and Philipp Ulrich (Infineon Technologies AG)   
  Abstract    Abstract   As simulating semiconductor manufacturing grows complex, model reuse becomes appealing since it can reduce the time incurred in developing future models. Also, considering a large network of the semiconductor supply chain, knowledge sharing can enable the efficient development of simulation models in a collaborative organization. Such necessity of reusability and interoperability of simulation models motivates this paper. We will address these challenges through ontological modeling and linking of the simulation components. The first application is generating reusable ontologies from simulation models. Another discussed application is ontology matching for knowledge sharing between simulation components and a meta-model of the semiconductor supply chain. The proposed approach succeeds in automatically transforming simulation into reusable knowledge and identifying interconnection in a semiconductor manufacturing system.  
 pdf   
  Simulation, Optimization and AI for Semiconductor Manufacturing and Supply Chains: Four Decades of Progress and a Vision for the Future    
 Hans Ehm (Infineon Technologies AG)   
  Abstract    Abstract   Semiconductor manufacturing and supply chain processes are one of the most complex but can be considered at the same time also as one of the most rewarding processes in the world. In thousands of detailed unit chemical and physical processes in cleanrooms and under statistical process control chips on wafers emerge and are assembled and tested to components. The Modeling and Analysis of Semiconductor Manufacturing (MASM) conference embedded in the annual Winter Simulation Conference (WSC) was, is, and will be key to understand the optimization and simulation challenges in this domain.  
  The operating curve management targeting a low variability value and thus enabling a low flow factor - thus speed - and high utilization - thus a good cost position - at the same time has been an early achievement. With discrete-event, agent based, and system dynamic simulations on the four levels (machine fab, internal and external supply chain) solution options for complex interactions could be proposed based on sophisticated mathematical models running on simulation testbeds like the MIMAC models and their successors. Accurate planning and advanced scheduling, available to promise (ATP) generation and usage with traditional or artificial intelligence (AI) / deep learning (DL) methods requires a huge amount of real data or qualified synthetic data (QSD).  
  Modeling Multivariate Relations in Multiblock Semiconductor Manufacturing Data Using Process PLS to Enhance Process Understanding    
 Geert van Kollenburg and Richard Verhoeven (Eindhoven University of Technology), Daniele Pagano (STMicroelectronics s.r.l.), and Mike Holenderski and Nirvana Meratnia (Eindhoven University of Technology)   
  Abstract    Abstract   The complexity of manufacturing process data has made it more challenging to extract useful insights. Data-analytic solutions have therefore become essential for analyzing and optimizing manufacturing processes. Path modeling, also known as structural equation modeling, is a statistical approach that can provide new insights into complex multivariate relationships between process variables from different stages of the manufacturing process. The incorporation of expert process knowledge and subsequent interpretation of model results can facilitate communication between stakeholders, promoting lean manufacturing and achieving the sustainability goals of Industry 5.0. This paper describes the use of a path modeling algorithm called Process Partial Least Squares (Process PLS) to gain new insights into the relationships between equipment data from several machines within the semiconductor manufacturing process. The methods used in this study can assist manufacturers in understanding the relations between different machines and identify the most influential variables that may be used to develop soft-sensors.  
 pdf   
  Multi-Resolution Modeling Method for Automated Material Handling System Systems in Semiconductor FABs    
 Kwanwoo Lee, Woosung Jeon, and Sangchul Park (Ajou University)   
  Abstract    Abstract   This paper presents a novel modeling framework for semiconductor fabrication facilities (FABs) that integrates production and material handling systems. Because the productivity of semiconductor FABs is significantly influenced by their material-handling systems, existing research has focused on optimizing operational logic considering both aspects. However, the scale and complexity of modern FABs make implementation of fully integrated models challenging, resulting in slow simulation speeds for long periods. To address this issue, we propose a multi-resolution modeling framework that creates material-handling system models at two distinct resolution levels, enabling fast fully integrated FAB models while accounting for material-handling effects. Experimental results demonstrated accelerated simulation completion compared to single-resolution models while maintaining consistent results. The proposed method provides a practical approach for semiconductor FABs to investigate long-term phenomena and urgent decision-making problems while considering both production and material-handling systems.  
 pdf   
  Scaling Deep Reinforcement Learning for Queue-time Management in Semiconductor Manufacturing    
 Harel Yedidsion, Prafulla Dawadi, David Norman, and Emrah Zarifoglu (Applied Materials)   
  Abstract    Abstract   Queue-Time Constraints (QTCs) set a maximum waiting time for lots between consecutive process steps. In semiconductor manufacturing exceeding these limits results in yield loss rework, or scrapping. Managing QTCs is challenging due to the need for lots to wait until there is available capacity for the final step. Specifically, accurately calculating the capacity is computationally expensive, making it difficult to handle large instances. Our research addresses the scalability of QTC management in real fabs with numerous constraints. We propose a deep Reinforcement Learning (RL) solution to handle lot release into the QTC. We describe the infrastructure developed for RL training using actual fab data assess the performance of our RL approach, and compare it to three baseline solutions. Our empirical evaluation demonstrates that the RL method surpasses the baselines in key performance metrics including queue-time violations, while requiring negligible online compute time.  
 pdf   
  Incorporation of Military Doctrines and Objectives into an AI Agent via Natural Language and Reward in Reinforcement Learning    
 Michael Möbius, Daniel Kallfass, and Matthias Flock (Airbus Defence and Space GmbH) and Thomas Doll and Dietmar Kunde (German Armed Forces)   
  Abstract    Abstract   This paper emphasizes the integration of sound tactical behavior in the generation of realistic military simulations, which includes the definition of combat tactics, doctrine, rules of engagement, and concepts of operations. Recent advances in reinforcement learning (RL) enable RL agents to generate a wide range of tactical actions. A multi-agent ground combat scenario is used in this paper to demonstrate how a machine learning (ML) application generates strategies and issues commands while following a given objective. Natural language is used to issue doctrines and objectives to improve communication between the human advisor and the ML agent. This allows us to embed objectives and existing doctrines into the reasoning of an artificial intelligence (AI). The research demonstrates the successful integration of natural language to enable an agent to achieve different objectives. This groundwork will enhance RL agents' ability in the future to uphold the doctrines and rules of military operations.  
 pdf   
  Open-Air Artillery Strike in a Rural Area: A Hypothetical Scenario    
 Mehdi Benhassine (Royal Military Academy); Ruben De Rouck, Michel Debacker, and Ives Hubloue (Vrije Universiteit Brussel); Erwin Dhondt (DO Consultancy); John Quinn (Charles University); and Filip Van Utterbeeck (Royal Military Academy)   
  Abstract    Abstract   The escalation of the Russian invasion in Ukraine, characterized by the deployment of conventional weapon systems, inflicts significant morbidity and mortality on the victims. It is imperative to ascertain optimal medical practices and disaster response strategies throughout the battlefield to minimize casualties and safeguard the well-being of medical and disaster responders. The challenges posed by large-scale battlefield threats can rapidly overwhelm healthcare providers due to the sheer number of victims which can result in the depletion of medical supplies and insufficient training and resources. To address these issues, we utilized the SIMEDIS simulator to establish and implement a battlefield scenario involving an open-air artillery strike in a field. Mortality rates were calculated based on the application of bleeding control measures and the distribution policy for allocating victims to medical treatment facilities. Controlling hemorrhage remains the most crucial factor influencing mortality outcomes.  
 pdf   
  A Modular Simulation Model for Mass Casualty Incidents    
 Kai Meisner (Bundeswehr Medical Academy, University of the Bundeswehr Munich) and Heiderose Stein, Nadiia Leopold, Tobias Uhlig, and Oliver Rose (University of the Bundeswehr Munich)   
  Abstract    Abstract   During military conflicts, the number of casualties is likely to exceed medical capabilities. For best treatment results, the patients must be distributed according to their needs to the available resources such as medical facilities and means of transportation. Computer simulations are used to verify and optimize current medical planning. However, recent models lack the capability of testing a wide range of decision rules. In this paper, we address this issue and propose a modular simulation concept whose components can be adapted and exchanged independently. Using modular submodels to control the simulated objects, we enable the implementation of a wide range of object behavior. A prototype implementation of the proposed concept is presented, showing the effects of applying different dispatching rules in an evacuation scenario.  
 pdf   
  Simulation-Based Optimization of Air Force Mission Planning    
 Best Contributed Applied Paper - Finalist    
 Mihaela Lechner and Alexander Roman (University of the Bundeswehr Munich), Thomas Mayer (ESG Elektroniksystem- und Logistik-GmbH), and Tobias Uhlig and Oliver Rose (University of the Bundeswehr Munich)   
  Abstract    Abstract   Military planning operations deal with highly dynamic environments and a variety of complex optimization challenges. In order to support decision-makers in this process, innovative concepts are required that can automatically generate applicable solutions for certain aspects of mission planning. Such instruments can simplify the planning process, reduce risks and lower operating costs. This paper presents a simulation-based optimization framework that addresses three problems in the context of aerial warfare planning: task assignment scheduling, and route planning. These problems are tackled with interconnected heuristics based on either greedy approaches or genetic algorithms. Additionally, hierarchical task networks are employed to incorporate domain knowledge in form of tactical doctrines into the solution. Our simulation results confirm the viability of the proposed approach for small to medium-sized scenarios. However, further investigation with regard to the evaluation function and the simulation environment is required.  
 pdf   
  Discrete Event Simulation of Aircraft Sortie Generation on an Aircraft Carrier    
 Hee Chang Yoon and Seung Heon Oh (Seoul National University); Jung-Hoon Chung, Hyuk Lee, and Sun-Ah Jung (Korea Institute of Machinery & Materials); and Jong Hun Woo (Seoul National University)   
  Abstract    Abstract   The Sortie Generation Rate (SGR) which refers to the number of sorties that can be generated per unit time, is a key indicator for evaluating the ability of an airbase. However, an aircraft carrier has many constraints compared to a land-based airbase, such as spatial and environmental constraints, making it difficult to apply existing land-based research to analyze aircraft carrier operations. On the other hand the Sortie Generation Process (SGP) on an aircraft carrier is similar to a logistics/production system in that sorties are generated through aircraft. Therefore, this study proposes a framework for analyzing the SGP on an aircraft carrier using discrete event simulation and defines the classes that make up the simulation. In addition, SGP analysis simulations were implemented using the proposed framework and several experiments were performed to demonstrate the feasibility of applying the proposed framework in practice.  
 pdf   
  The Holistic Prioritized SATCOM Throughput Requirements (HPSTR) Stochastic Model    
 Matthew Wesloh, Noelle Douglas, Brianne White, and Nicholas Shallcross (United States Army, The Research and Analysis Center)   
  Abstract    Abstract   The U.S. Army's command and control modernization efforts rely upon an expeditionary, mobile, hardened, and resilient network. Dispersed network access and data availability are central to increasing the operational speed required for effective command and control. The Army must define its satellite communication (SATCOM) requirements to support network modernization. This paper proposes the Holistic Prioritized SATCOM Throughput Requirements (HPSTR) simulation that prioritizes and adjudicates SATCOM throughput requirements for operational military units. Additionally the simulation evaluates the impact of a contested, degraded, and operationally limited (CDO) communication environment on force effectiveness. HPSTR addresses knowledge gaps concerning U.S. Army SATCOM activities in a large-scale combat operation (LSCO) to inform modernization decisions.  
 pdf   
  Evolving LVC to Include Evaluation of Human-AI Teaming Dynamics    
 Margaret Loper and Valerie Sitterle (GTRI)   
  Abstract    Abstract   There are significant differences between using systems as human-controlled tools to accomplish a specific task and using systems designed to “cooperate and partner” with humans to achieve capabilities beyond either side acting alone. The live, virtual, constructive (LVC) paradigm increasingly emphasized by the DoD has wide acceptance and is congruent with how the military thinks about training evaluation, and mission rehearsal. Consequently it may help address these challenges. This paper aims to overview the current LVC construct challenges associated with human-AI teaming and intentional design of these dynamics to achieve new capabilities, and the resulting need to evolve the LVC construct to improve our pursuit of understanding and evaluation that leads to effective fielding.  
 pdf   
  A Low-Code Approach for Simulation-based Analysis of Process Collaborations    
 Paolo Bocciarelli and Andrea D'Ambrogio (University of Rome Tor Vergata)   
  Abstract    Abstract   The simulation-based analysis of process collaborations introduces significant challenges, such as the ability to focus on the interchange of information and data without disclosing any internal details of collaboration participants' processes. The use of distributed simulation (DS) provides good opportunities to face these challenges. However, properly using DS standards and technologies requires significant technical know-how and effort. This paper introduces a largely automated approach to carry out distributed simulations of process collaborations. The DS standard addressed by the paper is the High Level Architecture (HLA), which is used to analyze process collaborations specified by using the Business Process Model and Notation (BPMN). The degree of automation is obtained by using a low-code development paradigm based on automated model transformations that reduce the amount of manual effort required to code the HLA-based simulation. An example application is also discussed to underline the pros and cons of the proposed approach.  
 pdf   
  Incremental Transformation of BPSIM-enriched BPMN Models into DEVS    
 Mariane El Kassis, Francois Trousset, Gregory Zacharewicz, and Nicolas Daclin (IMT Mines Alès)   
  Abstract    Abstract   In this paper, we introduce a novel methodology for business process simulation, focusing on the incremental transformation of Business Process Modeling and Notation (BPMN) models enriched with Business Process Simulation Interchange Standard (BPSIM) elements into the Discrete Event System Specification (DEVS) formalism. The proposed method enhances the precision and consistency of simulations by systematically converting BPMN components and BPSIM characteristics into DEVS representations, using adaptable rules and templates. A major contribution of this work is the introduction of the Interaction Intermediate Model (I2M), a model that provides a visually lucid representation with significant semantics effectively encapsulating BPMN and BPSIM simulation aspects. The resulting DEVS model ensures accurate, reliable, and interoperable simulations. We provide a thorough analysis of this methodology, emphasize its advantages, and validate its efficiency through a case study. This method, applicable across various sectors effectively bridging the gap between conceptual modeling and simulation methodologies.  
 pdf   
  An Approach Towards Predicting the Computational Runtime Reduction from Discrete-event Simulation Model Simplification Operations    
 Mohd Shoaib (Indian Institute of Technology Delhi), Navonil Mustafee (University of Exeter), and Varun Ramamohan (Indian Institute of Technology Delhi)   
  Abstract    Abstract   Model simplification is the process of developing a simplified version of an existing discrete-event simulation (DES) to study the performance of specific system subcomponents relevant to the analysis. The simplified model is referred to as a 'metasimulation'. A widely used model simplification operation is abstraction, which involves replacing the subcomponents, not core to the analysis, from the parent DES model with random variables representing the lengths of stay in said subcomponents. However, the one-time computational cost of developing metasimulations via abstraction can itself be considerable, as the approach necessitates executing the parent model for generating the necessary data for developing the metasimulation. Thus, this study proposes a queuing-theoretic approach for estimating the computational runtime reduction (CRR) achieved through abstraction, wherein the prediction of CRR precedes the development of the metasimulation. Towards this, we present preliminary results from applying this approach for simplification of DES models made up of M/M/n workstations.  
 pdf   
 Technical Session  ·  Modeling Methodology   
  Panel: Forty Years of Event Graphs in Research and Education   
 Chair: Gerd Wagner (Brandenburg University of Technology)  
  Forty Years of Event Graphs in Research and Education    
 Murat M. Gunal (Fenerbahce University); Yahya Ismail Osais (King Fahd University of Petroleum and Minerals Interdisc. Research Center for Intellig. Secure Systems); Lee Schruben (University of California Berkeley); Gerd Wagner (Brandenburg University of Technology); and Enver Yücesan (INSEAD)   
  CLAVS/ODVS: Combining Class/Object Diagrams and DEVS    
 Jordan Parezys and Randy Paredis (University of Antwerp) and Hans Vangheluwe (University of Antwerp, Flanders Make)   
  Abstract    Abstract   The Discrete Event System Specification (DEVS) formalism is a modular discrete-event modeling formalism. It has a formal specification in terms of systems theory and is supported by several efficient and usable simulator implementations. In these implementations, the DEVS formalism is often “grafted” onto an existing Object-Oriented programming language. Examples are C++ in the case of ADEVS and Python in the case of PythonPDEVS. To match this grafting, we present CLAVS, the CLAss diagram and deVS formalism and its instance counterpart ODVS, the Object Diagram and deVS formalism, and their visual notations. These languages use an automaton-like visual notation for Atomic DEVS models and a Class Diagram notation augmented with port information and event structure specification. An implementation of a visual CLAVS/ODVS modeling environment built on draw.io is presented. The use and usefulness of the formalism is demonstrated by means of a simple traffic model whose detailed specification is presented.  
 pdf   
  Project Simulation, Validation and Deployment with DEVS: IoT Framework for Blooms Monitoring and Alert    
 Segundo Esteban, Giordy A. Andrade, José L. Risco-Martín, Jesús Chacón, and Eva Besada-Portas (Complutense University of Madrid)   
  Abstract    Abstract   Harmful Algal and Cyanobacterial Blooms (HABs) constitute a relevant public health and ecological hazard due to their frequent production of toxic metabolites, which is increased by the current vulnerability of water resources to environmental changes such as global warming, population growth, and eutrophication. These blooms have been typically assessed by combining predictive models with manual collection. However, these processes are generally independent and do not provide data with sufficient resolution to apply proactive policies. In this work, we propose a novel and integrative framework to straightforwardly combine the conception, design, and deployment of advanced Early-Warning Systems (EWSs) that will allow us to automate all the processes involved in HABs detection and management and apply proactive policies. The framework is built upon solid Modeling and Simulation (M&S) principles, through Model Based Systems Engineering (MBSE) as the driving methodology and Discrete Event System Specification (DEVS) as the M&S formalism.  
 pdf   
  Automated Simulation and Virtual Reality Coupling for Interactive Digital Twins    
 Kai Franke, Jan Marius Stürmer, and Tobias Koch (German Aerospace Center (DLR), Institute for the Protection of Terrestrial Infrastructures)   
  Abstract    Abstract   While there are many efforts to simulate technical systems in virtual environments and provide a visual interaction for applications such as training, authoring and analysis, the process of generating applications still requires a lot of manual work. This is particularly critical in the context of interactive Digital Twins for resilience, where uncertain events can occur and every malfunction or mistreatment of any part of the system needs to be modeled. This paper presents an approach to model such systems in a modular way by automating the generation of its components for a game engine and simulators based on a common specification. Component instances are then synchronized bidirectionally across applications to achieve interaction between the game engine and simulators. An example hydraulic system is implemented and tested to demonstrate our approach, which needs minimal manual work by using predefined components. The solution can be extended by integrating more components and simulations.  
 pdf   
  Transforming Discrete Event Models to Machine Learning Models    
 Hessam S. Sarjoughian, Forouzan Fallah, and Seyyedamirhossein Saeidi (Arizona State University) and Edward J. Yellig (Intel Corporation)   
  Abstract    Abstract   Discrete event simulation, formalized as deductive modeling, has been shown to be effective for studying dynamical systems. Development of models, however, is challenging when numerous interacting components are involved and should operate under different conditions. Machine Learning (ML) holds the promise to help reduce the effort needed to develop models. Toward this goal, a collection of ML algorithms, including Automatic Relevance Determination are used. Parallel Discrete Event System Specification (PDEVS) models are developed for Single-stage and Two-stage cascade factories. Each model is simulated under different demand profiles. The simulated data sets are partitioned into subsets, each for one or more model components. The ML algorithms are applied to the data sets for generating models. The throughputs predicted by the ML models closely match those in the PDEVS simulated data. This study contributes to modeling by demonstrating the potential benefits and complications of utilizing ML for discrete-event systems.  
 pdf   
  Simulation Modeling for Sustainable Construction: A Case Study to Highlight the Social Aspect    
 Mai Ghazal, Fatemeh Parvaneh, Ahmed Hammad, and Yasser Mohamed (University of Alberta)   
  Abstract    Abstract   To cut costs and drive innovation in product development, many projects have turned to remote worksites for construction component pre-fabrication. Fabricating pipe spools in shops eliminates delays due to weather and allows for better resource planning. This paper aims to optimize labor resource usage in a pipe spool manufacturing plant that fabricates three different types of spools. It utilizes historical data to implement a discrete-event simulation model. The proposed simulation model effectively reduced idle time and evenly distributed the workload. As a result, the overall fabrication time for all three spools was reduced, leading to a 22% decrease in active shop usage. This allowed subsequent jobs to commence earlier, giving the team more flexibility in meeting deadlines and addressing labor constraints. This research provides insights into how resource allocation plans can be created to maximize sustainability results both socially (through improving working conditions and reducing workloads) and economically.  
 pdf   
  The Impact of Alcohol Use on Construction Safety Outcomes: An Agent-Based Modeling Investigation    
 Christin Manning and Ehsan Salari (Wichita State University)   
  Abstract    Abstract   Construction is a notoriously hazardous industry and heavy alcohol use is common. This project creates an agent-based modeling (ABM) simulation exploring the impact of alcohol on safety outcomes. Simulation modeling is useful in occupational safety research because it generates immediate results and bypasses ethical concerns. Workers and foremen interact on a virtual jobsite with hazards present. Positive blood alcohol concentration (BAC) decreases hazard awareness and reaction time, and additionally decreases competency of foremen. Scenarios of baseline, increased, and decreased alcohol consumption are analyzed for changes in near misses, injuries, and fatalities. Additional scenarios of improved training and engineering controls are explored also for comparison. A decrease in alcohol consumption led to a significant reduction in injuries by up to 12%, and an increase had the opposite effect. Neither scenario significantly impacted fatalities due to fatalities' low base rate. Safety training had a comparable impact but improving engineering controls outweighed both.  
 pdf   
  Applying Civil Information Modeling and Augmented Reality to the Construction of Underground Pipelines    
 Andy Cui (Montgomery Blair High School) and Man Liang (University of Maryland)   
  Abstract    Abstract   Municipal construction projects are often challenging and risk-prone due to unexpected underground conditions. Access to As-Built and As-Design data is essential to avoid budget overruns, schedule delays, and other construction disputes. However, coordinating field conditions with construction drawings can be difficult and lead to discrepancies. Traditional methods of denoting information onto the ground by surveyors and field workers have been limited in their ability to provide relevant information and support scaling up. These methods also create restrictions in data sharing and communication among workers and engineering teams. With the development and use of AR technology, our study proposes an augmented reality tool leveraging Google ARCore to assist construction engineers in a straightforward and efficient manner by displaying utility information, including pipe direction, type, slope, diameter, and material. The campus area of the University of Maryland College Park is used as a case study to demonstrate our approach.  
 pdf   
  A Value Stream Mapping-Based Discrete Event Simulation Template for Lean Off-Site Construction Activities    
 Prashanth Kumar Sreram (Indian Institute of Technology Bombay, NICMAR Hyderabad) and Albert Thomas (Indian Institute of Technology Bombay)   
  Abstract    Abstract   Lean construction is a promising approach for performance improvement in the construction industry. Value stream mapping (VSM) is an essential lean tool for the process improvement of construction activities. However, VSM regarded as a static pen-and-paper technique requires repeating the VSM preparation for every improvement alternative. Therefore, dynamism can be introduced into VSM by developing computer simulation models, which is the study's objective. A VSM-based discrete event simulation (DES) template is presented in this paper for off-site construction activities. The model provides a virtual testing environment for the user to decide upon the potential time reduction in non-value-added (NVA) activities for the process improvement. The development and validation of the model is done based on the actual data from a precast production factory. The DES-VSM simulation model assists plant managers with the best possible NVA reduction strategy and accelerates lean implementation in the construction industry.  
 pdf   
  Simulation of Earthmoving for a Dam Using Engineering Calculations    
 Photios G. Ioannou (University of Michigan)   
  Abstract    Abstract   Detailed STROBOSCOPE simulations of earthmoving for the construction of a dam use the engineering calculations typically employed in heavy construction to estimate equipment performance based on the characteristics of the haul and return roads and the mechanical properties of actual models of heavy loaders and trucks. Sensitivity analysis investigates the total cost of truck combinations while considering the traffic effects of one or two bridges needed to cross a river along the haul route. This example can serve as a simulation model template to facilitate the wider acceptance of simulation in heavy construction practice.  
 pdf   
  A Discrete-Event Simulation to Explore Disaggregation of Biotechnology Research and Development Workflows    
 Susan S.M. Hanson, Noah Mecikalski, Alex Tobias, Jack Morris, Neal Wagner, and Rebecca S. Widrick (MITRE Corporation) and Damon Bayer (University of California Irvine)   
  Abstract    Abstract   Research and development (R&D) of biotechnology products is an iterative process typically characterized by a monolithic workflow in which a single organization takes a project from start to finish through many complex operations. This paper presents a discrete-event simulation methodology to explore an alternative disaggregated workflow in which R&D is managed by a single organization but individual operations are distributed among multiple organizations. This methodology is applied to a protein engineering R&D process to compare the monolithic and disaggregated workflows over a range of conditions and scenarios. Based upon a set of assumed parameters, results identify conditions favorable to either workflow and provide a first indication that the industry’s trend towards disaggregation may lead to improvements in development timelines. The methodology also provides a foundation for decision support tools that enable decision-makers to manage biotechnology R&D projects.  
 pdf   
  Development of a Discrete Event Simulation Based Framework to Evaluate Six Sigma Implementation in the Construction Sector    
 Srinivas Rao Jalam (Indian Institute of Technology Bombay ,Mumbai); Vaishnavi Thumuganti (Stanford University); and Albert Thomas (Indian Institute of Technology Bombay ,Mumbai)   
  Abstract    Abstract   Six Sigma is a useful technique adopted in the construction industry to attain supreme quality levels by reducing the variability in the processes. However, rigorous field implementation of a Six Sigma methodology takes time, money, resources, and stakeholder commitment. This study develops a simulation-based framework that can mimic a Six Sigma implementation effort in a construction site using a discrete event simulation technique. Such a framework helps the decision makers to check the benefits of Six Sigma by assessing what-if scenarios for possible system improvement, even before expending the time and resources needed for field implementation of Six Sigma techniques. Therefore, through a combination of discrete event simulation and Six Sigma, the variations in a process at a construction project are eliminated. The results of this study can inspire construction managers to use simulation to understand Six Sigma implementation and improve the process or system to fulfill customer needs.  
 pdf   
  Simulating Justice: Simulation of Stochastic Models for Community Bail Funds    
 Sophia Gunluk (Mila) and Yidan Zhang and Jamol Pender (Cornell University)   
  Abstract    Abstract   Bail funds have a long history of helping those who cannot afford bail in order to wait for trial at home. They have also had a large impact on the verdict of the defendant. In this paper we present the first stochastic model for capturing the dynamics of a community bail fund. Our bail fund model integrates traditional queueing models with classic insurance/risk models to represent the bail fund’s intricate dynamics. We employ simulation techniques to assess Gaussian-based approximations that estimate the probability of a defendant being denied access to the bail fund when it lacks the adequate funds to support them. Additionally, we propose a new simulation-based algorithm that leverages a deterministic infusion of capital as a control variable to stabilize the probability that defendants have access to the bail fund. Our simulation results reveal that our Gaussian-based approximations are suitable for moderately and highly active bail funds.  
 pdf   
  Sensor Fusion DEVS for Angle Estimation on Inertial Measurement Unit    
 Gabriel Wainer, Joseph Boi-Ukeme, and Vedant Paranjape (Carleton University)   
  Abstract    Abstract   We explore the application of a Sensor Fusion Framework, called SAFE (Simple, Applicable Extensible, and Flexible) to improve the reliability of measurements obtained from Inertial Measurement Unit (IMU) sensors. SAFE is built using a DEVS specification and the Cadmium tool. Measuring angular position is a difficult task due to the unreliability of gyroscopes and accelerometers, two sensors widely used to measure angles. Although angular position can be measured using imaging systems, these are costly, and not ideal for handheld and portable devices. An alternative solution is to use sensor fusion to fuse the readings of both accelerometer and gyroscope, obtaining reliable readings. We show the application of the SAFE methodology and the results of our case study showing the potential of this method.  
 pdf   
  A Virtual Testbed for the Development and Verification of Cyber-Physical Systems    
 Jan Reitz, David Böken, and Jürgen Roßmann (RWTH Aachen University)   
  Abstract    Abstract   This paper presents a virtual testbed for the development and verification of cyber-physical systems, integrating network simulation physics, and hardware emulation within the multi-domain simulation framework VEROSIM. The testbed facilitates comprehensive software-in-the-loop testing, enabling accurate and reliable evaluation of control algorithms in complex, interconnected systems. The integrated approach simplifies simulation setup and model management, while allowing natural treatment of mobility and the use of sophisticated physical radio wave propagation models. The testbed also enables the simulation of various fault scenarios, supporting the assessment of system resilience and fault-tolerant strategies. A case study involving a capsule approaching the International Space Station demonstrates the effectiveness of the proposed testbed in capturing the interactions between software hardware, and physical elements, and verifying the overall behavior of a cyber-physical system under adverse conditions.  
 pdf   
  A Framework for Validating Data-Driven Discrete-Event Simulation Models of Cyber-Physical Production Systems    
 Jonas Friederich (University of Southern Denmark) and Sanja Lazarova-Molnar (Karlsruhe Institute of Technology)   
  Abstract    Abstract   In recent years, there has been a significant increase in the deployment of Cyber-physical Production Systems (CPPS) across various industries. CPPS consist of interconnected devices and systems that combine physical and digital elements to enhance the efficiency productivity, and reliability of manufacturing processes. Due to the continuous and fast-paced evolution of the behavior of CPPS, there is an increasing interest in generating data-driven Discrete-event Simulation (DES) models of such systems. The validation of these models however, remains a challenge, and traditional approaches may be insufficient to ensure their accuracy. To address this challenge, we propose a framework for validating data-driven DES models of CPPS. We emphasize the importance of continuously monitoring the validity of data-driven DES models and updating them when necessary to ensure their accuracy over time. We, furthermore, demonstrate our proposed approach through a case study in reliability assessment and discuss challenges and limitations of our framework.  
 pdf   
 pdf   
  A Facilitated Discrete Event Simulation Framework to Support Online Studies: An Intervention in a Small Enterprise    
 Milena Silva Oliveira, Carlos Henrique Santos, Gustavo Teodoro Gabriel, Fabiano Leal, and José Arnaldo Barra Montevechi (Federal University of Itajuba)   
  Abstract    Abstract   Considering some challenges that prevent the expansion of discrete event simulation studies such as financial constraints to invest in the data collection of large samples and to hire qualified people for data analysis and for developing complex models, this paper aims to propose a framework to support simulation studies where it is not widely used, adopting facilitated modeling. Since the facilitated DES frameworks in the literature focus on healthcare and face-to-face meetings, the present work offers a framework for simulation projects in production systems, which also supports online interventions. After its development, the FaMoSim (Facilitated Modeling Simulation) framework was applied in a real case to evaluate its applicability. In the application, it was possible to carry out a faster and more flexible online modeling process, create a simple computer model that does not require a complex data collection structure nor a specialist team and assist the stakeholders in identifying improvements.  
 pdf   
  GPT-Based Models Meet Simulation: How to Efficiently Use Large-Scale Pre-Trained Language Models Across Simulation Tasks    
 Philippe J. Giabbanelli (Miami University)   
  Abstract    Abstract   The disruptive technology provided by large-scale pre-trained language models (LLMs) such as ChatGPT or GPT-4 has received significant attention in several application domains, often with an emphasis on high-level opportunities and concerns. This paper is the first examination regarding the use of LLMs for scientific simulations. We focus on four modeling and simulation tasks, each time assessing the expected benefits and limitations of LLMs while providing practical guidance for modelers regarding the steps involved. The first task is devoted to explaining the structure of a conceptual model to promote the engagement of participants in the modeling process. The second task focuses on summarizing simulation outputs so that model users can identify a preferred scenario. The third task seeks to broaden accessibility to simulation platforms by conveying the insights of simulation visualizations via text. Finally, the last task evokes the possibility of explaining simulation errors and providing guidance to resolve them.  
 pdf   
  The Cloud-Based Implementation and Standardisation of Anthropomorphic Phantoms and their Applications    
 Osiris Núñez-Chongo and Manuel Carretero (Universidad Carlos III de Madrid); Rafael Mayo-García (Centro de Investigaciones Energéticas, Medioambientales y Tecnológicas (CIEMAT)); and Hernán Asorey (Comisión Nacional de Energía Atómica, Centro Atómico Bariloche)   
  Abstract    Abstract   Radiation protection applications often require the creation of a large number of precise simulations of radiation-human body interactions. Our research is focused on creating RadPhantom, a new Geant4 application that constructs voxelized anthropomorphic phantom models. This allows for the standardized and reproducible generation of Geant4 simulations in cloud-based environments. We have incorporated existing and publicly accessible models into Meiga, a framework designed for the integration of Geant4-based applications. To standardize these simulations, guarantee their reproducibility, and adhere to the FAIR principles, we have developed an extended vocabulary schema using metadata and ontologies that align with current standards. By employing virtualization containers, we capitalize on the scalability and adaptability of public and federated clouds. In this paper, we detail our implementation, present some benchmarking results and comparisons with current methodologies, and discuss the potential applications for evaluating doses on commercial flights or assessing radiation shielding in neutron production facilities.  
 pdf   
  A Hybrid Simulation-based Optimization Framework for Managing Modular Bridge Construction Projects: A Cable-Stayed Bridge Case Study    
 Mohamed Assaf, Sena Assaf, William Correa, Rafik Lemouchi, and Yasser Mohamed (University of Alberta)   
  Abstract    Abstract   Generally, bridge construction is one of the most complex structures in the construction industry due to the higher scalability and supply chain complexity. The modular bridge construction (MBC) technique is considered more advantageous in providing higher productivity shorter schedules, and better quality. Current practices in managing MBC projects overlook dynamic behaviors among the relevant stakeholders and the interactions among various interacting systems, including manufacturing logistics, and onsite assembly. To this end this paper proposes a simulation-optimization framework to enhance MBC projects planning. The simulation module comprises discrete event simulation and agent-based modeling to model the interconnected behaviors of the MBC systems. The optimization module aims to improve the key performance indicators (KPIs) of MBC projects including project cost, schedule, and sustainability. The proposed framework is validated by introducing an MBC case of a cable-stayed bridge. The generated solutions by the optimization model show possible significant enhancements in the identified KPIs.  
 pdf   
  Using System Dynamics to Adapt Business Models to Changing Conditions    
 Marisa Analia Sanchez (Universidad Nacional del Sur) and Javier García Fronti (Universidad de Buenos Aires)   
  Abstract    Abstract   This paper addresses the problem of determining organizational adaptations to ensure business continuity. We propose a methodology to assess the impact of disruptions on a business model and evaluate interventions using System Dynamics archetypes. The methodology aims to contribute to making decision-making more effective and efficient in an uncertain scenario.  
 pdf   
  RustSim: A Process-Oriented Simulation Framework for the Rust Language    
 Kevin Frez and Mauricio Oyarzun (Universidad Arturo Prat), Alonso Inostrosa-Psijas (Universidad de Valparaíso), Francisco Moreno (Universidad de Santiago), and Gabriel Wainer (Carleton University)   
  Abstract    Abstract   We present RustSim, a library for discrete-event process-oriented simulations designed and implemented in Rust programming language. It includes a broad set of classes to allow the user to implement simulation processes and process-oriented primitives. The flexible modular design of RustSim allows users to extend its functionality. In addition, RustSim includes mechanisms to avoid inconsistencies when applying state-changing primitives that other libraries in the language's ecosystem do not provide. We take advantage of Rust generators (coroutine equivalent) to implement process-oriented simulation primitives. Finally the library's internal process handling structure is discussed in detail, including its implementation, how simulations are executed and a case study with a highly detailed example of its use.  
 pdf   
  Modeling and Simulating Stream Processing Platforms    
 Alonso Inostrosa-Psijas (Universidad de Valparaíso); Veronica Gil-Costa (UNSL, CONICET); Roberto Solar and Mauricio Marin (Universidad de Santiago de Chile); and Gabriel Wainer (Carleton University)   
  Abstract    Abstract   Stream processing platforms allow processing and analyzing real-time data. Several tools have been developed for these platforms to guarantee that the applications running on them are scalable, fast, and fault-tolerant and that they can be deployed on many processors. However determining the proper number of processors suitable to hold a given stream processing-based software application is challenging, especially if the application is intended to serve a large user community. In this paper, we propose to model and simulate stream processing platforms for performance evaluation purposes. In our case study, we simulated a commonly used application for the analysis of Twitter streams with Storm. We evaluate its performance under different workloads. Our simulator supports profiling to measure various aspects of the application's performance. Results show that the simulator can replicate the metrics reported by the application running on a real platform with minimal error.  
 pdf   
  Using a Software Design Pattern for Redesign Routed DEVS Formalism    
 Mateo Toniolo, María Julia Blas, and Silvio Gonnet (Universidad Tecnológica Nacional - Facultad Regional Santa Fe)   
  Abstract    Abstract   Routed DEVS (RDEVS) models improve traditional discrete-event models by enhancing the development of routing processes over predefined behaviors. In this paper, we demonstrate how a Software Engineering design pattern specifically the Decorator pattern, was applied to the RDEVS formalism design to include event tracking into the models without altering their expected behavior. As a result, we provide a solution that allows getting structured data from RDEVS models at execution time.  
 pdf   
  Using a Hybrid ABMS to Study the Propagation of Vector-Borne Diseases in an Urban Area with Heterogenous Geospatial Conditions    
 Paula Escudero, Mariajose Franco, María Sofía Uribe, Susana Álvarez, and Rafael Mateus (Universidad EAFIT)   
  Abstract    Abstract   Agent-Based Modeling and Simulation (ABMS) is a valuable tool for understanding infectious disease propagation. This study presents a hybrid ABMS approach to explore the transmission dynamics of vector-borne diseases (Dengue, Zika and Chikungunya) in Bello, Colombia incorporating geospatial characteristics. The model was developed with specific assumptions to validate its alignment with theoretical behavior. Our results demonstrate the temperature’s significant impact on disease spread. Particularly, Chikungunya exhibits distinct behavior compared to Dengue and Zika. While major infection peaks occur early in the simulation, subsequent spread diminishes due to the absence of reinfection considerations. This research represents an early stage of a larger project, laying the groundwork for future research to address computational challenges, enabling statistical analysis with multiple runs, and enhancing the model’s realism with seasonal temperature variations and geographical distributions. These findings will provide valuable insights for policymakers and disease control strategies in Colombia.  
 pdf   
  Challenges of Using Simulation for Healthcare Operations Management in Developing Countries: The Case of Ethiopia    
 Tesfamariam M. Abuhay (University of Gondar, Queen's University); Mihret Woldesemayat Tereda, Lomi Eyachew Adane, and Malefia Demilie Melesse (University of Gondar); Stewart Robinson (Newcastle University); and Vedat Verter (Queen's University)   
  Abstract    Abstract   Simulation models have been employed in developed countries for healthcare service operations management. However, leveraging simulation in developing countries is limited because healthcare operations management challenges are quite different due to scarcity of resources, high population numbers, high healthcare demand, and poor planning implementation, monitoring and evaluation. This study, hence, aims to investigate the usage and adoption of simulation for healthcare operations management in developing countries and the challenges of using simulation in this context by studying the case of Ethiopia through a systematic literature review and survey.  
 pdf   
  Hybrid Approaches for Handling Mobile Crane Location Problems in Construction Sites    
 Khaoula Boutouhami, Rafik Lemouchi, and Mohamed Assaf (University of Alberta); Ahmed Bouferguene (university of alberta); Mohamed Al-Hussein (University of Alberta); and Joe Kosa (NCSG Crane and Heavy Haul Services)   
  Abstract    Abstract   Mobile crane location (MCL) in modular construction is a complex problem that affects both construction safety and efficiency. Sub-optimal MCL planning increases the number of crane relocations and the overall project cost. Interestingly, recently, research on crane operation planning and analysis focused on determining crane configurations, boom lengths and radii to enable lifting given a crane location. However, with a large number of feasible locations, finding the best solution becomes a harder task. In this respect, finding a single crane location ensures an optimal lift plan, e.g., minimizing the number of pick-location. As a result, this paper aims to bridge this gap by providing a hybrid approach using heuristics, grid-based, and combinatorial optimization algorithms to find the least required lifting points. The proposed approach is tested on a case study of a modular building. The study contributes by minimizing the number of crane relocations to enhance budget and cost planning.  
 pdf   
  Modeling and Simulation for Farming Drone Battery Recharging    
 Leonardo Grando (University of Campinas); Juan F. Galindo Jaramillo (University of Campinas, Herminio Ometto Foundation); and José Roberto Emiliano Leite and Edson Luiz Ursini (University of Campinas)   
  Abstract    Abstract   The Connected Farm is composed of several elements that communicate with each other through a 4G/5G Radio Base Station (RBS) placed in the middle of the farm. This RBS is connected to the Internet, allowing communication for all kinds of autonomous devices, performing uninterrupted tasks. This work simulates the Connected Farm environment for an autonomous drone. Our model intends to define when each drone needs to recharge its batteries, with no collusion regarding this recharging decision reducing the drone's battery usage due to the absence of this communication.  
 pdf   
  A Simulation-Optimization Approach for Designing Resilient Hyperconnected Physical Internet Supply Chains    
 Rafael D. Tordecilla, Jairo R. Montoya-Torres, and William J. Guerrero (Universidad de La Sabana)   
  Abstract    Abstract   The Physical Internet (PI) is a recent paradigm in the supply chain management that proposes a framework in which standardization and optimization are key factors to raise supply chain efficiency, resilience, and sustainability. Strategic decisions are included in the PI, including the supply chain network design (SCND). In fact, structuring a (near) optimal design is essential to achieve the PI objectives. Additionally, disruptive events such as the COVID-19 pandemic, earthquakes, or terrorist attacks threaten the supply chains. These events are difficult to predict, but their effects can be simulated when addressing this problem. Hence, we propose a simulation-optimization approach that hybridizes a multi-objective multi-period mixed-integer program with discrete-event simulation to optimize both cost and resilience in the SCND. Furthermore, a network hyperconnection strategy is tested. Results show that both resilience and risk are improved after hyperconnecting the supply chain, especially when active edges are disturbed, but incur higher costs.  
 pdf   
  Predicting Job Waiting Times in a Stochastic Scheduling Environment Using Simulation and Regression Machine Learning Models    
 Ivan Kristianto Singgih (University of Surabaya, The Indonesian Researcher Association in South Korea) and Stefanus Soegiharto (University of Surabaya)   
  Abstract    Abstract   Scheduling real systems is complicated because of the consideration of various working conditions. Although various combinatorial optimization methods, ranging from mathematical models, heuristics, metaheuristics, etc., have been developed, these methods could require a long computational time due to the complexity of the problems. This study proposes a framework to understand the system’s behavior using regression machine learning techniques. The considered system could be any type, e.g., the flow shop, job shop, and their variants, with a certain scheduling method. The framework consists of (1) the development of the simulation for generating the data and (2) how the data could be used for training the regression machine learning models. An example of the stochastic single-machine problem with the First-In-First-Out rule is considered. The framework could be used to simplify the process of understanding the system’s behavior without any necessity to solve the optimization problem, which could be time-consuming.  
 pdf   
  Optimization of Battery Allocation for Post-Earthquake Damage Assessment Using Drones    
 Selver Tugba Yaldiz (Marmara University) and Elvin Coban (Ozyegin University)   
  Abstract    Abstract   Earthquakes are one of the most common natural disasters and assessing the hazard levels of the affected regions and planning post-disaster operations, including search and rescue operations, are very critical. As the roads can be blocked due to an earthquake and debris removal may take time preventing critical rescue operations from starting, drone utilization has been increasing. Since the drones fly, it will be easier to assess the damage levels. However drones have a major drawback, their batteries. In this study, we propose a scenario-based mathematical model to allocate a limited of batteries before the earthquake while computing the drones’ paths for each scenario maximizing the total expected priority scores. Our preliminary analysis shows that small instances can be solved very efficiently.  
 pdf   
  Simulation of a Novel, Low Swap, Sparse Hyper-Dimensional Neural Network Architecture for Anomaly Detection AI at the Edge    
 Dean C. Mumme (RAM Laboratories, Inc.) and Ksenia Burova (RAM Laboratories, Inc)   
  Abstract    Abstract   This paper details the simulation and performance results of a Sparse Hyper-Distributed Robust Efficient Neural Network (SpHyRE-Net) architecture that performs anomaly detection for real-world time-series data. SpHyRE-Net is an innovative, novel, low size, weight and power (SWaP) machine learning solution for devices operating at the tactical edge. It utilizes bit operations and sparse hyper-dimensional representations for bio-inspired learning via a Hebbian-like rule that results in a combined power-latency reduction of 2-orders of magnitude over ordinary deep networks. The paper details the application of SpHyRE-Net to real-world cell-traffic datasets as well as simulation requirements to minimize latency and memory use. Also discussed are the mechanisms necessary for implementing the architecture on an FPGA as a precursor to realization on a neuro-morphic ASIC with ultra-low power profile.  
 pdf   
  A Conversational Human-Computer Interface for Smart Energy System Simulation Environments    
 Gabriel Dengler (FAU Erlangen-Nuremberg, Laboratory of Computer Networks and Communication Systems); Pooia Lalbakhsh (Monash University); Peter Bazan (FAU Erlangen-Nuremberg, Laboratory of Computer Networks and Communication Systems); Ariel Liebmann (Monash University); and Reinhard German (FAU Erlangen-Nuremberg, Laboratory of Computer Networks and Communication Systems)   
  Abstract    Abstract   This paper introduces a conversational framework that enhances the usability of smart energy system simulations. This study is centered around OpenAI's Generative Pre-trained Transformer (GPT), a fine-tuned conversational model that allows users to communicate with the system in a natural way. Therefore, users can describe their simulation scenarios in plain language and GPT seamlessly translates these descriptions into Python scripts, used as inputs to the simulation environment, in our case AnyLogic Simulation Software. Our framework is based on the i7-AnyEnergy core framework to compute distribution flows and relevant statistics. The proposed human-machine interface facilitates and accelerates simulation modeling as demonstrated through the two scenarios we have provided in this paper. Overall, our conversational framework has the potential to significantly improve the user experience of smart energy system simulation environments. By simplifying the interaction between users and complex simulation models, we enable users to obtain valuable insights rapidly and more easily.  
 pdf   
  A Machine Learning Framework to Explain Complex Geospatial Simulations: A Climate Change Case Study    
 Tanvir Ferdousi (University of Virginia); Mingliang Liu Kirti Rajagopalan, and Jennifer Adam (Washington State University); and Abhijin Adiga, Mandy Wilson, S. S. Ravi, Anil Vullikanti, Madhav Marathe, and Samarth Swarup (University of Virginia)   
  Abstract    Abstract   The explainability of large and complex simulation models is an open problem. We present a framework to analyze such models by processing multidimensional data through a pipeline of target variable computation, clustering supervised classification, and feature importance analysis. As a use case, the well-known large-scale hydrology and crop systems simulator VIC-CropSyst is utilized to evaluate how climate change may affect water availability in Washington, United States. We study how snowmelt varies with climate variables (temperature, precipitation) to identify different response characteristics. Based on these characteristics, spatial units are clustered into six distinct classes. A random forest classifier is used with Shapley values to rank static soil and land parameters that help detect each class. The results also include an analysis of risk across different classes to identify areas vulnerable to climate change. This paper demonstrates the usefulness of the proposed framework in providing explainability for large and complex simulations.  
 pdf   
  Dynamic Scheduling of Gantry Robots using Simulation and Reinforcement Learning    
 Horst Zisgen and Robert Miltenberger (Hochschule Darmstadt) and Markus Hochhaus and Niklas Stöhr (SimPlan AG)   
  Abstract    Abstract   Industry 4.0 induces an increasing demand of autonomous interaction between the units of production facilities, like work centers and transportation equipment. This has an impact on the requirements for production scheduling and control algorithms. These must be capable to adapt autonomously to changes on the shop floor. This paper presents a combination of Reinforcement Learning and discrete event simulation for controlling a flexible flow shop using a gantry robot system as transportation unit. In a gantry robot system parts are transported by carriages fitted with grippers that travel along rails from machine to machine. The presented agent learns autonomously the right control policy to move the carriages. It is shown that in cases the optimal policy can be determined the Reinforcement Learning based policy is optimal and in other cases the achieved throughput does slightly exceed the throughput gained by a heuristic priority rule for controlling the gantry robot.  
 pdf   
  Learning Environment for the Air Domain (LEAD)    
 Andreas Strand, Patrick R Gorton, Martin Asprusten, and Karsten Brathen (FFI)   
  Abstract    Abstract   A substantial part of fighter pilot training is simulation-based and involves computer-generated forces controlled by predefined behavior models. The behavior models are typically manually created by eliciting knowledge from experienced pilots, which is a time-consuming process. Despite the work put in, the behavior models are often unsatisfactory due to their predictable nature and lack of adaptivity, forcing instructors to spend time manually monitoring and controlling them. Reinforcement and imitation learning pose as alternatives to handcrafted models. This paper presents the Learning Environment for the Air Domain (LEAD), a system for creating and integrating intelligent air combat behavior in military simulations. By incorporating the popular programming library and interface Gymnasium LEAD allows users to apply readily available machine learning algorithms. Additionally, LEAD can communicate with third-party simulation software through distributed simulation protocols, which allows behavior models to be learned and employed using simulation systems of different fidelities.  
 pdf   
 Chair: Andreas Strand (FFI)  
  Dispatching in Real Frontend Fabs with Industrial Grade Discrete-Event Simulations by Deep Reinforcement Learning with Evolution Strategies    
 Patrick Stöckermann, Alessandro Immordino, and Thomas Altenmüller (Infineon Technologies AG); Georg Seidel (Infineon Technologies Austria); Martin Gebser and Pierre Tassel (University of Klagenfurt); and Chew Wye Chan and Feifei Zhang (D-SIMLAB Technologies Pte Ltd)   
  Abstract    Abstract   Scheduling is a fundamental task in each production facility with implications on the overall efficiency of the facility. While classic job-shop scheduling problems become intractable when the number of machines and jobs increase, the problem gets even more complex in the context of semiconductor manufacturing where flexible production control and stochastic event handling are required. In this paper, we propose a Deep Reinforcement Learning approach for lot dispatching to minimize the Flow Factor (FF) of a digital twin of a real-world stochastic, large-scale semiconductor manufacturing facility. We present the first application of Reinforcement Learning to an industrial grade semiconductor manufacturing scenario of that size. Our approach leverages self-attention mechanisms to learn an effective dispatching policy for the manufacturing facility and is able to reduce the global FF of the fab.  
 pdf   
  Reusing Historical Observations in Natural Policy Gradient    
 Yifan Lin and Enlu Zhou (Georgia Institute of Technology)   
  Abstract    Abstract   Reinforcement learning provides a mathematical framework for learning-based control, whose success largely depends on the amount of data it can utilize. The efficient utilization of historical samples obtained from previous iterations is essential for expediting policy optimization. Empirical evidence has shown that offline variants of policy gradient methods based on importance sampling work well. However existing literature often neglect the interdependence between observations from different iterations, and the good empirical performance lacks a rigorous theoretical justification. In this paper, we study an offline variant of the natural policy gradient method with reusing historical observations. We show that the biases of the proposed estimators of Fisher information matrix and gradient are asymptotically negligible and reduce the conditional variance of the gradient estimator. The proposed algorithm and convergence analysis could be further applied to popular policy optimization algorithms such as trust region policy optimization. Our theoretical results are verified on classical benchmarks.  
 pdf   
  Leveraging Digital Twins to Support a Sustained Human Presence on the Lunar Surface    
 Edward Hua and Linda Boan (The MITRE Corporation)   
  Abstract    Abstract   Having a sustained human presence on the lunar surface is a central objective of the Artemis Program, as it represents a key pre-requisite in resource mining operations on the Moon as well as an important steppingstone for future Martian exploration and colonization. Despite its importance, this endeavor has little precedent to rely on to inform the many challenges it needs to address. Digital Twin (DT), in recent years, has been employed in a wide range of applications. In this paper, we explore its usefulness in establishing the Artemis Base Camp. DT can be applied to various stages of the lifecycle of the lunar base development. We also identify several open questions that need be addressed before the digital twin can be utilized effectively in this project. In fact addressing these questions could facilitate deploying DTs in use cases in a wider spectrum of industries and sectors.  
 pdf   
  A General Framework for Human-in-the-loop Cognitive Digital Twins    
 Parisa Niloofar (University of Southern Denmark); Sanja Lazarova-Molnar (Institute AIFB, Karlsruhe Institute of Technology); Olufemi A. Omitaomu and Haowen Xu (Oak Ridge National Laboratory); and Xueping Li (University of Tennessee)   
  Abstract    Abstract   Modelling and analysis of systems that are equipped with sensors and connected to the Internet are becoming more automated and less human-dependent. However, bringing expert knowledge into the loop along with data obtained from Internet of Thing (IoT) devices minimizes the risk of making poor and unexplainable decisions and helps to assess the impact of different strategies before applying them in reality. While Digital Twins are more of a data-driven simulation of the physical system Cognitive Digital Twins bring the human dimension into the modelling and simulation. In this paper, we aim to emphasize the crucial role of explainability and the underlying rationale behind automated or interactive decision-making processes. Furthermore, we propose an initial framework that delineates the specific points within the feedback loop of a cognitive digital twin where human involvement can be incorporated.  
 pdf   
  Designing a Digital Twin Prototype for Improving Vaccination Centers' Daily Operations    
 Mohamed Ali Wafdi, Yasmina Maïzi, and Ygal Bendavid (ESG UQAM)   
  Abstract    Abstract   In this research paper, we propose a digital twin prototype to improve mass vaccination centers in the Montreal region. This research is important because is it always challenging to define an optimal layout/capacity for healthcare operations, especially in an emergency mode (e.g., pandemic mode). Indeed, in such stressful situations, all managers are more concerned about the effectiveness of daily operations regardless of their efficiency. Following a "design science" research approach, we developed (i) an IoT prototype for real-time patient tracking, (ii) a simulation model, and (iii) integrated them to build our digital twin prototype. Our institution's IoT lab was used as a testbed research environment for developing the IoT infrastructure and simulating the vaccination center. While the prototype was developed for vaccination centers, the approach can be used in any other multi-patient/multi flow operational environment where real-time visibility and simulation are required  
 pdf   
  Advancing Safety in Nuclear Applications with Reduced Order Modeling and Digital Twin    
 Justin Williams, Nicole Hatch, Jean Ragusa, and Jian Tao (Texas A&M University)   
  Abstract    Abstract   Ionizing radiation refers to particles or photons that carry enough energy to remove electrons from atoms or molecules. Through ionizing interactions, radiation can have severe implications for human health and the environment, making it essential to develop effective strategies to manage the risks it poses. To display the potential benefits from the application of digital twin technologies to concerns regarding radioactive material in laboratory, university, and national defense settings, this paper presents the development of a digital twin framework, and potential use cases for the framework. The platform was demonstrated in two scenario studies. The first scenario involves a faux radiation-detecting glovebox used for lab safety education, while the second scenario addresses training for first responders in a nuclear defense and safety situation.  
 pdf   
  Simulation as a Soft Digital Twin for Maintenance Reliability Operations    
 Xueping Li, Thomas Berg, Gerald Jones, and Kimon Swanson (University of Tennessee, Knoxville) and Vincent Lamberti, Luke Birt, and Pugazenthi Atchayagopal (Consolidated Nuclear Security, LLC)   
  Abstract    Abstract   A critical facility's reliability relies heavily on its maintenance process's effectiveness. This process involves numerous sub-processes, which can be challenging to model due to uncertainties and complexities. System managers often seek a predictive tool, and this work extends a previous study that developed a digital twin of a nuclear facility's maintenance task process using data-driven and stochastic modeling, along with expert input. The authors extended the project's previous iteration by enhancing the bootstrapping technique and improving the model's fidelity.  
 pdf   
  Renovation Logistics Park with Digital Twinning: A Simulation-Optimization-Powered Toolbox    
 Peixue Yuan (Northwestern Polytechnical University), Chi Zhang (Xi'an Jiaotong University), and Chenhao Zhou and Li Xue (Northwestern Polytechnical University)   
  Abstract    Abstract   Taking into account the crucial node of the logistics network, this paper concentrates on the layout design problem of logistics parks considering numerous uncertain factors during operations. To provide comprehensive support for park planners and managers, a simulation-optimization-powered toolbox is developed for decision-making, with core functions such as park layout design construction quantity calculations, and performance evaluations. A case study demonstrates the toolbox's effectiveness in assisting users to achieve their desired layout designs, and the result shows that the optimized layout generated by the toolbox can lead to improvements of approximately 13%.  
 pdf   
  A Simulation Optimization Method for Scheduling Automated Guided Vehicles in a Stochastic Warehouse Management System    
 Gongbo Zhang, Xiaotian Liu, and Yijie Peng (Peking University)   
  Abstract    Abstract   We consider the problem of scheduling automated guided vehicles (AGVs) in a stochastic warehouse management system. This problem was studied in the Case Study Competition of the 2022 Winter Simulation Conference. We propose a simulation optimization method that simultaneously optimizes dispatching and route planning for AGVs to enhance the system performance. Experimental results on two warehouse system simulation scenarios demonstrate that the proposed method outperforms the default method.  
 pdf   
  Emulation and Digital Twin Framework for the Validation of Material Handling Equipment in Warehouse Environments    
 Ankit Pandey, Rachael Flam, Raashid Mohammed, and Achuta Kalidindi (Amazon)   
  Abstract    Abstract   With modern warehouses becoming more automated there is a growing opportunity to test and validate material handling concepts throughout the project life cycle. Emulation and digital twin pose a capability for material handling system validation from the ideation stage through post-implementation. An emulation model is a virtual replica of a physical system, and digital twin is a transformation of an emulation model via connection to a virtual or physical controller. They can test factors such as design mechanics and layouts, calculate throughput test controls logic, and perform product flow analysis. Evaluation of these factors can provide a relatively accurate metric for system performance and lead to a more comprehensive return on investment (ROI) analysis. This paper discusses how incorporation of emulation and digital twin into all stages of the project life cycle of material handling systems can improve system efficiency and prevent live system commissioning risk.  
 pdf   
  Simulation Based High Fidelity Digital Twins of Manufacturing Systems: An Application Model and Industrial Use Case    
 Ali Ahmad Malik (Oakland University)   
  Abstract    Abstract   Modern manufacturing systems are required to be developed, commissioned, and reconfigured faster than ever before. Conventional methods for the development of manufacturing systems are time-consuming due to their sequential nature. A digital twin is an emerging technology that can offer a high-fidelity simulation of a real manufacturing system including its kinematics automation program, behavior, user interface and production parameters. Such a unified digital twin can be used as a support tool for verification and validation of complex behavior of modern-day manufacturing systems during design, commissioning, reconfiguration maintenance, and for end-of-life. The resulting benefits are to speed up the development and reconfiguration phases and improve system reliability. This article presents a framework to develop and use a digital twin for the development of complex machines. An industrial case from a large automation company is presented.  
 pdf   
  A Digital Twin for Production Control Based on Remaining Cycle Time Prediction    
 Giovanni Lugaresi (KU Leuven); Pedro Luis Bacelar Dos Santos, Alex Chalissery Lona, and Monica Rossi (Politecnico di Milano); Eduardo Zancul (University of Sao Paulo); and Andrea Matta (Politecnico di Milano)   
  Abstract    Abstract   The recent industrial context pushed manufacturers to invest heavily in digitization for a more efficient use of their equipment and scarce resources. The digitization of industrial environments allows the establishment of digital decision-support tools such as digital twins, to exploit the shop-floor data for making more accurate decisions considering the real system state. Existing literature focuses on the development of specific digital twin components as well as methods that are typically developed and tested without an integration within a digital twin architecture. This paper proposes a complete digital twin framework with the purpose of aiding production planning and control operations. The focus is on the design of a production control service that manages the material flow in the real system using simulation-based predictions of the remaining cycle time. Preliminary experiments are done by applying the digital twin architecture on a lab-scale model, demonstrating the applicability of the proposed approach.  
 pdf   
  Introducing the Kotlin Simulation Library (KSL)    
 Manuel D. Rossetti (University of Arkansas)   
  Abstract    Abstract   This paper introduces a Monte Carlo and discrete-event simulation library for the Kotlin programming language. The Kotlin Simulation Library (KSL) provides functionality to perform simulation experiments involving the generation of random processes, the execution of discrete-event simulation via the event and process views, and the analysis of the statistical quantities generated by simulation models. The architecture of the library leverages the object-oriented and functional programming capabilities of the widely used Kotlin programming language. The library provides functionality that is similar to proprietary software, while being open-source and readily extensible. This paper provides an overview of the architecture of the library. The functionality of the library is illustrated through several examples.  
 pdf   
  Teaching Discrete Event Simulation Software Design in the Context of Computer Engineering    
 James Frederick Leathrum (Old Dominion University)   
  Abstract    Abstract   Recent events resulted in the consolidation of a degree program in Modeling & Simulation Engineering with a degree in Computer Engineering, though with a major in Modeling & Simulation Engineering. The resulting major strongly highlights the computational aspects of M&S. However, the needs of discrete event simulation in computer engineering have somewhat of a different focus. For instance, the management of simultaneous events is crucial in digital circuit simulation. This paper looks at refocusing a course on discrete event simulation software design to meet the needs of a computer engineering degree while maintaining applicability to the more general community. It discusses modifications in the treatment of models and then mapping those models to software.  
 pdf   
  Chances and Challenges of ChatGPT and Similar Models for Education in M&S    
 Andreas Tolk (The MITRE Corporation), Philip Barry (L3Harris Corporation), Margaret Loper (Georgia Tech Research Institute), Ghaith Rabadi (University of Central Florida), William Scherer (University of Virginia), and Levent Yilmaz (Auburn University)   
  Abstract    Abstract   This position paper summarizes the inputs of a group of experts from academia and industry presenting their view on chances and challenges of using ChatGPT within Modeling and Simulation education. The experts also address the need to evaluate continuous education as well as education of faculty members to address scholastic challenges and opportunities while meeting the expectation of industry. Generally the use of ChatGPT is encouraged, but it needs to be embedded into an updated curriculum with more emphasis on validity constraints, systems thinking, and ethics.  
 pdf   
  Entrepreneurial Mindset Learning (EML) in Simulation Education    
 Michael E. Kuhl (Rochester Institute of Technology)   
  Abstract    Abstract   An entrepreneurial mindset is associated with recognizing and seeking opportunity that can result in societal benefits. Entrepreneurial minded learning (EML) is a pedagogy that has gained increasing attention in science technology, engineering, and math education. In this paper, we present as set of examples to illustrate how EML methods can be applied in simulation courses to foster the development of the entrepreneurial mindset of students. In addition, we discuss some of the opportunities and challenges for adoption of EML in simulation education.  
 pdf   
  Risk-Sensitive Ordinal Optimization    
 Dohyun Ahn (The Chinese University of Hong Kong) and Taeho Kim (Texas A&M University)   
  Abstract    Abstract   We consider the problem of risk-sensitive ordinal optimization, which aims to identify the "least risky'' system among a finite number of stochastic systems. Each system's riskiness is assumed to be measured by the probability that the system's loss exceeds a common threshold. Since the crude Monte Carlo estimator is highly inefficient in estimating rare-event probabilities, conventional ordinal optimization approaches coupled with that estimator show significant performance degradation in this problem, particularly for sufficiently large loss thresholds. To detour this issue, assuming that the parametric form of the underlying distribution is known, we propose to use the tail parameter, a function of distributional parameters, as a surrogate for the loss probability in comparing and ranking systems which is shown to work well for many well-known distributions. Building upon this observation we find the optimal computing budget allocation scheme that maximizes the likelihood of identifying the least risky system.  
 pdf   
  Data-Driven Optimal Allocation for Ranking and Selection under Unknown Sampling Distributions    
 Ye Chen (Virginia Commonwealth University)   
  Abstract    Abstract   Ranking and selection (R&S) is the problem of identifying the optimal alternative from multiple alternatives through sampling them. In the existing R&S literature, sampling distributions of the observations are usually assumed to be from some known parametric distribution families, even in works that consider input uncertainty. By contrast, this paper considers R&S under completely unknown sampling distributions. We for the first time propose a computationally-tractable nonparametric tuning-free sequential budget allocation strategy that can asymptotically achieve the optimal allocation specified by large deviation analysis. Especially, we propose a new point estimation approach for estimating the optimal large deviation rates directly which efficiently solves the challenge of estimating large deviation rate functions for lack of known sampling distributions.  
 pdf   
  POMDP-based Ranking and Selection    
 Ruihan Zhou and Yijie Peng (China)   
  Abstract    Abstract   In this paper, we formulate the ranking and selection (R&S) problem as a stochastic control problem under the Bayesian framework. We propose to use particle filter to approximate the posterior distribution of states under the general Bayesian framework. The learning and decision are treated under the umbrella of a partially observable Markov decision process and a rollout policy based on Monte Carlo simulation is proposed. This policy can use one or more classic R&S approaches as base policies to efficiently learn the value function by rolling out simulation trajectories. We present numerical examples to demonstrate the effectiveness of the rollout policy and the performance of our policy is significantly improved relatively to the base policies.  
 pdf   
  Epsilon Optimal Sampling    
 Travis Goodwin (MITRE Corporation), Jie Xu (George Mason University), Nurcin Celik (University of Miami), and Chun-Hung Chen (George Mason University)   
  Abstract    Abstract   Epsilon Optimal Sampling (EOS) is a novel algorithm that seeks to reduce the computational complexity of selecting the best design using stochastic simulation. EOS is an Optimal Computing Budget Allocation (OCBA) type algorithm that reduces computational complexity by integrating machine learning (ML) models into the simulation optimization algorithm. EOS avoids the pitfall of trading computational overhead in simulation execution for computational overhead in ML model training by using a concept we call policy stability. In this paper, we present the concept of policy stability, how it can be used to improve dynamic sampling techniques, and how low-fidelity ML estimates can be integrated into the process. Numerical results are presented to provide evidence as to the improvement in computational efficiency that can be achieved when using EOS in conjunction with ML models over the standard OCBA algorithm.  
 pdf   
  Cluster-based Sampling Allocation for Multi-fidelity Simulation Optimization    
 Zirui Cao (National University of Singapore); Haowei Wang (Rice-Rick Digitalization PTE. Ltd.); and Haobin Li, Ek Peng Chew, and Kok Choon Tan (National University of Singapore)   
  Abstract    Abstract   Simulation optimization is widely used to optimize complex systems. High-fidelity simulation can be expensive, especially when the number of designs is large. In practice, fast but less accurate low-fidelity simulation is often available and can provide valuable information. In this paper, we propose a sampling algorithm that utilizes information from multiple fidelity simulation models to improve the efficiency of searching for the best design. A k-means algorithm is introduced to help capture the performance clustering phenomenon among designs, and a cluster validity index is proposed to determine the optimal number of clusters. The proposed sampling algorithm can incorporate the information of performance clusters and approximately minimize the expected opportunity cost of the selected best design. Numerical results substantiate the superior performance of the proposed algorithm.  
 pdf   
  Simulation Optimization with Multiple Attempts    
 Jingjun Men and Zhihao Liu (Southern University of Science and Technology), Haowei Wang (Rice-Rick Digitalization PTE. Ltd.), and Songhao Wang (Southern University of Science and Technology)   
  Abstract    Abstract   Simulation optimization is a widely utilized approach that allows decision-makers to test various decision variable settings in simulators before implementing a final recommended action on the real systems. In some real-world scenarios, the recommended action can be executed multiple times and the performance is evaluated as the best one among these multiple attempts. In this paper, we introduce such simulation optimization problem with multiple attempts and provide insights of the problem through comparison to risk-averse decision making problem. We propose a surrogate-assisted algorithm based on the Gaussian process model and the upper confidence bound criterion for efficiently solving such problems. We demonstrate the efficiency and effectiveness of the proposed approach with several numerical examples.  
 pdf   
  Towards Greener Stochastic Derivative-Free Optimization with Trust Regions and Adaptive Sampling    
 Yunsoo Ha and Sara Shashaani (North Carolina State University)   
  Abstract    Abstract   Adaptive sampling-based trust-region optimization has emerged as an efficient solver for nonlinear and nonconvex problems in noisy derivative-free environments. This class of algorithms proceeds by iteratively constructing local models on objective function estimates that use a carefully chosen number of calls to the stochastic oracle. In this paper, we introduce a refined version of this class of algorithms that reuse the information from previous iterations. The advantage of this approach is reducing computational burden without sacrificing consistency or work complexity to attain the same level of optimality, which we demonstrate through numerical results using the SimOpt library.  
 pdf   
  Stochastic Adaptive Regularization Method with Cubics: A High Probability Complexity Bound    
 Katya Scheinberg and Miaolan Xie (Cornell University)   
  Abstract    Abstract   We present a high probability complexity bound for a stochastic adaptive regularization method with cubics, also known as regularized Newton method. The method makes use of stochastic zeroth-, first- and second-order oracles that satisfy certain accuracy and reliability assumptions. Such oracles have been used in the literature by other stochastic adaptive methods such as trust region and line search. These oracles capture many settings, such as expected risk minimization, stochastic zeroth-order optimization, and others. In this paper, we give the first high probability iteration bound for stochastic cubic regularization, and show that just as in the deterministic case, it is superior to other stochastic adaptive methods.  
 pdf   
  Efficient Hybrid Simulation Optimization via Graph Neural Network Metamodeling    
 Wang Cen and Peter Haas (University of Massachusetts Amherst)   
  Abstract    Abstract   Simulation metamodeling is essential for speeding up optimization via simulation to support rapid decision making. During optimization, the metamodel, rather than expensive simulation, is used to compute objective values. We recently developed graphical neural metamodels (GMMs) that use graph neural networks to allow the graphical structure of a simulation model to be treated as a metamodel input parameter that can be varied along with scalar inputs. In this paper we provide novel methods for using GMMs to solve hybrid optimization problems where both real-valued input parameters and graphical structure are jointly optimized. The key ideas are to modify Monte Carlo tree search to incorporate both discrete and continuous optimization and to leverage the automatic differentiation infrastructure used for neural network training to quickly compute gradients of the objective function during stochastic gradient descent. Experiments on stochastic activity network and warehouse models demonstrate the potential of our method.  
 pdf   
  Simultaneous Perturbation-Based Stochastic Approximation for Quantile Optimization    
 Best Contributed Theoretical Paper - Finalist    
 Meichen Song and Jiaqiao Hu (Stony Brook University) and Michael C. Fu (University of Maryland, College Park)   
  Abstract    Abstract   We study a gradient-based algorithm for solving differentiable quantile optimization problems under a black-box scenario. The algorithm finds improved solutions along the descent direction of the quantile objective function, which is approximated at each step using a simultaneous perturbation technique that involves the difference quotient of the output random variables. Compared to existing quantile optimization methods, our algorithm has a two-timescale stochastic approximation structure and uses only three observations of the output random variable per iteration without requiring knowledge of the underlying system model. We show the local convergence of the algorithm and establish a finite-time bound on the convergence rate of the algorithm. Numerical results are also presented to illustrate the algorithm.  
  Sequential Simulation Optimization with Censoring: An Application to Bike Sharing Systems    
 Cedric Gibbons (Chilean Navy), James Grant (Lancaster University), and Roberto Szechtman (Naval Postgraduate School)   
  Abstract    Abstract   Sequential Simulation Optimization is an online optimization framework where an operator iterates periodically between collecting data from a real-world system, using stochastic simulation to approximate the optimal values of some operational variables, and setting some choice of variables in the system for the next period. The aim is to converge to an optimum efficiently, as uncertainty due to finite data and finitely many simulations eventually reduces. Using Bike Sharing Systems (BSS) as a motivating example, we analyze a variant where data from the real-world system is subject to censoring, whose nature depends on the system variables selected by the operator. In the BSS setting, censoring is of customer demand, or slots in which to drop bikes off in. We show that a method built upon Sample Average Approximation attains asymptotically vanishing error in its parameter estimates and specification of the optimal operational variables.  
 pdf   
  SF-SFD: Stochastic Optimization of Fourier Coefficients to Generate Space-Filling Designs    
 Manisha Garg (University of Illinois Urbana-Champaign Argonne National Laboratory) and Tyler H. Chang and Krishnan Raghavan (Argonne National Laboratory)   
  Abstract    Abstract   Due to the curse of dimensionality, it is often prohibitively expensive to generate deterministic space-filling designs. On the other hand, when using naive uniform random sampling to generate designs cheaply, design points tend to concentrate in a small region of the design space. Although, it is preferable in these cases to utilize quasi-random techniques such as Sobol sequences and Latin hypercube designs over uniform random sampling in many settings, these methods have their own caveats especially in high-dimensional spaces. In this paper, we propose a technique that addresses the fundamental issue of measure concentration by updating high-dimensional distribution functions to produce better space-filling designs. Then we show that our technique can outperform Latin hypercube sampling and Sobol sequences by the discrepancy metric while generating moderately-sized space-filling samples for high-dimensional problems.  
 pdf   
  Upper-Confidence-Bound Procedure for Robust Selection of the Best    
 Yuchen Wan (Fudan University); Weiwei Fan (Tongji University); and L. Jeff Hong (Fudan University, School of Management)   
  Abstract    Abstract   Robust selection of the best (RSB) is an important problem in the simulation area, when there exists input uncertainty in the underlying simulation model. RSB models this input uncertainty by a discrete ambiguity set and then proposes a two-layer framework under which the best alternative is defined to have the best worst-case mean performance over the ambiguity set. In this paper, we adopt a fixed-budget framework to address the RSB problem. Specifically, in contrast with existing procedures, we develop a new robust upper-confidence-bound (UCB) procedure, named as R-UCB. We can show that, the R-UCB procedure successfully inherits the simplicity and convergence guarantee of the traditional UCB procedure. Furthermore, simulation experiments demonstrate that the R-UCB procedure numerically outperforms the existing RSB procedures.  
 pdf   
  Input Data Collection versus Simulation: Simultaneous Resource Allocation    
 Yuhao Wang and Enlu Zhou (Georgia Institute of Technology)   
  Abstract    Abstract   This paper investigates the problem of ranking and selection under input uncertainty with simultaneous resource allocation. In this problem, two types of resources are sequentially allocated at the same time to collect input data to reduce input uncertainty and run simulations to reduce stochastic uncertainty. We formulate the simultaneous resource allocation problem as a concave optimization problem that aims to maximize the asymptotic probability of correct selection (PCS) through the allocation policy for both input data collection and simulation based on a moving-average estimator for aggregation of simulation outputs and its asymptotic normality. The two optimal policies are interdependent since they jointly affect the PCS. We derive the optimality equations to characterize the optimal policies and develop a fully sequential algorithm that demonstrates high efficiency through numerical experiments.  
 pdf   
  Representative Calibration Using Black-box Optimization and Clustering    
 Serin Lee, Pariyakorn Maneekul, and Zelda B. Zabinsky (University of Washington)   
  Abstract    Abstract   Calibration is a crucial step for model validity, yet its representation is often disregarded. This paper proposes a two-stage approach to calibrate a model that represents target data by identifying multiple diverse parameter sets while remaining computationally efficient. The first stage employs a black-box optimization algorithm to generate near-optimal parameter sets, the second stage clusters the generated parameter sets. Five black-box optimization algorithms, namely, Latin Hypercube Sampling (LHS), Sequential Model-based Algorithm Configuration (SMAC), Optuna, Simulated Annealing (SA), and Genetic Algorithm (GA), are tested and compared using a disease-opinion compartmental model with predicted health outcomes. Results show that LHS and Optuna allow more exploration and capture more variety in possible future health outcomes. SMAC, SA, and GA, are better at finding the best parameter set but their sampling approach generates less diverse model outcomes. This two-stage approach can reduce computation time while producing robust and representative calibration.  
 pdf   
  Resampling Stochastic Gradient Descent Cheaply    
 Henry Lam and Zitong Wang (Columbia University)   
  Abstract    Abstract   Stochastic gradient descent (SGD) or stochastic approximation has been widely used in model training and stochastic optimization. While there is a huge literature on analyzing its convergence, inference on the obtained solutions from SGD has only been recently studied, yet is important due to the growing need for uncertainty quantification. We investigate two easily implementable resampling-based methods to construct confidence intervals for SGD solutions. One uses multiple, but few, SGDs in parallel via resampling with replacement from the data, and another operates this in an online fashion. Our methods can be regarded as enhancements of established bootstrap schemes to substantially reduce the computation effort in terms of resampling requirements, while at the same time bypasses the intricate mixing conditions in existing batching methods. We achieve these via a recent cheap bootstrap idea and Berry-Esseen-type bound for SGD.  
 pdf   
  Input Uncertainty Quantification Via Simulation Bootstrapping    
 Manjing Zhang (Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ)), Guangwu Liu (City University of Hong Kong), Shan Dai (Shenzhen Research Institute of Big Data), and Yulin He (Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ))   
  Abstract    Abstract   Input uncertainty, which refers to the output variability arising from statistical noise in specifying the input models, has been intensively studied recently. Ignoring input uncertainty often leads to poor estimates of system performance. In the non-parametric setting, input uncertainty is commonly estimated via bootstrap, but the performance by traditional bootstrap resampling is compromised when input uncertainty is also associated with simulation uncertainty. Nested simulation is studied to improve the performance by taking variance estimation into account, but suffers from a substantial burden on required simulation effort. To tackle the above problems, this paper introduces a non-nested method to build asymptotically valid confidence intervals for input uncertainty quantification. The convergence properties are studied, which establish statistical guarantees for the proposed estimators related to real-data size and bootstrap budget. An easy-implemented algorithm is also provided. Numerical examples show that the estimated confidence intervals perform satisfactorily under given confidence levels.  
 pdf   
  Asymptotic Normality of Joint Metamodel-Based Sobol' Index Estimators    
 Jingtao Zhang, Xi Chen, and Ruochen Wang (Virginia Tech)   
  Abstract    Abstract   This paper proposes two joint metamodel-based Sobol' index estimators and investigates their asymptotic properties. The numerical evaluation corroborates the theoretical results and highlights the impact of the combination of training sample size and Monte Carlo sample size on the estimators' performance.  
 pdf   
  SmartFactory AI Productivity Utilizing Simulation    
 Samantha Duchscherer (Applied Materials)   
  Abstract    Abstract   Accurately simulating a semiconductor environment is challenging. Tools and processing steps are constantly evolving due to advancements in technology nodes and other unforeseen manufacturing modifications. However AutoSched has out of the box capabilities to accurately simulate a particular tooling area as well as an entire facility. Models are also customizable to handle robust scenarios ranging from modifying how routes are built to varying the number of bottleneck stations. This flexibility makes AutoSched a key component in the data preparation phase for deploying various AI use cases. Here we will demonstration the capabilities of AutoSched modeling key factors inherent to semiconductor manufacturing and showcase how this enables AI innovations and real operational efficiency gains. From predicting lot cycle time with a gradient boosting model to utilizing reinforcement learning for optimizing dispatching parameter values and scheduling constraints, simulation is empowering SmartFactory AI Productivity.  
  Data Driven Digital Twin – Benefits and Advantages in Real-time Systems    
 Chair: Zeyu Zheng (University of California, Berkeley); María Julia Blas (INGAR CONICET UTN)  
  Using Narratives to Facilitate Public Acceptance of Policies through Agent-Based Simulations    
 Yusuke Goto (Shibaura Institute of Technology)   
  Abstract    Abstract   In this paper, we introduce a conceptual framework of policy communication that is propelled by narratives generated via agent-based simulations. The framework demonstrates that public acceptance of polices is contingent upon the interplay between generated narratives and the stakeholders who receive them. Moreover, it illustrates a model that employs narratives to facilitate public acceptance of policies through agent-based simulations. Drawing on the proposed framework we identify the following three challenges encountered in policy communication that is driven by narratives generated through agent-based simulations: developing a methodology of narrative design and visualization, identifying factors that influence public acceptance of policies, and providing the assurance of accountability as justified narratives.  
 pdf   
  Constructing an ABM to Enhance Residents' Conviction Regarding the Effectiveness of Town Development Measures    
 Ibu Ueno and Shingo Takahashi (Waseda University)   
  Abstract    Abstract   When evaluating town development measures social simulations have been attempted to be employed. In recent years, it is essential to involve diverse stakeholders in the modeling process and feedback of simulation results. This paper aims to construct a method using Gaming Simulation (GS) to allow participants to experience an Agent-Based Model (ABM), comprehend the model, and gain a sense of convincing from the simulation results.  
 pdf   
  Information Diffusion Model of SNS and Visualization Method    
 Kazumi Sekiguchi and Masakazu Furuichi (Nihon University)   
  Abstract    Abstract   The dissemination of social media has led to the explosion of fake news, other misinformation and disinformation, which significantly impacts society. They are sometimes based on information transmission by individuals, groups, and organizations. In order to analyze the influence of information diffusion, it is necessary not only to visualize the spread from a bird's eye view but also to examine the characteristics of local information propagation and the impact of the behavior. In this study, we developed a multi-agent information diffusion model of social networking service (SNS). We investigated a visualization method that simultaneously grasps the local information diffusion by individuals and the overarching information spread by multiple user clusters. This method facilitates the recognition of the information diffusion within a group and the final dispersal status in addition to the condition of information dissemination by each individual.  
 pdf   
  Using a Discrete Event Simulation to Improve Check-in Operations at the Port of Dover    
 Siti Fariya (University of Kent, The Port of Dover); Kathy Kotiadis (University of Kent); Timothy van Vugt (The Port of Dover); and Jesse O'Hanley (University of Kent)   
  Abstract    Abstract   This paper showcases our use of discrete event simulation (DES) to enhance check-in operations at the Port of Dover (PoD). PoD is the busiest international ferry port in the UK and since the UK left the European Union, the port has experienced increased processing times and considerable delays in passenger check-in. Three independent ferry operators run individual check-in systems for freight and tourist vehicles, leading to efficiency challenges notably prolonged queuing times and limited throughput. Our study investigates two alternatives: a common check-in booth for all operators and vehicle types, and a system that retains operator-specific booths but merges the process for all traffic types. We aim to identify an improved operational model that reduces queue times and to explore a range of solutions that could improve check-in operations at the Port of Dover, which not only make the check-in process more efficient but also significantly reduces queuing times.  
 pdf   
  Development and Application of the One-Stop Flow Analysis Framework Enabling Rapid Digital Engineering    
 Kengo Asada, Yuichi Matsuo, and Kozo Fujii (Tokyo University of Science)   
  Abstract    Abstract   This paper proposes a one-stop simulation framework from point cloud acquisition through flow analysis. Conventional flow analysis starts with computer-aided design (CAD) software to define the object shape and any mesh generator to build computational grids. However, CAD data of old buildings and rooms, including furniture is hardly available. Thus, CAD data creation which takes a lot of time, is required when conducting flow simulations of existing buildings first. The present study illustrates a simplified flow analysis procedure, which reduces this lead time by defining the object shape with point clouds and using a Cartesian-based flow solver. The proposed framework simplifies the design of heating ventilation, and air conditioning (HVAC) and could improve its existing process and quality.  
 pdf   
  Stochastically Constrained Level Set Approximation Via Probabilistic Branch and Bound    
 Hao Huang (Yuan Ze University), Shing Chih Tsai (National Cheng Kung University), and Chuljin Park (Hanyang University)   
  Abstract    Abstract   This paper investigates a simulation optimization problem with both stochastic objective and constraint functions with a discrete solution space. Our objective is to identify a set of near-optimal solutions within a specific quantile, such as the top 10%. To achieve this goal, we first employs a probabilistic branch-and-bound algorithm to find a level set of solutions. Then, we combine a penalty function approach with the probabilistic branch-and-bound algorithm to handle stochastically constrained problems. Both convergence analysis and experimental results are provided that demonstrate the superior efficiency of our proposed approaches over existing methods.  
 pdf   
  A Virtual Training System Using Digital Twins Based on Discrete Event System Formalism    
 JinWoo Kim, GyuSik Ham, Sooyoung Jang, and Changbeom Choi (Hanbat National University)   
  Abstract    Abstract   With the advancement of technology in education and training, it has become commonplace to conduct virtual rather than physical training to save time and money. In addition, various training hardware and software have been proposed to give immersive experiences to trainees to enhance the training effects in various domains. The training system can be regarded as a digital twin system, which collects data from the trainee, analyzes the data in the cyber world, and gives proper feedback to the trainee. This research proposes a virtual training system using digital twins based on discrete event system formalism. Especially, we focus on developing a cost-effective digital twin and helping the trainer to develop an evaluation system by composing models. The training system utilizes the webcam to collect skeleton data from the trainee and evaluate the data by composing discrete event system models.  
 pdf   
  Development of Production Digital Twin in Manufacturing Using Fischertechnik Factory Model    
 Yuichi Matsuo, Kengo Asada, and Kozo Fujii (Tokyo University of Science)   
  Abstract    Abstract   Recently, there have been more opportunities to see and hear the term Digital Twin (DT) in various situations. However, the reality is that only the concept of DT precedes and that there is a lack of places and materials to absorb the DT content and its implementation. This paper presents a case study at Tokyo University of Science to develop the Production Digital Twin in manufacturing by using Fischertechnik factory model and Matlab/Simulink software tool. DT can support not only the education in universities but also human resource development in manufacturing industries through the study and practice concerning production line optimization, virtual commissioning cyber-physical system implementation, real-time monitoring of production data, and furthermore lead the innovation in manufacturing in Japan.  
 pdf   
  Simulating Job Replication Versus Its Energy Usage    
 Vladimir Marbukh and Brian Cloteaux (NIST)   
  Abstract    Abstract   Due to the proliferation of computers in all aspects of our lives, the energy and ecological impacts of computing are becoming increasing important. Some of the transformative algorithms of recent years generate huge amounts of carbon dioxide, potentially damaging the environment. We have developed a set of simulations for understanding the trade-offs between distributed computing and its carbon impact. We briefly describe our current work and our future research aiming at finding practical algorithmic solutions.  
 pdf   
  Reusing Historical Observations in Natural Policy Gradient    
 Yifan Lin (Georgia Institute of Technology)   
  Abstract    Abstract   Reinforcement learning provides a framework for learning-based control, whose success largely depends on the amount of data it can utilize. The efficient utilization of historical samples obtained from previous iterations is essential for expediting policy optimization. Empirical evidence has shown that offline variants of policy gradient methods based on importance sampling work well. However, existing literature often neglect the interdependence between observations from different iterations, and the good empirical performance lacks a rigorous theoretical justification. In this paper, we study an offline variant of the natural policy gradient method with reusing historical observations. We show that the biases of the proposed estimators of Fisher information matrix and gradient are asymptotically negligible, and reusing historical observations reduces the conditional variance of the gradient estimator. The proposed algorithm and convergence analysis could be further applied to popular policy optimization algorithms such as trust region policy optimization.  
 pdf   
  Dispatching in Real Frontend Fabs With Industrial Grade Discrete-Event Simulations by Deep Reinforcement Learning With Evolution Strategies    
 Patrick Stöckermann (Infineon Technologies AG)   
  Abstract    Abstract   Scheduling is a fundamental task in each production facility with implications on the overall efficiency of the facility. While classic job-shop scheduling problems become intractable when the number of machines and jobs increases, the problem gets even more complex in the context of semiconductor manufacturing where flexible production control and stochastic event handling are required. In this paper, we propose a Deep Reinforcement Learning approach for lot dispatching to minimize the Flow Factor (FF) of a digital twin of a real-world stochastic, large-scale semiconductor manufacturing facility. We present the first application of Reinforcement Learning (RL) to an industrial grade semiconductor manufacturing scenario of that size. Our approach leverages a self-attention mechanism to learn an effective dispatching policy for the manufacturing facility and is able to reduce the global FF of the fab.  
 pdf   
  Conditional Importance Sampling for Convex Rare-Event Sets    
 Lewen Zheng (The Chinese University of Hong Kong)   
  Abstract    Abstract   This paper studies the efficient estimation of expectations defined on convex rare-event sets using importance sampling. Classical importance sampling methods often neglect the geometry of the target set, resulting in a significant number of samples falling outside the target set. This can lead to an increase in the relative error of the estimator as the target event becomes rarer. To address this issue, we develop a conditional importance sampling scheme that achieves bounded relative error by changing the sampling distribution to ensure that a majority of samples lie inside the target set. The proposed method is easy to implement and significantly outperforms the existing approaches in various numerical experiments.  
 pdf   
  Shapley-Shubik Explanations of Feature Importance    
 Gayane Grigoryan (Old Dominion University)   
  Abstract    Abstract   Explaining feature importance values in models is a central concern in the realm of explainable artificial intelligence (XAI). While the Shapley value has garnered significant attention, there are other promising cooperative game theory (CGT) solutions, such as the Shapley-Shubik that have not received the same amount of attention. In this paper, we explore the potential of the Shapley-Shubik method for elucidating feature importance values in simulations and machine learning models.  
 pdf   
  Focused Flexibility in Workforce Scheduling    
 Johanna Wiesflecker (The University of Edinburgh)   
  Abstract    Abstract   In many industries, work schedules often go through lengthy approval processes. Once approved, schedules may be locked in for long time horizons (e.g., months). Working regulations allow for partial changes (re-rostering) in a small number of extreme cases. Most other disruptions (staff absenteeism, change in demand pattern, etc.) will be dealt with only at huge costs. Injecting flexibility (affordable, case-specific re-rostering options) from the very outset (schedule approval stage) can foster schedule robustness at lower costs. This work shows how to jointly adopt simulation and Adaptive Large Neighborhood Search to do just that. At each iteration of the proposed Sim-ALNS algorithm ALNS selects a combination of levels of flexibility (within guidelines set by the organization), while a Monte-Carlo simulation scheme evaluates the performance of the solution. Experiments in an airport security setting show that the method leads to a 27% decrease in average weekly re-rostering cost.  
 pdf   
  Computer Simulation-based Templates for Lean Implementation in Small and Medium Construction Enterprises    
 Prashanth Kumar Sreram (Indian Institute of Technology Bombay, National Institute of Construction Management and Research Hyderabad)   
  Abstract    Abstract   A country's economic advancement hinges on the construction sector, but its growth is marred by the global construction industry's chief predicament: tangible and intangible waste. Lean construction employs strategies such as Value Stream Mapping (VSM), yielding crucial time and cost savings. Presently, VSM's execution is limited to static process representation segregating preparation, and assessment of enhancement alternatives. In the era of construction 4.0, embracing technological and digital shifts is imperative, enhancing performance via simulation. Hence, uniting Lean Construction with Simulation becomes essential validating lean principles through simulation models and aiding improved project decision-making. Thus, research concentrates on crafting VSM-based discrete event simulation (DES) models tailored for small and medium enterprises in the offsite construction realm. The current focus is offsite construction, while forthcoming research addresses complex activities, refining simulation models as valuable tools for industry practitioners.  
 pdf   
  Causal Dynamic Bayesian Networks for Simulation Metamodeling    
 Pracheta Amaranath (University of Massachusetts Amherst)   
  Abstract    Abstract   A traditional metamodel for a discrete-event simulation approximates a real-valued performance measure as a function of the input-parameter values. We introduce a novel class of metamodels based on modular dynamic Bayesian networks (MDBNs), a subclass of probabilistic graphical models which can be used to efficiently answer a rich class of probabilistic and causal queries (PCQs). Such queries represent the joint probability distribution of the system state at multiple time points, given observations of, and interventions on, other state variables and input parameters. This paper is a first demonstration of how the extensive theory and technology of causal graphical models can be used to enhance simulation metamodeling. We demonstrate this potential by showing how a single MDBN for an M/M/1 queue can be learned from simulation data and then be used to quickly and accurately answer a variety of PCQs, most of which are out-of-scope for existing metamodels.  
 pdf   
  Improving Buffer Storage Performance in Ceramic Tile Industry Via Simulation    
 Marco Taccini (University of Modena and Reggio Emilia)   
  Abstract    Abstract   This study aims at identifying the best strategy to temporarily store products within a buffer area in an Italian ceramic tile company. The storage policy is analyzed to maximize the storage capacity, facilitate operators' activities, and, consequently, improve the warehouse logistics performance. A discrete event simulation was conducted using Salabim, a Python based open-source software, in order to determine the best policy. We compare the performance of the current storage policy, based on technical production properties of products and a newly proposed one, based on products' downstream destination. The results suggested that the proposed strategy significantly improves the performance of the buffer area management. The approach can be applied to different applications, contributing to the literature on simulation-based decision-making in material management. Furthermore, the study provides a functional case study showing the potential and achievable results of Salabim for modeling complex systems.  
 pdf   
  Integrating AI and Simulation for Intelligent Material Handling    
 Sriparvathi Shaji Bhattathiri (Rochester Institute of Technology)   
  Abstract    Abstract   With the increasing integration of autonomous mobile robots in warehouse facilities for storage and retrieval, the need arises to make intelligent dispatching decisions to maximize operational efficiency and meet shipping deadlines. The aim of this research is to enable effective real-time, dispatching decisions taking into consideration both travel distance and due date. In particular, we develop a reinforcement learning method for task selection in a multi-agent warehouse environment. A Monte Carlo simulation approach is used to train the Artificial Intelligence model and assess its capabilities and limitations. The performance of the proposed model is compared with that of rule-based task selection methods. The preliminary experimental results indicate strong potential in employing reinforcement learning for real-time dispatch in warehouse environments.  
 pdf   
  Perishable Inventory Management: Human Milk Banking Case Study    
 Marta Staff (University of Exeter)   
  Abstract    Abstract   Despite providing lifesaving donor human milk to vulnerable premature infants, human milk banking is greatly overlooked from an Operations Research perspective, with yet to be explored distinctive characteristics, offering attractive prospects for Modelling and Simulation research. The effective management of inventory, where products have limited shelf life, adds to its complexity. The commonly utilized newsvendor model to study inventory decisions is unlikely to capture the intricacies of items with extended shelf lives. A milk donor typically accumulates milk over time, resulting in the donation of a “stash” consisting of milk units with different expiry dates. The decision of whether to treat it as a whole, or split it, when the “stash” is progressed out of the ingress inventory into production, will affect the remaining shelf life of the final product, but also the associated production costs. Hence DES is being utilized to investigate the cost-benefit analysis of batch splitting.  
 pdf   
  Adaptive Ranking and Selection Based Genetic Algorithms For Data-driven Problems    
 Kimia Vahdat (North Carolina State University)   
  Abstract    Abstract   We present ARGA, the Adaptive Robust Genetic Algorithm, for optimizing simulation problems with binary variables affected by input uncertainty and Monte Carlo noise. In this method, a population evolves as more information about the high-dimensional, stochastic problem becomes available. ARGA conducts ranking and selection with a debiasing mechanism of fitness values using fast iterated bootstraps economized with control variates. Debiasing reduces the model risk due to input uncertainty bias leading to a more accurate ranking of designs. Given the double loop of function evaluations we incorporate adaptive budget allocation throughout the search only if the current population's proximity to optimality signals the need for a smaller standard error. In that case we allocate replications to the input model of the design most responsible for risk. Empirical results with a fixed optimization budget show that ARGA obtains significantly better solutions in feature selection problems across various datasets.  
 pdf   
  Dynamic Weapon Target Assignment via Simulation Reinforcement Learning and Graph Neural Network    
 Seung Heon Oh (Seoul National University)   
  Abstract    Abstract   DWTA (dynamic weapon target assignment problem) is the important resource scheduling problem in battlefield. In this paper, deep reinforcement learning and graph neural network optimize the performance of the decision making of DWTA. The proposed method is evaluated experimentally for some cases and compared with other heuristic methods.  
 pdf   
  A Simulation Framework for Clearing Function-based Release Date Optimization in a Material Requirements Planned Planned Production System    
 Wolfgang Seiringer (University of Applied Science Upper Austria)   
  Abstract    Abstract   In this research work a simulation framework is developed helping to overcome the missing capacity limitation of material requirements planning (MRP) to obtain more reliable planning results. Therefore, the concept of clearing functions (CF) are integrated as constraints into a mathematical optimization problem. When using CF as capacity constraints it is possible to identify how much of the current workload is realistic to be processed on the shop floor of a production. The CF based release dates will replace the fixed planned lead time of MRP which is unable to handle capacity limitations. To evaluate the performance of CF based release date planning a comparison with standard MRP using a simulation experiment is done. First results show the potential of the CF approach but due to the complexity of the release mechanism adjustments to the planning and optimization component in the simulation are necessary.  
 pdf   
  Real-time Delay Prediction for Kidney Transplantation System    
 Najiya Fatma (Indian Institute of Technology Delhi)   
  Abstract    Abstract   We present a combined simulation and machine learning framework for predicting, at the time of end-stage renal disease patient’s registration on the kidney transplantation waitlist, whether the patient will receive a transplant before their health deteriorates. If the patient is predicted to receive a transplant, we predict their time on the waitlist before receiving the transplant. We accomplish this by developing a discrete-event simulation model of the kidney transplantation system using patient-related and organ donor-related information. We use the validated model to record clinical and operational features for each patient at the time of their registration, which is then used to train machine learning algorithms to predict the transplantation waitlist outcome, and, in turn the organ allocation time. Our approach is suitable for generating real-time delay predictions for complex queuing systems where data regarding state of the queueing system that can be used to train ML methods is not maintained.  
 pdf   
  Significance of Traffic Loading for Evacuation and Percolation-based Control Strategies    
 Ruqing Huang (The University of Tennessee, Knoxville)   
  Abstract    Abstract   This paper investigates the significance of traffic loading rate for evacuation efficiency through large-scale evacuation simulation on a 20*20 grid network, emphasizing the emergency evacuation of the central 10*10 CBD area. There exists an equilibrium between the loading flow into the CBD and the exiting flow out of the CBD, which simultaneously optimizes evacuation efficiency. Loading can be excessive, over equilibrium, or under-loaded, with overloading causing widespread jams and potential gridlocks. Using percolation theory, we also proposed several strategies that limit congestion spread to the CBD's edge, achieving equilibrium with optimal evacuee exit rates.  
 pdf
7. WSDM_0 conference:
Skip to main content  WSDM'23 - The 16th ACM International WSDM Conference  The 16th ACM International WSDM Conference   
   Main navigation  
  Calls | Call for Papers 
  Call for Workshop Proposals 
  Call for WSDM Cup Proposals 
  Call for Tutorials 
  Call for Demonstrations 
  Tutorials 
  Workshops 
  WSDM Cup 
  ACM Proceedings 
  Awards 
  Program Committee 
  Demo Program Committee 
  Best Paper Award Committee 
  Test of Time Award Committee 
  Sponsors | Become a sponsor 
 Home    
 WSDM (pronounced "wisdom") is one of the premier conferences on web-inspired research involving search and data mining. The 16th ACM International WSDM Conference will take place in Singapore (in-person conference with virtual elements), during February 27 to March 3, 2023.   
 WSDM is a highly selective conference that includes invited talks, as well as refereed full papers. WSDM publishes original, high-quality papers related to search and data mining on the Web and the Social Web, with an emphasis on practical yet principled novel models of search and data mining, algorithm design and analysis, economic implications, and in-depth experimental analysis of accuracy and performance.  
 WSDM on ACM Digital Library   
 WSDM on Twitter   
 WSDM on Facebook   
 WSDM on LinkedIn   
 WSDM on Whova   
 WSDM on Flickr   
 WSDM on ACM Digital Library  | WSDM on Twitter  | WSDM on Facebook  | WSDM on LinkedIn  | WSDM on Whova  | WSDM on Flickr
8. WSDM_1 conference:
The ACM Web Search and Data Mining (WSDM) Conference Series  
 Future WSDM conferences  
 Past WSDM conferences  
 WSDM 2024    
  The Seventeenth International Conference on Web Search and Data Mining. Mérida, México. March, 2024.  
 WSDM 2023    
 The Sixteenth International Conference on Web Search and Data Mining. Singapore. February, 2023.  
 WSDM 2022    
 The Fifteenth International Conference on Web Search and Data Mining, held virtually, March 2022.  
 WSDM Steering Committee    
 Members who advise and decide long term strategies.
9. WSDM_2 conference:
×     
 Report on the 16th ACM International Conference on Web Search and Data Mining (WSDM 2023)  
 Hady W. Lauw  , Tat-Seng Chua  , Luo Si  , Evimaria Terzi  , Panayiotis Tsaparas  , Andrew Tomkins    
  Published: 01 Jan 2023, Last Modified: 14 Nov 2024   SIGIR Forum 2023   Everyone   Revisions    BibTeX    CC BY-SA 4.0
10. WWW_0 conference:
Knowledge Graph Day 
  Entrepreneur Day 
  Satellite Events | W4A | W4A 2023 
  W4A 2023 Call for Paper 
  Web Sci2023 
  Provenance Week 
 Welcome to The  
  Web Conference 2023 in  
  Austin, Texas, USA  
 April 30 - May 4, 2023  
 AT&T Hotel and Conference Center at The University of Texas at Austin  
 Live Stream of TheWebConf    
  INTRODUCTION  
 The 2023 ACM Web Conference will offer a high quality program made of research sessions, posters and demonstrations, a PhD symposium for the junior scholars, workshops, tutorials, a developers track for the practitioners as well as thought provoking keynote speakers, panels, special track on web for good, History of the Web, and colocated special days.  
 The 2023 ACM Web Conference is an in-person conference with virtual components  including live streaming of ceremonies and keynotes, access to pre-recorded videos of talks, and the Whova platform for interaction with all conference attendees.  
 All speakers, presenters, organizers participating in any way at The Web Conference are expected to attend the conference in person. For exceptional reasons, if you are not able to attend in person to present, you may assign a proxy who must be in person. For special cases, we may make an exception for a live remote presentation.  
  (UPDATE: As of April 26, due to logistical situations, we are not able to accommodate anymore remote presentations)   
 Austin is honored and thrilled to host The Web Conference and is preparing an exceptional conference for sharing the latest insights of academic and industrial research. We thank you for your participation and look forward to seeing you in Austin!  
  ACM A.M. Turing Award Lecture  
  The Web Conference @ Austin  
 The Web Conference 2023 is organized by the School of Information at The University of Texas at Austin

output:1. WSCG_1 information:
2. WSCG_2 information:
3. WSCG_3 information:
4. WSC_0 information:
5. WSC_2 information:
6. WSC_3 information:
7. WSDM_0 information:
8. WSDM_1 information:
9. WSDM_2 information:
10. WWW_0 information:
