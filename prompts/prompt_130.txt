input:
1. ICEC_3 conference:
All Posts 
    Í±¥Ìù¨ ÍπÄ       Apr 14, 2023     1 min read     
 ICEC 2023 will be held in Xi'an, China!    
 The 24th International Conference on Electronic Commerce (ICEC 2023) will be held in Xi'an, China on June 29th - July 1st, 2023. ICEC is an academic conference that deals with issues related to information technology and management in e-commerce.    
 The selected papers from ICEC 2023 will be invited to the special issues of the journals such as Electronic Commerce Research (SSCI), Electronic Commerce Research and Application (SSCI), Data Science and Management (Scopus journal, Elseriver ) and Int. J. Electronic Business (Scopus journal).    
 ICEC 2023 aims at providing researchers and practitioners in electronic commerce and related areas with an opportunity to present original ideas and share insightful opinions.    
 Important notice: the conference will be hybrid with both online and offline meeting, and no nucleic acid testing and quarantine are required for international scholars to enter China.     
 We look forward to seeing you at ICEC 2023 in Xi'an.    
 Post not marked as liked                  
  ICEC 2024 will be held in Seoul, South Korea!   
 Post not marked as liked                  
 Overall Schedule of ICEC 2023 at Xi‚Äôan    
 Post not marked as liked                  
 ICEC           
 International Center for Electronic Commerce        
 CALL          
 icec.net           
 contact@icec.net           
 Jae Ik, Ahn          
 ¬© 2024 by ICEC, International Center for Electronic Commerce          
 bottom of page
2. ICER_0 conference:
ICER 2023   Tue 8 - Thu 10 August 2023 Chicago, Illinois, United States    
 Toggle navigation        
  COVID Policy 
  How to Participate, Physically or Virtually 
  Tracks | ICER 2023 
  Research Papers 
  Starting Down the TRAIL 
  Post Conference Workshops 
  Doctoral Consortium 
  Program | ICER Program 
  Your Program 
   Tue 8 Aug 
  Wed 9 Aug 
  Thu 10 Aug 
  Organization | ICER 2023 Committees 
  Organizing Committee 
  Steering Committee 
  Search 
  Series | Series 
    ICER 2024 
  ICER 2023 
  ICER 2022 
 UChicago Botany Pond  
 ACM Conference on International Computing Education Research (ICER) 2023  
  The 19th ACM Conference on International Computing Education Research will be a hybrid  conference: you may participate physically  in Chicago, Illinois, USA, or virtually  through our conference platform. Associated workshops will be held on Monday, August 7th and on Friday, August 11th. The main conference will run Tuesday, August 8th - Thursday, August 10th.  
 All virtual events will occur over Discord.  
  Featured News    
 Roommate matching Tue 27 Jun 2023 
 Student Volunteers Tue 20 Jun 2023 
   Posts   
  ICER 2023   
  contact form
3. ICER_1 conference:
ICER 2023   Tue 8 - Thu 10 August 2023 Chicago, Illinois, United States    
 Toggle navigation        
  COVID Policy 
  How to Participate, Physically or Virtually 
  Tracks | ICER 2023 
  Research Papers 
  Starting Down the TRAIL 
  Post Conference Workshops 
  Doctoral Consortium 
  Program | ICER Program 
  Your Program 
   Tue 8 Aug 
  Wed 9 Aug 
  Thu 10 Aug 
  Organization | ICER 2023 Committees 
  Organizing Committee 
  Steering Committee 
  Search 
  Series | Series 
    ICER 2024 
  ICER 2023 
  ICER 2022 
  Sign up 
  ICER 2023  ( series  ) /  ICER 2023 Program  
   Switch Program View  
   The GMT offsets shown reflect the offsets at the moment of the conference  .     
 Time Band   
 √ó    You're viewing the program in a time zone which is different from your device's time zone change time zone     
 Tue 8 Aug   
 Displayed time zone: Central Time (US & Canada)  change      
 Tiffany Wenting Li  University of Illinois at Urbana-Champaign  , Silas Hsu  University of Illinois at Urbana-Champaign  , Max Fowler  University of Illinois  , Zhilin Zhang  University of Illinois at Urbana-Champaign  , Craig Zilles  University of Illinois at Urbana-Champaign  , Karrie Karahalios  University of Illinois at Urbana-Champaign 
 Wed 9 Aug   
 Displayed time zone: Central Time (US & Canada)  change      
 Other | Excursion   Catering 
 Thu 10 Aug   
 Displayed time zone: Central Time (US & Canada)  change      
  ICER 2023   
  contact form
4. ICER_2 conference:
Events 
  ICER Conference 
 ICER Conference  
 Computing education, as a research discipline, is the study of how people come to understand computational processes and devices, and how to improve that understanding. As computation becomes ubiquitous in our world, understanding of computing in order to design, structure maintain, and utilize these technologies becomes increasingly important both for the technology professional, but also for the technologically literate citizen. The research study of how the understanding of computation develops, and how to improve that understanding, is critically important for the technology-dependent societies in which we live.  
 ICER Specific Policies  
 All Conference Policies  
 ICER History  
 A History of SIGCSE Events  (maintained by Susan Rodger)  
 Latest ICER conferences  
 Follow the links to conference web sites and proceedings in the ACM DL. Browse by the proceeding covers  .  
  View all ICER Conferences 
 About SIGCSE  
 Upcoming SIGCSE Events  
 ITiCSE 2024  
 8-10 July 2024 (WG: 5-7 July)  
  Milan, Italy 
  ICER '24  
 13-15 August 2024  
  RMIT, Melbourne, Australia 
  SIGCSE Virtual 2024  
 05-07 December 2024  
  Online
5. ICER_3 conference:
Events 
  ICER 
 ICER ‚Äò23  
  ‚Üê 2022  | ICER Index   
 Dates | 8-10 August 2023 |  
 Location | Chicago, IL, USA 
 Upcoming SIGCSE Events  
 ITiCSE 2024  
 8-10 July 2024 (WG: 5-7 July)  
  Milan, Italy 
  ICER '24  
 13-15 August 2024  
  RMIT, Melbourne, Australia 
  SIGCSE Virtual 2024  
 05-07 December 2024  
  Online
6. ICFCA_0 conference:
üìß Contact 
 ICFCA 2023, International Conference on Formal Concept Analysis  
 July 17-21, 2023, Kassel (Germany)  
 Aims  
 The ICFCA conference series is the major biennial event of the Formal Concept Analysis research community. The 17th International Conference on Formal Concept Analysis, ICFCA 2023, aims to bring together researchers and practitioners working on both theoretical and practical aspects of Formal Concept Analysis, as well as its applications in various application fields like data mining, machine learning, software engineering, semantic web, social and environmental sciences.  
 ICFCA 2023 will be hosted at the University of Kassel. It will be a hybrid conference with a strong emphasis on on-site interaction.  
 Partner
7. ICFCA_1 conference:
Sunbelt 2024 - Edinburgh 
  Sunbelt 2023 - Portland 
  Sunbelt Archives 
  Prospective Conference Organizers 
  Back to Events   Other Conferences in the Field    
 ICFCA 2023  
  Monday, July 17, 2023  to Friday, July 21, 2023     
  Kassel, Germany  
 Event Details  
 ICFCA 2023   
  17th International Conference on Formal Concept Analysis   
  July 17-21, 2023, Kassel, Germany   
 Benefits of Membership  
 Membership benefits include: reduced conference registration fees, a reduced subscription rate for the journal Social Networks  , a subscription to Connections  , the association's bulletin and journal, and through Connections  , access to a bank of network datasets. Additional membership benefits include timely notifications of conferences, symposia, and workshops in network analysis held throughout the year at various locations in the many countries represented by the INSNA membership and access to the world's leading experts on social network analysis through SOCNET (INSNA‚Äôs online discussion forum) and at INSNA‚Äôs signature conference, the Sunbelt conference. Members often receive discounts from publishers on new books on social network analysis.  
 Join Now   
 Access Your Existing Account   
  Create an Account    
 Are you ready to join INSNA?  
 We offer a variety of membership categories to serve the needs of association professionals and vendors to the association community.  
 Select a membership type below to get started!
8. ICFCA_2 conference:
This book constitutes the proceedings of the 17th International Conference on Formal Concept Analysis, ICFCA 2023, which   
 This book constitutes the refereed proceedings of 17th International Conference, AC 2023, held as part of the 25th Inter  
 This book constitutes the refereed proceedings of 17th International Conference, AC 2023, held as part of the 25th Inter  
 This book constitutes the refereed proceedings of the 4th International Conference on Formal Concept Analysis, held in F  
 This book constitutes the refereed proceedings of the 5th International Conference, AIS 2023, held as part of the 25th I  
 This book constitutes the refereed proceedings of the 17th International Conference on Reachability Problems, RP 2023, h  
 Author / Uploaded 
  Dominik D√ºrrschnabel 
  Domingo L√≥pez Rodr√≠guez 
  5 Conclusion  
  References  
  Author Index   
 Citation preview   
  Dominik D√ºrrschnabel Domingo L√≥pez Rodr√≠guez (Eds.)  
  Formal Concept Analysis 17th International Conference, ICFCA 2023 Kassel, Germany, July 17‚Äì21, 2023 Proceedings  
  Dominik D√ºrrschnabel ¬∑ Domingo L√≥pez Rodr√≠guez Editors  
  Formal Concept Analysis 17th International Conference, ICFCA 2023 Kassel, Germany, July 17‚Äì21, 2023 Proceedings  
  Editors Dominik D√ºrrschnabel Universit√§t Kassel Kassel, Germany  
  Preface  
  ‚Äì On the œï-degree of inclusion by Manuel Ojeda Aciego, Departmento de Matem√°tica Aplicada, Universidad de M√°laga, Spain ‚Äì Logical foundations of categorization theory by Alessandra Palmigiano, Department of Ethics, Governance and Society, Vrije Universiteit Amsterdam, The Netherlands ‚Äì Modern Concepts of Dimension for Partially Ordered Sets by William T. Trotter, School of Mathematics, Georgia Tech Institute, USA Moreover, due to the recent computation of the ninth Dedekind number using techniques from FCA, this edition also included a late-breaking result talk: ‚Äì Breaking the Barrier: A Computation of the Ninth Dedekind Number by Christian J√§kel, Methods of Applied Algebra, Dresden University of Technology, Germany We are deeply grateful to all the authors who submitted their papers to ICFCA 2023 as a venue to present their work. Our sincere appreciation goes to the members of the Editorial Board and Program Committee, as well as all the additional reviewers, whose timely and thorough reviews enabled the fruitful discussions of the high-quality papers during the conference. We would also like to express our gratitude to the local organizers, who were always quick to solve any problems that arose. We are very grateful to Springer for supporting the International Conference on Formal Concept Analysis and to the Department of Electrical Engineering and Computer Science and to the Research Center for Information System Design of the University of Kassel for hosting the event. July 2023  
  Dominik D√ºrrschnabel Domingo L√≥pez-Rodr√≠guez Gerd Stumme  
  Modern Concepts of Dimension for Partially Ordered Sets  
  William T. Trotter School of Mathematics, Georgia Tech Institute, USA Partially ordered sets (posets) are useful models for rankings on large data sets where linear orders may fail to exist or may be extremely difficult to determine. Many different parameters have been proposed to measure the complexity of a poset, but by far the most widely studied has been the Dushnik-Miller notion of dimension. Several alternate forms of dimension have been proposed and studied, and the pace of research on this theme has accelerated in the past 10 years. Among these variants are Boolean dimension, local dimension, fractional dimension and fractional local dimension. The last in this list holds promise for applications since it provides an answer to the natural question: How can we determine a partial order given only piecemeal observations made, often independently, and typically with conflicts, on extremely large populations? As an added bonus, this line of research has already produced results that have intrinsic mathematical appeal. In this talk, I will introduce the several concepts of dimension, outline some key results and applications for each, and close with more detailed comments on fractional local dimension.  
  Latebreaking Result Talk  
  Approximating Fuzzy Relation Equations Through Concept Lattices David Lobo , V¬¥ƒ±ctor L¬¥ opez-Marchante , and Jes¬¥ us Medina(B) Department of Mathematics, University of C¬¥ adiz, C¬¥ adiz, Spain {david.lobo,victor.lopez,jesus.medina}@uca.es  
  Abstract. Fuzzy relation equations (FRE) is a formal theory broadly studied in the literature and applied to decision making, optimization problems, image processing, etc. It is usual that the initial data contains uncertain, imperfect or incomplete information, which can imply, for instance, the existence of inconsistencies. As a consequence, the FRE that arises from the data may be unsolvable. Taking advantage of the relationship between FRE and concept lattices, this paper is focused on three mechanisms for approximating unsolvable FRE. Several properties have been introduced and diÔ¨Äerent distances for determining the best approximation are considered and applied to an example. Keywords: Fuzzy Sets ¬∑ Fuzzy Relation Equation concept lattice ¬∑ Adjoint triples  
  1  
  D. Lobo et al.  
  intensiÔ¨Åed with the generalization of FRE to the multi-adjoint paradigm in [13, 15]. A complete study on the computation of the whole solution set of a solvable FRE is shown in [15], where it is characterized in terms of an associated multiadjoint property-oriented concept lattice. Multi-adjoint relation equations (MARE) [13] provide a large Ô¨Çexibility for setting the equations, due to the generality of the underlying algebraic structure and the possibility of considering diÔ¨Äerent conjunctors for each variable depending on its nature. A given FRE might be not solvable because of diÔ¨Äerent reasons. For example, because of an excess of imposed restrictions, the consideration of constrains that cannot be satisÔ¨Åed or the imposition of two incompatible conditions. It is therefore necessary to have mechanisms that allow to transform a given unsolvable FRE into a solvable one, through slight changes. We will refer to this process as approximating an unsolvable FRE to a solvable one. In addition, it is important that the FRE approximation procedures can be easily interpretable, in the sense that the eÔ¨Äect that they have on the original equation when applied are known and controlled. This paper will analyze three mechanisms with diÔ¨Äerent philosophies for approximating an unsolvable FRE and their main features will be discussed. Moreover, several distances for measuring the change made by the approximation processes and the comparison among them on an example will also be presented. The three mechanisms arise thanks to the relationship between FRE and property-oriented concept lattices and object-oriented concept lattices [13]. The Ô¨Årst one was recently introduced in [20] and it is based on attribute reduction in FCA [8]. The attribute reduction results in FCA were translated to property-oriented and object-oriented concept lattices and applied to FRE. As a Ô¨Årst consequence, a mechanism for simplifying FRE without removing relevant information was introduced, and this reduction also oÔ¨Äers the possibility of approximating FRE. The other two methods were introduced in [4], where a comparison between FRE and logic programming was done. In this paper, we present these procedures in a general framework and several properties will be studied. The paper is structured as follows. Section 2 includes the algebraic structure considered in the paper, and several basic notions and results on FRE and concept lattices. Section 3 presents the three mechanisms to approximate FRE and analyzes diverse properties. Then, Sect. 4 considers four distances in order to compare the obtained approximated FRE on an example. Finally, some conclusions and prospects for future work are given.  
  2  
  Definition 3 ([22]). Let (L1 , L2 , P, &1 , . . . , &n ) be a multi-adjoint propertyoriented frame. A multi-adjoint context is a tuple (A, B, R, œÉ) where A and B are non-empty sets, R : A √ó B ‚Üí P is a fuzzy relation and œÉ : A √ó B ‚Üí {1, ..., n} is a mapping. Given a multi-adjoint frame and a context, two mappings can be deÔ¨Åned between the fuzzy subsets of attributes A, that is LA 1 = {f | f : A ‚Üí L1 }, and = {g | g : B ‚Üí L2 }. SpeciÔ¨Åcally, the the fuzzy subsets of objects B, that is LB 2 A ‚ÜìN A B ‚Üí L and : L ‚Üí L are deÔ¨Åned as mappings ‚ÜëœÄ : LB 2 1 1 2    (1) g ‚ÜëœÄ (a) = 1 R(a, b) &œÉ(a,b) g(b) | b ‚àà B    N f (a) œÉ(a,b) R(a, b) | a ‚àà A (2) f ‚Üì (b) = 2  
    B for all f ‚àà LA 1 and g ‚àà L2 , where 1 and 2 represent the suprema and N inÔ¨Åma of (L1 , 1 ) and (L2 , 2 ), respectively. The pair of mappings (‚ÜëœÄ ,‚Üì ) forms an isotone Galois connection [22]. This leads to the deÔ¨Ånition of multi-adjoint property-oriented concept lattice. Consider the order relation œÄN deÔ¨Åned as g1 , f1 œÄN g2 , f2 if and only if f1 1 f2 , or equivalently, if and only if g1 2 g2 . The multi-adjoint property-oriented concept lattice associated with the multi-adjoint propertyoriented frame is given by  A ‚ÜìN ‚ÜëœÄ (3) MœÄN (A, B, R, œÉ) = g, f ‚àà LB √ó L | g = f , f = g 2 1 The set MœÄN endowed with the order œÄN is a complete lattice [22]. Given a concept g, f , the mapping g is called extent of the concept and f is called the intent of the concept. The set of intents is denoted as I(MœÄN ) and the extents are denoted as E(MœÄN ). Next, several deÔ¨Ånitions and results concerning multi-adjoint relation equation (MARE) will be recalled. For more details see [13]. A MARE is an equation of the form R  S = T , where R, S and T are fuzzy relations, R or S is unknown, and  is a sup-composition operator. There exist diÔ¨Äerent composition operators  between fuzzy relations, in this paper we will consider the following one. Definition 4 ([13]). Let U, V, W be sets, (P1 , 1 ), (P2 , 2 ), (P3 , 3 ) posets, {(&i , i , i ) | i ‚àà {1, . . . , n}} a set of adjoint triples with respect P1 , P2 , P3 , œÉ : V ‚Üí {1, . . . , n} a mapping, and R ‚àà P1U √óV , S ‚àà P2V √óW , T ‚àà P3U √óW three fuzzy relations. If P3 is a complete lattice, the operator œÉ : P1U √óV √ó P2V √óW ‚Üí P3U √óW deÔ¨Åned as  (4) R œÉ S(u, w) = 3{R(u, v)&œÉ(v) S(v, w) | v ‚àà V } is called sup-&œÉ -composition. This sup-composition operator is used in the deÔ¨Ånition of the MARE analyzed in this paper.  
  Approximating FRE Through Concept Lattices  
  7  
  Definition 5 ([13]). A MARE with sup-&œÉ -composition is an equality of the form (5) R œÉ X = T where X is an unknown fuzzy relation. A MARE is solvable if there exists at least one solution, that is, a relation X exists satisfying (5). Otherwise, we say that the MARE is unsolvable. A dual equation can be developed if the relation R is the unknown relation in the equation R œÉ S = T . If P2 is a lower-semilattice and the MARE (5) is solvable, then its greatest solution exists and can be computed as follows. Proposition 1 ([13]). Let R œÉ X = T be a solvable MARE and (P2 , 2 ) a lower-semilattice. Its greatest solution X is given by  X(v, w) = 2{T (u, w) œÉ(v) R(u, v) | u ‚àà U } for each (v, w) ‚àà V √ó W In [13,15], diverse results related to the solvability and the computation of the solution set of a MARE were introduced based on its relationship with the isotone variants of FCA. Next, the most relevant ones in the scope of this paper will be recalled. First of all, the following deÔ¨Ånition assigns a context to a MARE. Definition 6 ([13]). The multi-adjoint context associated with the MARE RœÉ X = T is the property-oriented multi-adjoint context (U, V, R, œÉ). The following results are based on the notion of multi-adjoint concept lattice. The resolution procedure consists of associating a MARE with a context and, consequently, a multi-adjoint property-oriented concept lattice is associated with it too. The concept lattice (MœÄN (U, V, R, œÉ), œÄN ) of the context associated with a MARE characterizes its solvability. Proposition 2 ([13]). Let (U, V, R, œÉ) be the multi-adjoint context associated with a MARE R œÉ X = T and (MœÄN , œÄN ) the concept lattice associated with that context. Then R œÉ X = T is solvable if and only if Tw ‚àà I(MœÄN ) for all w ‚àà W , where Tw (u) = T (u, w), for all u ‚àà U , w ‚àà W . The solution set of a MARE can be characterized in terms of its associated context as was proved in [15]. Moreover, attribute reduction in FCA allows to reduce a MARE, thus leading to the notion of reduced MARE. Definition 7 ([20]). Let Y ‚äÜ U and consider the relations RY = R|Y √óV , TY = T|Y √óW . The MARE RY œÉ X = TY is called Y -reduced MARE of R œÉ X = T . Reducing a MARE in a consistent set/reduct preserves its solution set. The following result is one of the most relevant ones introduced in [20]. Theorem 1 ([20]). Let R œÉ X = T be a solvable MARE and Y a consistent set of its associated context (U, V, R, œÉ). The Y -reduced equation of R œÉ X = T is solvable. In addition, X ‚àà LV2 √óW is a solution of the Y -reduced equation if and only if it is a solution of the whole equation.  
  8  
  (6)  
  √óW where R ‚àà P U √óV , T ‚àà LU and X ‚àà LV2 √óW , with X being unknown. 1 The intuition behind the Ô¨Årst approximation procedure is to eliminate several of the rows of an unsolvable MARE to recover its solvability. If this happens, it can be reasoned that the inconsistencies that gave rise to the unsolvability were due to the eliminated rows. However, as with reduction procedures, removing too many rows from the equation can lead to a loss of relevant information. In fact, eliminating all rows always leads to a trivially solvable equation, but no information from the original equation is preserved in that case. Therefore, we will use the approach of Theorem 1, which states that reducing a solvable equation considering a consistent set does not cause loss of information. Based on the previous considerations, we will search for a consistent set of attributes Y of its associated context, such that the Y -reduced equation will be solvable, which means that all inconsistencies have been eliminated without losing relevant information. Moreover, in order to eliminate redundant information as well, we will always take into account reducts, which gives rise to the following deÔ¨Ånition.  
  Definition 8. Let R œÉ X = T be an unsolvable MARE and (U, V, R, œÉ) its associated context. We say that a reduct Y ‚äÜ U of (U, V, R, œÉ) is feasible if the Y -reduced equation RY œÉ X = TY is solvable. Note that every consistent set contains at least one reduct. Thus, in order to include as little redundant information as possible, feasible reducts will be Y N considered from now on. Given a subset of attributes Y ‚äÜ U , we will use (‚ÜëœÄ ,‚ÜìY ) to denote the Galois connection associated with the context (Y, V, RY , œÉ|Y √óV ). Suppose that an unsolvable MARE R œÉ X = T admits a feasible reduct Y ‚äÜ U . Since the equation RY œÉ X = TY is solvable, it is clear that the inconsistencies of the original MARE correspond to the rows that have been eliminated. Now, the question that naturally arises is whether it is possible to redeÔ¨Åne the independent term of those rows and so, preserving the dimension  
  (7) (8)  
  Note that, substituting Tw by an element of Lw or of Gw , for all w ‚àà W , gives rise to a solvable MARE since, by deÔ¨Ånition, the elements of these sets are intensions of concepts of MœÄN . The following result shows that the set Lw has a maximum element. Proposition 3. Let R œÉ X = T be an unsolvable MARE. For each w ‚àà W , N the set Lw deÔ¨Åned on (7) has a maximum element, which is given by Tw‚Üì ‚ÜëœÄ . In general, the sets of the form Gw deÔ¨Åned in (8) have no minimum element and, in certain cases, they may even be empty [15]. Therefore, we will use their minimal elements as an approximation, when they exist.  
  10  
  Selecting the Best Approximation  
  The three approximation mechanisms of unsolvable MARE presented in Sect. 3 are based on diÔ¨Äerent philosophies for obtaining a new independent term such that the resulting MARE is solvable. Furthermore, two of these three mechanisms may give rise to more than one approximation, as shown in Example 1, where four diÔ¨Äerent approximations of (9) have been calculated. In order to contrast the approximations of an unsolvable MARE, a measure is necessary. In [19], three unsolvability measures were introduced to compare the original MARE with independent term Tw from its conservative approximation N Tw‚Üì ‚ÜëœÄ [4]. Such study revealed how far is an unsolvable MARE from being solvable, assuming the (unique) conservative approximation. The idea here is deÔ¨Åning measures applicable to all the possible approximations of a MARE, leading to a basis to compare the approximations between them. Notice that, for instance, a MARE can be far from its conservative approximation but close to one of its optimistic approximations. It is clear that the Ô¨Årst measure presented in [19] (which will be recalled next) perfectly works for the other two approximation approaches, while the other two measures are meaningless for optimistic and reduced approximations. In this section, we will consider the unit interval as the underlying lattice. Hence, we will use three distances between two columns/vectors for comparing the given independent term T and an approximation T ‚àó . Given two columns C1 , C2 with  
  14  
  Conclusions and Future Work  
  This paper has analyzed three mechanisms to approximate FRE based on the relationship between FRE and the two isotone variants of FCA. The Ô¨Årst one takes advantage the attribute reduction results in FCA to remove problematic and redundant equations of the original FRE. As a consequence, unsolvable FRE becomes solvable because of removing possible inconsistencies in the systems of equations. The other two are based on looking for the intensions of the concept lattice associated with the given FRE that are closer to its independent term. DiÔ¨Äerent measures have been proposed to analyze what approximation is the most appropriated in practical cases. They have also been applied to an example. In the future, we will continue the study of approximations of unsolvable of FRE, introduce more measures and determine the impact of approximating FRE in their solution set.  
  Abstract. Formal Concept Analysis (FCA) transforms a context bigraph, having vertices of type object and attribute, into a lattice digraph, whose vertices and arcs represent formal concepts and their covering relation. The computational complexity of most FCA algorithms is a polynomial function of the numbers of vertices in both the context bigraph and lattice digraph. While the latter quantity is Ô¨Åxed, the former can be decreased by context standardisation, a process which we show is facilitated by the eÔ¨Écient partition reÔ¨Ånement algorithm of Spinrad. The Carve algorithm recursively partitions the context bigraph and corresponding lattice digraph by removing universal objects and attributes and their orphans and partitioning the resultant sub-context into its connected components. The associated software prototype uses the resultant tree structure to support coordinated browsing of both. This paper describes an additional, coordinated representation of the context bigraph which makes explicit in its bi-adjacency matrix the pattern of nested sub-contexts discovered by the Carve algorithm. We show that permuting this matrix into doubly-lexical order with the aid of Spinrad‚Äôs algorithm groups together into nested rectangles the bigraph edges belonging to these sub-contexts, and facilitates the two key processing steps of the Carve algorithm.  
  1  
  S. Ferr√©  
  objects, so that the concepts do not depend only on the individual descriptions of objects but also on relationship patterns over interconnected objects. Relational Concept Analysis [23] combines several classical FCA contexts and several binary relations to form concepts whose intents are similar to description logic class expressions [3], combining object attributes, binary relations, and quantiÔ¨Åer operators. Relational structures [19] and Graph-FCA [8] add n-ary relationships between objects (n ‚â• 1), and form n-ary concepts, i.e. concepts whose intents are equivalent to conjunctive queries, and whose extents are equivalent to the results of such queries, i.e. sets of n-tuples of objects. In this paper, we propose to merge two FCA extensions that are representative of the Ô¨Årst and last categories above: Pattern Structures (PS) and GraphFCA. The aim is to combine the beneÔ¨Åts of the two categories of extensions, in short complex descriptions and relationships between objects. Logical Concept Analysis (LCA) could have been used in place of PS but we have chosen PS as it has been more widely adopted, and because it is better suited to the eÔ¨Äective computation of concepts. In this paper we choose to merge PS with Graph-FCA but it would be perfectly relevant to do so with Relational Concept Analysis (RCA). We hope this work will encourage and facilitate the merge with RCA in a future work. The merge results in a new FCA extension called Graph-PS. It is an elegant extension in the sense that PS is a special case of Graph-PS, obtained by not using inter-object relationships; and Graph-FCA is a special case of Graph-PS, obtained by using sets of binary attributes as descriptions of individual objects and inter-object relationships. As a consequence, classical FCA is also a special case of Graph-PS. It therefore acts as an unifying FCA theory encompassing classical FCA and two mainstream FCA extensions. The paper is structured as follows. Section 2 recalls the main deÔ¨Ånitions and results of Pattern Structures and Graph-FCA, as preliminaries. Section 3 deÔ¨Ånes Graph-PS as the extension of Graph-FCA with PS-like descriptions, and illustrates the diÔ¨Äerent notions with a running example combining binary relationships, valued attributes and intervals. Section 4 describes its application to RDFS graphs by deÔ¨Åning a custom set of descriptions and similarity operator. Section 5 concludes the paper, and draws some perspectives.  
  2  
  =  
  Of course, this assumes to extend the set of literals L with all patterns that may be generated by the lgg operator, e.g. intervals. On valued properties the lgg operator can be obtained by combining the lgg operators on properties and literals. lgg(p : l , p : l ) = {p : l | p ‚àà lgg(p , p ), l ‚àà lgg(l , l )} Each lgg operator can be lifted to the PS similarity operator on sets of elements by collecting all least general generalizations of elements pairwise, and then Ô¨Åltering them to keep only the most speciÔ¨Åc ones. d  d = Min ‚â§ {x ‚àà lgg(x , x ) | x ‚àà d , y  ‚àà d } This is enough to deÔ¨Åne similarity on D2 -descriptions, which are sets of properties. On D1 -descriptions, similarity can be deÔ¨Åned element-wise as they are pairs (C, P L) of sets of elementary descriptors: C is a set of classes, and P L is a set of valued properties. (C  , P L )  (C  , P L ) = (C   C  , P L  P L ) Finally, the similarity between a D1 -description and a D2 -description is simply the empty description ‚ä•, although Graph-PS only applies similarity to the descriptions of tuples of objects with the same arity.  
  Graph-FCA Meets Pattern Structures  
  Conclusion and Perspectives  
  We have introduced a new extension of Formal Concept Analysis that merges two existing FCA extensions, Pattern Structures (PS) and Graph-FCA. In short, PSlike descriptions are used to describe the nodes and hyperedges of graphs, in place of sets of attributes. The new extension therefore combines the beneÔ¨Åts of the two existing extensions: complex descriptions and relationships between objects. A strength of Graph-PS is that it is a proper generalization of PS and GraphFCA, in the sense that PS and Graph-FCA ‚Äì as well as FCA ‚Äì are special cases of Graph-PS. Hence, all previous work about deÔ¨Åning custom pattern structures can be reused in Graph-PS, and the compact graphical representations of concept lattices in Graph-FCA can be reused in Graph-PS. We have also shown that GraphPS can accurately represent existing graph-based models like RDFS graphs. This paper focuses on the theoretical aspects of Graph-PS, and the most immediate perspectives concern its implementation and its applications. The implementation could be adapted from the existing implementation of GraphFCA [7], by taking into account the similarity operator  in the PGP operations ‚äÜq and ‚à©q . The additional cost of using Graph-PS in PS and Graph-FCA settings should be evaluated. A toolbox of components should be built in order to facilitate the design of new sets of descriptions, by capitalizing on previous applications of pattern structures, and by adopting the methodology of logic functors [13]. In the end, we plan to experiment Graph-PS in diverse knowledge graphs and other complex structures like sequences and trees.  
  M. Ojeda-Hern¬¥ andez et al.  
  pair ( c, Œ®) is a fuzzy Galois connection between (LA , S) and (Isot(AA ), œÅÀú). Furthermore, it is proved that any pair of closure structures (Œ¶, c) is a formal concept of the Galois connection. This problem is also studied for fuzzy closure relations, hence studying two additional Galois connections, one between (Isot(AA ), œÅ) and (IsotTot(LA√óA ), œÅÀÜ) and another one between (LA , S) and (IsotTot(LA√óA ), œÅÀÜ). In the case of paper [15], the main goal is to insert crisp closure systems in the problem. We proved the existence of crisp Galois connections between the crisp lattice (2A , ‚äÜ) and the three sets of the previous paragraph endowed with the 1-cut of their fuzzy relations. Moreover, the existence of Galois connections and the behavior of the sets of formal concepts have been considered. The main goal of this paper is to study the commutativity of the diagram of the three Galois connections presented in [15]. We prove that, of six possible commutative diagrams, two of them are indeed commutative, another one is commutative in the case where the underlying structure is a Heyting algebra, and the remaining three diagrams are not commutative in general, not even under the Heyting algebra assumption. The outline of the paper is as follows. First, a section of preliminaries to recall already known results that are useful to understand the paper better. The next section introduces the crisp closure systems to the framework and considers the new Galois connections and their formal concepts. The main results of the paper appear in the following section, where the study of the commutativity of the diagrams is completed. Finally, there is a section of conclusions and further work where the results are discussed and some hints of future research lines are shown.  
  2  
  Preliminaries  
  This section presents the necessary notions and results to properly follow the paper. The general framework throughout the paper is going to be a complete residuated lattice L = (L, ‚àß, ‚à®, √ó ‚Üí, 0, 1). For the properties of residuated lattices we refer the reader to [3, Chapter 2]. Given a L-fuzzy set X ‚àà LA , the 1-cut of X, denoted by X 1 , is the crisp set {a ‚àà A | X(a) = 1}. Equivalently, we will consider it as the fuzzy set whose characteristic mapping is X 1 (a) = 1 if X(a) = 1 and 0 otherwise. Given a fuzzy relation Œº between A and B, i.e., a crisp mapping Œº : A √ó B ‚Üí L, and a ‚àà A, the afterset aŒº is the fuzzy set aŒº : B ‚Üí L given by aŒº (b) = Œº(a, b). A fuzzy relation Œº is said to be total if, for all a ‚àà A, the aftersets aŒº are normal fuzzy sets, i.e., there exists x ‚àà A such that aŒ∫ (x) = 1. For œÅ being a binary L-relation in A, we say that ‚Äì ‚Äì ‚Äì ‚Äì  
  œÅ œÅ œÅ œÅ  
  A typical example of fuzzy poset is (LA , S), for any set A. If (A, œÅ) is a fuzzy poset, we will also use the so-called full fuzzy powering œÅ‚àù , which is the fuzzy relation on LA deÔ¨Åned as follows: for all X, Y ‚àà LA ,  (X(x) ‚äó Y (y)) ‚Üí œÅ(x, y). œÅ‚àù (X, Y ) = x,y‚ààA  
  Since the structure used in this paper is a complete fuzzy lattice, we require the notion of inÔ¨Åmum and supremum in the fuzzy setting. These concepts, originally introduced by BÀáelohl¬¥ avek in [4], are deÔ¨Åned as follows. Definition 2. Let (A, œÅ) be a fuzzy poset and X ‚àà LA . The down-cone (resp. up-cone) of X is defined as a fuzzy set with the following membership function.     X(a) ‚Üí œÅ(x, a) resp. X œÅ (x) = X(a) ‚Üí œÅ(a, x) . XœÅ (x) = a‚ààA  
  a‚ààA  
  Definition 8. Let (A, œÅ) be a complete fuzzy lattice. A fuzzy set Œ¶ ‚àà LA is said to be a fuzzy closure system if Œ¶1 is a closure system and Œ¶ is the extensional hull of Œ¶1 . This deÔ¨Ånition of fuzzy closure system maintains the well-known one-to-one relationship between closure systems and closure operators [14]. Theorem 3. Let (A, œÅ) be a complete fuzzy lattice. The following assertions hold: 1. If c is a closure operator on (A, œÅ), the fuzzy set Œ¶c defined as Œ¶c (a) = œÅ(c(a), a) is a fuzzy closure system. 2.  If Œ¶ is a fuzzy closure system, the mapping cŒ¶ : A ‚Üí A defined as cŒ¶ (a) = (aœÅ ‚äó Œ¶) is a closure operator on (A, œÅ). 3. If c : A ‚Üí A is a closure operator on (A, œÅ), then cŒ¶c = c. 4. If Œ¶ is a fuzzy closure system on (A, œÅ), then Œ¶ = Œ¶cŒ¶ . Analogously, the same discussion can be done by extending closure operators to fuzzy closure relations, which are isotone, idempotent and inÔ¨Çationary fuzzy relations Œ∫ : A√óA ‚Üí L. A fuzzy closure relation that is minimal among the extensional fuzzy closure relations is named strong fuzzy closure relations. These were introduced in [12]. Therein, it was proved the one-to-one correspondence between strong fuzzy closure relations and fuzzy closure systems [12, Theorem 23]. Fuzzy Galois connections are a main concept in this paper as well. Let us recall the deÔ¨Ånition. Definition 9. ([18]). Let (A, œÅA ) and (B, œÅB ) be fuzzy posets, f : A ‚Üí B and g : B ‚Üí A be two mappings. ‚Äì The pair (f, g) is called an isotone fuzzy Galois connection or fuzzy isotone Galois connection between (A, œÅA ) and (B, œÅB ), denoted by (f, g) :  (B, œÅB ), if (A, œÅA )  œÅA (g(b), a) = œÅB (b, f (a))  
  for all a ‚àà A and b ‚àà B.  
  Crisp Closure Systems  
  Notice that closure systems as crisp sets are not considered in the Galois connections mentioned above. Thus, a natural step is to study a similar problem with the partially ordered set (2A , ‚äÜ). This addition to the problem is not straightforward since (2A , ‚äÜ) is a crisp poset, whereas (LA , S) and (Isot(AA ), œÅ) are complete fuzzy lattices and (IsotTot(LA√óA ), œÅÀÜ) is a fuzzy preposet [13]. Thus, we will consider the 1-cut of the fuzzy relations deÔ¨Åned above and study the crisp problem. It is well-known that S 1 is Zadeh‚Äôs inclusion, hence throughout the paper we will follow the classical notation for subsethood ‚äÜ. We will also consider the 1-cut of œÅ, we will denote œÅ 1 (f, g) = 1 as f g, and œÅÀÜ1 (Œ∫1 , Œ∫2 ) = 1 will be denoted by Œ∫1  Œ∫2 , that is, f g if and only if œÅ(f (a), g(a)) = 1, for all a ‚àà A.  
  (1)  
  (Isot(AA ), œÅ)        Œ®  (‚àí1 ,‚àí‚âà )         Œ® (IsotTot(LA√óA ), œÅÀÜ) (LA , S)   
  We consider now restrictions to ensure the commutativity of, at least, the ÀÜ(Œ¶) is not a closure operator in upper part of the diagram. Let Œ¶ ‚àà LA , then c general. However,  c(Œ¶1 ) will be a closure operator due to Theorem 4. Thus, as expected, the diagram is not commutative in general. In the rest of this section we will give partial results on the relationships among the diÔ¨Äerent compositions. Lemma 1. Let X ‚àà 2A and Œ¶ ‚àà Ext(LA ). Then,  c(X ‚âà )  c(X)  
  and  
  Conclusions and Further Work  
  This paper continues the line of work which initiated in [13], where the mappings that relate fuzzy closure structures are studied from the point of view of fuzzy Galois connections, together with the commutativity of the corresponding diagrams. In [15], the crisp powerset lattice was introduced in that same framework. In this paper, we have completed following commutative diagrams.  (Isot(AA ), )        c  (‚àí1 ,‚àí‚âà ) ‚àí‚âà         Œ∫  (Ext(LA ), ‚äÜ) (IsotTot(LA√óA ), ) (2A , ‚äÜ)  
   c  
  Pre-scalings  
  Some data tables come with slightly richer information, for which we introduce an additional deÔ¨Ånition. A pre-scaling of a many-valued context D := (G, M, W, I) is a family (W (m) | m ‚àà M ) of sets W (m) ‚äÜ W such that W = m‚ààM W (m) and (g, m, w) ‚àà I =‚áí w ‚àà W (m) for all g ‚àà G, m ‚àà M . We call W (m) the value domain of the many-valued attribute m. A tuple (vm | m ‚àà M ) matches a pre-scaling iÔ¨Ä vm ‚àà W (m) ‚à™ {‚ä•} holds for all m ‚àà M . (G, M, W (m)m‚ààM , J) may be called a stratified manyvalued context. It is also allowed that the value domains additionally carry a structure, e.g., are ordered. This also falls under the deÔ¨Ånition of ‚Äúpre-scaling‚Äù. We remain a little vague here, because its seems premature to give a sharp deÔ¨Ånition. Prediger [13] suggests the notion of a relational many-valued context. This may be formalized as a tuple (G, M, (W (m), Rm )m‚ààM , I), where (G, M, W (m)m‚ààM , I) is a stratiÔ¨Åed many valued-context as deÔ¨Åned above, where on each value domain W (m) a family Rm of relations is given. Prediger and Stumme [12] then discuss deriving one-valued attributes using expressions in a suitable logical language, such as one of the OWL-variants. They call this logical scaling.  
  Scaling Dimension  
  A scale for an attribute m of a many-valued context (G, M, W (m)m‚ààM , I) is a formal context Sm := (Gm , Mm , Im ) with W (m) ‚äÜ Gm . The objects of a scale are the scale values, the attributes are called scale attributes. By specifying a scale a data analyst determines how the attribute values are used conceptually. For plain scaling a formal context (G, N, J) is derived from the manyvalued context (G, M, W (m)m‚ààM , I) and the scale contexts Sm , m ‚àà M , as follows: ‚Äì The object set is G, the same as for the many-valued context, ‚Äì the attribute set is the disjoint union of the scale attribute sets, formally  {m} √ó Mm , N := m‚ààM  
  ‚Äì and the incidence is given by g J (m, n) :‚áê‚áí (g, m, v) ‚àà I and v Im n. The above deÔ¨Ånition may look technical, but what is described is rather simple: Every column of the data table is replaced by several columns, one for each scale attribute of Sm , and if the cell for object g and many-valued attribute m contains the value v, then that is replaced by the corresponding ‚Äúrow‚Äù of the scale. Choosing the scales is already an act of interpretation, deriving the formal context when scales are given is deterministic. Pre-scaling, as mentioned above, may suggest the scales to use. An ordered pre-scaling naturally leads to an interordinal interpretation of data, using only interordinal scales. We repeat the standard deÔ¨Ånition of interordinal scaling: Definition 1 (Interordinal Scaling of D). When D := (G, M, W, I) is a many-valued context with linearly ordered value sets (W (m), ‚â§m ), then the formal context I(D) derived from interordinal scaling has G as its object set and attributes of the form (m, ‚â§m , v) or (m, ‚â•m , v), where v is a value of the many valued attribute m. The incidence is the obvious one, an object g has e.g., the attribute (m, ‚â§m , v) iÔ¨Ä the value of m for the object g is ‚â§m v. Instead of (m, ‚â§m , v) or (m, ‚â•m , v) one writes m : ‚â§ v and m : ‚â• v, respectively. Formally I(D) := (G, N, J), where N := {m : ‚â§ v | m ‚àà M, v ‚àà W (m)} ‚à™ {m : ‚â• v | m ‚àà M, v ‚àà W (m)} and (g, m : ‚â§ v) ‚àà J :‚áê‚áí m(g) ‚â§ v,  
  (g, m : ‚â• v) ‚àà J :‚áê‚áí m(g) ‚â• v.  
  √ó  
  Its Ferrers dimension is two, but there are three pairwise incomparable irreducible attributes, which forces its ordinal scaling dimension to be three. A more challenging problem is to determine the interordinal scaling dimension of a context K. We investigate this with the help of the following deÔ¨Ånition. Definition 5. An extent ladder of K is a set R ‚äÜ Ext(K) of nonempty extents that satisÔ¨Åes: i) the ordered set (R, ‚äÜ) has width ‚â§ 2, i.e., R does not contain three mutually incomparable extents, and ii) R is closed under complementation, i.e., when A ‚àà R, then also G \ A ‚àà R. Note that a Ô¨Ånite (and nonempty) extent ladder is the disjoint union of two chains of equal cardinality, for the following reason: Consider a minimal extent E in the ladder. Any other extent must either contain E or be contained in the complement of E, because otherwise there would be three incomparable extents. The extents containing E must form a chain, and so do their complements, which are all contained in the complement of E. Theorem 2 (Interordinal Scaling Dimension). The interordinal scaling dimension of a Ô¨Ånite formal context K, if it exists, is equal to the smallest number of extent ladders, the union of which contains all meet-irreducible extents of K. Proof. Let K be a formal context with interordinal scaling dimension d. W.l.o.g. we may assume that K was derived by plain interordinal scaling from a manyvalued context D with d many-valued attributes. We have to show that the  
  Discussion and Future Work  
  The presented results on the scaling dimension have a number of interfaces and correspondences to classical data science methods. A natural link to investigate would be comparing the scaling dimension with standard correlation measures. Two features that correlate prefectly, e.g., Fig. 1, induce an equivalent conceptual scaling on the data. An analog of the scaling dimension in this setting would be the smallest number of independent features. Or, less strict, the smallest number of features such that these features do not correlate more than some parameter. This obvious similarity of both methods is breached by a key advantage of our approach. In contrast to correlation measures, our method relies solely on ordinal properties [14] and does not require the introduction of measurements for distance or ratios. Proposition 4 has already shown that there is a relationship between an aspect of the scaling dimension of a formal context and the order dimension of its concept lattice. The assumption that further such relationships may exist is therefore reasonable. Yet, a thorough investigation of these relationships is an extensive research program in its own right and therefore cannot be addressed within the scope of this paper. An investigation on how the scaling dimension relates to other measures of dimension within the realm of FCA [9,15] is therefore deemed future work. Due to novel insights into the computational tractability of recognizing scalemeasures [7] (that is in preparation and will be made public later this year) we have little hope that the scaling dimension and interordinal scaling dimension can be decided in polynomial time. Despite that, eÔ¨Écient algorithms for real-world data that compute the scaling dimension and its speciÔ¨Åc versions, i.e., ordinal, interordinal, nominal, etc., may be developed. In addition to that, so far it is unknown if an approximation of the scaling dimension, e.g., with respect to some degree of conceptual scaling error [8] or bounds, is tractable. If computationally feasible, such an approximation could allow larger data sets to be handled. Another line of research that can be pursued in future work is how the scaling dimension can be utilized to derive more readable line diagrams. We can envision that diagrams of concept lattices that are composed of fewer scales, i.e., have a lower scaling dimension, are more readable even if they have slightly more concepts. An open problem that needs to be solved here is: for a context K and k ‚àà N identify k scales that cover the largest number of concepts from B(K) with respect to scale measures.  
  6  
  Universitat Polit`ecnica de Catalunya, Barcelona, Catalonia [email protected]  2 Instituto para la Resiliencia ante Desastres, Santiago, Chile 3 Universit¬¥e de Lyon. CNRS, INSA-Lyon, LIRIS, Lyon, France 4 Universit¬¥e de Lorraine, CNRS, LORIA, Nancy, France [email protected]   
  Abstract. Implications in Formal Concept Analysis (FCA), Horn clauses in Logic, and Functional Dependencies (FDs) in the Relational Database Model, are very important dependency types in their respective Ô¨Åelds. Moreover, they have been proved to be equivalent from a syntactical point of view. Then notions and algorithms related to one dependency type in a Ô¨Åeld can be reused and applied to another dependency type in the other Ô¨Åeld. One of these notions is that of cover, also known as a basis, i.e., a compact representation of a complete set of implications, FDs, or Horn clauses. Although the notion of cover exists in the three Ô¨Åelds, the characterization and the related uses of a cover are diÔ¨Äerent. In this paper, we study and compare, from an FCA perspective, the principles on which rely the most important covers in each Ô¨Åeld. Finally, we discuss some open questions that are of interest in the three Ô¨Åelds, and especially to the FCA community.  
  Keywords: Functional dependencies Dependency Covers ¬∑ Closure  
  iterative application of the Armstrong axioms is of importance in RDBM, logic, and FCA. We start by quoting the survey [13] which comes from the Relational Database Ô¨Åeld: Most of the papers in dependency theory deal exclusively with various aspects of the implication problem, that is, the problem of deciding for a given set of dependencies Œ£ and a dependency œÉ whether Œ£ logically implies œÉ. The reason for the prominence of this problem is that an algorithm for testing implication of dependencies enables us to test whether two given sets of dependencies are equivalent or whether a given set of dependencies is redundant. A solution for the last two problems seems a signiÔ¨Åcant step towards automated database schema design, which some researchers see as the ultimate goal for research in dependency theory. In what way are those two problems a signiÔ¨Åcant step towards automated database schema design and what is the reason of the prominence of the implication problem? Functional dependencies are used to design relational schemes (see for example the extensive Chap. 12.2 Nonloss decomposition and functional dependencies in [10]). However, some of the FDs that are used to describe the data base may be redundant in the sense that they are derivable from the others. These (redundant) FDs used to assist this method of schema design will induce redundancy in the relational schema, which is to be avoided since redundancy in relations creates serious problems in maintaining a consistent data base. Hence, one needs to be able to compute a covering (here we will use the term cover ) of a set of dependencies, this is, a non-redundant set of FDs that yields the same closure with respect to the axioms for FDs. And, the problem of Ô¨Ånding a covering reduces to computing the predicate œÉ ‚àà Œ£ + , that is, Œ£ |= œÉ (all portions of text in italic are citations from [6]). Summing up, the implication problem for FDs is of importance because it solves the problem of computing a cover of a set of FDs which, in turn, prevents the propagation of redundancy in the design of a database scheme using functional dependencies. In FCA, the basic data structure is the binary context which can have two related representations, namely the concept lattice and the basis of implications. The latter is the Duquenne-Guigues basis which is unique, minimal, and non redundant (see 5). There is an equivalence between these three views of an initial dataset. Moreover, one can be also interested in the so-called equivalence classes which are associated with one closed set and possibly several generators of diÔ¨Äerent types [21]. A typical implication is related to any equivalence class which is of the form X ‚Üí Y where Y is a closed set and closure(X) = Y . Then, a minimal basis has all its importance since it provides a summary of the dataset under study with a minimum number of elements. In particular, the number of implications in say the Duquenne-Guigues basis is much smaller than the number of concepts, that is, a substantial number of implications can be inferred from this minimum basis. This is also of importance when the problem of construction or reconstruction is considered, that is, starting with a set of  
  Definitions  
  In this section we introduce the deÔ¨Ånitions used in this paper. We do not provide the references for all of them because they can be found in all the textbooks and papers related to the RDBM, Logic and FCA. As explained in the introduction, implications [15], functional dependencies [20] and Horn clauses [16] are dependencies between sets of attributes, which are equivalent from a syntactical point of view, since they are in agreement with the Armstrong axioms. Definition 1. Given set of attributes U, for any X, Y, Z ‚äÜ U, the Armstrong axioms are: 1. Reflexivity: If Y ‚äÜ X, then X ‚Üí Y holds. 2. Augmentation. If X ‚Üí Y holds, then XZ ‚Üí Y Z holds. 3. Transitivity. If X ‚Üí Y and Y ‚Üí Z hold, then X ‚Üí Z holds. When we write that a dependency X ‚Üí Y holds, we mean all the instances in which this dependency is valid or true. Therefore, the sentence ‚ÄúIf X ‚Üí Y holds, then XZ ‚Üí Y Z holds‚Äù can be rephrased as ‚ÄúIn any instance in which X ‚Üí Y is valid, the dependency XZ ‚Üí Y Z is valid as well‚Äù. The Armstrong axioms allow us to deÔ¨Åne the closure of a set of dependencies as the iterative application of these axioms over a set of dependencies. Definition 2. Œ£ + denotes the closure of a set of dependencies Œ£, and can be constructed thanks to the iterative application of the Armstrong axioms over Œ£. This iterative application terminates when no new dependency can be added, and it is Ô¨Ånite. Therefore, Œ£ + contains the largest set of dependencies that hold in all instances in which all the dependencies in Œ£ hold. The closure of a set of dependencies induces the deÔ¨Ånition of the cover of such a set of dependencies. Definition 3. The cover or basis of a set of dependencies Œ£ is any set Œ£  such that Œ£ + = Œ£ + . We deÔ¨Åne now the concept of a closure of a set of attributes X ‚äÜ U with respect to a set of implications Œ£. Definition 4. The closure of X with respect to a set of dependencies Œ£ is closureŒ£ (X) = { Y | X ‚Üí Y ‚àà Œ£ + } that is, closureŒ£ (X) is the largest set of attributes Y such that X ‚Üí Y can be derived by the iterative application of the Armstrong axioms over the set Œ£. This closure operation returns the largest set of attributes such that Œ£ |= X ‚Üí closureŒ£ (X). Therefore, the implication problem Œ£ |= X ‚Üí Y boils down to testing whether Y ‚äÜ closureŒ£ (X).  
  Three Views on Dependency Covers from an FCA Perspective  
  // Outer loop // Inner loop  
  In Table 1 we list diÔ¨Äerent complexities of Closure as they are given in a classic database textbook [20], a FCA textbook [14] and the pioneer paper of Linclosure [4]1 . In general terms, the complexity of Closure depends on its two loops which are marked in the code as outer and inner loops. This algorithm iterates in the outer loop as long as there is a change in the computation of closureŒ£ (X). This means that in the worst case, the closure may be incremented by only one single attribute at each iteration of the outer loop, which implies that the outer loop is of order O(|U|). Regarding the inner loop, it necessarily iterates over all the dependencies that are in Œ£, that is, it is of order O(|Œ£|). Then the total number of iterations, in the worst case, is of order O(|U| √ó |Œ£|). Since in some cases it may happen that |Œ£| = |U|, the complexity of this algorithm can be, in the worst case, of order O(|Œ£|2 ). 1  
  Other relevant textbooks on RDBM line [1, 27] provide the same complexity analysis as in Table 1.  
  J. Baixeries et al.  
  However, there are two extra comments about this complexity analysis. First, we have stated that the inner loop (line 4) iterates over all the dependencies in Œ£, but all the dependencies that have been used to compute closureŒ£ (X) are deleted in line 8. But even if this removal is performed, the number of iterations is still of order |Œ£|, since in the worst case, we may remove only one single dependency from Œ£ at each iteration of the inner loop. Also, in line 5, there is a subset containment check of order O(|U|) that is performed as many times as there are iterations of the inner loop. This fact, which is only considered in [20], induces a complexity of order O(|U| √ó |Œ£|2 ). As we can observe in Table 1, the consensus is that the complexity of Closure is of order O(|Œ£|2 ) (in the worst case scenario |U| = |Œ£|). However, in cases when |U| 2 or m > 2. c1 c2 c3 c1 c2 c3 c1 c2 c3 a1 √ó √ó √ó √ó √ó √ó √ó √ó √ó a2 √ó √ó √ó a3 √ó √ó √ó √ó √ó √ó o1 o2 o3  
  c1 √ó √ó √ó  
  (‚Ä°)  
  for all x1 , . . . , xn ‚àà A, which precisely expresses that s is an endomorphism of the algebra A; f . Therefore, for F ‚äÜ OA the functions s ‚àà F ‚àó(1) are exactly the endomorphisms of the algebra A; F , i.e., F ‚àó(1) = End A; F . In other words, this means that for Ô¨Åxed A the (dually ordered) intent lattice of K1 is precisely the lattice of all possible endomorphism monoids of any possible algebraic structure on A, ordered by set inclusion. By inspecting the lattice, one may locate endomorphism monoids that are so-called ‚Äòcores‚Äô, which is relevant for determining the complexity of solving systems of equations over algebras. This article is concerned with the task of computationally enumerating all centralising monoids on a three-element set A, of giving witnesses for them in an automated fashion and of counting them. Rephrased in terms of algebraic structures, this means determining the elements and cardinality of the lattice of 1  
  For brevity we shall forego restricting the general commutation relation by intersection with OA ‚à©AA even though this would be required to be meticulously correct.  
  (1)  
  Proof. Let s ‚àà OA and an identiÔ¨Åcation closed set F ‚äÜ OA be ‚àó given, and assume that F  {s} . This means there exists some opera‚àó tion f ‚àà F \ {s} ; let us choose such a function f of minimum possible Proposition 8(ii) we have ns,F ‚â§ k, wherefore arity ns,F  ‚àà N+ . From ‚àó Is := ns,G | G  {s} closed w.r.t. proper variable identiÔ¨Åcations is a nonempty subset of {1, . . . , k}, and hence ns := max Is satisÔ¨Åes 1 ‚â§ ns ‚â§ k. As ‚àó ‚àó ns,F ‚àà Is , we infer ns,F ‚â§ ns ‚â§ k. Thus, f ‚àà F (ns,F ) \ {s} ‚äÜ F (‚â§ns ) \ {s} , ‚àó and therefore F (‚â§ns )  {s} . If we assume F to be closed under minors in general, then we can use the Ô¨Åctitious minor g := Œ¥Œ± f ‚àà F , where Œ± : ns,F ‚Üí ns ‚àó ‚àó is the identical embedding, to prove that g ‚àà F (ns ) \ {s} , i.e., F (ns )  {s} . Namely, by using the identiÔ¨Åcation map Œ≤ : ns ‚Üí ns,F given as Œ≤() :=  for indices 0 ‚â§  < ns,F and Œ≤() := ns,F ‚àí 1 else, we have Œ≤(Œ±()) = Œ≤() =  for 0 ‚â§  < ns,F , and thus Œ≤ ‚ó¶ Œ± = idns,F . By functoriality of taking minors, ‚àó / {s} , which by Corolwe conclude Œ¥Œ≤ g = Œ¥Œ≤ (Œ¥Œ± f ) = Œ¥Œ≤‚ó¶Œ± f = Œ¥idns,F f = f ‚àà ‚àó ‚àó lary 4 implies that indeed g ‚àà / {s} , for otherwise the centraliser {s} would have   to contain the minor Œ¥Œ≤ g = f . As an immediate consequence we may uniformly take ns = |A| for every (1) s ‚àà OA to satisfy the implication of Lemma 9 on a Ô¨Ånite set A. (1)  
  Corollary 10. For any Ô¨Ånite set A of size |A| = k, each s ‚àà OA and every ‚àó F ‚äÜ OA satisfying F  {s} and being closed under proper variable identiÔ¨Åca‚àó tions, we have F (‚â§k)  {s} . (1)  
  Proof. Given s ‚àà OA , take ns ‚â§ k constructed in Lemma 9. Then any function ‚àó set F  {s} that is closed under proper variable identiÔ¨Åcations fulÔ¨Åls, again by ‚àó ‚àó   Lemma 9, ‚àÖ = F (‚â§ns ) \ {s} ‚äÜ F (‚â§k) \ {s} , as required. (1)  
  For any Ô¨Ånite set A of size |A| = k and every s ‚àà OA , Lemma 9 guarantees ‚àó the existence of a smallest arity ns ‚àà {1, . . . , k} such that every F  {s} ‚àó (‚â§ns ) that is closed under variable identiÔ¨Åcations satisÔ¨Åes F  {s} . We shall mainly exploit this implication for very speciÔ¨Åc types of clones, in fact, speciÔ¨Åc (1) centraliser clones, and it may well be that for some s ‚àà OA there exists a smaller arity ns which satisÔ¨Åes the implications claimed by Lemma 9 under this restriction. We shall not explore Ô¨Ånding the smallest possible value of ns in detail, except for simple but important cases. ‚àó  
  Lemma 11. If s = idA or s = ca for some a ‚àà A, then F  {s} implies ‚àó F (1)  {s} for all F ‚äÜ OA that are closed under proper variable identiÔ¨Åcations. ‚àó  
  Lemma 13. Given any s ‚àà OA and n ‚àà N+ we have the equivalent description    (n)  ‚àó Œ¶s,n = f ‚àà OA  ‚àÄ0 ‚â§ i < j < n : Œîij f ‚àà {s}    (n)  ‚àó = f ‚àà OA  ‚àÄ0 ‚â§ m < n ‚àÄŒ± : n ‚Üí m : Œ¥Œ± f ‚àà {s} . ‚àó  
  Proof. If f ‚àà Œ¶s,n and 0 ‚â§ i < j < n, then clearly Œîij f = Œ¥Œ±ij ‚àà {s} because Œ±ij : n  n ‚àí 1 is surjective and non-injective due to i < j. For the second (n) ‚àó inclusion assume that f ‚àà OA satisÔ¨Åes Œîij f ‚àà {s} for all 0 ‚â§ i < j < n and consider any m < n and any Œ± : n ‚Üí m. As m < n, the map Œ± cannot be injective, hence there are 0 ‚â§ i < j < n for which Œ±(i) = Œ±(j). By our assumption ‚àó we have Œîij f ‚àà {s} . We deÔ¨Åne Œ≤ : n ‚àí 1 ‚Üí m by Œ≤() := Œ±() if 0 ‚â§  < j and Œ≤() := Œ±( + 1) if j ‚â§  ‚â§ n ‚àí 2. Hence, Œ≤(Œ±ij ()) = Œ≤() = Œ±() if 0 ‚â§  < j, Œ≤(Œ±ij (j)) = Œ≤(i) = Œ±(i) = Œ±(j), and Œ≤(Œ±ij ()) = Œ≤( ‚àí 1) = Œ±( ‚àí 1 + 1) = Œ±() for all j <  < n. Thus, we have Œ≤ ‚ó¶ Œ±ij = Œ±, and, by functoriality of taking ‚àó minors, we infer Œ¥Œ≤ ‚ó¶ Œ¥Œ±ij = Œ¥Œ≤‚ó¶Œ±ij = Œ¥Œ± , that is, Œ¥Œ± f = Œ¥Œ≤ (Œîij f ) ‚àà {s} because ‚àó ‚àó Œîij f ‚àà {s} and the centraliser {s} is closed under minors by Corollary 4. The  remaining containment relation in Œ¶s,n obviously follows by specialisation.  We now provide the theoretical backbone for constructing smaller witnesscomplete sets. The result is obtained by reÔ¨Åning the proof techniques used in [17, Theorem 2.5] and [22, Theorem 3.1]. Theorem 14. Let A be a Ô¨Ånite set of size |A| = k, and let (ns )s‚ààO(1) \{idA } (1)  
  A  
  D. I. Ignatov  
  Proof. Since every maximal independent set S is in one-to-one correspondence with (S, S), the formal concept of Kc (Qn ), mis(Qn ) = |M+ (Qn )|, where M+ (Qn ) = {(S, S) | (S, S) ‚àà B(Kc (Qn ))}. 2 . Let us also denote Let us denote mis(Qn ) as M+ , then |Kc (Qn )| = M+ by M‚àí all the remaining concepts with equally sized extent and intent, not contained in M+ (Qn ). 2 = M+ + M‚àí + 2l, where 2l counts all the concepts with unequal Hence, M+ sizes of extent and intent (it is even due to the existence of concept (B, A) for each (A, B) with |A| = |B|). Since, (M+ ‚àí 1)M+ is even, M‚àí is even.  
  Table 4. Maximal independence polynomials n Imax (Qn , x) 0 1 2 3 4 5  
  Conclusions  
  We hope the obtained results both can stimulate the interest of FCA practitioners in the problems of combinatorial enumeration in Graph Theory and attract mathematicians with the discovered facts and posed conjectures obtained with the help of concept lattices. The subsequent study of the problem includes further development and performance optimisation of the available FCA-based inventory in connection with tools from Linear Algebra and Generating Functions suitable for larger n, as well as theoretical proofs and reÔ¨Ånements of the posed conjectures and investigation of both the structural properties and analytical (asymptotic) behaviour of the maximal independence polynomials. Acknowledgement. This paper is an output of a research project implemented as part of the Basic Research Program at the National Research University Higher School of Economics (HSE University). This research was also supported in part through computational resources of HPC facilities at HSE University We would like to thank N.J.A. Sloane and OEIS editors for their assistance and the anonymous reviewers for their useful suggestions.  
  and implementation constraints, but has speciÔ¨Åc qualities for knowledge discovery. E.g. Graph-FCA provides concepts highlighting graph patterns shared by tuples, while RCA provides interconnected concept lattices, one per object category. This paper focuses on RCA. RCA is based on a simple input data model composed of objects described by Boolean attributes and unidirectional binary relationships between these objects. Practical application raised the issue of encoding a dataset into this formalism, which was more or less easy according to the dataset model structure, such as converting a ternary relation into binary relations [21]. Similar problems arise for encoding object descriptions with particular attribute values (e.g. numerical) into a formal context made of Boolean ones. The latter can be addressed, for example, using scaling approaches [15] or Pattern Structures [14]. To facilitate access of new users to RCA, capitalizing the experience gained in applying RCA in various existing applications is a need. This paper aims to describe a general approach, to pave the way for the deÔ¨Ånition of design patterns for RCA application. To this end, we present what such design patterns might look like, and give a few illustrations. Section 2 presents basics of RCA, some typical applications, and our motivation for capitalizing the encoding practices as design patterns. Section 3 outlines the design pattern notion, inspired by its deÔ¨Ånition in the Ô¨Åeld of software engineering, and illustrates it through two examples. Section 4 discusses opportunities for developing the approach. We conclude and give a few perspectives of this work in Sect. 5.  
  2  
  x x x x  
  e.g. concept C_Crop_15 that groups wheat and barley for the common attribute cereal (right-hand side lattice of Fig. 1). At the next step, the relational context attacks is used to form relational attributes that express a relation that a pest object may have with a crop concept, such as ‚àÉattacks(C_Crop_15) assigned to Contarinia triciti and Oulema melanopa because they attack at least one crop of C_Crop_15. This causes the creation of concept C_Pest_18, which would not be there without ‚àÉattacks(C_Crop_15) (left-hand side lattice of Fig. 1). The relational attributes can be formed with diÔ¨Äerent quantiÔ¨Åers (e.g. ‚àÉ‚àÄ, ‚äá, or with percentages). The number of iterations depends on the data model. The same process can be applied to more complex datasets, eventually containing circuits.  
  C_Pest_7 attacks(C_Crop_14)  
  A. Braud et al.  
  architect Christophe Alexander [3]. Gamma et al. oÔ¨Äers a catalog of DPs for object-oriented designers to transfer knowledge, in particular from experts to beginners, to help them achieve a good design by choosing among several proven alternatives. In the catalog, four essential parts are highlighted to describe a DP: the pattern name, the problem, the solution, and the consequences. The pattern name is important as it becomes part of a shared vocabulary. Describing the problem involves deÔ¨Åning the context and the favorable conditions of the DP application. The solution describes the diÔ¨Äerent elements that take part to the design in an abstract and conÔ¨Ågurable way. The consequences include predictable eÔ¨Äects of the pattern application and compromises that may have to be done between diÔ¨Äerent qualities of the results. In addition, each DP is described in the catalog using more than ten sections. While some sections are speciÔ¨Åc to objectoriented design (e.g. classes/objects participants, or sample code), others can be adopted for other domains. In this paper, to remain synthetic, the following Ô¨Åve description sections are used: ‚Äì Problem. The problem is expressed in terms of dataset content and analysis objective. As in [13], this is the most tricky part of the description. ‚Äì Solution. For RCA, the solution consists in expressing how to formally design and populate a Relational Context Family from the problem description. ‚Äì Example. This section presents a short example of the pattern application. ‚Äì Known uses. This section reports existing case studies of the literature where the DP has been applied. ‚Äì Consequences. This section reviews alternatives and discusses the consequences of the application of the DP relatively to the analysis objective, in particular in terms of usability/readability of the result. 3.2  
  The Design Pattern Separate/Gather Views  
  Fig. 3. Views on sushis: according to their weight (left-hand side) and their ingredients (right-hand side).  
  Known Uses. This DP has been implemented for the analysis of visual accessibility options in operating systems (OS) in [23]. This analysis had diÔ¨Äerent purposes, including making recommendations to OS developers to design a new version, to assist end-users Ô¨Ånding an accessibility conÔ¨Åguration close to the current conÔ¨Åguration when the OS upgrades, or when end-users have to change OS. In this study, the objects are operating systems (OS) and the views cover three visual accessibility options categories (contrast, text, zoom). Separating the views allows to analyze the OS along a single problematic, e.g. to observe commonly shared contrast options, which OS provides more contrast options than another, or which options are never provided together. Gathering the views classiÔ¨Åes the OS in a global way, e.g. helping identifying which ones are equivalent on all option categories, how they diÔ¨Äer from each other, and how the options of the diÔ¨Äerent categories interact. Moreover, an application has been developed by [18] using this DP to assist Feature location (FL) in Software Product Line Engineering. Consequences. Part of the value of this pattern relies on the relevance of the designed views. It may be more or less complex to determine which set of attributes corresponds to a view, as a single semantics should be associated with this view, e.g. habitat versus food for animals. Note that partitioning attributes participating to diÔ¨Äerent coherent sets is not relevant, e.g. for animals, the Boolean attribute aquatic environment can be an attribute in views natural habitat and growing conditions. An additional interest of using this RCA DP may occur when considering the pattern variation in which an object can have several views, corresponding for instance to diÔ¨Äerent versions. DiÔ¨Äerent quantiÔ¨Åers can thus be used in the diverse relations, e.g. in the Sushis example,  
  Perspectives  
  Section 3 presented two DPs, that were used in concrete applications, focusing on various aspects of relational data, as can be considered in the RCA framework. Several perspectives are oÔ¨Äered by this work. Two of them are discussed in this section, i.e. identifying additional DPs that can be useful to help RCA users and revisiting existing applications. New Opportunities for Defining DPs. Additional DPs were identiÔ¨Åed along the existing applications. A few examples are introduced hereafter. Some data models included a specialization/generalization (is-a) relationship. Analyzing the associated dataset required to Ô¨Çatten the hierarchical descriptions [10,16,19], to discover abstractions previously hidden. This new DP could be named Collapse Specialization. The DP Reify Relation may consist in introducing a formal context in the RCF for describing the tuples of a relation. This approach was used by [21] to derive a binary representation of an N-ary relation, without loosing information. The link reiÔ¨Åcation, as realized in [9] and [4], could be considered through the same perspective. The DP, dual to Separate/Gather Views, is Separate/Gather Objects, in which objects of a same category can be separated into several subsets to analyze each subset apart or all subsets as a whole. This approach was considered by [16] to normalize a UML class model to detect candidate attribute generalizations on diverse criteria, e.g. name, substring in the name, synonyms, type, default value. The DP Instances2Model  
  RCA in Practice  
  may address objects with multi-valued attributes to extract a schema, as it has been done from instance descriptions in [9]. It consists in simplifying the description considering that an object has a value for an attribute (but not the value). Introducing virtual objects representing a Query has been proposed by authors in the context of FCA. This can be extended to the context of RCA, such as in [6], introducing several virtual objects in formal contexts and virtual links in relational contexts. This approach has been adopted for solving the problem of replacing a failing web service in a web service workÔ¨Çow [5]. Finally, sequences can be modeled into RCA input with a transitive relation ‚Äôprecedes‚Äô or ‚Äôsucceeds‚Äô, according to the DP Temporal [28]. Other transitive relations (e.g. part-of/includes, or down/upstream-of [27]) may also correspond to this DP. Revisiting Applications with the DPs. The DP Separate/Gather Views presented in Sect. 3 could be applied to revisit and improve a previous work on component catalog FCA-based building [1], in which software components were described with provided/required interfaces, each interface containing a set of services. In this catalog, the description was made using a single formal context. The catalog then organized the software components with this description and exposed possible substitution between components from the two viewpoints as a whole (provided as well as required services). This hardly helps the lattice exploration considering only one viewpoint, e.g. a user may want to search a component with provided services, and consider in a second step the required services, that other components could provide. Another potential use of the DP Separate/Gather Views could be to consider positive versus negative description of objects, a question that has been addressed in [30], to complete their approach using an additional point of view.  
  5  
  Abstract. The Hasse diagrams of Formal Concept Analysis (FCA) concept lattices have the disadvantages that users need to be trained in reading the diagrams and diagrams of larger lattices tend to be too cluttered to be comprehensible. This paper therefore discusses how to reduce lattices and then represent them with a specific type of Euler diagram instead of Hasse diagrams. A semi-automated process of reducing concept lattices is described and supported by algorithms.  
  3 4  
  The diagrams should not be named after Hasse because he did not invent them, but the name is widely established in the literature. An introduction to FCA is not included in this paper. Standard FCA terminology is used: intension, extension, a cross table for the formal context, and so on. An object concept is the lowest concept which has the object in its extension. Attribute concepts are defined dually. Based on the author‚Äôs personal teaching experience with introductory mathematics courses. Again based on the author‚Äôs teaching experience. ‚ÄúSmall‚Äù in this paper means < 20 concepts.  
  3 Reducing Concept Lattices This section provides a brief summary of methods for reducing concept lattices by offloading information from diagrams and instead storing it as logical expressions. The resulting RD-Euler diagrams then focus on information that is easier to represent graphically whereas the expressions focus on information that is more suited to textual representation. As mentioned in the introduction, the topic of reducing lattices has been discussed in the literature but usually with a focus on special properties or using fuzzy/probabilistic methods. The methods discussed in this section are more general, simple and mostly well-known. But the practical, joint use of diagrams and textual information has not yet received much attention. The assumptions about the data of a given formal context for this paper are: crisp, non-fuzzy data: probability or other approximations are not relevant for this paper. background knowledge may be available providing further relations, groupings, domains and so on for the objects and attributes. three valued logic applies to most formal contexts because a missing cross can either mean that an attribute does not apply or that it is unknown whether it applies.  
  lists O, A, C of objects, attributes, concepts list L of logical statements (e.g. implications) lists OC and AC for the object/attribute concepts 2-dimensional Boolean array J of size |O| √ó |A| for the formal context 2-dimensional Boolean array N of size |C| √ó |C| containing the immediate upper neighbours for each concept (i.e. the edges of the Hasse diagram) The following should be computed:  
  ‚Ä¢ 2-dimensional array P of size |A| √ó |A| computed by pairwise comparison of the column bitvectors of the attributes. Contains: ‚Äúe‚Äù if the two attributes are equal, ‚Äús‚Äù for ‚Äúsmaller not equal‚Äù (i.e. for every 1 of the first there must be a 1 in the second), ‚Äúg‚Äù for ‚Äúgreater not equal‚Äù, ‚Äún‚Äù for negation and ‚Äú0‚Äù otherwise. ‚Ä¢ procedure delete(a) removes an attribute a from A and J and recomputes everything else as required ‚Ä¢ procedure neigh(c) returns the set of upper neighbours of concept c according to N ‚Ä¢ procedure meet(a) returns a (shortest) list of attributes with binary intersection a or NONE. ‚Ä¢ procedure join(a) returns a (shortest) list of attributes with binary union a or NONE. The algorithm SynAndOrNot computes attributes that are reducible with Synonym-, AND-, OR- or NOT-reduction. The algorithm Negate computes NEGATION-reduction. Horizontal splits are computed with the final algorithm. For a lower horizontal split, the algorithm HorizontalSplit is used but is stopped as soon as the immediate upper neighbours of all object concepts have been processed. Then the top concepts are removed from each partition and it is checked whether the partitions remain unchanged if all lower neighbours (apart from the bottom concept) are added to each partition. An Algorithm for Conceptual Partitioning is not provided in detail. Several different steps and strategies can be used to determine which concept extensions are most suitable for partitioning the objects: ‚Ä¢ determine which concepts are supplemental and whether objects should be added to non-supplemental concepts ‚Ä¢ check whether any other reduction methods are applicable ‚Ä¢ run a LOWER HORIZONTAL SPLIT algorithm and determine whether each set of objects corresponds to a concept extension ‚Ä¢ any negatable attribute always partitions the set of objects, therefore identify negatable attributes that partition the set of objects approximately in half (can involve single attributes, but also 2 or 3 attributes) ‚Ä¢ in order to compare all different possibilities of partitioning, determine which one reduces the number of supplemental concepts ‚Ä¢ show different versions to users and ask them which they prefer  
  Representing Concept Lattices with Euler Diagrams  
  Author Index
9. ICFCA_3 conference:
Conferences on Formal Concept Analysis  
 ( Links to proceedings of these conferences.  )  
 ICFCA | CLA | ICCS |  
 ICFCA'23 | in Kassel, July 2023 
  ICFCA'03 | Darmstadt, Germany | CLA'22 | Tallinn, June 2022 
  CLA'05 | Czech Republic 
  CLA'04 | Czech Republic | ICCS'23 | Berlin, Sept. 2023 
  ICCS'22 | M√ºnster, Sept. 2022 
  Other Conferences/Workshops with papers/sessions on FCA  
 IPMU 2022 | Milan, July 2022.
10. ICFEC_0 conference:
IEEE ICFEC 2023  
 Home 
  Sponsors 
    IEEE ICFEC 2023  
  7th IEEE International Conference on Fog and Edge Computing 2023  
  In Conjunction with CCGrid 2023   
  01-04 May, 2023 Bangalore, India  
  IEEE ICFEC 2023  
  In Conjunction with ACM CCGrid 2023   
  01-04 May, 2023 Bangalore, India  
  Bangalore (Bengaluru) is the "Silicon Valley" of India, home to top technology companies from India and globally and a hub for startups. Bangalore is also within driving distance to cultural and UNESCO heritage sites like Hampi, Mysore Palace and Mahabalipuram, and a short flight away from the Taj Mahal in Agra and the beaches of Goa. Bangalore Airport (BLR) has direct air connectivity to major cities in Europe and Asia, and one-hop connectivity to USA and Australia.  
 Important Days  
 January 21, 2023 (Paper Submission Deadline)   
  February 13, 2023 (Notifications)   
  February 14, 2023 (Registration Open)   
  March 16, 2023 (Camera-ready Due)   
  May 01-04, 2023 (Conference Date)    
 Attend  
  Travel Details     
  Travel Grants     
  Camera Ready     
  Preliminary Schedule      
 About  
 ICFEC 2023  
 The 7th IEEE International Conference on Fog and Edge Computing (ICFEC 2023) is a leading forum to disseminate and discuss research activities and results on a broad range of topics in the fields of fog and edge computing. ICFEC 2023 will take place in conjunction with The 23rd International Symposium on Cluster, Cloud and Internet Computing (CCGrid 2023).  
  Fog and edge computing have received much attention by both the research community and the industry in recent years, and are today seen as an alternative to the utilization of cloud-based computational resources. Especially, this is the case in scenarios where large amounts of data are produced in distributed settings, e.g., in the Internet of Things (IoT), where data needs to be processed in (near) real time, or where suboptimal network connectivity hampers the upload of very large amounts of data to the cloud. Use cases for fog and edge computing range from smart factories over smart grids to autonomous vehicles, to name just some examples.  
 Accepted Papers and Program  
  Papers accepted for the 2023 IEEE ICFEC have been published in the IEEE Xplore Digital Library   
  May 03, 2023  
  Amr M. Zaki, Sara A. Elsayed, Khalid Elgazzar and Hossam S. Hassanein 
  May 04, 2023  
 Session II: Machine Learning at the Edge [10:30am-12:30pm] Chair: Sandip Chakraborty  
  Josef Hammer and Hermann Hellwagner 
  All accepted papers will be published by IEEE Computer Society Press (EI-Index) and included in the IEEE Digital Library. For publication, each accepted paper is required to be registered by one of its authors, and at least one author is required to attend and present the paper at the conference for the paper to be included in the final technical program and the IEEE Digital Library.  
 Submission Instructions  
 ICFEC 2023  
  Papers that are accepted for publication may be accepted as REGULAR paper (8 pages) or SHORT papers (5 pages), depending on the reviewer recommendations. Accepted papers will be included in the conference proceedings that will be published through the IEEE Computer Society Conference Publishing Services.  
 Organization  
 ICFEC 2023 Committees  
 General Chairs:  
 We thank our generous sponsors.  
 ICFEC 2023  
 CONTACT  
 SHARE ON SOCIAL MEDIA  
 ¬© Copyright: ICFEC 2023

output:1. ICEC_3 information:
2. ICER_0 information:
3. ICER_1 information:
4. ICER_2 information:
5. ICER_3 information:
6. ICFCA_0 information:
7. ICFCA_1 information:
8. ICFCA_2 information:
9. ICFCA_3 information:
10. ICFEC_0 information:
