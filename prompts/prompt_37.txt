input:
1. CERIAS_1 conference:
www.cerias.purdue.edu 
  Agenda 
  Information | Registration  Poster Archive  Symposium Archive   Travel Information  Campus Map 
  2023 Symposium Posters  
 Posters  > 2023  
 Artificial Intelligence  
  Copyright © 2024, Purdue University, all rights reserved. Purdue University is an equal access/equal opportunity university.  
  If you have trouble accessing this page because of a disability, please contact the CERIAS webmaster at webmaster@cerias.purdue.edu  . Some content on this site may require the use of a special plug-in or application. Please visit our plug-ins page  for links to download these applications.  
  Privacy Policy
2. CERIAS_2 conference:
Events >   Event Details    
 Symposium  
  CERIAS Security Symposium 2023  
 The 24th annual CERIAS Security Symposium will bring together experts and practitioners from all areas of cyber and cyber-physical systems with interests in security, privacy, resiliency, autonomy, trusted electronics, and explainable AI. Attendees will consist of a mix of academic, industry, government and military representatives who are interested in learning new and innovative ways to secure our future. Join us as we celebrate the 25th anniversary of CERIAS!  
 Key Information  
   Download Cyware Social App        
 Terms of Use  Privacy Policy  © 2023
3. CERIAS_3 conference:
28-29    
 CERIAS 2023  
 Hosted by Purdue University  More Info    
 Event Details  
 Tuesday, March 28, 2023  
 Event Description  
 The 24th annual CERIAS Security Symposium will bring together experts and practitioners from all areas of cyber and cyber-physical systems with interests in security, privacy, resiliency, autonomy, trusted electronics, and explainable AI. Attendees will consist of a mix of academic, industry, government and military representatives who are interested in learning new and innovative ways to secure our future. Join us as we celebrate the 25th anniversary of CERIAS!  
 Other Upcoming Events You Might Like  
 Dec  4    
 @ VisionLoft Stutz    
  Dec  11    
 @ Indiana Wesleyan University - Indianapolis North Education and Conference Center    
  Dec  11    
 @ Virtual
4. CGI_0 conference:
Keynote Speakers 
  Presentation Guidelines 
  CGI WORKSHOP/Special Sessions 
  ENGAGE WORKSHOP 
  CGI CHALLENGE | CGI-PSG2023 
  CGI-NFR2023 
  CGI-CCC2023 
  CGI-HRDC2023 
  CGI-CLSLR2023 
  CGI-AIAA2023 
  CGI AWARDS 
  Contact 
 Computer Graphics International 2023    
 Shanghai, China  
 August 28 to September 1, 2023  
 CALL FOR PAPERS   FLYER     
 Registration is now open! We accept Wechat Payment, International and local bank transfer.  Due to some technical issues of our payment system, we have extended the registration deadline for the first round call for papers to the July 15th. We apologize for the inconvenience. Please email vrar@cs.sjtu.edu.cn if you have any concerns.    
 Address: Shanghai Marriott Hotel Pudong East, 15 Xinjinqiao Road, Pudong New  
 Conference Venues are located on the Fifth Floor for the Aug 28th – Aug 31st, the Third Floor for the Sep 1st and Lunch Venues are located on Level 2.    
 About Us  
 COMPUTER GRAPHICS INTERNATIONAL, Shanghai 2023  
 This year, CGI 2023 is organized by Shanghai Jiao Tong University and University of Sydney, and supported by the Computer Graphics Society (CGS), with the assistance of Wuhan Textile University and the STATE KEY LABORATORY OF COMPUTER SCIENCE (SKLCS), CGI 2023 will (hopefully) be held as a hybrid event-allowing both onsite and online participation – in Shanghai. The Visual Computer is the official journal of the Computer Graphics Society.  
 The main topics of the CGI 2023 conference are the following:   
 Rendering Techniques 
  Metaverse (VR/MR/XR) 
  Textures 
 CGI2023 papers can be submitted either on March 17  for possible publication in the journal Visual Computer  or June 12   (extented to June 19 )  for possible publication in a LNSC Proceedings book  published by Springer, or the CAVW  journal (Computer Animation and Virtual Worlds) published by Wiley, or the VRIH  journal (Virtual Reality and Intelligent hardware) publish by Science press.  
 Important Dates  
 Conference, Special sessions, and Workshops, August 28 to September 1, 2023   
 IMPORTANT DATES  
 Submission Deadline | Preliminary Notification to Authors | Deadline to Receive Revised Papers From Authors | Final Notification of Revised Papers 
 Visual Computer | March 10  (extented to March 17), 2023 | April 22, 2023 | May 18, 2023 | June 15, 2023 
 Submission Deadline | Notification of Acceptance | Camera-Ready 
 CGI Proceedings book papers   
  CAVW journal   
  VRIH journal | June 12  (extented to June 19 ) , 2023 | July 13, 2023 | August 5, 2023 
 GENERAL GUIDELINES FOR PAPERS SUBMISSIONS      
 The accepted papers from the second call for papers will be included either in the CGI conference Proceedings published by LNCS, Springer  , or   in the VRIH journal   (Virtual Reality and Intelligent Hardware journal published by Science Press), or  in the CAVW journal   (Computer Animation and Virtual Worlds) published by Wiley.   
 Note that for ALL submissions, the review process is double blind  , which requires the paper and all supplemental materials to be anonymous. Ensure that self-referencing is anonymous (refer to your full name rather than “I” or “we”). Avoid providing information that may identify the authors in the acknowledgements (e.g. co-workers and grant IDs) and in the supplemental material (e.g. titles in the movies, or attached papers). Avoid providing links to websites that identify the authors. Violation of any of these guidelines will lead to rejection without review.   
 Our Team  
  Lei Zhu, The Hong Kong University of Science and Technology, Hong Kong, China  
 Paper Awards Chairs  
 Nadia Magnenat Thalman, MIRALab-University of Geneva, Switzerland  
  Yiyu Cai, Nanyang Technological University, Singapore  
 Follow us on youtube  
 Copyright © 2024 CGI'23 Shanghai –  OnePress  theme by FameThemes
5. CGI_1 conference:
What | Conference 
 When | 2023-08-28  to   
  2023-09-01 
 Where | Shanghai, China 
 Contact Name | Nadia Magnenat Thalmann, Bin Sheng, Jinman Kim 
  About JVRB 
  Editorial Board & Guest Editors 
  Submission 
  Peer Review 
  Imprint 
 « | November 2024 | » 
 Su | Mo | Tu | We | Th | Fr | Sa 
 1 | 2
6. CGI_2 conference:
Join Us 
 CGI’23 Computer Graphics International – August 28 – September 1, Shangai, China  
 Posted on December 18, 2023  December 18, 2023    by cgs-admin      
 This year, CGI 2023 is organized by Shanghai Jiao Tong University and University of Sydney, and supported by the Computer Graphics Society (CGS), with the assistance of Wuhan Textile University and the STATE KEY LABORATORY OF COMPUTER SCIENCE (SKLCS), CGI 2023 will (hopefully) be held as a hybrid event-allowing both onsite and online participation – in Shanghai. The Visual Computer is the official journal of the Computer Graphics Society.  
 More info:  
 Home   
 Recent Posts  
 CGI’24 Computer Graphics International – JULY 1 – 5, Geneva, Switzerland 
  CASA’24Computer Animation and Social Agents – June 5 – 7, Wuhan, China 
  CGI’23 Computer Graphics International – August 28 – September 1, Shangai, China 
  CASA’23 Computer Animation and Social Agents – May 29 – 31, Limassol, Cyprus 
  CGI’22 Computer Graphics International – 12-16 September, Virtual (from Geneva, Switzerland) 
 Archives  
 December 2023
7. CGI_3 conference:
Bin Sheng (Editor)  , Lei Bi (Editor)  , Jinman Kim (Editor)    
 Publish Date:  January 3rd, 2024   
 Publisher:   
 Springer
8. CGO_0 conference:
CGO 2023   Sat 25 February - Wed 1 March 2023 Montreal, Canada    
 Toggle navigation        
  Travel Grants 
  Local Info 
  Program | CGO Program 
  Your Program 
   Sat 25 Feb 
  Sun 26 Feb 
  Mon 27 Feb 
  Tue 28 Feb 
  Wed 1 Mar 
  Tracks | CGO 2023 
  Main Conference 
  Student Research Competition 
  Workshops and Tutorials 
  Artifact Evaluation 
  Organization | CGO 2023 Committees 
  Track Committees 
  Main Conference  Organizing Committee 
  Series | Series 
  CGO 2024 
  CGO 2023 
  CGO 2022 
 Montreal skyline in winter  
 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)  
 February 25th – March 1st, 2023, Montreal, Canada   
 Co-located with  PPoPP  , CC  and HPCA   
 The International Symposium on Code Generation and Optimization (CGO) provides a premier venue to bring together researchers and practitioners working at the interface of hardware and software on a wide range of optimization and code generation techniques and related issues. The conference spans the spectrum from purely static to fully dynamic approaches, and from pure software-based methods to specific architectural features and support for code generation and optimization.  
 Latest News  
 Wed 1 Mar 2023 by Christof Schlaak | CGO 2023 is now closed! | We look forward to seeing you in Edinburgh in 2024, for March 2-6! More information for 2024 will be posted on the website in a couple of weeks. 
  Tue 28 Feb 2023 by Christof Schlaak | Test of Time Award | Ben Hardekopf and Calvin Lin received the test of time award for Flow-Sensitive Pointer Analysis for Millions of Lines of Code  (CGO’11) 
  Tue 28 Feb 2023 by Christof Schlaak | Distinguished Paper Awards | This year’s distinguished papers are: | D2X: An eXtensible conteXtual Debugger for Modern DSLs | by Ajay Brahmakshatriya, Saman Amarasinghe 
  To Pack or Not to Pack: A Generalized Packing Analysis and Transformation | by Caio Salvador Rohwedder, Nathan Henderson, João P. L. De Carvalho, Yufei Chen, Jose Nelson Amaral 
  Tue 28 Feb 2023 by Christof Schlaak | Presentations for the Student Research Competition selected | The selected presentations are: | 3D Flamegraphs for Performance Analysis, Alex Boots 
  A High-Performance Matrix Extension Design for Scaling AI to the Edge, Yen-Po Chen 
  Multiple Function Merging for Code Size Reduction, Yuta Saito 
  Generating Number Theoretic Transforms for Multi-Word Integer Data Types, Naifeng Zhang 
  HTO: “Header”-Time Optimization, William Moses 
  Thu 23 Feb 2023 by Christof Schlaak | Keynotes swapped! | Due to travel issues, the planned keynote for Monday and Wednesday have been swapped. Sorry for any inconvenience. 
 All News Articles     
  Featured News    
 CGO 2023 is now closed! Wed 1 Mar 2023 
 Test of Time Award Tue 28 Feb 2023 
 Distinguished Paper Awards Tue 28 Feb 2023 
 Presentations for the Student Research Competition selected Tue 28 Feb 2023 
 Keynotes swapped! Thu 23 Feb 2023 
 Local Info Thu 23 Feb 2023 
 Call for Participation Thu 19 Jan 2023 
 Complete Program Thu 19 Jan 2023 
 List of Accepted Papers Tue 3 Jan 2023 
 Attendees can now apply for Sat 31 Dec 2022 
   Posts   
 CGO    
  CGO 2023 Tracks   
 Main Conference  | Student Research Competition  | Workshops and Tutorials  | Artifact Evaluation    
  CGO 2023   
   Support page
9. CGO_1 conference:
CGO 2024 
  CGO 2023 
  CGO 2022 
 Las Vegas Night  
 CGO  
 All Editions   
 The International Symposium on Code Generation and Optimization (CGO) provides a premier venue to bring together researchers and practitioners working at the interface of hardware and software on a wide range of optimization and code generation techniques and related issues. The conference spans the spectrum from purely static to fully dynamic approaches, and from pure software-based methods to specific architect ... 
 Sat 2 - Wed 6 March 2024 Edinburgh, United Kingdom  CGO 2024   
 Important Dates Student Travel Grants: January 24, 2024 Early Registration Deadline: February 2, 2024 Conference Period: March 2 – 6, 2024 Register for the conference The International Symposium on Code Generation and Optimization (CGO) provides a premier venue to bring together researchers and practitioners working at the interface of hardware and software ... 
 Sat 25 February - Wed 1 March 2023 Montreal, Canada  CGO 2023   
 February 25th – March 1st, 2023, Montreal, Canada Co-located with PPoPP, CC and HPCA The International Symposium on Code Generation and Optimization (CGO) provides a premier venue to bring together researchers and practitioners working at the interface of hardware and software on a wide range of optimization and code generation techniques and related issues. The conference spans the spectrum from purely static ... 
 Sat 2 - Wed 6 April 2022  CGO 2022   
 April 2nd - April 6th, 2022, Seoul, South Korea Co-located with PPoPP, CC and HPCA &nbsp; Get Whova App &nbsp; Whova Conference Webpage (PC only) CGO 2022 was held as a virtual conference. IEEE Symposium on Code Generation and Optimization (CGO 2022) – Now Taking Place Virtually The safety and well-being of all conference participants is our priority. After evaluating the ongoing COVID-19 situation, th ...
10. CGO_2 conference:
CGO 2023: Proceedings of the 21st ACM/IEEE International Symposium on Code Generation and Optimization  
  Full Citation in the ACM Digital Library    
 SESSION: Keynote  
 PyTorch 2.0: The Journey to Bringing Compiler Technologies to the Core of PyTorch (Keynote)   
 Peng Wu 
  Four and a half years after PyTorch 1.0, we announced PyTorch 2.0 at the PyTorch Conference last December. The message was simple – introducing compiled mode, torch.compile(), to the core of PyTorch. This talk shares our 5-year journey of finding the right compiler solutions for PyTorch. We answer questions like: (i) Why did it take so long? (ii) What was the biggest challenge of designing compiler solutions for PyTorch? (iii) How did we co-design the compiler w/ the core of PyTorch? (iiii) What conventions did we break in the design of TorchDynamo and TorchInductor?  
 As an ML compiler, PyTorch 2.0 is unconventional in many ways. By sharing our thought processes, insights, and design decisions during the development of PT2, we hope to bring new thinking into the thriving landscape of ML compilers and inject a dose of real-world considerations into the research community.  
  Xu Liu 
  Java is the “go-to” programming language choice for developing scalable enterprise cloud applications. In such systems, even a few percent CPU time savings can offer a significant competitive advantage and cost savings. Although performance tools abound for Java, those that focus on the data locality in the memory hierarchy are rare.  
 In this paper, we first categorize data locality issues in Java programs. We then present DJXPerf, a lightweight, object-centric memory profiler for Java, which associates memory-hierarchy performance metrics (e.g., cache/TLB misses) with Java objects. DJXPerf uses statistical sampling of hardware performance monitoring counters to attribute metrics to not only source code locations but also Java objects. DJXPerf presents Java object allocation contexts combined with their usage contexts and presents them ordered by the poor locality behaviors. DJXPerf’s performance measurement, object attribution, and presentation techniques guide optimizing object allocation, layout, and access patterns. DJXPerf incurs only ~8.5% runtime overhead and ∼6% memory overhead on average, requiring no modifications to hardware, OS, Java virtual machine, or application source code, which makes it attractive to use in production. Guided by DJXPerf, we study and optimize a number of Java and Scala programs, including well-known benchmarks and real-world applications, and demonstrate significant speedups.  
 SESSION: Potpourri  
 Mridul Aanjaneya 
  Santosh Nagarakatte 
  This paper proposes fast polynomial evaluation methods for correctly rounded elementary functions generated using our RLibm approach. The resulting functions produce correct results for all inputs with multiple representations and rounding modes. Given an oracle, the RLibm approach approximates the correctly rounded result rather than the real value of an elementary function. A key observation is that there is an interval of real values around the correctly rounded result such that any real value in it rounds to the correct result. This interval is the maximum freedom available to RLibm’s polynomial generation procedure. Subsequently, the problem of generating correctly rounded elementary functions using these intervals can be structured as a linear programming problem. Our prior work on the RLibm approach uses Horner’s method for polynomial evaluation.  
  Anderson Faustino da Silva 
  Fernando M. Quintão Pereira 
  Algorithm classification consists in determining which algorithm a program implements, given a finite set of candidates. Classifiers are used in applications such malware identification and plagiarism detection. There exist many ways to implement classifiers. There are also many ways to implement evaders to deceive the classifiers. This paper analyzes the state-of-the-art classification and evasion techniques. To organize this analysis, this paper brings forward a system of four games that matches classifiers and evaders. Games vary according to the amount of information that is given to each player. This setup lets us analyze a space formed by the combination of nine program encodings; seven obfuscation passes; and six stochastic classification models. Observations from this study include: (i) we could not measure substantial advantages of recent vector-based program representations over simple histograms of opcodes; (ii) deep neural networks recently proposed for program classification are no better than random forests; (iii) program optimizations are almost as effective as classic obfuscation techniques to evade classifiers; (iv) off-the-shelf code optimizations can completely remove the evasion power of naïve obfuscators; (v) control-flow flattening and bogus-control flow tend to resist the normalizing power of code optimizations.  
 WARDen: Specializing Cache Coherence for High-Level Parallel Languages   
 Tyson Loveless 
  Philip Brisk 
  Digital Microfluidic Biochips (DMFBs) have the potential to fundamentally transform biochemical disciplines through automation, miniaturization, and the ability to facilitate repeatable chemical experimentation. Programming DMFBs has historically been accomplished by writing low-level bit manipulations to select which electrodes should activate in sequence. Recent research on high-level programming languages and compilers for DMFBs have begun to address the programmability challenge, but important capabilities such as loading and executing pre-compiled libraries and function calls, are absent from the literature. A primary driver of this oversight is the lack of a memory hierarchy to store physical chemicals off-chip to jump to and from function calls. This paper addresses the complexities involved in compiling function calls within the technology's unique boundaries, and provides a proof-of-concept implementation from language to code generation, with solutions evaluated using a cycle-accurate DMFB simulator as well as physical execution on an open-hardware DMFB.  
 Fine-Tuning Data Structures for Query Processing   
  Alexandru Calotoiu 
  Torsten Hoefler 
  With the rise of specialized hardware and new programming languages, code optimization has shifted its focus towards promoting data locality. Most production-grade compilers adopt a control-centric mindset --- instruction-driven optimization augmented with scalar-based dataflow --- whereas other approaches provide domain-specific and general purpose data movement minimization, which can miss important control-flow optimizations. As the two representations are not commutable, users must choose one over the other. In this paper, we explore how both control- and data-centric approaches can work in tandem via the Multi-Level Intermediate Representation (MLIR) framework. Through a combination of an MLIR dialect and specialized passes, we recover parametric, symbolic dataflow that can be optimized within the DaCe framework. We combine the two views into a single pipeline, called DCIR, showing that it is strictly more powerful than either view. On several benchmarks and a real-world application in C, we show that our proposed pipeline consistently outperforms MLIR and automatically uncovers new optimization opportunities with no additional effort.  
 Parsimony: Enabling SIMD/Vector Programming in Standard Compiler Flows   
  Jungyoon Kwon 
  Bernhard Egger 
  Recent neural accelerators often comprise multiple neural processing units (NPUs) with shared cache and memory. The regular schedules of state-of-the-art scheduling techniques miss important opportunities for memory reuse. This paper presents Flexer, an out-of-order (OoO) scheduler that maximizes instruction-level parallelism and data reuse on such multi-NPU systems. Flexer employs a list scheduling algorithm to dynamically schedule the tiled workload to all NPUs. To cope with the irregular data access patterns of OoO schedules, several heuristics help maximize data reuse by considering the availability of data tiles at different levels in the memory hierarchy. Evaluated with several neural networks on 2 to 4-core multi-NPUs, Flexer achieves a speedup of up to 2.2x and a 1.2-fold reduction in data transfers for individual layers compared to the best static execution order.  
 Pin or Fuse? Exploiting Scratchpad Memory to Reduce Off-Chip Data Transfer in DNN Accelerators   
  Seungwon Lee 
  Hwansoo Han 
  Neural processing units (NPUs) have become indispensable parts of mobile SoCs. Furthermore, integrating multiple NPU cores into a single chip becomes a promising solution for ever-increasing computing power demands in mobile devices. This paper addresses techniques to maximize the utilization of NPU cores and reduce the latency of on-device inference. Mobile NPUs typically have a small amount of local memory (or scratch pad memory, SPM) that provides space only enough for input/output tensors and weights of one layer operation in deep neural networks (DNNs). Even in multicore NPUs, such local memories are distributed across the cores. In such systems, executing network layer operations in parallel is the primary vehicle to achieve performance. By partitioning a layer of DNNs into multiple sub-layers, we can execute them in parallel on multicore NPUs. Within a core, we can also employ pipelined execution to reduce the execution time of a sub-layer. In this execution model, synchronizing parallel execution and loading/storing intermediate tensors in global memory are the main bottlenecks. To alleviate these problems, we propose novel optimization techniques which carefully consider partitioning direction, execution order, synchronization, and global memory access. Using six popular convolutional neural networks (CNNs), we evaluate our optimization techniques in a flagship mobile SoC with three cores. Compared to the highest-performing partitioning approach, our techniques improve performance by 23%, achieving a speedup of 2.1x over single-core systems.  
 PIMFlow: Compiler and Runtime Support for CNN Models on Processing-in-Memory DRAM

output:1. CERIAS_1 information:
2. CERIAS_2 information:
3. CERIAS_3 information:
4. CGI_0 information:
5. CGI_1 information:
6. CGI_2 information:
7. CGI_3 information:
8. CGO_0 information:
9. CGO_1 information:
10. CGO_2 information:
