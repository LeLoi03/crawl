input:
1. ICGSE_0 conference:
ICSSP 2023   Sun 14 - Mon 15 May 2023 Melbourne, Australia    
 co-located with ICSE 2023    
 Toggle navigation        
  Visiting Melbourne 
  Keynotes 
  ICSE 2023 
  Keynotes 
  Melbourne 
  Code of Conduct 
  Diversity and Inclusion Plan 
  Main Conference In-Person Presenter Instructions 
  Main Conference Virtual Presenter Instructions 
  Workshop and Co-Located Event Instructions 
  Visa Letter of Invitation 
  Social Events 
  Recruitment Opportunities at ICSE 2023 
  IEEE Computer Society Open Conference Statement 
  Travel Support 
  Your Program 
  Program Overview 
   Sun 14 May 
  Mon 15 May 
  Calls and Accepted Papers 
  Organization | ICSSP 2023 Committees 
  Organizing Committee 
  Track Committees 
  Search 
  Series | Series 
   ICSSP 2023 
 17th International Conference on Software and System Processes  
 The Schedule   of ICSSP 2023 is up. ICSSP 2023 will feature three Keynotes   from distinguished speakers on topics of AI-Augmented Software Engineering, Business Process Management, and AI-integrated Agile. The list of Accepted Papers   are available. When registering for participation, please select ICSSP under co-located events. We look forward to your participation!  
 Register Now    
  The theme of ICSSP 2023 is Software and System Processes for and with Emerging Technologies  .  
 ICSSP 2023 will be held on 14-15 May 2023  , and co-located with ICSE 2023  .  
 A by-invitation workshop will be held on 13 May 2023  .  
 Please use the contact form  to contact PC Chairs.  
 About ICSSP Conference Series  
 About ICSSP 2023  
 In recent years, innovative software and systems technologies have been rapidly adopted with increasingly widespread but uncertain impacts. These technologies include various forms of AI; big data and data science; blockchain and distributed ledgers; augmented, virtual, and extended reality; low-code/no-code platforms; and even quantum computing (among others). By their novel nature, these new technologies and applications demand new approaches to software and systems development. Beyond that, the novelty and uncertainty surrounding these technologies and applications requires new and more effective approaches and processes to assuring correctness, understandability, predictability, responsibility, security, ethics and other vital qualities of our software and systems.  
 At the same time, many of these new technologies may have applications within the software life cycle. So the question naturally arises, can we put technologies such as AI, blockchain, low code, and big data, to work in improving our ability to develop, manage, and apply new software and systems applications. We can even ask whether it will become essential to do so.  
 ICSSP 2023 is focusing on software and systems processes for and with these new technologies, as well as on incorporating these new technologies into new modes of working in software and systems development for business, government, society, and the environment. ICSSP 2023 aims to bring together researchers and practitioners to share their research findings, experiences, and new ideas on diverse topics related to software and system processes. For 2023, the theme of the conference is: " Software and System Processes for and with Emerging Technologies  ". The goal is to advance both the state of the research and the state of the practice by applying innovative ideas from different fields of research to the future of software and system engineering processes.  
  ICSSP 2023   
 17th International Conference on Software and System Processes    
  ICSSP 2023   
  contact form    
   Support page    
 ICSSP 2023  
 ICSSP 2023    
 Attending  
  Code of Conduct   
  Diversity and Inclusion Plan   
  Main Conference In-Person Presenter Instructions   
  Main Conference Virtual Presenter Instructions   
  Workshop and Co-Located Event Instructions   
  Visa Letter of Invitation   
  Social Events   
  Recruitment Opportunities at ICSE 2023   
  IEEE Computer Society Open Conference Statement   
  Travel Support
2. ICGSE_1 conference:
ICSSP 2023   Sun 14 - Mon 15 May 2023 Melbourne, Australia    
 co-located with ICSE 2023    
 Toggle navigation        
 Series 
  ICSSP 2023 
  All Editions | ICSSP 2023 
 All Editions   
 Sun 14 - Mon 15 May 2023 Melbourne, Australia  ICSSP 2023  with ICSE 2023    
 The Schedule of ICSSP 2023 is up. ICSSP 2023 will feature three Keynotes from distinguished speakers on topics of AI-Augmented Software Engineering, Business Process Management, and AI-integrated Agile. The list of Accepted Papers are available. When registering for participation, please select ICSSP under co-located events. We look forward to your participation! Register Now new! TechDebt &amp; ICS ... 
 Organizing Committee (ICSSP 2023)   
 Liming Zhu General Chair
3. ICGSE_2 conference:
Prioritizing trust in a globally distributed software engineering team to overcome complexity and make releases a non-event | IEEE Conference Publication | IEEE Xplore                       
 IEEE Account
4. ICGSE_3 conference:
Conference Paper  PDF Available  Using Scrum in Global Software Development: A Systematic Literature Review  
 Content uploaded by Hye-young Paik    
 Author content    
 All content in this area was uploaded by Hye-young Paik   
 these papers to  identify various challenges of  using Scrum in   
 GSD. Current strategies  to deal with the identified challenges   
 have  also  been ext  racted.  This  paper  presents  the  review’s   
 findings  that are expected  to   help  researchers and practiti  oners   
 to  understand the challenges  in  volved  in  using Scrum f  or  GSD   
 been closely researched yet [2].   
 Agile  Software  Development  (ASD)  paradigm  has   
 gained  significant attention  due to  its flexible  approach to   
 managing  the  requirement  volatilit  y  and  emphasis  on   
 extensive collaboration  between customers and  developers   
 the  practitione  rs  and re  searchers  to investigate  the  relevant   
 experiences reported  in th  e literature to  learn  how agile   
 practices  can be effecti  vely  used  in  GSD  projects.  Due to   
 the  fact  t  hat  agile  practices  are  b  ased  on  the philosophy of   
 close,  frequent  and  collocated  collaborations,  the   
 presented in  Section  IV.  Section V  discusses  the  findings to   
 draw some conclusions. The limitations of the study are   
 mentioned in Section VI. Section VII closes t  he paper with a   
 brief discussion of the  researchable issues on t  his topic.   
 II.  B    
 attend sprint review  meetings to  review the  state of  the   
 business,  the  market  and  technology.  These  meetings  could   
 also last up to 4 hours. A retrospective  meeting may be   
 scheduled to assess the teamwork in the completed sprin  ts. A   
 daily  Scrum  meeting  b  y  a  Scrum  team  is  a  15-minute  long   
 [4].  For  this  reason  we  have  decided  to  explore,  investigate   
 and  explain  various  challenging  factors  that  restrict  the  use   
 of  Scrum  pr  actices  due  to  t  he  global  project  .  Current   
 strategies to reduce these challenging factors are also be   
 explored.   
 synthesis,  and  reporting  the r  esults.  We  followed  all  these   
 steps for  the reported study  as described in  the following   
 sections of this paper.   
 The  broad  objective  of  this  stud  y  is  to  answer  the   
 following research question.   
 clearly  that   the  articles  w  ere  outside the scop  e  of the SLR   
 However,  a  paper’s  title  may  not  alwa  ys  represent  the   
 abstracts among thr  ee researchers in su  ch a way so that  each   
 papers for stage 4 of the selection  process.   
 C.  Final Selection    
 We  used  the following  screening criteria  to ensure  the   
 papers address our research topic  .   
 1.  Does  a paper  address  the  use of  any  Scrum pract  ices in    
 distributed projects?   
 2.  Does  a paper discuss any real life experience of using    
 Scrum practices in distributed projects  ?   
 As there  is a l  ack of existing  empirical r  esearch, we  also   
 that ad  dress the  use  of  Scrum  practice in  GSD  projects.  For   
 additional quality assessment, we included following two   
 criteria related to the quality of each  paper’s description.   
 3.  Does the objective of the paper is  clearly mentioned?    
 4.  Does  the  pa  per  discuss  GSD  project  contextual   factors    
 adequately?   
 was measured  based on  the GSE  background info  rmation as   
 shown in Appendix B. These  4 points provided a meas  ure of   
 the  ext  ent  to which  we  are  confi  dent  that   a selected  paper   
 could  ma  ke  a  valuable  contribution  to  understand  the   
 current use of Scrum  practices in distribute  d setting. Each of   
 papers  that  discussed  some  other  agile  m  ethods  and   
 practices  (e.g.  XP,  p  air  programming).  Among  t  he  21   
 papers,  we  found  that  one  journal  paper  [S1]  was  an   
 extended  versio  n  of  p  reviously  published conference pa  per   
 [S1a].  We  also  found  th  at  two  papers  [S3]  and  [S3a]   
 comprehensive recently published papers  as mentioned in   
 appendix A.  In  addition,  one researcher went  thro  ugh the   
 reference list o  f every selected pap  er of this final  stage. This   
 helped  us  to  i  dentify  an  y  r  elevant  paper  that  was  not   
 extracted  by  our  search  strategy.  In  this  proces  s,  we   
 identified on  e journal  paper  [S8]  that  was  not  retrieved   
 through  our  search  of  electronic  databases  but  was  cited  by   
 some of  the s  elected papers  [S1,  S4]. Th  e abstract  was   
 reviewed  by  two  resear  chers  independently  and  agreed  t  hat   
 the  paper  [S8]  appeared t  o b  e  within  the  scope  of  the   
 research.  Finall  y we  selected  20  papers  (e  xcluding  two   
 repeated pap  ers S1a  and  S3a  and  including  one  journal   
 paper  S8  from  initially  selected  21  papers)  for  data   
 extraction  and  synthesis  phases.  We  have  enlisted  the   
 selected primary studies in Appendi  x A.   
 D.  Data Extraction and Synthesis    
 From the final selected studies  , we extracted data using a   
 pre-defined  d  ata  extraction   form  as  shown in  Appendix  B.   
 The detail description  of the  data extraction form  can be   
 address our research questions.   
 We synthesized the  data by i  dentifying themes em  anating   
 from  the  findings  reported  in  each  of  the  paper  reviewed  in   
 this  study.  In  t  he  following  section,  we  present  frequencies   
 of t  he  number  of ti  mes  each the  me i  s id  entified  in d  ifferent   
 synthesized  o  verview  of  the  literature   on  using  Scrum   
 practices in different  distributed projects.    
 1)  RQ1-Challenges  of  Using  Scrum  Due   to  Project    
 Distribution   
 We have identified sixt  een papers that can  help us to   
 ISTRIBUTION   
 Challenging factors  Paper referenc  es  Frequency   
 (#  of   
 confusion  am  ong  team members.  This  SLR  has  f  ound  that   
 some Scrum t  eams could n  ot conduct effective  retrospective   
 meetings  due to t  he  socio-cultural distance i  nvolved  in the   
 distributed project  [S1, S7].  Communication   networks ca  n   
 also  be slow an  d  unreliable with poo  r  transmission quality   
 Scrum within a local team [S17]. Scrum teams also use   
 strict communication policy (e.g. E-mail repl  y within 12   
 hours) to avoid delay due to t  he temporal distance of a   
 distributed team  [S9]. Instead  of whole  team presence  in the   
 late night  (or earl  y morning) Scru  m meetings,  only key   
 ensures  that  a  Scrum  team  with  distribut  ed  project   
 stakeholders  is  sup  ported  with  various  options  of   
 communication  tools  s  uch  as  phone,  web  camera,   
 teleconference,  video  con  ference,  web  conference,  n  et   
 meeting, email,  shared mailing  list, Instant  Message (IM),   
 used strategy for managing a l  arge distributed team that   
 considered using S  crum is  to  split  into small manageable   
 sub-teams  [S1-2,  S5].  Thus,  a  large  GSD  project  may   
 contain  a  number  of  Scrum  teams  (or  sub  teams)  and  some   
 of  the  Scrum  teams  may  als  o  be  geographic  ally  distributed   
 teams are  cr  oss-functional with  team members  distributed   
 across geo  graphical l  ocations.  This  type o  f Scrum  team   
 should  consider  the ris  ks due  to  geographical,  temporal  and   
 socio-cultural distances. In this m  odel, all team members   
 should  attend  and  participate  in  every  Scrum  meeti  ng   
 using agile practices in  general and Scrum p  ractices in   
 particular in the context of GSD.   
 Conclusion  2. The  use  of  Scrum  practices  may be  limited    
 by various GSD project’s contextual  factors.   
 processes.   
 Our  review  findings  reveal  th  at  the  tempor  al,   
 geographical  and  socio-cultural  dist  ances  due  to  the  project   
 stakeholder’s distributi  on cause a  number of  challenging   
 factors  that  impact  GSD  communication, coordination  and   
 thorough selectio  n process  and in  volved two r  esearchers   
 cross checkin  g the  completeness  of searchers  and vali  dating   
 the suitability of each paper for inclusion.  However, the   
 [S4]  J.  Cho,  “Distributed  Scrum  for  Large-Scale  and   
 Mission-Critical Projects,” in Proce  edings of the Conference   
 [S5]  W.  Williams,  M.  Stout,  “Colossal,  Scattered,  and   
 [S9] M.  Vax, S. Michaud,  “Dist  ributed Agile:  Grow  ing a   
 Practice Together”  in Proc  eedings of th  e Conference on   
 [S10]  H.  Smits,  “Implementing  Scrum  in  a  Distrib  uted   
 [S11]  B. Jensen  , A.  Zilmer,  “Cross-  continent  Development   
 using Scrum  and XP” in  Proceedings of  t  he Conference on   
 [S14] A.  Danait,  “Agile o  ffshore techniques-  A  case Stud  y”   
 in proceedings of the Conference on Agile Development   
 [S15]  M.  Summers,  “Insights  into  an  Agile  Adventure  with   
 Offshore Partners,” in Proceedings of the Conference on   
 [S16] E.  Therrien,  “Overcoming  the  Challenges of  Building   
 Appendix B. Data Extraction fo  rm   
 Paper description:   
 1.  Paper identifier: Unique id for th  e paper    
 2.  Date of data extraction:    
 3.  Bibliographic reference: Author,  year, title, source    
 4.  Type  of  article:  Journal  article/conference  paper/    
 workshop paper/unclear   
 5.  Paper aims: what were the aims of thi  s paper?    
 6.  Paper  E  vidence:  empirical  study/experien  ce    
 report/unclear   
 of Scrum practices.   
 4.  Subjective  evaluation:  a  small sum  mary of  the  findings    
 from the paper.   
 A   
 [8]  Ambler,  S.:   Agile  Practice  and  Principles  Survey:  July   
 Article    
 Full-text available    
 Aug 2024 
 Oscar Díaz 
 Article    
 Sep 2024 
 Mateeh Ullah 
  Abdullah Asim 
 The main aim is to improvement in the quality of image, perform other operation, extraction of information and to classify the image while doing image processing. It is effectively used in computer, medical and other related fields. The main problem is that it is generally a time-consuming process; Parallel computing (parallelism) provides an efficient and convenient way to address this issue. There are many challenges in Image processing like Filtering, Restoration and classification etc. In addition, it is also a time-consuming process. The solution of these challenges is to use a parallel computing technique known as parallel image processing. The main focus of this paper is to review and to provide the comparative study of the existing contributions of tools and techniques of parallel image processing and analysis between different technique which are MATLAB, CUDA, BIONIC, Hadoop and GPU (graphic Processing Unit) along with limitation and advantage of these tools and techniques. In this review, we also tried to discuss the architecture of these parallel image processing techniques.    
 View     
 Chapter    
 Full-text available    
 Sep 2024 
 Krzysztof Woźniak 
 Article    
 Nov 2024 
  NUCL ENG DES 
 Article    
 Oct 2024 
 Ashraf Bany Mohammed 
 Article    
 Oct 2024 
 Mansurali Anifa 
 Article    
 May 2024 
 А.О. Пілюков 
 Article    
 Full-text available    
 May 2024 
 Meghna P Desai 
 Chapter    
 Mar 2024 
 Fernando Gonzalez-Aleu 
 Show abstract      
 Memorias del V Congreso internacional de investigación aplicada “Ecosistemas digitales” VIII Simposio internacional de ciencia innovación y tecnología (2023)    
 Article    
 Full-text available    
 Dec 2023 
 Servicio Nacional de Aprendizaje SENA 
 Incorporating social software into distributed agile development environments    
 Conference Paper    
 Full-text available    
  Filippo Lanubile 
 The use of social software applications, such as wikis and blogs, has emerged as a practical and economical option to consider as global teams may use them to organize, track, publish their work, and then, share knowledge. We intend to push further the application of social software principles and technologies into collaborative development environments for agile and distributed projects. As a first step, in this paper we first present a survey of social software, as well as tools and environments for collaborative development. Then, we present some opportunities and challenges of incorporating social software aspects in agile distributed development.    
 View     
 Adopting Agile in Distributed Development    
 Conference Paper    
  J. Jagadish Shrinivasavadhani 
 Key challenges of finding right skilled resources and the cost arbitrage factors have made distributed software development indispensable for quite some time now. The success stories of many offshore service providers particularly from India underlines the fact that this is working well in a "hands-free" mode, especially for projects following traditional development life cycles. The recent trend is an increase in the number of organizations adopting agile methodologies to tackle the challenges of requirements volatility and shorter time to market. However, the concept of a collocated team which is central to agile does not easily translate to distributed development. This paper captures our experience at Wipro in handling Distributed Agile projects. We discuss a validated model to make a smooth transition from a collocated to a distributed scenario in agile projects. We also share the lessons learnt and best practices that we have gained in implementing this model.    
 View     
 View     
 Outsourcing and Offshoring with Agility: A Case Study (Experience Paper).    
 Conference Paper    
 Discover more    
 Conference Paper    
 Full-text available    
 View full-text    
 Conference Paper    
 Full-text available    
  Hye-young Paik 
  June M. Verner 
  There is growing interest in applying agile practices in Global Software Development (GSD) projects. But project stakeholder distribution in GSD creates a number of challenges that make it difficult to use some agile practices. Moreover, little is known about what the key challenges or risks are, and how GSD project mangers deal with these risks while using agile practices. We conduct a ... [Show full abstract]  Systematic Literature Review (SLR) following existing guidelines to identify primary papers that discuss the use of Scrum practices in GSD projects. We identify key challenges, due to global project distribution, that restrict the use of Scrum and explore the strategies used by project managers to deal with these challenges. Our findings are consolidated into a conceptual framework and we discuss various elements of this framework. This research is relevant to project managers who are seeking ways to use Scrum in their globally distributed projects.    
 View full-text    
 Conference Paper    
 Full-text available    
  Paul L. Bannerman 
  R. Jeffery 
  Project stakeholder distribution in Global Software Development (GSD) is characterized by temporal, geographical and socio-cultural distance, which creates challenges for communication, coordination and control. Practitioners constantly seek strategies, practices and tools to counter the challenges of GSD. There is increasing interest in using Scrum in GSD even though it originally assumed ... [Show full abstract]  collocation. However, empirically, little is known about how Scrum practices respond to the challenges of GSD. This paper develops a research framework from the literature as a basis for future research and practice. The framework maps current knowledge and views on how Scrum practices can be used to mitigate commonly recognized challenges in GSD. This research is useful as a reference guide for practitioners who are seeking to understand how Scrum practices can be used effectively in GSD, and for researchers as a research framework to validate and extend current knowledge.    
 View full-text    
 Conference Paper    
 Towards a Framework for Using Agile Approaches in Global Software Development
5. ICGT_0 conference:
ICGT 2023   Wed 19 - Thu 20 July 2023 Leicester, United Kingdom    
 co-located with STAF 2023    
 Toggle navigation        
 Attending | Venue: College Court, Leicester, UK 
  STAF 2023 
  Cultural Activities 
  Instructions for Presenters, Participants, and Chairs 
  Social Events 
  History 
  Program | ICGT Program 
  Your Program 
  Proceedings 
   Wed 19 Jul 
  Thu 20 Jul 
  Tracks | ICGT 2023 
  Research Papers 
  Journal-First 
  STAF 2023 
  Keynotes 
  Organization | ICGT 2023 Committees 
  Steering Committee 
  Track Committees 
  Series | Series 
  ICGT 2024 
  ICGT 2023 
  ICGT 2022 
 Leicester, UK  
 ICGT 2023  
 The 16th International Conference on Graph Transformation (ICGT 2023)  will be held in Leicester, UK, as part of STAF 2023  (Software Technologies: Applications and Foundations). The conference takes place under the auspices of EASST, EATCS  , and IFIP WG 1.3  .  
 Aims and Scope   
 The use of graphs and graph-like structures as a formalism for specification and modelling is widespread in all areas of computer science as well as in many fields of computational research and engineering. Relevant examples include software architectures, pointer structures, state space and control/data flow graphs, UML and other domain-specific models, network layouts, topologies of cyber-physical environments, quantum computing and molecular structures. Often, these graphs undergo dynamic change, ranging from reconfiguration and evolution to various kinds of behaviour, all of which may be captured by rule-based graph manipulation. Thus, graphs and graph transformation form a fundamental universal modelling paradigm that serves as a means for formal reasoning and analysis, ranging from the verification of certain properties of interest to the discovery of fundamentally new insights.  
 ICGT aims at fostering exchange and collaboration of researchers from different backgrounds working with graphs and graph transformation, either in contributing to their theoretical foundations or by applying established formalisms to classical or novel areas. The conference not only serves as a well-established scientific publication outlet, but also as a platform to boost inter- and intra-disciplinary research and to leeway for new ideas.  
 Quick Links   
 ICGT’23 Programme 
  Attending: | Cultural Activities | , | Registration | , | Social Events 
  Tracks: | Keynotes | , | Research Papers | , | Journal-First 
  Fri 2 Jun 2023 by Chris Poskitt | ICGT'23 Programme | The ICGT’23 programme  is now online – we are looking forward to seeing your talks in-person this July! Please be sure to register  before the early-bird deadline (14th June) if you haven’t done so already. 
 All News Articles     
  ICGT 2023 Tracks   
 Research Papers  | Journal-First  | Keynotes    
  Featured News    
 ICGT'23 Proceedings Now Online Mon 17 Jul 2023 
 ICGT'23 Programme Fri 2 Jun 2023 
 ICGT'23 Accepted Papers Sat 13 May 2023 
 Supporters   
  ICGT 2023   
  contact form    
  Journal-First   
  STAF 2023  
 Keynotes
6. ICGT_1 conference:
Members 
 ICGT 2023 - CALL FOR PARTICIPATION  
 16th International Conference on Graph Transformation (ICGT 2023)  
 19-20 July in Leicester, UK, as part of STAF 2023  
 ABOUT   
 The International Conference on Graph Transformation aims at fostering exchange and collaboration of researchers from different backgrounds working with graphs and graph transformation, either in contributing to their theoretical foundations or by applying established formalisms to classical or novel areas. The conference not only serves as a well-established scientific publication outlet, but also as a platform to boost inter- and intra-disciplinary research and to leeway for new ideas. The 16th International Conference on Graph Transformation (ICGT 2023) will be held in Leicester, UK, as part of STAF 2023 (Software Technologies: Applications and Foundations). The conference takes place under the auspices of EASST, EATCS and IFIP WG 1.3. Proceedings will be published by Springer in the Lecture Notes in Computer Science (LNCS) series.  
 REGISTRATION   
 KEYNOTES   
 We are delighted to announce two keynote speakers at ICGT'23:  
 Dan Ghica, Huawei Research and University of Birmingham (UK)
7. ICGT_2 conference:
ICGT 2024 
  ICGT 2023 
  ICGT 2022 
  Sign up 
 ICGT  
 All Editions   
 Wed 10 - Thu 11 July 2024 Enschede, Netherlands  ICGT 2024  with STAF 2024    
 The 17th International Conference on Graph Transformation (ICGT 2024) will be held in Enschede, the Netherlands, as part of STAF 2024 (Software Technologies: Applications and Foundations). The conference takes place under the auspices of EASST, EATCS, and IFIP WG 1.3. Aims and Scope The use of graphs and graph-like structures as a formalism for specification and modelling is widespread in all areas of computer ... 
 Wed 19 - Thu 20 July 2023 Leicester, United Kingdom  ICGT 2023  with STAF 2023    
 The 16th International Conference on Graph Transformation (ICGT 2023) will be held in Leicester, UK, as part of STAF 2023 (Software Technologies: Applications and Foundations). The conference takes place under the auspices of EASST, EATCS, and IFIP WG 1.3. Aims and Scope The use of graphs and graph-like structures as a formalism for specification and modelling is widespread in all areas of computer science as w ... 
 July 2022, Nantes, France  ICGT 2022
8. ICGT_3 conference:
ICGT 2023   Wed 19 - Thu 20 July 2023 Leicester, United Kingdom    
 co-located with STAF 2023    
 Toggle navigation        
 Attending | Venue: College Court, Leicester, UK 
  STAF 2023 
  Cultural Activities 
  Instructions for Presenters, Participants, and Chairs 
  Social Events 
  History 
  Program | ICGT Program 
  Your Program 
  Proceedings 
   Wed 19 Jul 
  Thu 20 Jul 
  Tracks | ICGT 2023 
  Research Papers 
  Journal-First 
  STAF 2023 
  Keynotes 
  Organization | ICGT 2023 Committees 
  Steering Committee 
  Track Committees 
  Series | Series 
  ICGT 2024 
  ICGT 2023 
  ICGT 2022 
  Sign up 
  STAF 2023  ( series  ) /   ICGT 2023  ( series  ) /  History  
 Past ICGT Conferences   
  ICGT 2023   
  contact form    
  Journal-First   
  STAF 2023  
 Keynotes
9. ICIAP_0 conference:
Skip to navigation     
   ICIAP 2023   Home | Past editions 
  People 
  Calls | Call for Papers 
  Call for Tutorials 
  Call for Workshops 
  Submission 
  Registration 
  Programme | Proceedings 
  Social events 
  ICIAP 2023     
 Home | Past editions 
  People 
  Call for Tutorials 
  Call for Workshops 
  Submission 
  Registration 
  Programme | Proceedings 
  Call for Tutorials 
  Call for Workshops 
  Submission 
  Registration 
  Programme | Proceedings 
  Social events 
 ICIAP 2023 is the 22nd edition of a series of conferences organised biennially by CVPL, the Italian Member Society of the International Association for Pattern Recognition (IAPR).   
 The focus of the conference is on both classic and recent trends in computer vision, pattern recognition and image processing, and covers both theoretical and applicative aspects, with particular emphasis on the following topics:   
 Pattern Recognition 
  Computer Vision for UAVs 
  Brave New Ideas 
  ICIAP 2023  will be held in Udine, Italy on  11-15th September, 2023  .   
 The conference is structured in oral and poster sessions and offers invited lectures from distinguished speakers. Satellite  workshops  and  tutorials  are also organised.   
 Dates    
 Paper Submission 1st round:  15 February   24  February  2023 
  Notifications to Authors 1st round: 15 April 2023 
  Paper Submission 2nd round:  1 May 2023   15 May 2023 
  Notifications to Authors 2nd round: 1 July 2023 
  Camera Ready papers due: 15 July 2023 
  Main Conference: 12-14 September 2023 
  Workshop 11 September 2023 
  Tutorials: 15 September 2023 
   www.ccicongress.com    
 ICIAP 2023 - @ICIAP2023 - #ICIAP2023     
 © 2023 - ICIAP 2023 | 22nd International Conference on Image Analysis and Processing -  Privacy Policy   -  Safe event     
 Google Sites
10. ICIAP_1 conference:
Image Analysis and Processing – ICIAP 2023 | springerprofessional.de  Skip to main content    Menü   Fachgebiete Chevron down icon     Chevron up icon        Automobil + Motoren    Bauwesen + Immobilien    Business IT + Informatik    Elektrotechnik + Elektronik    Energie + Nachhaltigkeit    Finance + Banking    Management + Führung    Marketing + Vertrieb    Maschinenbau + Werkstoffe    Versicherung + Risiko      
 DE     
 nach oben    
 2023 | Buch  
 Kapitel lesen  Erstes Kapitel lesen     
 Image Analysis and Processing – ICIAP 2023  
 22nd International Conference, ICIAP 2023, Udine, Italy, September 11–15, 2023, Proceedings, Part I  
 herausgegeben von: Gian Luca Foresti, Andrea Fusiello, Edwin Hancock   
 Jia Cheng Hu, Roberto Cavicchioli, Alessandro Capotondi   
 Shallow Camera Pipeline for Night Photography Enhancement  
 Target-Driven One-Shot Unsupervised Domain Adaptation  
  In this paper, we introduce a novel framework for the challenging problem of One-Shot Unsupervised Domain Adaptation (OS-UDA), which aims to adapt to a target domain with only a single unlabeled target sample. Unlike existing approaches that rely on large labeled source and unlabeled target data, our Target-Driven One-Shot UDA (TOS-UDA) approach employs a learnable augmentation strategy guided by the target sample’s style to align the source distribution with the target distribution. Our method consists of three modules: an augmentation module, a style alignment module, and a classifier. Unlike existing methods, our augmentation module allows for strong transformations of the source samples, and the style of the single target sample available is exploited to guide the augmentation by ensuring perceptual similarity. Furthermore, our approach integrates augmentation with style alignment, eliminating the need for separate pre-training on additional datasets. Our method outperforms or performs comparably to existing OS-UDA methods on the Digits and DomainNet benchmarks.  
 Julio Ivan Davila Carrazco, Suvarna Kishorkumar Kadam, Pietro Morerio, Alessio Del Bue, Vittorio Murino   
 Combining Identity Features and Artifact Analysis for Differential Morphing Attack Detection  
  Due to the importance of the Morphing Attack, the development of new and accurate Morphing Attack Detection (MAD) systems is urgently needed by private and public institutions. In this context, D-MAD methods, i.e. detectors fed with a trusted live image and a probe tend to show better performance with respect to S-MAD approaches, that are based on a single input image. However, D-MAD methods usually leverage the identity of the two input face images only, and then present two main drawbacks: they lose performance when the two subjects look alike, and they do not consider potential artifacts left by the morphing procedure (which are instead typically exploited by S-MAD approaches). Therefore, in this paper, we investigate the combined use of D-MAD and S-MAD to improve detection performance through the fusion of the features produced by these two MAD approaches.  
 Nicolò Di Domenico, Guido Borghi, Annalisa Franco, Davide Maltoni   
 SynthCap: Augmenting Transformers with Synthetic Data for Image Captioning  
  Image captioning is a challenging task that combines Computer Vision and Natural Language Processing to generate descriptive and accurate textual descriptions for input images. Research efforts in this field mainly focus on developing novel architectural components to extend image captioning models and using large-scale image-text datasets crawled from the web to boost final performance. In this work, we explore an alternative to web-crawled data and augment the training dataset with synthetic images generated by a latent diffusion model. In particular, we propose a simple yet effective synthetic data augmentation framework that is capable of significantly improving the quality of captions generated by a standard Transformer-based model, leading to competitive results on the COCO dataset.  
 Davide Caffagni, Manuele Barraco, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara   
 FERMOUTH: Facial Emotion Recognition from the MOUTH Region  
  People use various nonverbal communicative channels to convey emotions, among which facial expressions are considered the most important ones. Consequently, automatic Facial Expression Recognition (FER) is a crucial task for enhancing computers’ perceptive abilities, particularly in human-computer interaction. Although state-of-the-art FER systems can identify emotions from the entire face, situations may arise where occlusions prevent the entire face from being visible. During the COVID-19 pandemic, many FER systems have been developed for recognizing emotions from the eye region due to the obligation to wear a mask. However, in many situations, the eyes may be covered, for instance, by sunglasses or virtual reality devices. In this paper, we faced the problem of developing a FER system that solely considers the mouth region and classifies emotions using only the lower part of the face. We tested the effectiveness of this FER system in recognizing emotions from the lower part of the face and compared the results to a FER system trained on the same datasets using the same approach on the entire face. As expected, emotions primarily associated with the mouth region (e.g., happiness, surprise) were recognized with minimal loss compared to the entire face. Nevertheless, even though most negative emotions were not accurately detected using only the mouth region, in cases where the face is partially covered, this area may still provide some information about the displayed emotion.  
 Berardina De Carolis, Nicola Macchiarulo, Giuseppe Palestra, Alberto Pio De Matteis, Andrea Lippolis   
 Towards Facial Expression Robustness in Multi-scale Wild Environments  
  Facial expressions are dynamic processes that evolve over temporal segments, including onset, apex, offset, and neutral. However, previous works on automatic facial expression analysis have mainly focused on the recognition of discrete emotions, neglecting the continuous nature of these processes. Additionally, facial images captured from videos in the wild often have varying resolutions due to fixed-lens cameras. To address these problems, our objective is to develop a robust facial expression recognition classifier that provides good performance in such challenging environments. We evaluated several state-of-the-art models on labeled and unlabeled collections and analyzed their performance at different scales. To improve performance, we filtered the probabilities provided by each classifier and demonstrated that this improves decision-making consistency by more than 10%, leading to accuracy improvement. Finally, we combined the models’ backbones into a temporal-sequence classifier, leveraging this consistency-performance trade-off and achieving an additional improvement of 9.6%.  
 David Freire-Obregón, Daniel Hernández-Sosa, Oliverio J. Santana, Javier Lorenzo-Navarro, Modesto Castrillón-Santana   
 Depth Camera Face Recognition by Normalized Fractal Encodings  
 Tomaso Fontanini, Claudio Ferrari, Massimo Bertozzi, Andrea Prati   
 Improved Bilinear Pooling for Real-Time Pose Event Camera Relocalisation  
  Traditional methods for estimating camera pose have been replaced by more advanced camera relocalization methods that utilize both CNNs and LSTMs in the field of simultaneous localization and mapping. However, the reliance on LSTM layers in these methods can lead to overfitting and slow convergence. In this paper, a novel approach for estimating the six degree of freedom (6DOF) pose of an event camera using deep learning is presented. Our method begins by preprocessing the events captured by the event camera to generate a set of images. These images are then passed through two CNNs to extract relevant features. These features are multiplied using an outer product and aggregated across different regions of the image after adding L2 normalization to normalize the combining vector. The final step of the model is a regression layer that predicts the position and orientation of the event camera. The effectiveness of this approach has been tested on various datasets, and the results demonstrate its superiority compared to existing state-of-the-art methods.  
 Ahmed Tabia, Fabien Bonardi, Samia Bouchafa   
 A Large-scale Analysis of Athletes’ Cumulative Race Time in Running Events  
  Action recognition models and cumulative race time (CRT) are practical tools in sports analytics, providing insights into athlete performance, training, and strategy. Measuring CRT allows for identifying areas for improvement, such as specific sections of a racecourse or the effectiveness of different strategies. Human action recognition (HAR) algorithms can help to optimize performance, with machine learning and artificial intelligence providing real-time feedback to athletes. This paper presents a comparative study of HAR algorithms for CRT regression, examining two important factors: the frame rate and the regressor selection. Our results indicate that our proposal exhibits outstanding performance for short input footage, achieving a mean absolute error of 11 min when estimating CRT for runners that have been on the course for durations ranging from 8 to 20 h.  
 David Freire-Obregón, Javier Lorenzo-Navarro, Oliverio J. Santana, Daniel Hernández-Sosa, Modesto Castrillón-Santana   
 Active Class Selection for Dataset Acquisition in Sign Language Recognition  
  Dataset collection for Sign Language Recognition (SLR) represents a challenging and crucial step in the development of modern automatic SLR systems. Typical acquisition protocols do not follow specific strategies, simply trying to gather equally represented classes. In this paper we provide some empirical evidences that alternative, more clever, strategies can be really beneficial, leading to a better performance of classification systems. In particular, we investigate the exploitation of ideas and tools of Active Class Selection (ACS), a peculiar Active Learning (AL) context specifically devoted to scenarios in which new data is labelled at the same time it is generated. In particular, differently from standard AL where a strategy asks for a specific label from an available set of unlabelled data, ACS strategies define from which class it is more convenient to acquire a new sample. In this paper, we show the beneficial effect of these methods in the SLR scenario, where these concepts have never been investigated. We studied both standard and novel ACS approaches, with experiments based on a challenging dataset recently collected for an ECCV challenge. We also preliminary investigate other possible exploitations of ACS ideas, for example to select which would be, for the classification system, the most beneficial signer.  
 Manuele Bicego, Manuel Vázquez-Enríquez, José L. Alba-Castro   
 MC-GTA: A Synthetic Benchmark for Multi-Camera Vehicle Tracking  
 Learning Landmarks Motion from Speech for Speaker-Agnostic 3D Talking Heads Generation  
  This paper presents a novel approach for generating 3D talking heads from raw audio inputs. Our method grounds on the idea that speech related movements can be comprehensively and efficiently described by the motion of a few control points located on the movable parts of the face, i.e., landmarks. The underlying musculoskeletal structure then allows us to learn how their motion influences the geometrical deformations of the whole face. The proposed method employs two distinct models to this aim: the first one learns to generate the motion of a sparse set of landmarks from the given audio. The second model expands such landmarks motion to a dense motion field, which is utilized to animate a given 3D mesh in neutral state. Additionally, we introduce a novel loss function, named Cosine Loss, which minimizes the angle between the generated motion vectors and the ground truth ones. Using landmarks in 3D talking head generation offers various advantages such as consistency, reliability, and obviating the need for manual-annotation. Our approach is designed to be identity-agnostic, enabling high-quality facial animations for any users without additional data or training. Code and models are available at: S2L+S2D .  
 Federico Nocentini, Claudio Ferrari, Stefano Berretti   
 Benchmarking of Blind Video Deblurring Methods on Long Exposure and Resource Poor Settings  
  This paper presents a benchmark evaluation of blind video deblurring methods in specific challenging settings. The employed videos are affected by severe deblurring artifacts and acquisition conditions (e.g., low resolution, high exposure, camera motion, complex scene motion, etc.). An in depth state of the art investigation has been carried out. Then, a specific set of methods based on mathematical optimization with image priors has been involved in our benchmark evaluation. The selected methods have been evaluated quantitatively and qualitatively.  
 Maria Ausilia Napoli Spatafora, Massimo O. Spata, Luca Guarnera, Alessandro Ortis, Sebastiano Battiato   
 LieToMe: An LSTM-Based Method for Deception Detection by Hand Movements  
  The ability to detect lies is a crucial skill in essential situations like police interrogations and court trials. At present, several devices, such as polygraphs and magnetic resonance, can ease the deception detection task. However, the effectiveness of these tools can be compromised by intentional behavioral changes due to the subject awareness of such appliances, suggesting that alternative ways must be explored to detect lies without using physical devices. In this context, this paper presents an approach focused on the extraction of meaningful features from hand gestures. The latter provide cues on the person’s behavior and are used to address the deception detection task in RGB videos of trials. Specifically, the proposed system extracts hands skeletons from an RGB video sequence and generates novel handcrafted features from the extrapolated keypoints to reflect the subject behavior through hand movements. Then, a long short-term memory (LSTM) neural network is used to classify these features and estimate whether the person is lying or not. Extensive experiments were performed to assess the quality of the derived features on a public collection of famous real-life trials. On this dataset, the proposed system sets new state-of-the-art performance on the unimodal hand-gesture deception detection task, demonstrating the effectiveness of the proposed approach and its handcrafted features.  
 Danilo Avola, Luigi Cinque, Maria De Marsico, Angelo Di Mambro, Alessio Fagioli, Gian Luca Foresti, Romeo Lanzino, Francesco Scarcello   
 Real-Time GAN-Based Model for Underwater Image Enhancement  
  Enhancing image quality is crucial for achieving an accurate and reliable image analysis in vision-based automated tasks. Underwater imaging encounters several challenges that can negatively impact image quality, including limited visibility, color distortion, contrast sensitivity issues, and blurriness. Among these, depending on how the water filters out the different light colors at different depths, the color distortion results in a loss of color information and a blue or green tint to the overall image, making it difficult to identify different underwater organisms or structures accurately. Improved underwater image quality can be crucial in marine biology, oceanography, and oceanic exploration. Therefore, this paper proposes a novel Generative Adversarial Network (GAN) architecture for underwater image enhancement, restoring good perceptual quality to obtain a more precise and detailed image. The effectiveness of the proposed method is evaluated on the EUVP dataset, which comprises underwater image samples of various visibility conditions, achieving remarkable results. Moreover, the trained network is run on the RPi4B as an embedded system to measure the time required to enhance the images with limited computational resources, simulating a practical underwater investigation setting. The outcome demonstrates the presented method applicability in real-world underwater exploration scenarios.  
 Danilo Avola, Irene Cannistraci, Marco Cascio, Luigi Cinque, Anxhelo Diko, Damiano Distante, Gian Luca Foresti, Alessio Mecca, Ivan Scagnetto   
 HERO: A Multi-modal Approach on Mobile Devices for Visual-Aware Conversational Assistance in Industrial Domains  
  We present HERO, an artificial assistant designed to communicate with users with both natural language and images to aid them carrying out procedures in industrial contexts. Our system is composed of five modules: 1) the input module retrieves user utterances and collects raw data, such as text and images, 2) the Natural Language Processing module processes text from user utterances, 3) the object detector module extracts entities by analyzing images captured by the user, 4) the Question Answering module generates responses to users’ specific questions on procedures, and 5) the output module selects the final response to give to the user. We deployed and evaluated the system in an industrial laboratory furnished with different tools and equipment for carrying out repair and test operations on electrical boards. In this setting, the HERO system allows the user to retrieve information on tools, equipment, procedures, and safety rules. Experiments on domain-specific labeled data, as well as a user study suggest that the design of our system is robust and that its use can be beneficial for users over classic methods for retrieving information and guide workers, such as printed manuals.  
 Claudia Bonanno, Francesco Ragusa, Antonino Furnari, Giovanni Maria Farinella   
 A Computer Vision-Based Water Level Monitoring System for Touchless and Sustainable Water Dispensing  
  In recent years, the need for contactless and sustainable systems has become increasingly relevant. The traditional water dispensers, which require contact with the dispenser and often involve single-use plastic cups or bottles, are not only unhygienic but also contribute to environmental pollution. This paper presents a touchless water dispenser system that uses artificial intelligence (AI) to control the dispensing of water or any liquid beverage. The system is designed to fill a container under the nozzle, dispense water when the container is aligned with the flow, and stop dispensing when the container is full, all without requiring any physical contact. This approach ensures compliance with hygiene regulations and promotes environmental sustainability by eliminating the need for plastic bottles or cups, making it a “plastic-free” and “zero waste” system. The prototype is based on a computer vision approach that employs an RGB camera and a Raspberry Pi board, which allows for real-time image processing and machine learning operations. The system uses image processing techniques to detect the presence of a container under the nozzle and then utilizes AI algorithms to control the flow of liquid. The system is trained using machine learning models and optimized to ensure accuracy and efficiency. We discuss the development and implementation of the touchless water dispenser system, including the hardware and software components used, the algorithms employed, and the testing and evaluation of the system. The results of our experiments show that the touchless water dispenser system is highly accurate and efficient, and it offers a safe and sustainable alternative to traditional water dispensers. The system has the potential to be used in a variety of settings, including public spaces, hospitals, schools, and offices, where hygiene and sustainability are of utmost importance.  
 Andrea Felicetti, Marina Paolanti, Rocco Pietrini, Adriano Mancini, Primo Zingaretti, Emanuele Frontoni   
 Hand Gesture Recognition Exploiting Handcrafted Features and LSTM  
  Hand gesture recognition finds application in several heterogeneous fields, such as Human-Computer Interaction, serious games, sign language interpretation, and more. Modern recognition approaches use Deep Learning methods due to their ability in extracting features without human intervention. The drawback of this approach is the need for huge datasets which, depending on the task, are not always available. In some cases, handcrafted features increase the capability of a model in achieving the proposed task, and usually require fewer data with respect to Deep Learning approaches. In this paper, we propose a method that synergistically makes use of handcrafted features and Deep Learning for performing hand gesture recognition. Concerning the features, they are engineered from hand joints, while for Deep Learning, a simple LSTM together with a multilayer perceptron is used. The tests were performed on the DHG dataset, comparing the proposed method with both state-of-the-art methods that use handcrafted features and methods that use learned features. Our approach overcomes the state-of-the-art handcrafted features methods in both 14 and 28 gestures recognition tests, while we overcome the state-of-the-art learned features methods for the 14 gesture recognition test, proving that it is possible to use a simpler model with well engineered features.  
 Danilo Avola, Luigi Cinque, Emad Emam, Federico Fontana, Gian Luca Foresti, Marco Raoul Marini, Daniele Pannone   
 An Optimized Pipeline for Image-Based Localization in Museums from Egocentric Images  
  With the increasing interest in augmented and virtual reality, visual localization is acquiring a key role in many downstream applications requiring a real-time estimate of the user location only from visual streams. In this paper, we propose an optimized hierarchical localization pipeline by specifically tackling cultural heritage sites with specific applications in museums. Specifically, we propose to enhance the Structure from Motion (SfM) pipeline for constructing the sparse 3D point cloud by a-priori filtering blurred and near-duplicated images. We also study an improved inference pipeline that merges similarity-based localization with geometric pose estimation to effectively mitigate the effect of strong outliers. We show that the proposed optimized pipeline obtains the lowest localization error on the challenging Bellomo dataset [11]. Our proposed approach keeps both build and inference times bounded, in turn enabling the deployment of this pipeline in real-world scenarios.  
 Nicola Messina, Fabrizio Falchi, Antonino Furnari, Claudio Gennaro, Giovanni Maria Farinella   
 Annotating the Inferior Alveolar Canal: The Ultimate Tool  
  The Inferior Alveolar Nerve (IAN) is of main interest in the maxillofacial field, as an accurate localization of such nerve reduces the risks of injury during surgical procedures. Although recent literature has focused on developing novel deep learning techniques to produce accurate segmentation masks of the canal containing the IAN, there are still strong limitations due to the scarce amount of publicly available 3D maxillofacial datasets. In this paper, we present an improved version of a previously released tool, iacat (Inferior Alveolar Canal Annotation Tool), today used by medical experts to produce 3D ground truth annotation. In addition, we release a new dataset, ToothFairy, which is part of the homonymous MICCAI2023 challenge hosted by the Grand-Challenge platform, as an extension of the previously released Maxillo dataset, which was the only publicly available. With ToothFairy, the number of annotations has been increased as well as the quality of existing data.  
 Luca Lumetti, Vittorio Pipoli, Federico Bolelli, Costantino Grana   
 Enhancing PFI Prediction with GDS-MIL: A Graph-Based Dual Stream MIL Approach  
  Whole-Slide Images (WSI) are emerging as a promising resource for studying biological tissues, demonstrating a great potential in aiding cancer diagnosis and improving patient treatment. However, the manual pixel-level annotation of WSIs is extremely time-consuming and practically unfeasible in real-world scenarios. Multi-Instance Learning (MIL) have gained attention as a weakly supervised approach able to address lack of annotation tasks. MIL models aggregate patches (e.g., cropping of a WSI) into bag-level representations (e.g., WSI label), but neglect spatial information of the WSIs, crucial for histological analysis. In the High-Grade Serous Ovarian Cancer (HGSOC) context, spatial information is essential to predict a prognosis indicator (the Platinum-Free Interval, PFI) from WSIs. Such a prediction would bring highly valuable insights both for patient treatment and prognosis of chemotherapy resistance. Indeed, NeoAdjuvant ChemoTherapy (NACT) induces changes in tumor tissue morphology and composition, making the prediction of PFI from WSIs extremely challenging. In this paper, we propose GDS-MIL, a method that integrates a state-of-the-art MIL model with a Graph ATtention layer (GAT in short) to inject a local context into each instance before MIL aggregation. Our approach achieves a significant improvement in accuracy on the “Ome18” PFI dataset. In summary, this paper presents a novel solution for enhancing PFI prediction in HGSOC, with the potential of significantly improving treatment decisions and patient outcomes.  
 Gianpaolo Bontempo, Nicola Bartolini, Marta Lovino, Federico Bolelli, Anni Virtanen, Elisa Ficarra   
 Metadaten   
 Titel  Image Analysis and Processing – ICIAP 2023    
 herausgegeben von  Gian Luca Foresti  
  Andrea Fusiello  
  Edwin Hancock  
 Copyright-Jahr  2023    
 Verlag  Springer Nature Switzerland

output:1. ICGSE_0 information:
2. ICGSE_1 information:
3. ICGSE_2 information:
4. ICGSE_3 information:
5. ICGT_0 information:
6. ICGT_1 information:
7. ICGT_2 information:
8. ICGT_3 information:
9. ICIAP_0 information:
10. ICIAP_1 information:
