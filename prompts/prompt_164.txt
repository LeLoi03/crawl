input:
1. IJCCI_2 conference:
Home  Log In  Contacts  FAQs  INSTICC Portal    
 Documents  Information  Conference Details  Important Dates  Event Chairs  Keynote Lectures  Best Paper Awards  Satellite Events  Workshops  Special Sessions  Tutorials  Demos  Panels  Doctoral Consortium  Partners  Academic Partners  Industrial Partners  Institutional Partners  Media Partners  Partner Events  Publication Partners  Previous Conferences  Websites  Abstracts  Invited Speakers  Awards  Books Published    
 Sponsored by:    
  Registration to IJCCI allows free access to the ICINCO, WEBIST, IN4PL, IC3K, CoopIS and EXPLAINS conferences (as a non-speaker).  
 The purpose of IJCCI is to bring together researchers, engineers and practitioners on the areas of Fuzzy Computation, Evolutionary Computation and Neural Computation.  
  Although the conference is back to the normal mode (i.e., in-person) speakers are allowed to present remotely if unable to travel to the venue (hybrid support).    
 ECTA   
  17th International Conference on Neural Computation Theory and Applications   
  Upcoming Submission Deadlines  
 Publications:     
  All papers presented at the conference venue  
  will be available at the SCITEPRESS Digital Library   
  ( consult SCITEPRESS  Ethics of Publication  )
2. IJCCI_3 conference:
7 th  International Joint Conference on      
 Advances in Computational Intelligence          
 IJCACI 2023      
 Organized by   
 SAU Center for Research and Innovative Learning (SCRIL), South Asian University, India    
 and   
 Jahangirnagar University, Bangladesh    
 October 14-15, 2023     
 The after-conference proceeding of the IJCACI 2023 will be published in Springer Book Series, ‘Algorithms for Intelligent Systems’     
 Home 
  IJCACI 2023 Program Schedule 
  Call for Papers 
  Camera Ready Paper Submission 
  Venue 
  Contact Us 
  Latest News NEW   
  IMPORTANT DATES  
 Last date of Full-length Submission:  August 05, 2023  August 25, 2023 
  Notification of acceptance:  September 14, 2023 
  Registration of accepted Paper:  September 29 , 2023   October 05, 2023 
  Conference Date:  October 14-15, 2023 
 Upcoming Conferences  
 3rd International Conference on Intelligent Vision and Computing (ICIVC 2023)     
  November 25-26, 2023      
 Congress on Smart Computing Technologies (CSCT 2023)    
  December 02-03, 2023     
 Publication  
 PAPER SUBMISSION  
 Paper submission will be through Microsoft CMT using the following link   
  Paper Submission Link      
    Announcement 
  Program Chair(s) 
  Publicity Committee 
  Paper Submission 
  Important Dates 
  Registration Fee 
  Previous IJCACI Conferences 
 Copyright @IJCACI 2023
3. IJCNLP_0 conference:
The 13th International Joint Conference on Natural Language Processing and The 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguisticss  
 Nusa Dua, Bali   
  November 2023   
   Links  
 Website 
  Pengfei Zhu  | Chao Pang  | Yekun Chai  | Lei Li  | Shuohuan Wang  | Yu Sun  | Hao Tian  | Hua Wu    
   up   bib (full)   Findings of the Association for Computational Linguistics: IJCNLP-AACL 2023 (Findings)   
 pdf  bib   
   Findings of the Association for Computational Linguistics: IJCNLP-AACL 2023 (Findings)    
  Jong C. Park  | Yuki Arase  | Baotian Hu  | Wei Lu  | Derry Wijaya  | Ayu Purwarianti  | Adila Alfa Krisnadhi    
 pdf  bib   
   Delving into Evaluation Metrics for Generation: A Thorough Assessment of How Metrics Generalize to Rephrasing Across Languages    
  Yixuan Wang  | Qingyan Chen  | Duygu Ataman    
 Language generation has been an important task in natural language processing (NLP) with increasing variety of applications especially in the recent years. The evaluation of generative language models typically rely on automatic heuristics which search for overlaps over word or phrase level patterns in generated outputs and traditionally some hand-crafted reference sentences in the given language ranging in the forms from sentences to entire documents. Language, on the other hand, is productive by nature, which means the same concept can be expressed potentially in many different lexical or phrasal forms, making the assessment of generated outputs a very difficult one. Many studies have indicated potential hazards related to the prominent choice of heuristics matching generated language to selected references and the limitations raised by this setting in developing robust generative models. This paper undertakes an in-depth analysis of evaluation metrics used for generative models, specifically investigating their responsiveness to various syntactic structures, and how these characteristics vary across languages with different morphosyntactic typologies. Preliminary findings indicate that while certain metrics exhibit robustness in particular linguistic contexts, a discernible variance emerges in their performance across distinct syntactic forms. Through this exploration, we highlight the imperative need for more nuanced and encompassing evaluation strategies in generative models, advocating for metrics that are sensitive to the multifaceted nature of languages.   
 pdf  bib  abs   
   Zero-shot Probing of Pretrained Language Models for Geography Knowledge    
  Nitin Ramrakhiyani  | Vasudeva Varma  | Girish Palshikar  | Sachin Pawar    
 Gauging the knowledge of Pretrained Language Models (PLMs) about facts in niche domains is an important step towards making them better in those domains. In this paper, we aim at evaluating multiple PLMs for their knowledge about world Geography. We contribute (i) a sufficiently sized dataset of masked Geography sentences to probe PLMs on masked token prediction and generation tasks, (ii) benchmark the performance of multiple PLMs on the dataset. We also provide a detailed analysis of the performance of the PLMs on different Geography facts.   
 pdf  bib  abs   
   Transformers Go for the LOL  s: Generating (Humourous) Titles from Scientific Abstracts End-to-End    
  Yanran Chen  | Steffen Eger    
 We consider the end-to-end abstract-to-title generation problem, exploring seven recent transformer based models (including ChatGPT) fine-tuned on more than 30k abstract-title pairs from NLP and machine learning (ML) venues. As an extension, we also consider the harder problem of generating humorous paper titles. For the latter, we compile the first large-scale humor annotated dataset for scientific papers in the NLP/ML domains, comprising 2.6k titles. We evaluate all models using human and automatic metrics. Our human evaluation suggests that our best end-to-end system per-forms similarly to human authors (but arguably slightly worse). Generating funny titles is more difficult, however, and our automatic systems clearly underperform relative to humans and often learn dataset artefacts of humor. Finally, ChatGPT, without any fine-tuning, performs on the level of our best fine-tuned system.   
 pdf  bib  abs   
   Large Language Models As Annotators: A Preliminary Evaluation For Annotating Low-Resource Language Content    
  Savita Bhat  | Vasudeva Varma    
 The process of collecting human-generated annotations is time-consuming and resource-hungry. In the case of low-resource (LR) languages such as Indic languages, these efforts are more expensive due to the dearth of data and human experts. Considering their importance in solving downstream applications, there have been concentrated efforts exploring alternatives for human-generated annotations. To that extent, we seek to evaluate multilingual large language models (LLMs) for their potential to substitute or aid human-generated annotation efforts. We use LLMs to re-label publicly available datasets in LR languages for the tasks of natural language inference, sentiment analysis, and news classification. We compare these annotations with existing ground truth labels to analyze the efficacy of using LLMs for annotation tasks. We observe that the performance of these LLMs varies substantially across different tasks and languages. The results show that off-the-shelf use of multilingual LLMs is not appropriate and results in poor performance in two of the three tasks.   
 pdf  bib  abs   
 pdf  bib  abs   
   The E  val4 NLP  2023 Shared Task on Prompting Large Language Models as Explainable Metrics    
  Christoph Leiter  | Juri Opitz  | Daniel Deutsch  | Yang Gao  | Rotem Dror  | Steffen Eger    
 Generative large language models (LLMs) have seen many breakthroughs over the last year. With an increasing number of parameters and pre-training data, they have shown remarkable capabilities to solve tasks with minimal or no task-related examples. Notably, LLMs have been successfully employed as evaluation metrics in text generation tasks. Strategies employed in this context differ in the choice of input prompts, the selection of samples for demonstration, and the methodology used to construct scores grading the generations. Approaches often differ in the input prompts, the samples that are selected for demonstration and the construction process of scores from the output. Within this context, we introduce the Eval4NLP 2023 shared task that asks participants to explore such approaches for machine translation evaluation and summarization eval- uation. Specifically, we select a list of allowed LLMs and disallow fine-tuning to ensure a focus on prompting. We test the approaches of the participants on a new reference-free test-set spanning 3 language pairs for machine transla- tion as well as a summarization dataset. Further, we present an overview of the approaches taken by the participants, present their results on the test set and analyze paths for future work. Fi- nally, as a separate track, we perform a human evaluation of the plausibility of explanations given by the LLMs and its effect on model performance. We make parts of our code and datasets available.   
 pdf  bib  abs   
   HIT  - MI  & T  Lab’s Submission to E  val4 NLP  2023 Shared Task    
  Rui Zhang  | Fuhai Song  | Hui Huang  | Jinghao Yuan  | Muyun Yang  | Tiejun Zhao    
 Recently, Large Language Models (LLMs) have boosted the research in natural language processing and shown impressive capabilities across numerous domains, including machine translation evaluation. This paper presents our methods developed for the machine translation evaluation sub-task of the Eval4NLP 2023 Shared Task. Based on the provided LLMs, we propose a generation-based method as well as a probability-based method to perform evaluation, explore different strategies when selecting the demonstrations for in-context learning, and try different ensemble methods to further improve the evaluation accuracy. The experiment results on the development set and test set demonstrate the effectiveness of our proposed method.   
 pdf  bib  abs   
   Understanding Large Language Model Based Metrics for Text Summarization    
  Abhishek Pradhan  | Ketan Todi    
 This paper compares the two most widely used techniques for evaluating generative tasks with large language models (LLMs): prompt-based evaluation and log-likelihood evaluation as part of the Eval4NLP shared task. We focus on the summarization task and evaluate both small and large LLM models. We also study the impact of LLAMA and LLAMA 2 on summarization, using the same set of prompts and techniques. We used the Eval4NLP dataset for our comparison. This study provides evidence of the advantages of prompt-based evaluation techniques over log-likelihood based techniques, especially for large models and models with better reasoning power.   
 pdf  bib  abs   
   LTRC  _ IIITH  ’s 2023 Submission for Prompting Large Language Models as Explainable Metrics Task    
  Pavan Baswani  | Ananya Mukherjee  | Manish Shrivastava    
 In this report, we share our contribution to the Eval4NLP Shared Task titled “Prompting Large Language Models as Explainable Metrics.” We build our prompts with a primary focus on effective prompting strategies, score-aggregation, and explainability for LLM-based metrics. We participated in the track for smaller models by submitting the scores along with their explanations. According to the Kendall correlation scores on the leaderboard, our MT evaluation submission ranks second-best, while our summarization evaluation submission ranks fourth, with only a 0.06 difference from the leading submission.   
 pdf  bib  abs   
   Which is better? Exploring Prompting Strategy For LLM  -based Metrics    
  JoongHoon Kim  | Sangmin Lee  | Seung Hun Han  | Saeran Park  | Jiyoon Lee  | Kiyoon Jeong  | Pilsung Kang    
 This paper describes the DSBA submissions to the Prompting Large Language Models as Explainable Metrics shared task, where systems were submitted to two tracks: small and large summarization tracks. With advanced Large Language Models (LLMs) such as GPT-4, evaluating the quality of Natural Language Generation (NLG) has become increasingly paramount. Traditional similarity-based metrics such as BLEU and ROUGE have shown to misalign with human evaluation and are ill-suited for open-ended generation tasks. To address this issue, we explore the potential capability of LLM-based metrics, especially leveraging open-source LLMs. In this study, wide range of prompts and prompting techniques are systematically analyzed with three approaches: prompting strategy, score aggregation, and explainability. Our research focuses on formulating effective prompt templates, determining the granularity of NLG quality scores and assessing the impact of in-context examples on LLM-based evaluation. Furthermore, three aggregation strategies are compared to identify the most reliable method for aggregating NLG quality scores. To examine explainability, we devise a strategy that generates rationales for the scores and analyzes the characteristics of the explanation produced by the open-source LLMs. Extensive experiments provide insights regarding evaluation capabilities of open-source LLMs and suggest effective prompting strategies.   
 pdf  bib  abs   
   Characterised LLM  s Affect its Evaluation of Summary and Translation    
  Yuan Lu  | Yu-Ting Lin    
 In today’s widespread use of Large Language Models (LLMs), there have been significant achievements in various text domains such as generating summaries and translations. However, there is still room for development and improvement in evaluating the outputs of LLMs. In this paper, we propose an innovative scoring system that assesses the quality of summaries and translations using multiple metrics, we also enhance LLM’s performance in scoring tasks by assigning it different roles, effectively making it act as an expert. We test four roles in the study: a teacher, a proofreader, a travel writer, and an internet troll, comparing the advantages and disadvantages of each role in the scoring task. Our research results demonstrate that emphasizing LLM’s multilingual capabilities and strict standards as its identity can effectively boost its performance. Additionally, imbuing LLM with a more critical thinking ability enhances its performance in translation tasks compared to a milder LLM identity. In summary, we show that assigning different identities to LLM can influence its performance in scoring tasks. We believe that this research will contribute to the use of LLMs for scoring purposes.   
 pdf  bib  abs   
   Reference-Free Summarization Evaluation with Large Language Models    
  Abbas Akkasi  | Kathleen Fraser  | Majid Komeili    
 With the continuous advancement in unsupervised learning methodologies, text generation has become increasingly pervasive. However, the evaluation of the quality of the generated text remains challenging. Human annotations are expensive and often show high levels of disagreement, in particular for certain tasks characterized by inherent subjectivity, such as translation and summarization.Consequently, the demand for automated metrics that can reliably assess the quality of such generative systems and their outputs has grown more pronounced than ever. In 2023, Eval4NLP organized a shared task dedicated to the automatic evaluation of outputs from two specific categories of generative systems: machine translation and summarization. This evaluation was achieved through the utilization of prompts with Large Language Models. Participating in the summarization evaluation track, we propose an approach that involves prompting LLMs to evaluate six different latent dimensions of summarization quality. In contrast to many previous approaches to summarization assessments, which emphasize lexical overlap with reference text, this method surfaces the importance of correct syntax in summarization evaluation. Our method resulted in the second-highest performance in this shared task, demonstrating its effectiveness as a reference-free evaluation.   
 pdf  bib  abs   
   Little Giants: Exploring the Potential of Small LLM  s as Evaluation Metrics in Summarization in the E  val4 NLP  2023 Shared Task    
  Neema Kotonya  | Saran Krishnasamy  | Joel Tetreault  | Alejandro Jaimes    
 This paper describes and analyzes our participation in the 2023 Eval4NLP shared task, which focuses on assessing the effectiveness of prompt-based techniques to empower Large Language Models to handle the task of quality estimation, particularly in the context of evaluating machine translations and summaries. We conducted systematic experiments with various prompting techniques, including standard prompting, prompts informed by annotator instructions, and innovative chain-of-thought prompting. In addition, we integrated these approaches with zero-shot and one-shot learning methods to maximize the efficacy of our evaluation procedures. Our work reveals that combining these approaches using a “small”, open source model (orca_mini_v3_7B) yields competitive results.   
 pdf  bib  abs   
 pdf  bib  abs   
   Team NLLG  submission for E  val4 NLP  2023 Shared Task: Retrieval-Augmented In-Context Learning for NLG  Evaluation    
  Daniil Larionov  | Vasiliy Viskov  | George Kokush  | Alexander Panchenko  | Steffen Eger    
 In this paper, we propose a retrieval-augmented in-context learning for natural language generation (NLG) evaluation. This method allows practitioners to utilize large language models (LLMs) for various NLG evaluation tasks without any fine-tuning. We apply our approach to Eval4NLP 2023 Shared Task in translation evaluation and summarization evaluation subtasks. The findings suggest that retrieval-augmented in-context learning is a promising approach for creating LLM-based evaluation metrics for NLG. Further research directions include exploring the performance of various publicly available LLM models and identifying which LLM properties help boost the quality of the metric.   
   up   pdf (full)   
   Large Language Model Adaptation for Financial Sentiment Analysis    
  Pau Rodriguez Inserte  | Mariam Nakhlé  | Raheel Qader  | Gaetan Caillaut  | Jingshu Liu    
 Natural language processing (NLP) has recently gained relevance within financial institutions by providing highly valuable insights into companies and markets’ financial documents. However, the landscape of the financial domain presents extra challenges for NLP, due to the complexity of the texts and the use of specific terminology. Generalist language models tend to fall short in tasks specifically tailored for finance, even when using large language models (LLMs) with great natural language understanding and generative capabilities. This paper presents a study on LLM adaptation methods targeted at the financial domain and with high emphasis on financial sentiment analysis. To this purpose, two foundation models with less than 1.5B parameters have been adapted using a wide range of strategies. We show that through careful fine-tuning on both financial documents and instructions, these foundation models can be adapted to the target domain. Moreover, we observe that small LLMs have comparable performance to larger scale models, while being more efficient in terms of parameters and data. In addition to the models, we show how to generate artificial instructions through LLMs to augment the number of samples of the instruction dataset.   
 pdf  bib  abs   
   From Numbers to Words: Multi-Modal Bankruptcy Prediction Using the ECL  Dataset    
  Henri Arno  | Klaas Mulier  | Joke Baeck  | Thomas Demeester    
 In this paper, we present ECL, a novel multimodal dataset containing the textual and numerical data from corporate 10K filings and associated binary bankruptcy labels. Furthermore, we develop and critically evaluate several classical and neural bankruptcy prediction models using this dataset. Our findings suggest that the information contained in each data modality is complementary for bankruptcy prediction. We also see that the binary bankruptcy prediction target does not enable our models to distinguish next year bankruptcy from an unhealthy financial situation resulting in bankruptcy in later years. Finally, we explore the use of LLMs in the context of our task. We show how GPT-based models can be used to extract meaningful summaries from the textual data but zero-shot bankruptcy prediction results are poor. All resources required to access and update the dataset or replicate our experiments are available on github.com/henriarnoUG/ECL.   
 pdf  bib  abs   
   Headline Generation for Stock Price Fluctuation Articles    
  Shunsuke Nishida  | Yuki Zenimoto  | Xiaotian Wang  | Takuya Tamura  | Takehito Utsuro    
 The purpose of this paper is to construct a model for the generation of sophisticated headlines pertaining to stock price fluctuation articles, derived from the articles’ content. With respect to this headline generation objective, this paper solves three distinct tasks: in addition to the task of generating article headlines, two other tasks of extracting security names, and ascertaining the trajectory of stock prices, whether they are rising or declining. Regarding the headline generation task, we also revise the task as the model utilizes the outcomes of the security name extraction and rise/decline determination tasks, thereby for the purpose of preventing the inclusion of erroneous security names. We employed state-of-the-art pre-trained models from the field of natural language processing, fine-tuning these models for each task to enhance their precision. The dataset utilized for fine-tuning comprises a collection of articles delineating the rise and decline of stock prices. Consequently, we achieved remarkably high accuracy in the dual tasks of security name extraction and stock price rise or decline determination. For the headline generation task, a significant portion of the test data yielded fitting headlines.   
 pdf  bib  abs   
   Audit Report Coverage Assessment using Sentence Classification    
  Sushodhan Vaishampayan  | Nitin Ramrakhiyani  | Sachin Pawar  | Aditi Pawde  | Manoj Apte  | Girish Palshikar    
 Audit reports are a window to the financial health of a company and hence gauging coverage of various audit aspects in them is important. In this paper, we aim at determining an audit report’s coverage through classification of its sentences into multiple domain specific classes. In a weakly supervised setting, we employ a rule-based approach to automatically create training data for a BERT-based multi-label classifier. We then devise an ensemble to combine both the rule based and classifier approaches. Further, we employ two novel ways to improve the ensemble’s generalization: (i) through an active learning based approach and, (ii) through a LLM based review. We demonstrate that our proposed approaches outperform several baselines. We show utility of the proposed approaches to measure audit coverage on a large dataset of 2.8K audit reports.   
 pdf  bib  abs   
   Multi-Lingual ESG  Impact Type Identification    
  Chung-Chi Chen  | Yu-Min Tseng  | Juyeon Kang  | Anaïs Lhuissier  | Yohei Seki  | Min-Yuh Day  | Teng-Tsai Tu  | Hsin-Hsi Chen    
 Assessing a company’s sustainable development goes beyond just financial metrics; the inclusion of environmental, social, and governance (ESG) factors is becoming increasingly vital. The ML-ESG shared task series seeks to pioneer discussions on news-driven ESG ratings, drawing inspiration from the MSCI ESG rating guidelines. In its second edition, ML-ESG-2 emphasizes impact type identification, offering datasets in four languages: Chinese, English, French, and Japanese. Of the 28 teams registered, 8 participated in the official evaluation. This paper presents a comprehensive overview of ML-ESG-2, detailing the dataset specifics and summarizing the performance outcomes of the participating teams.   
 pdf  bib  abs   
   Identifying ESG  Impact with Key Information    
  Le Qiu  | Bo Peng  | Jinghang Gu  | Yu-Yin Hsu  | Emmanuele Chersoni    
 The paper presents a concise summary of our work for the ML-ESG-2 shared task, exclusively on the Chinese and English datasets. ML-ESG-2 aims to ascertain the influence of news articles on corporations, specifically from an ESG perspective. To this end, we generally explored the capability of key information for impact identification and experimented with various techniques at different levels. For instance, we attempted to incorporate important information at the word level with TF-IDF, at the sentence level with TextRank, and at the document level with summarization. The final results reveal that the one with GPT-4 for summarisation yields the best predictions.   
 pdf  bib  abs   
   A low resource framework for Multi-lingual ESG  Impact Type Identification    
  Harsha Vardhan  | Sohom Ghosh  | Ponnurangam Kumaraguru  | Sudip Naskar    
 With the growing interest in Green Investing, Environmental, Social, and Governance (ESG) factors related to Institutions and financial entities has become extremely important for investors. While the classification of potential ESG factors is an important issue, identifying whether the factors positively or negatively impact the Institution is also a key aspect to consider while making evaluations for ESG scores. This paper presents our solution to identify ESG impact types in four languages (English, Chinese, Japanese, French) released as shared tasks during the FinNLP workshop at the IJCNLP-AACL-2023 conference. We use a combination of translation, masked language modeling, paraphrasing, and classification to solve this problem and use a generalized pipeline that performs well across all four languages. Our team ranked 1st in the Chinese and Japanese sub-tasks.   
 pdf  bib  abs   
   The Risk and Opportunity of Data Augmentation and Translation for ESG  News Impact Identification with Language Models    
  Yosef Ardhito Winatmoko  | Ali Septiandri    
 This paper presents our findings in the ML-ESG-2 task, which focused on classifying a news snippet of various languages as “Risk” or “Opportunity” in the ESG (Environmental, Social, and Governance) context. We experimented with data augmentation and translation facilitated by Large Language Models (LLM). We found that augmenting the English dataset did not help to improve the performance. By fine-tuning RoBERTa models with the original data, we achieved the top position for the English and second place for the French task. In contrast, we could achieve comparable results on the French dataset by solely using the English translation, securing the third position for the French task with only marginal F1 differences to the second-place model.   
 pdf  bib  abs   
   ESG  Impact Type Classification: Leveraging Strategic Prompt Engineering and LLM  Fine-Tuning    
  Soumya Mishra    
 In this paper, we describe our approach to the ML-ESG-2 shared task, co-located with the FinNLP workshop at IJCNLP-AACL-2023. The task aims at classifying news articles into categories reflecting either “Opportunity” or “Risk” from an ESG standpoint for companies. Our innovative methodology leverages two distinct systems for optimal text classification. In the initial phase, we engage in prompt engineering, working in conjunction with semantic similarity and using the Claude 2 LLM. Subsequently, we apply fine-tuning techniques to the Llama 2 and Dolly LLMs to enhance their performance. We report the results of five different approaches in this paper, with our top models ranking first in the French category and sixth in the English category.   
 pdf  bib  abs   
   Exploring Knowledge Composition for ESG  Impact Type Determination    
  Fabian Billert  | Stefan Conrad    
 In this paper, we discuss our (Team HHU’s) submission to the Multi-Lingual ESG Impact Type Identification task (ML-ESG-2). The goal of this task is to determine if an ESG-related news article represents an opportunity or a risk. We use an adapter-based framework in order to train multiple adapter modules which capture different parts of the knowledge present in the training data. Experimenting with various Adapter Fusion setups, we focus both on combining the ESG-aspect-specific knowledge, and on combining the language-specific-knowledge. Our results show that in both cases, it is possible to effectively compose the knowledge in order to improve the impact type determination.   
 pdf  bib  abs   
  Matiss Rikters  | Maija Kāle    
 pdf  bib   
   Boosting Adverse Drug Event Normalization on Social Media: General-Purpose Model Initialization and Biomedical Semantic Text Similarity Benefit Zero-Shot Linking in Informal Contexts    
  François Remy  | Simone Scaboro  | Beatrice Portelli
4. IJCNLP_3 conference:
中文  |  English  |  Español  |  日本語     
 Conference Partner  » Conferences  » IJCNLP    
  Conference Information   
 IJCNLP 2023: International Joint Conference on Natural Language Processing  
 Submission Date: | 2023-05-23 
 Notification Date: | 2023-09-04 
 Conference Date: | 2023-11-01 
 Location: | Bali, Indonesia 
 Years: | 13 
  Call For Papers   
 IJCNLP-AACL 2023 aims to have a broad technical program. Relevant topics for the conference include, but are not limited to, the following areas (in alphabetical order): Computational Social Science and Cultural Analytics Dialogue and Interactive Systems Discourse and Pragmatics Ethics and NLP Generation Information Extraction Information Retrieval and Text Mining Interpretability and Analysis of Models for NLP Language Grounding to Vision, Robotics and Beyond Multilingualism and Language Contact: Code-switching, Representation Learning, Cross-lingual transfer Linguistic Theories, Cognitive Modeling, and Psycholinguistics Machine Learning for NLP Machine Translation NLP Applications Phonology, Morphology, and Word Segmentation Question Answering Resources and Evaluation Semantics: Lexical Semantics: Sentence-level Semantics, Textual Inference, and Other Areas Sentiment Analysis, Stylistic Analysis, and Argument Mining Speech and Multimodality Summarization Syntax: Tagging, Chunking and Parsing Theme Track: Large Language Models and Regional/Low-Resource Languages Theme Track: Large Language Models and Regional/Low-Resource Languages LLMs (large language models) have been a major breakthrough in NLP, allowing machines to process and understand human language with unprecedented effectiveness and efficiency. However, LLMs are predominantly utilized for widely-spoken languages like English, Chinese, and Spanish. However, the development (e.g., pre-training or fine-tuning) and utilization of LLMs for regional languages, such as those spoken in ASEAN countries, as well as low-resource languages, often receive insufficient attention. The inadequate development and utilization of LLMs for regional and low-resource languages is a significant issue. Many people around the world speak such languages as their primary language, which often have unique grammatical structures, vocabulary, and cultural elements that are not easily translatable to other languages. The neglect of these languages in LLM research and development may hinder the creation of effective NLP tools for such languages, resulting in the linguistic and cultural exclusion of those who use them. Improving the situation for regional and low-resource languages requires researchers and developers to prioritize the development of LLMs specifically designed for these languages, through pre-training or fine-tuning, and with sufficient consideration given to the context of how these languages are typically used by their speakers (e.g., code-mixed with local dialects or English). This may involve developing new models that account for the unique features of each language or adapting existing models to work with languages that have limited data available. Another crucial research topic is exploring how existing LLMs can better support the processing of such languages, including in downstream applications. Furthermore, efforts should be made to collect and curate high-quality language data to train and evaluate LLMs for these languages, both in the aspects of capability and value alignment. In IJCNLP-AACL 2023, we are delighted to announce a special theme on “Large Language Models (LLMs) and Regional/Low-Resource Languages”. We welcome submissions from researchers on a range of topics within this theme, including position papers, opinion pieces, modeling studies, resource papers, and application papers. Possible topics of interest include (but are not limited to): Developing effective or efficient pre-training and fine-tuning techniques for large language models in regional/low-resource languages. Evaluating the effectiveness of current large language models on regional and low-resource languages, and identifying areas for improvement. Investigating the impact of pre-training and fine-tuning large language models on linguistic and cultural diversity for regional/low-resource languages. Developing strategies for creating high-quality data for pre-training or fine-tuning in regional/low-resource languages to improve the performance of large language models. Assessing the ethical considerations of using large language models in regional/low-resource languages, including issues of linguistic and cultural bias. Proposing techniques to manage regional-specific or emerging linguistic issues such as code-mixing, informal forms of regional languages in social media and English as used by regional (e.g., Southeast Asian) speakers. Exploring the potential of transfer learning or adaptation strategies to improve the performance of large language models in regional/low-resource languages, including those that take advantage of the common linguistic roots of some related regional languages or dialects. The theme track submissions can be either long or short papers.  Last updated by Dou Sun  in 2023-05-14   
  Best Papers   
  Related Conferences   
 CCF | CORE | QUALIS | Short | Full Name | Submission | Notification | Conference 
 Short | Full Name | Submission | Conference
5. IJCNN_0 conference:
More Sites    
 IEEE IJCNN 2023       
 About | Venue 
  Topics 
  Call For Proposals 
  Conference Photos 
  Program | IJCNN 2023 Program 
  Program at a Glance 
  Award Winners 
  CIS Events 
  INNS-Sponsored Events 
  Author Instructions | Presentation Information 
  Pre-Recorded Video Instructions 
  Special Sessions 
  Paper Submission Information 
  Final Paper Submission Instructions 
  Registration 
  Sponsor | Sponsoring Affiliates 
  Accommodations 
  VISA 
  How To Get To IJCNN 2023 
  CIS Travel Grant 
  INNS Travel Grant 
 IJCNN is the premier international conference in the area of neural networks theory, analysis and applications.  
 June 18 - 23, 2023    
 Gold Coast Convention and Exhibition Centre  
  Queensland, Australia  
 Thank you for attending IJCNN 2023 in Queensland, Australia!  
 IJCNN 2023 is a fully in-person conference. Hybrid attendance or presentations are not permitted.   
    Call For Papers  
 Calling all authors!  
 IJCNN is the premier international conference in the area of neural networks theory, analysis and applications.  
 Interest Areas    
 Cross-Disciplinary Topics         
 Join the IJCNN 2023 Mailing List    
  Receive IJCNN 2023 updates straight to your inbox!   
 Thank You    
 IEEE World Congress on Computational Intelligence (WCCI) 2024.  
  WCCI is the world’s largest technical event on computational intelligence, featuring the three flagship conferences of the IEEE Computational Intelligence Society (CIS) under one roof: The International Joint Conference on Neural Networks (IJCNN), the IEEE International Conference on Fuzzy Systems (FUZZ-IEEE) and the IEEE Congress on Evolutionary Computation (IEEE CEC).  
 About  Venue 
 Key Dates    
 Paper Submission  Special Sessions 
 Call for Proposal    
 Travel  Visit Queensland 
  Accommodations 
  How To Get To IJCNN 2023 
  Travel Grants 
  Conference Photos 
  Program 
  Author Instructions 
  Registration 
  Sponsor
6. IJCNN_1 conference:
More Sites    
 IEEE IJCNN 2023       
 About | Venue 
  Topics 
  Call For Proposals 
  Conference Photos 
  Program | IJCNN 2023 Program 
  Program at a Glance 
  Award Winners 
  CIS Events 
  INNS-Sponsored Events 
  Author Instructions | Presentation Information 
  Pre-Recorded Video Instructions 
  Special Sessions 
  Paper Submission Information 
  Final Paper Submission Instructions 
  Registration 
  Sponsor | Sponsoring Affiliates 
  Accommodations 
  VISA 
  How To Get To IJCNN 2023 
  CIS Travel Grant 
  INNS Travel Grant 
 Key Dates  Key Dates  
 2022-15-11    Special Session Proposals Deadline 
  2022-15-12    Tutorial, Workshop, and Competition Proposals Deadline 
  2023-07-02    Paper Submission Deadline 
  2023-07-04    Paper Decision Notification 
 About  Venue 
 Key Dates    
 Paper Submission  Special Sessions 
 Call for Proposal    
 Travel  Visit Queensland 
  Accommodations 
  How To Get To IJCNN 2023 
  Travel Grants 
  Conference Photos 
  Program 
  Author Instructions 
  Registration 
  Sponsor
7. IJCNN_2 conference:
More Sites    
 IEEE IJCNN 2023       
 About | Venue 
  Topics 
  Call For Proposals 
  Conference Photos 
  Program | IJCNN 2023 Program 
  Program at a Glance 
  Award Winners 
  CIS Events 
  INNS-Sponsored Events 
  Author Instructions | Presentation Information 
  Pre-Recorded Video Instructions 
  Special Sessions 
  Paper Submission Information 
  Final Paper Submission Instructions 
  Registration 
  Sponsor | Sponsoring Affiliates 
  Accommodations 
  VISA 
  How To Get To IJCNN 2023 
  CIS Travel Grant 
  INNS Travel Grant 
 Special Sessions  Special Sessions  
 The following Special Sessions have been accepted for IJCNN. If you want to submit your paper to one of the following special sessions, then you should select the relevant special session during the paper submission.  
 Submit Paper       
 Social Network Computation for Online Intelligence 
  Lifelong Learning: Recent Advances and Challenges 
  Neuromorphic Computing for Cloud, Edge and IoT 
  Computational Intelligence in Transactive Energy Management and Smart Energy Network (CITESEN 2023) 
  Evolutionary Neural Computation 
  Machine Learning and Deep Learning Methods applied to Vision and Robotics (MLDLMVR) 
 Transfer learning and transfer optimization aims to increase the quality or efficiency of learners and optimizers via transferring useful knowledge. They are essential in real-world applications, because in many scenarios, the input space, data distributions, learning tasks, and decision space may change over time. Thus, adapting learning or optimization approaches of historical environments can speed up learning or optimization problems solving in new environments. In some other scenarios,  
  collecting or labelling training data in a learning problem may be expensive or unavailable. Exploring the knowledge from different but related domains is much helpful in enhancing the quality of a model. Additionally, training models, such as the deep neural network or fitness evaluations, may computationally expensive. In this case, reusing models or solutions from related learning or optimization tasks are helpful in reducing computational time or resource. However, due to different characters of tasks, such as the size of collected data, the quality of collected data, the similarity between tasks, and complexities of tasks, exploring and transferring useful knowledge are often very  
  different. The theme of this special session is transfer learning and optimization, covering ALL different learning and optimization paradigms, machine learning and optimization approaches. The aim is to investigate the new theories, methods of leveraging and reusing knowledge of transfer learning and optimization, and their applications.  
   Cuie Yang 
  Ryosho Nakane 
  Akira Hirose 
  Computational Intelligence in Transactive Energy Management and Smart Energy Network (CITESEN 2023)  
  Federated Learning - Methods, Applications, Challenges, and beyond  
 Due to data isolation and privacy challenges in the real world, Federated Learning stands out among various AI technologies for real-world scenarios, ranging from business applications like risk evaluation systems in finance to drug discovery in life sciences. Although still in its infancy, FL has already shown significant theoretical and practical results, making it one of the hottest topics in the machine learning community. Nonetheless, many questions and challenges remain open and attract increasing interest from international research communities: e.g., the statistical unbalancing of data, distributed optimization problems, communication latency, security, and resilience to attack issues. In particular, the trustworthiness of FL systems is threatened by adversarial attacks against data privacy, the learning algorithm’s stability, and the system’s confidentiality. Such vulnerabilities are exacerbated by the distributed training in federated learning, which makes protecting against threats harder and makes it evident the need to further the research on defense methods to make federated learning a real solution for a trustworthy system.  
 The main objective of the 2023 Special Session on Federated Learning - Methods, Applications, Challenges, and beyond, is to focus the international research community’s attention on the emerging perspectives and practical algorithms in Federated Learning, with a particular emphasis on its privacy and security aspects. This session aims to collect novel contributions and research experiences from the variegated research communities participating in the IJCNN conference. We believe that such diversity will help in finding novel approaches for mitigating current issues and optimise Federated Learning algorithms.  
   Mirko Polato 
  Zenglin Xu 
 Reservoir Computing (RC) is a popular approach for efficiently training Recurrent Neural Networks (RNNs), based on (i) constraining the recurrent hidden layers to develop stable dynamics, and (ii) restricting the training algorithms to operate solely on an output (readout) layer.  
 Over the years, the field of RC attracted a lot of research attention, due to several reasons. Indeed, besides the striking efficiency of training algorithms, RC neural networks are distinctively amenable to hardware implementations (including neuromorphic unconventional substrates, like those studied in photonics and material sciences), enable clean mathematical analysis (rooted, e.g., in the field of random matrix theory), and finds natural engineering applications in resource-constrained contexts, such as edge AI systems. Moreover, in the broader picture of Deep Learning development, RC is a breeding ground for testing innovative ideas, e.g. biologically plausible training algorithms beyond gradient back-propagation. Although established in the Machine Learning field, RC lends itself naturally to interdisciplinarity, where ideas and inspirations coming from diverse areas such as computational neuroscience, complex systems and non-linear physics can lead to further developments and new applications.  
 This special session is intended to be a hub for discussion and collaboration within the Neural Networks community, and therefore invites contributions on all aspects of RC, from theory, to new models, to emerging applications.  
   Andrea Ceni 
  Fair, Explainable, and Interpretable AI to Address Fintech Challenges  
 Different regulatory bodies globally, namely in the framework of the European Commission, are proposing laws to regulate the use of artificial intelligence (AI), especially in critical applications, notably in financial applications. These so-called high-risk AI systems are being recommended to adhere to explainable principles in the spirit of creating trustworthy AI that can tackle hurdles that exist in real application due to lack of model interpretability.  
 Interpretability has been a focus of research since the beginning of Deep Learning, because high accuracy and high abstraction bring the black box problem, i.e., accuracy vs interpretability problem. This aspect is also of importance because of trustworthiness issues, i.e., a model that is not trusted is a model that will not be used. These issues often arise in real application scenarios, where end-users are not easily convinced of the reliability of black box model.  
 The financial sector is one of the largest users of digital technologies and a major driver in the digital transformation of the economy. Financial technology (FinTech) aims to both compete with and support the established financial industry in the delivery of financial services. As the emerging financial crisis is bringing to everyone’s attention, the financial sector is one of the forerunners in the public concern, e.g. credit scoring models are explicitly given as an example of a high-risk use case where standard intelligent models may fail in this new era.  
 The research field of deep learning for graphs studies the application of well-known deep learning concepts, such as convolution operators on images, to the processing of graph-structured data. Graphs are abstract objects that naturally represent interacting systems of entities, where interactions denote functional and/or structural dependencies between them. Molecular compounds and social networks are the most common examples of such graphs: on the one hand, a molecule is seen as a system of interacting atoms, whose bonds depend, e.g., on their inter-atomic distance; on the other hand, a social network represents a vastly heterogeneous set of user-user interactions, as well as between users and items, like, pictures, movies and songs. Besides, graph representations are extremely useful in far more domains, for instance to encode symmetries and constraints of combinatorial optimization problems as a proxy of our a-priori knowledge. For these reasons, learning how to properly map graphs and their nodes to values of interest poses extremely important, yet challenging, research questions. This special session on graph learning will solicit recent advances that exploit various topics to benefit the solving of real-world problems.   
 The special session we propose is an excellent opportunity for the machine learning community and IJCNN 2023 to gather together and host novel ideas, showcase potential applications, and discuss the new directions of this remarkably successful research field. In particular, the special session will attract papers proposing deep learning models and methods for graphs, e.g., graph coarsening, structure learning, graph kernels and distances, and graph stream processing. Theoretical results, benchmarks, and practical applications are also welcome and encouraged.   
   Davide Bacciu    Biography 
  Daniele Castellana    Biography 
 Key Dates    
 Paper Submission  Special Sessions 
 Call for Proposal    
 Travel  Visit Queensland 
  Accommodations 
  How To Get To IJCNN 2023 
  Travel Grants 
  Conference Photos 
  Program 
  Author Instructions 
  Registration 
  Sponsor
8. IJCNN_3 conference:
More Sites    
 IEEE IJCNN 2023       
 About | Venue 
  Topics 
  Call For Proposals 
  Conference Photos 
  Program | IJCNN 2023 Program 
  Program at a Glance 
  Award Winners 
  CIS Events 
  INNS-Sponsored Events 
  Author Instructions | Presentation Information 
  Pre-Recorded Video Instructions 
  Special Sessions 
  Paper Submission Information 
  Final Paper Submission Instructions 
  Registration 
  Sponsor | Sponsoring Affiliates 
  Accommodations 
  VISA 
  How To Get To IJCNN 2023 
  CIS Travel Grant 
  INNS Travel Grant 
 How To Get To IJCNN 2023  How To Get To IJCNN 2023  
 Gold Coast Airport  
 Key Dates    
 Paper Submission  Special Sessions 
 Call for Proposal    
 Travel  Visit Queensland 
  Accommodations 
  How To Get To IJCNN 2023 
  Travel Grants 
  Conference Photos 
  Program 
  Author Instructions 
  Registration 
  Sponsor
9. IJCRS (was RSCTC)_0 conference:
International Joint Conference on Rough Sets  
  Starts:  25 November, 2024  
 Ends:  25 November, 2024  
 Address:   
 Scope  
 The objective of the conference is to investigate rough set theory as receiving increasing attention in varied hybrid approaches in different practical fields, with a special emphasis on fostering interaction between academia and industry. Topics may include but are not limited to:  
 Core Rough Set Models and Methods:   
 Covering/Neighborhood-Based Rough Set Models,
10. IJCRS (was RSCTC)_1 conference:
Conference | Conference | About IJCRS 2023 
  Paper Submission, Fees & Registration 
  Important Dates 
  Organization Committees 
  Contact 
 October 5-8, 2023 / Kraków, Poland  
 International Joint Conference on Rough Sets  
 Photos from conference   
 Honorary patronage Mayor of Krakow   
 About IJCRS 2023  
 Download Call for Papers   
 Conference Program   
 The 2023 International Joint Conference on Rough Sets (IJCRS 2023) will take place in Krakow (Poland) from October 5 to October 8, 2023, and will be hosted by the Department of Applied Computer Science of the AGH University of Science and Technology. IJCRS is the principal international conference sponsored by the International Rough Set Society (IRSS).  
  The aim of the IJCRS conference is to be the main location for disseminating novel foundational results and practical applications, enabling the discussion of problems and exchange of ideas, as well as bringing together academic and industrial perspectives, centred around rough sets and related disciplines (such as granular computing, three-way decisions and fuzzy sets).  
 Best regards,  
  Dominik Slezak, Jaroslaw Was, JingTao Yao  
  Conference Chairs of IJCRS 2023  
 Paper Submission, Fees & Registration  
 There are two types of submissions:  
 Full papers (12–16 pages) will be published in the LNCS/LNAI Springer post-proceedings 
  Both forms will be treated equally: when designing the conference program of oral presentations 
  when selecting materials for the special issue in one of international journals 
  Papers must be original and not simultaneously submitted to another journal or conference. All accepted papers must be presented at the conference, and will be published in the conference post-proceedings, both in print and digitally. (By Springer in the LNCS/LNAI series, barring any unforeseen circumstances.)  
 Abstracts may describe work-in-progress as well as research that has been published elsewhere during the past year. Abstracts will not be included in the post-proceedings but must be presented at the conference.  
 All submissions must be prepared in the LNCS/LNAI Springer format   
 Registration fee is the necessary condition to include a paper / abstract in the conference program.  
  Note that for this edition IJCRS will have post-proceedings: informal pre-proceedings will be shared for exclusive use of the conference participants before the conference.  
 Papers on the topics of the conference (see list below) that have been rejected as borderline from ECAI are welcome for submission to IJCRS and will be considered and re-reviewed in the context of IJCRS.  
 Each submitted paper will be reviewed by at least three independent and anonymous reviewers.  
 REGISTRATION  
 Cancellations made after September 25, 2023 are non-refundable  
 Important Dates  
 Main track and Special Sessions Paper submission deadline: August 31, 2023 
  Notification of acceptance: September 14, 2023 
  Revised version deadline: September 25, 2023 
  Early registration deadline: September 25, 2023 
  Conference: October 5-8, 2023 
  Camera-ready deadline: October 15, 2023 
 Organization Committees  
 Special sessions  
 For submission dealines see Important Dates  .  
 Data Analytics in Cybersecurity and IoT Applications | Organizers: Marcin Michalak (bio)  , Piotr Synak (bio) | Pattern discovery, 
 QED Software  creates advanced technological components that enable fast and cost-efficient implementation of artificial intelligence systems. For many years, we have been supporting scientific research in the field of artificial intelligence, in particular in the area of rough sets.  
  This year, as the strategic partner of IJCRS 2023 and, at the same time, the silver sponsor of ECAI 2023  and the strategic partner of FedCSIS 2023  , we have two special offers for our friends and participants:  
  2. Anyone who registers for IJCRS 2023 can register for free for the Rough Set School organized as a part of FedCSIS 2023.  
  If you are interested, please send an email to Dominik Ślęzak  .  
  We invite you to participate jointly in the IJCRS 2023, ECAI 2023 and FedCSIS 2023 conferences!  
 Online Stream  
 Special Journal Issues  
 Research results presented at IJCRS 2023 will be considered for special issues that are being prepared by the chairs in the following journals:  
 International Journal of Applied Mathematics and Computer Science 
  Information Sciences 
 FREE TRAVEL ON PUBLIC TRANSPORT FOR CONFERENCE PARTICIPANTS  
 The City of Krakow provided our participants with free travel on public transport from 5 - 8 October. Rides are free with a conference badge with a stick-on hologram. Each participant will receive one during the conference.  
  PLEASE NOTE:  
 You do not need to validate tickets on the trams and buses. In case of ticket control, the conference ID must be shown.  
  Download a map  to see venue location in AGH campus.  
 The conference will be held in building C-2. The entrance is from Czarnowiejska street.  
  Lunches and coffee will be served in the Lunch Room located near the Conference Venue at level 4.  
 Conference Series Organizer

output:1. IJCCI_2 information:
2. IJCCI_3 information:
3. IJCNLP_0 information:
4. IJCNLP_3 information:
5. IJCNN_0 information:
6. IJCNN_1 information:
7. IJCNN_2 information:
8. IJCNN_3 information:
9. IJCRS (was RSCTC)_0 information:
10. IJCRS (was RSCTC)_1 information:
