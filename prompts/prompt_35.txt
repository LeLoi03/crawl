input:
1. CCGRID_3 conference:
Institution Edition 
  Discover | Subject category 
  Conference in Socialist Republic of Vietnam 
  Contribution library 
  Browse by venue 
 Log in  Sign up    
 2023 IEEE/ACM 23rd International Symposium on Cluster, Cloud and Internet Computing (CCGrid)  
 May. 01 - 04, 2023  
 , , , , , Bangalore, , India, , ;, Bangalore · India  
 AboutComputing and Processing  
  Keywords:cloud computing,Internet Computing,scalable systems,big data platforms,  
  Scope:CCGRID is a leading forum to disseminate and discuss research activities and results on a broad range of topics in distributed systems, ranging from computing clusters to widely distributed Clouds and emerging Internet computing paradigms such as Fog and Edge Computing to support Internet of Things (IoT) and Big Data applications. Topics of interest include but are not limited to: Future Internet and Quantum Computing Systems Programming Models and Runtime Systems Distributed Middleware and Network Architectures Storage and I/O Systems Security, Privacy, Trust and Resilience of Computing and Data Systems Performance Modeling, Scheduling, and Analysis of Large-scale Systems Sustainable and Green Computing Large-scale Scientific and Enterprise Applications Scalable Artificial intelligence, Machine Learning and Deep Learning CCGRID has been held for the past 22 years. This will be the 23rd edition.  
  Sponsor Type:1; 9  
 Call for paper  
 Submit Comment  
 All Comments  
 Submission Template  
 ×    
  Paper Template  
  Paper Template  
 Home 
 Important Date  
 Conference Date | May 01  
 2023  
  to  May 04  
 2023 
  May 04  2023 | Registration deadline 
 Sponsored By  
 2024-05-13 United States Philadelphia | 2024 IEEE 24th International Symposium on Cluster, Cloud and Internet Computing Workshops (CCGridW) 
  2024-05-06 United States Philadelphia | 2024 IEEE 24th International Symposium on Cluster, Cloud and Internet Computing 
  2023-05-01 India Bangalore | 2023 IEEE/ACM 23rd International Symposium on Cluster, Cloud and Internet Computing Workshops 
  2022-05-16 Italy Taormina | 2022 22nd International Symposium on Cluster, Cloud and Internet Computing
2. CCS_0 conference:
Keynotes 
  Call For | Call For Artifacts 
  Call For Paper 
  Call For Posters 
  Call For Sponsors 
  Travel Guide 
  Program 
  Proceedings | CCS Conference '23 
  AISEC '23 
  ARTMAN '23 
  Diversity and Inclusion 
  ACM CCS 2023    
 26-30 Nov., 2023    
 Tivoli Congress Center  ,  
  Copenhagen, Denmark  
  No Javascript Support   
  Please report it to ACM CCS Web Chair.    
 Latest Conference  
 Please enable Javascript.  
 About ACM CCS  
 The ACM Conference on Computer and Communications Security (CCS) is the flagship annual conference  of the Special Interest Group on Security, Audit and Control (SIGSAC) of the Association for Computing Machinery (ACM). The conference brings together information security researchers, practitioners, developers, and users from all over the world to explore cutting-edge ideas and results.  
  CCS will follow the ACM Policy Against Harassment at ACM Activities  . Please familiarize yourself with the ACM Policy Against Harassment  and guide  to Reporting Unacceptable Behavior.  
 Due to X's change of policy, you have to log into X  to view embedded timeline. Why is that?   
 Tweets by acm_ccs  If you still couldn't see the timeline, try  
  1. Disabling Tracking Prevention Add-ons in your web browsers  
  2. Disabling Tracking Prevention  or Enhanced Tracking Protection   
 Copyright © 2022-2023 ACM/SIGSAC.  
 DTU Compute
3. CCS_1 conference:
Keynotes 
  Call For | Call For Artifacts 
  Call For Paper 
  Call For Posters 
  Call For Sponsors 
  Travel Guide 
  Program 
  Proceedings | CCS Conference '23 
  AISEC '23 
  ARTMAN '23 
 Program  
 Last Update : [28 November, 2023]  
 Your Program 
   Reload the Database   
 Copyright © 2022-2023 ACM/SIGSAC.  
 DTU Compute
4. CCS_2 conference:
Keynotes 
  Call For | Call For Artifacts 
  Call For Paper 
  Call For Posters 
  Call For Sponsors 
  Travel Guide 
  Program 
  Proceedings | CCS Conference '23 
  AISEC '23 
  ARTMAN '23 
  Diversity and Inclusion 
 Call For Paper  
 Last Update : [2 September, 2023]  
 The 30th ACM Conference on Computer and Communications Security (CCS) seeks submissions presenting novel contributions related to all real-world aspects of computer security and privacy. Theoretical papers must make a convincing case for the relevance of their results to practice. Authors are encouraged to write the abstract and introduction of their paper in a way that makes the results accessible and compelling to a general computer-security researcher. In particular, authors should bear in mind that anyone on the program committee may be asked to review any paper.  
 CCS has 2 Review Cycles   
 In 2023.   
 For each submission,  
  one of the following decisions will be made:  
 Accept  
 Papers in this category will be accepted for publication in the proceedings and presentation at the conference possibly after making minor changes with the oversight of a shepherd.  
 Minor Revision  
 Papers in this category are considered to be promising but need some minor additional work (e.g., minor experiments, proofs to minor lemmas). Authors will be given the opportunity to resubmit such papers, with appropriate revisions, in which case they should clearly explain in a well-marked appendix how the revisions address the comments of the reviewers. The revised paper will then be re-evaluated, and either accepted or rejected.  
 Reject  
 Papers in this category are declined for inclusion in the conference. Papers rejected from the first review cycle may not be submitted again (even in revised form) to the second review cycle.  
 Authors of each accepted paper must ensure that at least one author registers for the conference, and that their paper is presented in-person at the conference if at all possible.   
 Important Dates  
 Quick Overview:  
 19 January, 2023 [First Review Cycle]   
 The submission deadline of the first round review.   
 4 May, 2023 [Second Review Cycle]   
 The submission deadline of the second round review.   
 First Review Cycle:  
 19 January, 2023  : Paper Submission Deadline  
  17 March, 2023:  Author Notification 
 Second Review Cycle:  
 4 May, 2023  : Paper Submission Deadline  
  3 June, 2023  : Early Reject Notification 
  23 - 27 June, 2023  : Author Rebuttal 
  28 June - 7 July, 2023  : Optional Reviewer-Author Interaction 
  2 September, 2023  : Author Notification 
 Paper Submission  
 Information  
 No Double Submission  
 Submitted papers must not substantially overlap with papers that have been published or accepted for publication or that are simultaneously in submission to a journal, conference, or workshop with published proceedings.  
 Must be anonymized  
 All submission should be properly anonymized; papers not properly anonymized may be rejected without review.  
 All submitted papers will be evaluated based on their merits, particularly their importance to practical aspects of computer and communications security and privacy, novelty, quality of execution, and presentation. For papers that might raise ethical concerns, authors are expected to convince reviewers that proper procedures (such as IRB approval or responsible disclosure) have been followed, and due diligence has been made to minimize potential harm.  
 Submitted papers may be rejected for being out of scope, at the discretion of the PC chairs. Authors who have questions about whether their paper is in scope are encouraged to ask the PC chairs in advance.  
 Paper Format  
 Quick Overview:  
 PDF File Format  
 Submission must be converted or readied in PDF File Format. Please contact your IT service provider if you have any difficulties on preparing your submission(s).  
 Double-Column ACM format (Sigconf style)   
 Bibliography, Well-marked Appendices, and Supplementary Material are excluded.  
 Submissions must be a PDF file in double-column ACM format  (see ACM Proceedings Template  , using the sigconf style  ), no more than 12 pages long  , excluding the bibliography, well-marked appendices, and supplementary material. Note that reviewers are not required to read the appendices or any supplementary material. Authors should not change the font or the margins of the ACM format. Submissions not following the required format may be rejected without review.  
 Providing Artifacts at Submission Time  
 Submissions whose claimed contributions rely on artifacts (e.g., code, models, data sets) are expected to make these accessible to the reviewers, unless there are good reasons not to, in which case these reasons must be mentioned in the submission.  
 Submissions whose claimed contributions do not rely on artifacts do not need to submit artifacts.  
 Optional Artifact Evaluation (New!)   
 A published scientific paper consists of a constellation of artifacts that extend beyond the document itself: software, hardware, evaluation data and documentation, raw survey results, mechanized proofs, models, test suites, benchmarks, and so on. To emphasize the importance of such artifacts, the benefits to the authors and the community as a whole, and promote the reproducibility of experimental results, ACM CCS will, for the first time, introduce an optional artifact evaluation (AE) process, inspired by similar efforts at several other conferences. All authors of accepted papers (including shepherd approved and minor revisions) are encouraged to submit artifacts for AE.  
 Each artifact submitted will be reviewed by the Artifact Evaluation Committee (AEC); a special call for artifacts will follow in early January.   
 Privacy and Anonymity  
 ACM CCS 2023 features a multi-track format. Each track operates as a separate mini-conference, with its own Track Program Chair and Track Program Committee. The overall process is managed by the Conference Co-Chairs (Cas Cremers and Engin Kirda).  
 At the time of submission, authors must select one track, which should be the most relevant to the topic of the paper. We understand that some papers might span multiple topics. In specific cases, PC members might be asked to provide reviews for papers outside their track, in an effort to provide the best possible reviews to the authors. The chairs may decide to move a paper to another track.  
 Conflicts of Interest  
 The conference requires cooperation from both authors and program-committee members to ensure a fair review process. For this purpose, authors must report all program-committee members who, in their opinion, have a conflict of interest and therefore may not be able to provide an unbiased review.  
 Mandatory declared conflicts of interest include current or former doctoral advisor/advisee, members of the same institution, close family members, and recent co-authors (within the past 2 years). For any other declared conflict, authors are required to explain the nature of the conflict, which will be reviewed by the Conference Co-Chairs and the Track Chairs. The chairs reserve the right to request further explanation and can remove non-mandatory conflicts at their discretion.  
 Track Chairs are allowed to submit papers, and those papers will be handled by the Conference Co-Chairs. They are only allowed to submit two papers in their own track, and any number in other tracks.  
 Program-committee members who have a genuine conflict of interest with a paper, including the Conference Co-Chairs and the Track Chairs, will be excluded from evaluation and discussion of that paper. When a Track Chair has a conflict, the paper will be handled by the Conference Co-Chairs. When a Conference Co-Chair is conflicted, the other Co-Chair will be responsible for managing that paper. When both Conference Co-Chairs are in conflict, a committee member will be appointed to handle the paper. Conference Co-Chairs are not allowed to be authors or co-authors of any submissions.  
 Policy for Peer-Review Integrity  
 Diversity and Inclusion  
 ACM CCS is committed to promoting diversity and inclusion in our community. If you have suggestions, concerns, or complaints related to biases or sexual harassment, we encourage you to reach out to the Conference Co-Chairs. We are committed to protecting the anonymity of such reports and helping to address your concerns. We value your feedback and ideas to help us all build a healthier and more welcoming community.  
 We encourage the authors to be mindful of not using language or examples that further the marginalization, stereotyping, or erasure of any group of people, especially historically marginalized and/or under-represented groups (URGs) in computing. Of course, exclusionary treatment can arise unintentionally. Be vigilant and actively guard against such issues in your writing. Reviewers will also be empowered to monitor and demand changes if such issues arise in your submissions. Please check the link   for more information.  
 Copyright © 2022-2023 ACM/SIGSAC.  
 DTU Compute
5. CCS_3 conference:
Menu    Menu 
 30th ACM Conference on Computer and Communications Security (ACM CCS 2023)  
   « All Events   
 30th ACM Conference on Computer and Communications Security (ACM CCS 2023)  
 November 26, 2023  - November 30, 2023   
 The ACM Conference on Computer and Communications Security (CCS) is the flagship annual conference of the Special Interest Group on Security, Audit and Control (SIGSAC) of the Association for Computing Machinery (ACM).  
 Location: Tivoli Congress Center, Copenhagen, Denmark  
 Goal   
   Mobile security  
 Dates   
  26-30 November 2023  
 Costs   
 Details  
 Start:  November 26, 2023   End:  November 30, 2023      
 + Google Calendar  + iCal Export    
 Details  
 Start:  November 26, 2023   End:  November 30, 2023      
 Event Navigation  
 «  13th International Conference on Artificial Intelligence, Soft Computing and Applications (AIAA 2023) 
  EU Conference “European Defence Sector: Navigating the Future through Skills and Innovation”. November 28, Brussels » 
 The European Commission’s support for the production of this publication does not constitute an endorsement of the contents, which reflect the views only of the authors, and the Commission cannot be held responsible for any use which may be made of the information contained therein.  
  13th International Conference on Artificial Intelligence, Soft Computing and Applications (AIAA 2023)        EU Conference “European Defence Sector: Navigating the Future through Skills and Innovation”. November 28, Brussels       
 Scroll to top
6. CC_0 conference:
CC 2023   Sat 25 - Sun 26 February 2023 Montréal, Canada    
 Toggle navigation        
  Code of Conduct 
  Local info 
  Program | CC Program 
  Your Program 
   Sat 25 Feb 
  Sun 26 Feb 
  Tracks | CC 2023 
  Artifact Evaluation 
  Research Papers 
  Organization | CC 2023 Committees 
  Organizing Committee 
  Steering Committee 
  Series | Series 
  CC 2024 
  CC 2023 
  CC 2022 
 It’s not always like this, but it can be!  
 ACM SIGPLAN 2023 International Conference on Compiler Construction  
 February 25-26, 2023, Montréal, Québec, Canada.   
 Co-located with  CGO  , PPoPP  , and HPCA   
 The International Conference on Compiler Construction (CC) is interested in work on processing programs in the most general sense: analyzing, transforming or executing input that describes how a system operates, including traditional compiler construction as a special case.  
 CC is an ACM SIGPLAN conference, and implements guidelines and procedures recommended by SIGPLAN  .  
  CC 2023   
 Artifact Evaluation  | Research Papers    
  Featured News    
 Early registration Mon 12 Dec 2022 
 Supporters   
  CC 2023   
   Support page    
 CC 2023  
 Artifact Evaluation   
  Research Papers
7. CC_1 conference:
Jingwen Pan 
  Amir Shaikhha 
  Probabilistic programming languages (PPLs) are essential for reasoning under uncertainty. Even though many real-world probabilistic programs involve discrete distributions, the state-of-the-art PPLs are suboptimal for a large class of tasks dealing with such distributions. In this paper, we propose BayesTensor, a tensor-based probabilistic programming framework. By generating tensor algebra code from probabilistic programs, BayesTensor takes advantage of the highly-tuned vectorized implementations of tensor processing frameworks. Our experiments show that BayesTensor outperforms the state-of-the-art frameworks in a variety of discrete probabilistic programs, inference over Bayesian Networks, and real-world probabilistic programs employed in data processing systems.  
 A Multi-threaded Fast Hardware Compiler for HDLs   
  Sergei Gorlatch 
  Mary Hall 
  We introduce a new scheduling language, based on the formalism of Multi-Dimensional Homomorphisms (MDH). In contrast to existing scheduling languages, our MDH-based language is designed to systematically "de-compose" computations for the memory and core hierarchies of architectures, and "re-compose" the computed intermediate results back to the final result -- we say "(de/re)-composition" for short. We argue that our scheduling langauge is easy to use and yet expressive enough to express well-performing (de/re)-compositions of popular related approaches, e.g., the TVM compiler, for MDH-supported computations (such as linear algebra routines and stencil computations). Moreover, our language is designed as auto-tunable, i.e., any optimization decision can optionally be left to the auto-tuning engine of our system, and our system can automatically recommend schedules for the user, based on its auto-tuning capabilities. Also, by relying on the MDH approach, we can formally guarantee the correctness of optimizations expressed in our language, thereby further enhancing user experience. Our experiments on GPU and CPU confirm that we can express optimizations that cannot be expressed straightforwardly (or at all) in TVM's scheduling language, thereby achieving higher performance than TVM, and also vendor libraries provided by NVIDIA and Intel, for time-intensive computations used in real-world deep learning neural networks.  
 SESSION: Code Generation and Synthesis  
  Hidetsugu Irie 
  Shuichi Sakai 
  The single-thread performance of a processor core is essential even in the multicore era. However, increasing the processing width of a core to improve the single-thread performance leads to a super-linear increase in power consumption. To overcome this power consumption issue, an instruction set architecture for general-purpose processors, called STRAIGHT, has been proposed. STRAIGHT adopts a distance-based ISA, in which source operands are specified by the distance between instructions. In STRAIGHT, it is necessary to satisfy constraints on the distance used as operands to generate executable code. However, it is not yet clear how to generate code that satisfies these constraints in the general case. In this paper, we propose three compiling techniques for STRAIGHT code generation and prove that our techniques can reliably generate code that satisfies the distance constraints. We implemented the proposed method on a compiler and evaluated benchmark programs compiled with it through simulation. The evaluation results showed that the proposed method works in all cases, including conditions where the number of registers is small and existing methods fail to generate code.  
 Matching Linear Algebra and Tensor Code to Specialized Hardware Accelerators   
  Machine learning (ML) models keep getting larger and more complex. Whereas before models used to be represented by static data-flow graphs, they are now implemented via arbitrary Python code. Eager-mode frameworks, such as PyTorch, are now the standard for developing new ML models. The semantics of eager-mode frameworks is that operations are computed straight away. This greatly simplifies the development process, and it enables more dynamic ML models.  
 Although eager-mode frameworks are more convenient, they are less efficient today as operations are dispatched to the hardware one at a time. This execution model precludes, for example, operation fusion, which is essential for executing ML workloads efficiently.  
 In this paper we present Torchy, a tracing JIT compiler for PyTorch. Torchy achieves similar performance as data-flow frameworks, while providing the same semantics of straight-away execution. Moreover, Torchy works with any PyTorch program unmodified. Torchy outperforms PyTorch by up to 12x in microbenchmarks, and PyTorch's static compiler (TorchScript) by up to 5x.  
 SESSION: Backend  
  Antonio J. Peña 
  Various kinds of applications take advantage of GPUs through automation tools that attempt to automatically exploit the available performance of the GPU's parallel architecture. Directive-based programming models, such as OpenACC, are one such method that easily enables parallel computing by just adhering code annotations to code loops. Such abstract models, however, often prevent programmers from making additional low-level optimizations to take advantage of the advanced architectural features of GPUs because the actual generated computation is hidden from the application developer.  
 This paper describes and implements a novel flexible optimization technique that operates by inserting a code emulator phase to the tail-end of the compilation pipeline. Our tool emulates the generated code using symbolic analysis by substituting dynamic information and thus allowing for further low-level code optimizations to be applied. We implement our tool to support both CUDA and OpenACC directives as the frontend of the compilation pipeline, thus enabling low-level GPU optimizations for OpenACC that were not previously possible. We demonstrate the capabilities of our tool by automating warp-level shuffle instructions that are difficult to use by even advanced GPU programmers. Lastly, evaluating our tool with a benchmark suite and complex application code, we provide a detailed study to assess the benefits of shuffle instructions across four generations of GPU architectures.  
 Register Allocation for Compressed ISAs in LLVM   
 HeuiChan Lim 
  Saumya Debray 
  Just-in-Time (JIT) compilers are ubiquitous in modern computing systems and are used in a wide variety of software. Dynamic code generation bugs, where the JIT compiler silently emits incorrect code, can result in exploitable vulnerabilities. They, therefore, pose serious security concerns and make quick mitigation essential. However, due to the size and complexity of JIT compilers, quickly locating and fixing bugs is often challenging. In addition, the unique characteristics of JIT compilers make existing bug localization approaches inapplicable. Therefore, this paper proposes a new approach to automatic bug localization, explicitly targeting the JIT compiler back-end. The approach is based on explicitly modeling architecture-independent back-end representation and architecture-specific code-generation. Experiments using a prototype implementation on a widely used JIT compiler (Turbofan) indicate that it can successfully localize dynamic code generation bugs in the back-end with high accuracy.  
 HyBF: A Hybrid Branch Fusion Strategy for Code Size Reduction   
  Nian Sun 
  Modern mobile applications have grown rapidly in binary size, which restricts user growth and hinders updates for existing users. Thus, reducing the binary size is important for application developers. Recent studies have shown the possibility of using link-time code size optimizations by re-invoking certain compiler optimizations on the linked intermediate representation of the program. However, such methods often incur significant build time overhead and require intrusive changes to the existing build pipeline.  
 In this paper, we propose several novel optimization techniques that do not require significant customization to the build pipeline and reduce binary size with low build time overhead. As opposed to re-invoking the compiler during link time, we perform true linker optimization directly as optimization passes within the linker. This enables more optimization opportunities such as pre-compiled libraries that prior work often could not optimize. We evaluate our techniques on several commercial iOS applications including NewsFeedApp, ShortVideoApp, and CollaborationSuiteApp, each with hundreds of millions of daily active users. Our techniques on average achieve 18.4% binary size reduction across the three commercial applications without any user-perceivable performance degradations.  
 SESSION: Domain Specific Languages  
 Hesam Shahrokhi 
  Amir Shaikhha 
  The simplicity of Python and its rich set of libraries has made it the most popular language for data science. Moreover, the interpreted nature of Python offers an easy debugging experience for the developers. However, it comes with the price of poor performance compared to the compiled code. In this paper, we adopt and extend state-of-the-art research in query compilers to propose an efficient query engine embedded in Python. Our open-sourced framework enables the developers to do the debugging in Python, while being able to easily build a compiled version of the code for deployment. Our benchmark results on the entire set of TPC-H queries show that our approach covers different types of relational workloads and is competitive with state-of-the-art in-memory engines in both single- and multi-threaded settings.  
 Codon: A Compiler for High-Performance Pythonic Applications and DSLs   
  Saman Amarasinghe 
  Ibrahim Numanagić 
  Domain-specific languages (DSLs) are able to provide intuitive high-level abstractions that are easy to work with while attaining better performance than general-purpose languages. Yet, implementing new DSLs is a burdensome task. As a result, new DSLs are usually embedded in general-purpose languages. While low-level languages like C or C++ often provide better performance as a host than high-level languages like Python, high-level languages are becoming more prevalent in many domains due to their ease and flexibility. Here, we present Codon, a domain-extensible compiler and DSL framework for high-performance DSLs with Python's syntax and semantics. Codon builds on previous work on ahead-of-time type checking and compilation of Python programs and leverages a novel intermediate representation to easily incorporate domain-specific optimizations and analyses. We showcase and evaluate several compiler extensions and DSLs for Codon targeting various domains, including bioinformatics, secure multi-party computation, block-based data compression and parallel programming, showing that Codon DSLs can provide benefits of familiar high-level languages and achieve performance typically only seen with low-level languages, thus bridging the gap between performance and usability.  
 MOD2IR: High-Performance Code Generation for a Biophysically Detailed Neuronal Simulation DSL   
  Christophe Dubach 
  Automatic differentiation (AD) is a central algorithm in deep learning and the emerging field of differentiable programming. However, the performance of AD remains a significant bottleneck in these fields. Training large models requires repeatedly evaluating gradients via AD potentially millions of times. Additionally, the most common form of AD incurs an asymptotically large memory cost relative to the original function being differentiated.  
 This paper introduces LAGrad, a reverse-mode, source-to-source AD system that leverages high-level information in MLIR to produce efficient differentiated code. LAGrad employs a collection of novel static optimizations that benefit from the semantics of high-level MLIR dialects to exploit the sparsity and structured control flow of generated code.
8. CC_2 conference:
CC 2024 
  CC 2023 
  CC 2022 
  Sign up 
 CC  
 All Editions   
 Co-located with PPoPP, CGO and HPCA - The International Conference on Compiler Construction (CC) is interested in work on processing programs in the most general sense: analyzing, transforming or executing input that describes how a system operates, including traditional compiler construction as a special case. CC is an ACM SIGPLAN conference, and implements guidelines and procedures recommended by SIGPLAN. 
 Sat 2 - Sun 3 March 2024 Edinburgh, United Kingdom  CC 2024   
 March 2nd – March 3th, 2024, Edinburgh, UK Co-located with PPoPP, CGO and HPCA The International Conference on Compiler Construction (CC) is interested in work on processing programs in the most general sense: analyzing, transforming or executing input that describes how a system operates, including traditional compiler construction as a special case. CC is an ACM SIGPLAN conference, and implements guidelines ... 
 Sat 25 - Sun 26 February 2023 Montréal, Canada  CC 2023   
 February 25-26, 2023, Montréal, Québec, Canada. Co-located with CGO, PPoPP, and HPCA The International Conference on Compiler Construction (CC) is interested in work on processing programs in the most general sense: analyzing, transforming or executing input that describes how a system operates, including traditional compiler construction as a special case. CC is an ACM SIGPLAN conference, and implements guide ... 
 Tue 5 - Wed 6 April 2022 Online conference  CC 2022   
 April 5 - 6, 2022, Online The International Conference on Compiler Construction (CC) is interested in work on processing programs in the most general sense: analyzing, transforming or executing input that describes how a system operates, including traditional compiler construction as a special case. CC is an ACM SIGPLAN conference, and implements guidelines and procedures recommended by SIGPLAN. CC 2022 is co-l ...
9. CC_3 conference:
Request account    
 CC - International Conference on Compiler Construction  
 From ConfIDent   
 Jump to: navigation  , search    
 Event Series    
 Acronym   
 CC   
 Title   
 Hashtag   
 CC    
 Related Identifiers   
 DBLP Series ID   
 cc     
 Wikidata Series ID   
 List   
 CC 2023   
 2023-02-25 → 2023-02-26  
 Computer Science   Compiler Construction   Programming Language    
 CC 2022   
 2022-04-05 → 2022-04-06
10. CD-MAKE_0 conference:
CD-MAKE  Cross Domain Conference for Machine Learning and Knowledge Extraction  
  co-organised with ARES 2023  , August 29 – September 01, 2023   
 About 
  Conference | Keynotes 2023 
  Detailed Program 
  Actionable Explainable AI (AxAI) 2023 
  Committee 2023 
  Call for Papers 2023 
  Proceedings 2023 
  Registration and Venue 
  Authors Area | Submission 
  Important Dates 
  Archive 
  ARES Conference 
 CD-MAKE  
 International IFIP Cross Domain (CD) Conference for  
  Machine Learning & Knowledge Extraction (MAKE)  
  CD-MAKE 2023   
 CD-MAKE is a joint effort of IFIP TC 5, IFIP TC 12, IFIP WG 8.4, IFIP WG 8.9 and IFIP WG 12.9 and is held as an on-site conference in conjunction with  
  the 18th International Conference on Availability, Reliability and Security ARES 2023  
 CD-Make 2023  
 The International IFIP Cross Domain Conference for Machine Learning & Knowledge Extraction will be held August 29 – September 1, 2023 at the University of Sannio in Benevento, Italy  and will be co-located with ARES  2023 (Conference on Availability, Reliability and Security).  
 PROCEEDINGS 2023  
 Data privacy notice 
 © 2024 CD-MAKE  
 CD-MAKE   
 About 
  Conference | Keynotes 2023 
  Detailed Program 
  Actionable Explainable AI (AxAI) 2023 
  Committee 2023 
  Call for Papers 2023 
  Back 
  Proceedings 2023 
  Registration and Venue 
  Authors Area | Submission 
  Important Dates 
  Back

output:1. CCGRID_3 information:
2. CCS_0 information:
3. CCS_1 information:
4. CCS_2 information:
5. CCS_3 information:
6. CC_0 information:
7. CC_1 information:
8. CC_2 information:
9. CC_3 information:
10. CD-MAKE_0 information:
