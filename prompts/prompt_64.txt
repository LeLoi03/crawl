input:
1. DICTA_3 conference:
International Conference on Digital Image Computing: Techniques and Applications, DICTA 2023, Port Macquarie, Australia, November 28 - Dec. 1, 2023  
  Computer Science
2. DIGRA_0 conference:
welcome  
  to digra  
  seville 2023  
 This new edition will take place on 19, 20, 21, 22 and 23 June 2023 in Seville, Spain  , under the theme Limits and Margins of Games  .  
 The organizing committee of the DiGRA 2023 conference is particularly interested in exploring the limits and margins of games.  
 The video game taxon seems insufficient today to describe the theoretical and practical nature linked to this means of expression.  
 As a result of these concerns, and with the aim of building an international framework for a dialogue about them, we proposed the Limits and Margins of Games as the central theme to this year’s edition.  
 We hope to be able to offer you an experience on a par with previous editions and a unique meeting point in the south of Europe.  
 Welcome to DiGRA 2023!  
 organizers
3. DIGRA_1 conference:
Conferences 
  Chapters 
  About | About DiGRA 
  Executive Board 
  Distinguished Scholars 
  Code of Conduct 
  Join DiGRA 
  Sign In 
 Join DiGRA 
  Sign In 
  Search        
   Conferences  
 DiGRA conferences are Digital Games Research Association’s core events that are held annually in changing locations.  
 Upcoming Conference    
 About Our Conferences  
 Our conferences gather several hundred people to share, talk, and debate about games and play – just like any scientists do at their conferences but possibly with a little bit more of fun. Our very first conference ‘Level Up’ was organised over 20 years ago at Utrecht University in the Netherlands by Joost Raessens, Marinka Copier, Jeffrey Goldstein, and Frans Mäyrä. Our future, meanwhile, is up to you! Around once a year, you can find a new call for conference hosts in our news section  . We are always on the lookout for research groups to bid us their location!  
 Our Next Conference  
 June 30th – July 4 th    
 Valletta, Malta   
 The theme of the conference will be Games at the Crossroads, exploring games and game studies at points of (cultural, disciplinary) encounter and divergence.  
 Past DiGRA Conferences  
 Chairs/Organizers:  Frans Mäyrä (Local Chair)  Sabine Harrer (Program Chair)  Tomasz Z. Majkowski (Program Chair)  Hanna Wirman (Program Chair)     
 DiGRA 2022 – “Bringing Worlds Together”  
 July 7, 2022 – July 11, 2022  
 Kraków, Poland  
 Chairs/Organizers:  Sonia Fizek (Program Chair)  Tomasz Z. Majkowski (Local Chair)  Marcelo de Vasconcellos     
 DiGRA 2023 – “Limits and Margins of Games”   
 June 19, 2023 – June 23, 2023  
 Seville, Spain  
 Chairs/Organizers:  Jesús Albarrán Ligero  Irene Baena Cuder  Rafael Luis Bono-Reyes  Antonio Campos Méndez  Antonio J. Gil González  Francisco Javier Gómez Pérez  Almudena Mata-Nuñez  Luis Navarrete Cardero  Carlos Ramírez-Moreno  Inmaculada Tobar Fernández  Juan José Vargas Iglesias  Ángeles Villanueva  Víctor Navarro-Remesal (Program Chair)  Tanja Sihvonen (Program Chair)  Marcelo Simão de Vasconcellos (Program Chair)      
 Visit Website     
 DiGRA 2024 – “Playgrounds”   
 July 1, 2024 – July 5, 2024  
 Guadalajara, Jalisco, México  
 Chairs/Organizers:  Victor M. Larios (Local Chair)  Tanja Sihvonen (Program Chair)  Sebastian Möring (Program Chair)  Ruth S. Contreras Espinosa (Program Chair)     
 Call for Conference Hosts  
 Interested in hosting a future DiGRA conference?  
 Contact Us about Hosting →    
 Become a DiGRA Member  
 Join the premier international association for professionals, academics, developers and other individuals interested in the evolving fields of digital gaming and game studies.  
 Join DiGRA Today    
 Contact Us
4. DIGRA_2 conference:
Conferences 
  Chapters 
  About | About DiGRA 
  Executive Board 
  Distinguished Scholars 
  Code of Conduct 
  Join DiGRA 
  Sign In 
 Join DiGRA 
  Sign In 
  Search        
   Digital Games Research Association (DiGRA)  
 An international association for academics and professionals who research digital games and associated phenomena.  
 Learn About DiGRA    
 Join DiGRA    
 What’s New at DiGRA  
 More News   
 Association News  ,  Elections    DiGRA Executive Board Election Committee established   
 Members-Only Content This content is only available to DiGRA members. Please sign in or join now to continue.  
  September 20, 2024 
  Association News  ,  Elections    DiGRA Executive Board Elections   
 Members-Only Content This content is only available to DiGRA members. Please sign in or join now to continue.  
  September 12, 2024 
  September 4, 2024 
 More News   
 The theme of the conference will be Games at the Crossroads, exploring games and game studies at points of (cultural, disciplinary) encounter and divergence.  
  Explore DiGRA Conferences    
 Digital Games Research  
 DiGRA Research Resources  
 DiGRA’s Digital Library and Research Journal provide an open access archival service for research papers and proceedings from a variety of academic venues including DiGRAs flagship and regional conferences.  
  Explore Research Resources    
 Become a DiGRA Member  
 Join the premier international association for professionals, academics, developers and other individuals interested in the evolving fields of digital gaming and game studies.  
 Join DiGRA Today    
 Contact Us
5. DIGRA_3 conference:
Conferences 
  Chapters 
  About | About DiGRA 
  Executive Board 
  Distinguished Scholars 
  Code of Conduct 
  Join DiGRA 
  Sign In 
 Join DiGRA 
  Sign In 
  Search        
 Category: Association News   
 Association News  ,  Elections    DiGRA Executive Board Election Committee established   
 Members-Only Content This content is only available to DiGRA members. Please sign in or join now to continue.  
  September 20, 2024 
  Association News  ,  Elections    DiGRA Executive Board Elections   
 Members-Only Content This content is only available to DiGRA members. Please sign in or join now to continue.  
  September 12, 2024 
  September 2, 2024 
  Association News    Response to the ‘DiGRA Diversity Collective Statement’   
 Dear Organisers of the ‘DiGRA Diversity Collective Statement’, the Signatories, and the DiGRA Community, Response from the Executive Board The DiGRA Executive Board received ‘DiGRA Diversity Collective Statement’ on August […]  
  August 19, 2024 
  Association News    ‘DiGRA Diversity Collective Statement’   
 A petition letter from ‘DiGRA Diversity Collective’ was delivered to the DiGRA Executive Board on August 10, 2024, including signatures. Below you can see the letter together with the PDF […]  
  August 19, 2024 
  Association News  ,  Conferences and Seminars  ,  General    DiGRA 2024 report   
  July 27, 2024 
  Association News    DiGRA 2024: the Call for Papers is out!   
 DiGRA 2024 will take place in Guadalajara, Mexico, 1–5 July 2024. A pre-conference will be held on the first day of the conference, on Monday 1st of July, together with […]  
  May 20, 2024 
  Association News    DiGRA Call for Conference Hosts   
 A central goal of the Digital Games Research Association (DiGRA) is to support international conferences on games, play, and game cultures.  
  January 5, 2024 
  Association News  ,  General    Announcing DiGRA Korea!   
 Dear colleagues, It is my great pleasure to announce DiGRA Korea! The DiGRA KR chapter is at the forefront of advancing the field of game studies in South Korea, while […]  
  April 11, 2023 
  Association News  ,  Conferences and Seminars    DiGRA Solidarity Fund   
 We are happy to announce the second edition of the DiGRA Solidarity Fund! The fund is meant for providing scholars from less privileged countries with means to travel to the DiGRA international […]  
  March 3, 2023 
  Association News  ,  Conferences and Seminars    DiGRA 2022 International Conference: July 7-11 in Krakow, Poland.   
 Due to a range of unavoidable circumstances, including issues created by the effects of the COVID-19 pandemic in Mexico, the 2022 DiGRA International Conference will not able to be held […]  
  February 14, 2022 
  Association News  ,  General    DiGRA Code of Conduct and Ombuds Team Official Launch!   
 The Digital Games Research Association (DiGRA) is pleased to announce the official launch of its Ombuds Team, an organizational ombuds program linked here, and its Code of Conduct, linked here. […]  
  Next Page
6. DIMVA_0 conference:
DIMVA  
 SIG SIDAR Conference on  
  Detection of Intrusions and Malware & Vulnerability Assessment  
 Past and future conferences  
 DIMVA 2024  was held in Lausanne, Switzerland, July 17 - 19, 2024.  
 DIMVA 2023  was held in Hamburg, Germany, July 12 - 14, 2023.  
 DIMVA 2022  was held in Cagliari, Italy, June 29 - July 1, 2022.  
  of the German Informatics Society (GI) | Past and future conferences  
 DIMVA 2024  was held in Lausanne, Switzerland, July 17 - 19, 2024.  
 DIMVA 2023  was held in Hamburg, Germany, July 12 - 14, 2023.  
 DIMVA 2022  was held in Cagliari, Italy, June 29 - July 1, 2022.  
 Past and future conferences  
 DIMVA 2024  was held in Lausanne, Switzerland, July 17 - 19, 2024.  
 DIMVA 2023  was held in Hamburg, Germany, July 12 - 14, 2023.  
 DIMVA 2022  was held in Cagliari, Italy, June 29 - July 1, 2022.
7. DIMVA_1 conference:
Buy Now, In-Store Pick Up Only   
 Free Preview of Detection of Intrusions and Malware, and Vulnerability Assessment: 20th International Conference, DIMVA 2023, Hamburg, Germany, July 12-14, 2023, Proceedings   
 ebook preview   
 Detection of Intrusions and Malware, and Vulnerability Assessment: 20th International Conference, DIMVA 2023, Hamburg, Germany, July 12-14, 2023, Proceedings  
 Daniel Gruss   Edited by  Federico Maggi   ,  Mathias Fischer     
  bvseo-msg: Unsuccessful GET. status = 'ERROR', msg = 'Not Found.'; 
 Jun 10, 2023    
 This product requires a minimum order of 1    
 Final Sale. No returns or exchanges.   
 This item will be shipped by appointment through our delivery partner.   
  Detection of Intrusions and Malware, and Vulnerability Assessment: 19th International Conference, DIMVA 2022, Cagliari, Italy, June 29 -July 1, 2022, Proceedings  
  Applications of Artificial Intelligence in 5G and Internet of Things: Proceedings of the 1st International Conference (Hybrid) Applications of AI in 5G and IOT (ICAAI5GI2024), August 9-10th 2024, Greater Noida, India  
  Freedom and Social Inclusion in a Connected World: 17th IFIP WG 9.4 International Conference on Implications of Information and Digital Technologies for Development, ICT4D 2022, Lima, Peru, May 25-27, 2022, Proceedings  
  Freedom and Social Inclusion in a Connected World: 17th IFIP WG 9.4 International Conference on Implications of Information and Digital Technologies for Development, ICT4D 2022, Lima, Peru, May 25-27, 2022, Proceedings  
  Software Quality: Higher Software Quality through Zero Waste Development: 15th International Conference, SWQD 2023, Munich, Germany, May 23-25, 2023, Proceedings  
  Applied Cryptography and Network Security: 21st International Conference, ACNS 2023, Kyoto, Japan, June 19-22, 2023, Proceedings, Part II  
  Passive and Active Measurement: 25th International Conference, PAM 2024, Virtual Event, March 11-13, 2024, Proceedings, Part I  
  Passive and Active Measurement: 25th International Conference, PAM 2024, Virtual Event, March 11-13, 2024, Proceedings, Part II  
  Applied Cryptography and Network Security: 21st International Conference, ACNS 2023, Kyoto, Japan, June 19-22, 2023, Proceedings, Part I  
 federico maggi    
 Read more     
 Author  
 Read more     
 Others Also Bought  
 Detection of Intrusions and Malware, and Vulnerability Assessment: 21st International Conference, DIMVA 2024, Lausanne, Switzerland, July 17-19, 2024, Proceedings  
  Detection of Intrusions and Malware, and Vulnerability Assessment: 21st International Conference, DIMVA 2024, Lausanne, Switzerland, July 17-19, 2024, Proceedings  
  Detection of Intrusions and Malware, and Vulnerability Assessment: 19th International Conference, DIMVA 2022, Cagliari, Italy, June 29 -July 1, 2022, Proceedings  
  Quantitative Evaluation of Systems: 19th International Conference, QEST 2022, Warsaw, Poland, September 12-16, 2022, Proceedings  
  Simulation and Modeling Methodologies, Technologies and Applications: 13th International Conference, SIMULTECH 2023 Rome, Italy, July 12-14, 2023 Revised Selected Papers  
  Swarm Intelligence: 14th International Conference, ANTS 2024, Konstanz, Germany, October 9-11, 2024, Proceedings  
  Security and Trust Management: 19th International Workshop, STM 2023, The Hague, The Netherlands, September 28, 2023, Proceedings  
  Relational and Algebraic Methods in Computer Science: 20th International Conference, RAMiCS 2023, Augsburg, Germany, April 3-6, 2023, Proceedings  
  Security and Trust Management: 20th International Workshop, STM 2024, Bydgoszcz, Poland, September 19-20, 2024, Proceedings  
  Formal Modeling and Analysis of Timed Systems: 21st International Conference, FORMATS 2023, Antwerp, Belgium, September 19-21, 2023, Proceedings  
  Passive And Active Measurement: 23rd International Conference, Pam 2022, Virtual Event, March 28-30, 2022, Proceedings  
  Advances in System-Integrated Intelligence: Proceedings of the 6th International Conference on System-Integrated Intelligence (SysInt 2022), September 7-9, 2022, Genova, Italy  
  Formal Aspects of Component Software: 20th International Conference, FACS 2024, Milan, Italy, September 9-10, 2024, Proceedings
8. DIMVA_2 conference:
This book constitutes the refereed proceedings of the 16th International Conference on Graph Transformation, ICGT 2023,  
 This book constitutes the refereed proceedings of the 20th International Conference on The Semantic Web, ESWC 2023, held  
 Author / Uploaded 
  Daniel Gruss (editor) 
  Federico Maggi (editor) 
  9 Conclusions  
  References  
  Author Index   
 Citation preview   
  Daniel Gruss Federico Maggi Mathias Fischer Michele Carminati (Eds.)  
  Detection of Intrusions and Malware, and Vulnerability Assessment 20th International Conference, DIMVA 2023 Hamburg, Germany, July 12–14, 2023 Proceedings  
  DIMVA 2023  
  Lecture Notes in Computer Science Founding Editors Gerhard Goos Juris Hartmanis  
  Daniel Gruss · Federico Maggi · Mathias Fischer · Michele Carminati Editors  
  Detection of Intrusions and Malware, and Vulnerability Assessment 20th International Conference, DIMVA 2023 Hamburg, Germany, July 12–14, 2023 Proceedings  
  Editors Daniel Gruss Graz University of Technology Graz, Austria  
  11  
  Fig. 2. Exemplary instrumentation of a lock-acquire-loop: The instrumentation may insert unconstrained instructions (marked in blue) into the atomic sequence, e.g., add a function call with parameters to trace a conditional branch instruction. In order to set the argument registers, the original register contents have to be written to the stack using an unconstrained store instruction. (Color ﬁgure online)  
  J. Wichelmann et al.  
  while on RISC–V it is only ±1 MiB. The code cache in MAMBO–V can be much larger than 1 MiB. Hence, for MAMBO–V, we decided to use indirect jumps to transfer control ﬂow back to the dispatcher. Loading the address and performing the jump takes 14 additional bytes in the code cache, but due to the long lifetime of translated code and runtime overhead of the client-dispatcher context switch the eﬀect on the overall performance and memory consumption is negligible.  
  5  
  Side-Channel Leakage Analysis.  
  In the following, we describe our approach for ﬁnding architecture-speciﬁc leakage in code compiled for RISC–V with the help of MAMBO–V. We focus on implementations of cryptographic algorithms, as their impact on the security of systems and communication is high. However, the concepts do apply to any scenario where secret information should not be exposed to an attacker recording execution traces. As discussed in Sect. 3, source-level analysis is often not sufﬁcient, and binaries may contain leakages even though the original source code is constant-time. Therefore, we opted for a binary approach based on RISC–Vspeciﬁc DBI for execution trace generation and Microwalk for leakage analysis. 5.1  
  Leakage Model  
  between two or more traces at a given code position, this diﬀerence is reported as leakage, as an attacker may exploit this diﬀerence to tell apart two or more secret inputs. If all traces are identical, the attacker does not learn anything about the underlying secret inputs, and the implementation is reported as nonleaking.  
  Fig. 3. Microwalk pipeline with a new trace generation module based on MAMBO– V. Each trace generation module may emit either source-based or binary execution traces, which are then preprocessed into a common trace format that can be parsed by all analysis modules.  
  5.2  
  J. Wichelmann et al.  
  receives a test case ﬁle with secret inputs and then calls the cryptographic primitive. Our MAMBO–V plugin registers a function call event callback for detecting execution of that function, so it can detect when test case execution starts and ends. This method has the advantage that we do not need to re-instrument the binary for each test case, but can reuse the existing instrumentation, which speeds up trace generation signiﬁcantly. Before the ﬁrst test case begins, we record a trace prefix, that contains initializations of all global objects that may be referenced during test case execution. Recording Control Flow and Memory Accesses. When a test case begins, which is signaled by the respective event callback, our plugin opens a new binary trace ﬁle. We also register an instrumentation callback, which is called whenever a new basic block is instrumented. In this callback, we check each instruction for control ﬂow and memory accesses, and add instrumentation to that instruction if necessary. The resulting instrumented code then writes to the trace ﬁle whenever the respective instruction is executed. To avoid tracing information outside our target functions, the plugin receives a list of binaries that should be traced. Tracking Memory Allocations. Microwalk needs both a list of allocated heap memory blocks and the regions of the memory-mapped executables. To collect heap blocks, we register function call and function return event callbacks for the malloc, calloc, realloc and free functions, and log their parameters and return addresses. For the static memory regions, we hook into the VM operation event handler and extract the required information from VM MAP events, which are triggered whenever a new ELF ﬁle is loaded.  
  6  
  29  
  work, in contrast, focuses on the power consumption of the CPU – we assume that, due to slight manufacturing diﬀerences in the hardware, the power consumption is slightly diﬀerent between each device. We would like to empirically demonstrate that this information is enough to signiﬁcantly improve the ﬁngerprint accuracy beyond the base rate of a naive classiﬁer choosing one of the devices at random. 4.1  
  Fingerprinting Process Overview  
  random noise. This mode, which may aﬀect our method’s eﬀectiveness, is currently engaged only when SGX is enabled, but may be extended to other settings in the future. We propose some workarounds to this limitation in Sect. 6.2. 4.2  
  Native Code Setup  
  W. Wang et al.  
  to break isolation protections provided by modern desktop or server processors. The two most relevant papers related to this article include Platypus [30], which focuses on attacking Intel SGX, and another software-based power side-channel attack [29], which focuses on AMD CPUs. On Intel CPUs, Platypus attacks [30] showed for the first time that attackers could distinguish different executed instructions and their operands by collecting power consumption information from the Intel Running Average Power Limit (RAPL) interface. With the help of APIC-timer interrupt, the attacker could get execution control with instruction-level granularity. These side-channel information could later be used to leak secret keys from the constant-time AES-NI implementation used by Intel SGX, break KASLR, and establish a time-independent convert channel. The power consumption of different instructions, but in AMD ’s Zen microarchitecture, and the feasibility of power-based side-channel attacks in SEV was also studied or discussed in the paper. Lipp et al. [29] later demonstrated the danger of power-based side-channel attacks in modern AMD processors through several end-to-end attacks, which successfully broke KASLR, stole kernel secrets and established a covert channel from unprivileged attackers. In their attacks, they combined power consumption with prefetch to infer system states and steal secrets. Inspired by those existing papers, in our paper, we focus on AMD’s Zen microarchitecture and explore the feasibility of stealing secrets from AMD SEV-protected VMs using software-based power side-channel attacks. 2.4  
  Common Power Analysis Methods  
  W. Wang et al.  
  register to get the number of executed instructions. For a newer version such as SEVES or SEV-SNP, the attacker may need to check the ciphertext of the rip register to distinguish a single-step from a zero-step. Power Interpolator. After locating the instruction, we measure the power consumption of these instructions by monitoring the core energy consumption MSR register (MSR CORE ENERGY STAT). As the register is updated in a related low rate (e.g., 1ms), it is hard to measure the power consumption of a small gadget of instructions (i.e. one instruction). To solve this problem, in Sect. 4.4, we test two power interpolators that can be used to amplify the power consumption of a single instruction. Power Attack. Finally, the attackers conduct a power attack by analyzing the power consumption. As we assume that the attacker has knowledge about the program binary to be attacked, the secret about this program can be inferred by distinguishing different operations in critical locations. 4.3  
  Instruction Identification  
  to be executed multiple times for measurement purposes [30]. However, the root reason of distinguishable power consumption of an instruction amplified by interrupt-based interpolator is not verified by the paper. The power consumption difference could be introduced by different hamming weight in VMCB or be introduced by transient execution of the next instruction. 4.5 Power Attack After amplifying and measuring the power consumption of the instructions with the power interpolator, P WR L EAK uses the power information to infer the secret. For operations with noticeable differences in power consumption, P WR L EAK uses the Simple Power Analysis (SPA) attack to infer the secret. P WR L EAK uses the cross correlation analysis (CCA) to infer the secret in those applications for which SPA fails.  
  5 Evaluation In this section, we evaluate P WR L EAK using two case studies. We first present how to use only the emulation-based interpolator to analyze the power leakage from libjpeg, and then demonstrate the attack targeting an RSA implementation with the interruptbased interpolator. The evaluation settings are identical as the experiment settings in Sect. 3, excepting the attacker now doesn’t control the SEV-protected VM. 5.1 Infer Images from Libjpeg Libjpeg is a widely used imagerendering library that offers lossy image compression and decompression implementations. The input of the libjpeg library is a bitmap image. The decoding of a JPEG image transfer a bitmap image into blocks with 8x8 pixels with three steps: decompression, dequantization, and inverse discrete cosine transformation (IDCT). The encoding procedure transfers blocks to a bitmap image with discrete cosine transform, quantization, and compression. The JPEG image is shown on the screen based on the decoded pixels. With enough information about each 8x8 pixels, adversaries Fig. 4. IDCT function in libjpeg. can recover the whole JPEG image. In IDCT algorithm [28], there are two loops to handle a block (i.e. eight columns and eight rows). A simple calculation applies when all elements in a row or a column are zeros; otherwise, a complex calculation with more page faults applies. The  
  6 Discussion Countermeasures. The power-based side-channel attack needs to gather fine-grained power information during run-time in order to analyze and infer secret using the collected data. Thus, adding additional noise may be one potential way to prevent powerbased side-channel attacks. The power-based side-channel attack could be prevented if the hardware or the VM itself could add noises during run-time to hide the power  
  Name, Email, Encrypted Password, DoB, Security question and answer  
  Following the introduction of the honeywords security mechanism by Juels and Rivest [13], the academic community has been actively exploring the technique. However, to our knowledge, only Wang et al. [29] concentrated on the production of honeywords in a targeted manner. All other works make the invalid assumption that attackers have no knowledge about the users. Each year, as demonstrated in Table 1, billions of password datasets including PII are leaked. Attackers might use the PII to determine which sweetword is the real password. If none of the sweetwords include PII existing in the password breach, the attackers may still create a knowledge map for each user by searching their information purposefully through social media and search engines using the known PII exposed in data breaches. This is especially a concern if the user is a public ﬁgure. Compromised accounts may have substantial ﬁnancial, political, and societal consequences. 1.2  
  Related Work  
  Our Contribution  
  – We are the ﬁrst to use generative language models to create honeywords that are robust to targeted attacks. We propose a novel HGT, termed ChunkGPT3 1 which generates honeywords by segmenting passwords into semantic chunks and then instructing GPT-3 to construct honeywords containing the given semantic chunks. Without being trained on real passwords, the oﬀ-theshelf GPT-3 model could generate high-quality honeywords that are more indistinguishable from literature counterparts, and thus are more robust to targeted attacks. Furthermore, unlike HGTs from the literature, our model makes no assumptions as to the PII an attacker may use to tell apart honeywords from the real password. – We are the ﬁrst to take semantic meaning into consideration to evaluate HGTs. We propose HWSimilarity, for measuring an HGT’s capabilities. HWSimilarity employs a pre-trained language model MPNet [23] to encode sweetwords into vectors, and then calculates the cosine similarity between each honeyword vector and its real password vector, taking into consideration the semantics of each sweetword. – We evaluated the capabilities of Chunk-GPT3 and two state-of-the-art HGTs and demonstrated that Chunk-GPT3-generated honeywords are signiﬁcantly more similar to their real passwords, making them more diﬃcult to diﬀerentiate regardless of what PII is available in a targeted attack. The remainder of the paper is structured as follows: Sect. 2 provides the preliminaries for understanding our work. Section 3 introduces our approach to generating honeywords in a targeted manner. Section 4 evaluates our HGT and other two approaches. Section 5 discusses the limitations of our work and future directions. Section 6 concludes our work. 1  
  Preliminaries  
  In this section, we explain the honeyword generation mechanism and datasets used in this paper. 2.1  
  The Honeyword Mechanism  
    
  Wang et al.’s [29]    Public info may include leaked password lists, password policy, and cryptographic algorithms. a  
  4.1  
  Comparable HGTs and Evaluation Results  
  We compare our Chunk-GPT3 with other three HGTs: generating honeywords using GPT-3 alone without semantic chunks provided, and two state-of-the-art HGTs chaﬃng-by-tweaking and fasttext. Chaﬃng-by-Tweaking. Chaﬃng-by-tweaking (tweaking) HGT was initially presented in [13] and mainly relies on random letter, digit, and symbol substitution. We choose to use chaﬃng-by-tweaking instead of other recently proposed methods in the literature because other methods are more vulnerable to targeted attacks [2,28]. Dionysiou et al. [9] highlight the intricacy of developing tweaking rules in such a way that it could be diﬃcult for an attacker to distinguish the password from its changed versions. For example, if a chaﬃng-by-tweaking strategy randomly perturbs the last three characters of a password, the adversary may easily conclude that the authentic password is the ﬁrst one in the instances “18!morning”, “18!morniey”, and “18!gorndge”. Thus, they replace all occurrences of a particular symbol in a given password with a randomly chosen alternate symbol, lower-case each letter in a password with probability p = 0.3, upper-case each letter in a password with probability f = 0.03, and replace each digit occurrence with probability q = 0.05. [9] contains the pseudocode and rationale for the assignment of p, q, and f . Table 5. Honeyword samples generated by the HGTs compared in the paper (ChunkGPT3, GPT-3, fasttext and tweaking). fasttext is required to be trained on a real password dataset (the rockyou dataset in the paper). Other three HGTs can generate honeywords directly without being trained on a password dataset. Only Chunk-GPT3generated honeywords retain the PII in the real password.  
  25/11/21  
  Issues acknowledged and MTConnect ﬁxed. THINC-API won’t be ﬁxed due to performance reasons Issues acknowledged and public advisory released  
  04/02/22 (direct). 01/03/22 (CERT)  
  Related Work  
  While previous work has addressed the security of smart manufacturing technologies, including CNCs to a limited extent, our extensive evaluation of the CNC domain using both controller simulators and real-world machines sets our research apart as the ﬁrst of its kind. Quarta et al. [10] conducted a security analysis of an industrial robot. By using a real-world industrial robot, the authors analyzed its architecture and evaluated the associated risks. However, this paper diﬀers from our work in the following ways: ﬁrstly, our work focuses on the overall ecosystem of computer numerical controls while this paper focuses on a single robot and its implementation; secondly, our work includes the analysis of CNC machines which diﬀer signiﬁcantly from industrial robots in terms of design, architecture, and implementation of both software and protocols; thirdly, manufacturers of industrial  
  Conclusions  
  Our research explored the risks associated with the adoption of Industry 4.0 in CNC machines. These machines underwent a shift from standalone systems to network-enabled ones that resemble full-ﬂedged machines more closely than they do mechanical devices. As a result, end-users are left dealing with sophisticated systems that, if not correctly conﬁgured or poorly designed, might open the door to abuse. In our research, we explored technologies speciﬁc to the CNC domain and conducted an extensive security evaluation. We implemented PoC attacks on real-world installations, demonstrating that our concerns have practical implications, and identiﬁed important issues that are common among all controllers under test. In addition to publishing our ﬁndings in this research paper, we also created demo material to educate the community about the security risks in the CNC domain. Our responsible disclosure process prompted interest from the aﬀected manufacturers, who acknowledged our ﬁndings. Our aim is to raise awareness in a ﬁeld that we believe will gain more attention in the future.  
  the same value across all scans of a sample. On the other hand, scan features may diﬀer across scans of the same sample, i.e., they evolve over time. For example, the hash of the certiﬁcate of a signed sample (cert thumbprint) should always be the same. But, whether the signature of a signed sample validates (sig verification res) can change across scans, e.g., if the certiﬁcate expires or is revoked. Features may be extracted only for a subset of ﬁletypes, e.g., be speciﬁc to Windows PE executables or Android APKs, and may be null for some samples (e.g., certiﬁcate features are not available for unsigned Windows executables). We detail the VT report features in Sect. 3.1 and the derived features in Sect. 3.2. 3.1  
  VT Report Features  
  Threat Model  
  The SuS model is a server-side defense system aimed at preventing adversaries 1) from successfully executing any backend request above their intended privilege level and 2) from making changes to server ﬁles that would enable them to attack other users. We assume that adversaries can only access the server program’s host machine via network communication and that they will attempt exploits via the packet payloads in the server program’s communication protocol. We assume the application server within a single-use container can be exploited and adversary-controlled. The adversary may arbitrarily control one or more clients and containers. We assume that the container facilitates access to information stored in one or more backend resources (e.g., in databases or ﬁle shares) but that it otherwise only stores per-user session state. For the defender, we assume that they leverage the SuS capability to conﬁgure the levels of access based on their applications and diﬀerent user roles. Such conﬁguration exercises a least-privilege principle, helping defenders mitigate exploitation against unknown vulnerabilities. We exclude attacks that cause privileged users to misuse their legitimate privileges, such as social engineering or cross-site request forgery. Similarly, we exclude attacks against our trusted computing base (TCB), which includes the operating system, the back-end resource servers, and the SuS infrastructure components themselves (such as middleboxes and container managers). While we evaluate container scalability and performance, we exclude ﬂooding-based denialof-service attacks and assume defenders employ current best practices. While a trusted kernel is a common threat model assumption, and one we use as well, we recognize that eﬀorts to escape a container and elevate privileges are possible. Given the importance of kernels and containers, we anticipate other continued eﬀorts to improve and protect them. The scope of the SuS approach is to explore  
  Container Isolation to Reduce Risk and Understand Vulnerabilities  
  Authentication Container and Permissions  
  Many application servers must identify the user associated with a given client. In our model, we cannot rely on the untrusted application to accurately report the client’s authentication status. Instead, all user authentication is handled by a trusted Authentication Container, which has a minimal code base that can be more easily veriﬁed and protected. This separation of roles is somewhat similar to the Kerberos authentication model [17]. The Container Manager communicates with the Authentication Container to adjust container permissions. If the Authentication Container conﬁrms a client’s identity, the Container Manager increases privileges in the SuS-to-backend middlebox and backend infrastructure to reﬂect the new user permissions. In essence, the SuS container gains only the privileges associated with the connected user. Our privilege model diﬀers from traditional web server conﬁgurations. An application container does not need a superset of users privileges during the conﬁguration (e.g., WordPress installation recommends granting all privileges in the WordPress database). Such a conﬁguration has the potential risk of letting adversaries ultimately control the entire WordPress database in case of an exploited WordPress instance. In our SuS model, the same exploitation is limited to the database privileges of the account associated with the exploited container. In other words, the adversary may issue queries, but the queries will only succeed if they can be performed within the limited permissions associated with the container. We treat database server privilege errors as evidence of compromise. 3.6  
  Client-Side Demultiplexing and Forwarding  
  Our Client-to-SuS middlebox acts as a load balancer that demultiplexes clients and directs each to a separate SuS container and as a proxy that handles all encryption functionality. This keeps cryptographic keys out of the untrusted SuS container environment while letting the middlebox vet unencrypted data. It controls access and blocks client communication in the event of an access violation. It logs network traﬃc for forensic reconstruction. This allows defenders to pinpoint the client messages that preceded the violation, potentially revealing the vulnerability exploited in the SuS container. 3.7  
  Guarding Backend Resources  
  Container Manager  
  The Container Manager creates a thread to maintain a pool of available containers for new clients. Our pooling strategy hides latency by ensuring a container is ready when a client arrives. When stopped, the Container Manager terminates all threads and containers and removes container credentials from the database. We use a startup script as the entry point that setup control arguments for the rest of the container processes. After parameter conﬁguration, the script then ﬁres up the web application. The scripts receive these arguments from the Container Manager as part of the container startup process. An internal control manager handles the generation of each container’s control arguments (including IP address, database credential with minimal privilege, PHP settings, etc.). Optimizing memory usage for SuS is important. Our memory deduplicator is implemented as a kernel module in Linux and a userspace component which is part of the Container Manager. The communication between the kernel and userspace is achieved through a ioctl call in which the manager passes a pair of in-container process IDs that requires merging. Container processes’ IDs are obtained by intercepting the Docker event interface and examining the corresponding cgroup directory on a container startup event. After receiving the process IDs, our kernel module’s callback function scans the processes’ pages. Before merging, we compute and store page metadata in a two-layered hashmap. This structure combines xxHash checksums with Blake2b checksums for each page to perform faster merge comparisons. The ﬁrst layer is indexed oﬀ xxHash’s ﬁrst bytes, and the second layer stores the full xxHash and points to a red-black tree indexed oﬀ the Blake2b hash. The mergeable pages between two processes are ﬁrst maintained in a link list and then merged using existing kernel functions.  
  Container Isolation to Reduce Risk and Understand Vulnerabilities  
  Y. Lei et al.  
  We deﬁne a ResourceRestrictTable that maps the tuple (Role, Resource, Access Type) to an Access Predicate. An Access Predicate is an extra limitation that can be applied to the query by appending it to the query’s WHERE clause or an assertion to check the presence of a speciﬁc row selector in the WHERE clause. The middlebox also maintains a UserContext dictionary that maps container IP to user information (e.g., user_id, role). For each database query, the middlebox ﬁrst retrieves the user’s role based on the container IP. Then it extracts the resource (table) and access type (e.g., SELECT, INSERT). The middlebox retrieves the Access Predicate using the above three values. An access predicate may have a variable, as in the case ID = :user_id. In this case, the middlebox inserts the corresponding value from the UserContext dictionary entry before appending it to the query. The modiﬁed query is then sent to the MySQL database, and the response is forwarded to the container from which the query originated as usual. This silently restricts the data available to each user. The middlebox monitors and logs MySQL server responses for permission violations and regards any such error messages as an indication that the container has been compromised. Upon detecting such an error, the middlebox issues a request to freeze the container. 4.6  
  Tracing Application Execution  
  We implement a PHP extension that leverages request hooks to mark the start and end of a request and log important contexts such as URLs and cookies. The SUS_LOG_COOKIE cookie (inserted by the Client-to-SuS middlebox as mentioned in Sect. 4.4) is extracted at the request_start hook function. In addition to the request information, we also leverage the function execution hook to record function execution information, including the function name, the function call site (the ﬁle and line at which the function is called), and the function’s parameter values. In this hook, a SUS_LOG_COOKIE value will be propagated if the function execution is part of the request handling. Because PHP handles requests synchronously, this propagation is scoped by the request_start and request_end hook functions. The proﬁling extension is application-independent and can be loaded and unloaded through the PHP runtime’s conﬁguration ﬁle when PHP processes start. We found that accessing a complete list of function parameter values can incur signiﬁcant overhead. Therefore, we only obtain the ﬁrst three elements’ values for composite-type parameters. In addition, we limit the parameter tracing depth when a composite-type parameter contains other composite-types. Since the proﬁling extension runs within each SuS container, the proﬁling data may be tainted. An attacker with control of the SuS container may manipulate the proﬁling extension to provide false data. We leverage Linux’s auditd from outside the container to implement rules that monitor ptrace and accesses to PHP’s conﬁguration directory. These rules can eﬀectively detect an attacker’s attempt to subvert the proﬁling modules through code injection and module replacement. Previous work explores syscall semantic reconstruction for interpreted program [5,18]. Tracing syscalls from outside the container can enable  
  Container Isolation to Reduce Risk and Understand Vulnerabilities  
  Background & Related Work  
  Automated vulnerability detection is approached using various methods such as code similarity and patch analysis [5], fuzzing [7], and various emulationbased methods [13]. Large-scale detection of known vulnerabilities requires sound ground truth. Thus, we focus our discussion on sound vulnerability information and previous research on discovering known vulnerabilities on binary code. Sound Data as Foundation for known Vulnerability Detection. Correct and detailed information on known vulnerabilities [10] is essential for eﬀective automated detection methods. The community-driven CVE catalog3 oﬀers a de facto standard for vulnerability identiﬁcation but comes with limitations due to errors in Common Platform Enumeration (CPE) assignments [1], missing or hard to obtain data [3] and inconsistent references to patches [11]. Additionally, for CVEs aﬀecting closed source projects, issuers will not share technical details on ﬁxes in public. In this work, we leverage upon the observation that the summary of most Linux kernel CVEs includes a ﬁle reference to mark which kernel part is aﬀected. 2 3  
  Methodology  
  This section describes our proposed methodology to enrich the version-based Linux kernel CVE attribution process with build-speciﬁc annotations. We show an automated static analysis pipeline that ﬁnds and extracts kernel conﬁgurations, dry builds the found kernel version, and ﬁlters CVEs based on aﬀected version and build log-included ﬁles. Figure 1 provides an overview of our methodology. We establish a two-stage process: In the ﬁrst and left-hand stage, we unpack, analyze, and annotate each ﬁle of an ingress ﬁrmware image. Gathered information includes Linux kernel version, Instruction Set Architecture (ISA), and kernel build conﬁguration. In the second and right-hand stage, we leverage upon said data to perform the actual CVE attribution and ﬁltering step. Yellow boxes in Fig. 1 mark components this paper contributes. 4  
  Gather Kernel Information via Static Firmware Analysis  
  For stage one, we apply and enhance the open source ﬁrmware analysis tool FACT [4]. FACT provides automated ﬁrmware analysis capabilities including recursive extraction, kernel version, and ISA detection. In the following, we describe all steps that are of importance for the proposed attribution methodology. Starting with an arbitrary Linux ﬁrmware image, we ﬁrst use FACT internals to recursively extract all components necessary for analysis, including the kernel. Next, we identify the ISA and kernel version. The Analysis Scheduler achieves this by running a selected set of analyses on each extracted object. The software version detection uses YARA rules and the ISA detection leverages ELF header information, detected kernel conﬁgurations, and device trees. We contribute the Kernel Configuration plugin, which detects and extracts Linux kernel build conﬁgurations in ﬁrmware images. It is pivotal to the succeeding dry build pipeline step, as it determines components included in kernel builds. In ﬁrmware, kernel conﬁgurations may be present as plain text or in binary form. Detection of plain text conﬁgurations is straight forward due to the distinctive key-value structure and well-known directive keywords. These can be used for pattern matching. If the CONFIG_IKCONFIG directive is enabled (Y) during build, the kernel conﬁguration gets embedded into the binary kernel image. This embedding might be an inline string or a binary compressed representation using common algorithms like LZMA or DEFLATE. If it is set to M, the conﬁguration is outsourced to a kernel module. Thus, if the ﬁle is either a kernel image or module, our plugin searches for an embedded magic word that precedes the kernel conﬁguration data. The plugin tests for all variations and extracts, and if necessary, decompresses the conﬁguration. 3.2  
  Build Log-Assisted CVE Attribution  
  Then, our contributed Kernel Downloader fetches mainline version sources from kernel.org. We emphasize that our assumption of unaltered mainline kernels in ﬁrmware images is likely false because vendors may custom-patch their kernels. However, we observe that modiﬁed kernel code is not accessible in scale, regardless of the Linux kernel’s GNU General Public License (GPL) that dictates vendors to publish modiﬁed open source code. For example, some vendors complicate distribution by implementing manual request procedures for each device, ﬁrmware, and version5 . Dry Build is the next step in Fig. 1. We set the target ISA and install the extracted kernel build conﬁguration in the downloaded kernel source project. Then, we execute a compilation dry run, which does not compile the kernel but prints each compilation recipe instead. This approach has the advantages of low computational overhead and no requirement for a cross-compilation toolchain. With this step, we gather a list of source ﬁles from the build log, which our pipeline witnesses to be included in the kernel build. The CVE Fetcher executes simultaneously. We query the NVD dataset for all Linux kernel CVEs and ﬁlter out all records that do not refer CPEs stating the extracted Linux kernel version to be vulnerable. The result of this stage is identical to naive version-based attribution. The File Filter step combines the outputs of CVE Fetcher and Dry Build: Based on the observation that Linux kernel CVEs summaries usually state the aﬀected source ﬁles, we improve on the version-based attribution by removing every CVE that does not reference an aﬀected ﬁle we witnessed in the build log.  
  4  
  In terms of applicability, our Linux kernel CVE attribution pipeline is bound to FACT’s static analysis success. If the kernel version, ISA, and build conﬁguration remain unknown, our method cannot identify possibly included components for reliable CVE ﬁltering. Yet, the case study in Sect. 4 shows that there is still a considerable amount of ﬁrmware fulﬁlling all requirements. As for sound ground truth, reliable and true-positive CVE attribution is limited by the quality of its underlying dataset. Unsound Linux kernel CVE records that reference unaﬀected versions or source ﬁles can introduce false matches in our proposed method. Our assumption of vendors using mainline kernels is another limiting factor that aﬀects reliability, but a methodical necessity due to missing insider information. Vendors may cherry-pick patches or introduce custom ﬁxes, which are not detectable by our approach. While some of the modiﬁcations might be obtainable through GPL portals, we identify the issue of scalable accessibility. Another limitation comes from the ﬁle-based ﬁltering. Kernel builds can in- or exclude only parts of a ﬁle based on conﬁguration options. This can lead to exclusion of vulnerable code, while the aﬀected ﬁle still appears in the build log. Regarding functional limits, we stress the inherent limitations of static analysis. It may use heuristics to ﬁnd indicators of bug presence but can hardly serve deﬁnitive proof – which usually requires triggering the bug during runtime. Finally, the conducted case study is limited in its validity, as the used corpus lacks device class heterogeneity.  
  6  
  L. Hafkemeyer et al.  
  Invasive Modification of the Program. Existing approaches signiﬁcantly aﬀect the program’s memory layout due to their instrumentation. Such modiﬁcations fall into the following categories: (1) Introduction of poisoned red zones around memory objects; (2) Introduction of new memory regions to store metadata, e.g., as shadow memory; (3) Direct and indirect modiﬁcation of stack frames caused by storing metadata and performing checks. Consider the snippet shown in Fig. 1 and its stack layout as implemented by ASan [29] and SoftBound [23] in Fig. 2. We can clearly see both solutions heavily modify the stack frame layout. This, accompanied with the extra register spilling introduced by the checking logic as well as compiler optimizations on the instrumented program, makes reliably identifying and triaging the memory objects aﬀected by OOB writes within the non-instrumented program challenging.  
  Fig. 2. Stack layouts of the function in Fig. 1 (Default, ASan, and SoftBound).  
  L. Hafkemeyer et al.  
  of semantics caused by the compilation process, which is critical to characterize OOB writes without requiring invasive modiﬁcations of the program. In the second phase, leveraging the collected information at compile time, we statically analyze the target binary to identify variables and parameters stored on the stack or in the globals, determine their sizes, identify pointer-creating instructions, and determine the destination objects of write operations. Besides, in this phase, we determine the internal structure of composite types such as struct, which is essential to detect intra-object OOB writes. In the third phase, we dynamically analyze the target program by using the ﬁndings obtained through static analysis, taint pointers, and identify write operations that have an eﬀect beyond the boundaries of the intended destination objects (IDOs). Here, we map our results back to the source code domain using the information we collect in the previous phases. Finally, because we do not alter the state or memory layout of the program at run-time, our approach guarantees that, by design, execution continues reliably after detecting an OOB write. Although the goals of preliminary and static analysis could theoretically be achieved by modifying the compiler, this would come with several drawbacks: (1) Heavy modiﬁcations of highly complex code at multiple compilation stages with little documentation; (2) Potentially altered binaries due to modiﬁcations, including in production builds; (3) Incompatibility with custom or new optimization passes. Therefore, we opted for the more portable hybrid approach. Our design for detecting OOB writes relies on the identiﬁcation and special treatment of the following types of machine code instructions. Independent Writes. For independent writes in the machine code, the dominant component from which the destination address is computed in the operand is either given by an immediate value or a stack frame boundary register (rbp or rsp). This has two important implications. First, independent writes can only write to global objects or within the stack frame of the containing function. Second, their intended destination object does not change at runtime. An example of an independent write is the instruction mov [rsp + rax], cl, which may access an array on the stack. Here, rsp constitutes the dominant component of the address calculation as its value will be substantially larger than the value in rax. Now, rsp being a stack boundary register makes this an independent write. Dependent Writes. For dependent writes, the dominant component used to compute the destination address is given by a general-purpose register as opposed to a stack frame boundary register. Thus, dependent writes rely on a previous instruction for determining the pointer used as the basis of the address computation. This requires detaching the logic for determining the intended destination object from the logic for checking the legality of the write. An example of a dependent write is the instruction mov [rcx + rax*8], rdx, which may access an array based at the address speciﬁed by rcx. Here, the dominant component is given by a general-purpose register, making this a dependent write. Pointer-creating Instructions (PCIs). To facilitate bounds-checking of dependent writes, it is essential to taint pointers with their intended pointee  
  Non-invasive Characterization of OOB Write Vulnerabilities  
  Fig. 2. Simpliﬁed Call Graph Illustration  
  responsible for device management, such as binding or unbinding the device with the owner, and updating the device’s ﬁrmware. Commands from the local apps are used to control interaction with the environment (physical world), e.g., turning on/oﬀ the switch, locking/unlocking the lock, adjusting the brightness of the light, etc. Diﬀerent channels are not supposed to interfere with other’s responsibilities. For example, the local app should not be able to update the device’s ﬁrmware. These properties can be violated by PSVs. We will discuss two particular types: over-privilege vulnerabilities and authentication bypass vulnerabilities. Over-Privilege Vulnerabilities. Listing 1.1 shows an over-privilege vulnerability. The command handling function extract cmd shared between the interfaces supports all commands, even those not authorized on some of them. There is a “valid” execution path (that is, one not violating CFI properties) from local handler to exec update, namely with the call trace task main → local handler → local recv → auth → parse local data → extract cmd → exec update. However, based on the program context, it appears that the “valid” path is unexpected and violates the privilege separation model. We can infer this from the user app lacking a user interface (e.g., button) that can initiate the exec update behavior. This behavior is not intended for the user app to perform. However, attackers can bypass the app interface and issue the command using scripts. This bug has been reported to the vendor and acknowledged [30]. Inferring expected behavior from the program context, including exposed user interfaces, is already used in existing research [26]. In this paper, we label such bugs as over-privilege vulnerabilities. Overprivilege vulnerabilities are common in IoT platforms, and previous research has  
  analyzing illegal path reachability. Ideally, we can use static analysis to detect illegal paths in advance and ensure that cmd1 will never be reached through channel2. However, since static analysis faces some common challenges (e.g., it is hard to precisely resolve all indirect calls), it is very hard if not possible to accurately exclude all paths from channel2 to cmd1. Moreover, any detected bugs still need code patches (defense solutions) to defend against potential attacks. ii) Blocking execution by checking input directly at the start point channel2. Recall the example in Listing 1.1, one may argue that we can easily block the execution if an “update” command is found at the local recv(). We note that the received raw data at the entry point has various complex formats (e.g., JSON format and encrypted formats [30]) and not completely parsed yet at this point. Therefore, it is infeasible to directly ﬁlter illegal commands at the entry point (i.e., local recv() and remote recv()). Futhermore, diﬀerent channels are not completely independent and often have some shared behaviors (e.g., both the cloud and user app are allowed to issue turn on/oﬀ commands) and call shared functions. Shared functions can easily lead to privilege separation vulnerabilities, as noted by Yao et al. [30]. Although the program can know which channel is involved at the entry point, it cannot predict the control ﬂow, since the command has not yet been parsed at that point. iii) Applying traditional CFI solutions. However, logic bugs follow a “legal” path in the program implementation. There is a path from channel2 to cmd1 which does not violate the CFG, so CFI solutions fundamentally cannot mitigate this type of vulnerability. 3.2  
  Threat Model  
  CEFI  
  In this section, we discuss the design and implementation of CEFI . Figure 3 shows the overall design of CEFI . Developers can use CEFI to protect their ﬁrmware. It acts as a compiler pass, and anyone who has access to the ﬁrmware source code can use it to generate a ﬁrmware binary hardened against privilege separation vulnerabilities. CEFI needs minimal manual annotations to specify the mapping between interfaces that can receive commands and commands permitted on those interfaces, and can then automatically instrument the program to enforce those policies at runtime, even in the face of logic bugs. Our approach consists of two phases, which are discussed in this section. The static calling context encoding (CCE) phase (Sect. 4.1) happens at compile time, and performs static analysis and instrumentation to create a hardened binary. It uses the policies speciﬁed by the user in the form of minimal annotations to generate an allowlist that speciﬁes the code paths that satisfy the policy, and are therefore valid contexts to execute particular commands, and instruments to code to be able to enforce this allowlist. The dynamic command execution ﬂow veriﬁcation phase (Sect. 4.2) oﬀers the necessary support at runtime to perform these checks in a secure way. We take advantage of secure storage and isolation provided by Trustzone-M the allowlist at runtime. We use Trustzone to protect the security of the allowlist, as our approach relies on the guarantee that it is not illegally written to. Meanwhile, due to the security isolation of TrustZone, we avoid having to perform checks at all risky (e.g., pointer-based) write instructions, which is expensive.  
  CEFI : Command Execution Flow Integrity for Embedded Devices  
  A. Peng et al.  
  dynamically updated and each path to EndPA can be uniquely mapped to a value in the runtime. Speciﬁcally, before the start point StartPA, the id is initialized to 1, and at the end point EndPA, the id may have two diﬀerent values (i.e., 1, 2), which can uniquely distinguish two diﬀerent paths (StartPA→f2 →f4 →EndPA and StartPA→f3 →f4 →EndPA). When CEFI is deployed, it will instrument a secure gateway API call at each edge, but it only requires instrumentation at the edge f3 →f4, as the process of “id+ = 0” does not alter the calling context ID, making instrumentation unnecessary at other edges (such as StartPA→f2, StartPA→f3, and f2→f4 ). CEFI is lightweight, which can be attributed to the fact that only a limited amount of instrumentation is required. Besides, the involved CCE algorithm is safe (i.e., diﬀerent contexts are guaranteed to have diﬀerent ID), reversible (i.e., calling context can be faithfully decoded and recovered) [23]. With the help of CCE, we can generate an allowlist for each end point (i.e., command execution function), as shown in Algorithm 1, which is denoted as AllowlistGenerate(). The algorithm takes the pair set of user-deﬁned start and end points and the whole call graph of the ﬁrmware as inputs. The output is the allowlist. For each pair (i.e., StartPA, EndPA), the algorithm ﬁrst gets an AllowPathSet using the ValidPathAnalyzer(), and each item in the set represents an allowed path from StartPA to EndPA. Then, it encodes each edge of an allowed path using CallingContextEncoding(), and accumulates the weights (IDs) of each allowed path to EndPA using ComputeID. Speciﬁcally, each call statement on the allowed path will be instrumented to update the value of context identiﬁer, so that we can obtain a value at the EndPA and check it against the allowlist. Note that we assign one to the start point instead of zero as the traditional CCE algorithm does for quickly distinguishing the remaining paths to the command function with zero values without encoding them. After traversing every item in pairSet, we obtain the allowlist dictionary, in which the key is EndPA and the value is AllowedIDset. Instrumentation with ARMv8-M Security Extension. During instrumentation, the ﬁrmware reads the allowlist and resides in the read-only secure memory before initialization at runtime. Then, all allowed paths are encoded with CCE as mentioned before. Meanwhile, any ID update before the function call site will be transferred to TrustZone-protected Secure World, thus we can guarantee the security of dynamically computed calling context ID. To enforce the integrity check before command execution, we also intercept all call instructions to the command functions (end points) and redirect them to the CEFI veriﬁer in the Secure World through secure gateway veneers [3]. If the veriﬁcation is passed, the control ﬂow returns back to the intended command function.  
  CEFI : Command Execution Flow Integrity for Embedded Devices  
  Performance Overhead  
  For defense mechanisms to be deployable, they must result in low performance overhead [25]. This is especially important for resource-constrained embedded devices. To study the runtime overhead introduced into a system by CEFI , we measure the execution time with and without CEFI for each test program. We record end-to-end overhead, based on the time between when a device receives an event and when a device completes the resulting action. The ﬁve programs we selected all have multiple execution paths that are triggered by diﬀerent inputs. Therefore, we design diﬀerent inputs to trigger each branch of the program. The reported runtimes are averages over ten executions of each input. We present the runtime overhead and memory overhead in Table 2. The column #Trans lists the average transitions between the trusted and normal world of each programs. The results show that CEFI has very low overhead for each of the programs, with a geometric mean of just 0.18% over all of them. Memory overhead consists of Flash overhead and RAM overhead. For Flash overhead, CEFI adds instrumentation to encode and decode the ID at each call site. In addition, before the speciﬁc function, we need instrumentation to send the ID to the Secure World to match it against the allowlist. These instrumentations Table 2. Runtime Overhead and Memory Overhead Program  
  #Trans  
  Annotation Eﬀort  
  CEFI requires annotation (see Listing 1.3) to express relationship between the interaction channel’s entry point and the end point (i.e., command execution function). Although this is a manual process, it requires only minimal eﬀort (see Table 1). In our experiments, we anticipate that a few minutes are enough to complete annotations for a program, assuming that programmers have the knowledge of its design logic. While these programs may seem particularly small, this reﬂects the fact that most embedded programs are by nature required to be much smaller than regular software. We note that there are currently no standard benchmarks, but we chose these programs because they are also widely used for evaluation in related research.  
  6  
  Defenses. As previously mentioned, the static code analysis process implemented in Untangle can help library developers to ﬁnd global function pointers in their code that can be reached through exported functions. With this information, they can employ appropriate measures to prevent global function pointers from being used as attack vectors for control-ﬂow hijacking exploits. This paper demonstrated the relevance of securing function pointers to avoid control-ﬂow hijacking attacks in settings where CFI defenses are in place. Indirect call protection mechanisms already exist in LLVM: Indirect Function Call Checks (IFCC) checks the original function pointer’s signature against the signature of the function that is actually called through the function pointer. Unfortunately, this mitigation is still not adopted among the major Linux distributions as the most used among them (Ubuntu, Debian, Arch, Fedora) use GCC as the default compiler in their build systems. Consequently, until this countermeasure becomes widespread, the results of Untangle can still be used for exploitation and underline the relevance of indirect call protection mechanisms. Some defense proposals are currently being developed with this goal. FineIBT [4] is a software defense proposal for the Linux kernel that builds over CET, adding special instrumentation to the generated binary to enforce the veriﬁcation of hashes on function prologues whenever these are indirectly called. The hashes are computed over function, and function pointer prototypes at compile-time and checked at run-time whenever an indirect call happens.  
  8  
  Author Index  
  Author Index  
  Y Yu, Fangyi
9. DIMVA_3 conference:
Shop Our Holiday Gift Guide Find a Gift    
 Detection of Intrusions and Malware, and Vulnerability Assessment: 20th International Conference, DIMVA 2023, Hamburg, Germany, July 12-14, 2023, Proceedings  This book constitutes the proceedings of the 20th International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, DIMVA 2023, held in Hamburg, Germany, in July 2023.  
  Books | 2 
    Detection of Intrusions and Malware, and Vulnerability Assessment: 20th International Conference, DIMVA 2023, Hamburg, Germany, July 12-14, 2023, Proceedings  
 View More    
  Add to Wishlist     
    Detection of Intrusions and Malware, and Vulnerability Assessment: 20th International Conference, DIMVA 2023, Hamburg, Germany, July 12-14, 2023, Proceedings  
 View More    
 Paperback (1st ed. 2023)   
 Paperback (1st ed. 2023) 
 SHIP THIS ITEM  Ships in 1-2 days | Instant Purchase 
  PICK UP IN STORE  Your local store may have stock of this item. | Available within 2 business hours 
  Want it Today?  
  Check Store Availability 
    Overview  
 This book constitutes the proceedings of the 20th International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, DIMVA 2023, held in Hamburg, Germany, in July 2023.  
 Publisher: | Springer Nature Switzerland 
 Publication date: | 06/09/2023 
 Edition description: | 1st ed. 2023 
 Product dimensions: | 6.10(w) x 9.25(h) x (d)
10. DISC_0 conference:
Skip to primary content    
 DISC 2023    
    Search     Main menu  
  Local Information 
  Committees 
  DISC Extended Stay Support Scheme 
  Information for Sponsors 
  Calls | Call for Workshops and Tutorials 
  Detailed Program 
  Streaming 
  CO2 PODC/DISC Report 
 Home  
 About   
 The International Symposium on Distributed Computing  ( DISC   ) is an international forum on the theory, design, analysis, implementation and application of distributed systems and networks.  
 DISC 2023 will be held in L’Aquila, Italy  , at Gran Sasso Science Institute  . The conference will be held on October 9-13, 2023  .  
 DISC is organized in cooperation with the European Association for Theoretical Computer Science   (EATCS).  
 Search      
 Main Conference: October 10-12, 2023  
 Workshops + Conference: October 9-13, 2023  
 SPONSORS

output:1. DICTA_3 information:
2. DIGRA_0 information:
3. DIGRA_1 information:
4. DIGRA_2 information:
5. DIGRA_3 information:
6. DIMVA_0 information:
7. DIMVA_1 information:
8. DIMVA_2 information:
9. DIMVA_3 information:
10. DISC_0 information:
