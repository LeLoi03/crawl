{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeLoi03/crawl/blob/master/content/drive/MyDrive/Spacy-Custom/labeling/path_to_your_model\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNPkYbf1hjyx"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import json\n",
        "# from bs4 import BeautifulSoup\n",
        "\n",
        "# # Đường dẫn tới thư mục chứa các file HTML\n",
        "# HTML_DIR = \"./html-data\"  # Thay đổi đường dẫn này thành thư mục của bạn\n",
        "\n",
        "# # Đường dẫn tới file JSON để lưu kết quả\n",
        "# OUTPUT_FILE = \"train_data.json\"\n",
        "\n",
        "# # Hàm đọc và tách văn bản từ tệp HTML\n",
        "# def extract_text_from_html(file_path):\n",
        "#     with open(file_path, 'r', encoding='utf-8') as file:\n",
        "#         html_content = file.read()\n",
        "\n",
        "#     # Sử dụng BeautifulSoup để tách nội dung văn bản\n",
        "#     soup = BeautifulSoup(html_content, 'html.parser')\n",
        "#     text = soup.get_text(separator=\" \").strip()  # Tách văn bản với khoảng trắng giữa các thẻ\n",
        "\n",
        "#     return text\n",
        "\n",
        "# # Hàm xử lý tất cả các file trong thư mục HTML và lưu kết quả vào TRAIN_DATA\n",
        "# def process_html_files(directory):\n",
        "#     train_data = []\n",
        "\n",
        "#     for filename in os.listdir(directory):\n",
        "#         if filename.endswith(\".html\"):\n",
        "#             file_path = os.path.join(directory, filename)\n",
        "\n",
        "#             # Trích xuất văn bản từ HTML\n",
        "#             text = extract_text_from_html(file_path)\n",
        "\n",
        "#             # Tạo cấu trúc dữ liệu JSON cho từng file\n",
        "#             train_data.append({\n",
        "#                 \"text\": text,\n",
        "#                 \"entities\": []  # Nếu bạn muốn thêm nhãn, có thể điều chỉnh\n",
        "#             })\n",
        "\n",
        "#     return train_data\n",
        "\n",
        "# # Hàm lưu dữ liệu vào file JSON\n",
        "# def save_train_data(train_data, output_file):\n",
        "#     with open(output_file, 'w', encoding='utf-8') as f:\n",
        "#         json.dump(train_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "# # Chạy chương trình\n",
        "# train_data = process_html_files(HTML_DIR)\n",
        "# save_train_data(train_data, OUTPUT_FILE)\n",
        "\n",
        "# print(f\"Đã lưu dữ liệu huấn luyện vào {OUTPUT_FILE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAT10VZNh0E-",
        "outputId": "a3039aca-d9e3-4ee4-9841-ee0aa6a729df"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy9qM4v8hjy5",
        "outputId": "0d770205-41f6-4def-d624-da9f637438d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lỗi JSON ở dòng 6: Extra data: line 1 column 13390 (char 13389)\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Đọc dữ liệu từ file JSONL với xử lý lỗi\n",
        "def load_train_data(jsonl_file):\n",
        "    train_data = []\n",
        "    with open(jsonl_file, 'r', encoding='utf-8') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            try:\n",
        "                data = json.loads(line.strip())\n",
        "                text = data[\"text\"]\n",
        "                entities = []\n",
        "                for label_data in data[\"label\"]:\n",
        "                    start = int(label_data[0])\n",
        "                    end = int(label_data[1])\n",
        "                    label = label_data[2]\n",
        "                    entities.append((start, end, label))\n",
        "                train_data.append((text, {\"entities\": entities}))\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Lỗi JSON ở dòng {i + 1}: {e}\")\n",
        "                continue  # Bỏ qua dòng lỗi\n",
        "    return train_data\n",
        "\n",
        "# File JSONL của bạn\n",
        "TRAIN_FILE = \"/content/drive/MyDrive/Spacy-Custom/labeling/train-data/admin.jsonl\"\n",
        "TRAIN_DATA = load_train_data(TRAIN_FILE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXXa7Adahjy8",
        "outputId": "ea12ee67-78ae-48ad-be0f-d471b2077cd2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Call for Papers - ACM MM 2023 Twitter Instagram Email Us Ottawa, Canada Home About Authors Info Author’s Advocate Dates Call for Technical Demos and Videos Program Grand Challenges Call for Open-Source Call for Doctorial Symposium Call for Brave New Ideas Call for Tutorial Proposals Call for Panel Proposals Workshops Submission Instructions Call for Workshops Call for Papers Attend Venue & Accomodation Ottawa Travel Info Visa Support Letter Requests STUDENT TRAVEL GRANTS Organizing Committee Organizing Committee Reviewer and Area Chair Guidelines ACM Multimedia Policies Program Keynote Speakers Main Program BNI Program Grand Challenges Program Open Source Program Workshops Sponsors Sponsors Call for Sponsors Printing Service Registration Home About Authors Info Author’s Advocate Dates Call for Technical Demos and Videos Program Grand Challenges Call for Open-Source Call for Doctorial Symposium Call for Brave New Ideas Call for Tutorial Proposals Call for Panel Proposals Workshops Submission Instructions Call for Workshops Call for Papers Attend Venue & Accomodation Ottawa Travel Info Visa Support Letter Requests STUDENT TRAVEL GRANTS Organizing Committee Organizing Committee Reviewer and Area Chair Guidelines ACM Multimedia Policies Program Keynote Speakers Main Program BNI Program Grand Challenges Program Open Source Program Workshops Sponsors Sponsors Call for Sponsors Printing Service Registration Call for Papers ACM Multimedia 2023 calls for research papers presenting novel theoretical and algorithmic solutions addressing problems across the domain of multimedia and related applications. The conference also calls for papers presenting novel, thought-provoking ideas and promising (preliminary) results in realizing these ideas. The conference invites research papers of varying length from 6 to 8 pages, plus additional pages for the reference pages; i.e., the reference page(s) are not counted towards the page limit of 6 to 8 pages. Please note that there is no longer a distinction between long and short papers, but the authors may themselves decide on the appropriate length of the paper. All papers will undergo the same review process and review period. Submit your paper to Open Review: ACMMM 2023 Conference | OpenReview ( https://openreview.net/group?id=acmmm.org/ACMMM/2023/Conference ) Questions: Please send your inquiries to: acmmm2023pc@gmail.com Important Dates Please note: The submission deadline is at 11:59 p.m. of the stated deadline date Anywhere on Earth . Paper abstract deadline (firm deadline, no extension): 23 April 2023 Paper submission deadline: 30 April 2023 ; May 4, 2023 (due to holidays in some countries) Deadline for the supplementary materials is one week after that of the submissions (May 11, 2023) Regular Paper Reviews To Author: 30 June 2023 Regular Paper Rebuttal Deadline: 5 July 2023 Notification: 20 July 2023 Camera-ready Submission: 31 July 2023 Conference dates: October 28, 2023 – November 3, 2023 The conference invites papers in four major themes of multimedia: Engagement, Experience, Systems and Understanding. Theme: Engaging users with multimedia The engagement of multimedia with society as a whole requires research that addresses how multimedia can be used to connect people with multimedia artifacts that meet their needs in a variety of contexts. The topic areas included under this theme include: Emotional and Social Signals This area focuses on the analysis of emotional, cognitive (e.g., brain-based) and interactive social behavior in the spectrum of individual to small group settings. It calls for novel contributions with a strong human-centered focus specializing in supporting or developing automated techniques for analyzing, processing, interpreting, synthesizing, or exploiting human social, affective and cognitive signals for multimedia applications.) Multimedia Search and Recommendation To engage user in information access, search and recommendation requires not only understanding of data but also user and context. This area calls for novel solutions for user-centric multimedia search and recommendations, in either automatic or interactive mode, with topics ranging from optimization, user intent prediction, to personalized, collaborative or exploratory algorithms. (Note: Topics focusing primarily on indexing and scalability should be submitted to\\xa0“Multimedia systems: Data Systems indexing and management”) Summarization, Analytics, and Storytelling The information underlying multimedia is by nature multi-perspective. Allowing efficient multi-perspective and context-adaptive information access remains an open problem. This area calls for new and novel solutions that can compose, link, edit and summarize multimedia data into a compact but insightful, enjoyable and multi-perspective presentation to facilitate tasks such as multimedia analytics, decision making, searching and browsing. Theme: Experience One of the core tenants of our research community is that multimedia data contributes to the user experience in a rich and meaningful fashion. The topics organized under this theme are concerned with innovative uses of multimedia to enhance the user experience, how this experience is manifested in specific domains, and metrics for qualitatively and quantitatively measuring that experience in useful and meaningful ways. Specific topics addressed this year include: Interactions and Quality of Experience Papers under this topic should address human-centered issues. Topics include (i) novel interaction techniques and modalities for accessing, authoring, and consuming multimedia data, (ii) design and implementation of novel interactive media (iii) new methodologies, models, and metrics to understand and/or measure multimedia quality of experience. Social-good, fairness and transparency This area seeks works that explicitly\\xa0aim at benefitting society by addressing challenges such as those related to environment, privacy, education and health. Also works that improve the fairness and transparency of multimedia systems and applications are of interest for this area. Metaverse, Art and Culture Papers under this topic area should develop techniques that enable effective engagement of the public with art and other forms of cultural expression, balancing between sophisticated computational/engineering techniques and artistic / cultural purposes. Topics include (i) digital artworks, including hybrid physical digital installations; dynamic, generative, and interactive multimedia artworks; (ii) computational tools to support creativity, cultural preservation, and curation. Multimedia Applications Papers under this topic area should push the envelope of how multimedia can be used to improve the user experience in a rich and meaningful manner. We solicit papers that design, implement, and evaluate applications that employ multimedia data in surprising new ways or in application scenarios that user experience remains challenging based on today’s start-of-the-art, such as immersive telepresence, and distance education. Theme: Multimedia systems Research in multimedia systems is generally concerned with understanding fundamental trade-offs between competing resource requirements, developing practical techniques and heuristics for realizing complex optimization and allocation strategies, and demonstrating innovative mechanisms and frameworks for building large-scale multimedia applications. Within this theme, we have focussed on three target topic areas: Systems and Middleware This area seeks novel contributions that address performance issues in one of the systems components. Topics include operating systems, mobile systems, storage systems, distributed systems, programming systems and abstractions, and embedded systems. Papers must establish performance improvement or non-trivial tradeoffs through integration of multiple systems components or enhancing one of the system components. Transport and Delivery Papers under this topic area should address improvement to multimedia transport and delivery mechanisms over a computer network. Topics include network protocol enhancement, and supporting multimedia data with network mechanisms such as SDN and NFV, and in-network content placement. Data Systems Management and Indexing Papers under this topic should address performance issues related to data management and indexing to support multimedia access at a large scale, including browsing, searching, recommendation, analysis, processing, and mining. Topics include scalable systems and indexing techniques that support multimedia access and analytics. Theme: Understanding multimedia content Multimedia data types by their very nature are complex and often involve intertwined instances of different kinds of information. We can leverage this multi-modal perspective in order to understand the meaning of the world, often with surprising results through computational representations. Specific topics addressed this year include: Multimodal Fusion and Embedding In the real world, some problems are addressable only through a combination of multiple medium and/or modalities. This topic seeks new insights and solutions of how multi-perspective media information should be embedded and fused for novel problems as well as innovative applications. Vision and Language Recent research has driven the merging of vision and language in different ways, such as captioning, question-answering, and multi-modal chatbots. This area seeks new solutions and results that are specific to the problems of combining or bridging vision and language. Media Interpretation This area seeks novel processing of media-related information in any form that can lead to new ways of interpreting multimedia content. Examples include processing of image, video, audio, music, language, speech, or other sensory modalities, for interpretation, knowledge discovery, and understanding. Copyright ©2023 ACM MM 2023',\n",
              "  {'entities': [(65, 71, 'Location'),\n",
              "    (2608, 2621, 'SubmissionDate'),\n",
              "    (2624, 2635, 'SubmissionDate'),\n",
              "    (2756, 2768, 'SubmissionDate'),\n",
              "    (2944, 2979, 'ConferenceDate')]}),\n",
              " ('ALT 2023 | Call for papers The Conference Conference Schedule Accepted Papers Plenary Speakers Organization AALT Homepage For Authors Call for papers Submission instructions For Participants Registration Venue Information Visa Information Lunch Options Accommodation and transport Code of Conduct Home Call for papers Call for papers The Algorithmic Learning Theory (ALT) 2023 conference will be held in Singapore on Feb 20-23, 2023 .  The conference is dedicated to all theoretical and algorithmic aspects of machine learning. We invite submissions with contributions to new or existing learning problems including, but not limited to: Design and analysis of learning algorithms. Statistical and computational learning theory. Online learning algorithms and theory. Optimization methods for learning. Unsupervised, semi-supervised, and active learning. Interactive learning, planning and control, and reinforcement learning. Privacy-preserving data analysis. Learning with additional societal and strategic considerations: e.g., fairness, economics. Robustness of learning algorithms to adversarial agents. Artificial neural networks, including deep learning. High-dimensional and non-parametric statistics. Adaptive data analysis and selective inference. Learning with algebraic or combinatorial structure. Bayesian methods in learning. Learning in distributed and streaming settings. Game theory and learning. Learning from complex data: e.g., networks, time series. Theoretical analysis of probabilistic graphical models. While the primary focus of the conference is theoretical, authors are welcome to support their analysis by including relevant experimental results. Accepted papers will be published electronically in the Proceedings of Machine Learning Research (PMLR), and will be presented at the conference as a full-length talk.\\xa0 Authors of accepted papers will have the option of opting out of the proceedings in favor of a 1-page extended abstract, which will point to an open access archival version of the full paper reviewed for ALT. Important dates Paper submission deadline: September 30, 2022, 5:00PM EST Author feedback: Nov 15-22, 2022 Author notification: December 21, 2022 Dual submission policy Conferences: In general, submissions that are substantially similar to papers that have been previously published, accepted for publication, or submitted in parallel to other peer-reviewed conferences with proceedings may not be submitted to ALT. Journals: submissions that are substantially similar to papers that are already published in a journal at the time of submission may not be submitted to ALT. Rebuttal phase This year there will be a rebuttal phase during the review process. Initial reviews will be sent to authors before final decisions have been made. Authors will have an opportunity to provide a short response to the initial reviews. Awards ALT will award both best paper and best student paper awards. To be eligible for the best student paper award, the primary contributor(s) must be full-time students at the time of submission. The paper can be co-authored by other researchers. For eligible papers, authors must indicate at submission time if they wish their paper to be considered for a student paper award. The program committee may decline to make these awards or may split them among several papers. Contact All questions about submissions should be emailed to the PC chairs at alt2023pc@gmail.com . Copyright © 2023. All rights reserved. Designed by WPlook Studio.',\n",
              "  {'entities': [(404, 413, 'Location'),\n",
              "    (417, 432, 'ConferenceDate'),\n",
              "    (2095, 2113, 'SubmissionDate')]}),\n",
              " (\"AMIA 2023 Symposium Schedule-at-a-Glance | AMIA - American Medical Informatics Association Skip to main content AMIA Homepage My Account Login Search Toggle navigation AMIA Homepage Join AMIA Quick Links Members-only AMIA Connect Knowledge Center JAMIA ACI Journal My Account Login Search About AMIA About AMIA Leadership and Governance Diversity, Equity, and Inclusion Partner with AMIA AMIA 25x5 Why Informatics? Donate Awards Staff Contact Us Membership Membership Individual Membership Academic Forum Corporate Partnership & Membership Health System Membership Student Center Why AMIA? Communities Communities Working Groups AF Communities Fellows of ACMI (FACMI) Fellows of AMIA (FAMIA) Nursing Informatics Physicians in AMIA Women In AMIA Education & Events Education & Events Education Catalog 10x10 Virtual Courses Clinical Informatics Board Review Course AMIA Health Informatics Review Course (ARC) Health Informatics Essentials Artificial Intelligence Showcase Annual Symposium Clinical Informatics Conference Informatics Summit Calendar AMIA Knowledge Center Careers & Certifications Careers & Certifications Informatics Academic Programs Clinical Informatics Subspecialty AMIA Health Informatics Certification (AHIC) Certification Careers News & Publications News & Publications Journals Press Room AMIA News Center Podcasts Advertising Public Policy Public Policy Current Policy Priorities Public Policy Principles AMIA in Action Day on Capitol Hill About AMIA About AMIA Leadership and Governance Diversity, Equity, and Inclusion Partner with AMIA AMIA 25x5 Why Informatics? Donate Awards Staff Contact Us Membership Membership Individual Membership Academic Forum Corporate Partnership & Membership Health System Membership Student Center Why AMIA? Communities Communities Working Groups AF Communities Fellows of ACMI (FACMI) Fellows of AMIA (FAMIA) Nursing Informatics Physicians in AMIA Women In AMIA Education & Events Education & Events Education Catalog 10x10 Virtual Courses Clinical Informatics Board Review Course AMIA Health Informatics Review Course (ARC) Health Informatics Essentials Artificial Intelligence Showcase Annual Symposium Clinical Informatics Conference Informatics Summit Calendar AMIA Knowledge Center Careers & Certifications Careers & Certifications Informatics Academic Programs Clinical Informatics Subspecialty AMIA Health Informatics Certification (AHIC) Certification Careers News & Publications News & Publications Journals Press Room AMIA News Center Podcasts Advertising Public Policy Public Policy Current Policy Priorities Public Policy Principles AMIA in Action Day on Capitol Hill Join AMIA Home Education & Events AMIA 2023 Annual Symposium AMIA 2023 Annual Symposium November 11 - 15 New Orleans, LA #AMIA2023 Registration For Attendees Venue Program CME/CNE More Keynotes LIEAF Sponsors/Exhibitors AMIA 2023 Symposium Schedule-at-a-Glance View the detailed program Friday, November 10 Time Event 4:00 pm - 7:00 pm Registration Open Saturday, November 11 Time Event 7:00 am - 5:30 pm Registration Open 8:30 am - 12:00 pm Workshops 8:30 am - 4:30 pm Workshops 10:00 am - 10:30 am Coffee Break 1:00 pm - 4:30 pm Workshops 2:30 pm - 5:30 pm Student Paper Competition 2:30 pm - 3:00 pm Coffee Break Sunday, November 12 Time Event 6:30 am - 7:45 am Fun Run 7:00 am - 5:30 pm Registration Open 8:30 am - 12:00 am Workshops 10:00 am - 10:30 am Coffee Break 1:30 pm - 3:00 pm Opening Plenary Session and Keynote Presentation 3:30 pm - 5:00 pm Scientific Sessions 5:00 pm - 7:00 pm Welcome Reception - Exhibition Hall Open Monday, November 13 Time Event 7:30 am - 5:00 pm Registration Open 8:30 am - 10:00 am Scientific Sessions 10:00 am - 10:30 am Coffee Break 10:00 am - 1:00 pm Exhibition Hall Open 10:30 am - 12:00 pm Scientific Sessions 10:30 am - 1:00 pm Poster Session 1 Preview 12:10 pm - 1:40 pm Corporate Roundtables (by invitation) 1:45 pm - 3:15 pm Scientific Sessions 3:00 pm - 6:30 pm Exhibition Hall Open 3:30 pm - 5:00 pm Scientific Sessions 5:00 pm - 6:30 pm Poster Session 1 5:30 pm - 7:00 pm Working Group Meetings Tuesday, November 14 Time Event 7:30 am - 4:30 pm Registration Open 8:30 am - 10:00 am Scientific Sessions 10:00 am - 10:30 am Coffee Break 10:00 am - 1:00 pm Exhibition Hall Open 10:30 am - 12:00 pm Scientific Sessions 10:30 am - 1:00 pm Poster Session 2 Preview 12:10 pm - 1:40 pm Corporate Roundtables (by invitation) 12:15 pm - 1:15 pm State of the Association Meeting 1:45 pm - 3:15 pm Scientific Sessions 3:00 pm - 6:30 pm Exhibition Hall Open 3:30 pm - 5:00 pm Scientific Sessions 5:00 pm - 6:30 pm Poster Session 2 5:30 pm - 7:00 pm Working Group Meetings 7:30 pm - 9:00 pm Party with a Purpose 9:00 pm - 12:00 am AMIA Dance Party Wednesday, November 15 Time Event 7:30 am - 11:00 am Registration Open 8:00 am - 9:15 am Scientific Sessions 9:15 am - 9:45 am Coffee Break 9:45 am - 11:00 am Scientific Sessions 11:15 am - 12:15 pm Closing Session and Keynote Presentation Title Sponsor Join the AMIA Community Explore opportunities with the multidisciplinary, interprofessional home for over 5,000 informatics professionals and join the AMIA community today. Learn more Why AMIA? To Connect, Learn, Grow, and Lead. Watch the video Headquarters: 6218 Georgia Avenue NW, Suite #1 PMB 3077 Washington, DC 20011 Phone: 301.657.1291 AMIA's Facebook Profile AMIA's Facebook Profile AMIA's Twitter Profile AMIA's LinkedIn Profile AMIA's YouTube Channel © 2024 American Medical Informatics Association. All Rights Reserved. Contact Us Site Map Privacy Back to top We use cookies on this site to enhance your user experience. By clicking the Accept button, you agree to us doing so. More info No, thanks Accept\",\n",
              "  {'entities': [(2725, 2741, 'ConferenceDate'),\n",
              "    (2742, 2757, 'Location'),\n",
              "    (3001, 3012, 'ConferenceDate')]}),\n",
              " ('Acivs 2023 Conference Acivs 2023 News Registration Scientific Program Call for papers Organisation Earlier editions Author pages Reviewer pages PC pages SC pages Forgot password? Contact Information About this website Acivs 2023 August 21-22, 2023 Kumamoto, Japan Advanced Concepts for Intelligent Vision Systems Conference proceedings The proceedings of Acivs 2023\\n( LNCS volume 14124 )  are available at \\nthe  Springer on-line.website. Acivs 2023 is a conference focusing on techniques\\nfor building adaptive, intelligent, safe and secure imaging systems.\\n Acivs 2023 consists of\\ntwo days of lecture sessions, both regular (25 minutes) and invited\\npresentations, and poster sessions. Conference topics Papers must show original and high-quality work, from basic research to\\npre-industrial application. Both classical research papers and application papers are welcome.\\nTopics of interest include, but are not limited to: Sensing, Representation, Modeling, and Registration Motion Estimation, Registration, and Fusion Compression, Coding, and Transmission Image & Video Interpretation, Deep Learning Restoration and Enhancement Detection, Recognition, Retrieval, and Classification Color, Multi and Hyper-spectral, Polarimetric Imaging Biometrics, Forensics, and Security Image & Video Quality Models Proceedings, journal special issue and student paper award The proceedings of Acivs 2023 will be published by Springer in the Lecture Notes in Computer Science series and are listed in the ISI proceedings index. LNCS is published, in parallel to the printed books, in full-text electronic form via Springer\\'s internet platform\\n( http://www.springerlink.com ). Authors of most innovative papers will be invited to submit a substantially extended version of the conference paper for possible publication in a special issue of the IOS international journal Integrated Computer-Aided Engineering (Impact Factor 4.827). As for previous years and thanks to sponsorship by Springer, Acivs 2023 will feature a\\n1,000 € Best Student Paper Award. Tutorials Call Tutorials at Acivs 2023 will be 2hr 20min, everyday. Proposals for tutorials must be submitted to the\\nSteering Committee. Acivs 2023 will also feature several social activities (included in the registration fee), including an opening reception, a conference dinner and a cultural  activity. Paper submission and review process Prospective authors should prepare a full paper and submit it\\nelectronically. The paper should consist of 8-12\\npages in A4 format and should conform to the style guidelines outlined on the Acivs 2023\\nwebsite. Detailed author guidelines are provided below. To upload your paper, first create an author account . Then follow the intructions.\\nIf after submission you would like to change some details, or upload a new version before the\\ndeadline, then  visit the list of papers you have submitted. Submitted papers should include all\\nauthor names. The anonymous reviewers will therefore know\\nwho the authors are (\"single blind\" system). LaTeX style sheets, MSWord templates and cal\\nmore detailed information on the submission process can be found on the Acivs 2023 website ( http://acivs.org/acivs2023/ ). It is absolutely essential that submitted papers are based on the provided templates . Accepted papers which do not satisfy the requirements or which cannot be processed without changes will be returned to the authors and may\\nnot be published. All submissions will be reviewed by at least 2 members of the Program\\nCommittee; additional reviewers will be consulted if needed. The papers\\nshould provide sufficient background information and should clearly indicate\\nthe original contribution.\\nThey should state and discuss the main results and\\nprovide adequate references. Paper submission implies that one of the\\nauthors will present the paper if it is accepted.\\nDuplicate submissions to other conferences, or\\nmodified copies of earlier papers are not acceptable. Submission implies the authors have obtained\\nall IP clearance from their employers, eg. the submitted material\\ncontains nothing that is commercial-in-confidence. Important deadlines May 15, 2023 Full paper submission June 1, 2023 Notification of acceptance June 30, 2023 Camera-ready papers due July 7, 2023 Registration deadline for authors of accepted papers July 7, 2023 Early registration deadline August 21-22, 2023 Acivs 2023 Organising\\nCommittee Patrice Delmas,\\nThe University of Auckland,\\nAuckland,\\nNew Zealand. Toshifumi Mukunoki,\\nKumamoto University,\\nKumamoto,\\nJapan. Steering\\nCommittee Jacques Blanc-Talon,\\nDGA,\\nToulouse,\\nFrance. Patrice Delmas,\\nThe University of Auckland,\\nAuckland,\\nNew Zealand. Wilfried Philips,\\nGhent University - imec,\\nGhent,\\nBelgium. Paul Scheunders,\\nUniversity of Antwerp,\\nAntwerp,\\nBelgium. Program committee Hamid Aghajan, Ghent University - imec,\\nGhent,\\nBelgium. João Ascenso, Instituto de Telecomunicações,\\nLisboa,\\nPortugal. Sebastiano Battiato, University of Catania,\\nCatania,\\nItaly. George Bebis, University of Nevada,\\nReno,\\nUSA. Fabio Bellavia, Università degli Studi di Palermo,\\nPalermo,\\nItaly. Jenny Benois-Pineau, University of Bordeaux,\\nBordeaux,\\nFrance. Janusz Bobulski, Czestochowa University of Technology,\\nCzęstochowa,\\nPoland. Egor Bondarev, Technische Universiteit Eindhoven,\\nEindhoven,\\nThe Netherlands. Salah Bourennane, Ecole Centrale de Marseille,\\nMarseille,\\nFrance. Catarina Brites, Instituto de Telecomunicações,\\nLisboa,\\nPortugal. Vittoria Bruni, University of Rome La Sapienza,\\nRoma,\\nItaly. Odemir Martinez Bruno, University of São Paulo,\\nSão Paulo,\\nBrazil. Giuseppe Cattaneo, University of Salerno,\\nFisciano,\\nItaly. Jocelyn Chanussot, Université de Grenoble Alpes,\\nGrenoble,\\nFrance. Kacem Chehdi, ENSSAT,\\nLannion,\\nFrance. Pamela Cosman, University of California,\\nSan Diego,\\nUSA. Mihai Datcu, DLR (German Aerospace Center),\\nKöln,\\nGermany. Patrice Delmas, The University of Auckland,\\nAuckland,\\nNew Zealand. Stéphane Derrode, Ecole Centrale de Lyon,\\nLyon,\\nFrance. Israel Mendoça Dos Santos, Kumamoto University,\\nKumamoto,\\nJapan. Christine Fernandez-Maloigne, Poitiers University,\\nChasseneuil,\\nFrance. Jérôme Gilles, San Diego State University,\\nSan Diego,\\nUSA. Daniele Giusto, Università degli Studi di Cagliari,\\nCagliari,\\nItaly. Christine Guillemot, INRIA,\\nRennes Cedex,\\nFrance. Monson Hayes, George Mason University,\\nFairfax,\\nUSA. Dimitris Iakovidis, University of Thessaly,\\nLamia,\\nGreece. Yuji Iwahori, Chubu University,\\nKasugai,\\nJapan. Hamid Krim, North Carolina State University,\\nRaleigh,\\nUSA. Bogdan Kwolek, AGH University of Science and Technology,\\nKrakow,\\nPoland. Ting-Lan Lin, National Taipei University of Technology,\\nTaipei,\\nTaiwan. Ludovic Macaire, Université Lille,\\nVilleneuve d\\'Ascq,\\nFrance. Jean-Michel Morel, ENS,\\nCachan,\\nFrance. Toshifumi Mukunoki, Kumamoto University,\\nKumamoto,\\nJapan. Adrian Munteanu, Vrije Universiteit Brussel,\\nBrussels,\\nBelgium. Shigeki Nakauchi, Toyohashi University of Technology,\\nToyohashi,\\nJapan. María Navascués, Universidad de Zaragoza,\\nZaragoza,\\nSpain. António J. R. Neves, University of Aveiro,\\nAveiro,\\nPortugal. Jennifer Newman, Iowa State University,\\nAmes,\\nUSA. Jun Otani, Kumamoto University,\\nKumamoto,\\nJapan. Jussi Parkkinen, University of Eastern Finland,\\nJoensuu,\\nFinland. Rudi Penne, University of Antwerp,\\nAntwerp,\\nBelgium. Giovanni Ramponi, University of Trieste,\\nTrieste,\\nItaly. Florent Retraint, Université de Technologie de Troyes,\\nTroyes,\\nFrance. Luis Salgado, Universidad Politécnica de Madrid,\\nMadrid,\\nSpain. Natalia Schmid, West Virginia University,\\nMorgantown,\\nUSA. Guna Seetharaman, U.S. Naval Research Laboratory,\\nUSA. Changming Sun, CSIRO,\\nSydney,\\nAustralia. Tamas Sziranyi, University of Technology and Economics,\\nBudapest,\\nHungary. Jean-Philippe Thiran, EPFL,\\nLausanne,\\nSwitzerland. Nadège Thirion-Moreau, SeaTech - Université de Toulon,\\nToulon,\\nFrance. Sylvie Treuillet, Université d\\'Orléans,\\nOrléans,\\nFrance. Alex Vasilescu, UCLA,\\nUSA. Luisa Verdoliva, Università degli Studi di Napoli Federico II,\\nNapoli,\\nItaly. Serestina Viriri, University of KwaZulu-Natal,\\nDurban,\\nSouth Africa. Bing Xue, Victoria University,\\nWellington,\\nNew-Zealand. Gerald Zauner, University of Applied Sciences Upper Austria,\\nWels,\\nAustria. Josiane Zerubia, INRIA,\\nSophia-Antipolis,\\nFrance. Djemel Ziou, Sherbrooke University,\\nSherbrooke,\\nCanada. This software generating these pages is © Wilfried Philips (not Ghent University), 2002-2024. \\n All rights reserved. The data on this page is  © Acivs 2023 . All rights reserved. The server hosting this website is owned by the department of Telecommunications and \\nInformation Processing (TELIN) of Ghent University. Problems with the website should be reported to Wilfried Philips . \" This page was generated on Tuesday September 24th, 2024 11:52:39. ✖ We use cookies to enhance your experience. By continuing to visit this site you agree to our use of cookies. More info cookie script',\n",
              "  {'entities': [(229, 247, 'ConferenceDate'),\n",
              "    (258, 263, 'Location'),\n",
              "    (4126, 4138, 'SubmissionDate'),\n",
              "    (4346, 4364, 'ConferenceDate'),\n",
              "    (4515, 4520, 'Location')]}),\n",
              " ('AICCSA2023 – ACS/IEEE Skip to content IEEE AICCSA 2023 National Telecommunication Institute (NTI) - Smart Village, Giza, Egypt IEEE AICCSA 2023 National Telecommunication Institute (NTI) - Smart Village, Giza, Egypt IEEE AICCSA 2023 4-7 December 2023 Home Committee Important dates Call For Call for Papers (Oral or Poster) PhD Forum Call for Workshops Proposals Call for Tutorial Proposals Registration Final Camera Ready Keynote Speakers Tracks and Subtopics Workshops W-STEM Sponsors and Exhibitors Scholarships Transportation & Accommodation Final Program Venue & Social Events Menu Home Committee Important dates Call For Call for Papers (Oral or Poster) PhD Forum Call for Workshops Proposals Call for Tutorial Proposals Registration Final Camera Ready Keynote Speakers Tracks and Subtopics Workshops W-STEM Sponsors and Exhibitors Scholarships Transportation & Accommodation Final Program Venue & Social Events 20th ACS/IEEE International Conference on Computer Systems and Applications (AICCSA 2023)\\xa0 \\xa04\\xa0– 7 December, 2023 AICCSA 2023 The ACS/IEEE International Conference on Computer Systems and Applications (AICCSA) is the premier conference covering all contemporary areas in computer systems and applications and hence it is an international forum for leading researchers and practitioners in this important and rapidly changing disciplines. AICCSA 2023 will be held in the lovely and highly vibrant National Telecommunication Institute (NTI) – Smart Village, Giza, Egypt. Past AICCSA Conferences AICCSA 2022 || AICCSA 2021 || AICCSA 2020 || AICCSA 2019 || AICCSA 2018 || AICCSA 2017 || AICCSA 2016 || AICCSA 2015 || AICCSA 2014 || AICCSA 2010 || AICCSA 09 || AICCSA 08 || AICCSA 07 || AICCSA 06 || AICCSA 05 || AICCSA 03 || AICCSA 01 || Symposiums and Workshops in conjunction with AICCSA 2023 Recent News – 15/01/2023 : Launching AICCSA 2023 website – 25/04/2023 : The PhD Symposium can now run in Hybrid mode (in Person and Online) to all as many PhD students to benefit from the symposium as possible. – 10/05/2023 : The deadline for workshops and Tutorial Proposals are extended to 30th June (Firm). 8 Workshops have already been accepted and will be added on the website soon. – 07/06/2023 : Following the many requests from authors the Deadline for submission extended to Sunday 18th June 2023 – 08/06/2023 : The steering committee decided to offer a number of scholarships for students, which will mainly be translated into discounted registration fees. more details to be provided soon – 28/07/2023 : Launch of the Second round of Submissions: check important Dates – 28/07/2023 : registration fees are now published with different categories, including\\xa0 one day registrations, and virtual attendance rates as well as rates for local participants and scholarships with considerable discounts for students. check REGISTRATION – 04/12/2023: program last version with sessions links Search Search Sponsors Copyright 2024 - AICCSA Close Menu Close Menu',\n",
              "  {'entities': [(121, 126, 'Location'),\n",
              "    (210, 215, 'Location'),\n",
              "    (233, 250, 'ConferenceDate'),\n",
              "    (1010, 1030, 'ConferenceDate'),\n",
              "    (1479, 1484, 'Location'),\n",
              "    (2100, 2109, 'SubmissionDate')]}),\n",
              " (\"ANT 2023 The 14th International Conference on Ambient Systems, Networks and Technologies March 15 - 17, 2023, Leuven, Belgium to ANT 2023 The 14th International Conference on Ambient Systems, Networks and Technologies (ANT 2023) is a leading international conference for researchers and industry practitioners to share their new ideas, original research results and practical development experiences from all Ambient Systems, Networks and Technologies related areas. ANT 2023 will be held in conjunction with the 6th International Conference on Emerging Data and Industry (EDI40) . ANT 2023 will be held in Leuven, Belgium. Leuven is the capital of the province of Flemish Brabant in Belgium. It is located about 25 kilometres (16 miles) east of Brussels. It is the 10th largest municipality in Belgium and the fourth in Flanders. Leuven is home to the Katholieke Universiteit Leuven, the largest and oldest university of the Low Countries and the oldest Catholic university still in existence. The related university hospital of UZ Leuven, is one of the largest hospitals of Europe. The city is also known for being the headquarters of Anheuser-Busch InBev, the world's largest brewer and one of the five largest consumer-goods companies in the world. Leuven's Town Hall is one of the best-known Gothic town halls worldwide and Leuven's pride and joy. It took three architects and thirty years to build it. Leuven's 'Hall of Fame' features 236 statues, which were only added to the façade after 1850. There are 220 men and 16 women in total. On the bottom floor are famous Leuven scientists, artists and historical figures, dressed in Burgundian garb. The first floor is reserved for the patron saints of the various parishes of Leuven. Above them the façade is adorned by the counts and dukes of Brabant while the towers primarily feature biblical figures. All ANT 2023 accepted papers will be published by Elsevier Science in the open-access Procedia Computer Science series on-line. Procedia Computer Science is hosted by Elsevier on www.Elsevier.com and on Elsevier content platform ScienceDirect (www.sciencedirect.com), and will be freely available worldwide. All papers in Procedia will be indexed by Scopus (www.scopus.com) and by Thomson Reuters' Conference Proceeding Citation Index (http://thomsonreuters.com/conference-proceedings-citation-index/).  All papers in Procedia will also be indexed by Scopus (www.scopus.com) and Engineering Village (Ei) (www.engineeringvillage.com). This includes EI Compendex (www.ei.org/compendex). Moreover, all accepted papers will be indexed in DBLP (http://dblp.uni-trier.de/). The papers will contain linked references, XML versions and citable DOI numbers. You will be able to provide a hyperlink to all delegates and direct your conference website visitors to your proceedings. =================================================================== In Conjunction with The 6th International Conference on Emerging Data and Industry (EDI40) Copyright ©. All rights reserved. Theme originally designed by BFT. Recreated and customized by Nan . Home page | Call for Papers | Workshop | Registration | Conference Program | Contact us\",\n",
              "  {'entities': [(89, 108, 'ConferenceDate'),\n",
              "    (118, 125, 'Location'),\n",
              "    (615, 622, 'Location')]}),\n",
              " (\"ACM CCS 2023 Home CCS30 Workshops Keynotes Call For Call For Artifacts Call For Paper Call For Posters Call For Sponsors Call For Workshops Attending Venue Location Venue Navigator Student Travel Grants Visa Letter Registration Hotel Offers Childcare Travel Guide Program Proceedings CCS Conference '23 AISEC '23 ARTMAN '23 ASHES '23 CCSW '23 CPSIoTSec '23 MTD '23 SaTS '23 SCORED '23 WAHC '23 WPES '23 HEPack4ML '23 Photo Album Organization Organizing Committee Program Committee Poster Committee AE Committee Code Code of Conduct Diversity and Inclusion Call For Paper Last Update : [2 September, 2023] The 30th ACM Conference on Computer and Communications Security (CCS) seeks submissions presenting novel contributions related to all real-world aspects of computer security and privacy. \\n                            Theoretical papers must make a convincing case for the relevance of their results to practice. Authors are encouraged to write the abstract and introduction of their paper in a way that makes the results accessible and compelling to a general computer-security researcher. \\n                            In particular, authors should bear in mind that anyone on the program committee may be asked to review any paper. CCS has 2 Review Cycles In 2023. For each submission, one of the following decisions will be made: Accept Papers in this category will be accepted for publication in the proceedings and presentation at the conference,\\n                                            possibly after making minor changes with the oversight of a shepherd. Minor Revision Papers in this category are considered to be promising but need some minor additional work (e.g., minor experiments, proofs to minor lemmas). \\n                                            Authors will be given the opportunity to resubmit such papers, with appropriate revisions, in which case they should clearly explain in a well-marked appendix how the revisions address the comments of the reviewers. \\n                                            The revised paper will then be re-evaluated, and either accepted or rejected. Reject Papers in this category are declined for inclusion in the conference. \\n                                            Papers rejected from the first review cycle may not be submitted again (even in revised form) to the second review cycle. Authors of each accepted paper must ensure that at least one author registers for the conference, and that their paper is presented in-person at the conference if at all possible. Important Dates and Deadlines Quick Overview: 19 January, 2023 [First Review Cycle] The submission deadline of the first round review. Submit your paper at https://ccs2023a.hotcrp.com/ 4 May, 2023 [Second Review Cycle] The submission deadline of the second round review. Submit your paper at https://ccs2023b.hotcrp.com/ First Review Cycle: 19 January, 2023 : Paper Submission Deadline Submission Site: https://ccs2023a.hotcrp.com 17 March, 2023: Author Notification Second Review Cycle: 4 May, 2023 : Paper Submission Deadline Submission Site: https://ccs2023b.hotcrp.com 3 June, 2023 : Early Reject Notification 23 - 27 June, 2023 : Author Rebuttal 28 June - 7 July, 2023 : Optional Reviewer-Author Interaction 2 September, 2023 : Author Notification Paper Submission Information Quick Overview: 11:59 PM AoE / (UTC-12) Submission must be received by 11:59 PM AoE (UTC-12) on the day of the corresponding deadline. No Double Submission Submitted papers must not substantially overlap with papers that have been published or accepted for publication,\\n                                            or that are simultaneously in submission to a journal, conference, or workshop with published proceedings. Must be anonymized All submission should be properly anonymized; papers not properly anonymized may be rejected without review. All submissions must be received by 11:59 PM AoE (UTC-12) on the day of the corresponding deadline. \\n                            Submitted papers must not substantially overlap with papers that have been published or accepted for publication, or that are simultaneously in submission to a journal, conference, or workshop with published proceedings. \\n                            All submissions should be properly anonymized; papers not properly anonymized may be rejected without review. All submitted papers will be evaluated based on their merits, particularly their importance to practical aspects of computer and communications security and privacy, novelty, quality of execution, and presentation. \\n                            For papers that might raise ethical concerns, authors are expected to convince reviewers that proper procedures (such as IRB approval or responsible disclosure) have been followed, and due diligence has been made to minimize potential harm. Submitted papers may be rejected for being out of scope, at the discretion of the PC chairs. Authors who have questions about whether their paper is in scope are encouraged to ask the PC chairs in advance. Paper Format Quick Overview: PDF File Format Submission must be converted or readied in PDF File Format. Please contact your IT service provider if you have any difficulties on preparing your submission(s). Double-Column ACM format (Sigconf style) Please refer ACM Proceedings Template for more information. 12 Pages Maximum Bibliography, Well-marked Appendices, and Supplementary Material are excluded. Submissions must be a PDF file in double-column ACM format (see ACM Proceedings Template , using the sigconf style ), no more than 12 pages long , excluding the bibliography, well-marked appendices, and supplementary material. \\n                            Note that reviewers are not required to read the appendices or any supplementary material. Authors should not change the font or the margins of the ACM format. Submissions not following the required format may be rejected without review. Providing Artifacts at Submission Time Submissions whose claimed contributions rely on artifacts (e.g., code, models, data sets) are expected to make these accessible to the reviewers, unless there are good reasons not to, in which case these reasons must be mentioned in the submission. Submissions whose claimed contributions do not rely on artifacts do not need to submit artifacts. Optional Artifact Evaluation (New!) A published scientific paper consists of a constellation of artifacts that extend beyond the document itself: software, hardware, evaluation data and documentation, raw survey results, mechanized proofs, models, test suites, benchmarks, and so on. \\n                        To emphasize the importance of such artifacts, the benefits to the authors and the community as a whole, and promote the reproducibility of experimental results, ACM CCS will, for the first time, introduce an optional artifact evaluation (AE) process, inspired by similar efforts at several other conferences. \\n                        All authors of accepted papers (including shepherd approved and minor revisions) are encouraged to submit artifacts for AE. Each artifact submitted will be reviewed by the Artifact Evaluation Committee (AEC); a special call for artifacts will follow in early January. Program Committee Chairs Email: ccs2023-pcchairs@cispa.de Cas Cremers CISPA Helmholtz Center for Information Security Engin Kirda Northeastern University Track Chairs Manuel Egele Boston University Software Security Nick Nikiforakis Stony Brook University Web Security Leyla Bilge NortonLifeLock Research Group Network Security Steve Kremer Inria Formal Methods and Programming Languages Veelasha Moonsamy Ruhr University Bochum Hardware, Side Channels, and Cyber-Physical Systems Dario Fiore IMDEA Software Institute Applied Cryptography Selcuk Uluagac Florida International University Machine Learning and Security Elissa Redmiles Max Planck Institute Security Usability and Measurement Ghassan Karame Ruhr-University Bochum Blockchain and Distributed Systems Rob Jansen U.S. Naval Research Laboratory Privacy and Anonymity ACM CCS 2023 features a multi-track format. Each track operates as a separate mini-conference, with its own Track Program Chair and Track Program Committee. \\n                            The overall process is managed by the Conference Co-Chairs (Cas Cremers and Engin Kirda). At the time of submission, authors must select one track, which should be the most relevant to the topic of the paper. We understand that some papers might span multiple topics. \\n                            In specific cases, PC members might be asked to provide reviews for papers outside their track, in an effort to provide the best possible reviews to the authors. The chairs may decide to move a paper to another track. Conflicts of Interest The conference requires cooperation from both authors and program-committee members to ensure a fair review process. \\n                        For this purpose, authors must report all program-committee members who, in their opinion, have a conflict of interest and therefore may not be able to provide an unbiased review. Mandatory declared conflicts of interest include current or former doctoral advisor/advisee, members of the same institution, close family members, and recent co-authors (within the past 2 years). For any other declared conflict, authors are required to explain the nature of the conflict, which will be reviewed by the Conference Co-Chairs and the Track Chairs. \\n                        The chairs reserve the right to request further explanation and can remove non-mandatory conflicts at their discretion. Track Chairs are allowed to submit papers, and those papers will be handled by the Conference Co-Chairs. They are only allowed to submit two papers in their own track, and any number in other tracks. Program-committee members who have a genuine conflict of interest with a paper, including the Conference Co-Chairs and the Track Chairs, will be excluded from evaluation and discussion of that paper. \\n                        When a Track Chair has a conflict, the paper will be handled by the Conference Co-Chairs. When a Conference Co-Chair is conflicted, the other Co-Chair will be responsible for managing that paper. \\n                        When both Conference Co-Chairs are in conflict, a committee member will be appointed to handle the paper. Conference Co-Chairs are not allowed to be authors or co-authors of any submissions. Policy for Peer-Review Integrity All SIGSAC sponsored conferences and workshops are required to follow ACM policies against harassment activities and ACM Code of Ethics and Professional Conduct. Also all authors, PC members and non-PC reviewers are required to follow ACM Publications Policies. Particularly, we require all reviewers to uphold the integrity of the peer review process and avoid conflict of interest of any form (e.g., reviewer collusion ring). Those who violate these policies will be penalized according to ACM policies . \\n                        If you would like to report a violation, please contact program chairs of your conferences/workshops or SIGSAC officers. We are committed to protecting the confidentiality of your communication. Diversity and Inclusion ACM CCS is committed to promoting diversity and inclusion in our community. \\n                        If you have suggestions, concerns, or complaints related to biases or sexual harassment, we encourage you to reach out to the Conference Co-Chairs. \\n                        We are committed to protecting the anonymity of such reports and helping to address your concerns. \\n                        We value your feedback and ideas to help us all build a healthier and more welcoming community. We encourage the authors to be mindful of not using language or examples that further the marginalization, stereotyping, or erasure of any group of people, especially historically marginalized and/or under-represented groups (URGs) in computing. Of course, exclusionary treatment can arise unintentionally. \\n                        Be vigilant and actively guard against such issues in your writing. Reviewers will also be empowered to monitor and demand changes if such issues arise in your submissions. Please check the link for more information. Copyright © 2022-2023 ACM/SIGSAC. DTU Compute\",\n",
              "  {'entities': [(2580, 2596, 'SubmissionDate')]}),\n",
              " ('AiML 2022 – Advances in Modal Logic, Rennes 2022 Skip to content Skip to content Home Important dates Invited speakers Accepted papers Call for papers Registration Program Local information Contact us LAMAS&SR 2022 Language: English Français Home Advances in Modal Logic Rennes, August 22-25 2022 Advances in Modal Logic 2022 Rennes, August 22-25 Advances in Modal Logic is an initiative aimed at presenting the state of the art in modal logic and its various applications. The initiative consists of a conference series together with volumes based on the conferences. Registrations are not possible any more. Information about the AiML series can be obtained at http://www.aiml.net . AiML 2022 is co-located with the Workshop on Logical Aspects of  Multi-Agent Systems and Strategic Reasoning ( LAMAS&SR 2022 ) in IRISA . About COVID-19 Local organizers are following closely the evolution of the pandemic situation. Our preference is for a full in-person event, but we will employ an online or hybrid format according to the situation. Organizing committee All organizing staff are affiliated to IRISA , except for additional affiliations listed next to their name. Sophie Pinchinat (chair) Sophie Maupilé Aurélie Amet Guillaume Aucher Dylan Bellier Aymen Bazouzi Frédéric Bouvet Lénaïg Cornanguer Catherine Jacques-Orban Antoine L’Azou Pierre Le Scornet Hervé Marchand Nicolas Markey Alexandre Terefenko, Université de Mons Adrien Thomas Programme committee chair David Fernández Duque, University of Ghent Alessandra Palmigiano, Vrije Universiteit Amsterdam Programme committee Erman Acar, VU Amsterdam Bahareh Afshari, University of Amsterdam Natasha\\xa0Alechina, University of Utrecht Steve Awodey, Carnegie Mellon Philippe Balbiani, CNRS, Toulouse University Marta Bilkova, Academy of Sciences of the Czech Republic Xavier Caicedo, University of los Andes Walter Carnielli, State University of Campinas Agata Ciabattoni, TU Wien Ivano Ciardelli, University of Munich Willem Conradie, University of the Witwatersrand Laurent De Rudder, University of Liege Tommaso Flaminio, Spanish National Research Council Sabine Frittella, INSA Centre Val de Loire Nick Galatos, University of Denver Sam van Gool, IRIF, Université de Paris Giuseppe Greco, VU Amsterdam Thomas Icard, Stanford University Ramon Jansana University of Barcelona Peter Jipsen,\\xa0Chapman University Joost Joosten, University of Barcelona Stanislav Kikot, Sber Automotive Technologies Philip Kremer, University of Toronto Alexander Kurz, Chapman University Roman\\xa0Kuznets, TU Wien Fei Liang, University of Shandong Minghui Ma, Sun Yat-Sen University, Guangzhou Morteza Moniri, Shahid Beheshti University Tommaso Moraschini, University of Barcelona Drew Moshier, Chapman University, Orange CA Eric Pacuit, University of Maryland Fedor Pakhomov, Ghent University Sophie Pinchinat, IRISA, University of Rennes I Daniele Porello, University of Genova Vit Puncochar, Academy of Sciences of the Czech Republic Revantha Ramanayake, University of Groningen Christian Retoré, University of Montpellier Umberto Rivieccio, Universidade Federal do Rio Grande do Norte Claudette Robinson, University of Johannesburg Gabriel\\xa0Sandu, University of Helsinki Igor Sedlar, Academy of Sciences of the Czech Republic Ilya Shapirovsky, New Mexico State University Apostolos Tzimoulis, VU Amsterdam Sara Uckelman,\\xa0Durham University Jouko Väänänen, University of Helsinki Heinrich Wansing, University of Bochum Frank Wolter, University of Liverpool Important dates Abstracts of full papers submission deadline: 7 March 2022 Full papers submission deadline: 14 March 2022 Full papers acceptance notification: 13 May 2022 Short presentations submission deadline: 23 May 2022 Short presentations acceptance notification: 6 June 2022 Final version of full papers and short presentations due: 13 June 2022 Registration\\xa0deadline:\\xa010\\xa0August\\xa02022 Conference: 22 August — 25 August 2022 (followed by LAMAS&SR 25 August — 26 August) Invited speakers Wesley Holliday Wesley H. Holliday is Professor of Philosophy and Chair of the Group in Logic and the Methodology of Science at the University of California, Berkeley. He earned his PhD from Stanford University in 2012, working under the supervision of Johan van Benthem and Krista Lawlor. His dissertation on epistemic logic won the E. W. Beth Dissertation Prize in 2013. At Berkeley he has worked mainly on modal and nonclassical logic, logic and natural language, logic and probability, and logic and social choice theory. Some of his papers on modal logic have appeared in AiML 2010, 2012, 2014, 2016, 2018, and 2020. Invited\\xa0talk\\xa0AiML 2022\\xa0: Non-classical modal logic for natural language Francesca Poggiolesi I obtained my PhD in Philosophy from the University of Florence, Italy and the University of Paris 1 Panthéon-Sorbonne, France. Before joining the IHPST UMR 8590, CNRS, where I have been a permanent member since 2015, I have held research and teaching positions at the VUB, Belgium and Aix-Marseille University. I have been actively working on the proof theory for modal logic for almost ten years. More recently I have moved my interests to more philosophical notions such as grounding or explanations; I use the techniques of proof theory to attempt to provide a rigorous account of these concepts. Invited\\xa0talk AiML 2022\\xa0: Explanations in Logic Willem Conradie Willem Conradie is a professor in the School of Mathematics at the University of the Witwatersrand (WITS), South Africa, where is also Assistant Dean for Teaching and Learning in the Faculty of  Science. Previously he was an associate professor and head of  department at the University of Johannesburg. After completing the  Master of Logic programme at the ILLC in 2002, he received a PhD in  Mathematics from WITS in 2007 under the supervision of Valentin Goranko. His main research  interests are in non-classical logics and their applications, on which he publishes regularly, with some recent contributions addressing the correspondence theory for non-distributive modal logics, new polarity and graph-based semantic for non-distributive modal logics suitable for interpretations of  these formalisms as logics of categorisation systems or as hyper-constructivists logics of informational entropy and evidential reasoning, as well as new algebraic semantics for hybrid logics. Conradie has co-authored the book “Logic and Discrete Mathematics: A Concise Introduction” published by Wiley UK. He serves on the council of the South African Mathematical Society, the council of the Association for Symbolic Logic and on the South African Mathematics Olympiad committee. Invited\\xa0talk\\xa0AiML\\xa02022\\xa0: On parametric phenomena in correspondence theory Rineke Verbrugge Rineke Verbrugge is a pioneer in building bridges between logic and cognitive science. She holds the chair of Logic and Cognition at the University of Groningen’s Bernoulli Institute of Mathematics, Computer Science and Artificial Intelligence. Verbrugge’s research spans an area covering provability logic, teamwork in multi-agent environments, and social cognition.  Since her PhD on logic and the foundations of mathematics at the University of Amsterdam in 1993, Verbrugge has published more than 170 peer-reviewed international publications and a monograph, Teamwork in Multi-Agent Systems, with Barbara Dunin-Kęplicz. Verbrugge has led the NWO Vici-project “Cognitive systems in interaction: Logical and computational models of higher-order social cognition”. She is one of the six principal investigators of the Gravitation project “Hybrid Intelligence: Augmenting Human Intellect” that runs in the Netherlands in 2020-2030. Verbrugge is associate editor of the Journal of Logic, Language and Information and has been program (co-)chair of several workshops and conferences, including AiML 2020 and TARK 2023, as well as chair of the Dutch Association for Logic. Since 2021, Verbrugge is an elected member of the Royal Netherlands Academy of Sciences (KNAW). Joint invited\\xa0talk\\xa0AiML &\\xa0LAMAS&SR\\xa02022 : Not the sky, but the third floor is the limit: Zero-one laws for provability logic, S4, and K4 Contact us Contact is not available any more. Your Name (required) Your Email (required) Subject Your message Sponsors Comments are closed. AiML 2022 Home Important dates Invited speakers Accepted papers Call for papers Registration Program Local information Contact us LAMAS&SR 2022 Language: English Français Powered by Nirvana & WordPress. Mentions légales & CGU & Politique de confidentialité & Cookies We are using cookies to give you the best experience on our website. You can find out more about which cookies we are using or switch them off in settings . Accept Close GDPR Cookie Settings Privacy Overview Strictly Necessary Cookies Powered by GDPR Cookie Compliance Privacy Overview This website uses cookies so that we can provide you with the best user experience possible. Cookie information is stored in your browser and performs functions such as recognising you when you return to our website and helping our team to understand which sections of the website you find most interesting and useful. Strictly Necessary Cookies Strictly Necessary Cookie should be enabled at all times so that we can save your preferences for cookie settings. Enable or Disable Cookies If you disable this cookie, we will not be able to save your preferences. This means that every time you visit this website you will need to enable or disable cookies again. Enable All Save Settings',\n",
              "  {'entities': [(37, 43, 'Location'),\n",
              "    (279, 296, 'ConferenceDate'),\n",
              "    (326, 332, 'Location'),\n",
              "    (334, 346, 'ConferenceDate'),\n",
              "    (3595, 3608, 'SubmissionDate'),\n",
              "    (3889, 3915, 'ConferenceDate')]}),\n",
              " ('ACM WiSec 2023 ACM WiSec 2023 Home Program Program Keynotes Panel Discussion Accepted Papers Venue Venue Conference and Workshops Location Campus Map Social Events Location Hotels in Guildford How to get to Guildford Important Dates For Authors Call for Artifacts Call for Papers Call for Posters and Demos Registration WiseML 2023 Program Keynotes Accepted Papers Organisation Organisation Committee Program Committee Steering Committee 16th ACM Conference on Security and Privacy in Wireless and Mobile Networks 16th ACM Conference on Security and Privacy in Wireless and Mobile Networks 16th ACM Conference on Security and Privacy in Wireless and Mobile Networks Guildford, Surrey, United Kingdom May 29 - June 01, 2023 Guildford, Surrey, United Kingdom • May 29 - June 01, 2023 Guildford, Surrey, United Kingdom • May 29 - June 01, 2023 16th ACM Conference on Security and Privacy in Wireless and Mobile Networks Guildford, Surrey, United Kingdom • May 29 - June 01, 2023 About ACM WiSec 2023 The 16th ACM Conference on Security and Privacy in Wireless and Mobile Networks (ACM WiSec 2023)\\nwill be held from May 29 to June 1st, 2023 in Guildford, United Kingdom.\\nThe event will be hosted by\\nthe Surrey Centre for Cyber Security (SCCS) and 6th Generation Innovation Centre (6GIC) at the University of Surrey . ACM is the world’s largest educational and scientific computing society. ACM WiSec is the leading ACM and SIGSAC conference dedicated to all aspects of security and privacy in wireless and mobile networks and their applications, mobile software platforms, Internet of Things, cyber-physical systems, usable security and privacy, biometrics, and cryptography. ACM WiSec is a very competitive, high-quality conference, and is very-well attended by industry, government, and academia to share information, network, explore ideas, and learn about emerging trends and today’s hottest and most provocative cybersecurity topics. This event is a great opportunity for like-minded colleagues, researchers, students, and industry to attend and learn about the current advances in the security and privacy field. Past conferences WiSec 2022 / WiseML 2022 WiSec 2021 / WiseML 2021 WiSec 2020 / WiseML 2020 WiSec 2019 / WiseML 2019 WiSec 2018 WiSec 2017 WiSec 2016 WiSec 2015 WiSec 2014 WiSec 2013 WiSec 2012 WiSec 2011 WiSec 2010 WiSec 2009 WiSec 2008 Important Dates WiSec 2023 Main conference: May 29th to 31st, 2023 WiseML 2023 Workshops Workshop Event: June 1st, 2023 Sponsored by Hosted by ↑ Home Copyright © 2023 University of Surrey',\n",
              "  {'entities': [(685, 699, 'Location'),\n",
              "    (700, 722, 'ConferenceDate'),\n",
              "    (742, 756, 'Location'),\n",
              "    (759, 781, 'ConferenceDate'),\n",
              "    (801, 815, 'Location'),\n",
              "    (818, 840, 'ConferenceDate'),\n",
              "    (936, 950, 'Location'),\n",
              "    (953, 975, 'ConferenceDate'),\n",
              "    (1112, 1136, 'ConferenceDate'),\n",
              "    (1151, 1165, 'Location'),\n",
              "    (2397, 2419, 'ConferenceDate')]}),\n",
              " ('ACM CCS 2023 ACM CCS 2023 Home CCS30 Workshops Keynotes Call For Call For Artifacts Call For Paper Call For Posters Call For Sponsors Call For Workshops Attending Venue Location Venue Navigator Student Travel Grants Visa Letter Registration Hotel Offers Childcare Travel Guide Program Proceedings CCS Conference \\'23 AISEC \\'23 ARTMAN \\'23 ASHES \\'23 CCSW \\'23 CPSIoTSec \\'23 MTD \\'23 SaTS \\'23 SCORED \\'23 WAHC \\'23 WPES \\'23 HEPack4ML \\'23 Photo Album Organization Organizing Committee Program Committee Poster Committee AE Committee Code Code of Conduct Diversity and Inclusion ACM CCS 2023 26-30 Nov., 2023 Tivoli Congress Center , Copenhagen, Denmark 27. January 2024 ACM CCS 2024 CCS 2024 1st Round CFP 13. March 2024 ACM CCS 2024 CCS 2024 2nd Round CFP 13. April 2024 ACM CCS 2024 CCS 2024 Workshop Submission 13. October 2024 ACM CCS 2024 CCS 2024 at Salt Lake, US. Latest\\xa0\\xa0Conference News [29. November 2023] ACM CCS 2024 ACM CCS 2024 will be held in Salt Lake, US. Looking forward to seeing you all there! More Information [28. November 2023] Tivoli Gardens We apologize for the inconvenience caused by the error accessing the CCS exclusive discount for Tivoli Gardens. Due to a typo in the internal system, the correct password for accessing the purchase is ACM CSS 2023 , not ACMCCS2023. More Information [28. November 2023] CCS Banquet Join us at Tivoli Congress Hall to celebrate your participation in making CCS the best security conference! More Information [28. November 2023] CCS Business Meeting CCS is grateful for your support! Your feedback is our driving force to make CCS better. Join us at Hall Harlekin More Information [26. November 2023] Location of CCS30 Remember to attend CCS30 at Tivoli Congress Hall! More Information [26. November 2023] Proceedings Access Proceedings Access are now available. Please click \"Proceedings\" in the navigation menu. More Information [24. November 2023] CCS 30 We are celebrating 30 years of CCS. We will have a special session to celebrate 30 years of CCS. More Information [21. November 2023] Venue Free access to the WiFi at the conference venue is provided. More Information [6. November 2023] Registration Main conference is sold out! You can still register for the workshop days (26 and 30 November). More Information [28. October 2023] Program Program has been released! Additional events and functions may come up or add up recently. More Information Sponsor ACM SIGSAC ACM Special Interest Group on Security, Audit and Control (SIGSAC) The ACM Special Interest Group on Security, Audit and Control\\'s mission is to develop the information security profession by sponsoring high quality research conferences and workshops. Diamond Patron Platinum Patron Platinum Patron Platinum Patron Platinum Patron Gold Patron Gold Patron Bronze Patron Bronze Patron Bronze Patron About ACM CCS The ACM Conference on Computer and Communications Security (CCS) is the flagship annual conference of the Special Interest Group on Security, Audit and Control (SIGSAC) \\n                            of the Association for Computing Machinery (ACM). The conference brings together information security researchers, practitioners, developers, \\n                            and users from all over the world to explore cutting-edge ideas and results. CCS will follow the ACM Policy Against Harassment at ACM Activities . Please familiarize yourself with the ACM Policy Against Harassment and guide to Reporting Unacceptable Behavior. Due to X\\'s change of policy, you have to log into X to view embedded timeline. Why is that? Tweets by acm_ccs If you still couldn\\'t see the timeline, try 1. Disabling Tracking Prevention Add-ons in your web browsers 2. Disabling Tracking Prevention or Enhanced Tracking Protection Copyright © 2022-2023 ACM/SIGSAC. DTU Compute',\n",
              "  {'entities': [(582, 598, 'ConferenceDate'), (636, 643, 'Location')]}),\n",
              " ('Advanced Concepts for Intelligent Vision Systems: 21st International Conference, ACIVS 2023 Kumamoto, Japan, August 21–23, 2023 Proceedings | SpringerLink Your privacy, your choice We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media. By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection. See our privacy policy for more information on the use of your personal data. Manage preferences for further information and to change your choices. Accept all cookies Skip to main content Advertisement Log in Menu Find a journal Publish with us Track your research Search Cart Home Conference proceedings Advanced Concepts for Intelligent Vision Systems 21st International Conference, ACIVS 2023 Kumamoto, Japan, August 21–23, 2023 Proceedings Conference proceedings © 2023 Overview Editors: Jaques Blanc-Talon 0 , Patrice Delmas 1 , Wilfried Philips ORCID: https://orcid.org/0000-0003-4456-4353 2 , … Paul Scheunders 3 Show editors Jaques Blanc-Talon DGA TA, Toulouse, France View editor publications You can also search for this editor in PubMed Google Scholar Patrice Delmas University of Auckland, Auckland, New Zealand View editor publications You can also search for this editor in PubMed Google Scholar Wilfried Philips Ghent University, Ghent, Belgium View editor publications You can also search for this editor in PubMed Google Scholar Paul Scheunders University of Antwerp, Wilrijk, Belgium View editor publications You can also search for this editor in PubMed Google Scholar Part of the book series: Lecture Notes in Computer Science (LNCS, volume 14124) Included in the following conference series: ACIVS: International Conference on Advanced Concepts for Intelligent Vision Systems Conference proceedings info:\\n                    \\n                        \\n                            ACIVS 2023. 9100 Accesses 5 Citations This is a preview of subscription content, log in via an institution to check access. Access this book Log in via an institution Subscribe and save Springer+ Basic €32.70 /Month Get 10 units per month Download Article/Chapter or eBook 1 Unit = 1 Article or 1 Chapter Cancel anytime Subscribe now Buy Now eBook EUR\\xa053.49 Price includes VAT (Vietnam) Available as EPUB and PDF Read on any device Instant download Own it forever Buy eBook Softcover Book EUR\\xa065.99 Price excludes VAT (Vietnam) Compact, lightweight edition Dispatched in 3 to 5 business days Free shipping worldwide - see info Buy Softcover Book Tax calculation will be finalised at checkout Licence this eBook for your library Learn about institutional subscriptions Other ways to access Licence this eBook for your library Institutional subscriptions About this book This book constitutes the proceedings of the 21st International Conference on Advanced Concepts for Intelligent Vision Systems, ACIVS 2023, held in Kumamoto, Japan, during August 2023. The 31 papers presented in this volume were carefully reviewed and selected from a total of 48 submissions. They were organized in topical sections named:\\xa0Computer Vision, Affective Computing and Human Interactions, Managing the Biodiversity, Robotics and Drones, Machine Learning. Keywords Activity recognition and understanding Affective computing Clustering classification Medical imaging Deep learning Tracking Robotics and drones Search within this book Search Table of contents (31 papers) Front Matter Pages i-xiii Download chapter PDF A Hybrid Quantum-Classical Segment-Based Stereo Matching Algorithm Shahrokh Heidari, Patrice Delmas Pages 1-13 Adaptive Enhancement of\\xa0Extreme Low-Light Images Evgeny Hershkovitch Neiterman, Michael Klyuchka, Gil Ben-Artzi Pages 14-26 Semi-supervised Classification and\\xa0Segmentation of\\xa0Forest Fire Using Autoencoders Akash Koottungal, Shailesh Pandey, Athira Nambiar Pages 27-39 Descriptive and\\xa0Coherent Paragraph Generation for\\xa0Image Paragraph Captioning Using Vision Transformer and\\xa0Post-processing Naveen Vakada, C. Chandra Sekhar Pages 40-52 Pyramid Swin Transformer for\\xa0Multi-task: Expanding to\\xa0More Computer Vision Tasks Chenyu Wang, Toshio Endo, Takahiro Hirofuchi, Tsutomu Ikegami Pages 53-65 Person Activity Classification from\\xa0an\\xa0Aerial Sensor Based on\\xa0a\\xa0Multi-level Deep Features Fatma Bouhlel, Hazar Mliki, Mohamed Hammami Pages 66-75 Person Quick-Search Approach Based on\\xa0a\\xa0Facial Semantic Attributes Description Sahar Dammak, Hazar Mliki, Emna Fendri Pages 76-87 Age-Invariant Face Recognition Using Face Feature Vectors and\\xa0Embedded Prototype Subspace Classifiers Anders Hast Pages 88-99 BENet: A Lightweight Bottom-Up Framework for\\xa0Context-Aware Emotion Recognition Tristan Cladière, Olivier Alata, Christophe Ducottet, Hubert Konik, Anne-Claire Legrand Pages 100-111 YOLOPoint: Joint Keypoint and\\xa0Object Detection Anton Backhaus, Thorsten Luettel, Hans-Joachim Wuensche Pages 112-123 Less-than-One Shot 3D Segmentation Hijacking a\\xa0Pre-trained Space-Time Memory Network Cyril Li, Christophe Ducottet, Sylvain Desroziers, Maxime Moreaud Pages 124-135 Segmentation of\\xa0Range-Azimuth Maps of\\xa0FMCW Radars with\\xa0a\\xa0Deep Convolutional Neural Network Pieter Meiresone, David Van Hamme, Wilfried Philips Pages 136-147 Upsampling Data Challenge: Object-Aware Approach for\\xa03D Object Detection in\\xa0Rain Richard Capraru, Jian-Gang Wang, Boon Hee Soong Pages 148-159 A Single Image Neuro-Geometric Depth Estimation George Dimas, Panagiota Gatoula, Dimitris K. Iakovidis Pages 160-171 Wave-Shaping Neural Activation for Improved 3D Model Reconstruction from Sparse Point Clouds Georgios Triantafyllou, George Dimas, Panagiotis G. Kalozoumis, Dimitris K. Iakovidis Pages 172-183 A Deep Learning Approach to\\xa0Segment High-Content Images of\\xa0the E. coli Bacteria Dat Q. Duong, Tuan-Anh Tran, Phuong Nhi Nguyen Kieu, Tien K. Nguyen, Bao Le, Stephen Baker et al. Pages 184-195 Multimodal Emotion Recognition System Through Three Different Channels (MER-3C) Nouha Khediri, Mohammed Ben Ammar, Monji Kherallah Pages 196-208 Multi-modal Obstacle Avoidance in\\xa0USVs via\\xa0Anomaly Detection and\\xa0Cascaded Datasets Tilen Cvenkel, Marija Ivanovska, Jon Muhovič, Janez Perš Pages 209-221 A Contrario Mosaic Analysis for\\xa0Image Forensics Quentin Bammey Pages 222-234 1 2 Next page Back to top Other volumes Advanced Concepts for Intelligent Vision Systems Editors and Affiliations DGA TA, Toulouse, France Jaques Blanc-Talon University of Auckland, Auckland, New Zealand Patrice Delmas Ghent University, Ghent, Belgium Wilfried Philips University of Antwerp, Wilrijk, Belgium Paul Scheunders Bibliographic Information Book Title : Advanced Concepts for Intelligent Vision Systems Book Subtitle : 21st International Conference, ACIVS 2023 Kumamoto, Japan, August 21–23, 2023 Proceedings Editors : Jaques Blanc-Talon, Patrice Delmas, Wilfried Philips, Paul Scheunders Series Title : Lecture Notes in Computer Science DOI : https://doi.org/10.1007/978-3-031-45382-3 Publisher : Springer Cham eBook Packages : Computer Science , Computer Science (R0) Copyright Information : The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2023 Softcover ISBN : 978-3-031-45381-6 Published: 14 November 2023 eBook ISBN : 978-3-031-45382-3 Published: 13 November 2023 Series ISSN : 0302-9743 Series E-ISSN : 1611-3349 Edition Number : 1 Number of Pages : XIII, 384 Number of Illustrations : 14 b/w illustrations, 128 illustrations in colour Topics : Image Processing and Computer Vision , Biometrics , Computer Imaging, Vision, Pattern Recognition and Graphics , Signal, Image and Speech Processing , Robotics Publish with us Policies and ethics Back to top Access this book Log in via an institution Subscribe and save Springer+ Basic €32.70 /Month Get 10 units per month Download Article/Chapter or eBook 1 Unit = 1 Article or 1 Chapter Cancel anytime Subscribe now Buy Now eBook EUR\\xa053.49 Price includes VAT (Vietnam) Available as EPUB and PDF Read on any device Instant download Own it forever Buy eBook Softcover Book EUR\\xa065.99 Price excludes VAT (Vietnam) Compact, lightweight edition Dispatched in 3 to 5 business days Free shipping worldwide - see info Buy Softcover Book Tax calculation will be finalised at checkout Licence this eBook for your library Learn about institutional subscriptions Other ways to access Licence this eBook for your library Institutional subscriptions Search Search by keyword or author Search Navigation Find a journal Publish with us Track your research Discover content Journals A-Z Books A-Z Publish with us Journal finder Publish your research Open access publishing Products and services Our products Librarians Societies Partners and advertisers Our imprints Springer Nature Portfolio BMC Palgrave Macmillan Apress Your privacy choices/Manage cookies Your US state privacy rights Accessibility statement Terms and conditions Privacy policy Help and support Cancel contracts here 14.234.30.106 Not affiliated © 2024 Springer Nature',\n",
              "  {'entities': [(102, 107, 'Location'),\n",
              "    (109, 127, 'ConferenceDate'),\n",
              "    (985, 990, 'Location'),\n",
              "    (992, 1010, 'ConferenceDate')]}),\n",
              " ('Program - ACM MM 2023 Twitter Instagram Email Us Ottawa, Canada Home About Authors Info Author’s Advocate Dates Call for Technical Demos and Videos Program Grand Challenges Call for Open-Source Call for Doctorial Symposium Call for Brave New Ideas Call for Tutorial Proposals Call for Panel Proposals Workshops Submission Instructions Call for Workshops Call for Papers Attend Venue & Accomodation Ottawa Travel Info Visa Support Letter Requests STUDENT TRAVEL GRANTS Organizing Committee Organizing Committee Reviewer and Area Chair Guidelines ACM Multimedia Policies Program Keynote Speakers Main Program BNI Program Grand Challenges Program Open Source Program Workshops Sponsors Sponsors Call for Sponsors Printing Service Registration Home About Authors Info Author’s Advocate Dates Call for Technical Demos and Videos Program Grand Challenges Call for Open-Source Call for Doctorial Symposium Call for Brave New Ideas Call for Tutorial Proposals Call for Panel Proposals Workshops Submission Instructions Call for Workshops Call for Papers Attend Venue & Accomodation Ottawa Travel Info Visa Support Letter Requests STUDENT TRAVEL GRANTS Organizing Committee Organizing Committee Reviewer and Area Chair Guidelines ACM Multimedia Policies Program Keynote Speakers Main Program BNI Program Grand Challenges Program Open Source Program Workshops Sponsors Sponsors Call for Sponsors Printing Service Registration Program Full Program of the main Track 902 accepted papers is available: Monday, October 30, 2023 : 10:30 – 12:30 Teaser Sessions M1 (in Room: province 1) & M2 (in Room: Province 2) 10:30 — Offline Teaser (in Room: NovaScotia / NewFoundland) also on Conflux Tuesday Oct. 31 2023 : 10:30 – 12:30 Teaser Sessions T1 (in Room: province 1) & T2 (in Room: Province 2) 10:30 — Offline Teaser (in Room: NovaScotia / NewFoundland) also on Conflux Wednesday Nov. 1 2023 : 10:30 – 12:30 Teaser Sessions W1 (in Room: province 1) W2 (in Room: Province 2) 10:30  — Offline Teaser (in Room: NovaScotia / NewFoundland) also on Conflux Demos ( list of demos ) will be presented on both days: Monday 15:30 – 17:30 & Tuesday 10:30 – 12:30 Listing paper numbers and titles for Brave New Ideas Listing paper numbers and titles for Open Source Listing paper numbers and titles for Doctoral Symposium Listing paper numbers and titles for Technical Demos Listing paper numbers and titles for Grand Challenges The program at a glance : 10_26_ACM-MM-2023-Program Download Copyright ©2023 ACM MM 2023',\n",
              "  {'entities': [(57, 63, 'Location')]}),\n",
              " ('AICCSA2023 – ACS/IEEE Skip to content IEEE AICCSA 2023 National Telecommunication Institute (NTI) - Smart Village, Giza, Egypt IEEE AICCSA 2023 National Telecommunication Institute (NTI) - Smart Village, Giza, Egypt IEEE AICCSA 2023 4-7 December 2023 Home Committee Important dates Call For Call for Papers (Oral or Poster) PhD Forum Call for Workshops Proposals Call for Tutorial Proposals Registration Final Camera Ready Keynote Speakers Tracks and Subtopics Workshops W-STEM Sponsors and Exhibitors Scholarships Transportation & Accommodation Final Program Venue & Social Events Menu Home Committee Important dates Call For Call for Papers (Oral or Poster) PhD Forum Call for Workshops Proposals Call for Tutorial Proposals Registration Final Camera Ready Keynote Speakers Tracks and Subtopics Workshops W-STEM Sponsors and Exhibitors Scholarships Transportation & Accommodation Final Program Venue & Social Events 20th ACS/IEEE International Conference on Computer Systems and Applications (AICCSA 2023)\\xa0 \\xa04\\xa0– 7 December, 2023 AICCSA 2023 The ACS/IEEE International Conference on Computer Systems and Applications (AICCSA) is the premier conference covering all contemporary areas in computer systems and applications and hence it is an international forum for leading researchers and practitioners in this important and rapidly changing disciplines. AICCSA 2023 will be held in the lovely and highly vibrant National Telecommunication Institute (NTI) – Smart Village, Giza, Egypt. Past AICCSA Conferences AICCSA 2022 || AICCSA 2021 || AICCSA 2020 || AICCSA 2019 || AICCSA 2018 || AICCSA 2017 || AICCSA 2016 || AICCSA 2015 || AICCSA 2014 || AICCSA 2010 || AICCSA 09 || AICCSA 08 || AICCSA 07 || AICCSA 06 || AICCSA 05 || AICCSA 03 || AICCSA 01 || Symposiums and Workshops in conjunction with AICCSA 2023 Recent News – 15/01/2023 : Launching AICCSA 2023 website – 25/04/2023 : The PhD Symposium can now run in Hybrid mode (in Person and Online) to all as many PhD students to benefit from the symposium as possible. – 10/05/2023 : The deadline for workshops and Tutorial Proposals are extended to 30th June (Firm). 8 Workshops have already been accepted and will be added on the website soon. – 07/06/2023 : Following the many requests from authors the Deadline for submission extended to Sunday 18th June 2023 – 08/06/2023 : The steering committee decided to offer a number of scholarships for students, which will mainly be translated into discounted registration fees. more details to be provided soon – 28/07/2023 : Launch of the Second round of Submissions: check important Dates – 28/07/2023 : registration fees are now published with different categories, including\\xa0 one day registrations, and virtual attendance rates as well as rates for local participants and scholarships with considerable discounts for students. check REGISTRATION – 04/12/2023: program last version with sessions links Search Search Sponsors Copyright 2024 - AICCSA Close Menu Close Menu',\n",
              "  {'entities': [(121, 126, 'Location'),\n",
              "    (210, 215, 'Location'),\n",
              "    (233, 250, 'ConferenceDate'),\n",
              "    (1010, 1030, 'ConferenceDate'),\n",
              "    (2299, 2313, 'SubmissionDate')]})]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "TRAIN_DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrMcTApShjy9",
        "outputId": "0ce32eb8-6dbb-42f3-a2b4-9301066d81fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65 72\n"
          ]
        }
      ],
      "source": [
        "text = \"Call for Papers - ACM MM 2023 Twitter Instagram Email Us Ottawa, Canada Home About Authors Info Author’s Advocate Dates Call for Technical Demos and Videos Program Grand Challenges Call for Open-Source Call for Doctorial Symposium Call for Brave New Ideas Call for Tutorial Proposals Call for Panel Proposals Workshops Submission Instructions Call for Workshops Call for Papers Attend Venue & Accomodation Ottawa Travel Info Visa Support Letter Requests STUDENT TRAVEL GRANTS Organizing Committee Organizing Committee Reviewer and Area Chair Guidelines ACM Multimedia Policies Program Keynote Speakers Main Program BNI Program Grand Challenges Program Open Source Program Workshops Sponsors Sponsors Call for Sponsors Printing Service Registration Home About Authors Info Author’s Advocate Dates Call for Technical Demos and Videos Program Grand Challenges Call for Open-Source Call for Doctorial Symposium Call for Brave New Ideas Call for Tutorial Proposals Call for Panel Proposals Workshops Submission Instructions Call for Workshops Call for Papers Attend Venue & Accomodation Ottawa Travel Info Visa Support Letter Requests STUDENT TRAVEL GRANTS Organizing Committee Organizing Committee Reviewer and Area Chair Guidelines ACM Multimedia Policies Program Keynote Speakers Main Program BNI Program Grand Challenges Program Open Source Program Workshops Sponsors Sponsors Call for Sponsors Printing Service Registration Call for Papers ACM Multimedia 2023 calls for research papers presenting novel theoretical and algorithmic solutions addressing problems across the domain of multimedia and related applications. The conference also calls for papers presenting novel, thought-provoking ideas and promising (preliminary) results in realizing these ideas. The conference invites research papers of varying length from 6 to 8 pages, plus additional pages for the reference pages; i.e., the reference page(s) are not counted towards the page limit of 6 to 8 pages. Please note that there is no longer a distinction between long and short papers, but the authors may themselves decide on the appropriate length of the paper. All papers will undergo the same review process and review period. Submit your paper to Open Review: ACMMM 2023 Conference | OpenReview ( https://openreview.net/group?id=acmmm.org/ACMMM/2023/Conference ) Questions: Please send your inquiries to: acmmm2023pc@gmail.com Important Dates Please note: The submission deadline is at 11:59 p.m. of the stated deadline date Anywhere on Earth . Paper abstract deadline (firm deadline, no extension): 23 April 2023 Paper submission deadline: 30 April 2023 ; May 4, 2023 (due to holidays in some countries) Deadline for the supplementary materials is one week after that of the submissions (May 11, 2023) Regular Paper Reviews To Author: 30 June 2023 Regular Paper Rebuttal Deadline: 5 July 2023 Notification: 20 July 2023 Camera-ready Submission: 31 July 2023 Conference dates: October 28, 2023 – November 3, 2023 The conference invites papers in four major themes of multimedia: Engagement, Experience, Systems and Understanding. Theme: Engaging users with multimedia The engagement of multimedia with society as a whole requires research that addresses how multimedia can be used to connect people with multimedia artifacts that meet their needs in a variety of contexts. The topic areas included under this theme include: Emotional and Social Signals This area focuses on the analysis of emotional, cognitive (e.g., brain-based) and interactive social behavior in the spectrum of individual to small group settings. It calls for novel contributions with a strong human-centered focus specializing in supporting or developing automated techniques for analyzing, processing, interpreting, synthesizing, or exploiting human social, affective and cognitive signals for multimedia applications.) Multimedia Search and Recommendation To engage user in information access, search and recommendation requires not only understanding of data but also user and context. This area calls for novel solutions for user-centric multimedia search and recommendations, in either automatic or interactive mode, with topics ranging from optimization, user intent prediction, to personalized, collaborative or exploratory algorithms. (Note: Topics focusing primarily on indexing and scalability should be submitted to\\xa0“Multimedia systems: Data Systems indexing and management”) Summarization, Analytics, and Storytelling The information underlying multimedia is by nature multi-perspective. Allowing efficient multi-perspective and context-adaptive information access remains an open problem. This area calls for new and novel solutions that can compose, link, edit and summarize multimedia data into a compact but insightful, enjoyable and multi-perspective presentation to facilitate tasks such as multimedia analytics, decision making, searching and browsing. Theme: Experience One of the core tenants of our research community is that multimedia data contributes to the user experience in a rich and meaningful fashion. The topics organized under this theme are concerned with innovative uses of multimedia to enhance the user experience, how this experience is manifested in specific domains, and metrics for qualitatively and quantitatively measuring that experience in useful and meaningful ways. Specific topics addressed this year include: Interactions and Quality of Experience Papers under this topic should address human-centered issues. Topics include (i) novel interaction techniques and modalities for accessing, authoring, and consuming multimedia data, (ii) design and implementation of novel interactive media (iii) new methodologies, models, and metrics to understand and/or measure multimedia quality of experience. Social-good, fairness and transparency This area seeks works that explicitly\\xa0aim at benefitting society by addressing challenges such as those related to environment, privacy, education and health. Also works that improve the fairness and transparency of multimedia systems and applications are of interest for this area. Metaverse, Art and Culture Papers under this topic area should develop techniques that enable effective engagement of the public with art and other forms of cultural expression, balancing between sophisticated computational/engineering techniques and artistic / cultural purposes. Topics include (i) digital artworks, including hybrid physical digital installations; dynamic, generative, and interactive multimedia artworks; (ii) computational tools to support creativity, cultural preservation, and curation. Multimedia Applications Papers under this topic area should push the envelope of how multimedia can be used to improve the user experience in a rich and meaningful manner. We solicit papers that design, implement, and evaluate applications that employ multimedia data in surprising new ways or in application scenarios that user experience remains challenging based on today’s start-of-the-art, such as immersive telepresence, and distance education. Theme: Multimedia systems Research in multimedia systems is generally concerned with understanding fundamental trade-offs between competing resource requirements, developing practical techniques and heuristics for realizing complex optimization and allocation strategies, and demonstrating innovative mechanisms and frameworks for building large-scale multimedia applications. Within this theme, we have focussed on three target topic areas: Systems and Middleware This area seeks novel contributions that address performance issues in one of the systems components. Topics include operating systems, mobile systems, storage systems, distributed systems, programming systems and abstractions, and embedded systems. Papers must establish performance improvement or non-trivial tradeoffs through integration of multiple systems components or enhancing one of the system components. Transport and Delivery Papers under this topic area should address improvement to multimedia transport and delivery mechanisms over a computer network. Topics include network protocol enhancement, and supporting multimedia data with network mechanisms such as SDN and NFV, and in-network content placement. Data Systems Management and Indexing Papers under this topic should address performance issues related to data management and indexing to support multimedia access at a large scale, including browsing, searching, recommendation, analysis, processing, and mining. Topics include scalable systems and indexing techniques that support multimedia access and analytics. Theme: Understanding multimedia content Multimedia data types by their very nature are complex and often involve intertwined instances of different kinds of information. We can leverage this multi-modal perspective in order to understand the meaning of the world, often with surprising results through computational representations. Specific topics addressed this year include: Multimodal Fusion and Embedding In the real world, some problems are addressable only through a combination of multiple medium and/or modalities. This topic seeks new insights and solutions of how multi-perspective media information should be embedded and fused for novel problems as well as innovative applications. Vision and Language Recent research has driven the merging of vision and language in different ways, such as captioning, question-answering, and multi-modal chatbots. This area seeks new solutions and results that are specific to the problems of combining or bridging vision and language. Media Interpretation This area seeks novel processing of media-related information in any form that can lead to new ways of interpreting multimedia content. Examples include processing of image, video, audio, music, language, speech, or other sensory modalities, for interpretation, knowledge discovery, and understanding. Copyright ©2023 ACM MM 2023\"\n",
        "start = text.find(\"Canada \")\n",
        "end = start + len(\"Canada \")\n",
        "print(start, end)  # Kiểm tra chỉ số"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4batKUmhjy-"
      },
      "outputs": [],
      "source": [
        "# import spacy\n",
        "# from spacy.training import offsets_to_biluo_tags\n",
        "\n",
        "# # Khởi tạo mô hình spaCy (en_core_web_sm)\n",
        "# nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# # Danh sách các tháng trong năm\n",
        "# months = [\n",
        "#     \"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n",
        "#     \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"\n",
        "# ]\n",
        "\n",
        "\n",
        "\n",
        "# # Hàm tìm vị trí tháng trong văn bản\n",
        "# def find_month_in_text(text):\n",
        "#     for month in months:\n",
        "#         if month in text:\n",
        "#             return text.find(month), month\n",
        "#     return -1, None\n",
        "\n",
        "# # Hàm điều chỉnh dữ liệu và trả về TRAIN_DATA mới\n",
        "# def auto_adjust_and_return(train_data, nlp):\n",
        "#     adjusted_data = []\n",
        "\n",
        "#     for entry in train_data:\n",
        "#         text = entry[0]\n",
        "#         annotations = entry[1]\n",
        "#         entities = annotations[\"entities\"]\n",
        "\n",
        "#         new_entities = []\n",
        "#         for entity in entities:\n",
        "#             start, end, label = entity\n",
        "#             # Tìm vị trí tháng trong văn bản\n",
        "#             month_start, month_text = find_month_in_text(text)\n",
        "#             if month_start != -1:\n",
        "#                 # Điều chỉnh lại vị trí từ tháng đến cuối câu (bỏ dấu chấm .)\n",
        "#                 correct_start = month_start\n",
        "#                 correct_end = len(text.rstrip('.'))\n",
        "#                 entity = (correct_start, correct_end, label)\n",
        "#             # Thêm thực thể đã điều chỉnh vào danh sách\n",
        "#             new_entities.append(entity)\n",
        "\n",
        "#         # Thêm vào dữ liệu đã điều chỉnh\n",
        "#         adjusted_data.append((text, {\"entities\": new_entities}))\n",
        "\n",
        "#     return adjusted_data\n",
        "\n",
        "# # Gọi hàm để điều chỉnh dữ liệu\n",
        "# adjusted_train_data = auto_adjust_and_return(TRAIN_DATA, nlp)\n",
        "\n",
        "# # In ra dữ liệu huấn luyện đã điều chỉnh\n",
        "# for entry in adjusted_train_data:\n",
        "#     print(entry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo596wKhhjy_",
        "outputId": "88caa600-4449-40ee-f776-3dc13d9ecc01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nhãn trong NER pipeline:\n",
            "('CARDINAL', 'ConferenceDate', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'Location', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'SubmissionDate', 'TIME', 'WORK_OF_ART')\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from spacy.util import minibatch, compounding\n",
        "from spacy.training.example import Example\n",
        "from spacy.language import Language\n",
        "\n",
        "# Tạo custom component để loại bỏ nhãn \"DATE\"\n",
        "@Language.component(\"remove_dates_component\")\n",
        "def remove_dates_component(doc):\n",
        "    # Duyệt qua tất cả các thực thể trong văn bản và giữ lại những thực thể không phải là DATE\n",
        "    filtered_ents = [ent for ent in doc.ents if ent.label_ != \"DATE\" and ent.label != \"LOC\"]\n",
        "    doc.set_ents(filtered_ents)  # Cập nhật lại các thực thể đã lọc vào document\n",
        "    return doc\n",
        "\n",
        "# Tải mô hình tiếng Anh\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Thêm component loại bỏ DATE vào pipeline, sau 'ner'\n",
        "nlp.add_pipe(\"remove_dates_component\", after=\"ner\")\n",
        "\n",
        "# Lấy pipe NER\n",
        "ner = nlp.get_pipe(\"ner\")\n",
        "\n",
        "# Thêm các nhãn mới vào pipe NER\n",
        "for _, annotations in TRAIN_DATA:\n",
        "    for ent in annotations.get(\"entities\"):\n",
        "        ner.add_label(ent[2])\n",
        "\n",
        "print(\"Nhãn trong NER pipeline:\")\n",
        "print(ner.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5nyIF37hjzA",
        "outputId": "22ef1b28-e480-442d-d307-5cee34d389f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses at iteration 0: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 1792.5084518582355}\n",
            "Losses at iteration 1: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 536.8311762893572}\n",
            "Losses at iteration 2: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 259.54698659064957}\n",
            "Losses at iteration 3: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 115.33920586377538}\n",
            "Losses at iteration 4: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 240.9784032876678}\n",
            "Losses at iteration 5: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 208.07966957426478}\n",
            "Losses at iteration 6: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 110.45963496751727}\n",
            "Losses at iteration 7: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 149.36802088779928}\n",
            "Losses at iteration 8: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 111.59794666988691}\n",
            "Losses at iteration 9: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 96.32259800492545}\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "# Khởi tạo optimizer để tiếp tục huấn luyện mô hình\n",
        "optimizer = nlp.resume_training()\n",
        "\n",
        "# Tải mô hình đã lưu\n",
        "# nlp = spacy.load(\"path_to_your_model\")\n",
        "\n",
        "# # Tải lại optimizer\n",
        "# with open(\"optimizer_state.pkl\", \"rb\") as f:\n",
        "#     optimizer = pickle.load(f)\n",
        "\n",
        "for i in range(10):  # Tăng số vòng lặp huấn luyện lên 50 vòng\n",
        "    losses = {}\n",
        "    batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
        "    for batch in batches:\n",
        "        texts, annotations = zip(*batch)\n",
        "        examples = [Example.from_dict(nlp.make_doc(text), annot) for text, annot in zip(texts, annotations)]\n",
        "        nlp.update(examples, drop=0.5, losses=losses)\n",
        "    print(f\"Losses at iteration {i}: {losses}\")\n",
        "\n",
        "# Huấn luyện xong, lưu mô hình và optimizer\n",
        "nlp.to_disk(\"path_to_your_model\")\n",
        "with open(\"optimizer_state.pkl\", \"wb\") as f:\n",
        "    pickle.dump(optimizer, f)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "md_jFNfqhjzV",
        "outputId": "2a507142-f70e-437a-83ad-cbe2b965877b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses at iteration 0: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 182.9068413612751}\n",
            "Losses at iteration 1: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 118.41914589054514}\n",
            "Losses at iteration 2: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 99.54750695237958}\n",
            "Losses at iteration 3: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 81.31641195619476}\n",
            "Losses at iteration 4: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 79.51974617084258}\n",
            "Losses at iteration 5: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 66.97382589364486}\n",
            "Losses at iteration 6: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 73.72623647085221}\n",
            "Losses at iteration 7: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 75.41629427424607}\n",
            "Losses at iteration 8: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 57.25774663711753}\n",
            "Losses at iteration 9: {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 187.58627230798393}\n"
          ]
        }
      ],
      "source": [
        "import pickle  # Import pickle để tải lại optimizer\n",
        "\n",
        "# Tải mô hình đã lưu\n",
        "nlp = spacy.load(\"path_to_your_model\")\n",
        "\n",
        "# Tải lại optimizer\n",
        "with open(\"optimizer_state.pkl\", \"rb\") as f:\n",
        "    optimizer = pickle.load(f)\n",
        "\n",
        "# Tiếp tục huấn luyện\n",
        "for i in range(10):  # Tăng số vòng lặp huấn luyện lên 50 vòng\n",
        "    losses = {}\n",
        "    batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
        "    for batch in batches:\n",
        "        texts, annotations = zip(*batch)\n",
        "        examples = [Example.from_dict(nlp.make_doc(text), annot) for text, annot in zip(texts, annotations)]\n",
        "        nlp.update(examples, drop=0.5, losses=losses, sgd=optimizer)\n",
        "    print(f\"Losses at iteration {i}: {losses}\")\n",
        "\n",
        "# Lưu mô hình đã huấn luyện lại\n",
        "nlp.to_disk(\"path_to_your_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "id": "_AYhqJE9hjzW",
        "outputId": "fc3ed4f9-7092-461c-b984-829d0b014c28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "[E002] Can't find factory for 'remove_dates_component' for language English (en). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, lemmatizer, trainable_lemmatizer, entity_linker, entity_ruler, tagger, morphologizer, ner, beam_ner, senter, sentencizer, spancat, spancat_singlelabel, span_finder, future_entity_ruler, span_ruler, textcat, textcat_multilabel, en.lemmatizer",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-80cba7df8c67>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Tải mô hình đã lưu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Spacy-Custom/labeling/path_to_your_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"AMIA 2023 Annual Symposium | AMIA - American Medical Informatics Association Skip to main content AMIA Homepage My Account Login Search Toggle navigation AMIA Homepage Join AMIA Quick Links Members-only AMIA Connect Knowledge Center JAMIA ACI Journal My Account Login Search About AMIA About AMIA Leadership and Governance Diversity, Equity, and Inclusion Partner with AMIA AMIA 25x5 Why Informatics? Donate Awards Staff Contact Us Membership Membership Individual Membership Academic Forum Corporate Partnership & Membership Health System Membership Student Center Why AMIA? Communities Communities Working Groups AF Communities Fellows of ACMI (FACMI) Fellows of AMIA (FAMIA) Nursing Informatics Physicians in AMIA Women In AMIA Education & Events Education & Events Education Catalog 10x10 Virtual Courses Clinical Informatics Board Review Course AMIA Health Informatics Review Course (ARC) Health Informatics Essentials Artificial Intelligence Showcase Annual Symposium Clinical Informatics Conference Informatics Summit Calendar AMIA Knowledge Center Careers & Certifications Careers & Certifications Informatics Academic Programs Clinical Informatics Subspecialty AMIA Health Informatics Certification (AHIC) Certification Careers News & Publications News & Publications Journals Press Room AMIA News Center Podcasts Advertising Public Policy Public Policy Current Policy Priorities Public Policy Principles AMIA in Action Day on Capitol ...\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \"\"\"\n\u001b[0;32m---> 51\u001b[0;31m     return util.load_model(\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# path to model data directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0moverrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfor_overrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m     nlp = load_model_from_config(\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_config\u001b[0;34m(config, meta, vocab, disable, enable, exclude, auto_fill, validate)\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;31m# registry, including custom subclasses provided via entry points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0mlang_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lang_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lang\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m     nlp = lang_cls.from_config(\n\u001b[0m\u001b[1;32m    588\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, vocab, disable, enable, exclude, meta, auto_fill, validate)\u001b[0m\n\u001b[1;32m   1887\u001b[0m                     \u001b[0;31m# The pipe name (key in the config) here is the unique name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m                     \u001b[0;31m# of the component, not necessarily the factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1889\u001b[0;31m                     nlp.add_pipe(\n\u001b[0m\u001b[1;32m   1890\u001b[0m                         \u001b[0mfactory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1891\u001b[0m                         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipe_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    819\u001b[0m             )\n\u001b[1;32m    820\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m             pipe_component = self.create_pipe(\n\u001b[0m\u001b[1;32m    822\u001b[0m                 \u001b[0mfactory_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36mcreate_pipe\u001b[0;34m(self, factory_name, name, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    688\u001b[0m                 \u001b[0mlang_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             )\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0mpipe_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_factory_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactory_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;31m# This is unideal, but the alternative would mean you always need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: [E002] Can't find factory for 'remove_dates_component' for language English (en). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, lemmatizer, trainable_lemmatizer, entity_linker, entity_ruler, tagger, morphologizer, ner, beam_ner, senter, sentencizer, spancat, spancat_singlelabel, span_finder, future_entity_ruler, span_ruler, textcat, textcat_multilabel, en.lemmatizer"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "# Tải mô hình đã lưu\n",
        "nlp = spacy.load(\"/content/drive/MyDrive/Spacy-Custom/labeling/path_to_your_model\")\n",
        "\n",
        "text = \"AMIA 2023 Annual Symposium | AMIA - American Medical Informatics Association Skip to main content AMIA Homepage My Account Login Search Toggle navigation AMIA Homepage Join AMIA Quick Links Members-only AMIA Connect Knowledge Center JAMIA ACI Journal My Account Login Search About AMIA About AMIA Leadership and Governance Diversity, Equity, and Inclusion Partner with AMIA AMIA 25x5 Why Informatics? Donate Awards Staff Contact Us Membership Membership Individual Membership Academic Forum Corporate Partnership & Membership Health System Membership Student Center Why AMIA? Communities Communities Working Groups AF Communities Fellows of ACMI (FACMI) Fellows of AMIA (FAMIA) Nursing Informatics Physicians in AMIA Women In AMIA Education & Events Education & Events Education Catalog 10x10 Virtual Courses Clinical Informatics Board Review Course AMIA Health Informatics Review Course (ARC) Health Informatics Essentials Artificial Intelligence Showcase Annual Symposium Clinical Informatics Conference Informatics Summit Calendar AMIA Knowledge Center Careers & Certifications Careers & Certifications Informatics Academic Programs Clinical Informatics Subspecialty AMIA Health Informatics Certification (AHIC) Certification Careers News & Publications News & Publications Journals Press Room AMIA News Center Podcasts Advertising Public Policy Public Policy Current Policy Priorities Public Policy Principles AMIA in Action Day on Capitol Hill About AMIA About AMIA Leadership and Governance Diversity, Equity, and Inclusion Partner with AMIA AMIA 25x5 Why Informatics? Donate Awards Staff Contact Us Membership Membership Individual Membership Academic Forum Corporate Partnership & Membership Health System Membership Student Center Why AMIA? Communities Communities Working Groups AF Communities Fellows of ACMI (FACMI) Fellows of AMIA (FAMIA) Nursing Informatics Physicians in AMIA Women In AMIA Education & Events Education & Events Education Catalog 10x10 Virtual Courses Clinical Informatics Board Review Course AMIA Health Informatics Review Course (ARC) Health Informatics Essentials Artificial Intelligence Showcase Annual Symposium Clinical Informatics Conference Informatics Summit Calendar AMIA Knowledge Center Careers & Certifications Careers & Certifications Informatics Academic Programs Clinical Informatics Subspecialty AMIA Health Informatics Certification (AHIC) Certification Careers News & Publications News & Publications Journals Press Room AMIA News Center Podcasts Advertising Public Policy Public Policy Current Policy Priorities Public Policy Principles AMIA in Action Day on Capitol Hill Join AMIA Home Education & Events AMIA 2023 Annual Symposium November 11 - 15 New Orleans, LA #AMIA2023 Registration For Attendees Venue Program CME/CNE More Keynotes LIEAF Sponsors/Exhibitors Transforming Healthcare and Biomedicine for a Sustainable Future Highlights A huge thanks to all of our wonder attendees. Check out our photo albums from events throughout the week in New Orleans. Handouts Attendees may continue to access presentations from various sessions. Login with your AMIA credentials and search by title, speaker, or session type. Claim Credit Claim your continuing education credit and download your certificate by December 15, 2023. The theme of AMIA 2023 Annual Symposium is Transforming Healthcare and Biomedicine for a Sustainable Future. Now, more than ever, healthcare and biomedicine face significant challenges in a number of areas, including staffing, knowledge translation, finances, and supply chain. Today’s challenges underscore the need for innovations in the field of informatics that not only transform healthcare and biomedicine but do so sustainably. As agents of change and transformation, we as informaticians must ensure our work helps to bring about a more equitable and sustainable future. Join us for the world’s premier health informatics meeting, and elevate your career alongside your colleagues from around the world. Network with industry leaders, colleagues, and students. Take advantage of career development opportunities. Find a mentor. Review your CV with an expert. Learn in hundreds of sessions designed for you, the informatics professional. Grow informatics’ knowledge base with reports, policy, and scientific papers. Scientific Program Committee Genevieve Melton-Meaux, MD, PhD, FACMI Chair University of Minnesota Read full bio Kenrick Cato, PhD, RN, CPHIMS, FAAN Vice Chair University of Pennsylvania / Children's Hospital of Philadelphia Read full bio Arlene Chung, MD, MHA, MMCi, FAMIA Vice Chair Google & Duke School of Medicine Read full bio Hojjat Salmasian, MD, MPH, PhD, FAMIA Vice Chair Children's Hospital of Philadelphia Read full bio Nicole Weiskopf, PhD Vice Chair Oregon Health & Science University Read full bio Laura Wiley, PhD Vice Chair University of Colorado Anschutz Medical Campus Read full bio Rui Zhang, PhD, FAMIA Vice Chair University of Minnesota Read full bio Meet the entire 2023 Scientific Program Committee Title Sponsor On-Demand Not able to attend the Symposium in person? On-Demand recordings are available now. Access includes pre-recorded sessions and presentation handouts. Purchase now View the rates Mobile App The AMIA Events app offers the most up-to-date information including session times and location. Registrants will receive an email with login information. iTunes App store Google Play Title Sponsor , Premier Sponsors Join the AMIA Community Explore opportunities with the multidisciplinary, interprofessional home for over 5,000 informatics professionals and join the AMIA community today. Learn more Why AMIA? To Connect, Learn, Grow, and Lead. Watch the video Headquarters: 6218 Georgia Avenue NW, Suite #1 PMB 3077 Washington, DC 20011 Phone: 301.657.1291 AMIA's Facebook Profile AMIA's Facebook Profile AMIA's Twitter Profile AMIA's LinkedIn Profile AMIA's YouTube Channel © 2024 American Medical Informatics Association. All Rights Reserved. Contact Us Site Map Privacy Back to top We use cookies on this site to enhance your user experience. By clicking the Accept button, you agree to us doing so. More info No, thanks Accept\"\n",
        "\n",
        "\n",
        "# Kiểm tra mô hình sau khi huấn luyện với nhãn mới\n",
        "doc = nlp(text)\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}