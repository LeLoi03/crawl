Toggle navigation        
  
 Home 
  Sponsorships | Conference sponsors 
  Industry Session 
  Exhibitors 
  Scientific patronage 
  Sponsorships opportunities 
  Program | Program 
  Invited Speakers 
  Accepted Papers 
  Proceedings 
  PAIS 
  Workshops 
  Tutorials 
  STAIRS 
  Doctoral Consortium 
  Outstanding Papers 
  Committees | Chairs 
  Organizing Committee 
  Program Committee Awards 
  Program Committee 
  Attending ECAI 2023 | Conference App 
  Awards and Community Events 
  Gala Dinner and guided tour 
  Venue: ICE Congress Center 
  Venue: JU Campus 
  Access to Kraków 
  Kraków 
  Useful information 
  Hotels 
  Registration information 
  Travel Grants 
  Accessibility 
  Poster Sessions 
  Gallery 
  Future ECAIs 

  Accepted Papers    
  
  19  Failure Handling in BDI Plans via Runtime Enforcement   
   
  Authors: Angelo Ferrando; Rafael C. Cardoso   
  ##MORE##Engineering a software system can be a complex process and prone to failure. This is exacerbated when the system under consideration presents some degree of autonomy, such as in cognitive agents. In this paper, we use runtime verification as a way to enforce safety properties on Belief-Desire-Intention (BDI) agents by enveloping certain plans in safety shields. These shields function as a failure handling mechanism, they can detect and avoid violations in shielded plans. The safety shields also provide automated failure recovery by attempting alternative execution paths to avoid violations.   
   
 22  Instance-aware Diffusion Implicit Process for Box-based Instance Segmentation   
   
  Authors: Hao Ren ; Xingson Liu ; Junjian Huang ; Ru Wan ; Jian Pu ; Hong Lu   
  ##MORE##The diffusion model has demonstrated impressive performance in image generation, but its potential for discriminative tasks such as instance segmentation remains unexplored. In this paper, we propose an Instance-aware Diffusion Implicit Process (IDIP) framework for instance segmentation based on boxes. During training, IDIP diffuses ground-truth boxes across various time steps, extracting corresponding Region of Interest (RoI) features. Dynamic convolution is then used to predict boxes and categories for each RoI, and the mask head generates masks from these predictions. During inference, IDIP iteratively refines randomly generated boxes with the denoising diffusion implicit model, while the mask head derives final masks from RoIs based on the refined boxes. Our method surpasses existing approaches on the COCO benchmark, requiring fewer training steps and less memory resources due to its dynamic design and instance-aware characteristic.   
   
 30  Stackelberg Attacks on Auctions and Blockchain Transaction Fee Mechanisms   
   
  Authors: Nikolaj I Schwartzbach ; Daji Landis   
  ##MORE##We study a multi-unit single-demand auction in a setting where agents can arbitrarily commit to strategies that may depend on the commitments of other agents. Such commitments non-trivially change the equilibria of the auction by inducing a metagame, in which agents commit to strategies. We demonstrate a strategy an attacker may commit to that ensures they receive one such item for free, while forcing the remaining agents to enter a lottery for the remaining items. The attack is detrimental to the auctioneer, who loses most of their revenue. We show that the strategy works as long as the agents have valuations that are somewhat concentrated. The attack is robust to a large fraction of the agents being either oblivious to the attack or having exceptionally high valuations. The attacker may coerce these agents into cooperating by promising them a free item. We show that the conditions for the attack to work hold with high probability when (1) the auction is not too congested, and (2) the valuations are sampled i.i.d. from either a uniform distribution or a Pareto distribution. The attack works for first-price auctions, second-price auctions, and the transaction fee mechanism EIP-1559 used by Ethereum.   
   
 45  Invisible Backdoor Attacks Using Data Poisoning in Frequency Domain   
   
  Authors: Chang Yue ; Lv Peizhuo ; Ruigang Liang ; Kai Chen   
  ##MORE##Backdoor attacks have become a significant threat to deep neural networks (DNNs), whereby poisoned models perform well on benign samples but produce incorrect outputs when given specific inputs with a trigger. These attacks are usually implemented through data poisoning by injecting poisoned samples (samples patched with a trigger and mislabelled to the target label) into the dataset, and the models trained with that dataset will be infected with the backdoor. However, most current backdoor attacks lack stealthiness and robustness because of the fixed trigger patterns and mislabelling, which can be easily detected by humans or some backdoor defense methods. To address this issue, we propose a frequency-domain-based backdoor attack method that implements backdoor implantation without mislabeling the poisoned samples or accessing the training process. We evaluated our approach on three benchmark datasets and two popular scenarios, including no-label self-supervised learning and clean-label supervised learning. Our approach achieved a high attack success rate (above 90%) on all tasks without significant performance degradation on main tasks. Furthermore, our experiments demonstrate that our attack is highly robust against mainstream defense approaches.   
   
 47  Enhanced Machine Reading Comprehension Method for Aspect Sentiment Quadruplet Extraction   
   
  Authors: Shuqin Ye ; Zepeng Zhai ; Ruifan Li   
  ##MORE##In the NLP domain, Aspect-Based Sentiment Analysis (ABSA) has gained significant attention in recent years due to its ability to perform fine-grained sentiment analysis. A challenging task in ABSA is Aspect Sentiment Quadruplet Extraction (ASQE), which involves the extraction of aspect terms and their associated opinion terms, sentiment polarities, and categories in the form of quadruplets. However, existing studies have ignored the strong dependence among the multiple subtasks involved in ASQE. In this paper, we propose a novel \textit{Enhanced Machine Reading Comprehension} (EMRC) method and formalize ASQE task as a multi-turn MRC task. Our EMRC effectively learns and utilizes the relationships among different subtasks by incorporating previously generated query answers into the current queries. We design a hierarchical category classification strategy to perform the category prediction in a structured manner, enabling the model to tackle intricate categories with ease. Furthermore, we employ the bi-directional attention mechanism, i.e., context-to-query and query-to-context attentions, to map the context into a task-aware representation. We conduct extensive experiments on two benchmark datasets. The results demonstrate that EMRC outperforms the state-of-art baselines.   
   
 52  Uncertainty-driven Trajectory Truncation for Data Augmentation in Offline Reinforcement Learning   
   
  Authors: Junjie Zhang ; Jiafei Lyu ; Xiaoteng Ma ; Jiangpeng Yan ; Jun Yang ; Le Wan ; Xiu Li   
  ##MORE##Equipped with the trained environmental dynamics, model-based offline reinforcement learning (RL) algorithms can often successfully learn good policies from fixed-sized datasets, even some datasets with poor quality. Unfortunately, however, it can not be guaranteed that the generated samples from the trained dynamics model are reliable (e.g., some synthetic samples may lie outside of the support region of the static dataset). To address this issue, we propose Trajectory Truncation with Uncertainty (TATU), which adaptively truncates the synthetic trajectory if the accumulated uncertainty along the trajectory is too large. We theoretically show the performance bound of TATU to justify its benefits. To empirically show the advantages of TATU, we first combine it with two classical model-based offline RL algorithms, MOPO and COMBO. Furthermore, we integrate TATU with several off-the-shelf model-free offline RL algorithms, e.g., BCQ. Experimental results on the D4RL benchmark show that TATU significantly improves their performance, often by a large margin.   
   
 58  Time-Series Data Imputation via Realistic Masking-Guided Tri-Attention BiGRU   
   
  Authors: ZhiPeng Zhang ; Yiqun Zhang ; An Zeng ; Dan Pan ; Yuzhu Ji ; Zhipeng Zhang ; Jing Lin   
  ##MORE##Time series data are ubiquitous in real-world accompanied with missing values due to various collection faults. Thus Time-Series Data Imputation (TSDI) problem is crucial to many temporal data analysis tasks. Existing missing data imputation methods usually consider only one of the following issues: (1) temporal dependencies in each time series, and (2) inter-feature correlation. Moreover, to the best of our knowledge, existing approaches that mask the data values for self-supervised TSDI model training use random masking only, which is far from the real complex missing situations. To achieve advanced performance on TDSI, we design a novel imputation model that delicately preserves the short-term, long-term, and inter-feature dependencies by attention mechanisms in a delay error-reduced bidirectional architecture. That is, it leverages GRU recurrent neural networks to model short-term temporal dependencies, and adopts Self-Attention (SA) mechanisms hierarchically to capture long-term temporal dependencies and inter-feature correlations. The multiple SAs are nested in a bidirectional structure to alleviate the problem of delay errors in RNN-like structures. To facilitate a model training with higher generality w.r.t. TSDI, a masking strategy that mimics various more extreme real missing situations beyond the simple random ones has been adopted for generating self-supervised tasks. Comprehensive experiments on real datasets demonstrates that our proposed approach outperforms the state-of-the-art methods in various data missing scenarios, and boosts the performance of several main downstream time series data analysis tasks, i.e. , clustering, classification, and ranking.   
   
 75  Structure-Aware Group Discrimination with Adaptive-View Graph Encoder: A Fast Graph Contrastive Learning Framework   
   
  Authors: Zhenshuo Zhang ; Yun Zhu ; Haizhou Shi ; Siliang Tang   
  ##MORE##Albeit having gained significant progress lately, large-scale graph representation learning remains expensive to train and deploy for two main reasons: (i) the repetitive computation of multi-hop message passing and non-linearity in graph neural networks (GNNs); (ii) the computational cost of complex pairwise contrastive learning loss. Two main contributions are made in this paper targeting this twofold challenge: we first propose an adaptive-view graph neural encoder (AVGE) with a limited number of message passing to accelerate the forward pass computation, and then we propose a structure-aware group discrimination (SAGD) loss in our framework which avoids inefficient pairwise loss computing in most common GCL and improves the performance of the simple group discrimination. By the framework proposed, we manage to bring down the training and inference cost on various large-scale datasets by a significant margin (250x faster inference time) without loss of the downstream-task performance.   
   
 78  On the Robustness of Split Learning against Adversarial Attacks   
   
  Authors: Mingyuan Fan ; Cen Chen ; Chengyu Wang ; Wenmeng Zhou ; Jun Huang   
  ##MORE##Split learning enables collaborative deep learning model training while preserving data privacy and model security by avoiding direct sharing of raw data and model details (i.e., sever and clients only hold partial sub-networks and exchange intermediate computations). However, existing research has mainly focused on examining its reliability for privacy protection, with little investigation into model security. Specifically, by exploring full models, attackers can launch adversarial attacks, and split learning can mitigate this severe threat by only disclosing part of models to untrusted servers. This paper aims to evaluate the robustness of split learning against adversarial attacks, particularly in the most challenging setting where untrusted servers only have access to the intermediate layers of the model. Existing adversarial attacks mostly focus on the centralized setting instead of the collaborative setting, thus, to better evaluate the robustness of split learning, we develop a tailored attack called SPADV, which comprises two stages: 1) shadow model training that addresses the issue of lacking part of the model and 2) local adversarial attack that produces adversarial examples to evaluate. The first stage only requires a few unlabeled non-IID data, and, in the second stage, SPADV perturbs the intermediate output of natural samples to craft the adversarial ones. The overall cost of the proposed attack process is relatively low, yet the empirical attack effectiveness is significantly high, demonstrating the surprising vulnerability of split learning to adversarial attacks.   
   
 88  On Quantified Observability Analysis in Multiagent Systems   
   
  Authors: Chunyan Mu ; Jun Pang   
  ##MORE##In multiagent systems (MASs), agents’ observation upon system behaviours may improve the overall team performance, but may also leak sensitive information to an observer. A quantified observability analysis can thus be useful to assist decision-making in MASs by operators seeking to optimise the relationship between performance effectiveness and information exposure through the observation in practice. This paper presents a novel approach to quantitatively analysing the observability properties in MASs. The concept of opacity is applied to formally express the characterisation of observability in MASs modelled as partially observable multiagent systems (POMASs). We propose a temporal logic oPATL to reason about agents’ observability with quantitative goals, which capture the probability of information transparency of system behaviours to an observer, and develop verification techniques for quantitatively analysing such properties.We also implement the approach as an extension of the probabilistic model checker PRISM, and illustrate its applicability via several examples.   
   
 89  Verifying Belief-based Programs via Symbolic Dynamic Programming   
   
  Authors: Daxin Liu ; Qinfei Huang ; Vaishak Belle ; Gerhard Lakemeyer   
  ##MORE##Belief-based programming is a probabilistic extension of the Golog programming language family, where every action and sensing could be noisy and every test refers to the subjective beliefs of the agent. Such characteristics make it rather suitable for robot control in a partial-observable uncertain environment. Recently, efforts have been made in providing formal semantics for belief programs and investigating the hardness of verifying belief programs. Nevertheless, a general algorithm that actually conducts the verification is missing. In this paper, we propose an algorithm based on symbolic dynamic programming to verify belief programs, an approach that generalizes the dynamic programming technique for solving (partially observable) Markov decision processes, i.e. (PO)MDP, by exploiting the symbolic structure in the solution of first-order (PO)MDPs induced by belief program execution.   
   
 98  On Explaining Agent Behaviour via Root Cause Analysis: A Formal Account Grounded in Theory of Mind   
   
  Authors: Shakil M Khan ; Maryam Rostamigiv   
  ##MORE##Inspired by a novel action-theoretic formalization of actual cause, Khan and Lespérance (2021) recently proposed a first account of causal knowledge that supports epistemic effects, models causal knowledge dynamics, and allows sensing actions to be causes of observed effects. To date, no other study has looked specifically at these issues. But their formalization is not sufficiently expressive enough to model explanations via causal analysis of mental states as it ignores a crucial aspect of theory of mind, namely motivations. In this paper, we build on their work to support causal reasoning about conative effects. In our framework, one can reason about causes of motivational states, and we allow motivation-altering actions to be causes of observed effects. We illustrate that this formalization along with a model of goal recognition can be utilized to explain agent behaviour in communicative multiagent contexts.   
   
 99  GAN-generated Faces Detection: A Survey and New Perspectives   
   
  Authors: Xin Wang ; Hui Guo ; Shu Hu ; Ming-Ching Chang ; Siwei Lyu   
  ##MORE##Generative Adversarial Networks (GAN) have led to the generation of very realistic face images, which have been used in fake social media accounts and other disinformation matters that can generate profound impacts. Therefore, the corresponding GAN-face detection techniques are under active development that can examine and expose such fake faces. In this work, we aim to provide a comprehensive review of recent progress in GAN-face detection. We focus on methods that can detect face images that are generated or synthesized from GAN models. We classify the existing detection works into four categories: (1) deep learning-based, (2) physical-based, (3) physiological-based methods, and (4) evaluation and comparison against human visual performance. For each category, we summarize the key ideas and connect them with method implementations. We also discuss open problems and suggest future research directions.   
   
 104  XFLT : Exploring Techniques for Generating Cross Lingual Factually Grounded Long Text   
   
  Authors: Bhavyajeet Singh ; Aditya Hari ; Rahul Mehta ; Tushar Abhishek ; Manish Gupta ; Vasudeva Varma   
  ##MORE##Multiple business scenarios require an automated generation of descriptive human-readable long text from structured input data, where the source is typically a high-resource language and the target is a low or medium resource language. We define the Cross-Lingual Fact to Long Text Generation (XFLT) as a novel natural language generation (NLG) task that involves generating descriptive and human-readable long text in a target language from structured input data (such as fact triples) in a source language. XFLT is challenging because of (a) hallucinatory nature of the state-of-the-art NLG models, (b) lack of good quality training data, and (c) lack of a suitable cross-lingual NLG metric. Unfortunately previous work focuses on different related problem settings (cross-lingual facts to short text or monolingual graph to text) and has made no efforts to handle hallucinations. In this paper, we propose a novel solution to the XFLT task which addresses these challenges by training multilingual Transformer-based encoder-decoder models with coverage prompts and grounded decoding. Further, it improves on the XFLT quality by defining task-specific reward functions and training on them using reinforcement learning. On a dataset with over 64,000 paragraphs across 12 different languages, we compare this novel solution with several strong baselines using a new metric, cross-lingual PARENT. We also make our code and data publicly available   
   
 119  Region-Specific Prototype Customization for Weakly Supervised Semantic Segmentation   
   
  Authors: Ruiguo Yu ; Yihang Zhao ; Mei Yu ; Jie Gao ; Chenhan Wang ; Ruixuan Zhang ; Xuewei Li   
  ##MORE##It is well known that weakly supervised semantic segmentation requires only image-level labels for training, which greatly reduces the annotation cost. In recent years, prototype-based approaches, which prove to substantially improve the segmentation performance, have been favored by a wide range of researchers. However, we are surprised to find that there are semantic gaps between different regions within the same object, hindering the optimization of prototypes, so the traditional prototypes can not adequately represent the entire object. Therefore, we propose region-specific prototypes to adaptively describe the regions themselves, which alleviate the effect of semantic gap by separately obtaining prototypes for different regions of an object. In addition, to obtain more representative region-specific prototypes, a plug-and-play Spatially Fused Attention Module is proposed for combining the spatial correlation and the scale correlation of hierarchical features. Extensive experiments are conducted on PASCAL VOC 2012 and MS COCO 2014, and the results show that our method achieves state-of-the-art performance using only image-level labels.   
   
 130  A Paraconsistency Framework for Inconsistency Handling in Qualitative Spatial and Temporal Reasoning   
   
  Authors: Yakoub Salhi ; Michael Sioutis   
  ##MORE##Inconsistency handling is a fundamental problem in knowledge representation and reasoning. In this paper, we study this problem in the context of qualitative spatio-temporal reasoning, a framework for reasoning about space and time in a symbolic, human-like manner, by following an approach similar to that used for defining paraconsistent logics; paraconsistency allows deriving informative conclusions from inconsistent knowledge bases by mainly avoiding the principle of explosion. Inspired by paraconsistent logics, such as Priest’s logic LPm, we introduce the notion of paraconsistent scenario (i.e., a qualitative solution), which can be seen as a scenario that allows a conjunction of base relations between two variables, e.g., x precedes ∧ follows y. Further, we present several interesting theoretical properties that concern paraconsistent scenarios, including computational complexity results, and describe two distinct approaches for computing paraconsistent scenarios and solving other related problems. Moreover, we provide implementations of our two methods for computing paraconsistent scenarios and experimentally evaluate them using different strategies/metrics. Finally, we show that our paraconsistent scenario notion allows us to adapt to qualitative reasoning one of the well-known inconsistency measures employed in the propositional case, namely, contension measure.   
   
 136  Model-based Reinforcement Learning with Multi-step Plan Value Estimation   
   
  Authors: Haoxin Lin ; Yihao Sun ; Jiaji Zhang ; Yang Yu   
  ##MORE##A promising way to improve the sample efficiency of reinforcement learning is model-based methods, in which many explorations and evaluations can happen in the learned models to save real-world samples. However, when the learned model has a non-negligible model error, sequential steps in the model are hard to be accurately evaluated, limiting the model’s utilization. This paper proposes to alleviate this issue by introducing multi-step plans into policy optimization for model-based RL. We employ the multi-step plan value estimation, which evaluates the expected discounted return after executing a sequence of action plans at a given state, and updates the policy by directly computing the multi-step policy gradient via plan value estimation. The new model-based reinforcement learning algorithm MPPVE (Model-based Planning Policy Learning with Multi-step Plan Value Estimation) shows a better utilization of the learned model and achieves a better sample efficiency than state-of-the-art model-based RL approaches. The code is available at https://github.com/HxLyn3/MPPVE  .   
   
 140  Mitigating Long-tail Language Representation Collapsing via Cross-lingual Bootstrapped Unsupervised Fine-tuning   
   
  Authors: Ping Guo ; Yue Hu ; Yubing Ren ; Yunpeng Li ; Jiarui Zhang ; Xingsheng Zhang   
  ##MORE##Large Language Models have shown great capability to comprehend natural language and provide reasonable responses. However, previous research has shown weak performance of these models on low-resource (long-tail) languages. It remains to be a problem to mitigate the performance gap between long-tail languages and rich-resource ones, which is referred to as long-tail language representation collapsing. Though some previous works can generate pseudo parallel corpora with auto-regressive generation, this generation progress is time-consuming and remains low quality particularly for long-tail languages. In this paper, we propose a (X) Cross-lingual Bootstrapped Unsupervised Fine-tuning Framework (X-BUFF) to mitigate long-tail language representation collapsing. X-BUFF iteratively updates the cross-lingual PLM in a curriculum way. In each iteration of X-BUFF, we (1) select sentences with certain semantics from monolingual corpora in long-tail languages. (2) match these selected sentences with semantic equivalent sentences in many other languages to create parallel sentence pairs, which we then merge with previous sentence pairs to build a larger and more difficult bootstrapped parallel queue. (3) fine-tune the PLM with the bootstrapped parallel queue in a curriculum way. Extensive experiments show that X-BUFF can mitigate the long-tail language representation collapsing problem in cross-lingual PLMs and achieve significant improvements over the previous baseline on several cross-lingual evaluation benchmarks.   
   
 145  Algorithmic Recognition of 2-Euclidean Preferences   
   
  Authors: Bruno Escoffier ; Olivier Spanjaard ; Magdalena Tydrichova   
  ##MORE##A set of voters' preferences on a set of candidates is 2-Euclidean if candidates and voters can be mapped to the plane so that the preferences of each voter decrease with the Euclidean distance between her position and the positions of candidates. Based on geometric properties, we propose a recognition algorithm, that returns either "yes" (together with a planar positioning of candidates and voters) if the preferences are 2-Euclidean, or "no" if it is able to find a concise certificate that they are not, or "unknown" if a time limit is reached. Our algorithm outperforms a quadratically constrained programming solver achieving the same task, both in running times and the percentage of instances it is able to recognize. In the numerical tests conducted on the PrefLib library of preferences, 91.5% (resp. 4.5%) of the available sets of complete strict orders are proven not to be (resp. to be) 2-Euclidean, and the status of only 4.5% of them could not be decided. Furthermore, for instances involving 5 (resp. 6, 7) candidates, we were able to find planar representations that are compatible with 87.4% (resp. 58.1%, 60.1%) of voters' preferences.   
   
 152  Effective and Efficient Community Search with Graph Embeddings   
   
  Authors: Xiaoxuan Gou ; Xiaoliang Xu ; Xiangying Wu ; Runhuai Chen ; Yuxiang Wang ; Tianxing Wu ; Xiangyu Ke   
  ##MORE##Given a graph $G$ and a query node $q$, community search (CS) seeks a cohesive subgraph from $G$ that contains $q$. CS has gained much research interests recently. In the database research community, researchers aim to find the most cohesive subgraph satisfying a specific community model (e.g., $k$-core or $k$-truss) via graph traversal. These works obtain good precision, however suffering from the low efficiency issue. In the AI research community, a new thought of using the deep learning model to support CS without relying on graph traversal emerges. Supervised end-to-end models using GCN are presented, which perform efficiently, but leave a large room for precision improvement. None of them can achieve a good balance between the efficiency and effectiveness. This motivates our solution: First, we present an offline community-injected graph embedding method to preserve the community's cohesiveness features into the learned node representations. Second, we resort to a proximity graph (PG) built from node representations, to quickly return the community online. Moreover, we develop a self-augmented method based on KL divergence to further optimize node representations. Extensive experiments on seven real-world graphs show our solution's superiority on effectiveness (at least 39.3\% improvement) and efficiency (one to two orders of magnitude faster).   
   
 166  Theoretically Guaranteed Policy Improvement Distilled from Model-Based Planning   
   
  Authors: Chuming Li ; Ruonan Jia ; Jie Liu ; Yinmin Zhang ; Yazhe Niu ; Yaodong Yang ; Yu Liu ; Wanli Ouyang   
  ##MORE##Model-based reinforcement learning (RL) has demonstrated remarkable successes on a range of continuous control tasks due to its high sample efficiency. To save the computation cost of conducting planning online, recent practices tend to distill optimized action sequences into an RL policy during the training phase. Although the distillation can incorporate both the foresight of planning and the exploration ability of RL policies, the theoretical understanding of these methods is yet unclear. In this paper, we extend the policy improvement step of Soft Actor-Critic (SAC) by developing an approach to distill from model-based planning to the policy. We then demonstrate that such an approach of policy improvement has a theoretical guarantee of monotonic improvement and convergence to the maximum value defined in SAC. We discuss effective design choices and implement our theory as a practical algorithm---\textit{\textbf{M}odel-based \textbf{P}lanning \textbf{D}istilled to \textbf{P}olicy (MPDP)}---that updates the policy jointly over multiple future time steps. Extensive experiments show that MPDP achieves better sample efficiency and asymptotic performance than both model-free and model-based planning algorithms on six continuous control benchmark tasks in MuJoCo.   
   
 168  A Simple Debiasing Framework for Out-of-Distribution Detection in Human Action Recognition   
   
  Authors: Minho Sim ; Young Jun Lee ; Dongkun Lee ; Jongwhoa Lee ; Ho-Jin Choi   
  ##MORE##In real-world scenarios, detecting out-of-distribution (OOD) action is important when deploying a deep learning-based human action recognition (HAR) model. However, HAR models are easily biased to static information in the video (e.g., background), which can lead to performance degradation of OOD detection methods. In this paper, we propose a simple debiasing framework for out-of-distribution detection in human action recognition. Specifically, our framework eliminates patches with static bias in video using attention maps extracted from the video vision transformer model. Experimental results show that our framework achieves consistent performance improvement on multiple OOD action detection methods and challenging benchmarks. Furthermore, we introduce two new OOD action detection tasks, Kinetics-400 vs. Kinetics-600 exclusive and Kinetics-400 vs. Kinetics-700 exclusive, to validate our method in a setting close to the real-world scenario. With extensive experiments, we demonstrate the effectiveness of our attention-based masking, and in-depth analysis validates the effect of static bias on OOD action detection. The source code and supplementary materials are available at: https://github.com/Simcs/attention-masking  .   
   
 171  From Intermediate Representations to Explanations: Exploring Hierarchical Structures in NLP   
   
  Authors: Housam Babiker ; Mi-Young Kim ; Randy Goebel   
  ##MORE##Interpretation methods for learned models used in natural language processing (NLP) applications usually provide support for local (specific) explanations, such as quantifying the contribution of each word to the predicted class. But they typically ignore the potential interaction amongst those word tokens. Unlike currently popular methods, we propose a deep model which uses feature attribution and identification of dependencies to support the learning of interpretable representations that will support creation of hierarchical explanations. In addition, hierarchical explanations provide a basis for visualizing how words and phrases are combined at different levels of abstraction, which enables end-users to better understand the prediction process of a deep network. Our study uses multiple well-known datasets to demonstrate the effectiveness of our approach, and provides both automatic and human evaluation.   
   
 175  Cardsformer: Grounding Language to Learn a Generalizable Policy in Hearthstone   
   
  Authors: Wannian Xia ; Yang Yiming ; Jingqing Ruan ; Xing Dengpeng ; Bo Xu   
  ##MORE##Hearthstone is a widely played collectible card game that challenges players to strategize using cards with various effects described in natural language. While human players can easily comprehend card descriptions and make informed decisions, artificial agents struggle to understand the game's inherent rules, let alone generalize their policies through natural language. To address this issue, we propose Cardsformer, a method capable of acquiring linguistic knowledge and learning a generalizable policy in Hearthstone. Cardsformer consists of a Prediction Model trained with offline trajectories to predict state transitions based on card descriptions and a Policy Model capable of generalizing its policy on unseen cards. To our knowledge, this is the first work to consider language knowledge in a card game. Experiments show that our approach significantly improves data efficiency and outperforms the state-of-the-art in Hearthstone even when there are untrained cards in the deck, inspiring a new perspective of tackling problems as such with knowledge representation from large language models. As the game constantly releases new cards along with new descriptions and new effects, the challenge in Hearthstone remains. To encourage further research, we will make our code publicly available and publish PyStone, the code base of Hearthstone on which we conducted our experiments, as an open benchmark.   
   
 179  Dual-Scale Interest Extraction Framework with Self-Supervision for Sequential Recommendation   
   
  Authors: Liangliang Chen ; Hongzhan Lin ; Jinshan Ma ; Guang Chen   
  ##MORE##In the sequential recommendation task, the recommender generally learns multiple embeddings from a user's historical behaviors, to catch the diverse interests of the user. Nevertheless, the existing approaches just extract each interest independently for the corresponding sub-sequence while ignoring the global correlation of the entire interaction sequence, which may fail to capture the user's inherent preference for the potential interests generalization and unavoidably make the recommended items homogeneous with the historical behaviors. In this paper, we propose a novel Dual-Scale Interest Extraction framework (DSIE) to precisely estimate the user's current interests. Specifically, DSIE explicitly models the user's inherent preference with contrastive learning by attending over his/her entire interaction sequence at the global scale and catches the user's diverse interests in a fine granularity at the local scale. Moreover, we develop a novel interest aggregation module to integrate the multi-interests according to the inherent preference to generate the user's current interests for the next-item prediction. Experiments conducted on three real-world benchmark datasets demonstrate that DSIE outperforms the state-of-the-art models in terms of recommendation preciseness and novelty.   
   
 181  Spectral Normalized-Cut Graph Partitioning with Fairness Constraints   
   
  Authors: Jia Li ; Yanhao Wang ; Arpit Merchant   
  ##MORE##Normalized-cut graph partitioning aims to divide the set of nodes in a graph into k disjoint clusters to minimize the fraction of the total edges between any cluster and all other clusters. In this paper, we consider a fair variant of the partitioning problem wherein nodes are characterized by a categorical sensitive attribute (e.g., gender or race) indicating membership to different demographic groups. Our goal is to ensure that each group is approximately proportionally represented in each cluster while minimizing the normalized cut value. To resolve this problem, we propose a two-phase spectral algorithm called FNM. In the first phase, we add an augmented Lagrangian term based on our fairness criteria to the objective function for obtaining a fairer spectral node embedding. Then, in the second phase, we design a rounding scheme to produce k clusters from the fair embedding that effectively trades off fairness and partition quality. Through comprehensive experiments on nine benchmark datasets, we demonstrate the superior performance of FNM compared with three baseline methods.   
   
 190  Argument Attribution Explanations in Quantitative Bipolar Argumentation Frameworks   
   
  Authors: Xiang Yin ; Nico Potyka ; Francesca Toni   
  ##MORE##Argumentative explainable AI has been advocated by several in recent years, with an increasing interest on explaining the reasoning outcomes of Argumentation Frameworks (AFs). While there is a considerable body of research on qualitatively explaining the reasoning outcomes of AFs with debates/disputes/dialogues in the spirit of extension-based semantics, explaining the quantitative reasoning outcomes of AFs under gradual semantics has not received much attention, despite widespread use in applications. In this paper, we contribute to filling this gap by proposing a novel theory of Argument Attribution Explanations (AAEs) by incorporating the spirit of feature attribution from machine learning in the context of Quantitative Bipolar Argumentation Frameworks (QBAFs): whereas feature attribution is used to determine the influence of features towards outputs of machine learning models, AAEs are used to determine the influence of arguments towards topic arguments of interest. We study desirable properties of AAEs, including some new ones and some partially adapted from the literature to our setting. To demonstrate the applicability of our AAEs in practice, we conclude by carrying out two case studies in the scenarios of fake news detection and movie recommender systems.   
   
 197  PLEASE: Generating Personalized Explanations in Human-Aware Planning   
   
  Authors: Stylianos Loukas Vasileiou ; William Yeoh   
  ##MORE##Model Reconciliation Problems (MRPs) and their variant, Logic-based MRPs (L-MRPs), have emerged as popular methods for explainable planning problems. Both MRP and L-MRP approaches assume that the explaining agent has access to an assumed model of the human user receiving the explanation, and it reconciles its own model with the human model to find the differences such that when they are provided as explanations to the human, they will understand them. However, in practical applications, the agent is likely to be fairly uncertain on the actual model of the human and wrong assumptions can lead to incoherent or unintelligible explanations. In this paper, we propose a less stringent requirement: the agent has access to a task-specific vocabulary known by the human and, if available, a human model capturing confidently known information. Our goal is to find a personalized explanation, which is an explanation that is at an appropriate abstraction level with respect to the human's vocabulary and model. Using a logic-based method called knowledge forgetting for generating abstractions, we propose a simple framework compatible with L-MRP approaches, and evaluate its efficacy through computational and human user experiments.   
   
 198  Anytime Index-Based Search Method for Large-Scale Simultaneous Coalition Structure Generation and Assignment   
   
  Authors: Redha Taguelmimt ; Samir Aknine ; Djamila Boukredera ; Narayan Mr Changder   
  ##MORE##Organizing agents into disjoint groups is a crucial challenge in artificial intelligence, with many applications where quick runtime is essential. The Simultaneous Coalition Structure Generation and Assignment (SCSGA) problem involves partitioning a set of agents into coalitions and assigning each coalition to a task, with the goal of maximizing social welfare. However, this is an NP-complete problem, and only a few algorithms have been proposed to address it for both small and large-scale problems. In this paper, we address this challenge by presenting a novel algorithm that can efficiently solve both small and large instances of this problem. Our method is based on a new search space representation, where each coalition is codified by an index. We have developed an algorithm that can explore this solution space effectively by generating index vectors that represent coalition structures. The resulting algorithm is anytime and can scale to large problems with hundreds or thousands of agents. We evaluated our algorithm on a range of value distributions and compared its performance against state-of-the-art algorithms. Our experimental results demonstrate that our algorithm outperforms existing methods in solving the SCSGA problem, providing high-quality solutions for a wide range of problem instances.   
   
 202  Synthesis of Procedural Models for Deterministic Transition Systems   
   
  Authors: Javier Segovia-Aguas ; Jonathan Ferrer Mestres ; Sergio Jiménez Celorrio   
  ##MORE##This paper introduces a general approach for synthesizing procedural models of the {\em state-transitions} of a given {\em discrete system}.  
  The approach is general in that it accepts different {\em target languages} for modeling the state-transitions of a discrete system; different model acquisition tasks with different target languages, such as the synthesis of \strips{} action models, or the update rule of a {\em cellular automaton}, fit as particular instances of our general approach. We follow an inductive approach to synthesis meaning that a set of examples of state-transitions, represented as {\em (pre-state, action, post-state)} tuples, are given as input. The goal is to synthesize a structured program that, when executed on a pre-state, outputs the associated post-state. Our synthesis method implements a combinatorial search in the space of well-structured terminating programs that can be built using a {\em Random-Access Machine} (RAM), with a minimalist instruction set, and a finite amount of memory. The combinatorial search is guided with functions that asses the computational complexity of the candidate programs, as well as their fitness to the input set of examples.   
   
 203  Individual Fairness Guarantee in Learning with Censorship   
   
  Authors: Wenbin Zhang ; Juyong Kim ; Zichong Wang ; Cheng Cheng ; Thomas Oommen ; Pradeep Ravikumar ; Jeremy C Weiss   
  ##MORE##Algorithmic fairness, the research field of making machine learning (ML) algorithms fair, is an established area in ML. As ML technologies expand their application domains, including ones with high societal impact, it becomes essential to take fairness into consideration during the building of ML systems. Yet, despite its wide range of socially sensitive applications, most work treats the issue of algorithmic bias as an intrinsic property of supervised learning, i.e. the class label is given as a precondition. Unlike prior studies in fairness, we propose an individual fairness measure and a corresponding algorithm that deal with censorship where there is uncertainty in class labels, while enforcing similar individuals to be treated similarly from a ranking perspective, free of the Lipchitz condition in the conventional individual fairness definition. We argue that this perspective represents a more realistic model of fairness research for real-world application deployment and show how learning with such a relaxed precondition draws new insights that better explains algorithmic fairness. We conducted experiments on four real-world datasets to evaluate our proposed method compared to other fairness models, demonstrating its superiority in minimizing discrimination while maintaining predictive performance with the presence of censorship.   
   
 205  BiERL: A Meta Evolutionary Reinforcement Learning Framework via Bilevel Optimization   
   
  Authors: Junyi Wang ; Yuanyang Zhu ; Zhi Wang ; Yan Zheng ; Jianye Hao ; Chunlin Chen   
  ##MORE##Evolutionary reinforcement learning (ERL) algorithms recently raise attention in tackling complex reinforcement learning (RL) problems due to high parallelism, while they are prone to insufficient exploration or model collapse without carefully tuning hyperparameters (aka meta-parameters). In the paper, we propose a general meta ERL framework via bilevel optimization (BiERL) to jointly update hyperparameters in parallel to training the ERL model within a single agent, which relieves the need for prior domain knowledge or costly optimization procedure before model deployment. We design an elegant meta-level architecture that embeds the inner-level's evolving experience into an informative population representation, and we introduce a simple and feasible evaluation of the meta-level fitness function to facilitate learning efficiency. We perform extensive experiments in MuJoCo and Box2D domains to verify that as a general framework, BiERL outperforms various baselines and consistently improves the learning performance for a diversity of ERL algorithms.   
   
 207  Exploration and Exploitation in Hierarchical Reinforcement Learning with Adaptive Scheduling   
   
  Authors: ZhiGang Huang ; Quan Liu   
  ##MORE##In hierarchical reinforcement learning (HRL), continuous options provide a knowledge carrier that is more aligned with human behavior, but reliable scheduling methods are not yet available. To design an available scheduling method for continuous options, in this paper, the hierarchical reinforcement learning with adaptive scheduling (HAS) algorithm is proposed. It focuses on achieving an adaptive balance between exploration and exploitation during the frequent scheduling of continuous options. It builds on multi-step static scheduling and makes switching decisions according to the relative advantages of the previous and the estimated options, enabling the agent to focus on different behaviors at different phases. The expected $t$-step distance is applied to demonstrate the superiority of adaptive scheduling in terms of exploration. Furthermore, an interruption incentive based on annealing is proposed to alleviate excessive exploration, accelerating the convergence rate. We develop a comprehensive experimental analysis scheme. The experimental results demonstrate the high performance and robustness of HAS. Furthermore, it provides evidence that the adaptive scheduling method has a positive effect both on the representation and option policies.   
   
 208  Create and Find Flatness: Building Flat Training Spaces in Advance for Continual Learning   
   
  Authors: WenHang Shi ; Yiren Chen ; Zhe Zhao ; Wei Lu ; Kimmo Yan ; Xiaoyong Du   
  ##MORE##Catastrophic forgetting remains a critical challenge in the field of continual learning, where neural networks struggle to retain prior knowledge while assimilating new information. Most existing studies emphasize mitigating this issue only when encountering new tasks, overlooking the significance of the pre-task phase. Therefore, we shift the attention to the current task learning stage, presenting a novel framework, C&F (Create and Find Flatness), which builds a flat training space for each task in advance. Specifically, during the learning of the current task, our framework adaptively creates a flat region around the minimum in the the loss landscape. Subsequently, it finds the parameters' importance to the current task based on their flatness degrees. When adapting the model to a new task, constraints are applied according to the flatness and a flat space is simultaneously prepared for the impending task. We theoretically demonstrate the consistency between created and found flatness. In this manner, our framework not only accommodates ample parameter space for learning new tasks but also preserves the preceding knowledge of earlier tasks. Experimental results exhibit C&F's state-of-the-art performance as a standalone continual learning approach and its efficacy as a framework incorporating other methods.   
   
 210  LoSS: Local Structural Separation Hypergraph Convolutional Neural Network   
   
  Authors: Bingde Hu ; Yang Gao ; Zunlei Feng ; Mingli Song ; Xinyu Wang ; Liying Liying   
  ##MORE##Graph classification is a classic problem with practical applications in many real-life scenes. Existing graph neural networks, including GCN, GAT, and GIN, are proposed to extract useful features from complex graph structures.  
  However, the features extraction and aggregation manner of most existing methods inevitably mixes the useful and redundant features, which will disturb the final classification performance. In this paper, to handle the above drawback, we put forward Local Structural Separation Hypergraph Convolutional Neural Network (LoSS) based on two discoveries: most graph classification tasks only focus on a few groups of adjacent nodes, and different categories have their specific high response bits in graph embeddings. In LoSS, we first decouple the original graph into different hypergraphs and aggregate the features in each substructure, which aims to find useful features for the final classification. Next, the low-correlation feature suppression strategy is devised to suppress the irrelevant node-level and bit-level features in the forward inference process, which can effectively reduce the disturbance of redundant features. Experiments on five datasets show that the proposed LoSS can effectively locate and aggregate useful hypergraph features and achieve SOTA performance compared with existing methods.   
   
 212  Truthful and Equitable Lateral Transshipment in Multi-Retailer Systems   
   
  Authors: Garima Shakya ; Sai Koti Reddy Danda ; Swaprava Nath ; Pankaj Dayama ; Surya Shravan Kumar Sajja   
  ##MORE##We consider a multi-retailer system where the sellers are connected with each other via a transportation network and the transactions with the consumers happen on a platform. Each consumer is serviced by only one retailer. Since the demands to the sellers (i.e., the retailers on the platform) are stochastic in nature, supplies can be either in excess or in deficit. Transshipping these items laterally among the retailers benefits both, the platform and the retailers. For retailers, excess supply leads to wastage and deficit to a loss of revenue, while via transshipment, they get a better outcome. The platform can also earn some revenue in facilitating this process. However, only the sellers know their excess (which can be salvaged at a price or transshipped to another seller) or the deficit (which can be directly procured from a supplier or transshipped from another seller), both of which have multiple information that is private. We propose a model that allows the lateral transshipment at a price and design mechanisms such that the sellers are incentivized to voluntarily participate and be truthful in the lateral transshipment. Experimenting on different types of network topologies, we find that the sellers at more central locations in the network get an unfair advantage in the classical mechanism that aims for economic efficiency. We, therefore, propose a modified mechanism with tunable parameters which can ensure that the mechanism is more equitable for non-central retailers. Our synthetic data experiments show that such mechanisms do not compromise too much on efficiency, and also reduce budget imbalance.   
   
 223  FATRER: Full-Attention Topic Regularizer for Accurate and Robust Conversational Emotion Recognition   
   
  Authors: Yuzhao Mao ; Di Lu ; Yang Zhang ; Xiaojie Wang   
  ##MORE##This paper concentrates on the understanding of interlocutors’ emotions evoked in conversational utterances. Previous studies on this literature mainly focus on more accurate emotional predictions, while ignoring the model robustness when the local context is corrupted by adversarial attacks. To cope with the impact from local perturbations, we propose a full-attention topic regularizer that enables a global view when modeling local context for conversational emotion recognition. A joint topic modeling strategy is introduced to enforce regularization from both representation and loss perspectives. To avoid over-regularization, we drop the constraints on prior distributions that exist in traditional topic modeling and perform full-attention-based probabilistic approximations. Experiments show that our models obtain more favorable results than the state-of-the-art models, and gain convincing robustness under three types of adversarial attacks. Code: https://github.com/ludybupt/FATRER    
   
 231  A semantics-driven methodology for high-quality image annotation   
   
  Authors: Fausto Giunchiglia ; Mayukh Bagchi ; Xiaolei Diao   
  ##MORE##Recent work in Machine Learning and Computer Vision has highlighted the presence of various types of systematic flaws inside ground truth object recognition benchmark datasets. Our basic tenet is that these flaws are rooted in the many-to-many mappings which exist between the visual information encoded in images and the intended semantics of the labels annotating them. The net consequence is that the current annotation process is largely under-specified, thus leaving too much freedom to the subjective judgment of annotators. In this paper, we propose vTelos, an integrated Natural Language Processing, Knowledge Representation, and Computer Vision methodology whose main goal is to make explicit the (otherwise implicit) intended annotation semantics, thus minimizing the number and role of subjective choices. vTelos is organized around four main design choices, each focusing on a specific aspect of the annotation process. In this respect, visual properties are used to specify the relevant elements of an image and labels are associated with natural language genus-differentia definitions which describe the selected visual properties. In turn, these definitions are organized into a lexico-semantic hierarchy that captures their intrinsic recursive structure. The methodology is validated on images populating a subset of the ImageNet hierarchy.   
   
 236  Towards a Rigorous Calibration Assessment Framework: Advancements in Metrics, Methods, and Use   
   
  Authors: Lorenzo Famiglini ; Andrea Campagner ; Federico Cabitza   
  ##MORE##Calibration is paramount in developing and validating Machine Learning models, particularly in sensitive domains such as medicine. Despite its significance, existing metrics to assess calibration have been found to have shortcomings in regard to their interpretation and theoretical properties. This article introduces a novel and comprehensive framework to assess the calibration of Machine and Deep Learning models that addresses the above limitations. The proposed framework is based on a modification of the Expected Calibration Error (ECE), called the Estimated Calibration Index (ECI), which grounds on and extends prior research. ECI was initially formulated for binary settings, and we adapted it to fit multiclass settings. ECI offers a more nuanced, both locally and globally, and informative measure of a model's tendency towards over/underconfidence. The paper first outlines the issues related to the prevalent definitions of ECE, including potential biases that may arise in the evaluation of their measures. Then, we present the results of a series of experiments conducted to demonstrate the effectiveness of the proposed framework in supporting a more accurate understanding of a model's calibration level. Additionally, we discuss how to address and potentially mitigate some biases in calibration assessment.   
   
 238  One-class classification approach to variational learning from biased positive unlabeled data   
   
  Authors: Jan Mielniczuk ; Adam Wawrzeńczyk   
  ##MORE##We discuss Empirical Risk Minimization approach in conjunction with one-class classification method to learn classifiers for biased Positive Unlabeled (PU) data. For such data, probability that an observation from a positive class is labeled may depend on its features. The proposed method extends Variational Autoencoder for PU data (VAE-PU) introduced in Na et al (2020) by proposing another estimator of a theoretical risk of a classifier to be minimized, which has important advantages over the previous proposal. This is based on one-class classification approach using generated pseudo-observations, which turns out to be an effective method of detecting positive observations among unlabeled ones. The proposed method leads to more precise estimation of the theoretical risk than the previous proposal. Experiments performed on real data sets show that the proposed VAE-PU+OCC algorithm works very promisingly in comparison to its competitors such as the original VAE-PU, SAR-EM and LBE methods in terms of accuracy and F1 score. The advantage is especially strongly pronounced for small labeling frequencies.   
   
 246  TreeFlow: Going Beyond Tree-based Parametric Probabilistic Regression   
   
  Authors: Patryk Wielopolski ; Maciej Zieba   
  ##MORE##The tree-based ensembles are known for their outstanding performance in classification and regression problems characterized by feature vectors represented by mixed-type variables from various ranges and domains. However, considering regression problems, they are primarily designed to provide deterministic responses or model the uncertainty of the output with Gaussian or parametric distribution. In this work, we introduce TreeFlow, the tree-based approach that combines the benefits of using tree ensembles with the capabilities of modeling flexible probability distributions using normalizing flows. The main idea of the solution is to use a tree-based model as a feature extractor and combine it with a conditional variant of normalizing flow. Consequently, our approach is capable of modeling complex distributions for the regression outputs. We evaluate the proposed method on challenging regression benchmarks with varying volume, feature characteristics, and target dimensionality. We obtain the SOTA results for both probabilistic and deterministic metrics on datasets with multi-modal target distributions and competitive results on unimodal ones compared to tree-based regression baselines.   
   
 247  Preserving Semantics in Textual Adversarial Attacks   
   
  Authors: David Herel ; Hugo Cisneros ; Tomas Mikolov   
  ##MORE##The growth of hateful online content, or hate speech, has been associated with a global increase in violent crimes against minorities (Laub, 2019). Harmful online content can be produced easily, automatically and anonymously. Even though, some form of auto-detection is already achieved through text classifiers in NLP, they can be fooled by adversarial attacks. To strengthen existing systems and stay ahead of attackers, we need better adversarial attacks. In this paper, we show that up to 70% of adversarial examples generated by adversarial attacks should be discarded because they do not preserve semantics. We address this core weakness and propose a new, fully supervised sentence embedding technique called Semantics-Preserving-Encoder (SPE). Our method outperforms existing sentence encoders used in adversarial attacks by achieving 1.2× ∼ 5.1× better real attack success rate. We release our code as a plugin that can be used in any existing adversarial attack to improve its quality and speed up its execution.   
   
 250  Settling the Score: Portioning with Cardinal Preferences   
   
  Authors: Edith Elkind ; Warut Suksompong ; Nicholas Teh   
  ##MORE##We study a portioning setting in which a public resource such as time or money is to be divided among a given set of candidates, and each agent proposes a division of the resource. We consider two families of aggregation rules for this setting - those based on coordinate-wise aggregation and those that optimize some notion of welfare - as well as the recently proposed Independent Markets mechanism. We provide a detailed analysis of these rules from an axiomatic perspective, both for classic axioms, such as strategyproofness and Pareto optimality, and for novel axioms, which aim to capture proportionality in this setting. Our results indicate that a simple rule that computes the average of all proposals satisfies many of our axioms, including some that are violated by more sophisticated rules.   
   
 253  Understanding and Improving Neural Active Learning on Heteroskedastic Distributions   
   
  Authors: Savya Khosla ; Kin Whye Chew ; Jordan Ash ; Cyril Zhang ; Kenji Kawaguchi ; Alex Lamb   
  ##MORE##Models that can actively seek out the best quality training data hold the promise of more accurate, adaptable, and efficient machine learning. Active learning techniques often tend to prefer examples that are the most difficult to classify. While this works well on homogeneous datasets, we find that it can lead to catastrophic failures when performed on multiple distributions with different degrees of label noise or heteroskedasticity. These active learning algorithms strongly prefer to draw from the distribution with more noise, even if their examples have no informative structure (such as solid color images with random labels). To this end, we demonstrate the catastrophic failure of these active learning algorithms on heteroskedastic distributions and propose a fine-tuning-based approach to mitigate these failures. Further, we propose a new algorithm that incorporates a model difference scoring function for each data point to filter out the noisy examples and sample clean examples that maximize accuracy, outperforming the existing active learning techniques on the heteroskedastic datasets. We hope these observations and techniques are immediately helpful to practitioners and can help to challenge common assumptions in the design of active learning algorithms.   
   
 264  Privacy-enhanced Personal Assistants based on Dialogues and Case Similarity   
   
  Authors: Xiao Zhan ; Stefan Sarkadi ; Jose Such   
  ##MORE##Personal assistants (PAs) such as Amazon Alexa, Google Assistant and Apple Siri are now widespread. However, without adequate safeguards and controls their use may lead to privacy risks and violations. In this paper, we propose a model for privacy-enhanced PAs. The model is an interpretable AI architecture that combines 1) a dialogue mechanism for understanding the user and getting online feedback from them, with 2) a decision making mechanism based on case-based reasoning considering both user and scenario similarity. We evaluate our model using real data about users' privacy preferences, and compare its accuracy and demand for user involvement with both online machine learning and other, more interpretable, AI approaches. Our results show that our proposed architecture is more accurate and requires less intervention from the users than existing approaches.   
   
 269  Causal Discovery and Knowledge Injection for Contestable Neural Networks   
   
  Authors: Fabrizio Russo ; Francesca Toni   
  ##MORE##Neural networks have proven to be effective at solving machine learning tasks but it is unclear whether they learn any relevant causal relationships, while their black-box nature makes it difficult for modellers to understand and debug them. We propose a novel method overcoming these issues by allowing a two-way interaction whereby neural-network-empowered machines can expose the underpinning learnt causal graphs and humans can contest the machines by modifying the causal graphs before re-injecting them into the machines, so that the learnt models are guaranteed to conform to the graphs and adhere to expert knowledge (some of which can also be given up-front). By building a window into the model behaviour and enabling knowledge injection, our method allows practitioners to debug networks based on the causal structure discovered from the data and underpinning the predictions. Experiments with real and synthetic tabular data show that our method improves predictive performance up to 2.4x while producing parsimonious networks, up to 7x smaller in the input layer, compared to SOTA regularised networks.   
   
 275  Cartesian Abstractions and Saturated Cost Partitioning in Probabilistic Planning   
   
  Authors: Thorsten Klößner ; Jendrik Seipp ; Marcel Steinmetz   
  ##MORE##Stochastic shortest path problems (SSPs) capture probabilistic planning tasks with the objective of minimizing expected cost until reaching the goal. One of the strongest methods to solve SSPs optimally is heuristic search guided by an admissible (lower-bounding) heuristic function. Recently, probability-aware pattern database (PDB) abstractions have been highlighted as an efficient way of generating such lower bounds, with significant advantages over traditional determinization-based approaches. Here, we follow this work, yet consider a more general type, Cartesian abstractions, which have been used successfully in the classical setting. We show how to construct probability-aware Cartesian abstractions via a counterexample-guided abstraction refinement (CEGAR) loop akin to classical planning. This method is complete, meaning it guarantees convergence to the optimal expected cost if not terminated prematurely. Furthermore, we investigate the admissible combination of multiple such heuristics using saturated cost partitioning (SCP), marking its first application in the probabilistic setting. In our experiments, we show that probability-aware Cartesian abstractions yield much more informative heuristics than their determinization-based counterparts. Finally, we show that SCP yields probability-aware abstraction heuristics that are superior to the previous state of the art.   
   
 276  Revision Transformers: Instructing Language Models to Change their Values   
   
  Authors: Felix Friedrich ; Wolfgang Stammer ; Patrick Schramowski ; Kristian Kersting   
  ##MORE##Current transformer language models (LM) are large-scale models with billions of parameters. They have been shown to provide high performances on a variety of tasks but are also prone to shortcut learning and bias. Addressing such incorrect model behavior via parameter adjustments is very costly. This is particularly problematic for updating dynamic concepts, such as moral values, which vary culturally or interpersonally. In this work, we question the current common practice of storing all information in the model parameters and propose the Revision Transformer (RiT) to facilitate easy model updating. The specific combination of a large-scale pre-trained LM that inherently but also diffusely encodes world knowledge with a clear-structured revision engine makes it possible to update the model's knowledge with little effort and the help of user interaction. We exemplify RiT on a moral dataset and simulate user feedback demonstrating strong performance in model revision even with small data. This way, users can easily design a model regarding their preferences, paving the way for more transparent AI models.   
   
 278  GraphSA: Smart Contract Vulnerability Detection Combining Graph Neural Networks and Static Analysis   
   
  Authors: Long He ; Xiangfu Zhao ; Yichen Wang ; Jiahui Yang ; XueLei Sun   
  ##MORE##Security incidents in smart contracts still occur frequently, as the underlying code is often vulnerable to attacks. However, traditional methods to detect vulnerabilities in smart contracts are limited by certain rigid rules, reducing accuracy and scalability. In this work, we propose GraphSA, which combines graph neural networks (GNNs) and static analysis for smart contract vulnerability detection. First, we present the contract tree, which is obtained by converting the control flow graph (CFG) of a smart contract. Each node in the tree represents a crucial operation code (opcode) block, and each edge represents the control flow (execution order) between code blocks. Then, we propose an extended SAGConv and Topkpooling graph neural network (ST-GNN) to learn the features of each node in the tree. To enhance detection accuracy, we eliminate and merge some non-crucial nodes to highlight key nodes and execution orders. Finally, we evaluate our approach on 7,962 real-world smart contracts running on Ethereum and compare it with state-of-the-art approaches on six types of vulnerabilities. Experimental results show that our approach achieves higher detection accuracy than others.   
   
 282  Worrisome Properties of Neural Network Controllers and Their Symbolic Representations   
   
  Authors: Jacek Cyranka ; Kevin E M Church ; Jean-Philippe Lessard   
  ##MORE##We raise concerns about controllers' robustness in simple reinforcement learning benchmark problems. We focus on neural network controllers and their low neuron and symbolic abstractions. A typical controller reaching high mean return values still generates an abundance of persistent low-return solutions, which is a highly undesirable property, easily exploitable by an adversary. We find that the simpler controllers admit more persistent bad solutions. We provide an algorithm for a systematic robustness study and prove the persistent solutions and, in some cases, periodic orbits, using a computer-assisted proof methodology.   
   
 285  Piecewise-Stationary Combinatorial Semi-Bandit with Causally Related Rewards   
   
  Authors: Behzad Nourani Koliji ; Steven Bilaj ; Amir Rezaei Balef ; Setareh Maghsudi   
  ##MORE##We study the piecewise stationary combinatorial semi-bandit problem with causally related rewards. In our nonstationary environment, variations in the base arms' distributions, causal relationships between rewards, or both, change the reward generation process. In such an environment, an optimal decision-maker must follow both sources of change and adapt accordingly. The problem becomes aggravated in the combinatorial semi-bandit setting, where the decision-maker only observes the outcome of the selected bundle of arms. The core of our proposed policy is the Upper Confidence Bound (UCB) algorithm. We assume the agent relies on an adaptive approach to overcome the challenge. More specifically, it employs a change-point detector based on the Generalized Likelihood Ratio test. Besides, we introduce the notion of group restart as a new alternative restarting strategy in the decision making process in structured environments. Finally, our algorithm integrates a mechanism to trace the variations of the underlying graph structure, which captures the causal relationships between the rewards in the bandit setting. Theoretically, we establish a regret upper bound that reflects the effects of the number of structural- and distribution changes on the performance. The outcome of our numerical experiments in real-world scenarios exhibits applicability and superior performance of our proposal compared to the state-of-the-art benchmarks.   
   
 293  What Wikipedia Misses about Yuriko Nakamura? Predicting Missing Biography Content by Learning Latent Life Patterns   
   
  Authors: Yijun Duan ; Xin Liu ; Adam Jatowt ; Chenyi Zhuang ; Hai-Tao Yu ; Steven Lynden ; Kyoung-Sook Kim ; Akiyoshi Matono   
  ##MORE##Action-related KnowledGe (AKG) is important for facilitating deeper understanding of people's life patterns, objectives and motivations. In this study, we present a novel framework for automatically predicting missing human biography records in Wikipedia by generating such knowledge. The generation method, which is based on a neural network matrix factorization model, is capable of encoding action semantics from diverse perspectives and discovering latent inter-action relations. By correctly predicting missing information and correcting errors, our work can effectively improve the quality of data about the behavioral records of historical figures in the knowledge base (e.g., biographies in Wikipedia), thus contributing to the understanding and study of human actions by the general public on the one hand, and can be considered as a new paradigm for managing action-related knowledge in digital libraries on the other. Extensive experiments demonstrate that the AKG we generate can capture well missing or "forgotten" human biography related information in Wikipedia.   
   
 294  CompLung: Comprehensive Computer-Aided Diagnosis of Lung Cancer   
   
  Authors: Adam Pardyl ; Dawid Damian Rymarczyk ; Joanna Jaworek-Korjakowska ; Dariusz Kucharski ; Andrzej Brodzicki ; Julia Lasek ; Zofia Schneider ; Iwona Kucybała ; Andrzej Urbanik ; Rafał Obuchowicz ; Zbisław Tabor ; Bartosz Zieliński   
  ##MORE##Lung cancer is a leading cause of cancer-related deaths, and early diagnosis is crucial for its effective treatment. That is why computer-aided tools have been developed to support particular steps of CT scan analysis, including lung segmentation, suspicious region detection, and patient-level diagnosis. However, none of the previous approaches addressed this process comprehensively. To fill this gap, we introduce CompLung, a comprehensive tool for lung cancer diagnosis that performs all of the above-listed steps in an end-to-end manner. We have trained the CompLung architecture using the publicly available LIDC-IDRI dataset extended with lung segmentation masks obtained from our internal radiologists, which we make publicly available to boost the research on this emerging topic. Finally, we conduct extensive experiments and demonstrate the superior performance and interpretability of CompLung compared to existing methods for lung cancer diagnosis.   
   
 298  The Problem of Coherence in Natural Language Explanations of Recommendations   
   
  Authors: Jakub Raczyński ; Mateusz Lango ; Jerzy Stefanowski   
  ##MORE##Providing explanations for predictions of complex machine learning algorithms, including recommender systems, remains one of the biggest research challenges in AI. One form of such explanation that is particularly useful from the perspective of a non-expert user is an explanation expressed in natural language. Several methods for providing such explanations have recently been proposed for the recommendation task, however, we argue that an important aspect of explanation quality has been overlooked in their experimental evaluation. Specifically, the coherence between generated text and predicted rating, which is a necessary condition for an explanation to be useful, is not properly captured by currently used evaluation measures. In this paper, we highlight the issue of explanation and prediction coherence by 1) presenting results from a manual verification of explanations generated by one of the state-of-the-art approaches 2) proposing a method of automatic coherence evaluation 3) introducing a new transformer-based method that aims to produce more coherent explanations than the state-of-the-art approaches 4) performing an experimental evaluation which demonstrates that this method significantly improves the explanation coherence without affecting the other aspects of recommendation performance.   
   
 299  An Empirical Study of Retrieval-enhanced Graph Neural Networks   
   
  Authors: Dingmin Wang ; Shengchao Liu ; Hanchen Wang ; Bernardo Cuenca Grau ; Linfeng Song ; Jian Tang ; Le Song ; Liu Qi   
  ##MORE##Graph Neural Networks (GNNs) are effective tools for graph representation learning. Most GNNs rely on a recursive neigh- borhood aggregation scheme, named message passing, thereby their theoretical expressive power is limited to the first-order Weisfeiler- Lehman test (1-WL). An effective approach to this challenge is to explicitly retrieve some annotated examples used to enhance GNN models. While retrieval-enhanced models have been proved to be ef- fective in many language and vision domains, it remains an open question how effective retrieval-enhanced GNNs are when applied to graph datasets. Motivated by this, we want to explore how the retrieval idea can help augment the useful information learned in the graph neural networks, and we design a retrieval-enhanced scheme called GRAPHRETRIEVAL, which is agnostic to the choice of graph neural network models. In GRAPHRETRIEVAL, for each input graph, similar graphs together with their ground-true labels are retrieved from an existing database. Thus they can act as a potential enhance- ment to complete various graph property predictive tasks. We conduct comprehensive experiments over 13 datasets, and we observe that GRAPHRETRIEVAL is able to reach substantial improvements over existing GNNs. Moreover, our empirical study also illustrates that retrieval enhancement is a promising remedy for alleviating the long-tailed label distribution problem.   
   
 306  Multi-Domain Learning From Insufﬁcient Annotations   
   
  Authors: Rui He ; Shengcai Liu ; Jiahao WU ; Shan He ; Ke Tang   
  ##MORE##Multi-domain learning (MDL) refers to simultaneously constructing a model or a set of models on datasets collected from different domains. Conventional approaches emphasize domain-shared information extraction and domain-private information preservation, following the shared-private framework (SP models), which offers signiﬁcant advantages over single-domain learning. However, the limited availability of annotated data in each domain considerably hinders the effectiveness of conventional supervised MDL approaches in real-world applications. In this paper, we introduce a novel method called multi-domain contrastive learning (MDCL) to alleviate the impact of insufﬁcient annotations by capturing both semantic and structural information from both labeled and unlabeled data. Speciﬁcally, MDCL comprises two modules: inter-domain semantic alignment and intra-domain contrast. The former aims to align annotated instances of the same semantic category from distinct domains within a shared hidden space, while the latter focuses on learning a cluster structure of unlabeled instances in a private hidden space for each domain. MDCL is readily compatible with many SP models, requiring no additional model parameters and allowing for end-to-end training. Experimental results across ﬁve textual and image multi-domain datasets demonstrate that MDCL brings noticeable improvement over various SP models. Furthermore, MDCL can further be employed in multi-domain active learning (MDAL) to achieve a superior initialization, eventually leading to better overall performance.   
   
 313  Improved Analysis of Greedy Algorithm on $k$-Submodular Knapsack   
   
  Authors: Zhongzheng Tang ; Chenhao Wang   
  ##MORE##A $k$-submodular function is a generalization of submodular functions that takes $k$ disjoint subsets as input and outputs a real value. It captures many problems in combinatorial optimization and machine leaning such as influence maximization, sensor placement, feature selection, etc. In this paper, we consider the monotone $k$-submodular maximization problem under a knapsack constraint, and explore the performance guarantee of a greedy-based algorithm: enumerating all size-2 solutions and extending every singleton solution greedily; the best outcome is returned. We provide a novel analysis framework and prove that this algorithm achieves an approximation ratio of at least $0.328$. This is the best-known result of combinatorial algorithms on $k$-submodular knapsack maximization.  
  In addition, within the framework, we can further improve the approximation ratio to a value approaching $\frac13$ with any desirable accuracy, by enumerating sufficiently large base solutions. The results can even be extended to non-monotone $k$-submodular functions.   
   
 321  Adam Accumulation to Reduce Memory Footprints of both Activations and Gradients for Large-scale DNN Training   
   
  Authors: Yijia Zhang ; Yibo Han ; Shijie Cao ; Guohao Dai ; Youshan Miao ; Ting Cao ; Fan Yang ; Ningyi Xu   
  ##MORE##Running out of GPU memory has become a main bottleneck for large-scale DNN training. How to reduce the memory footprint during training has received intensive research attention. We find that previous gradient accumulation reduces activation memory but fails to be compatible with gradient memory reduction due to a contradiction between preserving gradients and releasing gradients. To address this issue, we propose a novel optimizer accumulation method for Adam, named Adam Accumulation (AdamA), which enables reducing both activation and gradient memory. Specifically, AdamA directly integrates gradients into optimizer states and accumulates optimizer states over micro-batches, so that gradients can be released immediately after use. We mathematically and experimentally demonstrate AdamA yields the same convergence properties as Adam. Evaluated on transformer-based models, AdamA achieves up to 23% memory reduction compared to gradient accumulation with less than 2% degradation in training throughput. Notably, AdamA can work together with memory reduction methods for optimizer states to fit 1.26x~3.14x larger models over PyTorch and DeepSpeed baseline on GPUs with different memory capacities.   
   
 323  Gaifman Graphs in Lifted Planning   
   
  Authors: Rostislav Horčík ; Daniel Fišer   
  ##MORE##We introduce the metric induced by Gaifman graphs into lifted planning. We analyze what kind of information this metric carries and how it can be utilized for constructing lifted delete-free relaxation heuristics. In particular, we prove how the action dynamics influence the distances between objects. As a corollary, we derive a lower bound on the length of any plan. Finally, we apply our theoretical findings on the Gaifman graphs to improve the delete-free relaxation heuristics induced by PDDL homomorphisms.   
   
 330  Adversarial Benchmark Evaluation Rectified by Controlling for Difficulty   
   
  Authors: Behzad Mehrbakhsh ; Fernando Martínez-Plumed ; José Hernández-Orallo   
  ##MORE##Adversarial benchmark construction, where harder instances challenge new generations of AI systems, is becoming the norm. While this approach may lead to better machine learning models —on average and for the new benchmark—, it is unclear how these models behave on the original distribution. Two opposing effects are intertwined here. On the one hand, the adversarial benchmark has a higher proportion of difficult instances, with lower expected performance. On the other hand, models trained on the adversarial benchmark may improve on these difficult instances (but may also neglect some easy ones). To disentangle these two effects we can control for difficulty, showing that we can recover the performance on the original distribution, provided the harder instances were obtained from this distribution in the first place. We show this difficulty-aware rectification works in practice, through a series of experiments with several benchmark construction schemas and the use of a populational difficulty metric. As a take-away message, instead of distributional averages we recommend using difficulty- conditioned characteristic curves when evaluating models built with adversarial benchmarks.   
   
 336  Exploring Information Bottleneck for Weakly Supervised Semantic Segmentation   
   
  Authors: Jie Qin ; Yueming Lyu ; Xingang Wang   
  ##MORE##Image-level weakly supervised semantic segmentation (WSSS) has attracted much attention due to the easily acquired class labels. Most existing methods resort to utilizing Class Activation Maps (CAMs) obtained from the classification network to play as the initial pseudo labels. However, the classifiers only focus on the most discriminative regions of the target objects, which is referred to as the information bottleneck from the perspective of the information theory. To alleviate this information bottleneck limitation, we propose an Information Perturbation Module (IPM) to explicitly obtain the information difference maps, which provide the accurate direction and magnitude of the information compression in the classification network. After that, an information bottleneck breakthrough mechanism with three branches is proposed to overcome the information bottleneck in the classification network for segmentation. Additionally, a diversity regularization on the generated two information difference maps is proposed to improve the diversity of the output CAMs. Extensive experiments on PASCAL VOC2012 val and test sets demonstrate that the proposed method can effectively improve the weakly supervised semantic segmentation performance of the advanced approaches.   
   
 340  BridgeHand2Vec Bridge Hand Representation   
   
  Authors: Anna Sztyber-Betley ; Filip Kołodziej ; Jan Betley ; Piotr Duszak   
  ##MORE##Contract bridge is a game characterized by incomplete information, posing an exciting challenge for artificial intelligence methods. This paper proposes the BridgeHand2Vec approach, which leverages a neural network to embed a bridge player's hand (consisting of 13 cards) into a vector space. The resulting representation reflects the strength of the hand in the game and enables interpretable distances to be determined between different hands. This representation is derived by training a neural network to estimate the number of tricks that a pair of players can take. In the remainder of this paper, we analyze the properties of the resulting vector space and provide examples of its application in reinforcement learning, opening bid classification, and as an analysis tool for players. Although this was not our main goal, the neural network used for the vectorization achieves SOTA results on the DDBP2 problem (estimating the number of tricks for two given hands).   
   
 352  PARIS: Planning Algorithms for Reconfiguring Independent Sets   
   
  Authors: Remo Christen ; Salome Eriksson ; Michael Katz ; Christian Muise ; Alice Petrov ; Florian Pommerening ; Jendrik Seipp ; Silvan Sievers ; David Speck   
  ##MORE##Combinatorial reconfiguration studies how one solution of a combinatorial problem can be transformed into another. The transformation can only make small local changes and may not leave the solution space. An important example is the independent set reconfiguration (ISR) problem, where an independent set of a graph (a subset of its vertices without edges between them) has to be transformed into another one by a sequence of modifications that remove a vertex or add another that is not adjacent to any vertex in the set. The 1st Combinatorial Reconfiguration Challenge (CoRe Challenge 2022) was a competition focused on the ISR problem. The PARIS team participated with two solvers that model the ISR problem as a planning problem and employ different planning techniques for solving it. The solvers successfully competed in the challenge and were awarded 4 first, 3 second, and 3 third places across 9 tracks. In this work, we show how to model ISR problems as planning tasks and describe the planning techniques used by these solvers. For a fair comparison to competing ISR approaches, we re-run the entire competition under equal computational conditions. Besides showcasing the success of planning technology, we hope that this work will create a cross-fertilization of the two research fields.   
   
 354  Transparency in Sum-Product Network Decompilation   
   
  Authors:  Giannis Papantonis ; Vaishak Belle   
  ##MORE##Sum-product networks guarantee that conditionals and marginals can be computed efficiently, for a wide range of models, bypassing the hardness of inference. However, this advantage comes at the expense of transparency, since it is unclear how variables interact in sum-product networks. Due to this, a series of decompilation algorithms transform sum-product networks back to Bayesian networks. In this work, we first study the transparency and causal utility of the resulting Bayesian networks. We then propose a novel decompilation algorithm to address the identified limitations.   
   
 355  Reinforcement Learning for Bandits with Continuous Actions and Large Context Spaces   
   
  Authors:  Paul Duckworth ; Bruno Lacerda ; Katherine Vallis ; Nick Hawes   
  ##MORE##We consider the challenging scenario of contextual bandits with continuous actions and large context spaces. This is an increasingly important application area in personalised healthcare where an agent is requested to make dosing decisions based on a patient's single image scan. In this paper, we first adapt a reinforcement learning (RL) algorithm for continuous control to outperform contextual bandit algorithms specifically hand-crafted for continuous action spaces. We empirically demonstrate this on a suite of standard benchmark datasets for vector contexts. Secondly, we demonstrate that our RL agent can generalise problems with continuous actions to large context spaces, providing results that outperform previous methods on image contexts. Thirdly, we introduce a new contextual bandits test domain with multi-dimensional continuous action space and image contexts which existing tree-based methods cannot handle. We provide initial results with our RL agent.   
   
 359  Representative Answer Sets: Collecting Something of Everything   
   
  Authors: Elisa Böhl ; Sarah Alice Gaggl ; Dominik Rusovac   
  ##MORE##Answer set programming (ASP) is a popular problem solving paradigm with applications in planning and configuration. In practice, the number of answer sets can be overwhelmingly high, which naturally causes interest in a concise characterisation of the solution space in terms of representative answer sets. We establish a notion of representativeness that refers to the entropy of specified target atoms within a collection of answer sets. Accordingly, we propose different approaches for collecting such representative answer sets, based on answer set navigation. Finally, we conduct experiments using our prototypical implementation, which reveals promising results.   
   
 369  Multi-Source Domain Adaptation through Dataset Dictionary Learning in Wasserstein Space   
   
  Authors: Eduardo F Montesuma ; Fred Maurice Ngole Mboula ; Antoine Souloumiac   
  ##MORE##Multi-Source Domain Adaptation (MSDA) is an important machine learning problem that aims to mitigate data distribution shifts when transferring knowledge from multiple labeled source domains to an unlabeled target domain. We propose a novel MSDA approach based on a dictionary of empirical distributions. Our dictionary expresses each domain in MSDA as an interpolation in the Wasserstein hull of our dictionary atoms, i.e., through Wasserstein barycenters. We evaluate our method in 3 MSDA benchmarks: (i) Caltech-Office 10, (ii) Refurbished-Office 31, and (iii) CWRU. We improve previous state-of-the-art by 3.15\%, 2.29\%, and 7.71\% in terms of average domain adaptation performance. Furthermore, we show that interpolations in the Wasserstein hull of learned atoms provide data that can generalize to an unlabeled target domain.   
   
 371  On the Structural Complexity of Grounding - Tackling the ASP Grounding Bottleneck via Epistemic Programs and Treewidth   
   
  Authors: Viktor Besin ; Markus Hecher ; Stefan Woltran   
  ##MORE##Answer Set Programming is widely applied research area for knowledge representation and for solving industrial domains. One of the challenges of this formalism focuses on the so-called grounding bottleneck, which addresses the efficient replacement of first-order variables by means of domain values. Recently, there have been several works in this direction, ranging from lazy grounding, hybrid solving, over translational approaches. Inspired by a translation from non-ground normal programs to ground disjunctive programs, we attack the grounding bottleneck from a more general angle. We provide a polynomial reduction for grounding disjunctive programs of bounded domain size by reducing to epistemic logic programs (ELPs). By slightly adapting our reduction, we show new complexity results for non-ground programs that adhere to the measure treewidth. We complement these results by matching lower bounds under the exponential time hypothesis, ruling out significantly better algorithms.   
   
 373  The Sensitivity of Max Regret With Respect to Scaling of the Objectives   
   
  Author: Nic Wilson   
  ##MORE##In a multi-objective optimisation problem, when there is uncertainty regarding the correct user preference model, max regret is a natural measure for how far an alternative is from being necessarily optimal (i.e., optimal with respect to every candidate preference model). It can be used for recommending a relatively safe choice to the user, or used in the generation of an informative query, and in the decision to terminate the user interaction, because an alternative is sufficiently close to being necessarily optimal. We consider a common and simple form of user preference model: a weighted average over the objectives (with unknown weights). However, changing the scale of an objective by a linear factor leads to an essentially different set of preference models, and this changes the max regret values (and potentially their relative ordering), sometimes very considerably. Since the scaling of the objectives is often partly subjective and somewhat arbitrary, it is important to be aware of how sensitive the max regret values are to the choices of scaling of the objectives. We give mathematical results that characterise and enable computation of this variability, along with an asymptotic analysis.   
   
 374  Ensembling Uncertainty Measures to Improve Safety of Black-Box Classifiers   
   
  Authors: Tommaso Zoppi ; Andrea Ceccarelli ; Andrea Bondavalli   
  ##MORE##Machine Learning (ML) algorithms that perform classification may predict the wrong class, experiencing misclassifications. It is well-known that misclassifications may have cascading effects on the encompassing system, possibly resulting in critical failures. This paper proposes SPROUT, a Safety wraPper thROugh ensembles of UncertainTy measures, which suspects misclassifications by computing uncertainty measures on the inputs and outputs of a black-box classifier. If a misclassification is detected, SPROUT blocks the propagation of the output of the classifier to the encompassing system. The resulting impact on safety is that SPROUT transforms erratic outputs (misclassifications) into data omission failures, which can be easily managed at the system level. SPROUT has a broad range of applications as it fits binary and multi-class classification, comprising image and tabular datasets. We experimentally show that SPROUT always identifies a huge fraction of the misclassifications of supervised classifiers, and it is able to detect all misclassifications in specific cases. SPROUT implementation contains pre-trained wrappers, it is publicly available and ready to be deployed with minimal effort.   
   
 379  Evolutionary Explainable Rule Extraction from (Modal) Random Forests   
   
  Authors: Michele Ghiotti ; Federico Manzella ; Giovanni Pagliarini ; Guido Sciavicco ; Eduard Ionel Stan   
  ##MORE##Symbolic learning is the subfield of machine learning concerned with learning predictive models with knowledge represented in logical form, such as decision tree and decision list models. Ensemble learning methods, such as random forests, are usually deployed to improve the performance of decision trees; unfortunately, interpreting tree ensembles is challenging. In order to deal with unstructured (e.g., temporal or spatial) data, moreover, decision trees and random forests have been recently generalized to the use of modal logics, which are harder to interpret than their propositional counterpart. Recently, a methodology for extracting simple rules from propositional random forests, based on a sequence of optimization steps, was proposed. In this work, we generalize this approach along two directions: from propositional to modal logic and from a sequence of optimization steps to a single multi-objective optimization problem. Even if confined to the temporal domain, our experimental results, based on open-source implementations and public data, show that our method is robust, scalable, and able to extract small, accurate, and informative decision lists even for complex classification problems.   
   
 380  Neuro-Symbolic Procedural Semantics for Reasoning-Intensive Visual Dialogue Tasks   
   
  Authors: Lara Verheyen ; Jérôme Botoko Ekila ; Jens Nevens ; Paul Van Eecke ; Katrien Beuls   
  ##MORE##This paper introduces a novel approach to visual dialogue that is based on neuro-symbolic procedural semantics. The approach builds further on earlier work on procedural semantics for visual question answering and expands it on the one hand with neuro-symbolic reasoning operations, and on the other hand with mechanisms that handle the challenges that are inherent to dialogue, in particular the incremental nature of the information that is conveyed. Concretely, we introduce (i) the use of a conversation memory as a data structure that explicitly and incrementally represents the information that is expressed during the subsequent turns of a dialogue, and (ii) the design of a neuro-symbolic procedural semantic representation that is grounded in both visual input and the conversation memory. We validate the methodology using the reasoning-intensive MNIST Dialog and CLEVR-Dialog benchmark challenges and achieve a question-level accuracy of 99.8% and 99.2% respectively. The methodology presented in this paper responds to the growing interest in the field of artificial intelligence in solving tasks that involve both low-level perception and high-level reasoning using a combination of neural and symbolic techniques.   
   
 388  Graph Neural Networks For Mapping Variables Between Programs   
   
  Authors: Pedro Orvalho ; Jelle Piepenbrock ; Mikolas Janota ; Vasco Manquinho   
  ##MORE##Automated program analysis is a pivotal research domain in many areas of Computer Science --- Formal Methods and Artificial Intelligence, in particular. Due to the undecidability of the problem of program equivalence, comparing two programs is highly challenging. Typically, in order to compare two programs, a relation between both programs' sets of variables is required. Thus, mapping variables between two programs is useful for a panoply of tasks such as program equivalence, program analysis, program repair, and clone detection. In this work, we propose using graph neural networks (GNNs) to map the set of variables between two programs based on both programs' abstract syntax trees (ASTs). To demonstrate the strength of variable mappings, we present three use-cases of these mappings on the task of program repair to fix well-studied and recurrent bugs among novice programmers in introductory programming assignments (IPAs). Experimental results on a dataset of 4166 pairs of incorrect/correct programs show that our approach correctly maps 83% of the evaluation dataset. Moreover, our experiments show that the current state-of-the-art on program repair, greatly dependent on the programs' structure, can only repair about 72% of the incorrect programs. In contrast, our approach, which is solely based on variable mappings, can repair around 88.5%.   
   
 389  Normalized Stochastic Heavy Ball with Adaptive Momentum   
   
  Authors: Ziqing Wen ; Xiaoge Deng ; Tao Sun ; Dongsheng Li   
  ##MORE##The heavy ball momentum technique is widely used in accelerating the machine learning training process, which has demonstrated significant practical success in optimization tasks. However, most heavy ball methods require a preset hyperparameter that will result in excessive tuning, and a calibrated fixed hyperparameter may not lead to optimal performance. In this paper, we propose an adaptive criterion for the choice of the normalized momentum-related hyperparameter, motivated by the quadratic optimization training problem, to eliminate the adverse for tuning the hyperparameter and thus allow for a computationally efficient optimizer. We theoretically prove that our proposed adaptive method promises convergence for L-Lipschitz functions. In addition, we verify its practical efficiency on existing extensive machine learning benchmarks for image classification tasks. The numerical results show that besides the speed improvement, our proposed methods enjoy advantages, including more robust to large learning rates and better generalization.   
   
 396  Obstruction Logic: a Strategic Temporal Logic to Reason about Dynamic Game Models   
   
  Authors: Davide Catta ; Jean Leneutre ; Vadim Malvone   
  ##MORE##Games that are played in a dynamic (i.e., changing) game model have been studied in several contexts, such as cybersecurity and planning. In this paper, we introduce a logic for reasoning about a particular class of games with temporal goals played in a dynamic game model. In such games, the actions of a player can modify the game model itself. We show that the model-checking problem for our logic is decidable in polynomial-time. Then, using this logic, we show how to express interesting properties of cybersecurity games defined on attack graphs.   
   
 397  Exploiting epistemic uncertainty at inference time for early-exit power saving   
   
  Authors: Jack Dymond ; Steve R Gunn ; Sebastian Stein   
  ##MORE##Distinguishing epistemic from aleatoric uncertainty is a central idea to out-of-distribution (OOD) detection, by interpreting adversarial and OOD inputs from this perspective, we can collect them into a single unclassifiable group. Rejecting such inputs early in the classification process will reduce resource usage, which is of particular importance in resource-constrained environments. To achieve this, we apply deep k-nearest neighbour (KNN) classifiers to the embedding space of branched neural networks. These are implemented alongside conventional early exiting policies, introducing a novel means of saving power: an early-exit reject. Our technique works out-of-the-box on any branched neural network and can be competitive on OOD benchmarks, achieving an area under receiver operator characteristic (AUROC) of over 0.9 in most datasets, and scores of 0.95+ when identifying perturbed inputs. A mixed input test set is introduced, we show how OOD inputs can be identified up to 50% of the time, and adversarial inputs up to 85% of the time. In a balanced test environment, this equates to power savings of up to 18% in the OOD scenario and 40% in the adversarial scenario. This allows a more stringent in-distribution (ID) classification policy, leading to accuracy improvements of 15% and 20% on the OOD and adversarial tests respectively, when compared to conventional exit policies operating under the same conditions on the same dataset.   
   
 401  Dynamic Workload-Aware Bike Rebalancing for Bike-Sharing Systems   
   
  Author: Yuan Luo   
  ##MORE##Bike Sharing Systems (BSSs) offer a flexible and sustainable transport option that has gained popularity in urban areas globally. However, as users move bikes according to their own needs, imbalanced bike distribution becomes a significant challenge for BSS operators. To address this problem, we propose a Workload Awareness (WA) approach that considers the rebalancing workload of BSS sub-networks and congestion issues when repositioning bikes dynamically. Our algorithm, WA, identifies sub-networks in a BSS and ensures a similar rebalancing load for each sub-network. Our mixed integer nonlinear programming (MINLP) model then finds a repositioning policy for each sub-network, taking into account operator capacity, bike and dock information, and minimizing total losses due to bike shortages and dock congestion. Our experiments on the Ningbo City Bike system demonstrate that our approach outperforms state-of-the-art methods by reducing the loss of the system by up to 60% and significantly reducing the computational time by up to 36%.   
   
 411  Domain Knowledge Injection in Bayesian Search for New Materials   
   
  Authors: Zikai Xie ; Xenophon Evangelopoulos ; Andrew Cooper ; Joseph C R Thacker   
  ##MORE##In this paper we propose DKIBO, a Bayesian optimization (BO) algorithm that accommodates domain knowledge to tune exploration in the search space. Bayesian optimization has recently emerged as a sample-efficient optimizer for many intractable scientific problems. While various existing BO frameworks allow the input of prior beliefs to accelerate the search by narrowing down the space, incorporating such knowledge is not always straightforward and can often introduce bias and lead to poor performance. Here we propose a simple approach to incorporate structural knowledge in the acquisition function by utilizing an additional deterministic surrogate model to enrich the approximation power of the Gaussian process. This is suitably chosen according to structural information of the problem at hand and acts a corrective term towards a better-informed sampling. We empirically demonstrate the practical utility of the proposed method by successfully injecting domain knowledge in a materials design task. We further validate our method's performance on different experimental settings and ablation analyses.   
   
 413  Approximate Model Based Shielding for Safe Reinforcement Learning   
   
  Authors: Alexander W Goodall ; Francesco Belardinelli   
  ##MORE##Reinforcement learning (RL) has shown great potential for solving complex tasks in a variety of domains. However, applying RL to safety-critical systems in the real-world is a problem as many algorithms are sample inefficient and maximising the standard RL objective comes with no guarantees on worst case performance. In this paper we propose approximate model-based shielding (AMBS) a principled look-ahead shielding algorithm for verifying the performance of learned RL policies w.r.t a set of given safety-constraints. Our algorithm differs from other shielding approaches in that it does not require prior knowledge of the safety-relevant dynamics of the system. We provide a strong theoretical justification for AMBS and demonstrate superior performance to other safety-aware approaches on a small set of Atari games with state dependent safety labels.   
   
 419  Highly-Efficient Robinson-Foulds Distance Estimation with Matrix Correction   
   
  Authors: Fangchen Yu ; Rui Bao ; Jianfeng Mao ; Wenye Li   
  ##MORE##Phylogenetic trees are essential in studying evolutionary relationships, and the Robinson-Foulds (RF) distance is a widely used metric to calculate pairwise dissimilarities between phylogenetic trees, with various applications in both biology and computing communities. However, obtaining a high-quality RF distance matrix can become difficult or even intractable when tree information is partially missing. To address this issue, we propose a novel distance correction algorithm for estimating the RF distance matrix of incomplete phylogenetic trees. Our approach skillfully leverages the assumption of Euclidean embedding and corrects an approximate distance matrix to a valid distance metric with a theoretical guarantee to be closer to the unknown ground-truth. Despite its simplicity, the proposed approach exhibits effectiveness, efficiency, and scalability in empirical evaluations, outperforming classical distance correction algorithms and holding potential benefits in downstream applications.   
   
 422  Deep Co-Training for Cross-Modality Medical Image Segmentation   
   
  Authors: Lei Zhu ; Ling Ling Chan ; Teck Khim Ng ; Meihui Zhang ; Beng Chin Ooi   
  ##MORE##Due to the expensive segmentation annotation cost, cross-modality medical image segmentation aims to leverage annotations from a source modality (e.g. MRI) to learn a model for target modality (e.g. CT). In this paper, we present a novel method to tackle cross-modality medical image segmentation as semi-supervised multi-modal learning with image translation, which learns better feature representations and is more robust to source annotation scarcity. For semi-supervised multi-modal learning, we develop a deep co-training framework. We address the challenges of co-training on divergent labeled and unlabeled data distributions with a theoretical analysis on multi-view adaptation and propose decomposed multi-view adaptation, which shows better performance than a naive adaptation method on concatenated multi-view features. We further formulate inter-view regularization to alleviate overfitting in deep networks, which regularizes deep co-training networks to be compatible with the underlying data distribution. We perform extensive experiments to evaluate our framework. Our framework significantly outperforms state-of-the-art domain adaptation methods on three segmentation datasets, including two public datasets on cross-modality cardiac substructure segmentation and abdominal multi-organ segmentation and one large scale private dataset on cross-modality brain tissue segmentation. We will make our code publicly available.   
   
 424  Learning in teams: peer evaluation for fair assessment of individual contributions.   
   
  Author: Fedor Duzhin   
  ##MORE##"We develop a game-theoretical model of a classroom scenario, where $n$ students collaborate on a common task. We assume that there exists an objective truth known to the students but not to the course instructor. Each of the students estimates the contributions of all team members and reports her estimates to the instructor. Thus, a matrix $A$ of peer evaluations arises and the instructor's task is to grade students individually based on peer evaluations. The method of deriving individual grades from the matrix $A$ is supposed to be psychometrically valid and reliable. We argue that mathematically it means that 1) the collective truth-telling is a strict Nash equilibrium and 2) individual grade of student $i$ does not depend on the true contribution of student $j$ for $j\neq i$. Existing methods of peer evaluation commonly used in educational practice fail to satisfy at least one of these properties. We construct a new method of peer evaluation satisfying both desired properties for $n\ge 5$. We share a large dataset (1201 students, 220 teams, 6619 evaluations) of peer evaluations collected in undergraduate courses taught by the author, outline some practical challenges, and show how these challenges can be addressed.   
   
 427  Enhancing Link Prediction with Self-discriminating Augmentation for Structure-aware Contrastive Learning   
   
  Authors: Hao-Wei Yang ; Ming-Yi Chang ; Chih-Ya Shen   
  ##MORE##Link prediction is a crucial research area for both data mining and machine learning. Despite the success of contrastive learning in node classification tasks, applying it directly to link prediction tasks has revealed two major weaknesses, i.e., single positive sample contrasting and random augmentation, resulting in inferior performance. To overcome these issues, we propose a new contrastive learning approach for link prediction, called Structure-aware Contrastive Representation Learning with Self-discriminating Augmentation (SECRET). Our approach includes a novel data augmentation scheme based on the prediction model itself and takes into account both the contrastive objective and the reconstruction loss, which jointly improve the performance of link prediction. In addition to empirical analyses, we further provide theoretical justification to support our design. Our experiments on 11 benchmark datasets demonstrate that SECRET significantly outperforms the other state-of-the-art baselines.   
   
 432  A Novel Differentiable Rank Learning Method Towards Stock Movement Quantile Forecasting   
   
  Authors: Chenyou Fan ; Heng-Yang Lu ; Aimin Huang   
  ##MORE##We focus on Stock Movement Forecasting (SMF) using AI techniques to develop modern automated trading systems. Previous studies have only considered binary up-or-down trends, ignoring the importance of fine-grained categorization of the stock movements to facilitate decision-making. However, the challenges of SMF arise from the randomness of the global market impacting cross-sectional stocks and the volatility of internal dynamics in each time series. To address these challenges, we present a novel end-to-end learning-to-rank framework that incorporates both market-level and stock-level dynamics. Specifically, we aim to identify cross-sectional stocks that exhibit notable movements at every time step and learn to rank steps with the most significant movements in the temporal dimension. We conduct extensive evaluations of our multi-task learning framework utilizing real-world market data, which demonstrate superior performance when compared to state-of-the-art methods, with improvements in the Gain and Sharpe Ratio by 5-15%.   
   
 433  GenCo: A Novel Auxiliary Generator from Contrastive Learning for Enhanced Few-Shot Learning in Remote Sensing   
   
  Authors: Jing Wu ; Naira Hovakimyan ; Jennifer Hobbs   
  ##MORE##Classifying and segmenting patterns from a limited number of examples is a significant challenge in remote sensing and earth observation due to the difficulty in acquiring accurately labeled data in large quantities. Previous studies have shown that meta-learning, which involves episodic training on query and support sets, is a promising approach. However, there has been little attention paid to direct fine-tuning techniques. This paper repurposes contrastive learning as a pretraining method for few-shot learning for classification and semantic segmentation tasks. Specifically, we introduce a generator-based contrastive learning framework (GenCo) that pre-trains backbones and simultaneously explores variants of feature samples. In fine-tuning, the auxiliary generator can be used to enrich limited labeled data samples in feature space. We demonstrate the effectiveness of our method in improving few-shot learning performance on two key remote sensing datasets: Agriculture-Vision and EuroSAT. Empirically, our approach outperforms purely supervised training on the nearly 95,000 images in Agriculture-Vision for both classification and semantic segmentation tasks. Similarly, the proposed few-shot method achieves better results on the land-cover classification task on EuroSAT compared to the results obtained from fully supervised model training on the dataset.   
   
 439  Revisiting Graph Contrastive Learning for Anomaly Detection   
   
  Authors: Zhiyuan Liu ; Chunjie Cao ; Fangjian Tao ; Jingzhang Sun   
  ##MORE##Combining Graph neural networks (GNNs) with contrastive learning for anomaly detection has drawn rising attention recently. Existing graph contrastive anomaly detection (GCAD) methods have primarily focused on improving detection capability through graph augmentation and multi-scale contrast modules. However, the underlying mechanisms of how these modules work have not been fully explored. We dive into the multi-scale and graph augmentation mechanism and observed that multi-scale contrast modules do not enhance the expression, while the multi-GNN modules are the hidden contributors. Previous studies have tended to attribute the benefits brought by multi-GNN to the multi-scale modules. In the paper, we delve into the misconception and propose Multi-GNN and Augmented Graph contrastive framework MAG, which unified the existing GCAD methods in the contrastive self-supervised perspective. We extracted two variants from the MAG framework, L-MAG and M-MAG. The L-MAG is the lightweight instance of the MAG, which outperform the state-of-the-art on Cora and Pubmed with the low computational cost. The variant M-MAG equipped with multi-GNN modules further improve the detection performance. Our study sheds light on the drawback of the existing GCAD methods and demonstrates the potential of multi-GNN and graph augmentation modules. Our code is available at https://anonymous.4open.science/r/MAG-Framework-74D0.   
   
 440  Learning to Collaborate by Grouping: a Consensus-oriented Strategy for Multi-agent Reinforcement Learning   
   
  Authors: Jingqing Ruan ; Xiaotian Hao ; Dong Li   
  ##MORE##Multi-agent systems require effective coordination between groups and individuals to achieve common goals. However, current multi-agent reinforcement learning (MARL) methods primarily focus on improving individual policies and do not adequately address group-level policies, which leads to weak cooperation. To address this issue, we propose a novel {\it Consensus-oriented Strategy} (CoS) that emphasizes group and individual policies simultaneously.  
  Specifically, CoS comprises two main components: (a) the vector quantized group consensus module, which extracts discrete latent embeddings that represent the stable and discriminative group consensus, and (b) the group consensus-oriented strategy, which integrates the group policy using a hypernet and the individual policies using the group consensus, thereby promoting coordination at both the group and individual levels. Through empirical experiments on cooperative navigation tasks with both discrete and continuous spaces, as well as google research football, we demonstrate that CoS outperforms state-of-the-art MARL algorithms and achieves better collaboration, thus providing a promising solution for achieving effective coordination in multi-agent systems.   
   
 442  Offline Decentralized Multi-Agent Reinforcement Learning   
   
  Authors: Jiechuan Jiang ; Zongqing Lu   
  ##MORE##In many real-world multi-agent cooperative tasks, due to high cost and risk, agents cannot continuously interact with the environment and collect experiences during learning, but have to learn from offline datasets. However, the transition dynamics in the dataset of each agent can be much different from the ones induced by the learned policies of other agents in execution, creating large errors in value estimates. Consequently, agents learn uncoordinated low-performing policies. In this paper, we propose a framework for offline decentralized multi-agent reinforcement learning, which exploits \textit{value deviation} and \textit{transition normalization} to deliberately modify the transition probabilities. Value deviation optimistically increases the transition probabilities of high-value next states, and transition normalization normalizes the transition probabilities of next states. They together enable agents to learn high-performing and coordinated policies. Theoretically, we prove the convergence of Q-learning under the altered \textit{non-stationary} transition dynamics. Empirically, we show that the framework can be easily built on many existing offline reinforcement learning algorithms and achieve substantial improvement in a variety of multi-agent tasks.   
   
 443  Label Aggregation with Self-Supervision Enhanced Graph Transformer   
   
  Authors: Jiacheng Liu ; Feilong Tang ; Xiaofeng Hou   
  ##MORE##Aggregating the noisy labels produced by the crowd of workers to generate true labels is a challenging problem in crowdsourcing. The key behind label aggregation is to effectively utilize the hidden information (e.g., characteristics of workers and questions which are often missing) in the labeling process. Existing methods mainly generated aggregation models based on the complicated Bayesian model or some strong assumptions. Recently, deep learning-based methods attempt to automate label aggregation but need various labels. These all make them hard to deploy to real-world applications. In fact, abundant information in the process of crowdsourcing itself can be extremely helpful to aggregate the labels. In this paper, we propose ATHENA (lAbel aggregation witH sElf-supervision eNhanced graph transformer) to aggregate labels by utilizing the self-supervision signals in crowdsourcing. Firstly, we propose a transformer-based graph neural network that can learn from the crowdsourcing topology and features. Then, we use self-supervision signals inherently included in the dataset to help to aggregate the labels. To be specific, we identify the answer-based self-supervision signal that can predict the answer of any user given to different tasks. In our evaluation, we compare the proposed ATHENA with the other 11 representative methods on 10 datasets. Our experimental results demonstrate that ATHENA is highly effective in aggregating labels compared with the existing methods.   
   
 445  Uncertain Relational Hypergraph Attention Networks for Document-level Event Factuality Identification   
   
  Authors: Jiawei Sheng ; Xin Cong ; Jiangxia Cao ; Shu Guo ; Chen Li ; lihong wang ; Tingwen Liu ; Hongbo Xu   
  ##MORE##Document-level event factuality identification (DocEFI) is an important task in event knowledge acquisition, which aims to detect whether an event actually occurs or not from the perspective of the document. Unlike the sentence-level task, a document can have multiple sentences with different event factualities, leading to event factuality conflicts in DocEFI. Existing studies attempt to aggregate local event factuality by exploiting document structures, but they mostly consider textual components in the document separately, degrading complicated correlations therein. To address the above issues, this paper proposes a novel approach, namely UR-HAT, to improve DocEFI with uncertain relational hypergraph attention networks. Particularly, we reframe a document graph as a hypergraph, and establish beneficial n-ary correlations among textual nodes with relational hyperedges, which helps to globally consider local factuality features to resolve event factuality conflicts. To better discern the importance of event factuality features, we further represent textual nodes with uncertain Gaussian distributions, and propose novel uncertain relational hypergraph attention networks to refine textual nodes with the document hypergraph. In addition, we select factuality-related keywords as nodes to enrich event factuality features. Experimental results demonstrate the effectiveness of our proposed method, and outperforms previous methods on two widely used benchmark datasets.   
   
 446  Enforcing Natural Properties of Choice Functions, with Application for Combination   
   
  Author: Nic Wilson   
  ##MORE##One important and natural representation of preferences is a choice function, which returns the preferred options amongst any given subset of the alternatives. There are some very intuitive coherence conditions that might be assumed for an agent's choice function, in particular path independence, and a consistency condition stating that there is always at least one preferred alternative among any non-empty set. However, an elicited choice function may not satisfy path independence, because of the elicitation being incomplete, or because of there being some incoherence in the agent's reported choice function (despite the agent assenting to the general coherence conditions). Furthermore, if we wish to combine the choice functions of more than one agent, simple natural combination operations can lose path independence. This paper develops methods for enforcing path independence and restoring consistency, thus, making the user preferences coherent; this method also leads to approaches for combining two choice functions, in order to suggest the most promising alternatives for a pair of agents.   
   
 448  DCNet: Weakly Supervised Saliency Guided Dual Coding Network for Visual Sentiment Recognition   
   
  Authors: Xinyue Zhang ; Jing Xiang ; Hanxiu Zhang ; Chunwei Wu ; Hailing Wang ; Guitao Cao   
  ##MORE##Visual sentiment recognition is a challenging task with scientific significance in probing vision-processing mechanisms. Recent approaches mainly focused on using overall images or precise annotations to learn emotional representations, yet neglected to capture abstract semantics from regional information, or led to a heavy annotation burden. In this paper, we propose an end-to-end weakly supervised framework, called Dual Coding Network (DCNet), which models a dual coding process for both shallow features and high-level regional information. On the one hand, with the help of the fine-grained module (FG), visual features (e.g. texture features) are utilized to enhance the learning of distinguished representation. On the other hand, the DCNet innovatively leverages saliency information to imitate the neural decoding of perceived visual sentiment contents in human brain activity. Specifically, the saliency information guides the generation of sentiment-specific pseudo affective maps (SAMG), which serve as weak annotations. Then the DCNet couples fine-grained features with pseudo affective maps, and obtains semantic vectors for final sentiment prediction. Extensive experiments show that the proposed DCNet outperforms the state-of-the-art performance on five benchmark datasets.   
   
 453  MonoSKD: General Distillation Framework for Monocular 3D Object Detection via Spearman Correlation Coefficient   
   
  Authors: Sen Wang ; Jin Zheng   
  ##MORE##Monocular 3D object detection is an inherently ill-posed problem, as it is challenging to predict accurate 3D localization from a single image. Existing monocular 3D detection knowledge distillation methods usually project the LiDAR onto the image plane and train the teacher network accordingly. Transferring LiDAR-based model knowledge to RGB-based models is more complex, so a general distillation strategy is needed. To alleviate cross-modal problem, we propose MonoSKD, a novel Knowledge Distillation framework for Monocular 3D detection based on Spearman correlation coefficient, to learn the relative correlation between cross-modal features. Considering the large gap between these features, strict alignment of features may mislead the training, so we propose a looser Spearman loss. Furthermore, by selecting appropriate distillation locations and removing redundant modules, our scheme saves more GPU resources and trains faster than existing methods. Extensive experiments are performed to verify the effectiveness of our framework on the challenging KITTI 3D object detection benchmark. Our method achieves state-of-the-art performance until submission with no additional inference computational cost. Our code will be made public once accepted.   
   
 456  POINE2 : Improving Poincaré Embeddings for Hierarchy-Aware Complex Query Reasoning over Knowledge Graphs   
   
  Authors: Junnan Liu ; Qianren Mao ; Jianxin Li ; Xingcheng Fu ; Zheng Wang   
  ##MORE##Reasoning of complex logical queries on incomplete and massive knowledge graphs (KGs) remains a significant challenge. The prevailing method for this problem is query embedding, which embeds KG units (i.e., entities and relations) and complex queries into low-dimensional space. Recent developments in the field show that embedding queries as geometric shapes is a viable means for modeling entity set and logical relationships between them. Despite being promising, current geometric-based methods face challenges in capturing hierarchical structures of complex queries, which leaves considerable room for improvement. In this paper, we present POINE2, a geometric-based query embedding framework based on hyperbolic geometry to handle complex queries on knowledge graphs. POINE2 maps entities and queries as geometric shapes on a Cartesian product space of Poincaré ball spaces. To capture the hierarchical structures of complex queries, we use the Poincaré radius to represent the different levels of the hierarchy, and we use the aperture of the shape to indicate semantic differences at the same level of the hierarchy. Additionally, POINE2 offers a flexible and expressive definition of logical operations. Experimental results show that POINE2 outperforms existing salient geometric-based embedding methods, and achieves significant improvements over these methods on evaluation datasets.   
   
 463  Capsule Network with Label Dependency Modeling for Multi-Label Emotion Classification   
   
  Authors: Yu-Ping Ruan ; Taihao Li   
  ##MORE##This paper proposes a simple-yet-efficient model, called capsule network with label dependency modeling (CapsLDM), for the task of multi-label emotion classification (MLEC) in text, in which multiple emotion categories can be assigned to the input data instance (e.g., a sentence). Unlike the traditional single-label emotion classification, the modeling of label (i.e., emotion) dependency plays an important role in MLEC, since the co-existing emotions in an utterance are not independent of each other. The capsule network has been successfully applied to many multi-label classification scenarios, however, the modeling of label dependency has not been considered in existing work. In our proposed CapsLDM model, we add similarity regularization terms on both the dynamic routing weights and the instance vectors of emotion capsules by exploiting the co-occurrence information of emotion labels, which resembles the dependency between different emotion categories for a certain input instance. Extensive experiments are conducted on four MLEC benchmark datasets with state-of-the-art models employed as baselines for comparison. The empirical results demonstrate the superiority of our proposed CapsLDM model and confirm the effectiveness of label dependency modeling in CapsLDM for the MLEC task.   
   
 468  Double logistic regression approach to biased positive-unlabeled data   
   
  Authors: Konrad Furmańczyk ; Jan Mielniczuk ; Wojciech Rejchel ; Paweł Teisseyre   
  ##MORE##Positive and unlabeled learning is an important non-standard inference problem which arises naturally in many applications. The significant limitation of almost all existing methods addressing it lies in assuming that the propensity score function is constant and does not depend on features (Selected Completely at Random assumption), which is unrealistic in many practical situations. Avoiding this assumption, we consider parametric approach to the problem of joint estimation of posterior probability and propensity score functions. We show that if both these functions are logistic with different parameters (double logistic model) then the corresponding parameters are identifiable. Motivated by this, we propose two approaches to their estimation: a joint maximum likelihood method and the second approach based on an alternating maximization of two Fisher consistent approximations. Our experimental results show that the proposed methods perform on par or better than the existing methods based on Expectation-Maximization scheme.   
   
 475  Revisiting the Robustness of the Minimum Error Entropy Criterion: A Transfer Learning Case Study   
   
  Authors: Luis Silvestrin ; Shujian Yu ; Mark Hoogendoorn   
  ##MORE##Coping with distributional shifts is an important part of transfer learning methods in order to perform well in real-life tasks. However, most of the existing approaches in this area either focus on an ideal scenario in which the data does not contain noises or employ a complicated training paradigm or model design to deal with distributional shifts. In this paper, we revisit the robustness of the minimum error entropy (MEE) criterion, a widely used objective in statistical signal processing to deal with non-Gaussian noises, and investigate its feasibility and usefulness in real-life transfer learning regression tasks, where distributional shifts are common. Specifically, we put forward a new theoretical result showing the robustness of MEE against covariate shift. We also show that by simply replacing the mean squared error (MSE) loss with the MEE on basic transfer learning algorithms such as fine-tuning and linear probing, we can achieve competitive performance with respect to state-of-the-art transfer learning algorithms. We justify our arguments on both synthetic data and 5 real-world time-series data.   
   
 481  A Bilevel Formalism for the Peer-Reviewing Problem   
   
  Authors: Gennaro Auricchio ; Ruixiao Zhang ; Jie Zhang ; Xiaohao Cai   
  ##MORE##Due to the large number of submissions that more and more conferences experience, finding an automatized way to well distribute the submitted papers among reviewers has become necessary. We model the peer-reviewing matching problem as a {\it bilevel programming (BP)} formulation. Our model consists of a lower-level problem describing the reviewers' perspective and an upper-level problem describing the editors'. Every reviewer is interested in minimizing their overall effort, while the editors are interested in finding an allocation that maximizes the quality of the reviews and follows the reviewers' preferences the most. To the best of our knowledge, the proposed model is the first one that formulates the peer-reviewing matching problem by considering two objective functions, one to describe the reviewers' viewpoint and the other to describe the editors' viewpoint. We demonstrate that both the upper-level and lower-level problems are feasible and that our BP model admits a solution under mild assumptions. After studying the properties of the solutions, we propose a heuristic to solve our model and compare its performance with the relevant state-of-the-art methods. Extensive numerical results show that our approach can find fairer solutions with competitive quality and less effort from the reviewers.   
   
 482  On the Manipulability of Maximum Vertex-Weighted Bipartite $b$-matching Mechanisms   
   
  Authors: Gennaro Auricchio ; Jie Zhang   
  ##MORE##In this paper, we study the Maximum Vertex-weighted $b$-Matching (MVbM) problem on bipartite graphs in a new game-theoretical environment. In contrast to other game-theoretical settings, we consider the case in which the value of the tasks is public and common to every agent so that the private information of every agent consists of edges connecting them to the set of tasks. In this framework, we study three mechanisms. Two of these mechanisms, namely $\MB$ and $\MD$, are optimal but not truthful, while the third one, $\MG$, is truthful but sub-optimal. Albeit these mechanisms are induced by known algorithms, we show $\MB$ and $\MD$ are the best possible mechanisms in terms of Price of Anarchy and Price of Stability, while $\MG$ is the best truthful mechanism in terms of approximated ratio. Furthermore, we characterize the Nash Equilibria of $\MB$ and $\MD$ and retrieve sets of conditions under which $\MB$ acts as a truthful mechanism, which highlights the differences between $\MB$ and $\MD$. Finally, we extend our results to the case in which agents' capacity is part of their private information.   
   
 492  Reducing oversmoothing in graph neural networks by changing the activation function   
   
  Authors: Dimitrios Kelesis ; Dimitrios Vogiatzis ; Georgios Katsimpras ; Dimitris Fotakis ; Paliouras Georgios   
  ##MORE##The performance of Graph Neural Networks (GNNs) deteriorates as the depth of the network increases. That performance drop is mainly attributed to oversmoothing, which leads to similar node representations through repeated graph convolutions. We show that in deep GNNs the activation function plays a crucial role in oversmoothing. We explain theoretically why this is the case and propose a simple modification to the slope of ReLU to reduce oversmoothing. The proposed approach enables deep networks without the need to change the network architecture or to add residual connections. We verify the theoretical results experimentally and further show that deep networks, which do not suffer from oversmoothing, are beneficial in the presence of the ``cold start" problem, i.e. when there is no feature information about unlabeled nodes.   
   
 501  Tuning In to Neural Encoding: Linking Human Brain and Artificial Supervised Representations of Language   
   
  Authors: Jingyuan Sun ; Sien Moens ; Xiaohan Zhang   
  ##MORE##To understand the algorithm that supports the human brain's language representation, previous research has attempted to predict neural responses to linguistic stimuli using embeddings generated by artificial neural networks (ANNs), a process known as neural encoding. However, most of these studies have focused on probing neural representations of Germanic languages, such as English, with unsupervised ANNs. In this paper, we propose to bridge the gap between human brain and supervised ANN representations of the Chinese language. Specifically, we investigate how task tuning influences a pretained Transformer for neural encoding and which tasks lead to the best encoding performances. We generate supervised representations on eight Natural Language Understanding (NLU) tasks using prompt-tuning, a technique that is seldom explored in neural encoding for language. We demonstrate that prompt-tuning yields representations that better predict neural responses to Chinese stimuli than traditional fine-tuning on four tasks. Furthermore, we show that tasks that require a fine-grained processing of concepts and entities lead to representations that are most predictive of brain activation patterns. Additionally, we find that the proportion of tuned parameters highly influences the neural encoding performance of fine-tuned models. Overall, our experimental findings could help us better understand the relationship between supervised artificial and brain language representations.   
   
 508  Using Weighted Matching to Solve 2-Approval/Veto Control and Bribery   
   
  Authors: Zack Fitzsimmons ; Edith Hemaspaandra   
  ##MORE##Determining the complexity of election attack problems is a major research direction in the computational study of voting problems. The paper "Towards completing the puzzle: complexity of control by replacing, adding, and deleting candidates or voters" by Erdélyi et al. (JAAMAS 2021) provides a comprehensive study of the complexity of control problems. The sole open problem is constructive control by replacing voters for 2-Approval. We show that this case is in P, strengthening the recent RP (randomized polynomial-time) upper bound due to Fitzsimmons and Hemaspaandra (IJCAI 2022). We show this by transforming 2-Approval CCRV to weighted matching. We also use this approach to show that priced bribery for 2-Veto elections is in P. With this result, and the accompanying (unsurprising) result that priced bribery for 3-Veto elections is NP-complete, this settles the complexity for k-Approval and k-Veto standard control and bribery cases.   
   
 510  DTBS: Dual-Teacher Bi-directional Self-training for Domain Adaptation in Nighttime Semantic Segmentation   
   
  Authors:  Fanding Huang ; Zihao Yao ; Wenhui Zhou   
  ##MORE##Due to the poor illumination and the difficulty in annotating, nighttime conditions pose a significant challenge for autonomous vehicle perception systems. Unsupervised domain adaptation (UDA) has been widely applied to semantic segmentation on such images to adapt models from normal conditions to target nighttime-condition domains. Self-training (ST) is a paradigm in UDA, where a momentum teacher is utilized for pseudo-label prediction, but a confirmation bias issue exists. Because the one-directional knowledge transfer from a single teacher is insufficient to adapt to a large domain shift. To mitigate this issue, we propose to alleviate domain gap by incrementally considering style influence and illumination change. Therefore, we introduce a one-stage Dual-Teacher Bi-directional Self-training (DTBS) framework for smooth knowledge transfer and feedback. Based on two teacher models, we present a novel pipeline to respectively decouple style and illumination shift. In addition, we propose a new Re-weight EMA to merge the knowledge of style and illumination factors, and provide feedback to the student model. In this way, our method can be embedded in other UDA methods to enhance their performance. For example, the Cityscapes to ACDC night task yielded 53.8 mIoU (%), which corresponds to an improvement of +5% over the previous state-of-the-art.   
   
 512  Enhancing OOD Generalization in Offline Reinforcement Learning with Energy-Based Policy Optimization   
   
  Authors: Hongye Cao ; Shangdong Yang ; Jing Huo ; Xingguo Chen ; Yang Gao   
  ##MORE##Offline Reinforcement Learning (RL) is an important research domain for real-world applications because it can avert expensive and dangerous online exploration. Offline RL is prone to extrapolation errors caused by the distribution shift between offline datasets and states visited by behavior policy. Existing offline RL methods constrain the policy to offline behavior to prevent extrapolation errors. But these methods limit the generalization potential of agents in Out-Of-Distribution (OOD) regions and cannot effectively evaluate OOD generalization behavior. To improve the generalization of the policy in OOD regions while avoiding extrapolation errors, we propose an Energy-Based Policy Optimization (EBPO) method for OOD generalization. An energy function based on the distribution of offline data is proposed for the evaluation of OOD generalization behavior, instead of relying on model discrepancies to constrain the policy. The way of quantifying exploration behavior in terms of energy values can balance the return and risk. To improve the stability of generalization and solve the problem of sparse reward in complex environment, episodic memory is applied to store successful experiences that can improve sample efficiency. Extensive experiments on the D4RL datasets demonstrate that EBPO outperforms the state-of-the-art methods and achieves robust performance on challenging tasks that require OOD generalization.   
   
 520  Rationale-Guided Few-Shot Classification to Detect Abusive Language   
   
  Authors: Punyajoy Saha ; Divyanshu A Sheth ; Kushal Kedia ; Binny Mathew ; Animesh Mukherjee   
  ##MORE##Abusive language is a concerning problem in online social media. Past research on detecting abusive language covers different platforms, languages, demographies, etc. However, models trained using these datasets do not perform well in cross-domain evaluation settings. To overcome this, a common strategy is to use a few samples from the target domain to train models to get better performance in that domain (cross-domain few-shot training). However, this might cause the models to overfit the artefacts of those samples. A compelling solution could be to guide the models toward rationales, i.e., spans of text that justify the text's label. This method has been found to improve model performance in the in-domain setting across various NLP tasks. In this paper, we propose RGFS (Rationale-Guided Few-Shot Classification) for abusive language detection. We first build a multitask learning setup to jointly learn rationales, targets, and labels, and find a significant improvement of 6% macro F1 on the rationale detection task over training solely rationale classifiers. We introduce two rationale-integrated BERT-based architectures (the RGFS models) and evaluate our systems over five different abusive language datasets, finding that in the few-shot classification setting, RGFS-based models outperform baseline models by about 7% in macro F1 scores and perform competitively to models finetuned on other source domains. Furthermore, RGFS-based models outperform LIME/SHAP-based approaches in terms of plausibility and are close in performance in terms of faithfulness.   
   
 521  Comment-aware Multi-modal Heterogeneous Pre-training for Humor Detection in Short-form Videos   
   
  Authors: Yang Liu ; Huanqin Ping ; Dong Zhang ; Qingying Sun ; Shoushan Li ; Guodong Zhou   
  ##MORE##Conventional humor analysis normally focuses on text, text-image pair, and even long video (e.g., monologue) scenarios. However, with the recent rise of short-form video sharing, humor detection in this scenario has not yet gained much exploration. To the best of our knowledge, there are two primary issues associated with short-form video humor detection (SVHD): 1) At present, there are no ready-made humor annotation samples in this scenario, and it takes a lot of manpower and material resources to obtain a large number of annotation samples; 2) Unlike the more typical audio and visual modalities, the titles (as opposed to simultaneous transcription in the lengthy film) and associated interactive comments in short-form videos may convey apparent humorous clues. Therefore, in this paper, we first collect and annotate a video dataset from DouYin (aka. TikTok in the world), namely DY24h, with hierarchical comments. Then, we also design a novel approach with comment-aided multi-modal heterogeneous pre-training (CMHP) to introduce comment modality in SVHD. Extensive experiments and analysis demonstrate that our CMHP beats several existing video-based approaches on DY24h, and that the comments modality further aids a better comprehension of humor. Our dataset, code, and model parameters will be released at Github upon acceptance.   
   
 527  OER: Offline Experience Replay for Continual Offline Reinforcement Learning   
   
  Authors: Sibo Gai ; Donglin Wang ; Li He   
  ##MORE##The capability of continuously learning new skills via a sequence of pre-collected offline datasets is desired for an agent. However, consecutively learning a sequence of offline tasks likely leads to the catastrophic forgetting issue under resource-limited scenarios. In this paper, we formulate a new setting, continual offline reinforcement learning (CORL), where an agent learns a sequence of offline reinforcement learning tasks and pursues good performance on all learned tasks with a small replay buffer without exploring any of the environments of all the sequential tasks. For consistently learning on all sequential tasks, an agent requires acquiring new knowledge and meanwhile preserving old knowledge in an offline manner. To this end, we introduced continual learning algorithms and experimentally found experience replay (ER) to be the most suitable algorithm for the CORL problem. However, we observe that introducing ER into CORL encounters a new distribution shift problem: the mismatch between the experiences in the replay buffer and trajectories from the learned policy. To address such an issue, we propose a new model-based experience selection (MBES) scheme to build the replay buffer, where a transition model is learned to approximate the state distribution. This model is used to bridge the distribution bias between the replay buffer and the learned model by filtering the data from offline data that most closely resembles the learned model for storage. Moreover, in order to enhance the ability on learning new tasks, we retrofit the experience replay method with a new dual behavior cloning (DBC) architecture to avoid the disturbance of behavior-cloning loss on the Q-learning process. In general, we call our algorithm offline experience replay (OER). Extensive experiments demonstrate that our OER method outperforms SOTA baselines in widely-used Mujoco environments.   
   
 528  Data-Free Class-Incremental Learning with Implicit Representation of Prototypes   
   
  Authors: Tianwen Yang ; Leixiong Huang ; RongHua Luo   
  ##MORE##Class-incremental learning (CIL) has attracted much attention in deep learning due to the challenge problem of catastrophic forgetting. Various methods have been proposed for CIL, including exemplar-based class-incremental learning (EBCIL), non-exemplar class-incremental learning (NECIL) and data-free class-incremental learning (DFCIL). Without storing any information (such as examples and prototypes) about the old classes, DFCIL is obviously the most challenging one. To address the problem of lacking information in DFCIL and with the assumption that the learned representations are not linearly separable, we propose a method called IRP. We use the L2-similarity classifier instead of the FC classifier, where each weight vector represents a prototype that implicitly records information about the classes. We use representation-prototype distance minimization (RPDM) to solve the problem of loose representation caused by overfitting. To alleviate the excessive deviation of old prototypes under long-term CIL, we add prototype changing limitation (PCL) and prototype momentum updating (PMU) in incremental stages. In addition, we design a method for resampling around old prototypes (RAOP) to maintain the decision boundary of the old classes. Numerous experiments on three benchmarks have shown that IRP is significantly superior to other DFCIL methods and performs comparably to NECIL and partial EBCIL methods.   
   
 530  Adaptive Self-supervised Continual Learning   
   
  Authors: Lilei Wu ; Zhen Wang ; Jie Liu   
  ##MORE##Continual Learning (CL) studies the problem of developing a robust model that can learn new tasks while retaining previously learned knowledge. However, the current CL methods exclusively focus on data with annotations, disregarding that unlabelled data is the mainstream in real-world applications. To close this research gap, this study concentrates on continual self-supervised learning, which is plagued by challenges of memory over-fitting and class imbalance. Besides, these challenges are exacerbated throughout incremental training. Aimed at addressing these challenges from both loss and data perspectives, We introduce a framework, Adaptive Self-supervised Continual Learning (ASCL). Specifically, we devise an Adaptive Sharpness-Aware Minimization (ASAM) module responsible for identifying flatter local minima in the loss landscape with a smaller memory over-fitting risk. Additionally, we design an Adaptive Memory Enhancement (AME) module responsible for rebalancing self-supervised loss with new and old tasks from a data perspective. Finally, the adaptive mechanisms in AME and ASAM modules dynamically adjust the loss landscape sharpness and memory enhancement strength with the feedback of intermediate training results. The results of our extensive experiments demonstrate the state-of-the-art performance of our methods in continual self-supervised learning scenarios across multiple datasets.   
   
 531  Evolving Dictionary Representation for Few-shot Class-incremental Learning   
   
  Authors: Xuejun Han ; Yuhong Guo   
  ##MORE##New objects are continuously emerging in the dynamically changing world and a real-world artificial intelligence system should be capable of continual and effectual adaptation to new emerging classes without forgetting old ones. In view of this, in this paper we tackle a challenging and practical continual learning scenario named few-shot class-incremental learning (FSCIL), in which labeled data are given for classes in a base session but very limited labeled instances are available for new incremental classes. To address this problem, we propose a novel and succinct approach by introducing deep dictionary learning which is a hybrid learning architecture that combines dictionary learning and visual representation learning to provide a better space for characterizing different classes. We simultaneously optimize the dictionary and the feature extraction backbone in the base session, while only finetune the dictionary in the incremental session for adaptation to novel classes, which can alleviate the forgetting on base classes compared to finetuning the entire model. To further facilitate future adaptation, we also incorporate multiple pseudo classes into the base session training so that certain space projected by dictionary can be reserved for future new concepts. Moreover, we adopt a novel optimization process by implicitly incorporating the dictionary reconstruction loss into the learning process without adding extra loss terms. The extensive experimental results on CIFAR100, miniImageNet and CUB200 validate the effectiveness of our approach compared to other SOTA methods.   
   
 532  Contrastive Learning with Diverse Samples   
   
  Authors: Lilei Wu ; Jie Liu   
  ##MORE##Unsupervised visual representation learning has gained much attention from the computer vision community because of the recent contrastive learning achievements. Current work mainly adopts instance discrimination as the pretext task, which treats every single instance as a different class (negative), and uses a collection of data augmentation techniques to generate more examples (positive) for each class. The idea is straightforward and efficient but will generally cause similar instances to be classified into different classes. Such problem has been defined as ``class collision" in some previous works and is shown to hurt the representation ability. Motivated by this observation, we present a solution to address this issue by filtering similar negative examples from each mini-batch. Concretely, we model the problem as a Determinantal Point Process (DPP) so that similar instances can be filtered stochastically, and diverse samples are expected to be sampled for the contrastive training. Besides, we further introduce a priority term for each instance, which indicates the hardness of its positives, so that instances with more hard positives are more likely to be sampled for contributing to the optimization. Our sampling can be efficiently implemented in a feed-forward manner and further accelerated by our encouraged complement DPP. Extensive experimental results demonstrate our priority over the standard setup of contrastive learning.   
   
 543  RHALE: Robust and Heterogeneity-aware Accumulated Local Effects   
   
  Authors: Vasilis Gkolemis ; Theodore Dalamagas ; Eirini Ntoutsi ; Christos Diou   
  ##MORE##Accumulated Local Effects (ALE) is a widely-used explainability method for isolating the average effect of a feature on the output, because it handles cases with correlated features well. However, it has two limitations. First, it does not quantify the deviation of instance-level (local) effects from the average (global) effect, known as heterogeneity. Second, for estimating the average effect, it partitions the feature domain into user-defined, fixed-sized bins, where different bin sizes may lead to inconsistent ALE estimations. To address these limitations, we propose Robust and Heterogeneity-aware ALE (RHALE). RHALE quantifies the heterogeneity by considering the standard deviation of the local effects and automatically determines an optimal variable-size bin-splitting. In this paper, we prove that to achieve an unbiased approximation of the standard deviation of local effects within each bin, bin splitting must follow a set of sufficient conditions. Based on these conditions, we propose an algorithm that automatically determines the optimal partitioning, balancing the estimation bias and variance. Through evaluations on synthetic and real datasets, we demonstrate the superiority of RHALE compared to other methods, including the advantages of automatic bin splitting, especially in cases with correlated features.   
   
 549  Uncertainty-Encoded Multi-Modal Fusion for Robust Object Detection in Autonomous Driving   
   
  Authors: Yang Lou ; Qun Song ; Qian Xu ; Rui Tan ; Jianping Wang   
  ##MORE##Multi-modal fusion has shown initial promising results for object detection of autonomous driving perception. However, many existing fusion schemes do not consider the quality of each fusion input and may suffer from adverse conditions on one or more sensors. While predictive uncertainty has been applied to characterize single-modal object detection performance at run time, incorporating uncertainties into the multi-modal fusion still lacks effective solutions due primarily to the uncertainty's cross-modal incomparability and distinct sensitivities to various adverse conditions. To fill this gap, this paper proposes Uncertainty-Encoded Mixture-of-Experts (UMoE) that explicitly incorporates single-modal uncertainties into LiDAR-camera fusion. UMoE uses individual expert network to process each sensor's detection result together with encoded uncertainty. Then, the expert networks' outputs are analyzed by a gating network to determine the fusion weights. The proposed UMoE module can be integrated into any proposal fusion pipeline. Evaluation shows that UMoE achieves a maximum of 10.67%, 3.17%, and 5.40% performance gain compared with the state-of-the-art proposal-level multi-modal object detectors under extreme weather, adversarial, and blinding attack scenarios.   
   
 550  Deep Unsupervised Hashing with Hyperbolic Multi-structure Learning   
   
  Authors: Chuang Zhao ; Hefei Ling ; Yuxuan Shi ; Jiazhong Chen ; Qiang Cao   
  ##MORE##Unsupervised hashing aims to learn a compact binary hash code to represent complex image content without label information. Existing deep unsupervised hashing methods typically first employ extracted image embeddings to construct semantic similarity structures and then map the images into compact hash codes while preserving the semantic similarity structure. However, the limited representation power of embeddings in Euclidean space and the inadequate exploration of the similarity structure in current methods often result in poorly discriminative hash codes. In this paper, we propose a novel method called Hyperbolic Multi-Structure Hashing (HMSH) to address these issues. Specifically, to increase the representation power of embeddings, we propose to map embeddings from Euclidean space to hyperbolic space and use the similarity structure constructed in hyperbolic space to guide hash learning. Meanwhile, to fully explore the structural information, we investigate four kinds of data structures, including local neighborhood structure, global clustering structure, inter/intra-class variation and variation under perturbation. Different data structures can complement each other, which is conducive to hash learning. Extensive experimental results on three benchmark image datasets show that HMSH significantly outperforms state-of-the-art unsupervised hashing methods for image retrieval.   
   
 569  Attention Based Models for Cell Type Classification on Single-Cell RNA-Seq Data   
   
  Authors: Tianxu Wang ; Yue Fan ; Xiuli Ma   
  ##MORE##Cell type classification serves as one of the most fundamental analyses in bioinformatics. It helps recognizing various cells in cancer microenvironment, discovering new cell types and facilitating other downstream tasks. Single-cell RNA-sequencing (scRNA-seq) technology can profile the whole transcriptome of each cell, thus enabling cell type classification. However, high-dimensional scRNA-seq data pose serious challenges on cell type classification. Existing methods either classify the cells with reliance on the prior knowledge or by using neural networks whose massive parameters are hard to interpret. In this paper, we propose two novel attention-based models for cell type classification on single-cell RNA-seq data. The first model, Cell Feature Attention Network (CFAN), captures the features of a cell and performs attention model on them. To further improve interpretation, the second model, Cell-Gene Representation Attention Network (CGRAN), directly concretizes tokens as cells and genes and uses the cell representation renewed by self-attention over the cell and the genes to predict cell type. Both models show excellent performance in cell type classification; additionally, the key genes with high attention weights in CGRAN indicate and identify the marker genes of the cell types, thus proving the model’s biological interpretation.   
   
 578  A Generalization of the Shortest Path Problem to Graphs with Multiple Edge-Cost Estimates   
   
  Authors: Eyal Weiss ; Gal A Kaminka ; Ariel Felner   
  ##MORE##The shortest path problem in graphs is a cornerstone of AI theory and applications. Existing algorithms generally ignore edge weight computation time. We present a generalized framework for weighted directed graphs, where edge weight can be computed (estimated) multiple times, at increasing accuracy and run-time expense. This raises several generalized variants of the shortest path problem. We introduce the problem of finding a path with the tightest lower-bound on the optimal cost. We then present two complete algorithms for the generalized problem, and empirically demonstrate their efficacy.   
   
 579  Decentralized Local Updates with Dual-Slow Estimation and Momentum-based Variance-Reduction for Non-Convex Optimization   
   
  Authors: Kangyang Luo ; Kunkun Zhang ; Shengbo Zhang ; Xiang Li ; Ming Gao   
  ##MORE##Decentralized learning (DL) has recently employed local updates to reduce the communication cost for general non-convex optimization problems. Specifically, local updates require each node to perform multiple update steps on the parameters of the local model before communicating with others. However, most existing methods could be highly sensitive to data heterogeneity (i.e., non-iid data distribution) and adversely affected by the stochastic gradient noise. In this paper, we propose DSE-MVR to address these problems. Specifically, DSE-MVR introduces a dual-slow estimation strategy that utilizes the gradient tracking technique to estimate the global accumulated update direction for handling the data heterogeneity problem; also for stochastic noise, the method uses the mini-batch momentum-based variance-reduction technique. We theoretically prove that DSE-MVR can achieve optimal convergence results for general non-convex optimization in both iid and non-iid data distribution settings. In particular, the leading terms in the convergence rates derived by DSE-MVR are independent of the stochastic noise for large-batches or large partial average intervals (i.e., the number of local update steps). Further, we put forward DSE-SGD and theoretically justify the importance of the dual-slow estimation strategy in the data heterogeneity setting. Finally, we conduct extensive experiments to show the superiority of DSE-MVR against other state-of-the-art approaches.   
   
 582  Improving Adversarial Transferability with Ghost Samples   
   
  Authors: Yi Zhao ; Ningping Mou ; Yunjie Ge ; Qian Wang   
  ##MORE##Adversarial transferability is an intriguing phenomenon—adversarial examples crafted for one model can fool other models. By exploiting this property, various transfer-based methods are proposed to conduct adversarial attacks without knowledge of target models, posing significant threats to practical black-box applications. However, these methods either have limited transferability or require high resource consumption. To bridge the gap, we investigate adversarial transferability from the optimization perspective and propose the ghost sample attack (GSA), which improves adversarial transferability by alleviating the overfitting issue of adversarial examples on the surrogate model. Based on the insight that a slight shift of the adversarial example is similar to a minor change in the decision boundary, we aggregate gradients of perturbed adversarial copies (named ghost samples) to efficiently achieve a similar effect to calculating gradients of multiple ensemble surrogate models. Extensive experiments demonstrate that GSA achieves state-of-the-art adversarial transferability with restricted resources. On average, GSA improves the attack success rate by 4.8% on normally trained models compared to state-of-the-art attacks. Additionally, GSA reduces the computational cost by 62% compared with TAIG-R. When combined with other methods, GSA further improves the transferability to 96.9% on normally trained models and 82.7% on robust models.   
   
 587  Reasoning Guided by a Manual: Context-Aware Image Captioning with Novel Objects   
   
  Authors: Peiyao Hua ; Haifeng Sun ; Jiachang Hao ; Cong Liu ; Jingyu Wang ; Qi Qi ; Jianxin Liao   
  ##MORE##Novel object captioning task aims at describing objects that are absent from training data. Due to the scarcity of novel objects, it's challenging to find a way to utilize external data to improve model's reasoning ability. While previously designed methods all follow a deep learning approach, we boost novel object captioning by incorporating knowledge reasoning with a traditional deep learning framework. We design a manual from dictionaries that provides our model with sufficient and accurate external information on novel objects. We propose a Manual-guided Context-aware Novel Object Captioning model (MC-NOC) that utilizes image and caption context to reason novel object captions. It contains a Manual-Guided Novel Object Reasoning module to reason novel objects based on other objects of the given image. And a Caption Reconstruction module to incorporate novel objects into generated captions according to caption context. We validate MC-NOC with state-of-the-art performance on the challenging Held-out COCO and Nocaps dataset, leading their leaderboard. In particular, we improved the CIDER metric by 6.4 points on the held-out coco dataset. Comprehensive experiments demonstrate our model's reasoning capability and the quality of generated captions.   
   
 588  The Leximin Approach for a Sequence of Collective Decisions   
   
  Authors:  Ido Kahana ; Noam Hazon  
  ##MORE##In many situations, several agents need to make a sequence of decisions. For example, a group of workers that needs to decide where their weekly meeting should take place. In such situations, a decision-making mechanism must consider fairness notions. In this paper, we analyze the fairness of three known mechanisms: round-robin, maximum Nash welfare, and leximin. We consider both offline and online settings, and concentrate on the fairness notion of proportionality and its relaxations. Specifically, in the offline setting, we show that the three mechanisms fail to find a proportional or approximate-proportional outcome, even if such an outcome exists. We thus introduce a new fairness property that captures this requirement, and show that a variant of the leximin mechanism satisfies the new fairness property. In the online setting, we show that it is impossible to guarantee proportionality or its relaxations. We thus consider a natural restriction on the agents' preferences, and show that the leximin mechanism guarantees the best possible additive approximation to proportionality and satisfies all the relaxations of proportionality.   
   
 589  Evaluating Explanation Methods for Vision-and-Language Navigation   
   
  Authors: Guanqi Chen ; Lei Yang ; Guanhua Chen ; Jia Pan   
  ##MORE##The ability to navigate robots with natural language instructions in an unknown environment is a crucial step for achieving embodied artificial intelligence (AI). With the improving performance of deep neural models proposed in the field of vision-and-language navigation (VLN), it is equally interesting to know what information the models utilize for their decision-making in the navigation tasks. To understand the inner workings of deep neural models, various explanation methods have been developed for promoting explainable AI (XAI). But they are mostly applied to classification models and little work has been done in explaining the deep neural models for VLN tasks. In this paper, we address these problems by building quantitative benchmarks to evaluate explanation methods for VLN models in terms of faithfulness. We propose a new erasure-based evaluation pipeline to measure the step-wise textual explanation in the sequential decision-making setting. We evaluate several explanation methods for two representative VLN models on two popular VLN datasets and reveal valuable findings through our experiments.   
   
 592  Joint Multiple Intent Detection and Slot Filling with Supervised Contrastive Learning and Self-Distillation   
   
  Authors: Nguyen Anh Tu ; Hoang Thi Thu Uyen ; Tu Minh Phuong ; Ngo Xuan Bach   
  ##MORE##Multiple intent detection and slot filling are two fundamental and crucial tasks in spoken language understanding. Motivated by the fact that the two tasks are closely related, joint models that can detect intents and extract slots simultaneously are preferred to individual models that perform each task independently. The accuracy of a joint model depends heavily on the ability of the model to transfer information between the two tasks so that the result of one task can correct the result of the other. In addition, since a joint model has multiple outputs, how to train the model effectively is also challenging. In this paper, we present a method for multiple intent detection and slot filling by addressing these challenges. First, we propose a bidirectional joint model that explicitly employs intent information to recognize slots and slot features to detect intents. Second, we introduce a novel method for training the proposed joint model using supervised contrastive learning and self-distillation. Experimental results on two benchmark datasets MixATIS and MixSNIPS show that our method outperforms state-of-the-art models in both tasks. The results also demonstrate the contributions of both bidirectional design and the training method to the accuracy improvement.   
   
 596  Group Activity Recognition in Basketball Tracking Data - Neural Embeddings in Team Sports (NETS)   
   
  Authors: Sandro Hauri ; Slobodan Vucetic   
  ##MORE##Like many team sports, basketball involves two groups of players who engage in collaborative and adversarial activities to win a game. Players and teams are executing various complex strategies to gain an advantage over their opponents. Defining, identifying, and analyzing different types of activities is an important task in sports analytics, as it can lead to better strategies and decisions by the players and coaching staff. The objective of this paper is to automatically recognize basketball group activities from tracking data representing locations of players and the ball during a game. We propose a novel deep learning approach for group activity recognition (GAR) in team sports called NETS. To efficiently model the player relations in team sports, we combined a Transformer-based architecture with LSTM embedding, and a team-wise pooling layer to recognize the group activity. Training such a neural network generally requires a large amount of annotated data, which incurs high labeling cost. To address scarcity of manual labels, we generate weak-labels and pretrain the neural network on a self-supervised trajectory prediction task. We used a large tracking data set from 632 NBA games to evaluate our approach. The results show that NETS is capable of learning group activities with high accuracy, and that self- and weak-supervised training in NETS have a positive impact on GAR accuracy.   
   
 610  Generalizing similarity in noisy setups: the DIBS phenomenon   
   
  Authors: Nayara Fonseca ; Veronica Guidetti   
  ##MORE##This work uncovers an interplay among data density, noise, and the generalization ability in similarity learning. We consider Siamese Neural Networks (SNNs), which are the basic form of contrastive learning, and explore two types of noise that can impact SNNs, Pair Label Noise (PLN) and Single Label Noise (SLN). Our investigation reveals that SNNs exhibit double descent behavior regardless of the training setup and that it is further exacerbated by noise. We demonstrate that the density of data pairs is crucial for generalization. When SNNs are trained on sparse datasets with the same amount of PLN or SLN, they exhibit comparable generalization properties. However, when using dense datasets, PLN cases generalize worse than SLN ones in the overparametrized region, leading to a phenomenon we call Density-Induced Break of Similarity (DIBS). In this regime, PLN similarity violation becomes macroscopical, corrupting the dataset to the point where complete interpolation cannot be achieved, regardless of the number of model parameters. Our analysis also delves into the correspondence between online optimization and offline generalization in similarity learning. The results show that this equivalence fails in the presence of label noise in all the scenarios considered.   
   
 612  SCRAPS: Speech Contrastive Representations of Acoustic and Phonetic Spaces   
   
  Authors: Ivan Valles Perez ; Grzegorz Beringer ; Piotr Bilinski ; Gary Cook ; Roberto Barra-Chicote   
  ##MORE##Numerous examples in the literature proved that deep learning models have the ability to work well with multimodal data. Recently, CLIP has enabled deep learning systems to learn shared latent spaces between images and text descriptions, with outstanding zero- or few-shot results in downstream tasks. In this paper we explore the same idea proposed by CLIP but applied to the speech domain, where the phonetic and acoustic spaces usually coexist. We train a CLIP-based model with the aim to learn shared representations of phonetic and acoustic spaces. The results show that the proposed model is sensible to phonetic changes, with a 91% of score drops when replacing 20% of the phonemes at random, while providing substantial robustness against different kinds of noise, with a 10% performance drop when mixing the audio with 75% of Gaussian noise. We also provide empirical evidence showing that the resulting embeddings are useful for a variety of downstream applications, such as intelligibility evaluation and the ability to leverage rich pre-trained phonetic embeddings in speech generation task. Finally, we discuss potential applications with interesting implications for the speech generation and recognition fields.   
   
 615  SENA: Similarity-based Error-checking of Neural Activations   
   
  Authors: Raul Sena Ferreira ; Joris Guerin ; Jérémie Guiochet ; Hélène Waeselynck    
 ##MORE##In this work, we propose SENA, a runtime monitor focused on detecting unreliable predictions from machine learning (ML) classifiers. The main idea is that instead of trying to detect when an image is out-of-distribution (OOD), which will not always result in a wrong output, we focus on detecting if the prediction from the ML model is not reliable, which will most of the time result in a wrong output, independently of whether it is in-distribution (ID) or OOD. The verification is done by checking the similarity between the neural activations of an incoming input and a set of representative neural activations recorded during training. SENA uses information from both true positive and false negative examples collected during training to verify if a prediction is reliable or not. Our approach achieves results comparable to state-of-the-art solutions without requiring any prior OOD information and without hyperparameter tuning. Besides, the code is publicly available for easy reproducibility at https://github.com/raulsenaferreira/SENA.   
   
 618  Cache-Efficient Dynamic Programming MDP Solver   
   
  Authors: Jaël Champagne Gareau ; Guillaume Gosset ; Éric Beaudry ; Vladimir Makarenkov   
  ##MORE##Automated planning research often focuses on developing new algorithms to improve the computational performance of planners, but effective implementation can also play a significant role. Hardware features such as memory hierarchy can yield substantial running time improvements when optimized. In this paper, we investigate and compare the cache performance of various MDP planners, while proposing two state-reordering techniques for the Topological Value Iteration (TVI) algorithm. Our first technique organizes states in memory so that those belonging to the same Strongly Connected Component (SCC) are contiguous, while our second technique optimizes state value propagation by reordering states within each SCC. We analyze existing planning algorithms with respect to their cache efficiency and describe domain characteristics which can provide an advantage to each of them. Empirical results show that, in many instances, our new algorithms, called eTVI and eiTVI, run several times faster than traditional VI, TVI, LRTDP and ILAO* techniques.   
   
 622  Complexity of Control by Adding or Deleting Edges in Graph-Restricted Weighted Voting Games   
   
  Authors: Joanna Kaczmarek ; Joerg Rothe ; Nimrod Talmon   
  ##MORE##Graph-restricted weighted voting games generalize weighted voting games, a well-studied class of succinct simple games, by embedding them into a communication structure: a graph whose vertices are the players some of which are connected by edges. In such games, only connected coalitions are taken into consideration for calculating the players’ power indices. We focus on the probabilistic Penrose–Banzhaf index [5] and the Shapley–Shubik index [16] and study the computational complexity of manipulating these games by an external agent who can add edges to or delete edges from the graph. For the problems modeling such scenarios, we raise some of the lower bounds obtained by Kaczmarek and Rothe [9] from NP- or DP-hardness to PP-hardness, where PP is probabilistic polynomial time. We also solve one of their open problems by showing that it is a coNP-hard problem to maintain the Shapley–Shubik index of a given player in a graph-restricted weighted voting game when edges are deleted.   
   
 624  Declarative Encoding of Fairness in Logic Tensor Networks   
   
  Authors: Greta Greco ; Matteo Palmonari ; Federico Alberici ; Andrea Claudio Cosentini   
  ##MORE##Algorithms are vulnerable to biases that might render their decisions unfair toward particular groups of individuals. Fairness comes with a range of facets that strongly depend on the application domain and that need to be enforced accordingly. However, most mitigation models embed fairness constraints as a fundamental component of the loss function thus requiring code-level adjustments to adapt to specific contexts and domains. Rather than relying on a procedural approach, our model leverages declarative structured knowledge to encode fairness requirements in the form of logic rules. We propose a neuro-symbolic integration approach based on Logic Tensor Networks that combines data-driven network-based learning with high-level logical knowledge, allowing to perform classification tasks while reducing bias. Experimental evidence show that performances are as good as state-of-the-art and provides a flexible framework to account for non-discrimination often at a modest cost in terms of accuracy.   
   
 626  Revisiting the Efficiency-Accuracy Tradeoff in Adapting Transformer Models via Adversarial Fine-Tuning   
   
  Authors: Minjia Zhang ; Niranjan Uma Naresh ; Yuxiong He   
  ##MORE##Adversarial fine-tuning (i.e., training on adversarial perturbed inputs) has demonstrated promising results in improving the accuracy of natural language understanding tasks. However, the improved accuracy does not come for free but is accompanied by a significantly prolonged training time, limiting their applicability to larger and more complex models. This work revisits the efficiency-accuracy trade-off in adversarial fine-tuning by systematically analyzing if adversarial fine-tuning methods, in conjunction with several efficiency optimizations, are suitable for adapting pre-trained Transformer models for natural language understanding tasks. Our results show that multiple design choices are crucial in determining the efficiency-accuracy trade-off, and we introduce a method, ScaLA, that achieves better accuracy-vs-speed trade-off than prior methods. We show in experiments that our proposed method attains up to 14.7$\times$ adaptation speedups on BERT, RoBERTa, and T5, while achieving comparable accuracy to existing methods.   
   
 630  A Bayesian Optimization Framework for Finding Local Optima in Expensive Multimodal Functions   
   
  Authors: Yongsheng Mei ; Tian Lan ; Mahdi Imani ; Suresh Subramaniam   
  ##MORE##Bayesian optimization (BO) is a popular global optimization scheme for sample-efficient optimization in domains with expensive function evaluations. The existing BO techniques are capable of finding a single global optimum solution. However, finding a set of global and local optimum solutions is crucial in a wide range of real-world problems, as implementing some of the optimal solutions might not be feasible due to various practical restrictions (e.g., resource limitation, physical constraints, etc.). In such domains, if multiple solutions are known, the implementation can be quickly switched to another solution, and the best possible system performance can still be obtained. This paper develops a multimodal BO framework to effectively find local/global solutions for expensive-to-evaluate multimodal objective functions. We consider the standard BO setting with Gaussian process regression representing the objective function. We analytically derive the joint distribution of the objective function and its first-order derivatives. This joint distribution is used in the body of the BO acquisition functions to search for local optima during the optimization process. We introduce variants of the well-known BO acquisition functions to the multimodal setting and demonstrate the performance of the proposed framework in locating a set of local optimum solutions using multiple optimization problems.   
   
 641  Tab-Attention: Self-Attention-based Stacked Generalization for Imbalanced Credit Default Prediction   
   
  Authors: Yandan Tan ; Hongbin Zhu ; Jie Wu ; Hongfeng Chai   
  ##MORE##Accurately credit default prediction faces challenges due to imbalanced data and low correlation between features and labels. Existing default prediction studies on the basis of gradient boosting decision trees (GBDT), deep learning techniques, and feature selection strategies can have varying degrees of success depending on the specific task. Motivated by this, we propose Tab-Attention, a novel self-attention-based stacked generalization method for credit default prediction. This approach ensembles the potential proprietary knowledge contributions from multi-view feature spaces, to cope with low feature correlation and imbalance. We organize multi-view feature spaces according to the latent linear or nonlinear strengths between features and labels. Meanwhile, the f1 score assists the model in imbalance training to find the optimal state for identifying minority default samples. Our Tab-Attention achieves superior Recall_1 and f1_1 of default intention recognition than existing GBDT-based models and advanced deep learning by about 32.92% and 16.05% on average, respectively, while maintaining outstanding overall performance and prediction performance for non-default samples. The proposed method could ensemble essential knowledge through the self-attention mechanism, which is of great significance for a more robust future prediction system.   
   
 657  Rethinking Temporal Information in Session-Based Recommendation: A Position-agnostic Approach   
   
  Authors: Xianghong Xu ; Kai Ouyang ; Jiaxin Zou ; Hai-Tao Zheng ; Wenqiang Liu ; Dongxiao Huang ; Bei Wu   
  ##MORE##Session-based Recommendation (SBR) aims to predict the next item for a session, which consists of several clicked items in a transaction. Most SBR approaches follow an underlying assumption that all sequential information should be strictly utilized. Thus, they model temporal information for items using implicit, explicit, or ensemble methods. In fact, users may recall previously clicked items but might not remember the exact order in which they were clicked. Therefore, focusing on representing item temporal information in various ways could make learning session intents challenging. In this paper, we rethink the necessity of temporal information for items in SBR. We propose Aggregating the Contextual intents of the session with Attentive networks, namely ACARec. Specifically, we avoid explicitly modeling positional embeddings and learn contextual intents through aggregation methods (convolutions or poolings). We also demonstrate that even an entirely position-agnostic aggregation approach can yield promising results. Extensive experiments on real-world datasets validate our arguments. We hope our study can provide insights into SBR and inspire future research in the community.   
   
 659  Enhancing Downstream Text Generation with Cooperative Training   
   
  Authors: Tong Wu ; Hao Wang ; zhongshen zeng ; Wei Wang ; Hai-Tao Zheng ; Jiaxing Zhang   
  ##MORE##Recently, there has been a surge in the use of generated data to enhance the performance of downstream models, largely due to the advancements in pre-trained language models. However, most prevailing methods trained generative and discriminative models in isolation, which left them unable to adapt to changes in each other. These approaches lead to generative models that are prone to deviating from the true data distribution and providing limited benefits to discriminative models. While some works have proposed jointly training generative and discriminative language models, their methods remain challenging due to the non-differentiable nature of discrete data. To overcome these issues, we introduce a self-consistent learning framework in text domain that involves training a discriminator and generator cooperatively in a closed-loop manner until a scoring consensus is reached. By learning directly from selected samples, our framework are able to avoid training instabilities such as mode collapse and non-convergence. Extensive experiments on four downstream benchmarks, including AFQMC, CHIP-STS, QQP, and MRPC, demonstrate the efficacy of the proposed framework.   
   
 661  On the Price of Fairness in Discrete Cake Cutting Problems   
   
  Authors: Ankang Sun ; Bo Li   
  ##MORE##Discrete cake cutting is a fundamental model in fair resource allocation where the indivisible resources are located on a path. It is well motivated that, in reality, each agent is interested in receiving a contiguous block of items. An important question therein is to understand the economic efficiency loss by restricting the allocations to be fair, which is quantified as price of fairness (PoF). Informally, PoF is the worst-case ratio between the unconstrained optimal welfare and the optimal welfare achieved by fair allocations. Suksompong [Discret. Appl. Math., 2019] has studied this problem, where fairness is measured by envy-freeness (EF) and proportionality (PROP). An EF or a PROP allocation, however, may not exist in discrete cake cutting settings. Therefore, in this work, we revisit this problem and focus on the fairness criteria with guaranteed existence. We study both utilitarian and egalitarian welfare, and for most settings, we give (almost) tight bounds of PoF, where the upper bounds are proved by designing polynomial-time algorithms.   
   
 663  R-STAR: Robust Self-Taught Task-Wise Reweighting for Rehearsal-Based Class Incremental Learning   
   
  Authors: Yutian Luo ; Yizhao Gao ; Haoran Wu ; Ruitao Ma ; Zhiwu Lu   
  ##MORE##Class incremental learning (CIL) requires a model to learn the knowledge of new classes without overwriting that of old classes. The main challenge thus lies in catastrophic forgetting. Among all advances in addressing this challenge, rehearsal-based methods are the most widely-used due to their convenience and effectiveness. However, the (classification) scores bias between the old and new classes, known as the main cause of catastrophic forgetting for rehearsal-based methods, is still not fully addressed. Although some recent strategies are proposed to reduce the scores bias, they either take extra training time or sacrifice too much performance on the current task. In this paper, we propose a novel Robust Self-Taught Task-Wise Reweighting (R-STAR) method, which can act as a flexible and key component for improving existing rehearsal-based methods. Concretely, on top of the standard training process, it measures the forgetting degree of the model over the augmented buffer (for robust evaluation) on each task. Further, following the self-taught paradigm, it directly activates the task-wise forgetting degree into a reweighting ratio for scores bias reduction during the inference stage. Extensive experiments show that our R-STAR can improve most rehearsal-based methods with remarkable margins, but with (almost) no extra training cost or excessive performance sacrifice on the new task. Moreover, it also shows its advantages over existing scores bias correction strategies.   
   
 672  MFC: A Multishot Approach to Federated Data Clustering   
   
  Authors: Jaglike Makkar ; Bhumika . ; Shweta Jain ; Shivam Gupta   
  ##MORE##The work explores the federated data clustering problem. The primary goal is to perform $k$-means clustering of data distributed over multiple clients while preserving privacy during an exchange with the central server. Existing solutions to unsupervised federated data clustering are either computationally challenging or effective only in heterogeneous regimes, i.e., when the number of clusters per client ($k_z$) is less than the total number of clusters ($k$) (specifically, $k_z \le \sqrt{k}$). Moreover, existing one-shot approaches assume that the information about $k_z$ is available for each client. In this paper, we propose two multi-shot approaches which we call MFC and MFC-H, that perform well on both heterogeneous and non-heterogeneous regimes, i.e., are independent of the underlying client data distribution. Both MFC and MFC-H stand out as they do not rely on prior knowledge about $k_z$. We theoretically bound the closeness of the local centers obtained by MFC and MFC-H to that of the optimal global centers and prove that under some well-separability assumption, the centers will be close enough. MFC-H improvises MFC by only sharing a single cluster center from each client, thus ensuring more privacy. Our theoretical analysis shows that when at least O($k^2\log{k}$) clients are involved, centers obtained by MFC will closely approximate optimal global centers. Experiments on synthetic and real-world datasets validate the proposed approaches' efficacy showcasing lower objective costs in non-heterogeneous while having comparable performance in heterogeneous regimes. In addition, as a byproduct MFC exhibits higher device-level fairness in terms of the individual objective cost compared to existing state-of-the-art algorithms. The code is available as Appendix.   
   
 674  Optimizing Chance Constrained Submodular Problems with Variable Uncertainties   
   
  Authors: Xiankun Yan ; Anh V Do ; Feng Shi ; Xiaoyu Qin ; Frank Neumann   
  ##MORE##Chance constraints are frequently used to limit the probability of constraint violations in real-world optimization problems where the constraints involve stochastic components. We study chance-constrained submodular optimization problems, which capture a wide range of optimization problems with stochastic constraints. Previous studies considered submodular problems with stochastic knapsack constraints in the case where uncertainties are the same for each item that can be selected. However, uncertainty levels are usually variable with respect to the different stochastic components in real-world scenarios, and rigorous analysis for this setting is missing in the context of submodular optimization. This paper provides the first such analysis for the case, where the weights of items have the same expectation but different dispersion. We present greedy algorithms that can obtain a high-quality solution, i.e., a constant approximation ratio to the given optimal solution from the deterministic setting. In our experiments, we demonstrate that the algorithms perform effectively on several chance-constrained instances of the maximum coverage problem and the influence maximization problem.   
   
 676  Minimum Target Sets in Non-Progressive Threshold Models: When Timing Matters   
   
  Authors: Hossein Soltani ; Ahad N. Zehmakan ; Ataabak B. Hushmandi   
  ##MORE##Let $G$ be a graph, which represents a social network, and suppose each node $v$ has a threshold value $\tau(v)$. Consider an initial configuration, where each node is either positive or negative. In each discrete time step, a node $v$ becomes/remains positive if at least $\tau(v)$ of its neighbors are positive and negative otherwise. A node set $\mathcal{S}$ is a Target Set (TS) whenever the following holds: if $\mathcal{S}$ is fully positive initially, all nodes in the graph become positive eventually. We focus on a generalization of TS, called Timed TS (TTS), where it is permitted to assign a positive state to a node at any step of the process, rather than just at the beginning. We provide graph structures for which the minimum TTS is significantly smaller than the minimum TS, indicating that timing is an essential aspect of successful target selection strategies. Furthermore, we prove tight bounds on the minimum size of a TTS in terms of the number of nodes and maximum degree when the thresholds are assigned based on the majority rule. We show that the problem of determining the minimum size of a TTS is NP-hard and provide an Integer Linear Programming formulation and a greedy algorithm. We evaluate the performance of our algorithm by conducting experiments on various synthetic and real-world networks. We also present a linear-time exact algorithm for trees.   
   
 680  Multi-unit Auction over a Social Network   
   
  Authors: Yuan Fang ; Mengxiao Zhang ; Jiamou Liu ; Bakh Khoussainov ; Mingyu Xiao   
  ##MORE##Diffusion auction is an emerging business model where a seller aims to incentivise buyers in a social network to diffuse the auction information thereby attracting potential buyers. We focus on designing mechanisms for multi-unit diffusion auctions. Despite numerous attempts at this problem, existing mechanisms either fail to be incentive compatible (IC) or achieve only an unsatisfactory level of social welfare (SW). Here, we propose a novel graph exploration technique to realise multi-item diffusion auction. This technique ensures that potential competition among buyers stay ``localised'' so as to facilitate truthful bidding. Using this technique, we design multi-unit diffusion auction mechanisms MUDAN and MUDAN-$m$. Both mechanisms satisfy, among other properties, IC and $1/m$-weak efficiency. We also show that they achieve optimal social welfare for the class of rewardless diffusion auctions. While MUDAN addresses the bottleneck case when each buyer demands only a single item, MUDAN-$m$ handles the more general, multi-demand setting. We further demonstrate that these mechanisms achieve near-optimal social welfare through experiments.   
   
 682  Diverse, Top-k, and Top-Quality Planning Over Simulators   
   
  Authors: Lyndon Benke ; Tim Miller ; Michael Papasimeon ; Nir Lipovetzky   
  ##MORE##Diverse, top-k and top-quality planning are concerned with the generation of sets of solutions to sequential decision problems. Previously this area has been the domain of classical planners that require a symbolic model of the problem instance. This paper proposes a novel alternative approach that instead uses Monte Carlo Tree Search (MCTS), enabling application to problems for which only a black-box simulation model is available. We present a procedure for extracting bounded sets of plans from preconstructed search trees in best-first order, along with a metric for evaluating the relative quality of paths through a search tree. We demonstrate the effectiveness of this approach in a path-planning domain with hidden information, and suggest adaptations to the basic MCTS algorithm to increase the diversity of generated plans.   
   
 683  Siamese Representation Learning for Unsupervised Relation Extraction   
   
  Authors: Guangxin Zhang ; Shu Chen   
  ##MORE##Unsupervised relation extraction (URE) aims at discovering underlying relations between named entity pairs from open-domain plain text without prior information on relational distribution. Existing URE models utilizing contrastive learning, which attract positive samples and repulse negative samples to promote better separation, have got decent effect. However, fine-grained relational semantic in relationship makes spurious negative samples, damaging the inherent hierarchical structure and hindering performances. To tackle this problem, we propose Siamese Representation Learning for Unsupervised Relation Extraction – a novel framework to simply leverage positive pairs to representation learning, possessing the capability to effectively optimize relation representation of instances and retain hierarchical information in relational feature space. Experimental results show that our model significantly advances the state-of-the-art results on two benchmark datasets and detailed analyses demonstrate the effectiveness and robustness of our proposed model on unsupervised relation extraction.   
   
 684  FedCoop: Cooperative Federated Learning for Noisy Labels   
   
  Authors: Ka Hou Tam ; Li Li ; Yan Zhao ; Cheng-Zhong Xu   
  ##MORE##Federated Learning coordinates multiple clients to collaboratively train a shared model while preserving data privacy. However, the training data with noisy labels located on the participating clients severely harm the model performance. In this paper, we propose FedCoop, a cooperative Federated Learning framework for noisy labels. FedCoop mainly contains three components and conducts robust training in two phases, data selection and model training. In the data selection phase, in order to mitigate the confirmation bias caused by a single client, the Loss Transformer intelligently estimates the probability of each sample's label to be clean through cooperating with the helper clients, which have high data trustability and similarity. After that, the Feature Comparator evaluates the label quality for each sample in terms of latent feature space in order to further improve the robustness of noisy label detection. In the model training phase, the Feature Matcher trains the model on both the noisy and clean data in a semi-supervised manner to fully utilize the training data and exploits the feature of global class to increase the consistency of pseudo labeling across the clients. The experimental results show FedCoop outperforms the baselines on various datasets with different noise settings. It effectively improves the model accuracy up to 62% and 27% on average compared with the baselines.   
   
 696  Turn on the Right Track: Weakly Supervised Video Moment Retrieval with Self-Improving Query Reconstruction   
   
  Authors: Yiming Zhong ; Haifeng Sun ; Jiachang Hao ; Jing Wang ; Cheng Zhou ; Qi Qi ; Jingyu Wang ; Jianxin Liao   
  ##MORE##Existing weakly-supervised temporal sentence grounding methods typically regard query reconstruction as the pretext task in place of the absent temporal supervision. However, their approaches suffer from two flaws, i.e. insignificant reconstruction and discrepancy in alignment. Insignificant reconstruction indicates the randomly masked words may not be discriminative enough to distinguish the target event from unrelated events in the video. Discrepancy in alignment indicates the incorrect partial alignment built by query reconstruction task. The flaws undermine the reliability of current reconstruction-based methods. To this end, we propose a novel Self-improving Query ReconstrucTion (SQRT) framework for weakly-supervised temporal sentence grounding. To deal with insignificant reconstruction, we devise a key words mining strategy to determine the important words for language grounding. To attain better moment-query alignment, we introduce inter-sample contrast to tackle the partial alignment built by query reconstruction. The self-improving framework leverages query reconstruction for language grounding and alleviates the discrepancy in alignment, thus turning on the right track. Experiments on two popular datasets show that SQRT achieves state-of-the-art performance on Charades-STA and comparable performance to the state-of-the-art on ActivityNet Captions.   
   
 706  XFed: Improving Explainability in Federated Learning by Intersection Over Union Ratio Extended Client Selection   
   
  Authors: Juan Zhao ; YuanKai Zhang ; Ruixuan Li ; Yuhua Li ; haozhao wang ; xiaoquan yi ; Zhiying Deng   
  ##MORE##Federated Learning (FL) allows massive clients to collaboratively train a global model without revealing their private data. Because of the participants' not independently and identically distributed (non-IID) statistical characteristics, it will cause divergence among the client’s Deep Neural Network model weights and require more communication rounds before training can be converged. Moreover, models trained from non-IID data may also extract biased features and the rationale behind the model is still not fully analyzed and exploited. In this paper, we propose eXplainable-Fed (XFed) which is a novel client selection mechanism that takes both accuracy and explainability into account. Specifically, XFed selects participants in each round based on a small test set's accuracy via cross-entropy loss and interpretability via XAI-accuracy. XAI-accuracy is calculated by Intersection over Union Ratio between the heat map and the truth mask to evaluate the overall rationale of accuracy. The results of our experiments show that our method has comparable accuracy to state-of-the-art methods specially designed for accuracy while increasing explainability by 14\%-35\% in terms of rationality.   
   
 712  Abductive Explanations of Classifiers under Constraints: Complexity and Properties   
   
  Authors: Martin C Cooper ; Leila Amgoud   
  ##MORE##Abductive explanations (AXp's) are widely used for understanding decisions of classifiers. Existing definitions are suitable when features are independent. However, we show that ignoring constraints when they exist between features may lead to an explosion in the number of redundant or superfluous AXp's. We propose three new types of explanations that take into account constraints and that can be generated from the whole feature space or from a sample (such as a dataset). They are based on a key notion of coverage of an explanation, the set of instances it explains. We show that coverage is powerful enough to discard redundant and superfluous AXp's. For each type, we analyse the complexity of finding an explanation and investigate its formal properties. The final result is a catalogue of different forms of AXp's with different complexities and different formal guarantees.   
   
 713  Leveraging Error Patterns to Correct Prediction Intervals   
   
  Author: Thomas Bonnier   
  ##MORE##When assessing uncertainty in model predictions, it is key to consider potential error patterns in some regions of the feature space. In this paper, we build on quantile regression to propose a new method to produce prediction intervals in regression tasks. It estimates a conditional quantile function of the residual variable given a specific representation. The method then adjusts the regressor's prediction with an upper and lower conditional quantile prediction in order to produce an adaptive prediction interval for any new input. Further, we suggest an additional layer based on conformal prediction in order to provide coverage guarantees. Lastly, as distribution-free conditional coverage is impossible to achieve, we suggest a tree-based representation which displays patterns of undercoverage. This diagnostic tool aims to reveal which regions of the feature space are significantly less likely to have trustworthy prediction intervals. In order to prove their efficacy, our techniques are tested over various use cases and compared against four main baselines. Our methods empirically achieve the expected coverage and tend to produce shorter intervals.   
   
 720  Letting Go of Self-Domain Awareness: Multi-Source Domain-Adversarial Generalization via Dynamic Domain-Weighted Contrastive Transfer Learning   
   
  Authors: Yuan Ma ; Yiqiang Chen ; Han Yu ; Yang Gu ; Shijie Wen ; Shuai Guo   
  ##MORE##Domain generalization (DG), which aims to learn a model that can generalize to an unseen target domain, has recently attracted increasing research interest. A major approach is to learn domain invariant representations to avoid greedily capturing all the correlations found in source domains caused by empirical risk minimization. Nevertheless, overly emphasizing learning of domain invariant representations might lead to learning overly-compressed domain invariant representations, causing confusion of different classes in a same domain. To address this limitation, we introduce a novel dynamic domain-weighted contrastive loss, which maximizes the subdomain differences between different classes especially those belonging to the same domain, while minimizing the average distance between the points of the convex hull of the aligned source domains. We propose Multi-source domain-adversarial generalization via dynamic domain-weighted Contrastive transfer learning (MsCtrl), a novel domain-adversarial generalization framework, which optimizes the distribution alignment of source and potential target subdomains in an adversarial manner under the ``control'' of the aforementioned contrastive loss. Extensive experiments based on real-world datasets demonstrate significant advantages of MsCtrl over existing state-of-the-art methods.   
   
 723  Degradation-Resistant Offline Optimization via Accumulative Risk Control   
   
  Authors: Huakang Lu ; Hong Qian ; Yupeng Wu ; Ziqi Liu ; Ya-Lin Zhang ; Aimin Zhou ; Yang Yu   
  ##MORE##Offline optimization aims to elaborately construct an output solution that optimizes a black-box function with only access to the offline dataset. It is in great demand when active evaluation is expensive or even infeasible. A typical manner of constructing the output solution is to train a surrogate model of the black-box function based on the offline dataset and optimize the solution guided by the surrogate model. However, this manner often encounters a fundamental challenge that the surrogate model could erroneously estimate out-of-distribution (OOD) solutions. Therefore, the optimizer would be misled to produce inferior output solutions for online applications, i.e., degradation of performance. To this end, this paper formalizes the risk of degradation for OOD solutions and proposes an accumulative risk controlled offline optimization (ARCOO) method based on the energy model. Specifically, ARCOO learns a surrogate model in conjunction with an energy model. The energy model explicitly characterizes the risk of degradation by learning on high-risk solutions and low-risk ones contrastively. In the optimization procedure, the behavior of the optimizer in each step is controlled by a risk suppression factor calculated via the energy model, which leads to the controllable accumulative risk. Theoretically, we justify the efficacy of energy for accumulative risk control. Extensive experiments on offline optimization tasks such as drug discovery, material invention, and robotic design show that ARCOO surpasses state-of-the-art methods in both degradation-resistance and optimality of the output solution.   
   
 725  Satisfaction-Maximizing Optimal Stopping   
   
  Authors: Stav Koren ; David Sarne   
  ##MORE##In recent years, autonomous agents have been increasingly handling decision tasks on behalf of their human users. One such type of task with much potential to be carried out by an assisting autonomous agent is optimal stopping (e.g., in costly search). In such case, when it is the agent's responsibility to decide when to terminate search, the challenge of maximizing user satisfaction with the process becomes acute. This paper provides evidence for the loose correlation between agent performance, profit-wise, and user satisfaction in this application domain, ruling out the use of the profit-maximizing strategy. As an alternative, it proposes a strategy relying on behavioral features. An extensive comparative evaluation of the proposed strategy, as well as the profit-maximizing strategy and the highest ranked strategy elicited through crowdsourcing reveals that the average satisfaction with the first is substantially greater than when experiencing with the others. The analysis of the results also reveals several important insights related to people's ability to estimate the effectiveness of search strategies, satisfaction-wise, or propose such strategies themselves, contributing to the study of how human beings deal with optimal stopping problems in practice.   
   
 727  FBC: Fusing Bi-Encoder and Cross-Encoder for Long-form Text Matching   
   
  Authors: Jianbo Liao ; Mingyi Jia ; Junwen Duan ; Jianxin Wang   
  ##MORE##Semantic text matching has a wide range of applications in natural language processing. Recently proposed models that have achieved excellent results on short text matching tasks are not well suited to long-form text matching problems due to input length limitations and increased noise. On the other hand, long-form texts contain a large amount of information at different granularities after encoding, which cannot be fully interacted and utilized by existing methods. To address above issues, we propose a novel long-form text-matching framework which \textbf{f}uses \textbf{B}i-Encoder and \textbf{C}ross-Encoder (\textbf{FBC}). Specially, it first employs an entity-driven key sentence extraction method to obtain the crucial content of the text and filter out noise. Subsequently, it integrates Bi-Encoder and Cross-Encoder to better capture semantic features and matching signals. Extensive experiments on several publicly available datasets demonstrate the effectiveness of our approach, compared with strong competitors. Furthermore, our model exhibits greater stability and accuracy in determining the matching relationship between documents describing the same event, which outperforms previously established approaches.   
   
 730  Decoding Realistic Image from Brain Activity with Contrastive Self-supervision and Latent Diffusion   
   
  Authors: Jingyuan Sun ; Mingxiao Li ; Sien Moens   
  ##MORE##Reconstructing visual stimuli from human brain activities provides a promising opportunity to advance our understanding of the brain's visual system and its connection with computer vision models. Although deep generative models have been employed for this task, the challenge of generating high-quality images with accurate semantics persists due to the intricate underlying representations of brain signals and the limited availability of parallel data. In this paper, we propose a two-phase framework named Contrast and Diffuse (CnD) to decode realistic images from functional magnetic resonance imaging (fMRI) recordings. In the first phase, we acquire representations of fMRI data through self-supervised contrastive learning. In the second phase, the encoded fMRI representations condition the diffusion model to reconstruct visual stimulus through our proposed concept-aware conditioning method. Experimental results show that CnD reconstructs highly plausible images on challenging benchmarks. We also provide a quantitative interpretation of the connection between the latent diffusion model (LDM) components and the human brain's visual system. In summary, we present an effective approach for reconstructing visual stimuli based on human brain activity and offer a novel framework to understand the relationship between the diffusion model and the human brain visual system.   
   
 737  CAFIN: Centrality Aware Fairness inducing IN-processing for Unsupervised Representation Learning on Graphs   
   
  Authors: Arvindh Arun ; Aakash Aanegola ; Amul Agrawal ; Ramasuri Narayanam ; Ponnurangam Kumaraguru   
  ##MORE##Unsupervised Representation Learning on graphs is gaining traction due to the increasing abundance of unlabelled network data and the compactness, richness, and usefulness of the representations generated. In this context, the need to consider fairness and bias constraints while generating the representations has been well-motivated and studied to some extent in prior works. One major limitation of most of the prior works in this setting is that they do not aim to address the bias generated due to connectivity patterns in the graphs, such as varied node centrality, which leads to a disproportionate performance across nodes. In our work, we aim to address this issue of mitigating bias due to inherent graph structure in an unsupervised setting. To this end, we propose CAFIN, a centrality-aware fairness-inducing framework that leverages the structural information of graphs to tune the representations generated by existing frameworks. We deploy it on GraphSAGE (a popular framework in this domain) and showcase its efficacy on two downstream tasks - Node Classification and Link Prediction. Empirically, CAFIN consistently reduces the performance disparity across popular datasets (varying from 18 to 80% reduction in performance disparity) from various domains while incurring only a minimal cost of fairness.   
   
 747  A Flexible Debiasing Framework for Fair Heterogeneous Information Network Embedding   
   
  Authors: Meng Cao ; Mingcai Chen ; Jianqing Song ; Chenxuan Fang ; Chongjun Wang   
  ##MORE##Heterogeneous Information Networks (HINs) are prevalent in real-world systems. Recent advances in network embedding provide an effective way of encoding HINs into low-dimensional vectors. However, there is a growing concern that existing HIN embedding algorithms may suffer from the problem of generating biased representations, resulting in discrimination against certain demographic groups. In this paper, we propose a flexible debiasing framework for fair HIN embedding to address this issue. Specifically, we first formalize measurements and the definition of fairness in HIN embedding. Then, we propose a debiasing framework named FairHGNN, including a novel meta-path sampling method that focuses on mitigating the bias in random walks, and a fairness constraint with Wasserstein distance to alleviate the algorithmic bias in Graph Neural Networks (GNNs). Experimental results on real-world datasets validate the efficacy of FairHGNN in promoting fairness and maintaining comparable embedding utility.   
   
 759  Identical and Fraternal Twins: Fine-Grained Semantic Contrastive Learning of Sentence Representations   
   
  Authors: Qingfa Xiao ; Shuangyin Li ; Lei Chen   
  ##MORE##The enhancement of unsupervised learning of sentence representations has been significantly achieved by the utility of contrastive learning. This approach clusters the augmented positive instance with the anchor instance to create a desired embedding space. However, relying solely on the contrastive objective can result in sub-optimal outcomes due to its inability to differentiate subtle semantic variations between positive pairs. Specifically, common data augmentation techniques frequently introduce semantic distortion, leading to a semantic margin between the positive pair. While the InfoNCE loss function overlooks the semantic margin and prioritizes similarity maximization between positive pairs during training, leading to the insensitive semantic comprehension ability of the trained model. In this paper, we introduce a novel Identical and Fraternal Twins of Contrastive Learning (named IFTCL) framework, capable of simultaneously adapting to various positive pairs generated by different augmentation techniques. We propose a \textit{Twins Loss} to preserve the innate margin during training and promote the potential of data enhancement in order to overcome the sub-optimal issue. We also present proof-of-concept experiments combined with the contrastive objective to prove the validity of the proposed Twins Loss. Furthermore, we propose a hippocampus queue mechanism to restore and reuse the negative instances without additional calculation, which further enhances the efficiency and performance of the IFCL. We verify the IFCL framework on nine semantic textual similarity tasks with both English and Chinese datasets, and the experimental results show that IFCL outperforms state-of-the-art methods.   
   
 760  Online Privacy Preservation for Camera-Incremental Person Re-Identification   
   
  Authors: Sheng Wu ; Wenhang Ge ; Jiong Wu ; Jingke Meng ; Huang Zhang   
  ##MORE##Task-incremental person re-identification aims to train a model with consecutively available cross-camera annotated data in the current task and a small number of saved data in preceding tasks, which may lead to individual privacy disclosure due to data storage and annotation. In this work, we investigate a more realistic online privacy preservation scenario for camera-incremental person re-identification, where data storage in preceding cameras is not allowed, while data in the current camera are intra-camera annotated online by a pedestrian tracking algorithm without cross-camera annotation. In this setup, the missing data of previous cameras not only results in catastrophic forgetting as task-incremental learning, but also makes the cross-camera association infeasible, which further leads to the incapability of person matching across cameras due to the camera-wise domain gap. To solve these problems, we propose an Online Privacy Preservation (OPP) framework based on the generated exemplars of previous cameras by DeepInversion, where generated exemplars used as supplements to alleviate forgetting and enable cross-camera association to be feasible for camera-wise domain shift mitigation, meanwhile further improving the cross-camera matching capability. Specifically, we propose to mine underlying cross-camera positive pairs between samples of the current camera and exemplars of previous cameras by similarity cues. Furthermore, we introduce a mixup learning strategy to handle the domain gap with mixed samples and labels. Finally, intra-camera incremental learning and cross-camera incremental learning are aggregated into the OPP framework. Extensive experiments on Re-ID benchmarks validate the superiority of the OPP framework as compared with state-of-the-art methods.   
   
 762  QCCDM: A Q-Augmented Causal Cognitive Diagnosis Model for Student Learning   
   
  Authors: Shuo Liu ; Hong Qian ; Mingjia Li ; Aimin Zhou   
  ##MORE##Cognitive diagnosis is vital for intelligent education to determine students' knowledge mastery levels from their response logs. The Q-matrix, representing the relationships between exercises and knowledge attributes, improves the interpretability of cognitive diagnosis model. However, completing the Q-matrix poses an expensive and challenging task due to the fine-grained division of knowledge attributes. Moreover, a manually sparse Q-matrix can also compromise the accuracy and interpretability of deducing students' mastery levels, especially for infrequently observed or unseen knowledge attributes. To address this issue, this paper proposes a Q-augmented Causal Cognitive Diagnosis Model (QCCDM) for student learning. Specifically, QCCDM incorporates the structure causal model (SCM) to capture the causality between students' mastery levels on different attributes, which enables to infer their proficiency on rarely observed knowledge attributes with better accuracy and interpretability. Notably, with SCM, one can guide students on how to realize their self-improvement through intervention. Furthermore, we propose to augment the Q-matrix in QCCDM, which uses the manual Q-matrix as a prior to deduce the relationships between exercises and explicit as well as latent knowledge attributes, resulting in a complete and comprehensive assessment of students' abilities. We assess the efficacy of Q-augmentation across the widely-used Q-based cognitive diagnosis models and conduct the ablation study. The extensive experimental results on real-world datasets show that QCCDM outperforms the compared methods in terms of both accuracy and interpretability.   
   
 770  A Local Non-additive Framework for Explaining Black-box Predictive Models   
   
  Authors: Majid Mohammadi ; Ilaria Tiddi ; Annette Ten Teije   
  ##MORE##Understanding the reasons behind the prediction of a predictive model is crucial for many applications. To that end, different explainable models are developed to provide explanations by finding the contribution of features to the prediction of a black-box model. However, the interactions among features are ignored, and the attribution of contributions is typically limited to individual features. In this paper, we develop a Choquet integral-based explainable method, or ChoquEx, that is able to account for the interactions among features and compute also the contributions of any subset of features. Accordingly, we develop an algorithm based on support vector regression that estimates the contributions of all subsets of features in an efficient manner. The feature importance and the interaction index are then calculated by using game-theoretic notions, such as Shapley values and interaction index. Experiments on several real scenarios show the superiority of the proposed model.   
   
 771  Fair Latent Deep Generative Models (FLDGMs) for Syntax-agnostic and Fair Synthetic Data Generation   
   
  Authors: Resmi Ramachandranpillai ; Md Fahim Sikder ; Fredrik Heintz   
  ##MORE##Deep Generative Models (DGMs) for generating synthetic data with properties such as quality, diversity, fidelity, and privacy is an important research topic. Fairness is one particular aspect that has not received the attention it deserves. One difficulty is training DGMs with an in-process fairness objective, which can disturb the global convergence characteristics. To address this, we propose Fair Latent Deep Generative Models (FLDGMs) as enablers for more flexible and stable training of fair DGMs, by first learning a syntax-agnostic, model-agnostic fair latent representation (low dimensional) of the data. This separates the fairness optimization and data generation processes thereby boosting stability and optimization performance. Moreover, data generation in the low dimensional space enhances the accessibility of models by reducing the computational resources used for training and inference. We conduct extensive experiments on image and tabular domains using Generative Adversarial Networks (GANs) and Diffusion Models (DMs) and compare them to the state-of-the-art in terms of fairness and utility. Our proposed FLDGMs achieve superior performance in generating high-quality, high-fidelity, and high-diversity fair synthetic data compared to the state-of-the-art fair generative models.   
   
 774  Antecedent Predictions Are More Important Than You Think: An Effective Method for Tree-Based Code Generation   
   
  Authors: Yihong Dong ; Ge Li ; Xue Jiang ; Zhi Jin   
  ##MORE##Code generation focuses on automatically converting natural language (NL) utterances into code snippets. Sequence-to-tree (Seq2Tree) approaches are proposed for code generation with the aim of ensuring grammatical correctness of the generated code. These approaches generate subsequent Abstract Syntax Tree (AST) nodes based on the preceding predictions of AST nodes. However, existing Seq2Tree approaches tend to treat both antecedent predictions and subsequent predictions equally, which poses a challenge for models to produce accurate subsequent predictions if the antecedent predictions are incorrect under the constraints of the AST. Given this challenge, it is necessary to pay more attention to antecedent predictions compared to subsequent predictions. To this end, this paper proposes a novel and effective method, named Antecedent Prioritized (AP) Loss, which prioritizes antecedent predictions by leveraging the position information of the generated AST nodes. We design an AST-to-Vector (AST2Vec) method that maps AST node positions to two-dimensional vectors, thereby modeling the position information of AST nodes. To evaluate the effectiveness of our proposed loss, we implement and train an Antecedent Prioritized Tree-based code generation model called APT. Experiments on four benchmark datasets demonstrate that with better antecedent predictions and accompanying subsequent predictions, APT achieves significant improvements, indicating the superiority and generality of our proposed method.   
   
 776  Neural Network-Based Rule Models With Truth Tables   
   
  Authors: Adrien Benamira ; Tristan Guérand ; Thomas Peyrin ; Hans Farrell Soegeng   
  ##MORE##Understanding the decision-making process of a machine/deep learning model is crucial, particularly in security-sensitive applications. In this study, we introduce a neural network framework that combines the global and exact interpretability properties of rule-based models with the high performance of deep neural networks. Our proposed framework, called \textit{Truth Table rules} (TT-rules), is built upon \textit{Truth Table nets} (TTnets), a family of deep neural networks initially developed for formal verification. By extracting the set of necessary and sufficient rules $\mathcal{R}$ from the trained TTnet model (global interpretability), yielding the same output as the TTnet (exact interpretability), TT-rules effectively transforms the neural network into a rule-based model. This rule-based model supports binary classification, multi-label classification, and regression tasks for tabular datasets. Furthermore, our TT-rules framework optimizes the rule set $\mathcal{R}$ into $\mathcal{R}_{opt}$ by reducing the number and size of the rules. To enhance model interpretation, we leverage Reduced Ordered Binary Decision Diagrams (ROBDDs) to visualize these rules effectively. After outlining the framework, we evaluate the performance of TT-rules on seven tabular datasets from finance, healthcare, and justice domains. We also compare the TT-rules framework to state-of-the-art rule-based methods. Our results demonstrate that TT-rules achieves equal or higher performance compared to other interpretable methods while maintaining a balance between performance and complexity. Notably, TT-rules presents the first accurate rule-based model capable of fitting large tabular datasets, including two real-life DNA datasets with over 20K features. Finally, we extensively investigate a rule-based model derived from TT-rules using the Adult dataset.   
   
 778  ProMIL: Probabilistic Multiple Instance Learning for Medical Imaging   
   
  Authors: Łukasz Struski ; Dawid Damian Rymarczyk ; Arkadiusz Lewicki ; Robert Sabiniewicz ; Jacek Tabor ; Bartosz Zieliński   
  ##MORE##Multiple Instance Learning (MIL) is a weakly-supervised problem in which one label is assigned to the whole bag of instances. An important class of MIL models is instance-based, where we first classify instances and then aggregate those predictions to obtain a bag label. The most common MIL model is when we consider a bag as positive if at least one of its instances has a positive label. However, this reasoning does not hold in many real-life scenarios, where the positive bag label is often a consequence of a certain percentage of positive instances. To address this issue, we introduce a dedicated instance-based method called ProMIL, based on deep neural networks and Bernstein polynomial estimation. An important advantage of ProMIL is that it can automatically detect the optimal percentage level for decision-making. We show that ProMIL outperforms standard instance-based MIL in real-world medical applications. We make the code available.   
   
 787  Stock Movement Prediction via Attention-aware Multi-order Relation Graph Neural Network   
   
  Authors: Hao Peng ; Jie Yang   
  ##MORE##Stock Movement Prediction (SMP) is a challenging task that aims at predicting the future stock price trend of companies in the stock. Recent advances mainly apply the Graph Convolutional Network (GCN) to learn connections among companies for SMP. However, these methods usually ignore the semantics of the specific relations (e.g., investment and share) between two entities (i.e., companies and persons) on the market knowledge graph. Meanwhile, considering the long-chain cross-shareholding structures among entities, it is difficult for GCN to obtain high-order neighbor information over long distances. To address these two problems, we present an Attention-aware Multi-order Relation GCN for SMP (AMRGCN-SMP). Specifically, an attention-aware multi-channel aggregation manner achieves the weighted fusion of nodes across multiple semantic channels. Moreover, the dynamic update of the adjacent tensor can fuse the multi-order relation representations and bring more abundant long-chain connections. The experiments on the CSI100E and CSI300E datasets demonstrate that the proposed method achieves state-of-the-art performances compared with the recent advances.   
   
 801  Efficient Information Modulation Network for Image Super-Resolution   
   
  Authors: Xiao Liu ; Xiangyu Liao ; Xiuya Shi ; Linbo Qing ; Chao Ren   
  ##MORE##Recent researches have shown that the success of Transformers comes from their macro-level framework and advanced components, not just their self-attention (SA) mechanism. Comparable results can be obtained by replacing SA with spatial pooling, shifting, MLP, fourier transform and constant matrix, all of which have spatial information encoding capability like SA. In light of these findings, this work focuses on combining efficient spatial information encoding technology with superior macro architectures in Transformers. We rethink spatial convolution to achieve more efficient encoding of spatial features and dynamic modulation value representations by convolutional modulation techniques. The large-kernel convolution and Hadamard product are utilizated in the proposed Multi-orders Long-range convolutional modulation (MOLRCM) layer to imitate the implementation of SA. Moreover, MOLRCM layer also achieve long-range correlations and self-adaptation behavior, similar to SA, with linear complexity. On the other hand, we also address the sub-optimality of vanilla feed-forward networks (FFN) by introducing spatial awareness and locality, improving feature diversity, and regulating information flow between layers in the proposed Spatial Awareness Dynamic Feature Flow Modulation (SADFFM) layer. Experiment results show that our proposed efficient information modulation network (EIMN) performs better both quantitatively and qualitatively.   
   
 802  Partial Compilation of SAT using Selective Backbones   
   
  Authors: Andrea Balogh ; Guillaume Escamocher ; Barry O'Sullivan   
  ##MORE##Our goal in this paper is to significantly decrease the compiled size of a given Boolean instance with a large representation, while preserving as much information about the instance as possible. We achieve this by assigning values to a subset of the variables of the instance, in such a way that the resulting instance has a much smaller representation than the original one, and its number of solutions is almost as high as the starting one. We call the set of variable assignments that we make the selective backbone of the solutions that we keep. Large selective backbones allow for smaller representations, but also eliminate more solutions. We compare different methods of computing the selective backbone that offers the best compromise.   
   
 808  Balancing Fairness and Efficiency in 3D Repeated Matching in Ridesharing   
   
  Authors: Garima Shakya ; Makoto Yokoo   
  ##MORE##Ride-hailing services' main feature is mediating the assignment and transactions between drivers and passengers. Essentially, they decide on the quality of passengers' experience and the drivers' workload balancing. To boost the company's profit, these matching platforms try to maximize the utility for the passengers by optimizing the matching, resulting in shorter waiting times and better service availability. Often, in the process of maximizing revenue, drivers' interests get sidelined. We focus on two objectives: efficiency (minimizing total distance traveled by drivers) and fairness (minimizing the maximum traveled distance by any driver) for shared-mode rides, where the vehicles' capacity is two passengers. We theoretically show the relation between the optimal solutions of both objectives and as the problem is computationally intractable, we propose a heuristic algorithm to achieve an approximate optimal solution. We also propose a re-assignment-based algorithm when the aim is to achieve fairness up to a given threshold, if that is feasible. The experimental analysis for the proposed algorithms on real-world data from Chicago city shows that a bit of attention to fairness can bring significantly balanced allocation for drivers while not losing much efficiency.   
   
 815  SMT-based Satisfiability Checking of Strategic Metric Temporal Logic   
   
  Authors: Magdalena Kacprzak ; Artur Niewiadomski ; Wojciech Penczek ; Andrzej Zbrzezny   
  ##MORE##The paper presents a novel SMT-based method for testing the satisfiability of formulae that express strategic properties of timed multi-agent systems represented by networks of timed automata. Strategic Metric Temporal Logic (SMTL) is introduced, which extends Metric Temporal Logic (MTL) with strategy operators. SMTL is interpreted over maximal continuous time runs of timed automata. We define a procedure that synthesizes a model for a given SMTL formula if such a model exists. The method exploits Satisfiability Modulo Theories (SMT) techniques and Parametric Bounded Model Checking algorithms. The presented approach enables bounded satisfiability checking, where the model is partially given and needs to be completed in line with the given specification. Our method has been implemented, and its application is demonstrated through an example of the well-known dining philosophers problem extended with clocks and strategies. The experimental results are quite encouraging.   
   
 816  CCPO: Conservatively Constrained Policy Optimization using State Augmentation   
   
  Authors: Zepeng Wang ; Xiaochuan Shi ; Chao Ma ; Libing Wu ; Jia Wu   
  ##MORE##How to satisfy safety constraints almost surely (or with probability one) is becoming an emerging research issue for safe reinforcement learning (RL) algorithms in safety-critical domains. For instance, self-driving cars are expected to ensure that the driving strategy they adopt will never do harm to pedestrians and themselves. However, existing safe RL algorithms suffer from either risky and unstable constraint satisfaction or slow convergence. To tackle these two issues, we propose Conservatively Constrained Policy Optimization (CCPO) using state augmentation. CCPO designs a simple yet effective penalized reward function by introducing safety states and adaptive penalty factors under Safety Augmented MDP framework. Specifically, a novel Safety Promotion Function (SPF) is proposed to make the agent being more concentrated on constraint satisfaction with faster convergence by reshaping a more conservative constrained optimization objective. Moreover, we theoretically prove the convergence of CCPO. To validate both the effectiveness and efficiency of CCPO, comprehensive experiments are conducted in both single-constraint and more challenging multi-constraint environments. The experimental results demonstrate that the safe RL algorithms augmented by CCPO satisfy the predefined safety constraints almost surely and gain almost equivalent cumulative reward with faster convergence.   
   
 821  Towards Flexible Time-to-event Modeling: Optimizing Neural Networks via Rank Regression   
   
  Authors: Hyunjun Lee ; Junhyun Lee ; Taehwa Choi ; Jaewoo Kang ; Sangbum Choi   
  ##MORE##Time-to-event analysis, also known as survival analysis, aims to predict the time of occurrence of an event, given a set of features. One of the major challenges in this area is dealing with censored data, which can make learning algorithms more complex. Traditional methods such as Cox's proportional hazards model and the accelerated failure time (AFT) model have been popular in this field, but they often require assumptions such as proportional hazards and linearity. In particular, the AFT models often require pre-specified parametric distributional assumptions.  
  To improve predictive performance and alleviate strict assumptions, there have been many deep learning approaches for hazard-based models in recent years. However, representation learning for AFT has not been widely explored in the neural network literature, despite its simplicity and interpretability in comparison to hazard-focused methods.  
  In this work, we introduce the Deep AFT Rank-regression model for Time-to-event prediction (DART). This model uses an objective function based on Gehan's rank statistic, which is efficient and reliable for representation learning.  
  On top of eliminating the requirement to establish a baseline event time distribution, DART retains the advantages of directly predicting event time in standard AFT models. The proposed method is a semiparametric approach to AFT modeling that does not impose any distributional assumptions on the survival time distribution. This also eliminates the need for additional hyperparameters or complex model architectures, unlike existing neural network-based AFT models. Through quantitative analysis on various benchmark datasets, we have shown that DART has significant potential for modeling high-throughput censored time-to-event data.   
   
 833  MIATS:A Chinese Spelling Error Correction Algorithm Based on Multimodal Information Alignment of Three-towers Structure   
   
  Authors: Guochao Zhao ; yan guo ; Jia Tang ; Zongwei Zhu ; Guixing Wu   
  ##MORE##Chinese spelling errors correction is a crucial task in natural language processing,aiming to detect and correct spelling errors in Chinese text. However,current methods based on neural networks are mostly limited to using contextual information to correct misspelled words and cannot fully utilize glyph and pinyin information. To address this issue, this study extensively explores the application of multimodal technology in the correction task. Specifically, a three-tower multimodal structure is used to extract glyph, pinyin, and semantic information, and an error probability network as well as a transformer network are employed to achieve cross-modal information interaction. Additionally, an additional task is used to achieve cross-modal information alignment. The improved performance of Chinese spelling errors correction algorithms can enhance the efficiency and accuracy of upstream and downstream Chinese natural language processing tasks, such as OCR, ASR, and translation.   
   
 836  Fair rent revision on a budget revisited   
   
  Authors: Stephane Airiau ; Hugo Gilbert ; Umberto Grandi ; Jérôme Lang ; Anaëlle Wilczynski   
  ##MORE##Rent division consists in simultaneously computing an allocation of rooms to agents and a payment, starting from an individual valuation of each room by each agent. When agents have budget limits, it is known that envy-free solutions do not necessarily exist. We propose two solutions to overcome this problem. In the first one, we relax envy-freeness to account for budget disparities. In the second one, we allow fractional allocations, in which agents may change rooms during the duration of the lease.   
   
 838  A Convolutional Neural Network Approach to General Game Playing   
   
  Authors: Yu Wang ; Heng Zhang ; Guifei Jiang   
  ##MORE##General Game Playing (GGP), a research field aimed at developing agents that master different games in a unified way, is regarded as a necessary step towards creating artificial general intelligence. With the success of deep reinforcement learning (DRL) in games like Go, chess, and shogi, it has been recently introduced to GGP and is regarded as a promising technique to achieve the goal of GGP. However, the current work uses fully connected neural networks and is thus unable to efficiently exploit the topological structure of game states. In this paper, we propose an approach to applying general-purposed convolutional neural networks to GGP and implement a DRL-based GGP player. Experiments indicate that the built player not only outperforms the previous algorithm and UCT benchmark in a variety of games but also requires less training time.   
   
 843  Improving Text Semantic Similarity Modeling through a 3D Siamese Network   
   
  Authors: Jianxiang Zang ; Hui Liu   
  ##MORE##Siamese networks have gained popularity as a method for modeling text semantic similarity. Traditional methods rely on pooling operation to compress the semantic representations from Transformer blocks in encoding, resulting in two-dimensional semantic vectors and the loss of hierarchical semantic information from Transformer blocks. Moreover, this limited structure of semantic vectors is akin to a flattened landscape, which restricts the methods that can be applied in downstream modeling, as they can only navigate this flat terrain. To address this issue, we propose a novel 3D Siamese network for text semantic similarity modeling, which maps semantic information to a higher-dimensional space. The three-dimensional semantic coordinate not only retains more precise spatial and feature domain information but also provides the necessary structural condition for comprehensive downstream modeling strategies to capture them. Leveraging this structural advantage, we introduce several modules to reinforce this 3D framework, focusing on three aspects: feature extraction, attention, and feature fusion. Our extensive experiments on four text semantic similarity benchmarks demonstrate the effectiveness and efficiency of our 3D Siamese Network.   
   
 844  Leximin Approximation: From Single-Objective to Multi-Objective   
   
  Authors: Eden Hartman ; Avinatan Hassidim ; Yonatan Aumann ; Erel Segal-Halevi   
  ##MORE##Leximin is a common approach to multi-objective optimization, frequently employed in fair division applications. In leximin optimization, one first aims to maximize the smallest objective value; subject to this, one maximizes the second-smallest objective; and so on. Often, even the single-objective problem of maximizing the smallest value cannot be solved accurately. What can we hope to accomplish for leximin optimization in this situation?  
  Recently, Henzinger et al (2022) defined a notion of \emph{approximate} leximin optimality. Their definition, however, considers only an additive approximation. In this work, we first define the notion of approximate leximin optimality, allowing both multiplicative and additive errors. We then show how to compute, in polynomial time, such an approximate leximin solution, using an oracle that finds an approximation to the single-objective problem. The approximation factors of the algorithms are closely related: a $(\alpha,\epsilon)$ approximation for the single-objective problem (where $\alpha \in (0,1]$ and $\epsilon \geq 0$ are the multiplicative and additive factors respectively) translates into a $\left(\frac{\alpha^2}{1-\alpha + \alpha^2}, \frac{\epsilon}{1-\alpha +\alpha^2}\right)$ approximation for the multi-objective leximin problem, regardless of the number of objectives. Finally, we apply our algorithm to obtain an approximate leximin solution for the problem of \emph{stochastic allocations of indivisible goods}.   
   
 847  Making Friends in the Dark: Ad Hoc Teamwork Under Partial Observability   
   
  Authors: João Ribeiro ; Cassandro Martinho ; Alberto Sardinha ; Francisco S. Melo   
  ##MORE##This paper introduces a formal definition of the setting of ad hoc teamwork under partial observability and proposes a first-principled model-based approach which relies only on prior knowledge and partial observations of the environment in order to perform ad hoc teamwork. We make three distinct assumptions that set it apart previous works, namely: i) the state of the environment is always partially observable, ii) the actions of the teammates are always unavailable to the ad hoc agent and iii) the ad hoc agent has no access to a reward signal which could be used to learn the task from scratch. Our results from an empirical evaluation in 70 POMDPs from 11 domains show that our approach (ATPO) is not only effective in assisting unknown teammates in solving unknown tasks but is also robust in scaling to more challenging problems.   
   
 849  A Hybrid Approach to Preference Learning with Interaction Terms   
   
  Authors: Hugo Gilbert ; Mohamed Ouaguenouni ; Meltem Ozturk ; Olivier Spanjaard   
  ##MORE##Preference learning is an essential component in numerous applications, such as recommendation systems, decision-making processes, and personalized services. In this paper, we propose a novel approach to preference learning that interleaves Gaussian Processes (GP) and Robust Ordinal Regression (ROR). A Gaussian process gives a probability distribution on the latent function values that generate users' preferences. Our method extends the traditional non-parametric Gaussian process framework by approximating the latent function by a very flexible parameterized function, that we call $\theta$-additive function, where $\theta$ is the parameter set. The set $\theta$ represents the degree of sophistication of the generalized additive model that can potentially represent user preferences. To learn what are the components of $\theta$, we update a probability distribution on the space of all possible sets $\theta$, depending on the ability of the parameterized function to approximate the latent function. We predict pairwise preferences by using the parameter set $\theta$ that maximizes the posterior distribution and by performing robust ordinal regression based on this parameter set. Experimental results on synthetic data demonstrate the effectiveness and robustness of our proposed methodology.   
   
 857  Self-Expressive Network-Based Subspace Clustering for Deep Embedding   
   
  Authors: Tingting Leng ; zhao ling ; Xiaolong Xiong ; Peng Cheng ; Jun Zhou   
  ##MORE##Existing deep subspace clustering algorithms are difficult to scale to large-scale data. There are two reasons: Firstly, the existing subspace clustering algorithms almost all need to find the self-expressive coefficient matrix whose size is proportional to the square of the data set size at once. Secondly, spectral clustering needs to solve the eigenvector of the affinity matrix. These two points make the computational complexity of clustering very high when the data scale is large. This paper proposes Self-Expressive Network-Based Deep Embedded Subspace Clustering (SE-DESC), a subspace clustering method that can be applied to large-scale single-view and multi-view data. Using the idea of siamese networks, we design a self-expressive network to calculate the self-expressive coefficient between two data points, reducing the parameter amount of the self-expressive model to a constant. It can effectively avoid computational complexity. Then, we use a deeply embedded network to learn an embedding for each data point to map the data into the spectral space, avoiding the high computational complexity of spectral clustering. Extensive experiments demonstrate that SE-DESC improves the clustering performance on large-scale data compared to state-of-the-art methods.   
   
 864  Specializing Small Language Models towards Complex Style Transfer via Latent Attribute Pre-Training   
   
  Authors: Ruiqi Xu ; Yongfeng Huang ; Xin Chen ; Lin Zhang   
  ##MORE##In this work, we introduce the concept of complex text style transfer tasks, and constructed complex text datasets based on two widely applicable scenarios. Our dataset is the first large-scale data set of its kind, with 700 rephrased sentences and 1,000 sentences from the game Genshin Impact. While large language models (LLM) have shown promise in complex text style transfer, they have drawbacks such as data privacy concerns, network instability, and high deployment costs. To address these issues, we explore the effectiveness of small models (less than T5-large) with implicit style pre-training through contrastive learning. We also propose a method for automated evaluation of text generation quality based on alignment with human evaluations using ChatGPT. Finally, we compare our approach with existing methods and show that our model achieves state-of-art performances of few-shot text style transfer models.   
   
 870  Region-aware Dynamic Filtering Network for 3D Hand Reconstruction   
   
  Authors: Yuchen Chen ; Pengfei Ren ; Jingyu Wang ; Haifeng Sun ; Qi Qi ; Jing Wang ; Jianxin Liao   
  ##MORE##3D hand reconstruction from RGB image has attracted a lot of attention due to its important role in human-computer interaction. However, it is still challenging to perform 3D hand reconstruction under hand-object interaction due to severe mutual occlusion. Previous methods usually adopt fixed convolution kernel to extract features. We argue that simply sharing the static filter for all regions are impertinent, since the occlusion degree of different regions are different, resulting in inconsistent visual representations. Therefore, we proposed Region-aware Dynamic Filtering Network (\textbf{RDFNet}), which dynamically generates convolution kernels according to the features of different regions, so as to adaptively extract region-related information. Furthermore, we introduce a dynamic receptive field selection mechanism to determine the most appropriate scale for the convolution kernel. For the severely occluded regions, larger receptive field is needed to capture semantic-related features, while the visible regions are mainly concerned with their own local pattern to accumulate spatial-related features and avoid the interference of irrelevant information. Our proposed RDFNet outperforms state-of-the-art methods by a large margin on several challenging hand-object interaction datasets. We will make our code be available.   
   
 871  DeepDiscord: Dual Contrastive Coding for Transferable Time Series Anomaly Detection   
   
  Authors: Xin-Yi Li ; Pei-Nan Zhong ; Di Chen ; Zhen-Dong Zhang ; Yu-Bin Yang   
  ##MORE##Time series anomaly detection has attracted extensive research attention owing to its importance in real-world applications. Existing deep learning based anomaly detectors usually require a separate training phase for each dataset. However, the long training time restricts their practicality in the industry use. To address this limitation, we propose a novel deep learning based discord search method named DeepDiscord, which is a multi-scale anomaly detector capable of directly examining unseen datasets after pre-training. To the best of our knowledge, our study is the first to introduce contrastive learning in the discord search, in order to provide a flexible and effective similarity measure for various kinds of data. We innovatively divide the data into two categories according to their roles in discord search, and combine dual learning with contrastive learning, which improves the efficiency and efficacy of discord search. Furthermore, a novel pretext task is proposed based on our dual contrastive learning setting. We evaluate DeepDiscord comprehensively on five anomaly detection benchmarks. Experimental results show that DeepDiscord achieves the state-of-the-art results on the four out of five benchmarks.   
   
 876  ESP: Exploiting Symmetry Prior for Multi-Agent Reinforcement Learning   
   
  Authors: Xin Yu ; Rongye Shi ; Pu Feng ; Yongkai Tian ; Jie Mr Luo ; Wenjun Wu   
  ##MORE##Multi-agent reinforcement learning (MARL) has achieved promising results in recent years. However, most of the existing reinforcement learning methods require a large amount of data for model training. In addition, data-efficient reinforcement learning requires the construction of strong inductive biases, which are ignored in the current MARL approaches. Inspired by the symmetry phenomenon in multi-agent systems, this paper proposes a framework for exploiting prior knowledge by integrating a symmetry augmentation and a well-designed consistency loss into the existing MARL methods. In addition, the proposed framework is model-agnostic and can be applied to most of the existing MARL algorithms. Experimental tests on multiple challenging tasks demonstrate the effectiveness of the proposed framework. Moreover, the proposed framework is applied to a physical multi-robot testbed to show its superiority.   
  
  ​   
 881  Blame Attribution for Multi-Agent Path Finding Execution Failures   
   
  Authors: Avraham J Natan ; Roni Stern ; Meir Kalech   
  ##MORE##In Multi-Agent Systems (MAS), Multi-Agent Planning (MAP) is the problem of finding a sound set of plan series for a group of agents to execute concurrently and achieve a task defined by the system. Deviations from this MAP are standard in real-world applications and may decrease overall system efficiency and even lead to accidents and deadlocks. In large MAS scenarios with physical robots, multiple faulty events occur over time, contributing to the overall degraded system performance. This raises the main problem we address in this work: how to attribute blame for a degraded MAS performance over a set of faulty events. We formally define this problem and propose using the Shapley values to solve it. Then, we propose a diagnosis-based algorithm that efficiently approximates the Shapley value by considering only some subsets of faulty events set. We analyze this algorithm theoretically and experimentally and demonstrate that it enables effectively trading off runtime for error.   
   
 883  Seq2Space: A lightweight solution for sequence modelling   
   
  Authors: Joel Rixen ; Matthias Renz   
  ##MORE##This paper proposes a novel method for sequence modelling which we call Seq2Space. The basic idea is to project sequential information into the channel dimension. The Seq2Space layer outperforms the Transformer on every dataset contained in the Long Range Arena (LRA) benchmark as well as on the WSJ0-2 Mix benchmark for single-channel speech separation. Compared to previous methods which were tested on the LRA, the proposed Seq2Space layer does not quite reach the accuracy of the convolution-based methods. It is, however, more than twice as fast as the next fastest method as well as the most memory efficient, and still reaches an average accuracy of 71.15%. On the WSJ0-2Mix, the Seq2Space layer outperforms all other sequence modelling methods in our experiments except for the MEGA layer. By replacing Transformers with the Seq2Space layer on a current SOTA method, we are able to reach 22.8 dB SI-SDR improvement, which is comparable to current SOTA while being significantly faster and more memory efficient during both training and inference.   
   
 884  MaxSAT-Based Inconsistency Measurement   
   
  Authors: Andreas Niskanen ; Isabelle Kuhlmann ; Matthias Thimm ; Matti Järvisalo   
  ##MORE##Inconsistency measurement aims at obtaining a quantitative assessment of the level of inconsistency in knowledge bases. While having such a quantitative assessment is beneficial in various settings, inconsistency measurement of propositional knowledge bases is under most existing measures a significantly challenging computational task. In this work, we harness Boolean satisfiability (SAT) based solving techniques for developing practical inconsistency measurement algorithms. Our algorithms---some of which constitute, to the best of our knowledge, the first practical approaches for specific inconsistency measures---are based on using natural choices of SAT-based techniques for the individual inconsistency measures, ranging from direct maximum satisfiability (MaxSAT) encodings to MaxSAT-based column generation techniques making use of incremental computations. We show through an extensive empirical evaluation that our approaches scale well in practice and significantly outperform recently-proposed answer set programming approaches to inconsistency measurement.   
   
 885  Disentangling Interaction using Maximum Entropy Reinforcement Learning in Multi-Agent Systems   
   
  Authors: David Rother ; Thomas H. Weisswange ; Jan Peters   
  ##MORE##Research on multi-agent interaction involving both multiple artificial agents and humans is still in its infancy. Most recent approaches have focused on environments with collaboration-focused human behavior, or providing only a small, defined set of situations. When deploying robots in human-inhabited environments in the future, it will be unlikely that all interactions fit a predefined model of collaboration, where collaborative behavior is still expected from the robot.  
  Existing approaches are unlikely to effectively create such behaviors in such ""coexistence"" environments. To tackle this issue, we introduce a novel framework that decomposes interaction and task-solving into separate learning problems and blends the resulting policies at inference time. Policies are learned with maximum entropy reinforcement learning, allowing us to create interaction-impact-aware agents and scale the cost of training agents linearly with the number of agents and available tasks. We propose a weighting function covering the alignment of interaction distributions with the original task. We demonstrate that our framework addresses the scaling problem while solving a given task and considering collaboration opportunities in a co-existence particle environment and a new cooking environment. Our work introduces a new learning paradigm that opens the path to more complex multi-robot, multi-human interactions.   
   
 887  Investigating the Learning Behaviour of In-context Learning: A Comparison with Supervised Learning   
   
  Authors: Xindi Wang ; Yufei Wang ; Can Xu ; Xiubo Geng ; Bowen Zhang ; Chongyang Tao ; Frank Rudzicz ; Robert Mercer ; Daxin Jiang   
  ##MORE##Large language models (LLMs) have shown remarkable capacity for in-context learning (ICL), where learning a new task from just a few training examples is done without being explicitly pre-trained. However, despite the success of LLMs, there has been little understanding of how ICL learns the knowledge from the given prompts. In this paper, to make progress toward understanding the learning behaviour of ICL, we train the same LLMs with the same demonstration examples via ICL and supervised learning (SL), respectively, and investigate their performance under label perturbations (i.e., noisy labels and label imbalance) on a range of classification tasks. First, via extensive experiments, we find that gold labels have significant impacts on the downstream in-context performance, especially for large language models; however, imbalanced labels matter little to ICL across all model sizes. Second, when comparing with SL, we show empirically that ICL is less sensitive to label perturbations than SL, and ICL gradually attains comparable performance to SL as the model size increases.   
   
 888  Approximate Data Deletion in Generative Models   
   
  Authors: Zhifeng Kong ; Scott Alfeld   
  ##MORE##Users have the right to have their data deleted by third-party learned systems, as codified by recent legislation such as the General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA). Such data deletion can be achieved by full re-training, but this incurs a high computational cost for modern machine learning methods. To avoid this cost, many approximate deletion methods have been developed for supervised learning. Unsupervised learning, in contrast, remains largely an open problem when it comes to efficient approximate data deletion. In this paper, we introduce (1) an efficient method for approximate deletion in generative models, and (2) statistical tests for estimating whether training points have been deleted. We provide theoretical guarantees under various learner assumptions. We then empirically demonstrate our methods across a variety of generative methods.   
   
 890  Enhancing Document-level Relation Extraction with Relation-specific Entity Representation and Evidence Sentence Augmentation   
   
  Authors: Qizhu Dai ; Jiang Zhong ; Wei Zhu ; Chen Wang ; Hong Yin ; Qin Lei ; Xue Li ; Rongzhen Li   
  ##MORE##Document-level relation extraction (DocRE) is an important task in natural language processing, with applications in knowledge graph construction, question answering, and biomedical text analysis. However, existing approaches to DocRE have limitations in predicting relations between entities using fixed entity representations, which can lead to inaccurate results. In this paper, we propose a novel DocRE model that addresses these limitations by using a relation-specific entity representation method and evidence sentence augmentation. Our model uses evidence sentence augmentation to identify top-k evidence sentences for each relation and a relation-specific entity representation method that aggregates the importance of entity mentions using an attention mechanism. These two components work together to capture the context of each entity mention in relation to the specific relation being predicted and select evidence sentences that support accurate relation identification. Finally, we re-predicts entity relations based on the evidence sentences, called relationship reordering module. This module re-predicts entity relationships based on the predicted set of evidence sentences to form k sets of relationship predictions, and then averages these k+1 sets of results to obtain the final relationship predictions. Experimental results on the DocRED dataset demonstrate that our proposed model achieves an F1 score of 62.84\% and an lgn F1 score of 60.79\%, outperforming state-of-the-art methods.   
   
 911  Structured Sparse Multi-Task Learning with Generalized Group Lasso   
   
  Authors: Luhuan Fei ; Lu Sun ; Mineichi Kudo ; Kego Kimura   
  ##MORE##Multi-task learning (MTL) improves generalization by sharing information among related tasks. Structured sparsity-inducing regularization has been widely used in MTL to learn interpretable and compact models, especially in high-dimensional settings. These methods have achieved much success in practice, however, there are still some key limitations, such as limited generalization ability due to specific sparse constraints on parameters, usually restricted in matrix form that ignores high-order feature interactions among tasks, and formulated in various forms with different optimization algorithms. Inspired by Generalized Lasso, we propose the Generalized Group Lasso (GenGL) to overcome these limitations. In GenGL, a linear operator is introduced to make it adaptable to diverse sparsity settings, and helps it to handle hierarchical sparsity and multi-component decomposition in general tensor form, leading to enhanced flexibility and expressivity. Based on GenGL, we propose a novel framework for Structured Sparse MTL (SSMTL), that unifies a number of existing MTL methods, and implement its two new variants in shallow and deep architectures, respectively. An efficient optimization algorithm is developed to solve the unified problem, and its effectiveness is validated by synthetic and real-world experiments.   
   
 914  Micro-expression Spotting Method Based on AU Prototype   
   
  Authors: He Yuhong ; Guangyu Wang ; Lin Ma ; Haifeng Li   
  ##MORE##Micro-expressions (MEs) are brief, involuntary facial expressions that reveal genuine emotions, making their accurate detection crucial in various applications, such as security, psychology, and human-computer interaction. Due to its small intensity and short duration, how accurately capturing the subtle movements of micro-expression is a challenging problem. This paper presents a novel AU prototype-based method for micro-expression spotting, which offers high accuracy and robustness. Action Units (AUs) are basic facial actions, such as brow lower and lip corner puller, that are widely used for micro-expression analysis, and an expression can be encoded as a sequence of AUs. Our approach involves designing AU prototypes that record representative dynamic information of AUs. We then calculate the prototype matching index between AU prototypes and the image sequence to construct time-domain prototype matching curves for ME spotting. In the experimental section, AU prototypes derived from CASMEII dataset enable a more intuitive analysis of AU within micro-expressions. Results on the CAS(ME)2 dataset demonstrate that our ME spotting method significantly outperforms existing approaches. This makes our method highly valuable for various application scenarios, potentially enhancing emotion recognition and analysis in real-world settings.   
   
 924  Shrink-Perturb Improves Architecture Mixing during Population Based Training for Neural Architecture Search   
   
  Authors: Alexander Chebykin ; Arkadiy Dushatskiy ; Tanja Alderliesten ; Peter AN Bosman   
  ##MORE##In this work, we show that simultaneously training and mixing neural networks is a promising way to conduct Neural Architecture Search (NAS). For hyperparameter optimization, reusing the partially trained weights allows for efficient search, as was previously demonstrated by the Population Based Training (PBT) algorithm. We propose PBT-NAS, an adaptation of PBT to NAS where architectures are improved during training by replacing poorly-performing networks in a population with the result of mixing well-performing ones and inheriting the weights using the shrink-perturb technique. After PBT-NAS terminates, the created networks can be directly used without retraining. PBT-NAS is highly parallelizable and effective: on challenging tasks (image generation and reinforcement learning) PBT-NAS achieves superior performance compared to baselines (random search and mutation-based PBT).   
   
 932  Resource-constrained knowledge diffusion processes inspired by human peer learning   
   
  Authors: Ehsan Beikihassan ; Amy K. Hoover ; Ioannis Koutis ; Ali Parviz ; Niloofar Aghaieabiane   
  ##MORE##We consider a setting where a population of artificial learners is given, and the objective is to optimize aggregate measures of performance, under constraints on training resources. The problem is motivated by the study of peer learning in human educational systems. In this context, we study natural knowledge diffusion processes in networks of interacting artificial learners. By `natural', we mean processes that reflect human peer learning where the students' internal state and learning process is mostly opaque, and the main degree of freedom lies in the formation of peer learning groups by a coordinator who can potentially evaluate the learners before assigning them to peer groups. Among else, we empirically show that such processes indeed make effective use of the training resources, and enable the design of modular neural models that have the capacity to generalize without being prone to overfitting noisy labels.   
   
 933  EFx Budget-Feasible Allocations with High Nash Welfare   
   
  Authors: Marius Garbea ; Vasilis Gkatzelis ; Xizhi Tan   
  ##MORE##We study the problem of allocating indivisible items to budget-constrained agents, aiming to provide fairness and efficiency guarantees. Specifically, our goal is to ensure that the resulting allocation is envy-free up to any item (EFx) while minimizing the amount of inefficiency that this needs to introduce. We first show that there exist two-agent problem instances for which no EFx allocation is Pareto efficient. We, therefore, turn to approximation and use the Nash social welfare maximizing allocation as a benchmark. For two-agent instances, we provide a procedure that always returns an EFx allocation while achieving the best possible approximation of the optimal Nash social welfare that EFx allocations can achieve. For the more complicated case of three-agent instances, we provide a procedure that guarantees EFx, while achieving a constant approximation of the optimal Nash social welfare for any number of items.   
   
 936  Dynamic Graph Convolutional Network with Attention Fusion for Traffic Flow Prediction   
   
  Authors: Xunlian Luo ; Chunjiang Zhu ; Detian Zhang ; Qing Li   
  ##MORE##Accurate and real-time traffic state prediction is of great practical importance for urban traffic control and web mapping services. With the support of massive data, deep learning methods have shown their powerful capability in capturing the complex spatial-temporal patterns of traffic networks. However, existing approaches use pre-defined graphs and a simple set of spatial-temporal components, making it difficult to model multi-scale spatial-temporal dependencies. In this paper, we propose a novel dynamic graph convolution network with attention fusion to tackle this gap. The method first enhances the interaction of temporal feature dimensions, and then it combines a dynamic graph learner with GRU to jointly model synchronous spatial-temporal correlations. We also incorporate spatial-temporal attention modules to effectively capture long-range, multifaceted domain spatial-temporal patterns. We conduct extensive experiments in four real-world traffic datasets to demonstrate that our method surpasses state-of-the-art performance compared to 18 baseline methods.   
   
 937  PMAA: A Progressive Multi-scale Attention Autoencoder Model for High-performance Cloud Removal from Multi-temporal Satellite Imagery   
   
  Authors: Xuechao Zou ; Kai Li ; Junliang Xing ; Pin Tao ; Yachao Cui   
  ##MORE##Satellite imagery analysis plays a pivotal role in remote sensing; however, information loss due to cloud cover significantly impedes its application. Although existing deep cloud removal models have achieved notable outcomes, they scarcely consider contextual information. This study introduces a high-performance cloud removal architecture, termed Progressive Multi-scale Attention Autoencoder (PMAA), which concurrently harnesses global and local information to construct robust contextual dependencies using a novel Multi-scale Attention Module (MAM) and a novel Local Interaction Module (LIM). PMAA establishes long-range dependencies of multi-scale features using MAM and modulates the reconstruction of fine-grained details utilizing LIM, enabling simultaneous representation of fine- and coarse-grained features at the same level. With the help of diverse and multi-scale features, PMAA consistently outperforms the previous state-of-the-art model CTGAN on two benchmark datasets. Moreover, PMAA boasts considerable efficiency advantages, with only 0.5% and 14.6% of the parameters and computational complexity of CTGAN, respectively. These comprehensive results underscore PMAA's potential as a lightweight cloud removal network suitable for deployment on edge devices to accomplish large-scale cloud removal tasks. Our source code and pre-trained models are available at https://github.com/XavierJiezou/PMAA  .   
   
 943  Rectifying Binary Classifiers   
   
  Authors: Sylvie Coste-Marquis ; Pierre Marquis   
  ##MORE##We elaborate on the notion of rectification of a classifier Σ based on Boolean features, introduced recently. The purpose is to determine how to modify Σ when the way it classifies a given instance is considered incorrect since it conflicts with some expert knowledge T. Given Σ and T, postulates characterizing the way Σ must be changed into a new classifier Σ ⋆ T that complies with T were presented. We focus here on the specific case of binary classifiers, i.e., there is a single target concept, and any instance is classified either as positive (an element of the concept), or as negative (an element of the complementary concept). In this specific case, our main contribution is twofold: (1) we show that there is a unique rectification operator ⋆ satisfying the postulates, and (2) when Σ and T are Boolean circuits, we show how a classification circuit equivalent to Σ⋆T can be computed in time linear in the size of Σ and T; when Σ is a decision tree (resp. a random forest, a boosted tree) and T is a decision tree, a decision tree (resp. a random forest, a boosted tree) equivalent to Σ ⋆ T can be computed in time polynomial in the size of Σ and T .   
   
 949  Lifted Successor Generation by Maximum Clique Enumeration   
   
  Author: Simon Ståhlberg   
  ##MORE##Classical planning instances are often represented using first-order logic; however, the initial step for most classical planners is to transform the given instance into a propositional representation. For example, action schemas are converted into ground actions, aiming to generate as few ground actions as possible without eliminating any viable solutions to the problem. This step can become a bottleneck in some domains due to the exponential blowup caused by the grounding process. A recent approach to alleviate this issue involves utilizing the lifted (first-order) representation of the instance and generating all applicable ground actions on-the-fly during the search for each expanded state. In this paper, we propose a method that addresses this problem by enumerating all maximum cliques of a graph encoding the state and the action schema's preconditions. We compare our method with state-of-the-art across 46 domains, showcasing improved performance in 22 domains. In some cases, simply changing the maximum clique enumeration algorithm results in several orders of magnitude speedup compared to the state-of-the-art. Consequently, this enables a variety of lifted successor generation methods with diverse performance characteristics, suitable for different domains.   
   
 953  Intractability of Optimal Multi-Agent Pathfinding on Directed Graphs   
   
  Authors: Xing Tan ; Pascal Bercher   
  ##MORE##In Multi-Agent Pathfinding (MAPF) problems, multiple agents move simultaneously to reach their individual destinations without colliding with each other. The computational complexity of the problem has been extensively studied for undirected graphs over the past decades. However, plan existence for Directed MAPF (diMAPF) was only recently studied and was shown to be in PSPACE as well as NP-hard. In this paper, we study the optimization versions (on makespan and on travel distance of agents) of diMAPF problems and show that they remain NP-hard even when various important non-trivial restrictions are imposed (e.g., when considering the problem on directed, acyclic, and planar graphs where the vertex-degrees are bounded). We have also provide membership results, thus presenting the first set of NP-completeness results for various optimal diMAPF variants.   
   
 955  LTLf Best-Effort Synthesis in Nondeterministic Planning Domains   
   
  Authors: Giuseppe De Giacomo ; Gianmarco Parretti ; Shufang Zhu   
  ##MORE##We study best-effort strategies (aka plans) in fully observable nondeterministic domains (FOND) for goals expressed in Linear Temporal Logic on Finite Traces (LTLf). The notion of best-effort strategy has been introduced to deal also with the scenario when no agent strategy exists that fulfills the goal against every possible nondeterministic environment reaction. Such strategies fulfill the goal if possible, and do their best to do so otherwise. We present a game-theoretic technique for synthesizing best-effort strategies that exploit the specificity of nondeterministic planning domains. We formally show its correctness and demonstrate its effectiveness experimentally, exhibiting a much greater scalability with respect to a direct best-effort synthesis approach based on re-expressing the planning domain as generic environment specifications.   
   
 959  Bridging the Transparency Gap: What Can Explainable AI Learn From the AI Act?   
   
  Authors: Balint Gyevnar ; Nick J Ferguson ; Burkhard Schafer   
  ##MORE##The European Union has proposed the Artificial Intelligence Act which introduces detailed requirements of transparency for AI systems. Many of these requirements can be addressed by the field of explainable AI (XAI), however, there is a fundamental difference between XAI and the Act regarding what transparency is. The Act views transparency as a means that supports wider values, such as accountability, human rights, and sustainable innovation. In contrast, XAI views transparency narrowly as an end in itself, focusing on explaining complex algorithmic properties without considering the socio-technical context. We call this difference the ``transparency gap''. Failing to address the transparency gap, XAI risks leaving a range of transparency issues unaddressed. To begin to bridge this gap, we overview and clarify the terminology of how XAI and European regulation -- the Act and the related General Data Protection Regulation (GDPR) -- view basic definitions of transparency. By comparing the disparate views of XAI and regulation, we arrive at four axes where practical work could bridge the transparency gap: defining the scope of transparency, clarifying the legal status of XAI, addressing issues with conformity assessment, and building explainability for datasets.   
   
 962  Improving bi-objective shortest path search with early pruning   
   
  Authors: Lawrence Mandow ; José-Luis Pérez-de-la-Cruz   
  ##MORE##Bi-objective search problems are a useful generalization of shortest path search. This paper reviews some recent contributions for the solution of this problem with emphasis on the efficiency of the dominance checks required for pruning, and introduces a new algorithm that improves time efficiency over previous proposals. Experimental results are presented to show the performance improvement using a set of standard problems over bi-objective road maps.   
   
 968  Neural Architecture Search for Explainable Networks   
   
  Authors: Yaoman LI ; Irwin King   
  ##MORE##One of the main challenges in machine learning is providing understandable explanations for complex models. Despite outperforming humans in many tasks, machine learning models are often treated as black boxes that are difficult to interpret. Post-hoc explanation methods have been developed to create interpretable surrogate models that explain the behavior of black-box models. However, these methods have been shown to perpetuate bad practices and lack stability. Recently, inherent explainable approaches have been proposed to provide built-in explainability to models. However, most of these methods sacrifice performance. This paper proposes the Neural Architecture Search for Explainable Networks (NASXNet) approach to address the trade-off between performance and interpretability. Our method applies architecture search to generate high-performance and explainable neural networks for image classification tasks. We conduct experiments on four datasets: CUB-200-2011, Stanford Cars, CIFAR 10, and CIFAR 100. The results demonstrate that our models provide a high-level interpretation of prediction results, achieving state-of-the-art performance that is on par with non-explainable models. This paper contributes by solving the trade-off problem between performance and interpretability. It is the first to apply neural architecture search to develop explainable deep learning models, generating state-of-the-art explainable models that outperform existing approaches. Additionally, a new training process is proposed that enables faster convergence during model training.   
   
 971  Distributionally Robust Cross Subject EEG Decoding   
   
  Authors: Tiehang Duan ; Zhenyi Wang ; Gianfranco Doretto ; Fang Li ; Cui Tao ; Donald Adjeroh   
  ##MORE##Recently, deep learning has shown to be effective for Electroencephalography (EEG) decoding tasks. Yet, its performance can be negatively influenced by two key factors: 1) the high variance and different types of corruption that are inherent in the signal, 2) the EEG datasets are usually relatively small given the acquisition cost, annotation cost and amount of effort needed. Data augmentation approaches for alleviation of this problem have been empirically studied, with augmentation operations on spatial domain, time domain or frequency domain handcrafted based on expertise of domain knowledge. In this work, we propose a principled approach to perform dynamic evolution on the data for improvement of decoding robustness. The approach is based on distributionally robust optimization (DRO) and achieves robustness by optimizing on a family of evolved data distributions instead of the single training data distribution. We derived a general data evolution framework based on Wasserstein gradient flow (WGF) and provides two different forms of evolution within the framework. Intuitively, the evolution process helps the EEG decoder to learn more robust and diverse features. It is worth mentioning that the proposed approach can be readily integrated with other data augmentation approaches for further improvements. We performed extensive experiments on the proposed approach and tested its performance on different types of corrupted EEG signals. The model significantly outperforms competitive baselines on challenging decoding scenarios.   
   
 974  Associative Memories in the Feature Space   
   
  Authors: Tommaso Salvatori ; Beren Millidge ; Yuhang Song ; Rafal Bogacz ; Thomas Lukasiewicz   
  ##MORE##An autoassociative memory model is a function that, given a set of data points, takes as input an arbitrary vector and outputs the \emph{most similar} data point from the memorized set. However, popular memory models fail to retrieve images even when the corruption is mild and easy to detect for a human evaluator. This is because similarities are evaluated in the raw pixel space, which does not contain any semantic information about the images. This problem can be easily solved by computing \emph{similarities} in an embedding space instead of the pixel space. We show that an effective way of computing such embeddings is via a network pretrained with a contrastive loss. As the dimension of embedding spaces is often significantly smaller than the pixel space, we also have a faster computation of similarity scores. We test this method on complex datasets such as CIFAR10 , STL10, and ImageNet. An additional drawback of current models is the need of storing the whole dataset in the pixel space, which is often extremely large. We relax this condition and propose a class of memory models that only stores low-dimensional semantic embeddings, and uses them to retrieve similar, but not identical, memories. We demonstrate a proof of concept of this method on a simple task on the MNIST dataset.   
   
 981  Diversified Prior Knowledge Enhanced General Language Model for Biomedical Information Retrieval   
   
  Authors: Yizheng Huang ; Jimmy Huang   
  ##MORE##General language models have shown success in various information retrieval (IR) tasks, but their effectiveness is limited in the biomedical domain due to the specialized and complex nature of biomedical data. However, training domain-specific models is challenging and costly due to the limited availability of annotated data. To address these issues, we propose the Diversified Prior Knowledge Enhanced General Language Model (DPK-GLM) framework, which integrates domain knowledge with general language models for improved performance in biomedical IR. Our two-stage retrieval framework comprises a Knowledge-based Query Expansion method for enriching biomedical knowledge, an Aspect-based Filter for identifying highly-relevant documents, and a Diversity-based Score Reweighting method for re-ranking retrieved documents. Experimental results on public biomedical IR datasets show significant improvement, demonstrating the effectiveness of the proposed methods.   
   
 985  On the Learning Dynamics of Attention Networks   
   
  Authors: Rahul Vashisht ; Harish Guruprasad Ramaswamy   
  ##MORE##Attention models are typically learned by optimizing one of three standard loss functions that are variously called – soft attention, hard attention, and latent variable marginal likelihood (LVML) attention. All three paradigms are motivated by the same goal of finding two models– a ‘focus’ model that ‘selects’ the right segment of the input and a ‘classification’ model that processes the selected segment into the target label. However, they differ significantly in the way the selected segments are aggregated, resulting in distinct dynamics and final results. We observe a unique signature of models learned using these paradigms and explain this as a consequence of the evolution of the classification model under gradient descent when the focus model is fixed. We also analyze these paradigms in a simple setting and derive closed-form expressions for the parameter trajectory under gradient flow. With the soft attention loss, the focus model improves quickly at initialization and splutters later on. On the other hand, hard attention loss behaves in the opposite fashion. Based on our observations, we propose a simple hybrid approach that combines the advantages of the different loss functions and demonstrates it on a collection of semi-synthetic and real-world datasets.   
   
 987  Gated Adapters for Multi-Domain Neural Machine Translation   
   
  Authors: Mateusz Klimaszewski ; Zeno Belligoli ; Satendra Kumar ; Emmanouil Stergiadis   
  ##MORE##The Adapter framework introduces lightweight modules that reduce the complexity of Multi-Domain Machine Translation systems. Compared to fine-tuned models, Adapters train faster, do not overfit, have smaller memory requirements, and maintain the base model intact. However, just like fine-tuned models, they need prior information about the domain of the sentence. Otherwise, their performance decreases for out-of-domain and unknown-domain samples. In this work, we propose a solution that does not require the information and can decide on the sample’s origin on-the-fly without compromising quality or latency. We introduce a built-in gating mechanism utilising a knowledge distillation framework to activate a subset of softly-gated, domain-specific Adapters that are relevant to the sentence. The effectiveness of the proposed solution is demonstrated through our experiments on two language pairs, using both in-domain and out-of-domain datasets. Our analysis reveals that Gated Adapters provide significant benefits, particularly in the case of ambiguous, misclassified samples, resulting in an improvement of over +5 COMET points.   
   
 989  AlegAATr the Bandit   
   
  Authors: Ethan Pedersen ; Jacob Crandall   
  ##MORE##One design strategy for developing intelligent agents is to create N distinct behaviors, each of which works effectively in particular tasks and circumstances. At each time step during task execution, the agent, or bandit, chooses which of the N behaviors to use. Traditional bandit algorithms for making this selection often (1) assume the environment is stationary, (2) focus on asymptotic performance, and (3) do not incorporate external information that is available to the agent. Each of these simplifications limits these algorithms such that they often cannot be used successfully in practice. In this paper, we propose a new bandit algorithm, called AlegAATr, as a step toward overcoming these deficiencies. AlegAATr leverages a technique called Assumption-Alignment Tracking (AAT), proposed previously in the robotics literature, to predict the performance of each behavior in each situation. It then uses these predictions to decide which behavior to use at any given time. We demonstrate the effectiveness of AlegAATr in selecting behaviors in three problem domains: repeated games, ad hoc teamwork, and a human-robot pick-n-place task.   
   
 1008  Cost-awareness in Multi-Agent Active Search   
   
  Authors: Arundhati Banerjee ; Ramina Ghods ; Jeff Schneider   
  ##MORE##Multi-agent active search requires autonomous agents to choose sensing actions that efficiently locate targets. In a realistic setting, agents also must consider the costs that their decisions incur. Previously proposed active search algorithms simplify the problem by ignoring uncertainty in the agent's environment, using myopic decision making, and/or overlooking costs. In this paper, we introduce an online active search algorithm to detect targets in an unknown environment by making adaptive cost-aware decisions regarding the agent's actions. Our algorithm proposes an online lookahead planner that combines priniciples from Monte Carlo Tree Search, Thompson sampling and pareto-optimal confidence bounds for decentralized multi-agent multi-objective optimization in an unknown environment. We analyze the algorithm's performance in simulation to show its efficacy in cost-aware active search.   
   
 1014  Simplex Decomposition for Portfolio Allocation Constraints in Reinforcement Learning   
   
  Authors: David Winkel ; Niklas A Strauß ; Matthias Schubert ; Thomas Seidl   
  ##MORE##Portfolio optimization tasks describe sequential decision problems in which the investor’s wealth is distributed across a set of assets. Allocation constraints are used to enforce minimal or maximal investments into particular subsets of assets to control for objectives such as limiting the portfolio’s exposure to a certain sector due to environmental concerns. Although methods for constrained Reinforcement Learning (CRL) can optimize policies while considering allocation constraints, it can be observed that these general methods yield suboptimal results. In this paper, we propose a novel approach to handle allocation constraints based on a decomposition of the constraint action space into a set of unconstrained allocation problems. In particular, we examine this approach for the case of two constraints. For example, an investor may wish to invest at least a certain percentage of the portfolio into green technologies while limiting the investment in the fossil energy sector. We show that the action space of the task is equivalent to the decomposed action space, and introduce a new reinforcement learning (RL) approach CAOSD, which is built on top of the decomposition. The experimental evaluation on real-world Nasdaq-100 data demonstrates that our approach consistently outperforms state-of-the-art CRL benchmarks for portfolio optimization.   
   
 1022  FOND Planning for Pure-Past Linear Temporal Logic Goals   
   
  Authors: Luigi Bonassi ; Giuseppe De Giacomo ; Marco Favorito ; Francesco Fuggitti ; Alfonso Gerevini ; Enrico Scala   
  ##MORE##Recently, Pure-Past Temporal Logic (PPLTL) has been shown to be very effective for specifying temporally extended goals in deterministic planning domains. In this paper, we show its effectiveness also for FOND planning, both for strong and strong-cyclic plans. We present a notably simple encoding of FOND planning for PPLTL goals into standard FOND planning for reachability goals. The encoding only introduces few fluents (at most linear in the PPLTL goal) without adding any spurious action and allows planners to lazily build the relevant part of the DFA for the goal formula on-the-fly during the search. We formally prove its correctness, implement it in a tool called Plan4Past, and experimentally show its practical effectiveness.   
   
 1024  High Dynamic Range Image Reconstruction via Deep Explicit Polynomial Curve Estimation   
   
  Authors: Jiaqi Tang ; Xiaogang XU ; Sixing Hu ; Yingcong Chen   
  ##MORE##Due to limited camera capacities, digital images usually have a narrower dynamic illumination range than real-world scene radiance. To resolve this problem, High Dynamic Range (HDR) reconstruction is proposed to recover the dynamic range to better represent real-world scenes. However, due to different physical imaging parameters, the tone-mapping functions between images and real radiance are highly diverse, which makes HDR reconstruction extremely challenging. Existing solutions can not explicitly clarify a corresponding relationship between the tone-mapping function and the generated HDR image, but this relationship is vital when guiding the reconstruction of HDR images. To address this problem, we propose a method to explicitly estimate the tone mapping function and its corresponding HDR image in one network. Firstly, based on the characteristics of the tone mapping function, we construct a model by a polynomial to describe the trend of the tone curve. To fit this curve, we use a learnable network to estimate the coefficients of the polynomial. This curve will be automatically adjusted according to the tone space of the Low Dynamic Range (LDR) image, and reconstruct the real HDR image. Besides, since all current datasets do not provide the corresponding relationship between the tone mapping function and the LDR image, we construct a new dataset with both synthetic and real images. Extensive experiments show that our method generalizes well under different tone-mapping functions and achieves SOTA performance.   
   
 1026  Credal Learning: Weakly Supervised Learning from Credal Sets   
   
  Author: Andrea Campagner   
  ##MORE##In this article we study the problem of credal learning, a general form of weakly supervised learning in which instances are associated with credal sets (i.e., closed, convex sets of probabilities), which are assumed to represent the partial knowledge of an annotating agent about the true conditional label distribution. A variety of algorithms have been proposed in this setting, chiefly among them the generalized risk minimization method, a class of algorithms that extend empirical risk minimization. Despite its popularity and promising empirical results, however, the theoretical properties of this algorithm (as well as of credal learning more in general) have not been previously studied. In this article we address this gap by studying the problem of credal learning from the learning-theoretic and complexity-theoretic perspectives. We provide, in particular, three main contributions: 1) we show that, under weak assumptions about the accuracy of the annotating agent, credal learning is learnable in the convex learning setting, providing effective risk bounds; 2) we study the properties of generalized risk minimization and, in particular, identify the optimal instance of this approach, that we call trade-off risk minimization; 3) we study the computational complexity of generalized risk minimization, showing effective algorithms based on gradient descent and providing sufficient and necessary conditions for them being computationally efficient.   
   
 1032  Specifying Prior Beliefs over DAGs in Deep Bayesian Causal Structure Learning   
   
  Authors: Simon Rittel ; Sebastian Tschiatschek   
  ##MORE##We consider the principled incorporation of prior knowledge in deep learning based Bayesian approaches to causal structure learning via the prior belief. In particular, we investigate how to include knowledge about individual edges and causal dependencies in the prior over the underlying directed acyclic graph (DAG). While conceptually simple, substantial challenges arise because the acyclicity of a DAG limits the modeling choices of the marginal distributions over its edges. Specifying the marginals iteratively unveils their dependencies and ensures a sound formulation of the probability distribution over DAGs. We provide recipes for formulating valid priors over DAGs for two recent deep learning based Bayesian approaches to causal structure learning and demonstrate empirically that using this prior knowledge can enable significantly more sample-efficient causal structure search.   
   
 1052  Is Performance Fairness Achievable in Presence of Attackers under Federated Learning?   
   
  Authors: Ashish Gupta ; George Markowsky ; Sajal K. Das   
  ##MORE##In the last few years, Federated Learning (FL) has received extensive attention from the research community because of its capability for privacy-preserving, collaborative learning from heterogeneous data sources. Most FL studies focus on either average performance improvement or the robustness to attacks, while some attempt to solve both jointly. However, the performance disparities across clients in the presence of attackers have largely been unexplored. In this work, we propose a novel Fair Federated Learning scheme with Attacker Detection capability (abbreviated as FFL+AD) to minimize performance discrepancies across benign participants. FFL+AD enables the server to identify attackers and learn their malign intent (e.g., targeted label) by investigating suspected models via top performers. This two-step detection method helps reduce false positives. Later, we introduce fairness by regularizing the benign clients' local objectives with a variable boosting parameter that gives more emphasis on low performers in optimization. Under standard assumptions, FFL+AD exhibits a convergence rate similar to FedAvg. Experimental results show that our scheme builds a more fair and more robust model, under label-flipping and backdoor attackers, compared to prior schemes. FFL+AD achieves competitive accuracy even when 40% of the clients are attackers.   
   
 1058  Integrated Private Data Trading Systems for Data Marketplaces   
   
  Authors: Weidong Li ; Mengxiao Zhang ; Libo Zhang ; Jiamou Liu   
  ##MORE##In the digital age, data is a valuable commodity, and data marketplaces offer lucrative opportunities for data owners to monetize their private data. However, data privacy is a significant concern, and differential privacy has become a popular solution to address this issue. Private data trading systems (PDQS) facilitate the trade of private data by determining which data owners to purchase data from, the amount of privacy purchased, and providing specific aggregation statistics while protecting the privacy of data owners. However, existing PDQS with separated procurement and query processes are prone to over-perturbation of private data and lack trustworthiness. To address this issue, this paper proposes a framework for PDQS with an integrated procurement and query process to avoid excessive perturbation of private data. We also present two instances of this framework, one based on a greedy approach and another based on a neural network. Our experimental results show that both of our mechanisms outperformed the separately conducted procurement and query mechanism under the same budget regarding accuracy.   
   
 1062  Knowledge Injection for Multiagent Systems via Counterfactual Perception Shaping   
   
  Authors: Nicholas A Zerbel ; Kagan Tumer   
  ##MORE##Reward shaping can be used to train coordinated agent teams, but most learning approaches optimize for training conditions and by design, are limited by knowledge directly captured by the reward function. Advances in adaptive systems (e.g., transfer learning) may enable agents to quickly learn new policies in response to changing conditions, but retraining agents is both difficult and risks losing team coordination altogether. In this work we introduce Counterfactual Knowledge Injection (CKI), a novel approach to injecting high-level information into a multiagent system outside of the learning process. CKI encodes knowledge into counterfactual state representations to shape agent perceptions of the system so that their current policies better match the current system conditions. We demonstrate CKI in a multiagent exploration task where agents must collaborate to observe various Points of Interest (POI). We show that CKI successfully imparts high-level system knowledge to agents in response to imperceptible changes. We also show that CKI enables agents to adjust their level of agent-to-agent coordination ranging from tasks individuals can complete up to tasks that require the entire team.   
   
 1063  Reinforcement Learning In RDPs by Combining Deep RL with Automata Learning   
   
  Authors: Tal Shahar ; Ronen I. Brafman   
  ##MORE##Regular Decision Processes (RDPs) are a recently introduced model for decision making in non-Markovian domains in which states are not postulated a-priori, and the next observation depends in a regular manner on past history. As such, they provide a more succinct and understandable model of the dynamics and reward function. Existing algorithms for learning RDPs attempt to learn an automaton that reflects the regularity of the underlying domain. However, their scalability is limited due to the practical difficulty of learning automata. In this paper we propose to leverage the power of Deep reinforcement learning in partially observable domain to learn RDPs: First, we learn an RNN-based policy. Then, we generate an automaton that reflects the policy’s structure, and use our old data to transform it into an MDP, which we solve. This results in both a more explainable policy structure, and, as our empirical evaluation on old and new RDP benchmarks shows, better sample-complexity.   
   
 1065  Reinforcement Learning With Reward Machines in Stochastic Games   
   
  Authors: Jueming Hu ; Jean-Raphaël Gaglione ; YANZE WANG ; Zhe Xu ; Ufuk Topcu ; Yongming Liu   
  ##MORE##We investigate multi-agent reinforcement learning for stochastic games with complex tasks, where the reward functions are non-Markovian. We utilize reward machines to incorporate high-level knowledge of complex tasks. We develop an algorithm called Q-learning with Reward Machines for Stochastic Games (QRM-SG), to learn the best-response strategy at Nash equilibrium for each agent. In QRM-SG, we define the Q-function at a Nash equilibrium in augmented state space. The augmented state space integrates the state of the stochastic game and the state of reward machines. Each agent learns the Q-functions of all agents in the system. We prove that Q-functions learned in QRM-SG converge to the Q-functions at a Nash equilibrium if the stage game at each time step during learning has a global optimum point or a saddle point, and the agents update Q-functions based on the best-response strategy at this point. We use the Lemke-Howson method to derive the best-response strategy given current Q-functions. The three case studies show that QRM-SG can learn the best-response strategies effectively. QRM-SG learns the best-response strategies after around 7500 episodes in Case Study I, 1000 episodes in Case Study II, and 1500 episodes in Case Study III, while baseline methods such as Nash Q-learning and MADDPG fail to converge to the Nash equilibrium in all three case studies.   
   
 1067  Transferring Procedural Knowledge across Commonsense Tasks   
   
  Authors: Yifan Jiang ; Kaixin Ma ; Filip Ilievski   
  ##MORE##Stories about everyday situations are an essential part of human communication, motivating the need to develop AI agents that can reliably understand these stories. Despite the long list of supervised methods for story completion and procedural understanding, current AI fails to generalize its procedural reasoning to unseen stories. This paper is based on the hypothesis that the generalization can be improved by associating downstream prediction with fine-grained modeling and the abstraction of procedural knowledge in stories. To test this hypothesis, we design LEAP: a comprehensive framework that reasons over stories by jointly considering their (1) overall plausibility, (2) conflict sentence pairs, and (3) participant physical states. LEAP integrates state-of-the-art modeling architectures, training regimes, and augmentation strategies based on natural and synthetic stories. To address the lack of densely annotated training data on participants and their physical states, we devise a robust automatic labeler based on semantic parsing and few-shot prompting with large language models. Our experiments with in- and out-of-domain tasks reveal insights into the interplay of architectures, training regimes, and augmentation strategies. LEAP’s labeler consistently improves performance on out-of-domain datasets, while our case studies show that the dense annotation supports explainability.   
   
 1075  TASK-SENSITIVE DISCRIMINATIVE MUTUAL ATTENTION NETWORK FOR FEW-SHOT LEARNING   
   
  Authors: Baogui Xu ; Chengjin Xu ; Zhiwu Lu ; Bing Su   
  ##MORE##Many few-shot image classification methods focus on learning a fixed feature space from sufficient samples of seen classes that can be readily transferred to unseen classes. For different tasks, the feature space is either kept the same or only adjusted by generating attentions to query samples. However, the discriminative channels and spatial parts for comparing different query and support images in different tasks are usually different. In this paper, we propose a task-sensitive discriminative mutual attention (TDMA) network to produce task-and-sample-specific features. For each task, TDMA first generates a discriminative task embedding that encodes the inter-class separability and within-class scatter, and then employs the task embedding to enhance discriminative channels respective to this task. Given a specific query and different support images, TDMA further incorporates the task embedding and long-range dependencies to locate the discriminative parts in the spatial dimension. Experimental results on miniImageNet, tieredImageNet and FC100 datasets show the effectiveness of the proposed model.   
   
 1090  Multi-aspect Enhanced Convolutional Neural Networks for Knowledge Graph Completion   
   
  Authors: Fu Zhang ; Pengpeng Qiu ; Tong Shen ; Jingwei Cheng   
  ##MORE##Knowledge graph completion (KGC, also referred to as link prediction) aims at predicting missing entities and relations in knowledge graphs (KGs). Knowledge graph embedding (KGE) techniques have been proven to be effective for link prediction. Currently, a series of convolutional neural networks (CNNs) based models (e.g., ConvE and its extended models) have attained excellent results for link prediction. However, several aspects that are important for link prediction using CNNs have not been considered and enhanced simultaneously, which signiﬁcantly limit the performance of these models. In this paper we explore an effective KGE model based on CNNs. We investigate and discover four extremely important aspects that have a strong inﬂuence on ConvE: entity and relation embeddings, entity-to-relation interaction approaches, CNN structure, and loss function. Based on the optimization of the above four aspects, we propose a novel KGE method called ConvEICF. Through extensive experiments, we ﬁnd that ConvEICF outperforms the previous state-of-the-art link prediction baselines on FB15k-237 and WN18RR datasets. In particular, ConvEICF achieves a Hits@10 score that is 11.2% and 6.5% better than ConvE on FB15k-237 and WN18RR datasets respectively. Additionally, through in-depth experiments we observe an interesting phenomenon and important ﬁnding that the very common 1-N scoring technique in KGE can be considerably improved by just adding a dropout operation. Our code is available at https://github.com/NEU-IDKE/ConvEICF  .   
   
 1091  Multi-modal Fusion with Semantic Supervision for Radiology Report Generation   
   
  Authors: Xing Jia ; Yun Xiong ; Yao Zhang ; Li Luo   
  ##MORE##Radiology report generation, as one way of analyzing radiology images, is to generate a textual report automatically for the given image, and it is of great significance to assist diagnosis and alleviate the workload of radiologists. Some report generation methods have been therefore proposed. However, these methods suffer from the problem of low-quality generation, because of the visual and textual bias and training with text similarity oriented objective. To solve this problem, we propose a novel radiology report generation model with multi-modal fusion and semantic supervision, namely MS-Gen. MS-Gen consists of two main components, i.e., the semantic-visual fusion module and the semantic weighted contrastive loss. Specifically, the main idea of the semantic-visual fusion module is to make use of the domain-specific prior knowledge contained in a large pre-trained visual-language model and also the complementary nature between the image and text modalities. Moreover, a novel optimization term, i.e., the semantic weighted contrastive loss, is proposed to guide the optimization process with semantic similarity objective, and further enforce the generated reports with higher clinical accuracy. Extensive experiments conducted on two real datasets of IU X-Ray and MIMIC-CXR demonstrate the effectiveness of our proposed model.   
   
 1102  FASTC: A Fast Attentional Framework for Semantic Traversability Classification Using Point Cloud   
   
  Authors: Yirui Chen ; Pengjin Wei ; Zhenhuan Liu ; Bingchao Wang ; Jie Yang ; Wei Liu   
  ##MORE##Producing traversability maps and understanding the surroundings are crucial prerequisites for autonomous navigation. In this paper, we address the problem of traversability assessment using point clouds. We propose a novel pillar feature extraction module that utilizes PointNet to capture features from point clouds organized in vertical volume, and a 2D encoder-decoder structure to conduct traversability classification instead of the widely used 3D convolutions. This results in less computational cost while even better performance is achieved at the same time. We then propose a new spatiotemporal attention module to fuse multi-frame information, which can properly handle the varying density problem of LIDAR point clouds, and this makes our module able to assess distant areas more accurately. Comprehensive experimental results on augmented Semantic KITTI and RELLIS-3D datasets show that our method is able to achieve superior performance over existing approaches both quantitatively and quantitatively.   
   
 1106  Model-based Offline Policy Optimization with Adversarial Network   
   
  Authors: Junming Yang ; Xingguo Chen ; Shengyuan Wang ; Bolei Zhang   
  ##MORE##Model-based offline reinforcement learning (RL), which builds a supervised transition model with logging dataset to avoid costly interactions with the online environment, has been a promising approach for offline policy optimization. As the discrepancy between the logging data and online environment may result in a distributional shift problem, many prior works have studied how to build robust transition models conservatively and estimate the model uncertainty accurately. However, the over-conservatism can limit the exploration of the agent, and the uncertainty estimates may be unreliable. In this work, we propose a novel Model-based Offline policy optimization framework with Adversarial Network (MOAN). The key idea is to use adversarial learning to build a transition model with better generalization, where an adversary is introduced to distinguish between in-distribution and out-of-distribution samples. Moreover, the adversary can naturally provide a quantification of the model's uncertainty with theoretical guarantees. Extensive experiments showed that our approach outperforms existing state-of-the-art baselines on widely studied offline RL benchmarks. It can also generate diverse in-distribution samples, and quantify the uncertainty more accurately.   
   
 1107  Fast Pareto Optimization Using Sliding Window Selection   
   
  Authors: Frank Neumann ; Carsten Witt   
  ##MORE##Pareto optimization using evolutionary multi-objective algorithms has been widely applied to solve constrained submodular optimization problems. A crucial factor determining the runtime of the used evolutionary algorithms to obtain good approximations is the population size of the algorithms which grows with the number of trade-offs that the algorithms encounter. In this paper, we introduce a sliding window speed up technique for recently introduced algorithms. We prove that our technique eliminates the population size as a crucial factor negatively impacting the runtime and achieves the same theoretical performance guarantees as previous approaches within less computation time. Our experimental investigations for the classical maximum voverage problem confirms that our sliding window technique clearly leads to better results for a wide range of instances and constraint settings.   
   
 1114  Story Ending Generation using Commonsense Casual Reasoning and Graph Convolutional Networks   
   
  Authors: Eunkyung Park ; Raymond K Wong ; Victor W. Chu   
  ##MORE##Story Ending Generation is the task of generating a coherent and sensible ending for a given story. The key challenges of this task are i) how to obtain a good understanding of context, ii) how to capture hidden information between lines, and iii) how to obtain causal progression. However, recent machine learning-based models can only partially address these challenges due to the lack of causal entailment and consistency. The key novelty in our proposed approach is to capture the hidden story by generating transitional commonsense sentences between each adjacent context sentence, which substantially enriches causal and consistent story flow. Specifically, we adopt a soft causal relation using people's everyday commonsense knowledge to mimic the cognitive understanding process of readers. We then enrich the story with causal reasoning and utilize dependency parsing to capture long-range text relations. Finally, we apply multi-level Graph Convolutional Networks to deliver enriched contextual information across different layers. Both automatic and human evaluation results show that our proposed model can significantly improve the quality of generated story endings.   
   
 1115  Selective Learning for Sample-Efficient Training in Multi-Agent Sparse Reward Tasks   
   
  Authors: Xinning Chen ; Xuan Liu ; Yanwen Ba ; Shigeng Zhang ; Bo Ding ; Kenli Li   
  ##MORE##Learning effective strategies in sparse reward tasks is one of the fundamental challenges in reinforcement learning. This becomes extremely difficult in multi-agent environments, as the concurrent learning of multiple agents induces the non-stationarity problem and sharply increased joint state space. Existing works have attempted to promote multi-agent cooperation through experience sharing. However, learning from a large collection of shared experiences is inefficient as there are only a few high-value states in sparse reward tasks, which may instead lead to the curse of dimensionality in large-scale multi-agent systems. This paper focuses on sparse-reward multi-agent cooperative tasks and proposes an effective experience-sharing method MASL (Multi-Agent Selective Learning) to boost sample-efficient training by reusing valuable experiences from other agents. MASL adopts a retrogression-based selection method to identify high-value traces of agents from the team rewards, based on which some recall traces are generated and shared among agents to motivate effective exploration. Moreover, MASL selectively considers information from other agents to cope with the non-stationarity issue while enabling efficient training for large-scale agents. Experimental results show that MASL significantly improves sample efficiency compared with state-of-art MARL algorithms in cooperative tasks with sparse rewards.   
   
 1117  Long Tail Theory under Gaussian Mixtures   
   
  Authors: Zhenisbek Assylbekov ; Maxat Tezekbayev ; Igor Melnykov ; Artur Pak ; Arman Bolatov ; Vassilina Nikoulina   
  ##MORE##We suggest a simple Gaussian mixture model for data generation that complies with Feldman's long tail theory. We demonstrate that a linear classifier cannot decrease the generalization error below a certain level in the proposed model, whereas a nonlinear classifier with a memorization capacity can. This confirms that under long-tailed distribution, rare training examples must be considered for optimal generalization to new data. Finally, we show that the performance gap between linear and nonlinear models lessens as the tail becomes shorter in the subpopulation frequency distribution, confirmed by experiments on synthetic and real data.   
   
 1120  Multiplicative Sparse Tensor Factorization for Multi-View Multi-Task Learning   
   
  Authors: Xinyi Wang ; Lu Sun ; Canh Hao Nguyen ; Hiroshi Mamitsuka   
  ##MORE##Multi-View Multi-Task Learning (MVMTL) aims to make predictions on dual-heterogeneous data. Such data contains features from multiple views, and multiple tasks in the data are related with each other through common views. Existing MVMTL methods usually face two major challenges: 1) to save the predictive information from full-order interactions between views efficiently. 2) to learn a parsimonious and highly interpretable model such that the target is related to the features through a subset of interactions. To deal with the challenges, we propose a novel MVMTL method based on multiplicative sparse tensor factorization. For 1), we represent full-order interactions between views as a tensor, that enables to capture the complex correlations in dual-heterogeneous data by a concise model. For 2), we decompose the interaction tensor into a product of two components: one being shared with all tasks and the other being specific to individual tasks. Moreover, tensor factorization is applied to control the model complexity and learn a consensus latent representation shared by multiple tasks. Theoretical analysis reveals the equivalence between our method and a family of models with a joint but more general form of regularizers. Experiments on both synthetic and real-world datasets prove its effectiveness.   
   
 1128  Heteroscedastic Causal Structure Learning   
   
  Authors: Bao Duong ; Thin Nguyen   
  ##MORE##Heretofore, learning the directed acyclic graphs (DAGs) that encode the cause-effect relationships embedded in observational data is a computationally intensive problem. A recent trend of studies has shown that it is possible to recover the DAGs with polynomial time complexity under the equal variances assumption. However, this prohibits the heteroscedasticity of the noise, which allows for more flexible modeling capabilities, but at the same time is substantially more challenging to handle. In this study, we tackle the heteroscedastic causal structure learning problem under Gaussian noises. By exploiting the normality of the causal mechanisms, we can recover a valid causal ordering, which can uniquely identifies the causal DAG using a series of conditional independence tests. The result is HOST (Heteroscedastic causal STructure learning), a simple yet effective causal structure learning algorithm that scales polynomially in both sample size and dimensionality. In addition, via extensive empirical evaluations on a wide range of both controlled and real datasets, we show that the proposed HOST method is competitive with state-of-the-art approaches in both the causal order learning and structure learning problems.   
   
 1129  Robust Federated Learning Method against Data and Model Poisoning Attacks with Heterogeneous Data Distribution   
   
  Authors: Ebtisaam Alharbi ; Leandro Soriano Marcolino ; Antonios Gouglidis ; Qiang Ni   
  ##MORE##Federated Learning (FL) is essential for building global models across distributed environments. However, it is significantly vulnerable to data and model poisoning attacks that can critically compromise the accuracy and reliability of the global model. These vulnerabilities become more pronounced in heterogeneous environments, where clients’ data distributions vary broadly, creating a challenging setting for maintaining model integrity. Furthermore, malicious attacks can exploit this heterogeneity, manipulating the learning process to degrade the model or even induce it to learn incorrect patterns. In response to these challenges, we introduce RFCL, a novel Robust Federated aggregation method that leverages CLustering and cosine similarity to select similar cluster models, effectively defending against data and model poisoning attacks even amidst high data heterogeneity. Our experiments assess RFCL’s performance against  
  various attacker numbers and Non-IID degrees. The findings reveal that RFCL outperforms existing robust aggregation methods and demonstrates the capability to defend against multiple attack types.   
   
 1132  A Dynamic Selective Parameter Sharing Mechanism Embedded with Multi-Level Reasoning Abstractions   
   
  Authors: Yan Liu ; Ying He ; Zhong Ming ; F Richard Yu   
  ##MORE##Cooperative multi-agent reinforcement learning (Co-MARL) commonly employs different parameter sharing mechanisms, such as full and partial sharing. However, imprudent application of these mechanisms can potentially constrain policy diversity and limit cooperation flexibility. Recent methods that group agents into distinct sharing categories often exhibit poor performance due to challenges in precisely differentiating agents and neglecting the issue of promoting cooperation among these categories. To address these issues, we introduce a dynamic selective parameter sharing mechanism embedded with multi-level reasoning abstractions (DSPS-MA). Our approach uses self-comparison sequences to infer agents' abstract concepts, defining the differences between agents and allowing them to dynamically select partners to share parameters based on these abstract concepts. We also design an intrinsic reward to offer comprehensive collaboration guidance for agents, and introduce a policy cosine similarity regularization term to ensure sufficient policy diversity. Empirical evaluations demonstrate that our approach yields higher returns and faster convergence than state-of-the-art methods.   
   
 1138  A Conditional Denoising Diffusion Probabilistic Model for Radio Interferometric Image Reconstruction   
   
  Authors: Ruoqi Wang ; Zhuoyang Z Chen ; Qiong Luo ; Feng Wang    
 ##MORE##In radio astronomy, signals from radio telescopes are transformed into images to observe celestial objects, or sources. However, these images, called dirty images, contain real sources as well as artifacts due to signal sparsity and other factors. Therefore, radio interferometric image reconstruction is performed on dirty images, aiming to produce clean images in which artifacts are reduced and real sources are recovered. So far, existing methods have limited success on recovering faint sources, preserving detailed structures, and eliminating artifacts. In this paper, we present VIC-DDPM, a Visibility and Image Conditioned Denoising Diffusion Probabilistic Model. Our main idea is to use both the original visibility data in the spectral domain and dirty images in the spatial domain to guide the image generation process with DDPM. This way, we can leverage DDPM to generate fine details and eliminate noise, while utilizing visibility data to separate signals from noise and retaining spatial information in dirty images. We have conducted experiments in comparison with both traditional methods and recent deep learning based approaches. Our results show that our method significantly improves the resulting images by reducing artifacts, preserving fine details, and recovering dim sources. This advancement further facilitates radio astronomical data analysis tasks on celestial phenomena. Our code is available at https://github.com/RapidsAtHKUST/VIC-DDPM  .   
 1142  Take Expert Advice Judiciously: Combining Groupwise Calibrated Model Probabilities with Expert Predictions   
   
  Authors: Sumeet Gupta ; Shweta Jain ; Dr. Shashi Shekhar Jha ; Pao-Ann Hsiung ; Ming-Hung Wang    
 ##MORE##Training the machine learning (ML) models require a large amount of data; however, the capacity of these models is limited. Recent literature focuses on combining ML models' predictions with human experts. This setting is known as the human-in-the-loop or human-AI team setting. Human experts can complement the ML models as they are well-equipped with vast real-world experience and sometimes have access to private information that may not be accessible while training the ML model. Existing approaches for combining an expert and ML model either require end-to-end training of the combined model or require expert annotations for every task. Such end-to-end training requires a custom loss function and human annotations, which is cumbersome, results in slower convergence, and may adversely impact the ML model's accuracy. On the other hand, using expert annotations for every task is also cost-ineffective. We propose a novel technique that optimizes the cost of seeking the expert's advice while utilizing the ML model's predictions to improve accuracy. Our model considers two intrinsic parameters: the expert's cost for each prediction and the misclassification cost of the combined human-AI model. Further, we present the impact of group-wise calibration on the combined model that improves the overall model's performance. Experimental results on our combined model with group-wise calibration show a significant increase in accuracy with limited expert advice against different established ML models for the image classification task. In addition, the combined model's accuracy is always greater than the ML model, irrespective of the expert's accuracy, the expert's cost, and the misclassification cost.   
 1144  Causally Disentangled Generative Variational AutoEncoder   
   
  Authors: Seung Hwan ; Kyungwoo Song ; Jong-June Jeon    
 ##MORE##We present a new supervised learning technique for the Variational AutoEncoder (VAE) that allows it to learn a causally disentangled representation and generate causally disentangled outcomes simultaneously. We call this approach Causally Disentangled Generation (CDG). CDG is a generative model that accurately decodes an output based on a causally disentangled representation. Our research demonstrates that adding supervised regularization to the encoder alone is insufficient for achieving a generative model with CDG, even for a simple task. Therefore, we explore the necessary and sufficient conditions for achieving CDG within a specific model. Additionally, we introduce a universal metric for evaluating the causal disentanglement of a generative model. Empirical results from both image and tabular datasets support our findings.   
 1154  Motivated Agent with Semantic Memory   
   
  Authors: Janusz Starzyk ; Marcin Kowalik ; Adrian Horzyk    
 ##MORE##This paper introduces a motivated agent scheme that enables an agent to create its own goals using prior knowledge about its environment. A motivated agent operates in a dynamically changing environment and is capable of setting and achieving its own goals, as well as those set by the designer. The agent has access to additional knowledge about the environment, which is represented in associative semantic memory. This memory is constructed based on ANAKG associative knowledge graphs, which have been shown to have several advantages over other semantic memories for processing symbolic sequential inputs. They are easy to organize and train. In this paper, we demonstrate that a motivated agent with semantic memory learns to achieve its goals more easily and utilizes environmental resources more effectively. To simplify comparisons with reinforcement learning, we represent the environment as an environmental graph that shows the principles governing it. By exploring the environment, the agent learns these principles and can use them to accomplish its tasks. Our experiments and tests confirm our claims about the higher efficiency of agents with memory. Moreover, an extensive comparison with reinforcement learning agents highlights the advantages of motivated learning over reinforcement learning.   
 1155  ESSL: Enhanced Spatio-temporal Self-selective Learning Framework for Unsupervised Video Anomaly Detection   
   
  Authors: Qun Li ; Xubei Pan ; Fu Xiao ; Bir Bhanu    
 ##MORE##Unsupervised Video Anomaly Detection (UVAD) utilizes completely unlabeled videos for training without any human intervention. Due to the existence of unlabeled abnormal videos in the training data, the performance of UVAD has a large gap compared with semi-supervised VAD, which only uses normal videos for training. To address the problem of insufficient ability of the existing UVAD methods to learn normality and reduce the negative impact of abnormal events, this paper proposes a novel Enhanced Spatio-temporal Self-selective Learning (ESSL) framework for UVAD. This framework is designed for capturing both the appearance and motion features through effective network structures by solving the spatial and temporal jigsaw puzzles. Specially, we develop a Self-selective Learning Module (SLM) for UVAD, which prevents the model learning abnormal features and enhances the model by selecting normal features. Experimental results on three benchmark datasets show that the proposed method not only surpasses the state-of-the-art UVAD works, but also achieves the performance comparable to the classic semi-supervised methods for video anomaly detection that needs normal videos selected manually.   
 1163  Accelerating SAT-Based HTN Plan Verification by Exploiting Data Structures from HTN Planning   
   
  Authors: Songtuan Lin ; Gregor Behnke ; Pascal Bercher    
 ##MORE##Plan verification is the task of deciding whether a given plan is a solution to a planning problem. In this paper, we study the plan verification problem in the context of Hierarchical Task Network (HTN) planning, which has been proved to be NP-complete when partial order (PO) is involved. We will develop a novel SAT-based approach exploiting the data structures solution order graphs and path decomposition trees which encodes an HTN plan verification problem as a SAT one. We show in our experiments that this new approach outperforms the current state-of-the-art (SOTA) planning-based approach for verifying plans for POHTN problems.   
 1169  Mechanism Design for Ad Auctions with Display Prices   
   
  Authors: Bin Li ; Lei Yahui    
 ##MORE##In various applications, ads are displayed together with prices, so as to provide a direct comparison among similar products or services. The price-displaying feature not only influences the consumers' decision, but also affects the bidding behavior of advertisers. In this paper, we study ad auctions with display prices from the perspective of mechanism design, in which advertisers are asked to submit both the product costs and the display prices of their commodities. We first provide a characterization for all individually rational and incentive-compatible mechanisms in the presence of display prices, then use it to design ad auctions in two scenarios. In the former scenario, the display prices are assumed to be exogenously determined. For this scenario, we derive the welfare-maximizing and revenue-maximizing auctions for any given display price profile. In the latter, advertisers are allowed to strategize their display prices freely. We investigate two families of allocation policies within the scenario and identify the equilibrium display prices accordingly. Our findings demonstrate the impact of display prices on the design of ad auctions, and highlight how platforms can utilize display price information to optimize the performance of ad delivery.   
 1174  Detecting Out-of-distribution Objects Using Neuron Activation Patterns   
   
  Authors: Bartlomiej Olber ; Krystian Radlak ; Krystian Chachuła ; Piotr Frątczak ; Jakub Łyskawa    
 ##MORE##Object detection is an essential part of many perception algorithms used in modern robotics applications. Unfortunately, the existing models share a tendency to assign high confidence scores for out-of-distribution (OOD) samples. Although OOD detection has been extensively studied in recent years among the computer vision community, most proposed solutions apply only to the image recognition task. Real-world applications such as perception in autonomous vehicle struggle with far more complex challenges than classification. In our work, we focus on the popular field of object detection, adapting Neuron Activation Patterns (NAP) for out-of-distribution samples detection in object detection (NAPTRON). Our experiments show that NAPTRON outperforms state-of-the-art methods, without the need to affect in-distribution (ID) performance. We evaluate the methods on two different OOD scenarios and three types of object detectors which makes the comparison the largest open-source benchmark for OOD object detection.   
 1175  Identifying the Defective: Detecting Damaged Grains for Cereal Appearance Inspection   
   
  Authors:  Lei Fan ; Yiwen Ding ; dongdong fan ; Yong Wu ; Maurice Pagnucco ; Yang Song    
 ##MORE##Cereal grain plays a crucial role in the human diet as a major source of essential nutrients. Grain Appearance Inspection (GAI) serves as an essential process to determine grain quality and facilitate grain circulation, storage and processing. However, GAI is routinely performed manually by inspectors with cumbersome and tedious procedures, which poses a significant bottleneck in grain safety and smart agriculture. Therefore, it is imperative to establish a fair and efficient GAI system to ensure grain safety, thus contributing to the achievement of ``Zero Hunger'' and ``Good Health and Well-being'' for ending poverty and other deprivations. In this paper, we endeavor to develop an automated GAI system: AI4GrainInsp. By analyzing the distinctive characteristics of grain kernels, we formulate GAI as a ubiquitous problem: Anomaly Detection (AD), in which healthy and edible kernels are considered normal samples while damaged grains or unknown objects are regarded as anomalies. We further propose an AD model, called AD-GAI, which is trained using only normal samples yet can identify anomalies during inference. Moreover, we customize a prototype device for data acquisition and create a large-scale dataset including 220K high-quality images of wheat and maize kernels. Through extensive experiments, AD-GAI achieves considerable performance in comparison with advanced AD methods, and AI4GrainInsp has highly consistent performance compared to human experts and excels at inspection efficiency over 20x speedup. The dataset, code and models will be released at (*******anonymous).   
 1182  A Siamese Based System For City Verification   
   
  Authors: Omran Alamayreh ; Jun Wang ; Giovanna Dimitri ; Benedetta Tondi ; Mauro Barni    
 ##MORE##Image geolocalization is receiving increasing attention due to its importance in several applications, such as image retrieval, criminal investigations and fact-checking. Previous works focused on several instances of image geolocalization including place recognition, GPS coordinates estimation and country recognition. In this paper, we tackle an even more challenging problem, which is recognizing the city where an image has been taken. Due to the vast number of cities in the world, we cast the problem as a verification problem, whereby the system has to decide whether a certain image has been taken in a given city or not. In particular, we present a system that given a query image and a small set of images taken in a target city, decides if the query image has been shot in the target city or not. To allow the system to handle the case of images, taken in cities that have not been used during training, we use a Siamese network based on Vision Transformer as a backbone. The experiments we run prove the validity of the proposed system which outperforms solutions based on state-of-the-art techniques, even in the challenging case of images shot in different cities of the same country.   
 1185  Learning Logic Programs by Combining Programs   
   
  Authors: Andrew Cropper ; Céline Hocquette    
 ##MORE##The goal of inductive logic programming is to induce a logic program (a set of logical rules) that generalises training examples. Inducing programs with many rules and literals is a major challenge. To tackle this challenge, we introduce an approach where we learn small 'non-separable' programs and combine them. We implement our approach in a generate, test, combine, and constrain loop. Our approach can learn optimal and recursive programs and perform predicate invention. Our experiments on multiple domains, including game playing and program synthesis, show that our approach can drastically outperform existing approaches in terms of predictive accuracies and learning times, sometimes reducing learning times from over one hour to a few seconds.   
 1186  Using Unsupervised Dual Constraint Contrastive Learning for Cross-modal Retrieval   
   
  Authors: Xintong Wang ; Xiaoyu Li ; Liang Ding ; Sanyuan Zhao ; Chris Biemann    
 ##MORE##In this work, we present an unsupervised dual constraint contrastive method for efficiently fine-tuning the vision-language pre-trained (VLP) models that have achieved great success on various cross-modal tasks, since full fine-tune these pre-trained models is computationally expensive and tend to result in catastrophic forgetting restricted by the size and quality of labeled datasets. Our approach freezes the pre-trained VLP models as the fundamental, generalized, and transferable multimodal representation and incorporates lightweight parameters to learn domain and task-specific features without labeled data. We demonstrated that our unsupervised dual contrastive model performs better than previous fine-tuning methods on MS COCO and Flickr 30K datasets on the cross-modal retrieval task, with an even more pronounced improvement in zero-shot performance. Furthermore, experiments on the MOTIF dataset prove that our unsupervised approach remains effective when trained on a small, out-of-domain dataset without overfitting. As a plug-and-play method, our proposed method is agnostic to the underlying models and can be easily integrated with different VLP models, allowing for the potential incorporation of future advancements in VLP models.   
 1192  Aspect-oriented Opinion Alignment Network for Aspect-Based Sentiment Classification   
   
  Authors: Xueyi Liu ; Rui Hou ; Yanglei Gan ; Da Luo ; ChangLin Li ; Xiaojun Shi ; Qiao Liu    
 ##MORE##Aspect-based sentiment classification is a crucial problem in fine-grained sentiment analysis, which aims to predict the sentiment polarity of the given aspect according to its context. Previous works have made remarkable progress in leveraging attention mechanism to extract opinion words for different aspects. However, a persistent challenge is the effective management of semantic mismatches, which stem from attention mechanisms that fall short in adequately aligning opinions words with their corresponding aspect in multi-aspect sentences. To address this issue, we propose a novel Aspect-oriented Opinion Alignment Network (AOAN) to capture the contextual association between opinion words and the corresponding aspect. Specifically, we first introduce a neighboring span enhanced module which highlights various compositions of neighboring words and given aspects. In addition, we design a multi-perspective attention mechanism that align relevant opinion information with respect to the given aspect. Extensive experiments on three benchmark datasets demonstrate that our model achieves state-of-the-art results. The source code is available at https://github.com/AONE-NLP/ABSA-AOAN  .   
 1195  Boosting Visual Question Answering through Geometric Perception and Region Features   
   
  Authors: Hong Yu ; Zhiyue Wang ; Yuanqiu Liu ; Han Liu    
 ##MORE##Visual question answering (VQA) is a crucial yet challenging task in multimodal understanding. To correctly answer questions about an image, VQA models are required to comprehend the fine-grained semantics of both the image and the question. Recent advances have shown that both grid and region features contribute to improving the VQA performance, while grid features surprisingly outperform region features. However, grid features will inevitably induce visual semantic noise due to fine granularity. Besides, the ignorance of geometric relationships makes VQA models difficult to understand the object relative positions in the image and answer questions accurately. In this paper, we propose a visual enhancement network for VQA that leverages region features and position information to enhance grid features, thus generating richer visual grid semantics. First, the grid enhancement multi-head guided attention module utilizes regions around the grid to provide visual context, forming rich visual grid semantics and effectively compensating for the fine granularity of the grid. Second, a novel geometric perception multi-head self-attention is introduced to process two types of features, incorporating geometric relations such as relative direction between objects while exploring internal semantic interactions. Extensive experiments demonstrate that the proposed method can obtain competitive results over other strong baselines.   
 1196  Sensitivity Analysis for Saturated Post-hoc Optimization in Classical Planning   
   
  Authors: Paul Höft ; David Speck ; Jendrik Seipp    
 ##MORE##Cost partitioning is the foundation of today's strongest heuristics for optimal classical planning. However, computing a cost partitioning for each evaluated state is prohibitively expensive in practice. Thus, existing approaches make an approximation and compute a cost partitioning only for a set of sampled states, and then reuse the resulting heuristics for all other states evaluated during the search. In this paper, we present exact methods for cost partitioning heuristics based on linear programming that fully preserve heuristic accuracy while minimizing computational cost. Specifically, we focus on saturated post-hoc optimization and establish several sufficient conditions for when reusing a cost partitioning computed for one state is optimal for other states, mainly based on a sensitivity analysis of the underlying linear program formulation. Our experiments demonstrate that our theoretical results transfer into practice and that our exact cost partitioning algorithms are competitive with the strongest approximations currently available while needing fewer linear program evaluations.   
 1197  Unsupervised Zero-shot learning to achieve cross-modal alignment with counterfactuals   
   
  Authors: Jinyang Tai ; Yike Guo    
 ##MORE##Zero-shot Learning is the process of transferring knowledge (Cross-modal mapping relationship) of the seen classes to unseen classes. However, the realization of this knowledge transfer process relies on a large number of expensive labels. Even if the model has labels, Zero-shot learning also has the phenomenon of 'negative causality' in the process of Cross-modal alignment. In this paper, We propose an unsupervised learning model and leverage a counterfactual causal inference framework for cross-modal mapping relationship adjustment (CMRA). Specifically, we aim to regard images as cause and Wikipedia text as effect form a causal relationship diagram. First, it uses multiple attributes attention to learn images semantic attributes and corresponding Wikipedia text description word to form Cross-modal alignment. Then, using contrastive learning and stop-gradient are combined to form a new Cross-modal mapping relationship. Finally, we compare whether multiple attributes attention has consistency in the distribution of semantic attributes learned before and after image transformation and the attentions with larger distributions are eliminated using an inactivation strategy. This model evaluates the classification accuracy in AWA, CUB, APY, SUN. The experimental results show that the algorithm outperforms the state-of-the-art algorithms technology approaches.   
 1201  Information Bound and its Applications in Bayesian Neural Networks   
   
  Authors: Jiaru Zhang ; Yang Hua ; Tao Song ; Hao Wang ; Zhengui Xue ; Ruhui Ma ; Haibing Guan    
 ##MORE##Bayesian neural networks (BNNs) have drawn extensive interest because of their distinctive probabilistic representation framework. However, despite its recent success, little work focuses on the information-theoretic understanding of Bayesian neural networks. In this paper, we propose Information Bound as a metric of the amount of information in Bayesian neural networks. Different from mutual information on deterministic neural networks where modification of network structure or specific input data is usually necessary, Information Bound can be easily estimated on current Bayesian neural networks without any modification of network structures or training processes. By observing the trend of Information Bound during training, we demonstrate the existence of the ``critical period'' in Bayesian neural networks. Besides, we show that the Information Bound can be used to judge the confidence of the model prediction and to detect out-of-distribution datasets. Based on these observations of model interpretation, we propose Information Bound regularization and Information Bound variance regularization methods. The Information Bound regularization encourages models to learn the minimum necessary information and improves the model generality and robustness. The Information Bound variance regularization encourages models to learn more about complex samples with low Information Bound. Extensive experiments on KMNIST, Fashion-MNIST, CIFAR-10, and CIFAR-100 verify the effectiveness of the proposed regularization methods.   
 1202  Expert-Free Online Transfer Learning in Multi-Agent Reinforcement Learning   
   
  Authors: Alberto Castagna ; Ivana Dusparic    
 ##MORE##Transfer learning in Reinforcement Learning (RL) has been widely studied to overcome training challenges in Deep-RL, i.e., exploration cost, data availability and convergence time, by bootstrapping external knowledge to enhance learning phase. While this overcomes the training issues on a novice agent, a good understanding of the task by the expert agent is required for such a transfer to be effective. As an alternative, in this paper we propose Expert-Free Online Transfer Learning (EF-OnTL), an algorithm that enables expert-free real-time dynamic transfer learning in multi-agent system. No dedicated expert agent exists, and transfer source agent and knowledge to be transferred are dynamically selected at each transfer step based on agents’ performance and level of uncertainty. To improve uncertainty estimation, we also propose State Action Reward Next-State Random Network Distillation (sars-RND), an extension of RND that estimates uncertainty from RL agent-environment interaction. We demonstrate EF-OnTL effectiveness against a no-transfer scenario and state-of-the-art advice-based baselines, with and without expert agents, in three benchmark tasks: Cart-Pole, a grid-based Multi-Team Predator-Prey (MT-PP) and Half Field Offense (HFO). Our results show that EF-OnTL achieves overall comparable performance to that of advice-based approaches, while not requiring expert agents, external input, nor threshold tuning. EF-OnTL outperforms no-transfer with an improvement related to the complexity of the task addressed.   
 1205  Overlay Neural Networks for Heterophilous Graphs   
   
  Author: Giuseppe Pirrò    
 ##MORE##The popularity of Graph Neural Networks (GNNs) has soared due to their proficiency in encapsulating intricate connections among graphs by aggregating information from (the immediate) node neighbors. Nonetheless, when dealing with graphs displaying a high degree of heterophily, the GNN performance declines as the faraway nodes that are pertinent to the task at hand are ignored during node aggregation. To contend with the issue of integrating long-range neighbors that are relevant into the GNN node aggregation mechanism, this paper introduces a model called the Overlay Graph Neural Networks (OGN). OGN is inspired by P2P overlay networks, where the idea is to find neighbor peers (nodes) that, although not directly connected to a given node (a peer), are semantically similar and could favorably improve both query routing and query results. In the context of OGN, the network refers to the graph, and the message passing procedure executed by a GNN to aggregate node features represents the routing process. OGN networks are built by stacking one or more overlay layers, each taking as input the graph and a node feature matrix either available or derivable (e.g., by analyzing the graph’s structure). Each overlay layer combines base embeddings, learned by considering node features and short-range node neighbors, with overlay embeddings computed by projecting nodes with similar features close in an overlay space and then aggregating (overlay) neighbor nodes via a sliding window attention mechanism. Base and overlay embeddings are combined to capture nodes’ immediate and global context in a graph. We evaluate OGN in a node classification task using state-of-the-art benchmarks and show that the OGN model is competitive with the advantage of being easily portable to any existing GNN model.   
 1206  Efficiently Computing Smallest Agreeable Sets   
   
  Authors: Robert Bredereck ; Till Fluschnik ; Nimrod Talmon    
 ##MORE##We study the computational complexity of identifying a small agreeable subset of items. A subset of items is agreeable if every agent does not prefer its complement set. We study the setting where agents can give arbitrary utilities to the items, can only approve or disapprove items, or rank the items with Borda scores. We prove all variants NP-hard, and perform a parameterized analysis regarding the natural parameters number of agents, number of items, and the upper bound on the size of the agreeable subset in question.   
 1208  Adversarial Erasing with Pruned Elements: Towards Better Graph Lottery Ticket   
   
  Authors: Yuwen Wang ; Shunyu Liu ; Kaixuan Chen ; Tongtian Zhu ; Ji Qiao ; Mengjie Shi ; Yuanyu Wan ; Mingli Song    
 ##MORE##Graph Lottery Ticket (GLT), a combination of core subgraph and sparse subnetwork, has been proposed to mitigate the computational cost of deep Graph Neural Networks (GNNs) on large input graphs while preserving original performance. However, the winning GLTs in exisiting studies are obtained by applying iterative magnitude-based pruning (IMP) without re-evaluating and re-considering the pruned information, which disregards the dynamic changes in the significance of edges/weights during graph/model structure pruning, and thus limits the appeal of the winning tickets. In this paper, we formulate a conjecture, i.e., existing overlooked valuable information in the pruned graph connections and model parameters which can be re-grouped into GLT to enhance the final performance. Specifically, we propose an adversarial complementary erasing (ACE) framework to explore the valuable information from the pruned components, thereby developing a more powerful GLT, referred to as the ACE-GLT. The main idea is to mine valuable information from pruned edges/weights after each round of IMP, and employ the ACE technique to refine the GLT processing. Finally, experimental results demonstrate that our ACE-GLT outperforms existing methods for searching GLT in diverse tasks. Our code will be made publicly available.   
 1231  ALFR++: A novel algorithm for Learning Adversarial Fair Representations   
   
  Author: Max Knobbout    
 ##MORE##As more decisions in our daily life become automated, the need to have machine learning algorithms that make fair decisions increases. In fair representation learning we are tasked with finding a suitable representation of the data in which a sensitive variable is censored. Recent work aims to learn fair representations through adversarial learning. With this paper, we build upon this work by introducing a novel algorithm, ALFR++, to learn adversarial fair representations independent of the downstream task that may be encountered (supervised or unsupervised). We introduce balanced error rate modulation, to stabilize the interaction between actor and adversary. We couple it with a recently introduced censoring technique called stacking, to learn strong censored representations within a restricted hypothesis space. Results show that our algorithm improves on previous work in both censoring and reconstruction, allowing us to create fairer data without knowing the task beforehand.   
 1235  Active Finetuning Protein Language Model: A Budget-Friendly Method for Directed Evolution   
   
  Authors: Ming Qin ; Keyan Ding ; Bin Wu ; Zhenping Li ; Haihong Yang ; Zeyuan Wang ; Hongbin Ye ; Haoran Yu ; Huajun Chen ; Qiang Zhang    
 ##MORE##Directed evolution is a widely-used strategy of protein engineering to improve protein function via mimicking natural mutation and selection. Machine learning-assisted directed evolution(MLDE) approaches aim to learn a fitness predictor, thereby efficiently searching for optimal mutants within the vast combinatorial mutation space. Since annotating mutants is both costly and labor-intensive, how to efficiently sample and utilize informative protein mutants to train the predictor is a critical problem in MLDE. Previous MLDE works just simply utilized pre-trained protein language models (PPLMs) for sampling without tailoring to the specific target protein of interest, which has not fully exploited the potential of PPLMs. In this work, we propose a novel method, the Actively-Finetuned Protein model for Directed Evolution(AFP-DE) which leverages PPLMs to actively sample and fine-tune themselves, continuously improving the model’s sampling and overall performance through iterations, to achieve efficiently directed protein evolution. Extensive experiments have shown the effectiveness of our method in generating optimal mutants with minimal annotation effort, outperforming previous works even with fewer annotated mutants, making it budget-friendly for biological experiments.   
 1262  Theoretical remarks on feudal hierarchies and reinforcement learning   
   
  Authors: Diogo S Carvalho ; Francisco S. Melo ; Pedro A Santos    
 ##MORE##Hierarchical reinforcement learning is an increasingly demanded resource for learning to make sequential decisions towards long term goals with successful credit assignment and temporal abstraction. Feudal hierarchies are among the most deployed frameworks. However, there is lack of formalism over the hierarchical structure and of theoretical guarantees. We formalize the common two-level feudal hierarchy as two Markov decision processes, with the one on the high-level being dependent on the policy executed at the low-level. Despite the non-stationarity raised by the dependency, we show that each of the processes presents stable behavior. We then build on the first result to show that, regardless of the convergent learning algorithm used for the low-level, convergence of both prediction and control algorithms at the high-level is guaranteed with probability 1. Our results contribute with theoretical support for the use of feudal hierarchies in combination with standard reinforcement learning methods at each level.   
 1266  Characterizations of Network Auctions and Generalizations of VCG   
   
  Authors: Mingyu Xiao ; Guixin Lin ; Bakh Khoussainov ; Yuchao Song    
 ##MORE##With the growth of networks, promoting products through social networks has become an important problem. For auctions in social networks, items are needed to be sold to agents in a network, where each agent can bid and also diffuse the sale information to her neighbors. Thus, the agents' social relations are intervened with their bids in the auctions. In network auctions, the classical VCG mechanism fails to retain key properties. In order to better understand network auctions, in this paper, we characterize network auctions for the single-unit setting with respect to IR, WBB, IC, efficiency, and other properties. For example, we present sufficient conditions for mechanisms to be efficient and (weakly) incentive compatible. With the help of these properties and new concepts such as rewards, participation rewards, and so on, we show how to design efficient mechanisms to satisfy IC as much as possible, and IC mechanisms to maximize the revenue. Our results provide insights into understanding auctions in social networks.   
 1276  Enhancing Dyadic Relations with Homogeneous Graphs for Multimodal Recommendation   
   
  Authors: Hongyu Zhou ; Xin Zhou ; lingzi zhang ; Zhiqi Shen    
 ##MORE##User-item interaction data in recommender systems is a form of dyadic relation, reflecting user preferences for specific items. To generate accurate recommendations, it is crucial to learn representations for both users and items. Recent multimodal recommendation models achieve higher accuracy by incorporating multimodal features, such as images and text descriptions. However, our experimental findings reveal that current multimodality fusion methods employed in state-of-the-art models may adversely affect recommendation performance without compromising model architectures. Moreover, these models seldom investigate internal relations between item-item and user-user interactions. In light of these findings, we propose a model that enhances the dyadic relations by learning Dual RepresentAtions of both users and items via constructing homogeneous Graphs for multimOdal recommeNdation. We name our model as DRAGON. Specifically, DRAGON constructs user-user graphs based on commonly interacted items and item-item graphs derived from item multimodal features. Graph learning on both the user-item heterogeneous and homogeneous graphs is used to obtain dual representations of users and items. To capture information from each modality, DRAGON employs an effective fusion method, attentive concatenation. Extensive experiments on three public datasets and eight baselines show that DRAGON can outperform the strongest baseline by 21.41% on average.   
 1279  Unsupervised Graph Structure-Assisted Personalized Federated Learning   
   
  Authors: Xiaoying Li ; Xiaojun CHEN ; Bisheng Tang ; Shaopu Wang ; Yuexin Xuan ; Zhendong Zhao    
 ##MORE##Non-IID data presents a significant challenge for federated learning, and personalized Federated Learning(FL) is a natural solution to address this challenge. Recently, Graph Neural Network (GNN) has recently emerged to model the complex client relationship using a client graph to refine personalized models. However, this approach depends on an existing client relation graph on the server, making it impractical unless this prerequisite is satisfied. Furthermore, noisy and missing connections in the original graph structures can degrade personalization performance. In this work, we propose an unsupervised structure learning approach to improve personalized FL, where the server learns a dynamic client graph through self-supervision and generates structure-based client representations. These representations are then broadcasted to users, regulating local training using the learned knowledge as an inductive bias. Empirical studies on benchmark datasets demonstrate the significant effectiveness of our approach and the high quality of the client graphs.   
 1289  Cognitive effects in large language models   
   
  Authors: Jonathan Shaki ; Sarit Kraus ; Michael Wooldridge    
 ##MORE##Large Language Models (LLMs) such as ChatGPT have received enormous attention over the past year, and are now used by hundreds of millions of people every day. The rapid adoption of this technology naturally raises serious questions about the possible biases that such models might exhibit. In this work, we tested one of these models (GPT-3) on a range of cognitive effects, which are systematic patterns that are usually found in human cognition. We found that such models are indeed prone to a number of human cognitive effects. Specifically, we show that the \emph{priming}, \emph{distance}, \emph{SNARC}, and \emph{size congruity} effects were presented with GPT-3, while the \emph{anchoring} effect is absent. We describe our methodology, and specifically the way we converted real-world experiments to text-based experiments. Finally, we speculate on the possible reasons why GPT-3 exhibits these effects, and discuss the question of whether they are imitated or reinvented.   
 1299  Cooperative Thresholded Lasso for Sparse Linear Bandit Problems   
   
  Authors: Haniyeh Barghi ; Xiaotong Cheng ; Setareh Maghsudi    
 ##MORE##We present a novel approach to address the multi-agent sparse contextual linear bandit problem, in which the feature vectors have a high dimension $d$ whereas the reward function depends on only a limited set of features - precisely $s_0 \ll d$. Furthermore, the learning follows under information-sharing constraints. The proposed method employs Lasso regression for dimension reduction, allowing each agent to independently estimate an approximate set of main dimensions and share that information with others depending on the network's structure. The information is then aggregated through a specific process and shared with all agents. Each agent then resolves the problem with ridge regression focusing solely on the extracted dimensions. We represent algorithms for both a star-shaped network and a peer-to-peer network. The approaches effectively reduce communication costs while ensuring minimal cumulative regret per agent. Theoretically, we show that our proposed methods have a probabilistic regret bound of order $\mathcal{O}(s_0 \log d + s_0 \sqrt{T})$, where $T$ is the time horizon. To our best knowledge, it is the first algorithm that tackles row-wise distributed data in sparse linear bandits, achieving comparable performance compared to the state-of-the-art single and multi-agent methods. Besides, it is widely applicable to high-dimensional multi-agent problems where efficient feature extraction is critical for minimizing regret. To validate the effectiveness of our approach, we present experimental results on both synthetic and real-world datasets.   
 1304  High Probability Analysis for Non-Convex Stochastic Optimization with Clipping   
   
  Authors: Shaojie Li ; Yong Liu    
 ##MORE##Gradient clipping is a commonly used technique to stabilize the training process of neural networks. A growing body of studies has shown that gradient clipping is a promising technique for dealing with the heavy-tailed behavior that emerged in stochastic optimization as well. While gradient clipping is significant, its theoretical guarantees are scarce. Most theoretical guarantees only provide an in-expectation analysis and only focus on optimization performance. In this paper, we provide high probability analysis in the non-convex setting and derive the optimization bound and the generalization bound simultaneously for popular stochastic optimization algorithms with gradient clipping, including stochastic gradient descent and its variants of momentum and adaptive stepsizes. With the gradient clipping, we study a heavy-tailed assumption that the gradients only have bounded $\alpha$-th moments for some $\alpha \in (1, 2]$, which is much weaker than the standard bounded second-moment assumption. Overall, our study provides a relatively complete picture for the theoretical guarantee of stochastic optimization algorithms with clipping.   
 1308  Do Not Trust Me: Explainability Against Text Classification   
   
  Authors: Mateusz Gniewkowski ; Marek Klonowski ; Piotr Syga ; Paweł Walkowiak ; Tomasz Walkowiak    
 ##MORE##Explaining artificial intelligence models can be utilized to launch targeted adversarial attacks on text classification algorithms. Understanding the reasoning behind the model's decisions makes it easier to prepare such samples. Most of the current text-based adversarial attacks rely on brute-force by using SHAP approach to identify the importance of tokens in the samples, we modify the crucial ones to prepare targeted attacks. We base our results on experiments using 5 datasets. Our results show that our approach outperforms TextBugger and TextFooler, achieving better results with 4 out of 5 datasets against TextBugger, and 3 out of 5 datasets against TextFooler, while minimizing perturbation introduced to the texts. In particular, we managed to outperform the efficacy of TextFooler by over 1900% and TextBugger by over 200% on the WikiPL dataset, additionally keeping high cosine similarity between the original text sample and the adversarial example. The evaluation of the results was additionally supported through a survey to assess their quality and ensure that the text perturbations did not change the intended class according to subjective, human classification.   
 1317  Identifying Helpful Learnwares without Examining the Whole Market   
   
  Authors: Yi Xie ; Zhi-Hao Tan ; Yuan Jiang ; Zhi-Hua Zhou    
 ##MORE##The learnware paradigm aims to construct a market of numerous well-performing machine learning models, which enables users to leverage these models to accomplish specific tasks without having to build models from scratch. Each learnware in the market is a model associated with a specification, representing the model's utility and enabling it to be identified according to future users' requirements. In the learnware paradigm, due to the vast and ever-increasing number of models in the market, a significant challenge is to identify helpful learnwares efficiently for a specific user task without leaking data privacy. However, existing identification methods require examining the whole market, which is computationally unaffordable in a large market. In this paper, we propose a new framework for identifying helpful learnwares without examining the whole market. Specifically, using the Reduced Kernel Mean Embedding (RKME) specification, we derive a novel learnware scoring criterion for assessing the helpfulness of a learnware, based on which we design an anchor-based framework to identify helpful learnwares by examining only a small portion of learnwares in the market. Theoretical analyses are provided for both the criterion and the anchor-based method. Empirical studies on market containing thousands of learnwares from real-world datasets confirm the effectiveness of our proposed approach.   
 1339  Instance-Wise Adaptive Tuning and Caching for Vision-Language Models   
   
  Authors: Chunjin Yang ; Fanman Meng ; Shuai Chen ; Mingyu Liu ; Runtong Zhang    
 ##MORE##Large-scale vision-language models (LVLMs) pre-trained on massive image-text pairs have achieved remarkable success in visual representations. However, existing paradigms to transfer LVLMs to downstream tasks encounter two primary challenges. Firstly, the text features remain fixed after being calculated and cannot be adjusted according to image features, which decreases the model's adaptability. Secondly, the model’s output solely depends on the similarity between the text and image features, leading to excessive reliance on LVLMs. To address these two challenges, we introduce a novel two-branch model named the Instance-Wise Adaptive Tuning and Caching ( ATC) . Specifically, one branch implements our proposed ConditionNet, which guides image features to form an adaptive textual cache that adjusts based on image features,achieving instance-wise inference and improving the model's adaptability. The other branch introduces the similarities between images and incorporates a learnable visual cache, designed to decouple new and previous knowledge, allowing the model to acquire new knowledge while preserving prior knowledge. The model's output is jointly determined by the two branches, thus overcoming the limitations of existing methods that rely solely on LVLMs. Additionally, our method requires limited computing resources to tune parameters, yet outperforms existing methods on 11 benchmark datasets.   
 1341  Combating Short Circuit Behavior in Natural Language Reasoning: Crossover and Mutation Operations for Enhanced Robustness   
   
  Authors: Shanshan Huang ; Siyu Ren ; Kenny Q Zhu    
 ##MORE##In this study, we delve into the “short circuit” phenomenon observed in multiple-choice natural language reasoning tasks, where models tend to make accurate choices without properly considering the context of the question. To better understand this phenomenon, we propose white-box and black-box proxy tests as investigative tools to detect short circuit behavior, confirming its presence in fine-tuned NLU reasoning models. To tackle the short circuit issue, we introduce biologically inspired “crossover” and “mutation” operations. These operations are applied to augment the training data for popular models such as BERT, XLNet, and RoBERTa. Our results demonstrate that these data augmentation techniques effectively enhance the models’ robustness and mitigate the short circuit problem.   
 1348  Diffusion Model for Camouflaged Object Detection   
   
  Authors: Zhennan Chen ; Rongrong Gao ; Tian-Zhu Xiang ; Fan Lin    
 ##MORE##Camouflaged object detection is a challenging task that aims to identify objects that are highly similar to their background. Due to the powerful noise-to-image denoising capability of denoising diffusion models, in this paper, we propose a diffusion-based framework for camouflaged object detection, termed diffCOD, a new framework that considers the camouflaged object segmentation task as a denoising diffusion process from noisy masks to object masks. Specifically, the object mask diffuses from the ground-truth masks to a random distribution, and the designed model learns to reverse this noising process. To strengthen the denoising learning, the input image prior is encoded and integrated into the denoising diffusion model to guide the diffusion process. Furthermore, we design an injection attention module (IAM) to interact conditional semantic features extracted from the image with the diffusion noise embedding via the cross-attention mechanism to enhance denoising learning. Extensive experiments on four widely used COD benchmark datasets demonstrate that the proposed method achieves favorable performance compared to the existing 11 state-of-the-art methods, especially in the detailed texture segmentation of camouflaged objects. Our code will be made publicly available later.   
 1353  DRBERT: Efficient Inference for BERT based on Dynamic Routing   
   
  Authors: Weixin Wu ; Hankz Hankui Zhuo    
 ##MORE##Large-scale pre-trained language models such as BERT have contributed significantly to the development of NLP. However, those models require large computational resources, making it difficult to be applied to mobile devices where computing power is limited. In this paper we aim to address the weakness of existing input-adaptive inference methods which fail to take full advantage of the structure of BERT. We propose Dynamic Routing in BERT, a novel fine-tuning strategy that can accelerate the inference process of BERT through selecting a subsequence of transformer layers list of backbone as a computational path for an input sample. To do this, our approach adds a routing module to the original BERT model to determine whether a layer is included or bypassed during inference. Experimental results on the GLUE benchmark exhibit that our method reduces latency to 75% while maintaining 98% accuracy, yielding a better accuracy-speed trade-off compared to state-of-the-art input-adaptive methods.   
 1355  Hierarchical Text Classification using Contrastive Learning Informed Path Guided Hierarchy   
   
  Authors: Neeraj Agrawal ; Saurabh Kumar ; Priyanka Bhatt ; Tanishka Agarwal    
 ##MORE##Hierarchical Text Classification (HTC) has recently gained traction given the ability to handle complex label hierarchy. This has found applications in domains like E- commerce, Customer care and medicine industry among other real world applications. Existing HTC models either encode label hierarchy separately and mix it with text encoding or guide the label hierarchy structure in the text encoder. Both approaches capture different characteristics of label hierarchy and are complementary to each other. In this paper, we propose a Hierarchical Text Classification using Contrastive Learning Informed Path guided hierarchy (HTC-CLIP), which learns hierarchy-aware text representation and text informed path guided hierarchy representation using contrastive learning. During the training of HTC-CLIP, we learn two different sets of class probabilities distributions and during inference, we use the pooled output of both probabilities for each class to get the best of both representations. Our results show that the two previous approaches can be effectively combined into one architecture to achieve improved performance. Tests on two public benchmark datasets showed an improvement of 0.99 - 2.37 % in Macro F1 score using HTC-CLIP over the existing state-of-the-art models.   
 1358  VMBRL3: A Simple Visual Model-based Reinforcement Learning Framework for Continuous Control   
   
  Authors: Jian Wang ; Haitao Wang ; Hejun Wu    
 ##MORE##Unsupervised pre-training has demonstrated its potential for accurately constructing world model in visual model-based reinforcement learning (MBRL). However, most MBRL approaches that rely on unsupervised pre-training exhibit limited generalizability, thereby limiting their practicality in diverse scenarios. These methods produce models that are restricted to the specific task they were trained on, and are not easily adaptable to other tasks. In this work, we introduce a powerful unsupervised pre-training RL framework called VMBRL3, which improves the generalization ability of visual MBRL. VMBRL3 employs task-agnostic videos to pretrain both an autoencoder and world model without access to action or reward information. The fine-tuned world model can then be applied to a range of downstream reinforcement learning tasks, allowing for rapid adaptation to diverse environments and facilitating strategic learning. We demonstrate that our framework significantly improves generalization ability in a variety of manipulation and locomotion tasks. Furthermore, VMBRL3 doubles the sample efficiency and overall performance compared to previous visual RL methods.   
 1359  Robustness Testing for Multi-Agent Reinforcement Learning: State Perturbations on Critical Agents   
   
  Authors: Ziyuan Zhou ; Guanjun Liu    
 ##MORE##Multi-Agent Reinforcement Learning (MARL) has been widely applied in many fields such as smart traffic and unmanned aerial vehicles. However, most MARL algorithms are vulnerable to adversarial perturbations on agent states. Robustness testing for a trained model is an essential step for confirming the trustworthiness of the model against unexpected perturbations. This work proposes a novel Robustness Testing framework for MARL that attacks states of Critical Agents (RTCA). The RTCA has two innovations: 1) a Differential Evolution (DE) based method to select critical agents as victims and to advise the worst-case joint actions on them; and 2) a team cooperation policy evaluation method employed as the objective function for the optimization of DE. Then, adversarial state perturbations of the critical agents are generated based on the worst-case joint actions. This is the first robustness testing framework with varying victim agents. RTCA demonstrates outstanding performance in terms of the number of victim agents and destroying cooperation policies.   
 1361  A Declarative Approach to Compact Controllers for FOND Planning via Answer Set Programming   
   
  Authors: Nitin Yadav ; Sebastian Sardina    
 ##MORE##We present an approach to non-deterministic planning under full observability via Answer Set Programming. The technique can synthesise compact policies, handle both fair and unfair actions simultaneously, and readily accommodate control knowledge and procedural domain constraints. We show that whereas compact controllers may yield sub-optimal behaviour under a naive executor, optimality can be recovered under a smarter, and still efficient, executor. The planner developed is succinct, elegant, and directly implementable, thus providing higher confidence of its correctness and ease of elaboration. Experimental results show that its performance is competitive against the state-of-the-art.   
 1370  Improving Visual Reinforcement Learning with Discrete Information Bottleneck Approach   
   
  Authors: Haitao Wang ; Hejun Wu    
 ##MORE##Contrastive learning has been used to learn useful low-dimensional state representations in visual reinforcement learning (RL). Such state representations substantially improve the sample efficiency of visual RL. Nevertheless, existing contrastive learning-based RL methods have the problem of unstable training. Such instability comes from the fact that contrastive learning requires an extremely large batch size (e.g., 4096 or larger), while current contrastive learning-based RL methods typically set a small batch size (e.g., 512). In this paper, we propose an approach of discrete information bottleneck (DIB) to address this problem. DIB applies the technique of discretization and information bottleneck to contrastive learning in representing the state with concise discrete representation. Using this discrete representation for policy learning results in more stable algorithm training and higher sample efficiency with a small batch size. We demonstrate the advantage of discrete state representation of DIB on several continuous control tasks in the DeepMind Control suite. In the experiments, DIB outperforms prior visual RL methods, both model-based and model-free, in terms of performance and sample efficiency.   
 1383  Investigating Neural Fit Approaches for Sentence Embedding Model Paradigms   
   
  Authors: Helena Balabin ; Antonietta Gabriella Liuzzi ; Jingyuan Sun ; Patrick Dupont ; Rik Vandenberghe ; Sien Moens    
 ##MORE##In recent years, representations from brain activity patterns and pre-trained language models have been linked to each other based on neural fits to validate hypotheses about language processing. Nonetheless, open questions remain about what intrinsic properties of language processing these neural fits reflect and whether they differ across neural fit approaches, brain networks, and models. In this study, we use parallel sentence and functional magnetic resonance imaging data to perform a comprehensive analysis of four paradigms (masked language modeling, pragmatic coherence, semantic comparison, and contrastive learning) representing linguistic hypotheses about sentence processing. We include three sentence embedding models for each paradigm, resulting in a total of 12 models, and examine differences in their neural fit to four different brain networks using regression-based neural encoding and Representational Similarity Analysis (RSA). Among the different models tested, GPT-2, SkipThoughts, and S-RoBERTa yielded the strongest correlations with language network patterns, whereas contrastive learning-based models resulted in overall low neural fits. Our findings demonstrate that neural fits vary across brain networks and models representing the same linguistic hypothesis (e.g., GPT-2 and GPT-3). More importantly, we show the need for both neural encoding and RSA as complementary methods to provide full understanding of neural fits.   
 1396  Adversarial Discriminator to Mitigate Gender Bias in Abusive Language Detection   
   
  Authors: Jaeil Park ; Sung-Bae Cho    
 ##MORE##Abusive language detection models tend to have a gender bias problem in which the model is biased towards sentences containing identity words of specific gender groups. Previous studies to reduce bias, such as projection methods, lose information in word vectors and sentence context, reducing detection accuracy. This paper proposes a bias mitigation method that optimizes gender bias mitigation and original information preservation by regularizing sentence embedding vectors based on information theory. Latent vectors generated by an autoencoder are debiased through dual regularization using a gender discriminator, an abuse classifier, and a decoder. While the gender discriminator labels are rumpled, the discriminator softens the gender feature, and the classifier retains the abuse information. Latent vectors are regularized through information theoretic adversarial optimization that disentangles and mitigates gender features. We show that the proposed method successfully orthogonalizes the direction of the correlated information and reduces the gender feature by calculation of subspaces and embedding vector visualization. Moreover, the proposed method maintains the highest accuracy among the four state-of-the-art bias mitigation methods and shows superior performance in reducing gender bias in four different Twitter datasets for abusive language detection.   
 1398  Data-Driven Self-Supervised Graph Representation Learning   
   
  Authors: Ahmed Mr. Emad ; Zekarias Tilahun Kefato ; Sarunas Girdzijauskas    
 ##MORE##Self-supervised graph representation learning (SSGRL) is a representation learning paradigm used to reduce or avoid manual labeling. An essential part of SSGRL is graph data augmentation. Existing methods usually rely on heuristics commonly identified through trial and error and are effective only within some application domains. Also, it is not clear why one heuristic is better than another. Moreover, recent studies have argued against some techniques (e.g., dropout: that can change the properties of molecular graphs or destroy relevant signals for graph-based document classification tasks). In this study, we propose a novel data-driven SSGRL approach that automatically learns a suitable graph augmentation from the signal encoded in the graph (i.e., the nodes’ predictive feature and topological information). We propose two complementary approaches that produce learnable feature and topological augmentations. The former learns multi-view augmentation of node features, and the latter learns a high-order view of the topology. Moreover, the augmentations are jointly learned with the representation. Our approach is general that it can be applied to homogeneous and heterogeneous graphs. We perform extensive experiments on node classification (using nine homogeneous and heterogeneous datasets) and graph property prediction (using another eight datasets). The results show that the proposed method matches or outperforms the SOTA SSGRL baselines and performs similarly to semi-supervised methods. The anonymised source code is available at https://anonymous.4open.science/r/dsgrl-D086    
 1402  Generosity and the Emergence of Forgiveness in the Donation Game    
  
  Authors: Nathan Griffiths ; Nir Oren   
    
 ##MORE##Research has shown that cooperative action struggles to emerge in the noisy variant of the donation game, a simple model of noisy multi-agent systems where indirect reciprocity is required to maximise utility. Such noise can arise when agents may have an incorrect view of the reputation of their interaction partners, or when the actions themselves may fail. Concepts such as generosity, as well as the use of higher-order norms, have been investigated as mechanisms to facilitate cooperation in such environments, but often are not effective or require additional assumptions or infrastructure in the system to operate. In this paper, we demonstrate both analytically and empirically that a simple form of generosity when combined with fine grained reputation can help cooperation emerge. We also show that the use of individual forgiveness strategies rather than the presence of global generosity can support cooperation in such environments.   
 1407  Deep Reinforcement Learning with Implicit Imitation for Lane-Free Autonomous Driving   
   
  Authors: Iason Chrysomallis ; Dimitrios Troullinos ; Georgios Chalkiadakis ; Ioannis Papamichail ; Markos Papageorgiou    
 ##MORE##Implicit imitation assumes that learning agents observe only the state transitions of an agent they use as a mentor, and try to recreate them based on their own abilities and knowledge of their environment. In this paper, we put forward a deep implicit imitation Q-network (DIIQN) model, which incorporates ideas from three well-known Deep Q-Network (DQN) variants. As such, we enable a novel implicit imitation method for online, model-free deep reinforcement learning. Our thorough experimentation in the complex environment of the emerging lane-free traffic paradigm, verifies the benefits of our approach. Specifically, we show that deep implicit imitation RL dramatically accelerates the learning process when compared to a "vanilla" DQN method; and, unlike explicit imitation reinforcement learning, it is able to outperform mentor performance without resorting to additional information, such as the mentor's actions.   
 1413  Incomplete Bipolar Argumentation Frameworks   
   
  Authors: Bettina Fazzinga ; Sergio Flesca ; Filippo Furfaro    
 ##MORE##We introduce Incomplete Bipolar Argumentation Frameworks (iBAFs), the extension of Dung's Abstract Argumentation Frameworks (AAFs) allowing the simultaneous presence of supports (borrowed from BAFs - Bipolar AAFs) and of uncertain elements of the argumentation graph (borrowed from iAAFs - incomplete AAFs). We investigate the computational complexity of the acceptance problem and the verification problem (under the possible perspective), by performing an analysis of sensitivity to the semantics of supports and the semantics of extensions. On the one hand, we show that adding supports on top of incompleteness does not affect the complexity of the acceptance. On the other hand, surprisingly, we show that the joint use of bipolarity and incompleteness has a deep impact on the verification's complexity: for the Dungean semantics under which the verification over AAFs is polynomial-time solvable, although moving from AAFs to BAFs or to iAAFs does not change the complexity, the verification's complexity over iBAFs may increase up to NP-complete.   
 1414  Exploring the feasibility of physical adversarial attacks: a cybersecurity study   
   
  Authors: Ronan Hamon ; Henrik Junklewitz    
 ##MORE##Adversarial machine learning (AML), by designing attacks that intentionally break or misuse state-of-the-art machine learning models, has become the most prominent scientific field to explore the security aspects of Artificial Intelligence. A whole range of vulnerabilities, previously irrelevant in traditional ICT, have effectively emerged in these studies. In the light of upcoming legislations mandating security requirements for AI products and services, there is a need to understand how AML techniques connect with the broader field of cybersecurity, and how to articulate more tightly mathematical threat models with realistic cybersecurity procedures. This article aims to contribute to closing the gap between AML and cybersecurity by proposing an approach to study the feasibility of an attack in a cybersecurity risk assessment framework, illustrated with a specific use case of an evasion attack designed to fool traffic sign recognition systems in the physical world. The importance of considering the feasibility of carrying out such attacks under real conditions is emphasized through the analysis of two factors: the reproducibility of the attack according to a published description or existing code, and the applicability of the attack by a malicious actor operating in a real-world environment.   
 1417  On the Effectiveness of Compact Strategies for Opinion Diffusion in Social Environments   
   
  Authors: Carlo Adornetto ; Valeria Fionda ; Gianluigi Greco    
 ##MORE##An opinion diffusion scenario is considered where two marketers compete to diffuse their own opinions over a social network. In particular, they implement social proof marketing approaches that naturally give rise to a strategic setting, where it is crucial to find the appropriate order for targeting the individuals to which provide the incentives to adopt their opinions. The setting is extensively studied from the theoretical and empirical viewpoint, by considering strategies defined in a compact way, such as those that can be defined by selecting the individuals according to their degree of centrality in the underlying network. In addition to depicting a clear picture of the complexity issues arising in the setting, several compact strategies are empirically compared on real-world social networks. Results suggest that the effectiveness of compact strategies is moderately influenced by the characteristic of the network, with some centrality measures naturally emerging as good candidates to define heuristic approaches for marketing campaigns.   
 1427  Multilingual Lexical Simplification via Paraphrase Generation   
   
  Authors: Kang Liu ; Jipeng Qiang ; Yun Li ; Yunhao Yuan ; Yi Zhu ; Kaixun Hua    
 ##MORE##Lexical simplification (LS) methods based on pretrained language models have made remarkable progress, generating potential substitutes for a complex word through analysis of its contextual surroundings. However, these methods require separate pretrained models for different languages and disregard the preservation of sentence meaning. In this paper, we propose a novel multilingual LS method via paraphrase generation, as paraphrases provide diversity in word selection while preserving the sentence's meaning. We regard paraphrasing as a zero-shot translation task within multilingual neural machine translation that supports hundreds of languages. After feeding the input sentence into the encoder of paraphrase modeling, we generate the substitutes based on a novel decoding strategy that concentrates solely on the lexical variations of the complex word. Experimental results demonstrate that our approach surpasses BERT-based methods and zero-shot GPT3-based method significantly on English, Spanish, and Portuguese.   
 1428  How Does Diffusion Influence Pretrained Language Models on Out-of-Distribution Data?   
   
  Authors: Huazheng Wang ; Daixuan Cheng ; Haifeng Sun ; Jingyu Wang ; Qi Qi ; Jianxin Liao ; Jing Wang ; Cong Liu    
 ##MORE##Transformer-based pretrained language models (PLMs) have achieved great success in modern NLP. An important advantage of PLMs is good out-of-distribution (OOD) robustness. Recently, diffusion models have attracted a lot of work to apply diffusion to PLMs. It remains under-explored how diffusion influences PLMs on OOD data. The core of diffusion models is a forward diffusion process which gradually applies Gaussian noise to inputs, and a reverse denoising process which removes noise. The noised input reconstruction is a fundamental ability of diffusion models. We directly analyze OOD robustness by measuring the reconstruction loss, including testing the abilities to reconstruct OOD data, and to detect OOD samples. Experiments are conducted by analyzing different training parameters and data statistical features on eight datasets. It shows that finetuning PLMs with diffusion degrades the reconstruction ability on OOD data. The comparison also shows that diffusion models can effectively detect OOD samples, achieving state-of-the-art performance in most of the datasets with an absolute accuracy improvement up to 18%. These results indicate that diffusion reduces OOD robustness of PLMs.   
 1432  H2T-FAST: Head-to-Tail Feature Augmentation by Style Transfer for Long-Tailed Recognition   
   
  Authors: Ziyao Meng ; Xue Gu ; Qiang Shen ; Adriano J.C Tavares ; Sandro Pinto ; Hao Xu    
 ##MORE##Deep learning algorithms perform poorly on long-tailed datasets because there is insufficient data in the tail classes to recover its original distribution, resulting in an under-representation of the tail classes in the model. In this work, we propose H2T-FAST, a Head-to-Tail Feature Augmentation method by Style Transfer to improve the performance of the tail. H2T-FAST has the following advantages: (1) It is a fast and universal method that acts on the feature space and so, it can be applied to different backbone networks as well as easily integrated into various imbalanced algorithms with stable performance gains; and (2) it is used only in the training phase and therefore, imposes no additional burden on the deep neural network in the testing phase. In particular, we firstly and randomly select the same number of head samples as the tail ones in each training mini batch. Secondly, the style of the head is transferred to the tail to generate new tail data containing the head style, as a way to increase the number of the tail and get better feature representations. We test our methods on several benchmark vision tasks with state-of-the-art performances.   
 1435  Deep Interactions-boosted Emeddings for Link Prediction on Knowledge Graph   
   
  Authors: Hong Yin ; Jiang Zhong ; Qizhu Dai    
 ##MORE##Link prediction for Knowledge Graphs (KGs) aims to predict missing links between entities. Previous works have utilized Graph Neural Networks (GNNs) to learn specific embeddings of entities and relations. However, these works only consider the linear aggregation of neighbors and do not consider interactions among neighbors, resulting in the neglect of partial indicating information. To address this issue, we propose Deep Interactions-boosted Embeddings (DInBE) which encodes interaction information to enrich the entity representations. To obtain interaction information, we disentangle the representation behind entities to learn diverse disentangled representations for each entity. Then, we learn intra-interactions among neighboring entities in the same component and inter-interactions among different components based on these disentangled representations. With the help of interaction information, our model generates more expressive representations. In addition, we propose a relation-aware scoring mechanism to select useful components based on the given query. Our experiments demonstrate that our proposed model outperforms existing state-of-the-art methods by a large margin in the link prediction task, and this verifies the effectiveness of exploring interactions and adaptive scoring.   
 1436  The Emotions of the Crowd: Learning Image Sentiment from Tweets via Cross-modal Distillation   
   
  Authors: Alessio Serra ; Fabio Carrara ; Maurizio Tesconi ; Fabrizio Falchi    
 ##MORE##Trends and opinion mining in social media increasingly focus on novel interactions involving visual media, like images and short videos, in addition to text. In this work, we tackle the problem of visual sentiment analysis of social media images -- specifically, the prediction of image sentiment polarity. While previous work relied on manually labeled training sets, we propose an automated approach for building sentiment polarity classifiers based on a cross-modal distillation paradigm; starting from scraped multimodal (text + images) data, we train a student model on the visual modality based on the outputs of a textual teacher model that analyses the sentiment of the corresponding textual modality. We applied our method to randomly collected images crawled from Twitter over three months and produced, after automatic cleaning, a weakly-labeled dataset of $\sim$1.5 million images. Despite exploiting noisy labeled samples, our training pipeline produces classifiers showing strong generalization capabilities and outperforming the current state of the art on five manually labeled benchmarks for image sentiment polarity prediction.   
 1443  Uniform Training and Marginal Decoding for Multi-Reference Question-Answer Generation   
   
  Authors: Svitlana Vakulenko ; Bill Byrne ; Adrià de Gispert    
 ##MORE##Question generation is an important task that helps to improve question answering performance and augment search interfaces with possible suggested questions. While multiple approaches have been proposed for this task, none addresses the goal of generating a diverse set of questions given the same input context. The main reason for this is the lack of multi-reference datasets for training such models. We propose to bridge this gap by seeding a baseline question generation model with named entities as candidate answers. This allows us to automatically synthesize an unlimited number of question-answer pairs. We then propose an approach designed to leverage such multi-reference annotations, and demonstrate its advantages over the standard training and decoding strategies used in question generation. An experimental evaluation on synthetic, as well as manually annotated data shows that our approach can be used in creating a single generative model that produces a diverse set of question-answer pairs per input sentence.   
 1449  WeaGAN: Weather-Aware Graph Attention Network for Traffic Prediction   
   
  Authors: Yuxi Wang ; Yuan Luo    
 ##MORE##In recent years, traffic conditions in centralised cities have become more severe. To optimise public resources and reduce congestion, transportation departments rely on traffic prediction. However, unexpected events, for instance, rainfall can impact traffic conditions, which necessitates the introduction of weather elements to improve prediction results. Moreover, most of the existing works characterise the relationship between weather and traffic by simply combining these two issues together. Without carefully designing a structure that captures the inter-dependency between weather and traffic data, it is impossible to produce accurate predictions within a reasonable computational time. To address this issue, we propose a Weather-Aware Graph Attention Network (WeaGAN) that adapts an encoder-decoder architecture with weather attention mechanisms and a gate to model the complex spatial-temporal inter-dependency between weather and traffic adaptively. We further design a self-attention mechanism to improve prediction accuracy. Our experiments on a standard real-world dataset show that, compared to the state-of-the-art, WeaGAN: (i) can improve the prediction accuracy by up to 29\%; and (ii) is efficient in terms of saving up to 61\% of the computation time.   
 1450  Robust Assignment of Labels for Active Learning with Sparse and Noisy Annotations   
   
  Authors: Daniel Kaluza ; Andrzej Janusz ; Dominik Slezak    
 ##MORE##Supervised classification algorithms are used to solve a growing number of real-life problems around the globe. Their performance is strictly connected with the quality of labels used in training. Unfortunately, acquiring good-quality annotations for many tasks is infeasible or too expensive to be done in practice. To tackle this challenge, active learning algorithms are commonly employed to select only the most relevant data for labeling. However, this is possible only when the quality and quantity of labels acquired from experts are sufficient. Unfortunately, in many applications, a trade-off between annotating individual samples by multiple annotators to increase label quality vs. annotating new samples to increase the total number of labeled instances is necessary. In this paper, we address the issue of faulty data annotations in the context of active learning. In particular, we propose two novel annotation unification algorithms that utilize unlabeled parts of the sample space. The proposed methods require little to no intersection between samples annotated by different experts. Our experiments on four public datasets indicate the robustness and superiority of the proposed methods in both, the estimation of the annotator's reliability, and the assignment of actual labels, against the state-of-the-art algorithms and the simple majority voting.   
 1471  BMIPN: A Biased Multi-granularity Interaction Prototype Network for Few-Shot Relation Extraction   
   
  Authors: Yile Li ; Yinliang Yue ; Xiaoyan Gu ; Peng Fu ; Weiping Wang    
 ##MORE##Few-shot relation extraction (FSRE) focuses on detecting new relations through a few annotated instances. Most existing works adopt prototypical network-based models for FSRE. They compute prototype representations for each class in the support set separately, and then use prototype representations for relation prediction. In this way, they learn only the knowledge of each class, regardless of the high-level interactions among these classes. However, these interactions can help the model understand diversity and improve discrimination, which is essential for FSRE, especially for similar relations' prediction. In this work, we introduce a novel Biased Multi-granularity Interaction Prototype Network (BMIPN). Specifically, we mimic human cognitive processes to model explicit and adaptive interactions from intra- and inter-class aspects. Furthermore, we propose a novel biased contrastive learning method that encourages the model to focus on contrasting similar relations, generating discriminative and robust prototype representations. Experimental results on two benchmark datasets demonstrate that BMIPN outperforms state-of-the-art models and achieves better performance with respect to similar relations.   
 1476  FedPerturb: Covert Poisoning Attack on Federated Learning via Partial Perturbation   
   
  Authors: Tongsai Jin ; Fu Zhihui ; Dan Meng ; Jun Wang ; Yue Qi ; Guitao Cao    
 ##MORE##Federated learning breaks through the barrier of data owners by allowing them to collaboratively train a federated machine learning model without compromising the privacy of their own data. However, Federation Learning also faces the threat of poisoning attacks, especially from the client model updates, which may impair the accuracy of the global model. To defend against the poisoning attacks, previous work aims to identify the malicious updates in high dimensional spaces. However, we find that the distances in high dimensional spaces cannot identify the changes in a small subset of dimensions, and the small changes may affect the global models severely. Based on this finding, we propose an untargeted poisoning attack under the federated learning setting via the partial perturbations on a small subset of the carefully selected model parameters, and present two attack object selection strategies. We experimentally demonstrate that the proposed attack scheme achieves high attack success rate on five state-of-the-art defense schemes. Furthermore, the proposed attack scheme remains effective at low malicious client ratios and still circumvents three defense schemes with a malicious client ratio as low as 2%.   
 1478  TrojBits: A Hardware Aware Inference-Time Attack on Transformer-based Language Models   
   
  Authors: Mansour Al Ghanim ; Muhammad H Santriaji ; Qian Lou ; Yan Solihin    
 ##MORE##Transformer-based language models demonstrate exceptional performance in Natural Language Processing (NLP) tasks but remain susceptible to backdoor attacks involving hidden input triggers. Trojan injection via hardware bitflips presents a significant challenge for contemporary language models. However, previous research overlooks practical hardware considerations, such as DRAM and cache memory structures, resulting in unrealistic attacks that demand the manipulation of an excessive number of parameters and bits. In this paper, we present TrojBits, a novel approach requiring minimal bit-flips to effectively insert Trojans into real-world Transformer language model systems. This is achieved through a three-module framework designed to efficiently target Transformer-based language models, consisting of Vulnerable Parameters Ranking (VPR), Hardware-aware Attack Optimization (HAO), and Vulnerable Bits Pruning (VBP). Within the VPR module, we are the first to employ Gradient-guided Fisher information to identify the most susceptible Transformer parameters, specifically in the word embedding layer. The HAO module then redistributes these parameters across multiple triggers, conforming to hardware constraints by incorporating a regularization term in the trojan optimization methodology. Finally, the VBP module aims to reduce the number of bit-flips by discarding less significant bits. We evaluate TrojBits on two representative NLP models, BERT and XLNE, on three classification tasks (SST2, OffensEval, and AG's News). Our results demonstrate that our TrojBits successfully achieves the inference-time attack with only 64 parameters out of 116 million and 90-bit flips while maintaining the model performance.   
 1480  A Landmark-Cut Heuristic for Lifted Optimal Planning   
   
  Authors: Julia Wichlacz ; Daniel Höller ; Daniel Fišer ; Joerg Hoffmann    
 ##MORE##Lifted planning – finding plans directly on the PDDL input model – has attracted renewed attention during the last years. This avoids the process of grounding, which can become computationally prohibitive very easily. However, the main focus of recent research in this area has been on satisficing, i.e., (potentially) suboptimal planning. We present a novel heuristic for optimal lifted planning. Our basic idea is inspired by the LM-cut heuristic, which has been very successful in grounded optimal planning. Like LM-cut, we generate cut-based landmarks via back-chaining from the goal, generating cuts of partially grounded actions. However, exactly mimicking the ground formulation is not feasible, this includes computing the h max heuristic several times for one computation of the LM-cut heuristic (which is already NP-hard to compute). We show that our heuristic is admissible and evaluate it in a cost optimal setting.   
 1486  Grafting Fine-tuning and Reinforcement Learning for Empathetic Emotion Elicitation in Dialog Generation   
   
  Authors: Ying Zhu ; Bo Wang ; Dongming Zhao ; Kun Huang ; Zhuoxuan Jiang ; Ruifang He ; Yuexian Hou    
 ##MORE##For human-like dialogue systems, it is significant to inject the empathetic ability or elicit the opposite's positive emotions, while existing studies mostly only focus on either of the above two research lines. In this work, we propose a novel and grafted task named Empathetic Emotion Elicitation Dialog to make a dialog system able to possess both aspects of ability simultaneously. We do not train an empathetic dialog system and an emotion elicitation dialog system separately and then simply concatenate the responses generated by these two systems, which will cause illogical and repetitive responses. Instead, we propose a unified solution: (1) To generate empathetic responses and emotion elicitation responses within the same semantic space, we design a unified framework. (2) The unified framework has three stages which first retrieve the empathetic and emotion elicitation exemplars as external knowledge, then fine-tune the emotion/action prediction on a pre-trained language model to enhance the empathetic ability, and finally model the user feedback by reinforcement learning to enhance the emotion elicitation ability. Experiments show that our method outperforms the baselines in the response generation quality and simultaneously empathizes with the user and elicits their positive emotions.   
 1488  Unit refutations of difference constraint systems   
   
  Authors: K. Subramani ; Piotr Wojciechowski    
 ##MORE##This paper is concerned with a refutation system (proof system) for linear constraints, heretofore unaddressed in the literature. Associated with a refutation system are three important features, viz., (a) Soundness, (b) Completeness, and (c) Efficiency. In this paper, we investigate refutability in Difference Constraint Systems (DCSs) under the Unit Refutation (UR) system. Recall that a difference constraint is a linear relationship of the form: $x_{i}-x_{j} \le b_{ij}$ and a DCS is a conjunction of such constraints. The UR refutation system is {\bf incomplete}, in that unsatisfiable DCSs may not have unit refutations. We establish that this refutation system is efficient in that there exists a tractable algorithm for determining if a DCS has an UR. Investigating {\bf weak} (incomplete) refutation systems leads to a better understanding of the inference rules required for establishing contradictions in the given constraint system. Thus, this study is well-motivated. Difference constraints are used in the field of abstract interpretation. Abstract interpretation is an extremely useful technique for program verification. Note that a program can be modeled using a system of linear constraints. Depending on how the model is constructed, a refutation of such a system corresponds to proof that the original program is incorrect. Despite the fact that unit refutations can be exponentially long in terms of the input system size, we provide a compact representation of these refutations. This compact representation is a unique contribution of this paper.   
 1491  Decidable Fragments of LTLf Modulo Theories   
   
  Authors: Luca Geatti ; Alessandro Gianola ; Nicola Gigante ; Sarah Winkler    
 ##MORE##We study Linear Temporal Logic Modulo Theories over Finite Traces (LTLfMT), a recently introduced extension of LTL over finite traces (LTLf) where propositions are replaced by first-order formulas. In general, LTLfMT was shown to be semi-decidable for any decidable first-order theory (e.g., linear arithmetics), with a tableau-based semi-decision procedure. In this paper we focus on theories that satisfy the property of model completion, equivalent to the existence of uniform interpolants. This includes a variety of theories, including arithmetics, theories underlying database systems, and combinations thereof. We show that those theories admit a sound and complete pruning rule for the LTLfMT tableau that, when coupled with additional requirements, guarantees termination as well. This technique allows us to establish new decidability results for several fragments of LTLfMT, as well as to give new decidability proofs for classes that are already known.   
 1492  Visualization enhancement of saliency methods based on the sliding window mechanism   
   
  Authors: Xiaohong Xiang ; Fuyuan Zhang ; Xin Deng ; Xiaoyu Ding    
 ##MORE##Deep neural networks are widely used in image classification tasks, but their internal decision-making mechanisms are often difficult to explain. While various algorithms have been developed to visualize these mechanisms, many of them produce coarse, noisy results that are not always convincing. To address this issue, we propose a method for enhancing saliency maps produced by saliency methods. Our method uses a fixed-size sliding window to upsample local regions of the input image and feed them into the selected visualization algorithm to generate class-specific saliency maps and probability scores. We then downsample the resulting saliency maps and multiply them by the probability scores to obtain maps with greater detail. We evaluate our method using different saliency methods and network architectures, and demonstrate its effectiveness through both quantitative metrics and intuitive evaluation. Our results show that our method significantly improves the performance of these saliency methods, providing a more valid and reliable means of visualizing the decision mechanisms of deep neural networks.   
 1494  SpArX: Sparse Argumentative Explanations for Neural Networks   
   
  Authors: Hamed Ayoobi ; Nico Potyka ; Francesca Toni    
 ##MORE##Neural networks (NNs) have various applications in AI, but explaining their decisions remains challenging. Existing approaches often focus on explaining how changing individual inputs affects NNs' outputs. However, an explanation that is consistent with the input-output behaviour of an NN is not necessarily faithful to the actual mechanics thereof. In this paper, we exploit relationships between multi-layer perceptrons (MLPs) and quantitative argumentation frameworks (QAFs) to create argumentative explanations for the mechanics of MLPs. Our SpArX method first sparsifies the MLP while maintaining as much of the original structure as possible. It then translates the sparse MLP into an equivalent QAF to shed light on the underlying decision process of the MLP, producing global and/or local explanations. We demonstrate experimentally that SpArX can give more faithful explanations than existing approaches, while simultaneously providing deeper insights into the actual reasoning process of MLPs.   
 1499  Reconciling SHACL and Ontologies: Semantics and Validation via Rewriting   
   
  Authors: Shqiponja Ahmetaj ; Magdalena Ortiz ; Anouk M. Oudshoorn ; Mantas Simkus    
 ##MORE##OWL and SHACL are two prominent W3C standards for managing RDF graphs, the data model of the Web. They are used for different purposes and make different assumptions about the completeness of data: SHACL is used for expressing integrity constraints on complete data, while OWL allows inferring implicit facts from incomplete data; SHACL reasoners perform validation, while OWL reasoners do logical inference. Integrating these two tasks into one  
  uniform approach is a relevant but challenging problem. The SHACL standard envisions graph validation in combination with OWL entailment, but it does not provide technical guidance on how to realize this. To address this problem, we propose new intuitive semantics for validating SHACL constraints with OWL 2 QL ontologies based on a suitable notion of the chase. We propose an algorithm that rewrites a set of recursive SHACL constraints (with stratified negation) and  
  an OWL 2 QL ontology into a stand-alone set of SHACL constraints that preserves validation for every input graph, which can in turn be evaluated using an off-the-shelf SHACL validator. We show that validation in this setting is ExpTime complete in combined complexity, but only PTime complete in data complexity, i.e., if the constraints and the ontology are fixed.   
 1501  Representing and Reasoning with Multi-Stakeholder Qualitative Preference Queries   
   
  Authors: Samik Basu ; Vasant Honavar ; Ganesh Ram Santhanam ; Jia Tao    
 ##MORE##Many decision-making scenarios, e.g., public policy, healthcare, business, and disaster response, require accommodating the preferences of multiple stakeholders. We offer, to the best of our knowledge, the first formal treatment of reasoning with multi-stakeholder qualitative preferences in a setting where each stakeholder expresses their preferences in a qualitative preference language, e.g., CP-net, CI-net, TCP-net, CP-Theory. We introduce a query language for expressing queries against preferences of multiple stakeholders over sets of outcomes that satisfy specified conditions, e.g., $\mlangpref{\psi_1}{\psi_2}{A}$ (read as the set of stakeholders in $A$ prefer outcomes that satisfy $\psi_1$ over outcomes that satisfy $\psi_2)$, etc. Motivated by practical application scenarios, we introduce and compare alternative semantics for such queries, and examine their interrelationships. We provide a provably correct algorithm for answering multi-stakeholder preference queries using model checking in alternation-free $\mu$-calculus. The results of our experiments demonstrate the feasibility of our approach.   
 1507  On Solution Discovery via Reconfiguration   
   
  Authors: Michael R. Fellows ; Mario Grobler ; Nicole Megow ; Amer Mouawad ; Vijayaragunathan Ramamoorthi ; Frances A. Rosamond ; Daniel Schmand ; Sebastian Siebertz    
 ##MORE##The dynamics of real-world applications and systems require efficient methods for improving infeasible solutions or restoring corrupted ones by making modifications to the current state of a system in a restricted way. We propose a new framework of solution discovery via reconfiguration for constructing a feasible solution for a given problem by executing a sequence of small modifications starting from a given state. Our framework integrates different aspects of classical local search, reoptimization, and combinatorial reconfiguration. We exemplify our framework on a multitude of fundamental combinatorial problems, namely Vertex Cover, Independent Set, Dominating Set, and Coloring. We study the classical as well as the parameterized complexity of the solution discovery variants of those problems and explore the boundary between tractable and intractable instances.   
 1512  Complexity of Verification and Existence Problems in Epistemic Argumentation Framework   
   
  Authors: Gianvincenzo Alfano ; Sergio Greco ; Domenico Mandaglio ; Francesco Parisi ; Irina Trubitsyna    
 ##MORE##Dung’s Argumentation Framework (AF) has been extended in several directions. An interesting extension, among others, is the Epistemic AF (EAF) which allows representing the agent’s belief by means of epistemic constraints. In particular, an epistemic constraint is a propositional formula over labeled arguments (e.g. in(a), out(c)) extended with the modal operators K and M that intuitively state that the agent believes that a given formula is certainly or possibly true, respectively. In this paper, focusing on EAF, we investigate the complexity of the possible and necessary variants of three canonical problems in abstract argumentation: verification, existence, and non-empty existence. Moreover, we explore the relationship between EAF and incomplete AF (iAF), an extension of AF where arguments and attacks may be uncertain. Our complexity analysis shows that the verification problem in iAF can be naturally reduced to the verification in EAF, while it turns out that a similar result cannot hold for the necessary (non-empty) existence problem.   
 1526  Reachability Poorman Discrete-Bidding Games   
   
  Authors: Guy Avni ; Tobias Meggendorfer ; Suman Sadhukhan ; Josef Tkadlec ; Đorđe Žikelić    
 ##MORE##We consider ""bidding games"", a class of two-player zero-sum ""graph games"". The game proceeds as follows. Both players have bounded budgets. A token is placed on a vertex of a graph, in each turn the players simultaneously submit bids, and the higher bidder moves the token. In case of ties, Player 1 moves the token. Player 1 wins the game iff the token visits a designated target vertex. We consider, for the first time, ""poorman discrete-bidding"" in which the granularity of the bids is restricted and the higher bid is paid to the bank. In contrast, in ""Richman continuous-bidding"" bids can be arbitrarily small and are paid to the other player. While the latter mechanism is technically more accessible, the former is more appealing from a practical standpoint. Our study focuses on threshold budgets, which is the necessary and sufficient initial budget required for Player 1 to ensure winning against a given Player 2 budget. We first show existence of thresholds. In DAGs, we show that threshold budgets can be approximated with error bounds by thresholds under continuous-bidding and that they exhibit a periodic behavior. We identify closed-form solutions in special cases. We implement and experiment with an algorithm to find threshold budgets.   
 1531  On Contrastive Explanations for Tree-Based Classifiers   
   
  Authors: Gilles Audemard ; Jean-Marie Lagniez ; Pierre Marquis ; Nicolas szczepanski    
 ##MORE##We define contrastive explanations that are suited to tree-based classifiers. In our framework, contrastive explanations are based on the set of (possibly non-independent) Boolean characteristics used by the classifier and are at least as general as contrastive explanations based on the set of characteristics of the instances considered at start. We investigate the computational complexity of computing contrastive explanations for any Boolean classifier (including tree-based ones), when the Boolean conditions used are not independent. Finally, we present and evaluate empirically an algorithm for computing minimum-size contrastive explanations for random forests.   
 1533  A Semantic Approach to Decidability in Epistemic Planning   
   
  Authors: Alessandro Burigana ; Paolo Felli ; Marco Montali ; Nicolas Troquard    
 ##MORE##The use of Dynamic Epistemic Logic (DEL) in multi-agent planning has led to a widely adopted action formalism that can handle nondeterminism, partial observability and arbitrary knowledge nesting. As such expressive power comes at the cost of undecidability, several decidable fragments have been isolated, mainly based on syntactic restrictions of the action formalism. In this paper, we pursue a novel semantic approach to achieve decidability. Namely, rather than imposing syntactical constraints, the semantic approach focuses on the axioms of the logic for epistemic planning. Specifically, we augment the logic of knowledge S5n and with an interaction axiom called (knowledge) commutativity, which controls the ability of agents to unboundedly reason on the knowledge of other agents. We then provide a threefold contribution. First, we show that the resulting epistemic planning problem is decidable. In doing so, we prove that our framework admits a finitary non-fixpoint characterization of common knowledge, which is of independent interest. Second, we study different generalizations of the commutativity axiom, with the goal of obtaining decidability for more expressive fragments of DEL. Finally, we show that two well-known epistemic planning systems based on action templates, when interpreted under the setting of knowledge, conform to the commutativity axiom, hence proving their decidability.   
 1535  Efficient Algorithms for Monroe and CC Rules in Multi-Winner Elections with (Nearly) Structured Preferences   
   
  Authors: Jiehua Chen ; Christian Hatschka ; Sofia Simola    
 ##MORE##We investigate winner determination for two popular proportional representation systems: the Monroe and Chamberlin-Courant (abbrv. CC) systems. Our study focuses on (nearly) single-peaked resp. single-crossing preferences. We show that for single-crossing approval preferences, winner determination of the Monroe rule is polynomial, and for both rules, winner determination mostly admits FPT algorithms with respect to the number of voters to delete to obtain single-peaked or single-crossing preferences. Our results answer some complexity questions from the literature [18, 28, 21].   
 1540  Graph-based Abstractive Summarization of Extracted Essential Knowledge for Low-Resource Scenarios   
   
  Authors: Gianluca Moro ; Luca Ragazzi ; Lorenzo Valgimigli    
 ##MORE##Although current summarization models can process increasingly long text sequences, they still struggle to capture salient related information spread across the extremely-lengthy size of inputs with few labeled training instances. Today's research still relies on standard input truncation without considering graph-based modeling of multiple semantic units to summarize only crucial facets. This paper proposes G-Seek, a graph-based summarization of extracted essential knowledge. By representing the long source with a heterogeneous graph, our method extracts and provides salient sentences to an abstractive summarization model to generate the summary. Experimental results in low-resource scenarios, distinguished by data scarcity, reveal that G-Seek consistently improves both long and multi-document summarization performance and accuracy across several datasets.   
 1552  Pretraining the Vision Transformer using self-supervised methods for vision based Deep Reinforcement Learning   
   
  Authors: Manuel Goulão ; Arlindo L Oliveira    
 ##MORE##The Vision Transformer architecture has shown to be competitive in the computer vision (CV) space where it has dethroned convolution-based networks in several benchmarks. Nevertheless, convolutional neural networks (CNN) remain the preferential architecture for the representation module in reinforcement learning. In this work, we study pretraining a Vision Transformer using several state-of-the-art self-supervised methods and assess the quality of the learned representations. To show the importance of the temporal dimension in this context we propose an extension of VICReg to better capture temporal relations between observations by adding a temporal order verification task. Our results show that all methods are effective in learning useful representations and avoiding representational collapse for observations from the Atari Learning Environment (ALE) which leads to improvements in data efficiency when we evaluated in reinforcement learning (RL). Moreover, the encoder pretrained with the temporal order verification task shows the best results across all experiments, with richer representations, more focused attention maps and sparser representation vectors throughout the layers of the encoder, which shows the importance of exploring such similarity dimension. With this work, we hope to provide some insights into the representations learned by ViT during a self-supervised pretraining with observations from RL environments and to understand which properties arise in the representations that lead to the best-performing agents.   
 1554  Towards a Neuronally Consistent Ontology for Robotic Agents   
   
  Authors: Florian Ahrens ; Daniel Beßler ; Thorsten Fehr ; Manfred Herrmann ; Michael Beetz ; Mihai Pomarlan    
 ##MORE##Our Collaborative Research Center (CRC) aims to enable robots to perform environmental interaction tasks with close to human capacity. It therefore employs a shared ontology to model the activity of both kinds of agents, empowering robots to learn from human experiences. To properly describe these human experiences, the ontology will strongly benefit from incorporating characteristics of neuronal information processing which are not accessible from a behavioral perspective alone. We, therefore, propose the analysis of human neuroimaging data for evaluation and validation of concepts and events defined in the ontology model underlying most of the CRC projects. In an exploratory analysis, we employed an Independent Component Analysis (ICA) on functional Magnetic Resonance Imaging (fMRI) data from participants who were presented with the same complex video stimuli of activities as robotic and human agents in different environments and contexts. We then correlated the activity patterns of brain networks represented by derived components with timings of annotated event categories as defined by the ontology model. The present results demonstrate a subset of common networks with stable correlations and specificity towards particular event classes and groups, associated with environmental and contextual factors. These neuronal characteristics will open up avenues for adapting the ontology model to be more consistent with human information processing.   
 1558  Strategy Repair in Reachability Games   
   
  Authors: Pierre Gaillard ; Fabio Patrizi ; Giuseppe Perelli    
 ##MORE##We introduce Strategy Repair, the problem of finding a minimal amount of modifications to turn a strategy for a reachability game from losing into winning. The problem is relevant for a number of settings in Planning and Synthesis, where solutions essentially correspond to winning strategies in a suitably defined reachability game. We show, via reduction from Vertex Cover, that Strategy Repair is NP-complete and devise two algorithms, one exact and exponential and one polynomial but suboptimal, which we compared experimentally. The reported experimentation includes some heuristics for strategy modification, which proved crucial in dramatically improving performance.   
 1573  From Decision Trees to Explained Decision Sets   
   
  Authors: Xuanxiang Huang ; Joao Marques-Silva    
 ##MORE##Recent work demonstrated that path explanation redundancy is ubiquitous in decision trees, i.e. most often paths in decision trees include literals that are redundant for explaining a prediction. The implication of this result is that decision trees must be explained. Nevertheless, there are applications of DTs where running an explanation algorithm is impractical. For example, in settings that are time or power constrained, running software algorithms for explaining predictions would be undesirable. Although the explanations for paths in DTs do not generally represent themselves a decision tree, this paper shows that one can construct a decision set from some of the decision tree explanations, such that the decision set is not only explained, but it also exhibits a number of properties that are critical for replacing the original decision tree.   
 1582  Extracting and Exploiting Bounds of Numeric Variables for Optimal Linear Numeric Planning   
   
  Authors: Ryo Kuroiwa ; Alexander Shleyfman ; Christopher Beck    
 ##MORE##In numeric AI planning, a state is represented by propositions and numeric variables, actions change the values of numeric variables in addition to adding and deleting propositions, and goals and preconditions of actions may include conditions over numeric variables. While domains of numeric variables are rational numbers in general, upper and lower bounds on variables affected only by constant increase and decrease can sometimes be determined and exploited by a heuristic function. In this paper, we generalize the existing method to variables that are changed by linear effects. We exploit the extracted bounds to improve the numeric LM-cut heuristic, a state-of-the-art admissible heuristic for linear numeric planning. Empirical evaluation shows that our method improves the performance of LM-cut in multiple domains. The proposed method can also detect unsolvability of some numeric tasks in polynomial time.   
 1584  Enhancing Hybrid CP-SAT Search for Disjunctive Scheduling   
   
  Author: Arthur Bit-Monnot    
 ##MORE##Disjunctive scheduling problems such as the job shop and open shop are at the heart of many real world scheduling instances. In this paper, we frame such problems as disjunctive temporal networks associated with a makespan minimization objective. For those, we propose a hybrid approach between SMT and CP solvers. In particular, we keep from SMT solvers the aggregated constraint propagation in decision procedures as well as the explanations and clause learning mechanisms upon conflict. However, like all CP solvers, we maintain an explicit domain representation of integer variables, tightly integrated with clause learning. Automated search exploits explanations to derive activity-based heuristics combined with more classical value-based heuristics of CP solvers. The resulting solver is compared to state-of-the-art exhaustive search solvers on the classical benchmarks of job shop and open shop problems.   
 1588  Iterative Reward Shaping using Human Feedback for Correcting Reward Misspecification   
   
  Authors: Jasmina Gajcin ; James McCarthy ; Rahul Nair ; Radu Marinescu ; Elizabeth Daly ; Ivana Dusparic    
 ##MORE##A well-defined reward function is crucial for successful training of an reinforcement learning (RL) agent. However, defining a suitable reward function is a notoriously challenging task, especially in complex, multi-objective environments. To define a reward function in such environments an initial, potentially misspecified reward function is often iteratively adjusted based on observed learned behavior. In this work, we aim to automate this process by proposing ITERS, an iterative reward shaping approach using human feedback for mitigating the effects of a misspecified reward function. Our approach allows the user to provide trajectory-level feedback on agent's behavior during training, which can be integrated as a reward shaping signal in the following training iteration. We also allow the user to provide explanations of their feedback, which are used to augment the feedback and reduce user effort and feedback frequency. We evaluate ITERS in three environments and show that it can successfully correct misspecified reward functions.   
 1591  PiercingEye: Identifying Both Faint and Distinct Clues for Explainable Fake News Detection with Progressive Dynamic Graph Mining   
   
  Authors: Yasan Ding ; Bin Guo ; Yan Liu ; Hao Wang ; Haocheng Shen ; Zhiwen Yu    
 ##MORE##Explainability is crucial for the successful use of AI for fake news detection (FND). Researchers aim to improve the explainability of FND by highlighting important descriptions in crowd-contributed comments as clues. From the perspective of law and sociology, there are distinct clues that are easy to discover and understand, and faint clues that require careful observation and analysis. For example, in fake new related to COVID-Omicron showing increased pathogenicity and transmissibility, distinct clues might involve virologists’ opinions regarding the inverse correlation between pathogenicity and transmissibility. Meanwhile, faint clues might be reflected in an infected person’s claim that the symptoms are milder than a cold (indirectly indicating reduced pathogenicity). Occasionally, the statements of some ordinary eyewitness can decisively reveal the truth of news, leading to the judgment of fake news. Existing methods generally use static networks to model the entire news life-cycle, which makes it fail to capture the subtle dynamic interactions between individual clues and news. Thereby faint clues, whose relations to the truth of news are challenging to be characterized and extracted directly, are more likely to be overshadowed by distinct clues. To address this issue, we propose an explainable FND method, dubbed as PiercingEye, which leverages dynamic interaction information to progressively mine valuable clues. PiercingEye models the news propagation topology as a dynamic graph, with interactive comments serving as nodes, and employs the time-semantic encoding mechanism to refine the modeling of temporal interaction information between comments and news to preserve faint clues. Subsequently, it utilizes the self-attention mechanism to aggregate distinct and faint clues for FND. Experimental results demonstrate that PiercingEye outperforms state-of-the-art methods and is capable of identifying both faint and distinct clues for humans to debunk fake news.   
 1597  Multi-agent Cooperative Games Using Belief Map Assisted Training   
   
  Authors: Chen Luo ; Qinwei Huang ; Alex B. Wu ; Simon Khan ; Hai Li ; Qinru Qiu    
 ##MORE##In a multi-agent system, agents share their local observations to gain global situational awareness for decision making and collaboration using a message passing system. When to send a message, how to encode a message, and how to leverage the received messages directly affect the effectiveness of the collaboration among agents. When training a multi-agent cooperative game using reinforcement learning (RL), the message passing system needs to be optimized together with the agent policies. This consequently increases the model’s complexity and poses significant challenges to the convergence and performance of learning. To address this issue, we propose the Belief-map Assisted Multi-agent System (BAMS), which leverages a neuro-symbolic belief map to enhance training. The belief map decodes the agent's hidden state to provide a symbolic representation of the agent's understanding of the environment and other agents' status. he simplicity of symbolic representation allows the gathering and comparison of the ground truth information for the belief, which provides an additional channel of feedback for the learning. Compared to the sporadic and delayed feedback coming from the reward in RL, the feedback from the belief map is more consistent and reliable. Agents using BAMS can learn a more effective message passing network to better understand each other, resulting in better performance in the game. We evaluate BAMS's performance in a cooperative predator and prey game with varying levels of map complexity and compare it to previous multi-agent message passing models. The simulation results showed that BAMS reduced training epochs by 66%, and agents who apply the BAMS model completed the game with 34.62% fewer steps on average.   
 1599  SDV: Simple Double Validation Model-based Offline Reinforcement Learning   
   
  Authors: Xun Wang ; Haonan Chen ; Junming Yang ; Zhuzhong Qian ; Bolei Zhang    
 ##MORE##Offline reinforcement learning (RL) aims to learn effective policies from recorded data without further interactions in the environments that are often costly or risky. Model-based algorithms, which begin by constructing an environmental model and then learn the policy under the model, have become a promising approach. However, most existing works have been over-conservative to avoid the out-of-distribution error induced by the model generated samples, leading to poor performance instead. In this work, we propose a novel model-based offline RL method, named Simple Double Validation (SDV). The main idea of SDV is to introduce an additional guidance model to assist the agent in determining the rationality of the states, combined with an advantage weighting factor to avoid effects that could potentially mislead the models due to suboptimal samples. In this way, the agent can be guided to more favourable states with reliable decisions. We evaluated SDV on the widely studied offline RL benchmarks and demonstrated its state-of-the-art performance. At the same time, our work introduces the idea of double validation and model advantage weighting into the field of model-based offline RL, providing new insights for future research.   
 1605  User-Controlled Recommenders via Counterfactual Retrospective and Prospective Explanations   
   
  Authors: Juntao Tan ; Yingqiang Ge ; Yan Zhu ; Yinglong Xia ; Jiebo Luo ; Jianchao Ji ; Yongfeng Zhang    
 ##MORE##Modern recommender systems utilize users' historical behaviors to generate personalized recommendations. However, these systems often lack user controllability, leading to diminished user satisfaction and trust in the systems. Acknowledging the recent advancements in explainable recommender systems that enhance users' understanding of recommendation mechanisms, we propose leveraging these advancements to improve user controllability. In this paper, we present a user-controllable recommender system that seamlessly integrates explainability and controllability within a unified framework. By providing both retrospective and prospective explanations through counterfactual reasoning, users can customize their control over the system by interacting with these explanations. Furthermore, we introduce and assess two attributes of controllability in recommendation systems: controllability complexity and controllability accuracy. Experimental evaluations on MovieLens and Yelp datasets substantiate the effectiveness of our proposed framework. Additionally, our experiments demonstrate that offering users control options can potentially enhance recommendation accuracy in the future.   
 1606  Reinforcement Learning by Guided Safe Exploration   
   
  Authors: Qisong Yang ; Thiago D. Simão ; Nils Jansen ; Simon H Tindemans ; Matthijs T. J. Spaan    
 ##MORE##Safety is critical to broadening the application of reinforcement learning (RL). Often, we train RL agents in a controlled environment, such as a laboratory, before deploying them in the real world. However, the real-world target task might be unknown prior to deployment. Reward-free RL trains an agent without the reward to adapt quickly once the reward is revealed. We consider the constrained reward-free setting, where an agent (the guide) learns to explore safely without the reward signal. This agent is trained in a controlled environment, which allows unsafe interactions and still provides the safety signal. After the target task is revealed, safety violations are not allowed anymore. Thus, the guide is leveraged to compose a safe behavior policy. Drawing from transfer learning, we also regularize a target policy (the student) towards the guide while the student is unreliable and gradually eliminate the influence from the guide as training progresses. The empirical analysis shows that this method can achieve safe transfer learning and helps the student solve the target task faster.   
 1613  Dynamic Causality   
   
  Authors: Maksim Gladyshev ; Natasha Alechina ; Mehdi Dastani ; Dragan Doder ; Brian Logan    
 ##MORE##There have been a number of attempts to develop a formal definition of causality that accords with our intuitions about what constitutes a cause. Perhaps the best known is the "modified'' definition of actual causality, HPm, due to Halpern. In this paper, we argue that HPm gives counterintuitive results for some simple causal models. We propose Dynamic Causality (DC), an alternative semantics for causal models that leads to an alternative definition of causes. DC ascribes the same causes as HPm on the examples of causal models widely discussed in the literature and ascribes intuitive causes for the kinds of causal models we consider. Moreover, we show that the complexity of determining a cause under the DC definition is lower than for the HPm definition.   
 1615  Fair Few-shot learning with Auxiliary Sets   
   
  Authors: Song Wang ; Jing Ma ; Lu Cheng ; Jundong Li    
 ##MORE##Recently, there has been a growing interest in developing machine learning (ML) models that can promote fairness, i.e., eliminating biased predictions towards certain populations (e.g., individuals from a specific demographic group). Most existing works learn such models based on well-designed fairness constraints in optimization. Nevertheless, in many practical ML tasks, only very few labeled data samples can be collected, which can lead to inferior fairness performance. This is because existing fairness constraints are designed to restrict the prediction disparity among different sensitive groups, but with few samples, it becomes difficult to accurately measure the disparity, thus rendering ineffective fairness optimization. In this paper, we define the fairness-aware learning task with limited training samples as the fair few-shot learning problem. To deal with this problem, we devise a novel framework that accumulates fairness-aware knowledge across different meta-training tasks and then generalizes the learned knowledge to meta-test tasks via fairness adaptation. To compensate for insufficient training samples, we propose an essential strategy to select and leverage an auxiliary set for each meta-test task. These auxiliary sets contain several labeled training samples that can enhance fairness adaptation in meta-test tasks, thereby allowing for the transfer of learned useful fairness-oriented knowledge to meta-test tasks. Furthermore, we conduct extensive experiments on three real-world datasets to validate the superiority of our framework against the state-of-the-art baselines.   
 1616  Deep Ensemble Robustness by Adaptive Sampling in Dropout-Based Simultaneous Training   
   
  Authors: QuanWei Wu ; Bo Huang ; Yi Wang ; Zhiwei Ke ; Da Luo    
 ##MORE##Recent studies show that an ensemble of deep networks can have better adversarial robustness by increasing the learning diversity of base models to limit adversarial transferability. However, existing schemes mostly rely on a second-order method for gradient regularization which usually involves a heavy computation overhead. In this paper, we propose a simple yet effective method which eliminates the use of a second-order optimization and significantly reduces the computation complexity of regularized simultaneous training of deep ensemble networks. For the first time, we show analytically that stochastic regularization by the proposed approach can promote both model smoothness and feature diversity of representation learning in the deep space. We also show that the proposed method is able to achieve a better gain of certified robustness. This is due to the effect of a prioritized feature selection enabled by an adaptive and continuous sampling of neuron activation among the base networks. Experimental results show that our method can improve adversarial robustness signiﬁcantly comparing with the existing ensemble models on several image benchmark datasets. The ensemble performance can be further boosted by complementing the stochastic regularization approach with other defense paradigms such as adversarial training.   
 1625  Counterfactual Prediction Under Selective Confounding   
   
  Authors: Sohaib Kiani ; Bo Luo ; Jared Barton ; Lynda Heimbach ; Jon Sushinsky    
 ##MORE##This research proposes an interpretable and practical solution for learning the causal relationship between a desired treatment and its outcome from observed data. This is crucial to assist decision-makers in various fields. However, in real-world scenarios, learning causal relationships from observed data is difficult due to confounding factors that influence treatment and outcome, and are not reported for all treatments, a problem known as Selective Confounding. This issue is prevalent in child welfare, where caseworkers determine whether children should remain in their family homes or be assigned out-of-home placements like foster care during child maltreatment assessments. In such cases, factors reported for children kept with their family are often lower than those taken out of home, making it difficult to observe all confounding factors under desired treatment. Our proposed scheme uses dual-treatment samples to identify the target quantity under Selective Confounding and adapts two-step procedures to learn counterfactual predictors such as Regression Adjustment or Doubly-Robust. We provide both theoretical error bounds and empirical evidence of the effectiveness of our proposed scheme using synthetic and real-world child placement data. Additionally, we propose three evaluation methods specifically tailored to child placement data. By promoting transparency and interpretability, we aim to provide a valuable tool for decision-makers.   
 1632  Oracle-Based Local Search for Pseudo-Boolean Optimization   
   
  Authors: Markus Iser ; Jeremias Berg ; Matti Järvisalo    
 ##MORE##Significant advances have been recently made in the development of increasingly effective in-exact (or incomplete) search algorithms---particularly geared towards finding good though not provably optimal solutions fast---for the constraint optimization paradigm of maximum satisfiability (MaxSAT). One of the most successful recent approaches is a new type of stochastic local search in which---to an extent counterintuitively---a Boolean satisfiability (SAT) solver is used as a decision oracle for moving from a solution to another. In this work, we strive for extending the success of the approach to the more general realm of pseudo-Boolean optimization (PBO), where constraints are expressed as linear inequalities over binary variables. As a basis for the approach, we make use of recent advances in practical approaches to satisfiability checking pseudo-Boolean constraints. We outline various heuristics within the oracle-based approach to anytime PBO solving, and show that the approach compares in practice favourably both to a recently-proposed local search approach for PBO that is in comparison a more traditional instantiation of the stochastic local search paradigm, and a recent exact PBO approach when used as an anytime solver.   
 1639  Do Topic and Causal Consistency Affect Emotion Cognition? A Graph Interactive Network for Conversational Emotion Detection   
   
  Authors: Geng Tu ; Bin Liang ; Xiucheng Lyu ; Lin Gui ; Ruifeng Xu    
 ##MORE##Emotion recognition in conversations (ERC) typically involves modeling both intra- and inter-speaker context dependencies. While modeling inter-speaker dependencies has limitations in highlighting differences among listeners. Recent research in ERC has focused on incorporating causal knowledge to enhance utterance representation. However, the incorporation of causal knowledge ignores the consistency of speakers' causal cues (SCC) in modeling speaker-level context, which does not meet emotional dynamics in conversations. Additionally, it is observed that historical utterances from various topics are blindly leveraged in dialogue context modeling, which fails the inter- and intra-topic coherence. To address these issues, we propose the topic- and causal-aware graph interactive network (TCA-GIN). Specifically, we suggest a graph encoder to model topic-level context dependencies based on a context-sensitive neural topic model, achieving inter- and intra-topic coherences. Then, we present a causal-aware graph attention to keep the consistency of SCC, improving speaker-level context modeling. Finally, considering the defect of context modeling insensitive to the differences among inter-speaker or inter-topic dependencies, we employ supervised comparative learning to sweeten it. Experimental results show that TCA-GIN outperforms state-of-the-art methods on three public conversational datasets.   
 1654  Counterfactual Reasoning for Bias Evaluation and Detection in a Fairness under Unawareness setting   
   
  Authors: Giandomenico Cornacchia ; Vito Walter Anelli ; Fedelucio Narducci ; Azzurra Ragone ; Eugenio Di Sciascio    
 ##MORE##Current AI regulations require discarding sensitive features (e.g., gender, race, religion) in the algorithm's decision-making process to prevent unfair outcomes. However, even without sensitive features in the training set, algorithms can persist in discrimination. Indeed, when sensitive features are omitted (fairness under unawareness), they could be inferred through non-linear relations with the so-called proxy features. In this work, we propose a way to reveal the potential hidden bias of a machine learning model that can persist even when sensitive features are discarded. This study shows that it is possible to unveil whether the black-box predictor is still biased by exploiting counterfactual reasoning. In detail, when the predictor provides a negative classification outcome, our approach first builds counterfactual examples for a discriminated user category to obtain a positive outcome. Then, the same counterfactual samples feed an external classifier (that targets a sensitive feature) that reveals whether the modifications to the user characteristics needed for a positive outcome moved the individual to the non-discriminated group. When this occurs, it could be a warning sign for discriminatory behavior in the decision process. Furthermore, we leverage the deviation of counterfactuals from the original sample to determine which features are proxies of specific sensitive information. Our experiments show that, even if the model is trained without sensitive features, it often suffers discriminatory biases.   
 1657  Learning Task Automata for Reinforcement Learning Using Hidden Markov Models   
   
  Authors: Alessandro Abate ; Yousif Almulla ; James Fox ; David Hyland ; Michael Wooldridge    
 ##MORE##Training reinforcement learning (RL) agents using scalar reward signals is often infeasible when an environment has sparse and non-Markovian rewards. Moreover, handcrafting these reward functions before training is prone to misspecification. We learn non-Markovian finite task specifications as finite-state `task automata' from episodes of agent experience within environments with unknown dynamics. First, we learn a product MDP, a model composed of the specification's automaton and the environment's MDP (both initially unknown), by treating it as a partially observable MDP and employing hidden Markov model learning algorithms. Second, we efficiently distil the task automaton (assumed to be a deterministic finite automaton) from the learnt product MDP. Our automaton enables a task to be decomposed into sub-tasks, so an RL agent can later synthesise an optimal policy more efficiently. It is also an interpretable encoding of high-level task features, so a human can verify that the agent's learnt tasks have no misspecifications. We also take steps towards ensuring that the automaton is environment-agnostic, making it well-suited for use in transfer learning.   
 1662  GeneMask: Fast Pretraining of Gene Sequences to Enable Few-Shot Learning   
   
  Authors: Soumyadeep Roy ; Jonas Wallat ; Sowmya S Sundaram ; Wolfgang Nejdl ; Niloy Ganguly    
 ##MORE##Large-scale language models such as DNABert and LOGO aim to learn optimal gene representations and are trained on the entire Human Reference Genome. However, standard tokenization schemes involve a simple sliding window of tokens like k-mers that do not leverage any gene-based semantics and thus may lead to (trivial) masking of easily predictable sequences, and subsequently inefficient Masked Language Modeling (MLM) training. Therefore, we propose a novel masking algorithm, GeneMask, for MLM training of gene sequences, where we randomly identify positions in a gene sequence as mask centers and locally select the span around the mask center with the highest Normalized Pointwise Mutual Information (NPMI) to mask. We observe that in the absence of human-understandable semantics in the genomics domain (in contrast, semantic units like words and phrases are inherently available in NLP). GeneMask-based models substantially outperform the SOTA models (DNABert and LOGO) over four benchmark gene sequence classification datasets in five few-shot settings (10 to 1000-shot). More significantly, the GeneMask-based DNABert model is trained for less than one-tenth of the number of epochs of the original SOTA model. We also observe a strong correlation between top-ranked PMI tokens and conserved DNA sequence motifs, which may indicate the incorporation of latent genomic information. The codes (including trained models) and datasets are made publicly available at https://github.com/clinical-trial/GeneMask  .   
 1664  Scaling-Up LAO* in FOND Planning: An Ablation Study   
   
  Author: Ramon Fraga Pereira    
 ##MORE##The use of multi-queue heuristic search and tie-breaking strategies has shown to be very effective for satisficing planning in the Classical Planning setting. However, to the best of our knowledge, the use of such techniques has never been studied and employed in heuristic search algorithms for Fully Observable Non-Deterministic (FOND) Planning. In this paper, we adapt existing satisficing techniques for scaling-up an AND/OR heuristic search algorithm for FOND Planning. Namely, we employ multi-queue heuristic search, dead-end detection, and tie-breaking strategies in LAO* for improving the extraction of strong-cyclic policies. We assess the efficiency of our alternative techniques in LAO* through an extensive ablation study over two different FOND Planning benchmarks. Empirical results show that our techniques improve the performance of LAO* in terms of coverage, expanded nodes, and planning time compared to a well-known planner based on vanilla LAO*. Indeed, the best configuration of our techniques is competitive with the current state-of-the-art in FOND Planning.   
 1673  Expediting Self-Play Learning in AlphaZero-Style Game-Playing Agents   
   
  Authors: Yngvi Bjornsson ; Robert Leo Thormar Jonsson ; Sigurjón Ingi Jónsson    
 ##MORE##One of the main appeals of AlphaZero-style game-playing agents, which combine deep learning and Monte Carlo Tree Search, is that they can be trained autonomously without external expert-level domain knowledge. However, training such agents is generally computationally expensive, with the most computationally time-consuming step being generating training data via self-play. Here we propose an improved strategy for generating self-play training data, resulting in higher-quality samples, especially in earlier training phases. The new strategy initially emphasizes the latter game phases and gradually extends those phases to entire games as the training progresses. In our test domains, the games Connect4 and Breakthrough, we show that game-playing agents using the improved training approach learn significantly faster than counterpart agents using a standard approach. Furthermore, we empirically show that the proposed strategy is (in our test domains) superior to several recently proposed strategies for expediting self-play learning in game playing.   
 1677  Aggregating Correlated Estimations with (Almost) no Training   
   
  Authors: Théo Delemazure ; François Durand ; Fabien Mathieu    
 ##MORE##Many decision problems cannot be solved exactly and use several estimation algorithms that assign scores to the different available options. The estimation errors can have various correlations, from low (e.g. between two very different approaches) to high (e.g. when using a given algorithm with different hyperparameters). Most aggregation rules would suffer from this diversity of correlations. In this article, we propose different aggregation rules that take correlations into account, and we compare them to naive rules in various experiments based on synthetic data. Our results show that when sufficient information is known about the correlations between errors, a maximum likelihood aggregation should be preferred. Otherwise, typically with limited training data, we recommend a method that we call Embedded Voting (EV).   
 1685  Rank-envy-freeness in roommate matchings   
   
  Authors: Baptistin Coutance ; Prasanna Maddila ; Anaëlle Wilczynski    
 ##MORE##In the roommate problem, pairs of agents must be formed, based on ordinal preferences of the agents over each other. In this article, we examine fair roommate matchings by relaxing envy-freeness to account for justified envy based on the rank in the agents’ preferences. A rank-envy-free matching prevents that an agent prefers the partner of another agent whereas she has ranked it better. Although this requirement is pretty weak in house allocation [Belahcène et al., 2021], we show that it is more demanding in the roommate setting. We study parameterizations of rank-envy-freeness, as well as further natural relaxations of this concept. We also investigate the connections between this family of rank-based fairness criteria and known optimality or stability concepts.   
 1689  SPAT: Semantic-Preserving Adversarial Transformation for Perceptually Similar Adversarial Examples   
   
  Authors: Subrat Kumar Swain ; Vireshwar Kumar ; Dan Dongseong Kim ; Guangdong Bai    
 ##MORE##Although machine learning models achieve high classification accuracy against benign samples, they are vulnerable to adversarial machine learning (AML) attacks which generate adversarial samples by adding well-crafted perturbations to the benign samples. The perturbations can be increased to enhance the attack success rate, however, if the perturbations are added without considering the semantic or perceptual similarity between the benign and adversarial samples, the attack can be easily perceived/detected. As such, there exists a trade-off between the attack success rate and the perceptual similarity. In this paper, we propose a novel Semantic-Preserving Adversarial Transformation (SPAT) framework which facilitates an advantageous trade-off between the two metrics. SPAT modifies the optimisation objective of an AML attack to include the goal of increasing the attack success rate as well as the goal of maintaining the perceptual similarity between benign and adversarial samples. Our experiments on a variety of datasets including CIFAR-10, GTSRB, and MNIST demonstrate that SPAT-transformed AML attacks achieve higher attack success rates than the conventional AML attacks while maintaining the same perceptual similarity.   
 1691  Towards Feasible Counterfactual Explanations: A Taxonomy Guided Template-based NLG Method   
   
  Authors: Pedram Salimi ; Nirmalie Wiratunga ; David Corsar ; Anjana Wijekoon    
 ##MORE##Counterfactual Explanations (cf-XAI) describe the smallest changes in feature values necessary to change an outcome from one class to another. However, presently many cf-XAI methods neglect the feasibility of those changes. In this paper, we introduce a novel approach for presenting cf-XAI in natural language (Natural-XAI), giving careful consideration to actionable and comprehensible aspects while remaining cognizant of immutability and ethical concerns. We present three contributions to this endeavor. Firstly, through a user study, we identify two types of themes present in cf-XAI composed by humans: content-related, focusing on how features and their values are included from both the counterfactual and the query perspectives; and structure-related, focusing on the structure and terminology used for describing necessary value changes. Secondly, we introduce a feature actionability taxonomy with four clearly defined categories, each accompanied by an example, to streamline the explanation presentation process. Using insights from the user study and our taxonomy, we created a generalisable template-based natural language generation (NLG) method compatible with existing explainers like DICE, NICE, and DisCERN, to produce counterfactuals that address the aforementioned limitations of existing approaches. Finally, we conducted a second user study to assess the performance of our taxonomy-guided NLG templates on three domains. Our findings show that the taxonomy-guided Natural-XAI approach (n-XAI^T ) received higher user ratings across all dimensions, with significantly improved results in the majority of the domains assessed for articulation, acceptability, feasibility, and sensitivity dimensions.   
 1692  BEDCOE: Borderline Enhanced Disjunct Cluster Based Oversampling Ensemble for Online Multi-class Imbalance Learning   
   
  Authors: Shuxian Li ; Liyan Song ; Yiu-ming Cheung ; Xin Yao    
 ##MORE##Multi-class imbalance learning usually confronts more challenges especially when learning from streaming data. Most existing methods focus on manipulating class imbalance ratios, disregarding other data properties such as the borderline and the disjunct. Recent studies have shown non-negligible impact of disregarding these properties on deteriorating predictive performance. Online multi-class imbalance would further exacerbate such negative impact. To abridge the research gap of online multi-class imbalance learning, we propose to enhance the number of training times of borderline samples based on the disjunct class-wise clusters that are adaptively constructed over time for each class individually. Specifically, we propose a borderline enhanced strategy for ensemble aiming to increase the number of training times of samples neighboring to borderline areas of different classes. We also propose to generate synthetic samples for training based on the adaptively learned disjunct clusters that are maintained for each class individually online, catering for online multi-class imbalance problem directly. These two components construct the Borderline Enhanced Disjunct Cluster Based Oversampling Ensemble (BEDCOE). Experimental studies are conducted to investigate the effectiveness of BEDCOE and each of its components in dealing with online multi-class imbalance.   
 1696  Online Algorithms for Matchings with Proportional Fairness Constraints and Diversity Constraints   
   
  Authors: Anand Louis ; Meghana Nasre ; Prajakta Nimbhorkar ; Govind S. Sankar    
 ##MORE##Matching problems with group-fairness constraints and diversity constraints have numerous applications such as in allocation problems, committee selection, school choice, etc. Moreover, online matching problems have lots of applications in ad allocations and other e-commerce problems like product recommendation in digital marketing. We study two problems involving assigning items to platforms, where items belong to various groups depending on their attributes; the set of items are available offline and the platforms arrive online. In the first problem, we study online matchings with proportional fairness constraints. Here, each platform on arrival should either be assigned a set of items in which the fraction of items from each group is within specified bounds or be assigned no items; the goal is to assign items to platforms in order to maximize the number of items assigned to platforms. In the second problem, we study online matchings with diversity constraints, i.e. for each platform, absolute lower bounds are specified for each group. Each platform on arrival should either be assigned a set of items that satisfy these bounds or be assigned no items; the goal is to maximize the set of platforms that get matched. We study approximation algorithms and hardness results for these problems. The technical core of our proofs is a new connection between these problems and the problem of matchings in hypergraphs. Our experimental evaluation shows the performance of our algorithms on real-world and synthetic datasets exceeds our theoretical guarantees.   
 1703  XGBD: Explanation-Guided Graph Backdoor Detection   
   
  Authors: Zihan Guan ; Mengnan Du ; Ninghao Liu   
    
 ##MORE##Backdoor attacks are a serious security risk for graph learning models. Backdoors can be embedded in the target model by inserting backdoor triggers into the training dataset, causing the model to make incorrect predictions when the trigger is present. To counter backdoor attacks, backdoor detection has been proposed. An emerging detection strategy in the vision and NLP domains is based on an intriguing phenomenon: when training models on a mixture of backdoor and clean samples, the loss on backdoor samples drops significantly faster than on clean samples, allowing backdoor samples to be easily detected by selecting samples with the lowest loss values. However, the ignorance of topological feature information on graph data limits its detection effectiveness when directly applied to the graph domain. To this end, we propose an explanation-guided backdoor detection method to take advantage of the topological information. Specifically, we train a helper model on the graph dataset, feed each graph sample into the model, and then adopt explanation methods to attribute model prediction to an important subgraph. We observe that backdoor samples have distinct attribution distribution than clean samples, so the explanatory subgraph could serve as more discriminative features for detecting backdoor samples. Comprehensive experiments on multiple popular datasets and attack methods demonstrate the effectiveness and explainability of our method. Our code is available at https://anonymous.4open.science/r/GNN_backdoor_detection-2BBF  .   
 1706  IPERS: Individual Prioritized Experience Replay with Subgoals for Sparse Reward Multi-Agent Reinforcement Learning   
   
  Authors: Zaipeng Xie ; Yufeng Zhang ; Chentai Qiao ; Sitong Shen   
    
 ##MORE##Value decomposition methodologies have gained considerable traction in the domain of multi-agent reinforcement learning. However, in environments characterized by sparse rewards, agents encounter difficulties in assessing the effectiveness of their actions in achieving the global objective, thereby impeding the algorithm's convergence rate and overall efficacy. To tackle this issue, we propose IPERS, an efficient algorithm that utilizes Individual Prioritized Experience Replay with Subgoals for Sparse Reward Multi-Agent Reinforcement Learning. IPERS incorporates stochastic episode selection from experience replay and employs Q-learning to identify individual subgoals for each agent. By leveraging intrinsic rewards, the proposed IPERS method guides agents towards these subgoals, mitigating the adverse consequences of sparse rewards. Additionally, IPERS decomposes the joint action and combines it with prioritized experience replay to facilitate each agent's learning of state transitions. Experimental evaluations of IPERS in the SMAC environment demonstrate its swift adaptability and significant improvements in convergence performance and win rate across diverse multi-agent tasks, surpassing state-of-the-art algorithms   
 1708  No Agreement Without Loss: Learning and Social Choice in Peer Review   
   
  Authors: Pablo Barceló ; Mauricio Duarte ; Cristobal Rojas ; Tomasz Steifer    
 ##MORE##In peer review systems, reviewers are often asked to evaluate various features of submissions, such as technical quality or novelty. A score is given to each of the predefined features and based on these the reviewer has to provide an overall quantitative recommendation. It may be assumed that each reviewer has her own mapping from the set of features to a recommendation, and that different reviewers have different mappings in mind. This introduces an element of arbitrariness known as commensuration bias. In this paper we discuss a framework, introduced by Noothigattu, Shah and Procaccia, and then applied by the organizers of the AAAI 2022 conference. Noothigattu, Shah and Procaccia proposed to aggregate reviewer's mapping by minimizing certain loss functions, and studied axiomatic properties of this approach, in the sense of social choice theory. We challenge several of the results and assumptions used in their work and report a number of negative results. On the one hand, we study a trade-off between some of the axioms proposed and the ability of the method to properly capture agreements of the majority of reviewers. On the other hand, we show that dropping a certain unrealistic assumption has dramatic effects, including causing the method to be discontinuous.   
 1711  Learning Dual Mean Field Games on Graphs   
   
  Authors: Xu Chen ; Shuo Liu ; Xuan Di    
 ##MORE##Reinforcement learning (RL) has been developed for mean field games over graphs ($\mathcal{G}$-MFG) in social media and network economics, in which the transition of agents between a node pair incurs an instantaneous reward. However, agents' en-route choices on edges are largely neglected that incur an experienced reward depending on agents' actions and population evolution along edges. Here we focus on a broader class of MFGs, named "dual MFG on graphs" ($\mathcal{G}$-dMFG), which models two interacting MFGs, namely, one on edges and one at nodes over a graph. In this setting, agents select travel speed along edges and next-go-to edge at nodes for a minimum cumulative cost, which arises from the congestion effect when many agents compete for the same resource. This has various implications for autonomous driving navigation, spatial resource allocation, and internet packet routing. We establish formally that $\mathcal{G}$-dMFG is a generic $\mathcal{G}$-MFG, encompassing a more complex cost structure (that is nonseparable between states and actions) and with no need to pre-specify a termination time horizon. RL algorithms are designed to solve mean field equilibria (MFE) on large-sized networks.   
 1722  Dimensions of Similarity: Towards Interpretable Dimension-Based Text Similarity   
   
  Authors: Hans Ole Hatzel ; Fynn Petersen-Frey ; Tim Fischer ; Chris Biemann    
 ##MORE##This paper paves the way for interpretable and configurable semantic similarity search, by training state-of-the-art models for identifying textual similarity guided by a set of aspects or dimensions. The similarity models are analyzed as to which interpretable dimensions of similarity they place the most emphasis on. We conceptually introduce configurable similarity search for finding documents similar in specific aspects but dissimilar in others. To evaluate the interpretability of these dimensions, we experiment with downstream retrieval tasks using weighted combinations of these dimensions. Configurable similarity search is an invaluable tool for exploring datasets and will certainly be helpful in many applied natural language processing research applications.   
 1723  Anticipating Responsibility in Multiagent Planning   
   
  Authors: Timothy J Parker ; Umberto Grandi ; Emiliano Lorini    
 ##MORE##Responsibility anticipation is the process of determining if the actions of an individual agent may cause it to be responsible for a particular outcome. This can be used in a multi-agent planning setting to allow agents to anticipate responsibility in the plans they consider. The planning setting in this paper includes partial information regarding the initial state and considers formulas in linear temporal logic as positive or negative outcomes to be attained or avoided. We firstly define attribution for notions of active, passive and contributive responsibility, and consider their epistemic variants. We then use these to define the notion of responsibility anticipation. We prove that our notions of anticipated responsibility can be used to coordinate agents in a planning setting and give complexity results for our model, including showing that anticipation and attribution for passive responsibility are equivalent to classical planning. We also present an outline for solving some of our attribution and anticipation problems using PDDL solvers.   
 1727  Language Models as Controlled Natural Language Semantic Parsers for Knowledge Graph Question Answering   
   
  Authors: Jens Lehmann ; Preetam Gattogi ; Dhananjay R Bhandiwad ; Sébastien Ferré ; Sahar Vahdati    
 ##MORE##We propose the use of controlled natural language as a target for knowledge graph question answering (KGQA) semantic parsing via language models as opposed to using formal query languages directly. Controlled natural languages are close to (human) natural languages, but can be unambiguously translated into a formal language such as SPARQL. Our research hypothesis is that the pre-training of large language models (LLMs) on vast amounts of textual data leads to the ability to parse into controlled natural language for KGQA with limited training data requirements. We devise an LLM-specific approach for semantic parsing to study this hypothesis. Our approach takes advantage of the hallucination and self-reflection capabilities of LLMs for relation linking. To conduct our study, we created a dataset that allows the comparison of one formal and two different controlled natural languages. Our analysis shows that training data requirements are indeed substantially reduced when using controlled natural languages, which is of paramount importance since collecting and maintaining high-quality KGQA semantic parsing training data is very expensive and time-consuming.   
 1747  Optimal Alignment of Temporal Knowledge Bases   
   
  Authors: Oliver Fernandez Gil ; Fabio Patrizi ; Giuseppe Perelli ; Anni-Yasmin Turhan    
 ##MORE##Answering temporal CQs over temporalized Description Logic knowledge bases (TKB) is a main technique to realize ontology-based situation recognition. In case the collected data in such a knowledge base is inaccurate, important query answers can be missed. In this paper we introduce the TKB Alignment problem, which computes a variant of the TKB that minimally changes the TKB, but entails the given temporal CQ and is in that sense (cost-)optimal. We investigate this problem for ALC TKBs and conjunctive queries with LTL operators and devise a solution technique to compute (cost-optimal) alignments of TKBs that extends techniques for the alignment problem for propositional LTL over finite traces.   
 1753  A Logic-based Framework for Explainable Agent Scheduling Problems   
   
  Authors: Stylianos Loukas Vasileiou ; Borong Xu ; William Yeoh    
 ##MORE##Agent Scheduling Problems (ASPs) are common in various real-world situations, requiring explainable decision-making processes to effectively allocate resources to multiple agents while fostering understanding and trust. To address this need, this paper presents a logic-based framework for providing explainable decisions in ASPs. Specifically, the framework addresses two types of queries: reason-seeking queries, which explain the reasoning behind scheduling decisions, and modification-seeking queries, which offer guidance on making infeasible decisions feasible. Acknowledging the importance of privacy in multi-agent scheduling, we introduce a privacy-loss function that measures the disclosure of private information in explanations, enabling a privacy-preserving aspect in our framework. By using this function, we introduce the notion of privacy-aware explanations and present an algorithm for computing them. Empirical evaluations demonstrate the effectiveness and versatility of our approach.   
 1760  Feasible Action-Space Reduction as a Metric of Causal Responsibility in Multi-Agent Spatial Interactions   
   
  Authors: Ashwin George ; Luciano Cavalcante Siebert ; David Abbink ; Arkady Zgonnikov    
 ##MORE##Modelling causal responsibility in multi-agent spatial interactions is crucial for safety and efficiency of interactions of humans with autonomous agents. However, current formal metrics and models of responsibility either lack grounding in ethical and philosophical concepts of responsibility, or cannot be applied to spatial interactions. In this work we propose a metric of causal responsibility which is tailored to spatial interactions. In such interactions, a given agent can, by reducing another agent's feasible action space, influence the latter. Therefore, we propose feasible action space reduction (FeAR) as a metric for causal responsibility among agents. Specifically, we look at ex-post causal responsibility for simultaneous actions. We propose the use of moves de rigueur - a consistent set of prescribed actions for agents - to model the effect of norms on responsibility allocation. We applied the metric in a grid world simulation for spatial interactions and show how the actions, contexts and norms affect the causal responsibility ascribed to agents. We demonstrate the application of this metric in complex multi-agent interactions. We argue that the FeAR metric is a step towards an interdisciplinary framework for quantifying responsibility that is needed to ensure safety and meaningful human control in human-AI systems.   
 1767  Conditionally Acyclic CO-Networks for Efficient Preferential Optimization   
   
  Authors: Pierre-François Gimenez ; Jerome Mengin    
 ##MORE##This paper focuses on graphical models for modelling preferences in combinatorial space and their use for item optimization. The preferential optimization task seeks to find the preferred item that contains some defined values, which is useful for many recommendation settings found in e-commerce. We show that efficient (i.e., with polynomial time complexity) preferential optimization is achieved with a subset of cyclic CP-nets called conditional acyclic CP-net. We also introduce a new graphical preference model, called Conditional-Optimality networks (CO-networks), that are more succinct than conditional acyclic CP-nets and LP-trees but have the same expressiveness with respect to optimization. Finally, we show that preferential optimization can be used for encoding alternatives into partial instantiations, and vice versa, paving the way towards CO-nets and CP-nets unsupervised learning with the minimal description length (MDL) principle.   
 1770  An Easy Rejection Sampling Baseline via Gradient Refined Proposals   
   
  Authors: Edward Raff ; Mark McLean ; James Holt    
 ##MORE##Rejection sampling is a common tool, often touted as an ``easy'' way to obtain valid samples from a distribution $f(\cdot)$ of interest. In practice it is non-trivial to apply, often requiring considerable mathematical effort to devise a good proposal distribution $g(\cdot)$ and select a supremum $C$. More advanced samplers require additional mathematical derivations, limitations on $f(\cdot)$, or even cross-validation, making them difficult to apply. We devise a new approximate baseline approach to rejection sampling that works with less information, requiring only a differentiable $f(\cdot)$ be specified, making it easier to use. We propose a new approach to rejection sampling by refining a parameterized proposal distribution with a loss derived from the acceptance threshold. In this manner we obtain comparable or better acceptance rates on current benchmarks by up to $7.3\times$, while requiring no extra assumptions or any derivations to use: only a differentiable $f(\cdot)$ is required. While approximate, the results are correct with high probability, and in all tests pass a distributional check. This makes our approach easy to use, reproduce, and efficacious.   
 1780  On the notion of envy among groups of agents in house allocation problems   
   
  Authors: Nathanaël Gross--Humbert ; Nawal Benabbou ; Aurelie Beynier ; Nicolas Maudet    
 ##MORE##Envy-freeness is one of the prominent fairness notions in fair multiagent resource allocation but it has been mainly studied from an individual point of view. When the agents are partitioned into groups, fairness between groups is desirable. Several notions of group envy-freeness have been proposed over the last few years in the domain of fair division. In this paper we show that when groups may have different sizes and each agent gets at most one item, existing group envy-freeness notions fail to satisfy some desirable axioms. This motivates us to propose an original notion of degree of envy-freeness among groups, based on the counterfactual comparison of sub-groups of the same size. While this notion is computationally demanding, we show that it can be efficiently approximated thanks to an adapted sampling method, thus showing that our approach can be of practical relevance.   
 1794  Preference-based Reinforcement Learning towards Abstractive Timeline Summarisation   
   
  Authors: Yuxuan Ye ; Edwin Simpson    
 ##MORE##This paper introduces a novel pipeline for summarising timelines of events reported by multiple news sources. Transformerbased models for abstractive summarisation generate coherent and concise summaries of long documents but can fail to outperform established extractive methods on specialised tasks such as timeline summarisation (TLS). While extractive summaries are more faithful to their sources, they may be less readable and contain redundant or unnecessary information. This paper proposes a preference-based reinforcement learning (PBRL) method for adapting pretrained abstractive summarisers to TLS, which can overcome the drawbacks of extractive timeline summaries. We define a compound reward function that learns from keywords of interest and pairwise preference labels, which we use to fine-tune a pretrained abstractive summariser via offline reinforcement learning. We carry out both automated and human evaluation on three datasets, finding that our method outperforms a comparable extractive TLS method on two of the three benchmark datasets, and participants prefer our method’s summaries to those of both the extractive TLS method and the pretrained abstractive model. The method does not require expensive reference summaries and needs only a small number of preferences to align the generated summaries with human preferences.   
 1795  Ada-QPacknet - Multi-Task Forget-Free Continual Learning with Quantization Driven Adaptive Pruning   
   
  Authors: Marcin Pietroń ; Dominik Żurek ; Kamil Faber ; Roberto Corizzo    
 ##MORE##Continual learning (CL) is a challenging machine learning setting that is attracting the interest of an increasing number of researchers. Among recent CL works, architectural strategies appear particularly promising due to their potential to expand and adapt the model architecture as new tasks are presented. However, existing solutions do not efficiently exploit model sparsity due to the adoption of constant pruning ratios. Moreover, current approaches exhibit a tendency to quickly saturate model capacity since the number of weights is limited and each weight is restricted to a single value. In this paper, we propose Ada-QPacknet, a novel architectural CL method that resorts to adaptive pruning and quantization. These two features allow our model to overcome the two crucial issues of effective exploitation of model sparsity and efficient use of model capacity. Specifically, adaptive pruning restores model capacity by reducing the number of weights assigned to each task to a smaller subset of weights that preserves the performance of the full set, allowing other weights to be used for future tasks. Adaptive quantization separates each weight into multiple components with adaptively reduced bit-width, allowing a single weight to solve more than one task without significant performance drops, leading to improved exploitation of model capacity. Experimental results on benchmark CL scenarios show that our proposed method achieves better results in terms of accuracy than existing rehearsal, regularization, and architectural CL strategies. Moreover, our method significantly outperforms forget-free competitors in terms of efficient exploitation of model capacity.   
 1808  Adaptive Self-supervision Algorithms for Physics-informed Neural Networks   
   
  Authors: Shashank Subramanian ; Robert Kirby ; Michael Mahoney ; Amir Gholami    
 ##MORE##Physics-informed neural networks (PINNs) incorporate physical knowledge from the problem domain as a soft constraint on the loss function, but recent work has shown that this can lead to optimization difficulties. Here, we study the impact of the location of the collocation points on the trainability of these models. We find that the vanilla PINN performance can be significantly boosted by adapting the location of the collocation points as training proceeds. Specifically, we propose a novel adaptive collocation scheme which progressively allocates more collocation points (without increasing their number) to areas where the model is making higher errors (based on the gradient of the loss function in the domain). This, coupled with a judicious restarting of the training during any optimization stalls (by simply resampling the collocation points in order to adjust the loss landscape) leads to better estimates for the prediction error. We present results for several problems, including a 2D Poisson and diffusion-advection system with different forcing functions. We find that training vanilla PINNs for these problems can result in up to 70% prediction error in the solution, especially in the regime of low collocation points. In contrast, our adaptive schemes can achieve up to an order of magnitude smaller error, with similar computational complexity as the baseline. Furthermore, we find that the adaptive methods consistently perform on-par or slightly better than vanilla PINN method, even for large collocation point regimes. The code for all the experiments has been anonymously open-sourced.   
 1811  Symbolic Knowledge-Extraction Evaluation Metrics: The FiRe Score   
   
  Authors: Federico Sabbatini ; Roberta Calegari    
 ##MORE##Symbolic knowledge-extraction (SKE) techniques are becoming of key importance for AI applications since they enable the explanation of opaque black-box predictors, enhancing trust and transparency. Among all the available SKE techniques, the best option for the case at hand should be selected. However, an automatic comparison between different options can be performed only if an adequate metric -- such as a scoring function resuming all the interesting features of the extractors -- is provided. The definition of evaluation metrics for symbolic knowledge extractors is currently neglected in the literature. Accordingly, in this paper we introduce the FiRe score metric to assess the quality of a symbolic knowledge-extraction procedure, taking into account both its predictive performance and the readability of the extracted knowledge. It is compared to another existing scoring metric and a rigorous mathematical formulation is provided along with several practical examples to highlight its effectiveness to the end of being exploited inside automatic hyper-parameter tuning procedures.   
 1812  How should I compute my candidates? A taxonomy and classification of diagnosis computation algorithms   
   
  Author: Patrick Rodler    
 ##MORE##Model-based diagnosis is a powerful, versatile and well-founded approach to troubleshooting a wealth of different types of systems. Diagnosis algorithms are both numerous and highly heterogeneous. In this work, we propose a taxonomy that allows their standardized assessment, classiﬁcation and comparison. The aim is to (i) give researchers and practitioners an impression of the diverse landscape of available techniques, (ii) allow them to easily retrieve and compare the main features as well as pros and cons, and (iii) facilitate the selection of the “right” algorithm to adopt for a particular problem case, e.g., in practical diagnostic settings, for comparison in experimental evaluations, or for reuse, modiﬁcation, extension, or improvement in the course of research. Finally, we demonstrate the value and application of the taxonomy by assessing and categorizing a range of more than 30 important diagnostic methods, and we point out how using the taxonomy as a common guideline for algorithm analysis would beneﬁt the research community in various regards.   
 1815  On Sustainable Ride Pooling through Conditional Expected Value Decomposition   
   
  Authors: Avinandan Bose ; Hao Jiang ; Pradeep Varakantham ; Zichang Ge    
 ##MORE##Centralized Multi-Agent Reinforcement Learning (MARL) presents itself as an ideal framework for aggregation companies (e.g., Uber, Lyft, Deliveroo) that have to take a sequential set of centralized decisions on assigning individual agents (typically resources like taxis, food delivery personnel) to customer requests online in the presence of demand uncertainty. However, centralized learning is especially challenging in such very large scale environments, with thousands of agents/resources and hundreds of thousands of requests coming in each day. In this paper, we provide a novel value decomposition mechanism that is able to tackle the scale and provide high quality (matching) decisions at each time step. We show that our value decomposition approach, Conditional Expectation  
  based Value Decomposition (CEVD) is more sustainable (requires 9.9% fewer vehicles to serve equal number of requests) and more efficient (serves 9.76% more requests, while traveling 13.32% lesser distance) than the current best approach over two different city scale (New York and Chicago) benchmarks for ride pooling using taxis.   
 1825  Finite Sample Guarantees of Differentially Private Expectation Maximization Algorithm   
   
  Authors: Di Wang ; Jiahao Ding ; Lijie Hu ; Zejun Xie ; Miao Pan ; Jinhui Xu    
 ##MORE##(Gradient) Expectation Maximization (EM) is a widely used algorithm for estimating the maximum likelihood of mixture models or incomplete data problems. A major challenge facing this popular technique is how to effectively preserve the privacy of sensitive data. Previous research on this problem has already lead to the discovery of some Differentially Private (DP) algorithms for (Gradient) EM. However, unlike in the non-private case, existing techniques are not yet able to provide finite sample statistical guarantees. To address this issue, we propose in this paper the first DP version of Gradient EM algorithm with statistical guarantees. Specifically, we first propose a new mechanism for privately estimating the mean of a heavy-tailed distribution, which significantly improves a previous result in \cite{wangicml2020}, and it could be extended to the local DP model, which has not been studied before. Next, we apply our general framework to three canonical models: Gaussian Mixture Model (GMM), Mixture of Regressions Model (MRM) and Linear Regression with Missing Covariates (RMC). Specifically, for GMM in the DP model, our estimation error is near optimal in some cases. For the other two models, we provide the first result on finite sample statistical guarantees. Our theory is supported by thorough numerical experiments on both real-world data and synthetic data.   
 1834  Answer Set Automata: A Learnable Pattern Specification Framework for Complex Event Recognition   
   
  Authors: Nikos Katzouris "Demokritos"; Paliouras Georgios    
 ##MORE##Complex Event Recognition (CER) systems detect event occurrences in streaming input using predefined event patterns. Techniques that learn event patterns from data highly desirable in CER. Since such patterns are typically represented by symbolic automata, we propose a family of such automata where the transition-enabling conditions are defined by Answer Set Programming (ASP) rules, and which, thanks to the strong connections of ASP to symbolic learning, are learnable from data. We present such a learning approach in ASP, capable of jointly learning the structure of an automaton, while synthesizing the transition guards from building-block predicates, and a scalable, incremental version thereof that progressively revises models learnt from mini-batches using Monte Carlo Tree Search. We evaluate our approach on three CER datasets and empirically demonstrate its efficacy.   
 1838  Omega-Regular Reward Machines   
   
  Authors: Ernst Moritz Hahn ; Mateo Perez ; Sven Schewe ; Fabio Somenzi ; ashutosh trivedi ; Dominik Wojtczak    
 ##MORE##Reinforcement learning (RL) is a powerful approach to training agents to perform tasks, but designing an appropriate reward mechanism is critical to its success. However, in many cases, the complexity of the learning objectives goes beyond the capabilities of the Markovian assumption, necessitating a more sophisticated reward mechanism. Reward machines and omega-regular languages are two formalisms used to express non-Markovian rewards for quantitative and qualitative objectives, respectively. This paper introduces omega-regular reward machines, which integrate reward machines with omega-regular languages to enable an expressive and effective reward mechanism for RL. We present a model-free RL algorithm to compute epsilon-optimal strategies against omega-regular reward machines and evaluate the effectiveness of the proposed algorithm through experiments.   
 1846  NEHATE: Large-Scale Annotated Data Shedding Light on Hate Speech in Nepali Local Election Discourse   
   
  Authors: Surendrabikram Thapa ; Kritesh Rauniyar ; Shuvam Shiwakoti ; Sweta Poudel ; Usman Naseem ; Mehwish Nasim    
 ##MORE##The use of social media during election campaigns has become increasingly popular. However, the unbridled nature of online discourse can lead to the propagation of hate speech, which has far-reaching implications for the democratic process. Natural Language Processing (NLP) techniques are being used to counteract the spread of hate speech and promote healthy online discourse. Despite the increasing need for NLP techniques to tackle hate speech, research on low-resource languages like Nepali is limited, posing a challenge to the realization of the United Nations' Leave No One Behind principle, which calls for inclusive development that benefits all individuals and communities, regardless of their backgrounds or circumstances. To bridge this gap, we introduce NEHATE, a large-scale manually annotated dataset of hate speech and its targets in Nepali local election discourse. The dataset comprises 13,505 tweets, annotated for hate speech with further sub-categorization of hate speech into targets such as community, individual, and organization. Benchmarking of the dataset with various algorithms has shown potential for improvement in performance. We have made the dataset publicly available to promote further research and development, while also contributing to the UN SDGs aimed at fostering peaceful, inclusive societies and justice and strong institutions.   
 1858  Automatic Parallel Portfolio Selection   
   
  Authors: Haniye Kashgarani ; Lars Kotthoff    
 ##MORE##Algorithms to solve hard combinatorial problems often exhibit complementary performance, i.e. where one algorithm fails, another shines. Algorithm portfolios and algorithm selection take advantage of this by running all algorithms in parallel or choosing the best one to run on a problem instance. In this paper, we show that neither of these approaches gives the best possible performance and propose the happy medium of running a subset of all algorithms in parallel. We propose a method to choose this subset automatically for each problem instance, and demonstrate empirical improvements of up to 19% in terms of runtime, 81% in terms of misclassification penalty, and 26% in terms of penalized averaged runtime on scenarios from the ASlib benchmark library. Unlike all other algorithm selection and scheduling approaches in the literature, our performance measures are based on the actual performance for algorithms running in parallel rather than assuming overhead-free parallelization based on sequential performance. Our approach is easy to apply in practice and does not require to solve hard problems to obtain a schedule, unlike other techniques in the literature, while still delivering superior performance.   
 1875  S2M: Converting Single-Turn to Multi-Turn Datasets for Conversational Question Answering   
   
  Authors: Baokui Li ; Sen Zhang ; Wangshu Zhang ; Yicheng Chen ; Changlin Yang ; Sen Hu ; TENG XU ; Siye Liu ; Jiwei Li    
 ##MORE##Supplying data augmentation to conversational question answering (CQA) can effectively improve model performance. However, there is less improvement from single-turn datasets in CQA due to the distribution gap between single-turn and multi-turn datasets. On the other hand, while numerous single-turn datasets are available, we have not utilized them effectively. To solve this problem, we propose a novel method to convert single-turn datasets to multi-turn datasets. The proposed method consists of three parts, namely, a QA pair Generator, a QA pair Reassembler, and a question Rewriter. Given a sample consisting of context and single-turn QA pairs, the Generator obtains candidate QA pairs and a knowledge graph based on the context. The Reassembler utilizes the knowledge graph to get sequential QA pairs, and the Rewriter rewrites questions from a conversational perspective to obtain a multi-turn dataset S2M. Our experiments show that our method can synthesize effective training resources for CQA. Notably, S2M ranks 1st place on the QuAC leaderboard1 at the time of submission (Aug 24th, 2022).   
 1891  Towards Legal Judgment Summarization: A Structure-Enhanced Approach   
   
  Authors: Qiqi Wang ; Ruofan Wang ; Kaiqi Zhao ; Robert Amor ; Benjamin Liu ; Xianda Zheng ; Zeyu Zhang ; Zijian Huang    
 ##MORE##Judgment summaries are beneficial for legal practitioners to comprehend and retrieve case law efficiently. Unlike summaries in general domains, e.g., news, judgment summaries often requires a clear structure. Such a structure helps readers grasp the information contained in the summary and reduces information loss. To the best of our knowledge, none of the existing text summarizers can generate summaries aligned with the summary structure in the legal domain. Inspired by this observation, this paper introduces a Summary Structure-Enhanced (SSE) method to synthesize structured summaries for legal documents. SSE can easily be incorporated into the Encoder-Decoder framework, which is commonly adopted in state-of-the-art text summarizers. Experiments on the datasets of New Zealand and Chinese judgments show that the proposed method consistently improves the performance of state-of-the-art summarizers in terms of Rouge scores.   
 1892  Diffusion Multi-unit Auctions with Diminishing Marginal Utility Buyers   
   
  Authors: Haolin Liu ; Xinyuan Lian ; Dengji Zhao    
 ##MORE##We consider an auction design problem where a seller sells multiple homogeneous items to a set of connected buyers. Each buyer only knows the buyers she directly connects with and has a diminishing marginal utility valuation for the items. The seller initially only connects to some buyers who can be directly invited to the sale by the seller. Our goal is to design an auction to incentivize the buyers who are aware of the auction to further invite their neighbors to join the auction. This is challenging because the buyers are competing for the items and they would not invite each other by default. Thus, rewards need to be given to buyers who diffuse information, but the rewards should be carefully designed to guarantee both invitation incentives and the seller's revenue. Solutions have been proposed recently for the settings where each buyer requires at most one unit and demonstrated the difficulties of the design. We move this forward to propose the very first diffusion auction for the multi-unit demand settings to improve both the social welfare and the seller's revenue.   
 1910  Task-prompt Generalized World Model in Multi-environment Offline Reinforcement Learning   
   
  Authors: Xuantang Xiong ; Linghui Meng ; Jingqing Ruan ; Qingyang Zhang ; Guoqi Li ; Xing Dengpeng ; Bo Xu    
 ##MORE##Offline reinforcement learning (RL) circumvents costly interactions with the environment by utilising historical trajectories. Incorporating a world model into this method could substantially enhance the transfer performance of various tasks without expensive calculations from scratch. However, due to the complexity arising from different types of generalisation, previous works have focused almost exclusively on single-environment tasks. In this study, we introduce a multi-environment offline RL setting to investigate whether a generalised world model can be learned from large, diverse datasets and serve as a good surrogate for policy learning in different tasks. Inspired by the success of multi-task prompt methods, we propose the Task-prompt Generalised World Model (TGW) framework, which demonstrates notable performance in this setting. TGW comprises three modules: a task-state prompter, a generalised dynamics module, and a reward module. We implement the generalised dynamics module as a transformer-based recurrent state-space model (TransRSSM) and employ prompts to provide task-specific instructions, enabling TGW to address the internal stochasticity of the generalised world model. On the MuJoCo control benchmarks, TGW significantly outperforms previous offline RL algorithms in multi-environment setting.   
 1927  Automatic Radiology Report Generation by Learning with Increasingly Hard Negatives   
   
  Authors: Bhanu Prakash Voutharoja ; Lei Wang ; Luping Zhou    
 ##MORE##Automatic radiology report generation is challenging as medical images or reports are usually similar to each other due to the common content of anatomy. This makes a model hard to capture the uniqueness of individual images and is prone to producing undesired generic or mismatched reports. This situation calls for learning more discriminative features that could capture even fine-grained mismatches between images and reports. To achieve this, this paper proposes a novel framework to learn discriminative image and report features by distinguishing them from their closest peers, i.e., hard negatives. Especially, to attain more discriminative features, we gradually raise the difficulty of such a learning task by creating increasingly hard negative reports for each image in the feature space during training, respectively. By treating the increasingly hard negatives as auxiliary variables, we formulate this process as a min-max alternating optimisation problem. At each iteration, conditioned on a given set of hard negative reports, image and report features are learned as usual by minimising the loss functions related to report generation. After that, a new set of harder negative reports will be created by maximising a loss reflecting image-report alignment. By solving this optimisation, we attain a model that can generate more specific and accurate reports. It is noteworthy that our framework enhances discriminative feature learning without introducing extra network weights. Also, in contrast to the existing way of generating hard negatives, our framework extends beyond the granularity of the dataset by generating harder samples out of the training set. Experimental study on benchmark datasets verifies the efficacy of our framework and shows that it can serve as a plug-in to readily improve existing medical report generation models.   
 1928  Fingerprint Attack: Client De-Anonymization in Federated Learning   
   
  Authors: Qiongkai Xu ; Trevor Cohn ; Olga Ohrimenko    
 ##MORE##Federated Learning allows collaborative training without data sharing in settings where participants do not trust the central server and one another. Privacy can be further improved by ensuring that communication between the participants and the server is anonymized through a shuffle; decoupling the participant id from their data. This paper seeks to examine whether such a defense is adequate to guarantee anonymity, by proposing a novel fingerprinting attack over gradients sent by the participants to the server. We show that clustering of gradients can easily break the anonymization in an empirical study of learning federated language models on two language corpora. We then show that training with differential privacy can provide a practical defense against our fingerprint attack.   
 1930  Using Earley Parser for Recognizing Totally Ordered Hierarchical Plans   
   
  Authors: Kristýna Pantůčková ; Roman Barták    
 ##MORE##Earley Parser is a top-down parser proposed for context-free grammars and used, for example, in the grammar constraint. Parsing trees of context-free grammars are very close to task decomposition trees used in hierarchical planning, specifically when the actions are totally ordered. This paper suggests using the Earley Parser to recognize totally ordered hierarchical plans. Given a sequence of actions - a prefix of the plan - and a task decomposition model, the plan recognition problem asks which task decomposes to a plan containing the given plan prefix. We will show that the Earley parser significantly increases the speed of plan recognition compared to the existing bottom-up parsing-based plan recognizer. The Earley parser's performance is also on a par with the planning-based plan recognizer despite not using any planning heuristics.   
 1932  Action-Failure Resilient Planning   
   
  Authors: Diego Aineto ; Alessandro Gaudenzi ; Alfonso Gerevini ; Alberto Rovetta ; Enrico Scala ; Ivan Serina    
 ##MORE##In the real world, the execution of the actions planned for an agent is never guaranteed to succeed, as they can fail in a number of unexpected ways that are not explicitly captured in the planning model. Based on these observations, we introduce the task of finding plans for classical planning that are resilient to action execution failures. We refer to this problem as Resilient Planning and to its solutions as K-resilient plans; such plans guarantee that an agent will always be able to reach its goals (possibly by replanning alternative sequences of actions) as long as no more than K failures occur along the way. We also present ResPlan, a new algorithm for Resilient Planning, and we compare its performance to methods based on compiling Resilient Planning to FOND planning.   
 1933  Pareto Rank-Preserving Supernetwork for Hardware-aware Neural Architecture Search   
   
  Authors: Hadjer Benmeziane ; Kaoutar El Maghraoui ; Hamza Ouarnoughi ; Smail Niar    
 ##MORE##In neural architecture search (NAS), training every sampled architecture is very time-consuming and should be avoided. Weight-sharing is a promising solution to speed up the evaluation process. However, training the supernetwork incurs many discrepancies between the actual ranking and the predicted one. Additionally, efficient deep-learning engineering processes require incorporating realistic hardware-performance metrics into the NAS evaluation process, also known as hardware-aware NAS (HW-NAS). In HW-NAS, estimating task-specific performance and hardware efficiency are both required. This paper proposes a supernetwork training methodology that preserves the Pareto ranking between its different subnetworks resulting in more efficient and accurate neural networks for a variety of hardware platforms. The results show a 97% near Pareto front approximation in less than 2 GPU days of search, which provides 2x speed up compared to state-of-the-art methods. We validate our methodology on NAS-Bench-201, DARTS, and ImageNet. Our optimal model achieves 77.2% accuracy (+1.7% compared to baseline) with an inference time of 3.68ms on Edge GPU for ImageNet, which yields a 2.3x speedup. Training implementation can be found: https://anonymous.4open.science/r/PRP-NAS-7CA6/    
 1934  Semantic-Aware Dual Contrastive Learning for Multi-label Image Classification   
   
  Authors: Leilei Ma ; Dengdi Sun ; Lei Wang ; Haifeng Zhao ; Bin Luo    
 ##MORE##Extracting image semantics effectively and assigning corresponding labels to multiple objects or attributes for natural images is challenging due to the complex scene contents and confusing label dependencies. Recent works have focused on modeling label relationships with graph and understanding object regions using class activation maps (CAM). However, these methods ignore the complex intra- and inter-category relationships among specific semantic features, and CAM is prone to generate noisy information. To this end, we propose a novel semantic-aware dual contrastive learning framework that incorporates sample-to-sample contrastive learning (SSCL) as well as prototype-to-sample contrastive learning (PSCL). Specifically, we leverage semantic-aware representation learning to extract category-related local discriminative features and construct category prototypes. Then based on SSCL, label-level visual representations of the same category are aggregated together, and features belonging to distinct categories are separated. Meanwhile, we construct a novel PSCL module to narrow the distance between positive samples and category prototypes and push negative samples away from the corresponding category prototypes. Finally, the discriminative label-level features related to the image content are accurately captured by the joint training of the above three parts. Experiments on five challenging large-scale public datasets demonstrate that our proposed method is effective and outperforms the state-of-the-art methods. Code and supplementary materials are released on https://github.com/yu-gi-oh-leilei/SADCL  .   
 1937  Epistemic JAADL: A Modal Logic for Joint Abilities with Imperfect Information   
   
  Authors: Zhaoshuai Liu ; Aiting Liang ; Yongmei Liu    
 ##MORE##Coordination and joint ability are important problems in representation and reasoning about multi-agent systems. Ghaderi et al. presented a formalization of joint ability of coalitions in the expressive first-order language of the situation calculus. Essentially, a coalition has joint ability to achieve a goal if after iterated elimination of dominated strategies, any remaining joint strategy achieves the goal. Based on their work, Liu et al. proposed JAADL, a modal logic for joint abilities under strategy commitments. In this paper, we propose EJAADL, an epistemic extension of JAADL, for imperfect information games where agents may have incomplete knowledge or even false beliefs about the world. Like Ghaderi et al.’s work, elimination of dominated strategies is now based on beliefs about the world, rather than facts about the world as in JAADL. Strategies are required to be uniform, i.e., they select the same action in all accessible histories. We illustrate EJAADL with examples, analyze its properties, and show that model checking memoryless EJAADL is in EXPTIME. Morover, we consider the fragment of memoryless EJAADL with only bounded number of elimination of dominated strategies, and show that the model checking problem for this fragment can be done in PSPACE.   
 1941  A Two-stage Approximately Orthogonal Training Framework in Deep Neural Networks   
   
  Authors: Taoyong Cui ; Jianze Li ; Yuhan Dong ; Li Liu    
 ##MORE##The orthogonality constraints, including the hard and soft ones, have been used to normalize the weight matrices of Deep Neural Network (DNN) models, especially the Convolutional Neural Network (CNN) and Vision Transformer (ViT), to reduce model parameter redundancy and improve training stability. However, the robustness to noisy data of these models with constraints is not always satisfactory. In this work, we propose a novel two-stage approximately orthogonal training framework (TAOTF) to find a trade-off between the orthogonal solution space and the main task solution space to solve this problem in noisy data scenarios. In the first stage, we propose a novel algorithm called polar decomposition-based orthogonal initialization (PDOI) to find a good initialization for the orthogonal optimization. In the second stage, unlike other existing methods, we apply soft orthogonal constraints for all layers of DNN model. We evaluate the proposed model-agnostic framework both on the natural image and medical image datasets, which show that our method achieves stable and superior performances to existing methods.   
 1949  Read Key Points: Dialogue-Grounded Knowledge Points Generation with Multi-Level Salience-Aware Mixture   
   
  Authors: Sen Zhang ; Baokui Li ; Wangshu Zhang ; Changlin Yang ; Yicheng Chen ; Sen Hu ; Teng Xu ; Jiwei Li    
 ##MORE##Knowledge-grounded dialogue (KGD) has become increasingly essential for online services, enabling individuals to obtain desired information. While KGD contains knowledge information, most knowledge points are fragmented and repeated in dialogues, making it difficult for users to quickly grasp complete and key information from a collection of sessions. In this paper, we propose a novel task of dialogue-grounded knowledge points generation (DialKPG) to condense a collection of sessions on a topic into succinct and complete knowledge points. To enable empirical study, we create TopicDial and OpenDial corpus based on two existing knowledge-grounded dialogue corpus FaithDial and OpenDialKG by a Three-Stage Annotation Framework, and establish a novel approach for DialKPG task, namely MSAM (Multi-Level Salience-Aware Mixture). MSAM explicitly incorporates salient information at the token-level, utterance-level, and session-level to better guide knowledge points generation. Extensive experiments have verified the effectiveness of our method over competitive baselines. Furthermore, our analysis shows that the proposed model is particularly effective at handling long inputs and multiple sessions due to its strong capability of duplicated elimination and knowledge integration.   
 1955  Towards Trustworthy NLP: An Adversarial Robustness Enhancement based on Perplexity Difference   
   
  Authors: Zhaocheng Ge ; Hanping Hu ; Tengfei Zhao    
 ##MORE##The vulnerability of artificial intelligence has become a bottleneck, with adversarial attacks posing a significant threat to natural language processing. Although multiple defense mechanisms have been proposed, they often suffer from strong constraints, weak generalization, and low scalability. To address these issues, we propose leveraging perplexity to quantify the difference between clean and adversarial examples based on the observation of numerous cases. We then statistically prove the significant difference between them using Bayesian hypothesis testing.  
  Subsequently, we develop an adversarial defense framework named UMPS, which contains two branches: “Uncovering the Mask”(UM) and “Perplexity-guided Sampling”(PS). UM utilizes a masked language model and JW distance to recover out-of-vocabulary words, while PS employs perplexity to locate the optimal sample within a convex hull which is constructed with integrated gradients. Theoretically, the proposed framework fulfills three requirements: effectiveness, universality, and portability. The experimental results demonstrate that UMPS effectively enhances the robustness of language models including Bert, against advanced attacks and outperforms three baselines. Furthermore, the ablation study is conducted to support the validity and necessity of the two branches, and the post-hoc test of the difference in perplexity explains the defense performance of our framework.   
 1958  CERM: Context-aware Literature-based Discovery via Sentiment Analysis   
   
  Authors: Julio Christian Young ; Uchenna Akujuobi    
 ##MORE##Motivated by the abundance of biomedical publications and the need to better understand the relationship between food and health, we study a new sentiment analysis task based on literature- based discovery. Many attempts have been made to introduce health into recipe recommendation systems and food analysis. However, these methods focus highly on ingredient nutritional components or use simple computational models trained on curated labeled data. With the high availability of food and health information in biomedical texts but with a high cost of data labeling, there is a need for enhanced models to capture the intrinsic relationship between food ingredients and biomedical concepts, including genes, diseases, nutrition, and chemicals. This model should also utilize both available labeled resources and unlabelled data. In this paper, we propose a new sentiment analysis task called Entity Relationship Sentiment Analysis (ERSA) that focuses on capturing the relationship between biomedical and food concepts. This task extends the popularly studied Aspect Based Sentiment Analysis (ABSA) task. Specifically, our study focuses on the sentiment analysis of (entity-entity) pairs given a biomedical text sentence. This task presents a more significant challenge than traditional sentiment analysis tasks, as the sentiment expressed in the sentence may not necessarily reflect the sentiment of the relationship between two given entities in the sentence. Furthermore, we propose a semi-supervised architecture that combines two different types of word embeddings to encode the ERSA task better. The experimental results demonstrate that our proposed method consistently outperforms other semi-supervised learning methods across various learning scenarios.   
 1965  A Model-theoretic Approach to Belief Revision in Multi-agent Belief Logic and its Syntactic Characterizations   
   
  Authors: Aiting Liang ; Yongmei Liu    
 ##MORE##Belief change studies how an agent modifies her beliefs on receiving new information. However, so far most research on belief change works on beliefs represented in propositional logic. There have been many works on integrating belief revision with reasoning about actions, and some works extending belief change from propositional logic to epistemic logics. In this paper, we study revision on beliefs of a third person represented with the multi-agent KD45 logic. Our formal technique is analogous to that of distance-based belief revision in propositional logic: to revise a KB by a formula, select from models of the formula those that are closest to models of the KB. To this end, a challenge is that in modal logics, a formula may have infinitely many Kripke models. To tackle this, we propose a variant of Moss' canonical formulas called alternating canonical formulas, treat them as models for formulas, and define a notion of distance between them, based on the Hausdorff distance between two sets. We show that our revision satisfies all of the AGM postulates. To give syntactic characterizations of our revision, we make use of a normal form for KD45n called alternating cover disjunctive formulas (ACDFs). We give syntactic characterizations firstly on fragments of ACDFs called proper ACDFs and alternating cover conjunctive formulas (ACCFs), and finally on the whole ACDFs.   
 1968  High-Multiplicity Fair Allocation Using Parametric Integer Linear Programming   
   
  Authors: Robert Bredereck ; Andrzej Kaczmarczyk ; Dušan Knop ; Rolf Niedermeier    
 ##MORE##Using insights from parametric integer linear programming, we significantly improve a previous result [Proc. ACM EC 2019] on high-multiplicity fair allocation. Therein (answering an open question from a preceding work [Proc. IJCAI 2016]) the authors proved that the problem of finding envy-free Pareto-efficient allocations of indivisible items is fixed-parameter tractable with respect to the combined parameter “number of agents” plus “number of item types.” Our central improvement, compared to this result, is to break the condition that the corresponding utility and multiplicity values have to be encoded in unary required there. Concretely, we show that, while preserving fixed-parameter tractability, these values can be encoded in binary, thus greatly expanding the range of feasible values.   
 1969  T-VAKS: A Tutoring-based Multimodal Dialog System via Knowledge Selection   
   
  Authors: Raghav Jain ; Tulika Saha ; Sriparna Saha    
 ##MORE##Advancements in Conversational Natural Language Processing (NLP) have the potential to address critical social challenges, particularly in achieving the United Nations' Sustainable Development Goal of quality education through the development of Virtual Tutors. However, the application of NLP in the educational domain, especially language learning, has been limited due to the inherent complexities of the field and the scarcity of available datasets. In this paper, we introduce T-VAKS (Tutoring Virtual Agent with Knowledge Selection), a novel language tutoring multimodal Virtual Agent (VA) designed to assist students in learning a new language. Our approach employs an information theory-based knowledge selection module built on top of a multimodal seq2seq generative model, facilitating the generation of appropriate, informative, and contextually relevant tutor responses. T-VAKS aims to bridge the gap between NLP and the educational domain, enabling more effective language tutoring through intelligent virtual agents. The knowledge selection module consists of two sub-modules: (i) knowledge relevance estimation, and (ii) knowledge focusing framework. We evaluate the performance of our proposed model against various baseline models and the most recent state-of-the-art models, using multiple evaluation metrics. The results demonstrate that T-VAKS outperforms competing models, highlighting the potential of our approach in enhancing language learning through the use of conversational NLP and virtual agents, ultimately addressing social challenges and promoting well-being.   
 1972  LFAA: Crafting Transferable Targeted Adversarial Examples with Low-Frequency Perturbations   
   
  Authors: Kunyu Wang ; Juluan SHI ; Wenxuan Wang    
 ##MORE##Deep neural networks are susceptible to adversarial attacks, which pose a significant threat to their security and reliability in real-world applications. The most notable adversarial attacks are transfer-based attacks, where an adversary crafts an adversarial example to fool one model, which can also fool other models. While previous research has made progress in improving the transferability of untargeted adversarial examples, the generation of targeted adversarial examples that can transfer between models remains a challenging task. In this work, we present a novel approach to generate transferable targeted adversarial examples by exploiting the vulnerability of deep neural networks to perturbations on high-frequency components of images. We observe that replacing the high-frequency component of an image with that of another image can mislead deep models, motivating us to craft perturbations containing high-frequency information to achieve targeted attacks. To this end, we propose a method called Low-Frequency Adversarial Attack (LFAA), which trains a conditional generator to generate targeted adversarial perturbations that are then added to the low-frequency component of the image. Extensive experiments on ImageNet demonstrate that our proposed approach significantly outperforms state-of-the-art methods, improving targeted attack success rates by a margin from 3.2% to 15.5%.   
 1977  GridFormer: Spatial-Temporal Transformer Network for Citywide Crowd Flow Prediction   
   
  Authors: Chaoqun Su ; Chenwang Wu ; Defu Lian    
 ##MORE##Crowd flow prediction is vital in various fields such as traffic management, public safety, and urban planning. The main challenge in crowd flow prediction lies in effectively modeling the periodic temporal dependency and long-range spatial dependency. In the temporal domain, crowd flow shows a strong periodicity which is exploited by existing works to build multi-time-scale spatial-temporal features. However, these works hardly consider the disturbance of periods, that is, the crowd flow is not strictly periodic. In the spatial domain, existing works mainly utilize CNN to capture spatial dependency, but the small receptive field of the convolution operator limits the ability to capture the long-range dependency between crowd flows in different regions. In this paper, we propose GridFormer, a Transformer network, in which a periodically shifted sampling method and attention mechanism are employed to handle the temporal shifting in the daily and weekly periodicity, and a pyramid 3D Swin Transformers network is designed to capture long-range spatial dependency in a hierarchical manner. Meanwhile, the pyramid 3D Swin Transformers network jointly models spatial-temporal features to enable better interaction between the spatial and temporal domains. Experimental results on three crowd flow datasets demonstrate that our GridFormer outperforms the state-of-the-art crowd flow prediction methods.   
 1988  Fair Deep Reinforcement Learning with Preferential Treatment   
   
  Authors: Guanbao Yu ; Umer Siddique ; Paul Weng    
 ##MORE##Learning fair policies in reinforcement learning (RL) is important when the RL agent may impact many users. We investigate a variant of this problem where equity is still desired, but some users may be entitled to preferential treatment. In this paper, we formalize this more sophisticated fair optimization problem in deep RL using generalized fair social welfare functions (SWF), provide a theoretical discussion to justify our approach, explain how deep RL algorithms can be adapted to tackle it, and empirically validate our propositions on several domains. Our contributions are both theoretical and algorithmic, notably: (1) We obtain a general bound on the suboptimality gap in terms of SWF-optimality using average reward of a policy SWF-optimal for the discounted reward, which notably justifies using standard deep RL algorithms, even for the average reward; (2) Our algorithmic innovations include a state-augmented DQN-based method for learning either deterministic or stochastic policies, which also applies to the usual fair optimization setting without any preferential treatment.   
 1989  Local context is not enough! Towards Query Semantic and Knowledge Guided Multi-Span Medical Question Answering   
   
  Authors: Abhisek Tiwari ; Aman Bhansali ; Sriparna Saha ; Pushpak Bhattacharya ; Preeti Verma ; Minakshi Dhar    
 ##MORE##Medical Question Answering (MedQA) is one of the most popular and significant tasks in developing healthcare assistants. When humans extract an answer to a question from a document, they first (a) understand the question itself in detail and (b) utilize relevant knowledge/experiences to determine the answer segments. In multi-span question answering, it becomes increasingly important to comprehend the query accurately and possess relevant knowledge, as the interrelationship among different answer segments is essential for achieving completeness. Motivated by this, we first propose a transformer-based query semantic and knowledge ({\em QueSemKnow}) guided multi-span question-answering model. The proposed {\em QueSemKnow} works in a two-phased manner; in the first stage, a multi-task model is proposed to extract query semantics: (i) intent identification and (ii) question type prediction. In the second stage, {\em QueSemKnow} selects a relevant subset of the knowledge graph as the underlying context/document and extracts answers depending on the semantic information extracted from the first stage and context. We build a multi-task query semantic extraction model for query intent and query type identification to investigate the co-relation among these tasks. We also develop a semantically aware medical question-answering corpus called {\em QueSeMSpan MedQA}, where each question is tagged with its semantic information. The proposed model outperforms several baselines and existing state-of-the-art models by a large margin on multiple datasets, which firmly demonstrates the effectiveness of the human-inspired multi-span question-answering methodology. The dataset and code are available at https://github.com/AnonymousRW/QueSemKnow  /.   
 2007  Progression for Monitoring in Temporal ASP   
   
  Authors: Davide Soldà ; Ignacio D. Lopez-Miguel ; Ezio Bartocci ; Thomas Eiter    
 ##MORE##In recent years, there has been growing interest in the application of temporal reasoning approaches and non-monotonic logics from artificial intelligence in dynamic systems that generate data. A well-known approach to temporal reasoning is the use of the progression technique, which allows for the online computation of logical consequences of a logical knowledge base over time. We consider the progression technique for Temporal Here and There and Temporal Equilibrium Logic, which is the logic underlying answer programming over linear-temporal logic (LTL). Compared to usual LTL online computation, where the goal is to check whether a trace is compliant with a temporal specification, our approach provides also the means to compute non-monotonic temporal reasoning over a trace of observations. Besides formal notions and results, we also present an algorithm for performing progression to monitor a dynamic system, which has been implemented as a proof of concept and allows for handling expressive application scenarios.   
 2034  THUNDER: Named Entity Recognition using a Teacher-student Model with Dual Classifiers for Strong and Weak Supervisions   
   
  Authors: Seongwoong Oh ; Woohwan Jung ; Kyuseok Shim    
 ##MORE##Strong and weak supervisions have complementary characteristics. However, utilizing both supervisions for named entity recognition (NER) has not been extensively studied. Moreover, the existing works address only incomplete annotations and neglects inaccurate annotations during NER model training. To effectively utilize weak labels, we introduce an auxiliary classifier that learns from weak labels. Furthermore, we adopt the teacher-student framework to handle both incomplete and inaccurate weak labels. A teacher model is first trained using both strongly and weakly supervised data, and next generates pseudo labels to replace weak labels. Then, the student model is trained so that the main classifier learns from both strong labels and confident pseudo labels while the auxiliary classifier learns from less confident pseudo labels. We also incorporate data augmentation through ChatGPT to generate additional annotated sentences to improve model performance and generalization capabilities. The experimental results with different weak supervisions demonstrate that our proposed method surpasses existing techniques.   
 2043  Graduality in Probabilistic Argumentation Frameworks   
   
  Authors: Jeroen P Spaans ; Dragan Doder    
 ##MORE##Gradual semantics are methods that evaluate overall strengths of individual arguments in graphs. In this paper, we investigate gradual semantics for extended frameworks in which probabilities are used to quantify the uncertainty about arguments and attacks belonging to the graph. We define the likelihoods of an argument's possible strengths when facing uncertainty about the topology of the argumentation framework. We also define an approach to compare the strengths of arguments in this probabilistic setting. Finally, we propose a method to calculate the overall strength of each argument in the framework, and we evaluate this method against a set of principles.   
 2048  Grouped Multi-Task Learning with Hidden Tasks Enhancement   
   
  Authors: Jiachun Jin ; Jiankun Wang ; Lu Sun ; Jie Zheng ; Mineichi Kudo    
 ##MORE##In multi-task learning (MTL), multiple prediction tasks are learned jointly, such that generalization performance is improved by transferring information across the tasks. However, not all tasks are related, and training unrelated tasks together can worsen the prediction performance because of the phenomenon of negative transfer. To overcome this problem, we propose a novel MTL method that can robustly group correlated tasks into clusters and allow useful information to be transferred only within clusters. The proposed method is based on the assumption that the task clusters lie in the low-rank subspaces of the parameter space, and the number of them and their dimensions are both unknown. By applying subspace clustering to task parameters, parameter learning and task grouping can be done in a unified framework. To relieve the error induced by the basic linear learner and robustify the model, the effect of hidden tasks is exploited. Moreover, the framework is extended to a multi-layer architecture so as to progressively  
  extract hierarchical subspace structures of tasks, which helps to further improve generalization. The optimization algorithm is proposed, and its effectiveness is validated by experimental results on both synthetic and real-world datasets.   
 2056  Generating Replanning Goals through Multi-objective Optimization in Response to Execution Observation   
   
  Authors: Alberto Pozanco ; Daniel Borrajo ; Manuela Veloso    
 ##MORE##In some applications, planning-monitoring systems generate plans and monitor their execution by other agents. During execution, agents might deviate from these plans for various reasons. The deviation from the expected behavior will be observed by the planning-monitoring system, which will replan in order to provide the agent a new suggested plan. Most existing replanning approaches maintain the goals and compute a plan that achieves them under  
  the new circumstances. This is often not realistic, as achieving the original goal might be very costly or impossible under the new circumstances. Furthermore, replanning approaches usually overlook agent’s behavior up to the observed deviation from the original plan. In this paper we introduce GREPLAN, a novel approach that proposes new replanning goals (and plans) by solving a multi-objective optimization problem that considers all goals within a perimeter of the original goal. Empirical results in several planning benchmarks show that GREPLAN successfully reacts to deviations from the original plan by generating new appropriate replanning goals.   
 2073  Compilation of tight ASP programs   
   
  Authors: Carmine Dodaro ; Giuseppe Mazzotta ; Francesco Ricca    
 ##MORE##Answer Set Programming (ASP) is a well-known AI formalism. Traditional ASP systems, that follow the “ground&Solve” approach, are intrinsically limited by the so-called grounding bottleneck. Basically, the grounding step (i.e., variable-elimination) can be computationally expensive and even unfeasible in several cases of practical interest. Recent work demonstrated that the grounding bottleneck can be partially overcome by compiling in external propagators subprograms acting as constraints. In this paper a novel compilation technique is presented that can be applied to tight normal programs; thus, the class of ASP programs that can be compiled is extended beyond constraints. The approach is implemented in the new system ProASP. ProASP skips entirely the grounding phase, and performs solving by injecting custom propagators in GLUCOSE. An experiment conducted on ground-intensive ASP benchmarks shows that ProASP is capable of solving instances that are out of reach for state-of-the-art ASP systems   
 2096  SUDS: Sanitizing Universal and Dependent Steganography   
   
  Authors: Preston Robinette ; Taylor T Johnson ; David Wang ; Nishan Shehadeh ; Daniel C Moyer    
 ##MORE##Steganography, or hiding messages in plain sight, is a form of information hiding that is most commonly used for covert communication. As modern steganographic mediums include images, text, audio, and video, this communication method is being increasingly used by bad actors to propagate malware, exfiltrate data, and discreetly communicate. Current protection mechanisms rely upon steganalysis, or the detection of steganography, but these approaches are dependent upon prior knowledge, such as steganographic signatures from publicly available tools and statistical knowledge about known hiding methods. These dependencies render steganalysis useless against new or unique hiding methods, which are becoming increasingly common with the application of deep learning models. To mitigate the shortcomings of steganalysis, this work focuses on a deep learning sanitization technique called SUDS that is not reliant upon knowledge of steganographic hiding techniques and is able to sanitize universal and dependent steganography. SUDS is tested using least significant bit method (LSB), dependent deep hiding (DDH), and universal deep hiding (UDH). We demonstrate the capabilities and limitations of SUDS by answering five research questions, including baseline comparisons and an ablation study. Additionally, we apply SUDS to a real-world scenario, where it is able to increase the resistance of a poisoned classifier against attacks by 1375%.   

 Honorary patronage   
     
  Jacek Majchrowski, Mayor of the City of Kraków   

 Co-organized and supported by   
     
  Jagiellonian University in Kraków   

  AGH University of Science and Technology    

  Krakow Technology Park    

  Silver Sponsors   

  ​     

 Bronze Sponsors   
  
  ​     

  ​     
  
  ​     
  
  ​     

  Media Partners   

  ​     
  
  ​     

  ​     
  
  ​     

  Official Community Partner   

  ​     
  
  ​     

 © 2023 26th European Conference on Artificial Intelligence ECAI 2023  
  e-mail: contact@ecai2023.eu