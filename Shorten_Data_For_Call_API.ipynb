{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hàm Extract Date Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregate file created at: D:/2023-playwright/shorten_aggregate_file.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "def extract_information(\n",
    "    input_dir=\"D:/2023-playwright/text-from-html-data-test\", \n",
    "    output_dir=\"D:/2023-playwright/shorten/test-2023/text-from-html-data\", \n",
    "):\n",
    "    parent_dir = os.path.basename(os.path.dirname(input_dir))\n",
    "    year_match = re.search(r\"\\d{4}\", parent_dir)\n",
    "    if year_match:\n",
    "        base_year = int(year_match.group())\n",
    "    else:\n",
    "        print(\"Không tìm thấy năm trong tên thư mục!\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(input_dir):\n",
    "        raise FileNotFoundError(f\"Input directory not found: {input_dir}\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # File tổng hợp\n",
    "    aggregate_file_path = \"D:/2023-playwright/shorten_aggregate_file.txt\"\n",
    "\n",
    "    # Khởi tạo từ khóa và regex\n",
    "    date_name_keywords = [\"submission\", \"deadline\", \"paper\", \"notification\", \"acceptance\", \"camera\", \"due\", \"ready\", \"final\", \"author\"]\n",
    "    special_keywords = [r\"\\$\", r\"http\", r\"volume\"]\n",
    "    month_keywords = [\n",
    "        \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"Jun\", \"May\", \"Jul\", \"Aug\", \"Sep\", \"Sept\", \"Oct\", \"Nov\", \"Dec\",\n",
    "        \"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"\n",
    "    ]\n",
    "\n",
    "    # Regex patterns\n",
    "    date_name_pattern = re.compile(r\"(\\b\" + r\"\\b|\\b\".join(date_name_keywords) + r\"\\b)\", re.IGNORECASE)\n",
    "    month_pattern = re.compile(r\"(\\b\" + r\"\\b|\\b\".join(month_keywords) + r\"\\b)\", re.IGNORECASE)\n",
    "    time_pattern = re.compile(r\"\\b\\d{1,2}:\\d{2}\\b\")\n",
    "    special_pattern = re.compile(r\"(\" + r\"|\".join(special_keywords) + r\")\", re.IGNORECASE)\n",
    "    four_digit_pattern = re.compile(r\"(\\d{4})\")\n",
    "    non_four_digit_pattern = re.compile(r\"(?<!\\d)\\d{1,3}(?!\\d)\")\n",
    "    two_number_valid_or_four_number_pattern = re.compile(r\"(?<!\\d)(0?[1-9]|[12][0-9]|3[01])(?!\\d)|(\\d{4})\")\n",
    "\n",
    "\n",
    "    # Hàm kiểm tra số lớn hơn 31\n",
    "    def contains_large_number(line):\n",
    "        numbers = [int(num) for num in non_four_digit_pattern.findall(line)]\n",
    "        return any(num > 31 for num in numbers)\n",
    "\n",
    "    # Hàm kiểm tra dòng hợp lệ\n",
    "    def is_valid_line(line):\n",
    "        year_matches = four_digit_pattern.findall(line)\n",
    "        contains_valid_year = not year_matches or all(base_year - 1 <= int(year) <= base_year + 1 for year in year_matches)\n",
    "\n",
    "        return (\n",
    "            not contains_large_number(line) and\n",
    "            not time_pattern.search(line) and\n",
    "            not special_pattern.search(line) and\n",
    "            contains_valid_year\n",
    "        )\n",
    "\n",
    "    # Hàm thêm ngữ cảnh xung quanh một dòng\n",
    "    def add_context_lines(lines, idx, added_lines, context_range=2):\n",
    "        context_buffer = []\n",
    "        for i in range(-context_range, context_range + 1):\n",
    "            neighbor_idx = idx + i\n",
    "            if 0 <= neighbor_idx < len(lines) and (lines[neighbor_idx], neighbor_idx) not in added_lines:\n",
    "                context_buffer.append(lines[neighbor_idx])\n",
    "                added_lines.add((lines[neighbor_idx], neighbor_idx))\n",
    "        return context_buffer\n",
    "\n",
    "    # Xử lý các file\n",
    "    with open(aggregate_file_path, \"w\", encoding=\"utf-8\") as aggregate_file:\n",
    "        for filename in os.listdir(input_dir):\n",
    "            file_path = os.path.join(input_dir, filename)\n",
    "            if not os.path.isfile(file_path):\n",
    "                continue\n",
    "\n",
    "\n",
    "            # Trích xuất từ khóa từ tên file (phần trước dấu gạch dưới cuối cùng)\n",
    "            file_keyword = \"_\".join(filename.rsplit('_', 1)[0].split('_'))\n",
    "\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                lines = file.readlines()\n",
    "\n",
    "            final_lines = []\n",
    "            added_lines = set()\n",
    "\n",
    "            for idx, line in enumerate(lines):\n",
    "                contains_date_keyword = date_name_pattern.search(line)\n",
    "                contains_day_and_month = month_pattern.search(line) and two_number_valid_or_four_number_pattern.search(line)\n",
    "\n",
    "                contains_geo_entity = re.search(\n",
    "                    fr\"(\\b({base_year}|{file_keyword})\\b)|\"\n",
    "                    fr\"(\\b(in|at)\\b.*\\b(conference|event|{file_keyword})\\b|\"\n",
    "                    fr\"\\b(conference|event|{file_keyword})\\b.*\\b(in|at)\\b)\", \n",
    "                    line, \n",
    "                    re.IGNORECASE\n",
    "                )\n",
    "\n",
    "                if any([contains_date_keyword, contains_day_and_month, contains_geo_entity]) and is_valid_line(line):\n",
    "                    context_lines = add_context_lines(lines, idx, added_lines)\n",
    "                    final_lines.extend(context_lines)\n",
    "            \n",
    "\n",
    "            # Lọc các dòng không chứa số lớn hơn 31\n",
    "            final_lines = [\n",
    "                line for line in final_lines\n",
    "                if is_valid_line(line)  # Loại bỏ dòng nếu chứa số lớn hơn 31\n",
    "            ]\n",
    "\n",
    "            # Loại bỏ dòng trống và ghi kết quả\n",
    "            final_lines = [line for line in final_lines if line.strip()]\n",
    "            if final_lines:\n",
    "                # output_path = os.path.join(output_dir, filename)\n",
    "                # with open(output_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "                #     output_file.write(\"\".join(final_lines))\n",
    "\n",
    "                aggregate_file.write(f\"File: {filename}\\n\")\n",
    "                aggregate_file.write(\"\".join(final_lines) + \"\\n\\n\")\n",
    "\n",
    "    print(\"Aggregate file created at:\", aggregate_file_path)\n",
    "\n",
    "extract_information()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'D:/2023-playwright/shorten/test-2023/text-from-html-data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 41\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTổng số dòng đã gộp từ tất cả các file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_lines\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile tổng hợp được tạo tại: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m \u001b[43maggregate_all_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 13\u001b[0m, in \u001b[0;36maggregate_all_files\u001b[1;34m(input_dir, output_file)\u001b[0m\n\u001b[0;32m      9\u001b[0m aggregate_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/2023-playwright/all_aggregate_file.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Mở file tổng hợp để ghi\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m aggregate_file:\n\u001b[0;32m     14\u001b[0m     total_lines \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Duyệt qua từng file trong thư mục input\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'D:/2023-playwright/shorten/test-2023/text-from-html-data'"
     ]
    }
   ],
   "source": [
    "def aggregate_all_files(\n",
    "    input_dir=\"D:/2023-playwright/text-from-html-data-test\", \n",
    "    output_file=\"D:/2023-playwright/shorten/test-2023/text-from-html-data\"\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Gộp nội dung của tất cả các file trong thư mục input_dir vào một file tổng hợp.\n",
    "    \"\"\"\n",
    "\n",
    "    # Mở file tổng hợp để ghi\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as aggregate_file:\n",
    "        total_lines = 0\n",
    "\n",
    "        # Duyệt qua từng file trong thư mục input\n",
    "        for filename in os.listdir(input_dir):\n",
    "            file_path = os.path.join(input_dir, filename)\n",
    "\n",
    "            # Kiểm tra nếu là file\n",
    "            if os.path.isfile(file_path):\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                    lines = file.readlines()\n",
    "\n",
    "                # Loại bỏ các dòng trống\n",
    "                non_empty_lines = [line for line in lines if line.strip() != \"\"]\n",
    "\n",
    "                # Đếm số dòng không trống và ghi vào file tổng hợp\n",
    "                line_count = len(non_empty_lines)\n",
    "                total_lines += line_count\n",
    "\n",
    "                \n",
    "                aggregate_file.write(f\"File: {filename}\\n\")\n",
    "                aggregate_file.write(\"\".join(lines) + \"\\n\\n\")\n",
    "                print(f\"Đã gộp file {filename} với {line_count} dòng.\")\n",
    "\n",
    "        print(f\"Tổng số dòng đã gộp từ tất cả các file: {total_lines}\")\n",
    "\n",
    "    print(f\"File tổng hợp được tạo tại: {output_file}\")\n",
    "\n",
    "aggregate_all_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
