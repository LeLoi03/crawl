1. BMVC_0 conference:
BMVC 2023      
 Home 
  Dates 
  Attending | About the City  Registration  Student Funding  Plan Your Visit  Venue 
  Programme | Conference Schedule  Keynotes  Oral Presentations  Poster Presentations  Workshops  Proceedings  Programme (PDF)  Workshop Proceedings 
  Authors | Call for Papers  Call for Workshops  Call for Papers - Doctoral Consortium  Frequently Asked Questions  Rebuttal Instructions  Reviewing Guidelines  Submit Your Paper 
  People | Organisers  Volunteers  Area Chairs  Emergency Reviewers  Reviewers 
  Sponsors 

 The 34 th  British Machine Vision Conference  20 th  - 24 th  November 2023, Aberdeen, UK     

 The 34 th  British Machine Vision Conference   20 th  - 24 th  November 2023, Aberdeen, UK    

 The British Machine Vision Conference (BMVC) is the British Machine Vision Association’s (BMVA) annual conference on machine vision, image processing, and pattern recognition. It is one of the major international conferences on computer vision and related areas held in the UK. With increasing popularity and quality, it has established itself as a prestigious event on the vision calendar.  
 THANKS TO EVERYONE THAT MADE BMVC2023 A SUCCESS! SEE YOU AT BMVC2024 IN GLASGOW!  
  
  -Photos of the event can be found here  .  
 -If you liked the Attendr App  please rate it in the Google Play/Apple store. It would mean a lot to us!  
 -Special Issue: Our sponsor, Frontiers in Imaging  has launched a Research Topic for BMVC 2023, more information here  .  
   
 Call for Papers  
 The 34th BMVC will be held from 20th - 24th November 2023. We invite papers to be submitted for the conference and ask that potential authors read the call for papers  that details both the topics of interest for the conference.  
 See the Call for Papers   
   
 See the whole timeline   

 About the BMVC  
 The British Machine Vision Conference is organised by The British Machine Vision Association and Society for Pattern Recognition  for the purposes of the scholarly advancement of education and research in machine vision, pattern recognition and associated academic research areas, including the application of such scholarly research within industry. The Association is a Company limited by guarantee, No.2543446, and a non-profit-making body, registered in England and Wales as Charity No.1002307 (Registered Office: Dept. of Computer Science, Durham University, South Road, Durham, DH1 3LE, UK).  
   
 Sponsors   
 Platinum Sponsor    
     
 Gold Sponsors    
         
 Special Sponsors    

  News  
 [28 Sep.] | The conference schedule is available now: | [link] | . 
  [29 Aug.] | BMVC is now CORE rank A. 
  [22 Aug.] | The complete list of accepted papers is available now: | [link] | . 
  [21 Jun.] | Conference registration is available now.: | [link] | . 
  [4 Apr.] | The CMT submission site is open: | [link] | . 
  [20 Feb.] | The "call for workshops" is now available here: | [link] | . Workshop proposal submission deadline: 5th May 2023. 
  [17 Jan.] | Paper abstract and submission deadlines are released, see the details here: | [link] | . 

   BMVCconf   
 News by BMVCconf    

 © 2022-2023 The BMVA    
  [email protected]     
 The British Machine Vision Conference is organised by The British Machine Vision Association and Society for Pattern Recognition  . The Association is a Company limited by guarantee, No.2543446, and a non-profit-making body, registered in England and Wales as Charity No.1002307 (Registered Office: Dept. of Computer Science, Durham University, South Road, Durham, DH1 3LE, UK).

2. BSN_3 conference:
IEEE.org 
  IEEE CS Standards 
  Career Center 
  About Us 
  Subscribe to Newsletter 
  More | IEEE Standards 
  Career Center 
  About Us 
  Subscribe to Newsletter 
   Sign In 
  0 

   MEMBERSHIP | Overview | For Industry Professionals 
  For Students 
  Launch a New Career 
  Membership FAQ 
  Contact Us 
  Membership Information | Membership FAQs 
  Membership Grades 
  Special Circumstances 
  Discounts & Payments 
  Distinguished Contributor Recognition 
  Grant Programs 
  Communities | Find a Local Chapter 
  Find a Distinguished Visitor 
  About Distinguished Visitors Program 
  Find a Speaker on Early Career Topics 
  Technical Communities 
  Collabratec (Discussion Forum) 
  Current Members | Renew 
  My Profile 
  My Subscriptions 
  My Referrals 
  Computer  Magazine 
  ComputingEdge  Magazine 
  CONFERENCES | Let us help make your event a success.  EXPLORE PLANNING SERVICES 
  Discover Conferences | Events Calendar 
  Calls for Papers 
  Conference Proceedings 
  Conference Highlights 
  Top 2024 Conferences 
  Organize a Conference | Conference Sponsorship Options 
  Conference Planning Services 
  Conference Organizer Resources 
  Virtual Conference Guide 
  Conference Publishing Services | Get a Quote 
  CPS Dashboard 
  CPS Author FAQ 
  CPS Organizer FAQ 
  PUBLICATIONS | Find the latest in advanced computing research.  VISIT THE DIGITAL LIBRARY 
  Discover Publications | Magazines 
  Journals 
  Calls for Papers 
  Open Access 
  ComputingEdge  Magazine 
  Tech News Blog 
  Peer Review Resources | Author Guidelines 
  Reviewer Information 
  Guest Editor Information 
  Editor Information 
  Editor-in-Chief Information 
  Volunteer Opportunities 
  Additional Resources | Podcasts 
  Video Library 
  My Subscriptions 
  Member Benefits 
  Institutional Library Subscriptions 
  Advertising and Sponsorship 
  EDUCATION & CAREER | Research | Magazines 
  Journals 
  Conference Proceedings 
  Video Library 
  ComputingEdge  Magazine 
  Tech News Blog 
  Education & Career | Code of Ethics 
  Educational Webinars 
  Online Education 
  Certifications 
  Podcasts 
  Career Center 
  Industry & Trends | Tech News Blog 
  Industry Webinars & Whitepapers 
  Research Reports 
  Bodies of Knowledge 
  Standards 
  CS for Industry Professionals 
  Additional Resources | Resource Library 
  Newsletters 
  Women in Computing 
  Recruiting 
  Press Room 
  Digital Library Access 
  VOLUNTEER | Get Involved | Organize a Conference 
  Run a Publication 
  Become a Distinguished Speaker 
  Participate in Standards Activities 
  Peer Review Content 
  Volunteer Opportunities 
  Publish | Author Resources 
  Calls for Papers 
  Publish Open Access 
  CPS Author FAQ 
  Leadership Network | Society Leadership 
  Boards & Committees 
  Technical Communities 
  Local Chapters 
  Community Resources | Governance Resources 
  Conference Organizer Resources 
  Conference Publishing Services 
  Editor Information 
  Chapter Resources 
  Elections 
  ABOUT | About the Society | About Us 
  About the Board of Governors 
  Board of Governors Members 
  Grant Programs 
  Diversity & Inclusion 
  Communities | Boards & Committees 
  Technical Communities 
  Find a Local Chapter 
  Open Volunteer Opportunities 
  Awards & Recognition | Award Recipients 
  Fellows 
  Student Scholarships & Awards 
  Nominate an Election Candidate 
  Nominate a Colleague 
  Partnerships & Society News | Corporate Partnerships 
  Conference Sponsorships & Exhibits 
  Advertising 
  Recruitment 
  Press Room 
  JOIN US 
   MORE | Publications 
  Education & Career 
  Volunteer 
  About 

 Home  / Conferences     

 CLOSED: Call for Papers: IEEE BSN 2023  
 9 - 11 October 2023 | Boston, MA, USA   

 Share this on:           

 Submissions Due: 5 June 2023   
 Important Dates  
 Full Paper (4-pages) Deadline: 5 June 2023 
  Paper Acceptance Notification: 21 July 2023 
  Conference: 9-11 October 2023 
   IEEE-EMBS 19th International Conference on Body Sensor Networks – Sensors and Systems for Digital Health  ( IEEE BSN  ) is the premier conference in the areas of sensors and systems for digital health. Celebrating the 20 years of IEEE BSN, the conference will embrace its new branding for “Sensors and Systems for Digital Health.” Sponsored by the IEEE Engineering in Medicine and Biology Society (IEEE-EMBS), the conference will be co-located with the IEEE-EMBS Conference on Healthcare Innovation and Point-of-Care Technologies (IEEE HI-POCT) in Boston.  
 IEEE BSN will bring together leaders and experts in academia, industry, healthcare, and non-profit organizations and provide a cross-disciplinary, highly selective, and single-track forum for cutting-edge research related to devices and sensors, hardware and software systems, predictive models, and data analytics in the healthcare/medical domains. Areas of interest include but are not limited to:  
 Novel digital health solutions (i.e., sensors and algorithms) for diagnosis, disease progress tracking, and self-management. 
  Prototyping of novel in-body, on-body, and off-body sensors and systems for digital health, wellness, and sports. 
  Conformable decoders: unintrusive, comfortable, self-powered sensors and systems. 
  Flexible, stretchable, and imperceptible electronics for sensors and systems. 
  Contactless solutions for human sensing. 
  Power-optimization for implantable and wearable sensors and systems. 
  Wearable robotics system for digital healthcare. 
  Signal processing, machine learning, deep learning, and decision-support algorithms. 
  Adaptive, personalized intervention systems by closing the loop between technologies and humans. 
  Security, privacy, and trust in digital health technologies. 
  Inclusiveness, fairness, and equality for under-represented and under-served communities in digital health technologies and studies. 
  Human-centered design for digital healthcare to address real-world stakeholder needs. 
   Special Session – Clinical Abstract  
 New to this year’s conference, we invite the submission of clinical abstracts. Our goal is to bring together technical researchers and clinicians together to identify unmet clinical needs, explore potential technical solutions, and/or demonstrate the translation of novel technologies to clinical care. Abstracts will be non-archival.  
 We seek submissions from clinicians and teams partnering with clinicians on novel uses of digital health technologies. Abstracts could focus on introducing new clinical problems, preliminary successes, and demonstration of technological solutions relevant to the following topics. Teams will have the opportunity to present their work as posters and lightning talks and attend the full conference. These abstracts will focus on applications of digital health technologies in domains such as (but not limited to):  
 Clinical translation and application of digital health technologies in clinical settings or remote health settings. 
  Use of digital health technologies for diagnosis and treatment decision-making. 
  Point-of-care technologies for clinical care in remote and underserved settings. 
  Important  : The authors will have the option to submit the full paper version of their abstract to the journals of their choice. Our editorial team has established partnerships with Circulation: Cardiovascular Quality and Outcomes   and Frontiers in Digital Health   to support concurrent or successive publication of the full paper version (instructions will be announced soon).  
  Submission​ ​Details  
 IEEE BSN 2023 will accept the following paper formats:  
 Full papers (4 pages) 
  Demo/Poster abstracts (1 page) 
  SUBMISSION SITE    
 Importance:  IEEE BSN 2023 will accept regular, workshop, demo, and poster papers. The Best Paper Award  and the BSN Service Award  will be presented at the conference. Excellent papers (e.g., Best Paper Award candidates) will be invited to extend their works for rapid review and publication in the IEEE Open Journal of Engineering in Medicine and Biology  ( OJEMB   )  or PLOS Digital Health   . IEEE OJEMB will waive the Article Processing Charges. In addition, Student Travel Awards  will be provided to selected students from worldwide institutions.  

 Recommended by IEEE Computer Society  
     
 Three Tips for Avoiding the IT Bucket Shop   

 Master Data Governance and the Use of AI in Supply Chain Operations   

 An Investment in AI: Not an Option but a Mandate for Financial Services   

 The Role of Ethics in Gaming Design: How to Optimize Player Well-being, Fairness, and Inclusivity   

 Intent-Based Networking: The Future of Network Management Using AI   

 AI and Ethics: Bridging The Gap   

 Working with Recruiters: Five Tips for Early Career Professional   

 How System Integration Unlocks New Growth and Profit Potential   

  Sign up for our newsletter.  
 EMAIL ADDRESS  

 IEEE COMPUTER SOCIETY  
 About Us 
  Board of Governors 
  Newsletters 
  Press Room 
  IEEE Support Center 
  Contact Us 
  DIGITAL LIBRARY  
 Magazines 
  Journals 
  Conference Proceedings 
  Video Library 
  Librarian Resources 
    
 COMPUTING RESOURCES  
 Career Center 
  Courses & Certifications 
  Webinars 
  Podcasts 
  Tech News 
  Membership 
  COMMUNITY RESOURCES  
 Governance 
  Conference Organizers 
  Authors 
  Chapters 
  Communities 
    
 BUSINESS SOLUTIONS  
 Corporate Partnerships 
  Conference Sponsorships & Exhibits 
  Advertising 
  Recruiting 
  Digital Library Institutional Subscriptions 
   
  POLICIES  
 Privacy 
  Accessibility Statement 
  IEEE Nondiscrimination Policy 
  XML Sitemap 

 ©IEEE — All rights reserved. Use of this website signifies your agreement to the IEEE Terms and Conditions.  
 A not-for-profit organization, the Institute of Electrical and Electronics Engineers (IEEE) is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity.  

    Sign In

3. ADCS_3 conference:
IR   Anthology        

 Main  »   
  Australasian Document Computing Symposium  
  2021   
   
 ADCS '21: Australasian Document Computing Symposium, Virtual Event, Australia, 9 December 2021 | 12 papers 

 2019   
   
 Proceedings of the 24th Australasian Document Computing Symposium, ADCS 2019, Sydney, Australia, December 5-6, 2019 | 6 papers 

 2018   
   
 Proceedings of the 23rd Australasian Document Computing Symposium, ADCS 2018, Dunedin, New Zealand, December 11-12, 2018 | 14 papers 

 2017   
   
 Proceedings of the 22nd Australasian Document Computing Symposium, ADCS 2017, Brisbane, QLD, Australia, December 7-8, 2017 | 13 papers 

 2016   
   
 Proceedings of the 21st Australasian Document Computing Symposium, ADCS 2016, Caulfield, VIC, Australia, December 5-7, 2016 | 15 papers 

 2015   
   
 Proceedings of the 20th Australasian Document Computing Symposium, ADCS 2015, Parramatta, NSW, Australia, December 8-9, 2015 | 13 papers 

 2014   
   
 Proceedings of the 2014 Australasian Document Computing Symposium, ADCS 2014, Melbourne, VIC, Australia, November 27-28, 2014 | 23 papers 

 2013   
   
 The Australasian Document Computing Symposium, ADCS '13, Brisbane, QLD, Australia, December 5-6, 2013 | 19 papers 

 2012   
   
 The Seventeenth Australasian Document Computing Symposium, ADCS '12, Dunedin, New Zealand, December 5-6, 2012 | 20 papers 

 2004   
   
 ADCS 2004, Proceedings of the Ninth Australasian Document Computing Symposium, Melbourne, Australia, December 13, 2004 | 14 papers 

 2002   
   
 ADCS 2002, Proceedings of the Seventh Australasian Document Computing Symposium, Sydney, Australia, December 16, 2002 | 28 papers 

 Credits  • Contribute   ©2023 Webis Group  •       • Contact  • Impressum / Terms / Privacy

4. BMVC_1 conference:
BMVC 2023      

 The 34 th  British Machine Vision Conference Proceedings  

 If there are any mistakes on this page, please do not hesitate to contact yyliu@cs.jhu.edu   
 -1   
 4 | Instance Mask Growing on Leaf    
  Chuang Yang (Northwestern Polytechnical University), Haozhao Ma (Northwestern Polytechnical University), Qi Wang (Northwestern Polytechnical University)*  
  PDF  Poster  Video  Code 
 7 | HWD: A Novel Evaluation Score for Styled Handwritten Text Generation    
  Vittorio Pippi (University of Modena and Reggio Emilia),* Fabio Quattrini (University of Modena and Reggio Emilia), Silvia Cascianelli (Università di Modena e Reggio Emilia), Rita Cucchiara (Università di Modena e Reggio Emilia)  
  PDF  Poster  Video  Supplementary  Code 
 10 | Improving Out-of-Distribution Detection Performance using Synthetic Outlier Exposure Generated by Visual Foundation Models    
  Gitaek Kwon (VUNO Inc.), Jaeyoung Kim (VUNO Inc.),* Hong-Jun Choi (VUNO Inc.), Byung-Moo Yoon (Gachon University), Sungchul Choi (Pukyong National University), Kyu-Hwan Jung (Sungkyunkwan University)  
  PDF  Video  Supplementary  Code 
 12 | RestNet: Boosting Cross-Domain Few-Shot Segmentation with Residual Transformation Network    
  Xinyang Huang (Beijing University of Posts and Telecommunications),* Chuang Zhu (Beijing University of Posts and Telecommunications ), Wenkai Chen (Beijing University of Posts and Telecommunications)  
  PDF  Poster  Video 
 14 | A-Scan2BIM: Assistive Scan to Building Information Modeling    
  Weilian Song (Simon Fraser University),* Jieliang Luo (Autodesk Research), Dale Zhao (Autodesk Research), Yan Fu (Autodesk Research), Chin-Yi Cheng (Google Research), Yasutaka Furukawa (Simon Fraser University)  
  PDF  Video  Supplementary  Code 
 15 | The Interstate-24 3D Dataset: a new benchmark for 3D multi-camera vehicle tracking    
  Derek Gloudemans (Vanderbilt University),* Daniel Work (Vanderbilt University), Yanbing Wang (Vanderbilt University), Gracie E Gumm (Vanderbilt University), William Barbour (Vanderbilt University)  
  PDF  Poster  Video  Code 
 16 | VETIM: Expanding the Vocabulary of Text-to-Image Models only with Text    
  Martin Nicolas Everaert (EPFL),* Marco Bocchio (Largo.ai), Sami Arpa (Largo.ai), Sabine Süsstrunk (EPFL), Radhakrishna Achanta (EPFL)  
  PDF  Poster  Video  Supplementary 
 18 | Random Word Data Augmentation with CLIP for Zero-Shot Anomaly Detection    
  Masato Tamura (Hitachi America, Ltd.)*  
  PDF  Poster  Video  Supplementary 
 22 | Locality-Aware Hyperspectral Classification    
  Fangqin Zhou (Technology University of Eindhoven), Mert Kilickaya (Eindhoven University of Technology),* Joaquin Vanschoren (Eindhoven University of Technology)  
  PDF  Poster  Video  Supplementary  Code 
 25 | Motion and Context-Aware Audio-Visual Conditioned Video Prediction    
  Yating Xu (National University of Singapore),* Conghui Hu (National University of Singapore), Gim Hee Lee (National University of Singapore)  
  PDF  Poster  Video  Supplementary 
 33 | Scale Adaptive Network for Partial Person Re-identification: Counteracting Scale Variance    
  HongYu Chen (Northwestern Polytechnical University),* BingLiang Jiao (Northwestern Polytechnical University ), Liying Gao ( Northwestern Polytechnical University), Peng Wang (Northwestern Polytechnical University)  
  PDF  Poster  Video  Code 
 40 | Learning a Pedestrian Social Behavior Dictionary    
  Faith M Johnson (Rutgers University),* Kristin Dana (Rutgers University)  
  PDF  Poster  Video 
 45 | A Critical Robustness Evaluation for Referring Expression Comprehension Methods    
  zhipeng zhang (Northwestern Polytechnical University), Zhimin Wei (Northwestern Polytechnical University), Peng Wang (Northwestern Polytechnical University)*  
  PDF  Video  Code 
 46 | Joint Low-light Enhancement and Super Resolution with Image Underexposure Level Guidance    
  Mingjie Xu (Beihang University), Chaoqun Zhuang (Beihang University), Feifan Lv (Beihang University), Feng Lu (Beihang University)*  
  PDF  Poster  Video  Supplementary 
 53 | Unsupervised Hashing with Similarity Distribution Calibration    
  Kam Woh Ng (University of Surrey),* Xiatian Zhu (University of Surrey), Jiun Tian Hoe (Nanyang Technological University), Chee Seng Chan (University of Malaya), Tianyu Zhang (Geek Plus), Yi-Zhe Song (University of Surrey), Tao Xiang (University of Surrey)  
  PDF  Poster  Video  Supplementary  Code 
 70 | Diversifying the High-level Features for better Adversarial Transferability    
  Zhiyuan Wang (Huazhong University of Science and Technology), Zeliang Zhang (University of Rochester), Siyuan Liang (Chinese Academy of Sciences), Xiaosen Wang (Huazhong University of Science and Technology)*  
  PDF  Video  Supplementary 
 77 | One-stage Progressive Dichotomous Segmentation    
  Jing Zhu (Samsung Research America),* Karim Ahmed (Samsung Research America), Wenbo Li (Samsung Research America), Yilin Shen (Samsung Research America), Hongxia Jin (Samsung Research America)  
  PDF  Poster  Video  Supplementary 
 81 | Towards Robust Few-shot Point Cloud Semantic Segmentation    
  Yating Xu (National University of Singapore),* Na Zhao (SUTD), Gim Hee Lee (National University of Singapore)  
  PDF  Poster  Video  Supplementary  Code 
 82 | Object-Centric Multi-Task Learning for Human Instances    
  Hyeongseok Son (Samsung Advanced Institute of Technology),* Sangil Jung (Samsung), Solae Lee (Samsung Advanced Institute of Technology), Seongeun Kim (Samsung), Seung-In Park (SAIT), ByungIn Yoo (Samsung Advanced Institute of Technology)  
  PDF  Video  Supplementary  Code 
 84 | Spatial and Planar Consistency for Semi-Supervised Volumetric Medical Image Segmentation    
  Yanfeng Zhou (Institute of Automation, Chinese Academy of Sciences), yiming huang (nstitute of Automation，Chinese Academy of Sciences), Ge Yang (National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences)*  
  PDF  Poster  Video  Code 
 89 | Strong Stereo Features for Self-Supervised Practical Stereo Matching    
  Pierre-André Brousseau (Université de Montréal),* Sebastien Roy (Universite de Montreal)  
  PDF  Poster  Video  Code 
 90 | Floorplan Restoration by Structure Hallucinating Transformer Cascades    
  Sepidehsadat Hosseini (Simon Fraser University),* Yasutaka Furukawa (Simon Fraser University)  
  PDF  Poster  Supplementary  Code 
 93 | Open-Vocabulary Object Detection with Meta Prompt Representation and Instance Contrastive Optimization    
  Zhao Wang (The Chinese University of Hong Kong),* Aoxue Li (Noah's Ark Lab), Fengwei Zhou (Huawei Noah's Ark Lab), Zhenguo Li (Huawei Noah's Ark Lab), DOU QI (The Chinese University of Hong Kong)  
  PDF  Poster  Video  Supplementary 
 94 | Likelihood-based Out-of-Distribution Detection with Denoising Diffusion Probabilistic Models    
  Joseph S Goodier (University of Bath),* Neill Campbell (University of Bath)  
  PDF  Poster  Video  Supplementary 
 95 | SketchDreamer: Interactive Text-Augmented Creative Sketch Ideation    
  Zhiyu Qu (University of Surrey),* Tao Xiang (University of Surrey), Yi-Zhe Song (University of Surrey)  
  PDF  Video  Code 
 98 | Prompting Visual-Language Models for Dynamic Facial Expression Recognition    
  Zengqun Zhao (Queen Mary University of London),* Ioannis Patras (Queen Mary University of London)  
  PDF  Poster  Video  Supplementary  Code 
 99 | ReSynthDetect: A Fundus Anomaly Detection Network with Reconstruction and Synthetic Features    
  Jingqi Niu (Shanghai Jiaotong University),* Qinji Yu (Shanghai Jiao Tong University), Shiwen Dong (Shanghai Jiao Tong University), Zilong Wang (Voxelcloud), Kang Dang (Voxelcloud Inc), xiaowei ding (Shanghai Jiao Tong University)  
  PDF  Poster  Video  Supplementary 
 102 | ReCoT: Regularized Co-Training for Facial Action Unit Recognition with Noisy Labels    
  Yifan Li (Michigan State University), Hu Han (Institute of Computing Technology, Chinese Academy of Sciences),* Shiguang Shan (Institute of Computing Technology, Chinese Academy of Sciences), zhilong ji (Tomorrow Advancing Life), Jinfeng Bai (Tomorrow Advance Life), Xilin Chen (Institute of Computing Technology, Chinese Academy of Sciences)  
  PDF  Code 
 103 | Video Infilling with Rich Motion Prior    
  Xinyu Hou (Nanyang Technological University),* Liming Jiang (Nanyang Technological University), Rui Shao (Harbin Institute of Technology (Shenzhen)), Chen Change Loy (Nanyang Technological University)  
  PDF  Poster  Video  Supplementary 
 105 | High-Fidelity Eye Animatable Neural Radiance Fields for Human Face    
  Hengfei Wang (University of Birmingham), Zhongqun Zhang (University of Birmingham), Yihua Cheng (University of Birmingham),* Hyung Jin Chang (University of Birmingham)  
  PDF  Video  Supplementary 
 111 | SeqCo-DETR: Sequence Consistency Training for Self-Supervised Object Detection with Transformers    
  Guoqiang Jin (SenseTime Research),* Fan Yang (中国科学院自动化研究所), Mingshan Sun (SenseTime Research ), Ruyi Zhao (Tongji University), Yakun Liu (SenseTime Research), Wei Li (SenseTime Research), Tianpeng Bao (SenseTime Research), Liwei Wu (SenseTime Research), Xingyu ZENG (SenseTime Group Limited), Rui Zhao (SenseTime Group Limited)  
  PDF  Poster  Video  Supplementary 
 114 | Attributes-Aware Network for Temporal Action Detection    
  Rui Dai (INRIA),* Srijan Das (University of North Carolina at Charlotte), Michael S Ryoo (Stony Brook/Google), Francois Bremond (Inria Sophia Antipolis, France)  
  PDF  Video 
 117 | Detect, Augment, Compose, and Adapt: Four Steps for Unsupervised Domain Adaptation in Object Detection    
  Mohamed Lamine Mekhalfi (Fondazione Bruno Kessler),* Davide Boscaini (Fondazione Bruno Kessler), Fabio Poiesi (Fondazione Bruno Kessler)  
  PDF  Poster  Video  Supplementary  Code 
 119 | Integrating Transient and Long-term Physical States for Depression Intelligent Diagnosis    
  Ke Wu (Beihang University), Han Jiang (State Key Laboratory of Virtual Reality Technology and Systems，Beihang University),* Li Kuang (Beihang University), Yixuan Wang (Beihang University), Huaiqian Ye (Beihang University), Yuanbo He (State Key Laboratory of Virtual Reality Technology and Systems, Beihang University)  
  PDF  Poster  Video  Code 
 123 | Knowledge Distillation Layer that Lets the Student Decide    
  Ada Gorgun (Middle East Technical University),* Yeti Z. Gurbuz (Tecnische Universitat Berlin), Aydin Alatan (Middle East Technical University, Turkey)  
  PDF  Poster  Video  Supplementary  Code 
 127 | SynBlink and BlinkFormer: A Synthetic Dataset and Transformer-Based Method for Video Blink Detection    
  Bo Liu (Beihang University), Yang Xu (Beihang University), Feng Lu (Beihang University)*  
  PDF  Poster  Video  Code 
 135 | Infinite Class Mixup    
  Thomas Mensink (Google Research), Pascal Mettes (University of Amsterdam)*  
  PDF  Poster  Video  Code 
 139 | Continuous Levels of Detail for Light Field Networks    
  David Li (University of Maryland College Park),* Brandon Yushan Feng (University of Maryland, College Park), Amitabh Varshney (University of Maryland)  
  PDF  Poster  Video  Supplementary  Code 
 143 | Sparse and Privacy-enhanced Representation for Human Pose Estimation    
  Ting-Ying Lin (National Tsing Hua University),* Lin-Yung Hsieh (National Tsing Hua University), Fu-En Wang (National Tsing Hua University), Wen-Shen Wuen (Novatek Microelectronics Corp.), Min Sun (NTHU)  
  PDF  Poster  Video  Supplementary  Code 
 144 | Dual Attention for Audio-Visual Speech Enhancement with Facial Cues    
  Fexiang Wang (ICT, UCAS),* Shuang Yang (ICT, CAS), Shiguang Shan (Institute of Computing Technology, Chinese Academy of Sciences), Xilin Chen (Institute of Computing Technology, Chinese Academy of Sciences)  
  PDF  Poster  Video  Supplementary 
 146 | Learning Separable Hidden Unit Contributions for Speaker-Adaptive Visual Speech Recognition    
  Songtao Luo (Institute of Computing Technology, Chinese Academy of Sciences),* Shuang Yang (ICT, CAS), Shiguang Shan (Institute of Computing Technology, Chinese Academy of Sciences), Xilin Chen (Institute of Computing Technology, Chinese Academy of Sciences)  
  PDF  Poster  Video  Supplementary  Code 
 149 | Five A+ Network: You Only Need 9K Parameters for Underwater Image Enhancement    
  JingXia Jiang (jimei university), Tian Ye (The Hong Kong University of Science and Technology (Guangzhou)),* Sixiang Chen (The Hong Kong University of Science and Technology (Guangzhou)), Erkang Chen (Jimei University), Yun Liu (Southwest University), Shi Jun (XinJiang University), Jinbin Bai (Nanjing University), Wenhao Chai (University of Washington)  
  PDF  Poster  Video  Supplementary  Code 
 152 | Primitive Geometry Segment Pre-training for 3D Medical Image Segmentation    
  Ryu Tadokoro (Tohoku University),* Ryosuke Yamada (University of Tsukuba, National Institute of Advanced Industrial Science and Technology (AIST)), Kodai Nakashima (CyberAgent, Univ. of Tsukuba, AIST), Ryo Nakamura (Fukuoka University, National Institute of Advanced Industrial Science and Technology (AIST)), Hirokatsu Kataoka (National Institute of Advanced Industrial Science and Technology (AIST))  
  PDF  Video  Supplementary  Code 
 161 | Long Story Short: a Summarize-then-Search Method for Prompt-Based Long Video Question Answering    
  Jiwan Chung (Yonsei University),* Youngjae Yu (Yonsei University)  
  PDF  Poster  Video  Supplementary  Code 
 167 | Efficient Vision Transformer for Human Pose Estimation via Patch Selection    
  Kaleab A Kinfu (Johns Hopkins University),* Rene Vidal (University of Pennsylvania)  
  PDF  Video 
 172 | Backdoor Attack on Hash-based Image Retrieval via Clean-label Data Poisoning    
  Kuofeng Gao (Tsinghua University),* Jiawang Bai (Tsinghua University), Bin Chen (Harbin Institute of Technology, Shenzhen), Dongxian Wu (the University of Tokyo), Shu-Tao Xia (Tsinghua University)  
  PDF  Poster  Video  Supplementary  Code 
 174 | Sparse Multi-Object Render-and-Compare    
  Florian Maximilian Langer (Department of Engineering, University of Cambridge),* Ignas Budvytis (Department of Engineering, University of Cambridge), Roberto Cipolla (University of Cambridge)  
  PDF  Poster  Video 
 179 | Boost Video Frame Interpolation via Motion Adaptation    
  Haoning Wu (Shanghai Jiao Tong University), Xiaoyun Zhang (Shanghai Jiao Tong University),* Weidi Xie (Shanghai Jiao Tong University), Ya Zhang (Cooperative Medianet Innovation Center, Shang hai Jiao Tong University), Yan-Feng Wang (Cooperative medianet innovation center of Shanghai Jiao Tong University)  
  PDF  Poster  Video  Supplementary  Code 
 182 | BDC-Adapter: Brownian Distance Covariance for Better Vision-Language Reasoning    
  Yi Zhang (Southern University of Science and Technology), Ce Zhang (Carnegie Mellon University), Zihan Liao (Southern University of Science and Technology), Yushun Tang (Southern University of Science and Technology), Zhihai He (Southern University of Science and Technology)*  
  PDF  Poster  Video  Supplementary 
 187 | Can Deep Networks be Highly Performant, Efficient and Robust simultaneously?    
  Madan Ravi Ganesh (BCAI),* Salimeh Yasaei Sekeh (University of Maine), Jason J Corso (University of Michigan)  
  PDF  Video  Supplementary 
 188 | Diverse Explanations for Object Detectors with Nesterov-Accelerated iGOS++    
  Mingqi Jiang (Oregon State University),* Saeed Khorram (Oregon State University), Li Fuxin (Oregon State University)  
  PDF  Poster  Video  Supplementary 
 190 | UniLip: Learning Visual-Textual Mapping with Uni-Modal Data for Lip Reading    
  Bingquan Xia (Institute of Computing Technology, Chinese Academy of Sciences),* Shuang Yang (ICT, CAS), Shiguang Shan (Institute of Computing Technology, Chinese Academy of Sciences), Xilin Chen (Institute of Computing Technology, Chinese Academy of Sciences)  
  PDF  Poster  Supplementary 
 192 | MILA: Memory-Based Instance-Level Adaptation for Cross-Domain Object Detection    
  Onkar Krishna (Hitachi Ltd.),* Hiroki Ohashi (Hitachi Ltd), Saptarshi Sinha (University of Bristol)  
  PDF  Video  Code 
 193 | Functional Hand Type Prior for 3D Hand Pose Estimation and Action Recognition from Egocentric View Monocular Videos    
  WONSEOK ROH (Korea University), Seung Hyun Lee (Korea University), Won Jeong Ryoo (Korea University), Jakyung Lee (Korea University), Gyeongrok Oh (Korea University), Sooyeon Hwang (Korea University Sejong), Hyung-gun Chi (Purdue University), Sangpil Kim (Korea University)*  
  PDF  Video  Supplementary 
 194 | mmPoint: Dense Human Point Cloud Generation from mmWave    
  Qian Xie (University of Oxford),* Qianyi Deng (University of Oxford), Ta-Ying Cheng (University of Oxford), Peijun Zhao (Massachusetts Institute of Technology), Amir Patel (University of Cape Town), Niki Trigoni (University of Oxford), Andrew Markham (University of Oxford)  
  PDF  Poster  Video  Code 
 197 | Domain-Sum Feature Transformation For Multi-Target Domain Adaptation    
  Takumi Kobayashi (National Institute of Advanced Industrial Science and Technology),* Lincon Souza (National Institute of Advanced Industrial Science and Technology (AIST)), Kazuhiro Fukui (University of Tsukuba)  
  PDF  Video  Supplementary 
 202 | Few-Shot Anomaly Detection with Adversarial Loss for Robust Feature Representations    
  Jae Young Lee (KAIST),* Wonjun Lee (University of Science and Technology ), Jaehyun Choi (KAIST), Yongkwi LEE (ETRI), Young Seog Yoon (Electronics and Telecommunications Research Institute)  
  PDF  Poster  Video  Supplementary 
 204 | Cardiac Landmark Detection using Generative Adversarial Networks from Cardiac MR Images    
  Aparna Kanakatte (TCS),* DIVYA M BHATIA (TCS), Pavan Kumar Reddy K (TCS Research), Jayavardhana Gubbi (TCS Research), Avik Ghose (TCS)  
  PDF  Poster  Video 
 207 | Embedding Human Knowledge into Spatio-Temproal Attention Branch Network in Video Recognition via Temporal attention    
  Saki Noguchi (Chubu University),* Yuzhi Shi ( Chubu University), Tsubasa Hirakawa (Chubu University), Takayoshi Yamashita (Chubu University), Hironobu Fujiyoshi (Chubu University)  
  PDF  Poster  Video  Supplementary 
 214 | Understanding Gaussian Attention Bias of Vision Transformers Using Effective Receptive Fields    
  Bum Jun Kim (POSTECH), Hyeyeon Choi (POSTECH), Hyeonah Jang (POSTECH), Sang Woo Kim (POSTECH)*  
  PDF  Poster  Video  Supplementary  Code 
 215 | Hierarchical Quantization Consistency for Fully Unsupervised Image Retrieval    
  Guile Wu (Researcher), Chao Zhang (Toshiba Europe Limited),* Stephan Liwicki (Toshiba Europe Limited)  
  PDF  Poster  Video  Supplementary  Code 
 216 | READ Avatars: Realistic Emotion-controllable Audio Driven Avatars    
  Jack Saunders (University of Bath),* Vinay Namboodiri (University of Bath)  
  PDF  Video  Supplementary 
 226 | PanoMixSwap – Panorama Mixing via Structural Swapping for Indoor Scene Understanding    
  Yu-Cheng Hsieh (National Tsing Hua University),* Cheng Sun (National Tsing Hua University), Suraj Dengale (National Tsing Hua University), Min Sun (NTHU)  
  PDF  Poster  Video 
 229 | Weakly-Supervised Visual-Textual Grounding with Semantic Prior Refinement    
  Davide Rigoni (University of Padova), Luca Parolari (University of Padova), Luciano Serafini (Fondazione Bruno Kessler), Alessandro Sperduti (Università di Padova (IT)), Lamberto Ballan (University of Padova)*  
  PDF  Poster  Video  Code 
 230 | De-identification of facial videos while preserving remote physiological utility    
  Marko Radisa Savic (University of Oulu),* Guoying Zhao (University of Oulu)  
  PDF  Poster  Video  Code 
 231 | Propose-and-Complete: Auto-regressive Semantic Group Generation for Personalized Scene Synthesis    
  Shoulong Zhang (Beihang University), Shuai Li (BeihangUniversity), Xinwei Huang (Beihang University), Wenchong Xu (Beihang University), Aimin Hao (BeihangUniversity), HONG QIN (Stony Brook University)*  
  PDF  Poster  Video  Supplementary 
 235 | What Should Be Balanced in a "Balanced" Face Recognition Dataset?    
  Haiyu Wu (University of Notre Dame),* Kevin Bowyer (University of Notre Dame)  
  PDF  Poster  Video  Code 
 236 | Temporal-controlled Frame Swap for Generating High-Fidelity Stereo Driving Data for Autonomy Analysis    
  Yedi Luo (Northeastern University), Xiangyu Bai (Northeastern University), Jiang Le (Northeastern University ), Aniket Gupta (Northeastern University), Eric C Mortin (US Army DEVCOM Analysis Center), Hanumant Singh (Northeastern University), Sarah Ostadabbas (Northeastern University)*  
  PDF  Poster  Video  Code 
 237 | Spatio-Temporal MLP-Graph Network for 3D Human Pose Estimation    
  Md. Tanvir Hassan (Concordia University), Abdessamad Ben Hamza (Concordia University)*  
  PDF  Supplementary  Code 
 240 | StereoFlowGAN: Co-training for Stereo and Flow with Unsupervised Domain Adaptation    
  Zhexiao Xiong (Washington University in St. Louis),* Feng Qiao (RWTH Aachen University), Yu Zhang (Bastian Solutions), Nathan Jacobs (Washington University in St. Louis)  
  PDF  Poster  Video  Supplementary 
 243 | Class-Continuous Conditional Generative Neural Radiance Field    
  Jiwook Kim (Chung-Ang University),* Minhyeok Lee (Chung-Ang University)  
  PDF  Poster  Video  Supplementary  Code 
 258 | A Structure-Guided Diffusion Model for Large-Hole Image Completion    
  Daichi Horita (The University of Tokyo),* Jiaolong Yang (Microsoft Research), Dong Chen (Microsoft Research Asia), Yuki Koyama (National Institute of Advanced Industrial Science and Technology (AIST)), Kiyoharu Aizawa (The University of Tokyo), Nicu Sebe (University of Trento)  
  PDF  Poster  Video  Code 
 259 | Prototype-Aware Contrastive Knowledge Distillation for Few-Shot Anomaly Detection    
  Zhihao Gu (Shanghai Jiao Tong University),* Taihai Yang (East China Normal University), Lizhuang Ma (Shanghai Jiao Tong University)  
  PDF  Supplementary 
 264 | Predictive Consistency Learning for Long-Tailed Recognition    
  Nan Kang (Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences (CAS)),* Hong Chang (Chinese Academy of Sciences), Bingpeng MA (University of Chinese Academy of Sciences), Shutao Bai (Institute of Computing Technology, Chinese Academy of Sciences), Shiguang Shan (Institute of Computing Technology, Chinese Academy of Sciences), Xilin Chen (Institute of Computing Technology, Chinese Academy of Sciences)  
  PDF  Poster  Video  Supplementary 
 265 | A Multi-step Fusion Network Based on Environmental Knowledge Graph for Camouflaged Object Detection    
  Zheng Wang (Tianjin University),* Wenjun Huang (Tianjin University), Ruoxun Su (Tianjin University), Xinyu Yan (Tianjin University), Meijun Sun (Tianjin University)  
  PDF  Poster  Video 
 268 | Lips-SpecFormer: Non-Linear Interpolable Transformer for Spectral Reconstruction using Adjacent Channel Coupling    
  Abhishek Kumar Sinha (Indian Space Research Organization),* Manthira Moorthi S (ISRO)  
  PDF  Poster  Video 
 271 | Semantic Adversarial Attacks via Diffusion Models    
  Chenan Wang (Drexel University),* Jinhao Duan (Drexel University), Chaowei Xiao (ASU), Edward Kim (Drexel University), Matthew c Stamm (Drexel University), Kaidi Xu (Drexel University)  
  PDF  Poster  Video  Supplementary  Code 
 272 | SMPLitex: A Generative Model and Dataset for 3D Human Texture Estimation from Single Image    
  Dan Casas (Universidad Rey Juan Carlos),* Marc Comino-Trinidad (Universidad Rey Juan Carlos)  
  PDF  Poster  Video  Code 
 274 | Frequency-consistent Optimization for Image Enhancement Networks    
  Bing Li (University of Science and Technology of China),* Naishan Zheng (University of Science and Technology of China), Qi Zhu (University of Science and Technology of China), Jie Huang (University of Science and Technology of China), Feng Zhao (University of Science and Technology of China)  
  PDF  Poster  Video  Supplementary 
 276 | Attentive Contractive Flow with Lipschitz Constrained Self-Attention    
  Avideep Mukherjee (Indian Institute of Technology Kanpur),* Badri N Patro (KU Leuven), Vinay Namboodiri (University of Bath)  
  PDF  Video  Supplementary  Code 
 282 | SlackedFace: Learning a Slacked Margin for Low-Resolution Face Recognition    
  Cheng Yaw Low (Institute for Basic Science),* Jacky Chen Long Chai (Yonsei University), Jaewoo Park (Yonsei University), KYEONGJIN ANN (KAIST), Meeyoung Cha (KAIST & IBS)  
  PDF  Video  Supplementary  Code 
 283 | MG-MLP: Multi-gated MLP for Restoring Images from Spatially Variant Degradations    
  Jaihyun Koh (Samsung Display),* Jaihyun Lew (Seoul National University), Jangho Lee (Incheon National University), Sungroh Yoon (Seoul National University)  
  PDF  Poster  Video  Supplementary 
 286 | Lightweight Image Super-Resolution with Scale-wise Network    
  Xiaole Zhao (School of Computing and Artificial Intelligence, Southwest Jiaotong University), Xinkun Wu (School of Computing and Artificial Intelligence, Southwest Jiaotong University)*  
  PDF  Poster  Video  Supplementary 
 287 | EventFormer: AU Event Transformer for Facial Action Unit Event Detection    
  Yingjie Chen (Peking University),* Jiarui Zhang (Peking University), Tao Wang (Peking University), Yun Liang (Peking University)  
  PDF  Supplementary 
 290 | Highly Efficient SNNs for High-speed Object Detection    
  Nemin Qiu (Beijing University of Posts and Telecommunications),* zhiguo li (Peking University), Yuan Li (Peking University), Chuang Zhu (Beijing University of Posts and Telecommunications )  
  PDF  Video  Code 
 292 | Generating Pseudo-labels Adaptively for Few-shot Model-Agnostic Meta-Learning    
  Guodong Liu (Huazhong University of Science and Technology), Tongling Wang (Huazhong University of Science and Technology), Shuoxi Zhang (Huazhong University of Science and Technology), Kun He (Huazhong University of Science and Technology)*  
  PDF  Poster 
 295 | LOCATE: Self-supervised Object Discovery via Flow-guided Graph-cut and Bootstrapped Self-training    
  Silky Singh (Adobe Systems),* Shripad V Deshmukh (Adobe), Mausoom Sarkar (Adobe), Balaji Krishnamurthy ()  
  PDF  Poster  Video  Supplementary  Code 
 296 | RBFormer: Improve Adversarial Robustness of Transformers by Robust Bias    
  Hao Cheng (The Hong Kong University of Science and Technology(Guangzhou)),* Jinhao Duan (Drexel University), Hui Li (Samsung Research and Development Institute China Xi'an), Jiahang Cao (The Hong Kong University of Science and Technology (Guangzhou)), Ping Wang (Xi'an Jiaotong University), Lyutianyang Zhang (University of Washington), Jize Zhang (HKUST), Kaidi Xu (Drexel University), Renjing Xu (The Hong Kong University of Science and Technology (Guangzhou))  
  PDF  Poster  Video  Supplementary 
 297 | Exploring the Limits of Deep Image Clustering using Pretrained Models    
  Nikolas Adaloglou (HHU),* Felix Michels (HHU), Hamza Kalisch (HHU), Markus Kollmann (HHU)  
  PDF  Poster  Video  Supplementary  Code 
 300 | Contrastive Consistent Representation Distillation    
  Shipeng Fu (Sichuan University ),* Haoran Yang (Sichuan University), Xiaomin Yang (Sichuan University)  
  PDF  Poster  Video  Supplementary  Code 
 304 | Learning Part Motion of Articulated Objects Using Spatially Continuous Neural Implicit Representations    
  Yushi Du (Peking University),* Ruihai Wu (Peking University), Yan Shen (Peking University), Hao Dong (Peking University)  
  PDF  Poster  Video  Code 
 305 | Learnable Geometry and Connectivity Modelling of BIM Objects    
  Haritha Jayasinghe (University of Cambridge),* Ioannis Brilakis (University of Cambridge)  
  PDF  Video  Code 
 306 | Point Cloud Sampling Preserving Local Geometry for Surface Reconstruction    
  Kohei Matsuzaki (KDDI Research, Inc.),* Keisuke Nonaka (KDDI Research, Inc.)  
  PDF  Poster  Video 
 307 | RUPQ: Improving low-bit quantization by equalizing relative updates of quantization parameters    
  Valentin Buchnev (Huawei Technologies Co. Ltd.),* Jiao He (huawei company), Fengyu Sun (Huawei), Ivan Koryakovskiy (Huawei Technologies Co., Ltd.)  
  PDF  Poster  Video  Code 
 310 | Widely Applicable Strong Baseline for Sports Ball Detection and Tracking    
  Shuhei Tarashima (NTT Communications / Tokyo Metropolitan University),* Muhammad Abdul Haq (Tokyo Metropolitan University), Yushan Wang (Tokyo Metropolitan University), Norio Tagawa (Tokyo Metropolitan University)  
  PDF  Poster  Video  Supplementary 
 311 | RepQ: Generalizing Quantization-Aware Training for Re-Parametrized Architectures    
  Anastasiia Prutianova (Huawei),* Alexey Zaytsev (Skoltech), Chung-Kuei Lee (Huawei), Fengyu Sun (Huawei), Ivan Koryakovskiy (Huawei Technologies Co., Ltd.)  
  PDF  Video  Supplementary 
 314 | GOPro: Generate and Optimize Prompts in CLIP using Self-Supervised Learning    
  Mainak Singha (Indian Institute of Technology Bombay),* Ankit Jha (Indian Institute of Technology Bombay), Biplab Banerjee (Indian Institute of Technology, Bombay)  
  PDF  Poster  Video  Supplementary  Code 
 315 | Generalized Imaging Augmentation via Linear Optimization of Neurons    
  Daoyu Li (Beijing Institute of Technology), Lu Li (Beijing Institute of Technology), Bin Li (Beijing University of Posts and Telecommunications), Liheng Bian (Beijing Institute of Technology)*  
  PDF  Poster  Video  Supplementary 
 317 | Spherical Vision Transformer for 360° Video Saliency Prediction    
  Mert Cokelek (Koç University),* Nevrez Imamoglu (AIST), Cagri Ozcinar (Samsung), Erkut Erdem (Hacettepe University), Aykut Erdem (Koc University)  
  PDF  Video  Supplementary  Code 
 320 | Learning Unified Representations for Multi-Resolution Face Recognition    
  Hulingxiao He (School of Automation,Beijing Institute of Technology), Wu Yuan (School of Computer Science,Beijing Institute of Technology),* Yidian Huang (Beijing Institute of Technology), Shilong Zhao (Beijing Institute of Technology), Wen Yuan (State Key Laboratory of Resources and Environmental Information System, Institute of Geographic Sciences and Natural Resources Research, CAS), Hanqing Li (University of the Chinese Academy of Sciences)  
  PDF  Poster  Video  Code 
 322 | 3D Structure-guided Network for Tooth Alignment in 2D Photograph    
  Yulong Dou (Shanghaitech),* Lanzhuju Mei (ShanghaiTech University), Dinggang Shen (United Imaging Intelligence), Zhiming Cui (HKU)  
  PDF  Poster  Video  Code 
 323 | Point-to-RBox Network for Oriented Object Detection via Single Point Supervision    
  Yucheng Wang (WuHan University),* Chu He (Wuhan University), Xi Chen (Wuhan university)  
  PDF  Poster  Video 
 326 | X-PDNet: Accurate Joint Plane Instance Segmentation and Monocular Depth Estimation with Cross-Task Distillation and Boundary Correction    
  Duc Cao Dinh (Computer Vision Lab, Hanyang University),* Jongwoo Lim (Seoul National University)  
  PDF  Poster  Video  Code 
 329 | Maskomaly: Zero-Shot Mask Anomaly Segmentation    
  Jan Ackermann (ETH Zurich),* Christos Sakaridis (ETH Zurich), Fisher Yu (ETH Zurich)  
  PDF  Poster  Video  Code 
 330 | Fine-grained Few-shot Recognition by Deep Object Parsing    
  Ruizhao Zhu (Boston University),* Pengkai Zhu (Amazon Web Services), Samarth Mishra (Boston University), Venkatesh Saligrama (Boston University)  
  PDF  Poster  Video  Supplementary 
 332 | Learning Temporal Sentence Grounding From Narrated EgoVideos    
  Kevin Flanagan (University of Bristol),* Dima Damen (University of Bristol), Michael Wray (University of Bristol)  
  PDF  Poster  Video  Supplementary  Code 
 335 | Supervised Contrastive Learning with Identity-Label Embeddings for Facial Action Unit Recognition    
  Tangzheng Lian (Nottingham Trent Univeristy), David A Adama (Nottingham Trent University), Pedro Machado (Nottingham Trent University), Doratha E Vinkemeier (NTU)*  
  PDF  Poster  Video  Supplementary  Code 
 337 | Active Learning for Fine-Grained Sketch-Based Image Retrieval    
  Himanshu Thakur (Carnegie Mellon University), Soumitri Chattopadhyay (Jadavpur University)*  
  PDF  Poster  Video 
 339 | Structured Knowledge Distillation Towards Efficient Multi-View 3D Object Detection    
  Linfeng Zhang (Tsinghua University ),* Yukang Shi (Xi’an Jiaotong University), Ke Wang (UNC Chapel Hill), Zhipeng Zhang (DiDi), Hung-Shuo Tai (Didi Autonomous Drive), Yuan He (KargoBot), Kaisheng Ma (Tsinghua University )  
  PDF  Video 
 345 | Region-aware Knowledge Distillation for Efficient Image-to-Image Translation    
  Linfeng Zhang (Tsinghua University ),* Xin Chen (Intel Corp.), Runpei Dong (Xi'an Jiaotong University), Kaisheng Ma (Tsinghua University )  
  PDF  Video 
 347 | SRNet: Striped Pyramid Pooling and Relational Transformer for Retinal Vessel Segmentation    
  Wei Yan (College of Computer Science and Engineering, Northwest Normal University),* Yun Jiang (College of Computer Science and Engineering, Northwest Normal University), Zequn Zhang (Northwest Normal University ), Yao Yan (College of Computer Science and Engineering, Northwest Normal University), Bingxi Liu (Northwest Normal University)  
  PDF  Poster  Video 
 348 | RGB and LUT based Cross Attention Network for Image Enhancement    
  Tengfei Shi (Beihang University), Chenglizhao Chen (China University of Petroleum (East China)),* Yuanbo He (State Key Laboratory of Virtual Reality Technology and Systems, Beihang University), wenfeng song (Beijing Information Science and Technology University), Aimin Hao (BeihangUniversity)  
  PDF  Poster  Video 
 351 | Cross-domain Semantic Decoupling for Weakly-Supervised Semantic Segmentation    
  Zaiquan Yang (Beihang University),* Zhanghan Ke (City University of Hong Kong), Gerhard P. Hancke (City University of Hong Kong), Rynson W.H. Lau (City University of Hong Kong)  
  PDF  Poster  Video  Supplementary 
 353 | Adapting Self-Supervised Representations to Multi-Domain Setups    
  Neha Kalibhat (University of Maryland - College Park),* Sam Sharpe (Capital One), Jeremy Goodsitt (Capital One), C. Bayan Bruss (Capital One), Soheil Feizi (University of Maryland)  
  PDF  Poster  Video 
 356 | Lightweight Self-Supervised Depth Estimation with few-beams LiDAR Data    
  Rizhao Fan (University of Bologna),* Fabio Tosi (University of Bologna), Matteo Poggi (University of Bologna), Stefano Mattoccia (University of Bologna)  
  PDF  Code 
 358 | RawSeg: Grid Spatial and Spectral Attended Semantic Segmentation Based on Raw Bayer Images    
  Guoyu Lu (University of Georgia)*  
  PDF 
 360 | FLRKD: Relational Knowledge Distillation Based on Channel-wise Feature Quality Assessment    
  Zeyu An (University of Electronic Science and Technology of China),* Changjian Deng (University of Electronic Science and Technology of China), Wanli Dang (University of Electronic Science and Technology of China;The Second Research Institute of the Civil Aviation Administration of China), Zhicheng Dong (Tibet university), 谦 罗 (中国民用航空总局第二研究所), Jian Cheng (University of Electronic Science and Technology of China)  
  PDF  Poster  Video 
 366 | Divide & Bind Your Attention for Improved Generative Semantic Nursing    
  Yumeng Li (Bosch Center for Artificial Intelligence),* Margret Keuper (University of Siegen, Max Planck Institute for Informatics), Dan Zhang (Bosch Center for Artificial Intelligence), Anna Khoreva (Bosch Center for Artificial Intelligence)  
  PDF  Video  Supplementary  Code 
 367 | How Can Contrastive Pre-training Benefit Audio-Visual Segmentation? A Study from Supervised and Zero-shot Perspectives    
  Jiarui Yu (USTC),* Haoran Li (University of Science and Technology of China), Yanbin Hao (University of Science and Technology of China), Wu Jinmeng (Wuhan Institute of Technology), Tong Xu (University of Science and Technology of China), Shuo Wang (University of Science and Technology of China), Xiangnan He (University of Science and Technology of China)  
  PDF  Poster  Supplementary  Code 
 375 | Building A Mobile Text Recognizer via Truncated SVD-based Knowledge Distillation-Guided NAS    
  Weifeng Lin (South China University of Technology), Canyu Xie (South China University of Technology), Dezhi Peng (South China University of Technology), Jiapeng Wang (South China University of Technology), Lianwen Jin (South China University of Technology),* Wei Ding (Alibaba Group), Cong Yao (Alibaba DAMO Academy), Mengchao He (DAMO Academy, Alibaba Group)  
  PDF  Poster  Video 
 376 | Adapting Generic Features to A Specific Task: A Large Discrepancy Knowledge Distillation for Image Anomaly Detection    
  Chenkai Zhang (Zhejiang University),* Tianqi Du (Zhejiang University), Yueming Wang (Zhejiang University)  
  PDF  Poster  Video  Supplementary 
 377 | Describe Your Facial Expressions by Linking Image Encoders and Large Language Models    
  Yujian Yuan (Institute of Computing Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences), Jiabei Zeng (Institute of Computing Technology, Chinese Academy of Sciences),* Shiguang Shan (Institute of Computing Technology, Chinese Academy of Sciences)  
  PDF  Video  Supplementary  Code 
 378 | Neural Feature Filtering for Faster Structure-from-Motion Localisation    
  Alexandros Rotsidis (University of Bath),* Yuxin Wang (École polytechnique fédérale de Lausanne), Yiorgos Chrysanthou (CYENS Centre of Excellence), Christian Richardt (Meta)  
  PDF  Poster  Video  Code 
 379 | Test-Time Adaptation for Robust Face Anti-Spoofing    
  Pei-Kai Huang (National Tsing Hua University),* Chen-Yu Lu (National Tsing Hua University), Shu-Jung Chang (National Tsing Hua University), Jun-Xiong Chong (National Tsing Hua University), Chiou-Ting Hsu (National Tsing Hua University)  
  PDF  Poster  Video  Code 
 381 | Zero-shot Composed Text-Image Retrieval    
  Yikun Liu (Beijing University of Posts and Telecommunications),* Jiangchao Yao (Cooperative Medianet Innovation Center, Shang hai Jiao Tong University), Ya Zhang (Cooperative Medianet Innovation Center, Shang hai Jiao Tong University), Yan-Feng Wang (Cooperative medianet innovation center of Shanghai Jiao Tong University), Weidi Xie (Shanghai Jiao Tong University)  
  PDF  Poster  Video  Supplementary  Code 
 382 | Fully Quantum Auto-Encoding of 3D Shapes    
  Lakshika Rathi (Indian Institute of Technology Delhi), Edith Tretschk (Max-Planck-Institut für Informatik),* Christian Theobalt (MPI Informatik), Rishabh Dabral (IIT Bombay), Vladislav Golyanik (MPI for Informatics)  
  PDF  Supplementary  Code 
 385 | Personalized Fashion Recommendation via Deep Personality Learning    
  Dongmei Mo (The Hong Kong Polytechnic University),* Xingxing Zou (Laboratory for Artificial Intelligence in Design, The Hong Kong Polytechnic University), Waikeung Wong (Institute of Textiles and Clothing, The Hong Kong Polytechnic University)  
  PDF  Poster  Video  Supplementary 
 394 | Unifying Synergies between Self-supervised Learning and Dynamic Computation    
  Tarun Krishna (DCU),* Ayush K. Rai (Dublin City University), Alexandru F Drimbarean (Xperi), Eric Arazo (Insight Centre for Data Analytics (DCU)), Paul Albert (Insight Centre for Data Analytics (DCU)), Alan Smeaton (Insight Centre for Data Analytics, Dublin City University), Kevin McGuinness (DCU), Noel O Connor (Home)  
  PDF  Poster  Video  Supplementary  Code 
 402 | Revisiting the Encoding of Satellite Image Time Series    
  Xin Cai (Ulster University),* Yaxin Bi (Ulster University), Peter Nicholl (Ulster University), Roy Sterritt (Ulster University)  
  PDF  Video  Supplementary  Code 
 405 | Breathing New Life into 3D Assets with Generative Repainting    
  Tianfu Wang (ETH Zurich), Menelaos Kanakis (ETH Zurich), Konrad Schindler (ETH Zurich), Luc Van Gool (ETH Zurich), Anton Obukhov (ETH Zurich)*  
  PDF  Video  Supplementary  Code 
 406 | Exploring Non-additive Randomness on ViT against Query-Based Black-Box Attacks    
  Jindong Gu (University of Oxford),* Fangyun Wei (Microsoft Research Asia), Philip Torr (University of Oxford), Han Hu (Microsoft Research Asia)  
  PDF  Poster  Video  Supplementary 
 409 | AGMDT: Virtual Staining of Renal Histology Images with Adjacency-Guided Multi-Domain Transfer    
  Tao Ma (Peking University),* Chao Zhang (Peking University), MIN LU (Peking University Health Science Center), Lin Luo (Peking University)  
  PDF  Poster  Video  Supplementary 
 411 | LACFormer: Toward accurate and efficient polyp segmentation    
  Quan Van Nguyen (R&D Lab, Sun Asterisk Inc Vietnam),* Mai Nguyen ( R&D Lab, Sun Asterisk Inc Vietnam), Thanh Tung Nguyen (Sun Asterisk Vietnam), Huy Trịnh Quang (Sun-asterisk), Toan Pham Van (R&D Lab, Sun Asterisk Inc Vietnam), Linh Bao Doan (Sun* Inc.)  
  PDF  Poster  Video  Code 
 417 | Deformation-Guided Unsupervised Non-Rigid Shape Matching    
  Aymen Merrouche (INRIA),* Joao Pedro Cova Regateiro (Interdigital), Stefanie Wuhrer (Inria), Edmond Boyer (Inria)  
  PDF  Poster  Video  Supplementary  Code 
 429 | Zero-Shot Video Captioning by Evolving Pseudo-tokens    
  Yoad Tewel (Tel-Aviv University),* Yoav Shalev (Tel Aviv University), Roy Nadler (Tel Aviv University), Idan Schwartz (Technion), Lior Wolf (Tel Aviv University, Israel)  
  PDF  Video  Supplementary  Code 
 433 | Variational Autoencoders with Decremental Information Bottleneck for Disentanglement    
  Jiantao Wu (University of Surrey),* Shentong Mo (Carnegie Mellon University), Xingshen Zhang (University of Jinan), Muhammad Awais (University of Surrey), Sara Ahmed (University of surrey), Zhenhua Feng (University of Surrey), Lin Wang (University of Jinan), Xiang Yang (Zhejiang Mingyi Technology Co., Ltd.)  
  PDF  Poster  Video  Supplementary  Code 
 437 | Maturity-Aware Active Learning for Semantic Segmentation with Hierarchically-Adaptive Sample Assessment    
  Amirsaeed Yazdani (Pennsylvania State University),* Xuelu Li (Amazon), Vishal Monga (The Pennsylvania State University)  
  PDF  Video  Supplementary  Code 
 438 | Score-PA: Score-based 3D Part Assembly    
  Junfeng Cheng (Imperial College London), Mingdong Wu (Peking University), Ruiyuan Zhang (zhejiang university), Guanqi Zhan (University of Oxford), Chao Wu (Zhejiang University), Hao Dong (Peking University)*  
  PDF  Video  Supplementary  Code 
 441 | EgoFlowNet: Non-Rigid Scene Flow from Point Clouds with Ego-Motion Support    
  Ramy Battrawy (DFKI),* René Schuster (DFKI), Didier Stricker (DFKI)  
  PDF  Poster  Video  Supplementary 
 444 | Semi-Supervised Domain Generalization for Object Detection via Language-Guided Feature Alignment    
  Sina Malakouti (University of Pittsburgh),* Adriana Kovashka (University of Pittsburgh)  
  PDF  Poster  Video  Supplementary  Code 
 448 | Optimal Camera Configuration for Large-Scale Motion Capture Systems    
  Xiongming Dai (louisiana state university),* Gerald Baumgartner (Louisiana State University)  
  PDF  Poster  Video  Supplementary  Code 
 451 | Complex Scene Image Editing by Scene Graph Comprehension    
  Zhongping Zhang (Boston University),* Huiwen He (Boston University), Bryan Plummer (Boston University), Zhenyu Liao (Kwai Inc), Huayan Wang (Kuaishou Technology)  
  PDF  Poster  Video  Supplementary  Code 
 452 | Domain-Aware Augmentations for Unsupervised Online General Continual Learning    
  Nicolas Michel (LIGM)*  
  PDF  Poster  Video 
 460 | AMA: Adaptive Memory Augmentation for Enhancing Image Captioning    
  Shuang Cheng (Institute of Computing Technology, Chinese Academy of Sciences),* Jian Ye (Institute of Computing Technology, CAS)  
  PDF  Poster  Video 
 462 | Enhance Regional Wall Segmentation by Style Transfer for Regional Wall Motion Assessment    
  Kaikai Liu (Northwest A&F University), Yiyu Shi (University of Notre Dame), Jian Zhuang (Guangdong Provincial People's Hospital), Meiping Huang (Guangdong Provincial People's Hospital), Hongwen Fei (Guangdong Provincial People's Hospital), Boyang Li (Meta), Jin Hong (Guangdong Provincial People's Hospital), Qing Lu (University of Notre Dame), Erlei Zhang (Northwest A&F University), Xiaowei Xu (Guangdong Provincial People's Hospital)*  
  PDF  Code 
 467 | Cross-Modal Attention for Accurate Pedestrian Trajectory Prediction    
  Mayssa ZAIER (IMT NORD EUROPE),* Hazem Wannous (University of Lille), Hassen Drira (University of Strasbourg), Jacques boonaert (imt lille douai)  
  PDF  Poster  Video  Code 
 470 | KFC: Kinship Verification with Fair Contrastive loss and Multi-Task Learning    
  Jia Luo Peng (National Tsing Hua University),* Keng Wei Chang (National Tsing Hua University), Shang-Hong Lai (National Tsing Hua University)  
  PDF  Poster  Video  Code 
 471 | Enhancing Interpretable Object Abstraction via Clustering-based Slot Initialization    
  Ning Gao (Bosch Center for Artificial Intelligence (BCAI)),* Bernard Hohmann (Karlsruhe Institute of Technology), Gerhard Neumann (Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany)  
  PDF  Poster  Video  Supplementary 
 478 | Conditional Generation from Pre-Trained Diffusion Models using Denoiser Representations    
  Alexandros Graikos (Stony Brook University),* Srikar Yellapragada (Stony Brook University), Dimitris Samaras (Stony Brook University)  
  PDF  Poster  Video  Code 
 480 | Comprehensive Quantitative Quality Assessment of Thermal Cut Sheet Edges using Convolutional Neural Networks    
  Janek Stahl (Fraunhofer IPA),* Andreas Frommknecht (Fraunhofer IPA), Marco Huber (University of Stuttgart)  
  PDF  Poster  Video 
 482 | BiUNet: Towards More Effective UNet with Bi-Level Routing Attention    
  Kun Dong (University of Chinese Academy of Sciences), Jian Xue (University of Chinese Academy of Sciences), Xing Lan (University of Chinese Academy of Sciences), Ke Lu (University of Chinese Academy of Sciences)*  
  PDF  Video  Code 
 486 | ADoPT: LiDAR Spoofing Attack Detection Based on Point-Level Temporal Consistency    
  Minkyoung Cho (University of Michigan),* Yulong Cao (Nvidia), Zixiang Zhou (University of Michigan), Zhuoqing Morley Mao (University of Michigan)  
  PDF  Poster  Video  Supplementary 
 497 | EDeNN: Event Decay Neural Networks for low latency vision    
  Celyn Walters (University of Surrey), Simon Hadfield (University of Surrey)*  
  PDF  Poster  Video  Supplementary  Code 
 498 | CERiL: Continuous Event-based Reinforcement Learning    
  Celyn Walters (University of Surrey), Simon Hadfield (University of Surrey)*  
  PDF  Poster  Video  Code 
 499 | Clustered Saliency Prediction    
  Rezvan Sherkati (McGill University),* James J. Clark (McGill University)  
  PDF  Poster  Video 
 501 | Temporal Lidar Depth Completion    
  Pietari Kaskela (NVIDIA),* Philipp Fischer (NVIDIA), Timo Roman (NVIDIA)  
  PDF  Poster  Video 
 506 | GestSync: Determining who is speaking without a talking head    
  Sindhu B Hegde (University of Oxford),* Andrew Zisserman (University of Oxford)  
  PDF  Video  Supplementary  Code 
 510 | Open-world Text-specifed Object Counting    
  Niki Amini-Naieni (University of Oxford),* Kiana Amini-Naieni (University of California, Davis), Tengda Han (University of Oxford), Andrew Zisserman (University of Oxford)  
  PDF  Poster  Video  Supplementary  Code 
 511 | McQueen: Mixed Precision Quantization of Early Exit Networks    
  Utkarsh Saxena (Purdue University),* Kaushik Roy (Purdue Uniiversity)  
  PDF  Poster  Video  Supplementary 
 514 | DFFG: Fast Gradient Iteration for Data-free Quantization    
  huixing leng (Beihang University), shuangkang fang (megvii,buaa), Yufeng Wang (Beihang University),* Zehao ZHANG (beihang university), Qi Dacheng (Beijing Jiaotong University), Wenrui Ding (Beihang University)  
  PDF  Poster  Video 
 521 | Selective Scene Text Removal    
  Hayato Mitani (Kyushu University),* Akisato Kimura (NTT Corporation), Seiichi Uchida (Kyushu University)  
  PDF  Poster  Video  Supplementary  Code 
 522 | Train ViT on Small Dataset With Translation Perceptibility    
  CHEN HUAN (Institute of Computing Technology),* WENTAO WEI (Southeast University), Ping Yao (Institute of Computing Technology, Chinese Academy of Sciences )  
  PDF  Poster  Video  Code 
 523 | SHLS: Superfeatures learned from still images for self-supervised VOS    
  Marcelo M Santos (UFBA),* Jefferson Fontinele da Silva (University Federal of Maranhão), Luciano Oliveira (UFBA)  
  PDF  Poster  Video  Supplementary  Code 
 530 | AutoSAM: Adapting SAM to Medical Images by Overloading the Prompt Encoder    
  Tal Shaharbany (Tel Aviv University),* ‪Aviad Dahan‬‏ (Tel Aviv University), Raja Giryes (Tel Aviv University), Lior Wolf (Tel Aviv University, Israel)  
  PDF  Poster  Video  Code 
 534 | Dual Feature Augmentation Network for Generalized Zero-shot Learning    
  Lei Xiang (Nanjing University of Information Science and Technology ),* Yuan Zhou (Nanjing University of Information Science and Technology), Haoran Duan (Durham University), Yang Long (Durham University)  
  PDF  Poster  Video  Code 
 535 | Security Analysis on Locality-Sensitive Hashing-based Biometric Template Protection Schemes    
  Seunghun Paik (Hanyang University), Sunpill Kim (Hanyang University), Jae Hong Seo (Hanyang university)*  
  PDF  Video  Supplementary  Code 
 538 | Learning Disentangled Representations for Environment Inference in Out-of-distribution Generalization    
  Dongqi Li (Beijing Jiaotong University), Zhu Teng (Beijing Jiaotong University), Li Qirui (AFCtech), Wang Ziyin (AFCtech), Baopeng Zhang (BJTU),* Jianping Fan (Lenovo)  
  PDF  Poster  Video  Supplementary 
 540 | Sketch-based Video Object Segmentation: Benchmark and Analysis    
  Ruolin Yang (Beijing University of Posts and Telecommunications),* Da Li (Samsung), Conghui Hu (National University of Singapore), Timothy Hospedales (Edinburgh University), Honggang Zhang (Beijing University of Posts and Telecommunications), Yi-Zhe Song (University of Surrey)  
  PDF  Poster  Video  Supplementary  Code 
 542 | Temporal-aware Hierarchical Mask Classification for Video Semantic Segmentation    
  Zhaochong An (ETH Zurich), Guolei Sun (ETH Zurich),* Zongwei WU (University of Wurzburg), Hao Tang (ETH Zurich), Luc Van Gool (ETH Zurich)  
  PDF  Poster  Video  Code 
 543 | Robust and Efficient Edge-guided Pose Estimation with Resolution-conditioned NeRF    
  Liesbeth Claessens (ETH Zurich),* Fabian Manhardt (Google), Ricardo Martin-Brualla (Google), Roland Siegwart (ETH Zürich, Autonomous Systems Lab), Cesar Cadena Lerma (ETH Zurich), Federico Tombari (Google)  
  PDF  Video  Supplementary 
 544 | Re-Degradation and Contrastive Learning for Zero-shot Underwater Image Restoration    
  Nisha Varghese (IIT Madras),* Rajagopalan N Ambasamudram (Indian Institute of Technology Madras)  
  PDF  Video  Supplementary 
 562 | Fiducial Focus Augmentation for Facial Landmark Detection    
  Purbayan Kar (Sony Research India), Vishal M Chudasama (Sony Research India), Naoyuki Onoe (Sony), Pankaj Wasnik (Sony Research India),* Vineeth Balasubramanian (Indian Institute of Technology Hyderabad)  
  PDF  Poster  Video  Supplementary 
 566 | Polarimetric Imaging for Perception    
  Michael Baltaxe (General Motors),* Tomer Pe'er (General Motors), Dan Levi (General Motors)  
  PDF  Video  Supplementary 
 571 | Exploiting Multiple Priors for Neural 3D Indoor Reconstruction    
  Federico Lincetto (University of Padova),* Gianluca Agresti (Sony Europe B.V.), Mattia Rossi (SONY Europe B.V.), Pietro Zanuttigh (University of Padova)  
  PDF  Video  Supplementary 
 575 | Dual-Query Multiple Instance Learning for Dynamic Meta-Embedding based Tumor Classification    
  Simon Holdenried-Krafft (University of Tübingen),* Peter Somers (University of Tübingen), Ivonne Montes-Mojarro (University Hospital of Tübingen), Diana Silimon (University Hospital of Tübingen), Cristina Tarín (University of Stuttgart), Falko Fend (University Hospital of Tübingen), Hendrik P. A. Lensch (University of Tübingen)  
  PDF  Video  Supplementary  Code 
 578 | H-NeXt: The next step towards roto-translation invariant networks    
  Tomáš Karella (Institute of Information Theory and Automation, Czech Academy of Sciences),* Filip Šroubek (Institute of Information Theory and Automation, Czech Academy of Sciences), Jan Blažek (Institute of Information Theory and Automation, Czech Academy of Sciences), Jan Flusser (UTIA, Czech Academy of Sciences), Václav Košík (UTIA, Czech Academy of Sciences)  
  PDF  Video  Supplementary  Code 
 581 | Video-adverb retrieval with compositional adverb-action embeddings    
  Thomas Hummel (University of Tübingen),* Otniel-Bogdan Mercea (University of Tübingen), A. Sophia Koepke (University of Tübingen), Zeynep Akata (University of Tübingen)  
  PDF  Video  Supplementary  Code 
 589 | Staged Contact-Aware Global Human Motion Forecasting    
  Luca Scofano (Sapienza University of Rome), Alessio Sampieri (Sapienza University),* Elisabeth Schiele (Technische Universität München), Edoardo De Matteis (Sapienza University of Rome), Laura Leal-Taixé (NVIDIA), Fabio Galasso (Sapienza University)  
  PDF  Poster  Video  Code 
 595 | Face Aging via Diffusion-based Editing    
  Xiangyi Chen (Télécom Paris, Shanghai Jiao Tong University),* Stéphane Lathuilière (Telecom-Paris)  
  PDF  Poster  Video  Supplementary  Code 
 596 | Generating Context-Aware Natural Answers for Questions in 3D Scenes    
  Mohammed Munzer Dwedari (Technical University of Munich),* Matthias Niessner (Technical University of Munich), Zhenyu Chen (Technical University of Munich)  
  PDF  Poster  Video  Supplementary  Code 
 598 | Unsupervised Landmark Discovery Using Consistency-Guided Bottleneck    
  Mamona Awan (MBZU), Muhammad Haris Khan (Mohamed Bin Zayed University of Artificial Intelligence),* Sanoojan Baliah (Mohamed Bin Zayed University of Artificial Intelligence), Muhammad Ahmad Waseem (Information Technology University), Salman Khan (MBZUAI), Fahad Shahbaz Khan (MBZUAI), Arif Mahmood (Information Technology University)  
  PDF  Video  Supplementary  Code 
 601 | Overcoming Degradation Imbalance for Consistent Image Dehazing    
  Pranjay Shyam (Faurecia IRYStec),* Hyunjin Yoo (Faurecia IRYStec)  
  PDF 
 603 | READMem: Robust Embedding Association for a Diverse Memory in Unconstrained Video Object Segmentation    
  Stephane Vujasinovic (Fraunhofer IOSB),* Sebastian W Bullinger (Fraunhofer IOSB), Stefan Becker (Fraunhofer IOSB), Norbert Scherer-Negenborn (Fraunhofer IOSB), Michael Arens (Fraunhofer IOSB), Rainer Stiefelhagen (Karlsruhe Institute of Technology)  
  PDF  Poster  Video  Supplementary  Code 
 606 | STARS: Zero-shot Sim-to-Real Transfer for Segmentation of Shipwrecks in Sonar Imagery    
  Advaith V Sethuraman (University of Michigan ),* Katherine A Skinner (University of Michigan)  
  PDF  Video  Supplementary 
 608 | Object-Centric Open-Vocabulary Image Retrieval with Aggregated Features    
  Hila Levi (General Motors),* Guy Heller (General Motors), Dan Levi (General Motors), Ethan Fetaya (Bar Ilan University)  
  PDF  Poster  Video  Supplementary 
 609 | Cross-attention Masked Auto-Encoder for Human 3D Motion Infilling and Denoising    
  David Björkstrand (KTH Royal Institute of Technology / Tracab),* Josephine Sullivan (KTH Royal Institute of Technology), Lars M C Bretzner (Tracab AB), Gareth Loy (TRACAB), Tiesheng Wang (Tracab)  
  PDF  Video 
 614 | FRE: A Fast Method For Anomaly Detection And Segmentation    
  Ibrahima Ndiour (Intel),* Nilesh A Ahuja (Intel), Ergin U Genc (Intel), Omesh Tickoo (Intel)  
  PDF  Poster  Video  Supplementary  Code 
 617 | Learning Anatomically Consistent Embedding for Chest Radiography    
  Ziyu Zhou (Shanghai Jiao Tong University), Haozhe Luo ( Arizona State University, USA ), Jiaxuan Pang (Arizona State University), xiaowei ding (Shanghai Jiao Tong University), Michael Gotway (Mayo Clinic), Jianming Liang (Arizona State University, USA)*  
  PDF  Poster  Video  Supplementary 
 620 | Unifying the Harmonic Analysis of Adversarial Attacks and Robustness    
  Shishira R Maiya (University of Maryland),* Max Ehrlich (NVIDIA), Vatsal Agarwal (University of Maryland), Ser-Nam Lim (Meta AI), Tom Goldstein (University of Maryland), Abhinav Shrivastava (University of Maryland)  
  PDF  Poster  Video  Supplementary 
 622 | Teaching AI to Teach: Leveraging Limited Human Salience Data Into Unlimited Saliency-Based Training    
  Colton R Crum (University of Notre Dame),* Aidan Boyd (University of Notre Dame), Kevin Bowyer (University of Notre Dame), Adam Czajka (University of Notre Dame)  
  PDF  Poster  Video  Supplementary 
 623 | Superpixel Positional Encoding to Improve ViT-based Semantic Segmentation Models    
  Roberto Amoroso (University of Modena and Reggio Emilia),* Matteo Tomei (Prometeia), Lorenzo Baraldi (University of Modena and Reggio Emilia), Rita Cucchiara (Università di Modena e Reggio Emilia)  
  PDF  Poster  Video  Supplementary 
 624 | Text-to-Motion Synthesis using Discrete Diffusion Model    
  Ankur Chemburkar (USC Institute for Creative Technologies),* Shuhong Lu (USC Institute for Creative Technologies), Andrew Feng (USC Institute for Creative Technologies)  
  PDF  Poster  Video  Supplementary 
 629 | Biased Attention: Do Vision Transformers Amplify Gender Bias More than Convolutional Neural Networks?    
  Abhishek Mandal (Dublin City University),* Susan Leavy (University College Dublin), Suzanne Little (Dublin City University, Ireland)  
  PDF  Poster  Video  Code 
 633 | Multi-Target Domain Adaptation with Class-Wise Attribute Transfer in Semantic Segmentation    
  Changjae Kim (DGIST), Seunghun Lee (DGIST),* Sunghoon Im (DGIST)  
  PDF  Poster  Video  Supplementary 
 635 | Log RGB Images Provide Invariance to Intensity and Color Balance Variation for Convolutional Networks    
  Bruce A Maxwell (Northeastern University),* Sumegha Singhania (Northeastern University), Heather Fryling (Northeastern University), Haonan Sun (Northeastern University)  
  PDF  Poster  Video 
 643 | Color Constancy: How to Deal with Camera Bias?    
  Yi-Tun Lin (University of East Anglia),* Bianjiang Yang (Purdue University), Hao Xie (Meta Platforms, Inc.), Wenbin Wang (Meta), Honghong Peng (Meta), JUN HU (Apple Inc)  
  PDF  Poster  Video  Supplementary 
 647 | Dictionary-Guided Text Recognition for Smart Street Parking    
  Deyang Zhong (University of Washington Tacoma), Jiayu Li (University of Washington ), Wei Cheng (University of Washington), Juhua Hu (University of Washington)*  
  PDF  Poster  Video 
 650 | Towards Debiasing Frame Length Bias in Text-Video Retrieval via Causal Intervention    
  Burak Satar (Nanyang Technological University),* Hongyuan Zhu (Institute for Infocomm, Research Agency for Science, Technology and Research (A*STAR) Singapore), Hanwang Zhang (Nanyang Technological University), Joo-Hwee Lim (Institute for Infocomm Research)  
  PDF  Poster  Video  Supplementary  Code 
 659 | Open Set Synthetic Image Source Attribution    
  Shengbang Fang (Drexel University),* Tai D Nguyen (Drexel University), Matthew c Stamm (Drexel University)  
  PDF  Poster  Video 
 660 | G2N2: Lightweight Event Stream Classification with GRU Graph Neural Networks    
  Thomas Mesquida (CEA LIST),* Manon Dampfhoffer (SPINTEC University Grenoble Alpes), Thomas Dalgaty (CEA List), Pascal Vivet (CEA-LIST), Amos Sironi (PROPHESEE), Christoph Posch (PROPHESEE)  
  PDF  Poster  Video  Supplementary 
 664 | Stream-based Active Learning by Exploiting Temporal Properties in Perception with Temporal Predicted Loss    
  Sebastian Schmidt (BMW),* Stephan Günnemann (Technical University of Munich)  
  PDF  Poster  Video  Supplementary 
 665 | Distillation for High-Quality Knowledge Extraction via Explainable Oracle Approach    
  MyungHak Lee (Kookmin University),* Wooseong Syz Cho (Kookmin University), Sungsik Kim (Kookmin University), Jinkyu Kim (Korea University), Jaekoo Lee (Kookmin University)  
  PDF  Poster  Video  Code 
 666 | E2SAM: A Pipeline for Efficiently Extending SAM's Capability on Cross-Modality Data via Knowledge Inheritance    
  Su sundingkai (Beijing University of Posts and Telecommunications), Mengqiu Xu (Beijing University of Posts and Telecommunications), Kaixin Chen (Beijing University of Posts and Telecommunications), Ming Wu (Beijing University of Posts and Telecommunications),* Chuang Zhang (Beijing University of Posts and Telecommunications)  
  PDF  Poster  Video  Code 
 669 | SRBGCN: Tangent space-Free Lorentz Transformations for Graph Feature Learning    
  Abdelrahman Mostafa (University of Oulu),* Wei Peng (Stanford University), Guoying Zhao (University of Oulu)  
  PDF  Poster  Video  Supplementary 
 670 | DisCLIP: Open-Vocabulary Referring Expression Generation    
  Lior Bracha (Bar Ilan University),* Eitan Shaar (bar Ilan University), Aviv Shamsian (Bar Ilan University), Ethan Fetaya (Bar Ilan University), Gal Chechik (NVIDIA)  
  PDF  Video  Supplementary  Code 
 674 | Estimating Absorption Coefficient from a Single Image via Entropy Minimization    
  Junya Katahira (Kyushu Institute of Technology), Ryo Kawahara (Kyushu Institute of Technology), Takahiro Okabe (Kyushu Institute of Technology)*  
  PDF  Poster  Video  Supplementary 
 676 | BFC-BL: Few-Shot Classification and Segmentation combining Bi-directional Feature Correlation and Boundary constraint    
  Haibiao Yang (Guangdong University of Technology),* Zeng Bi (Guangdong University of Technology), Pengfei Wei (Guangdong University of Technology), Jianqi Liu (Guangdong University of Technology)  
  PDF  Poster  Video  Code 
 677 | MFSC: Matching by Few-Shot Classification    
  Daniel Shalam (University of Haifa), Elie Abboud (University of Haifa), Roee Litman (-), Simon Korman (University of Haifa)*  
  PDF  Poster  Video  Code 
 682 | ManifoldNeRF: View-dependent Image Feature Supervision for Few-shot Neural Radiance Fields    
  Daiju Kanaoka (Kyushu Institute of Technology),* Motoharu Sonogashira (RIKEN), Hakaru Tamukoh (Kyushu Institute of Technology), Yasutomo Kawanishi (RIKEN)  
  PDF  Poster  Video  Supplementary  Code 
 685 | Protecting Publicly Available Data With Machine Learning Shortcuts    
  Nicolas M Müller (Fraunhofer AISEC),* Maximilian Burgert (TU Munich), Pascal Debus (Fraunhofer AISEC), Jennifer Williams (University of Southampton), Philip Sperl (Fraunhofer AISEC), Konstantin Böttinger (Fraunhofer AISEC)  
  PDF  Video 
 699 | Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions    
  Ben Keel (University of Leeds),* Aaron Quyn (University of Leeds), David Jayne (University of Leeds), Samuel D. Relton (University of Leeds)  
  PDF  Poster  Video  Code 
 703 | Foveation in the Era of Deep Learning    
  George W Killick (University of Glasgow),* Paul Henderson (University of Glasgow), Jan Paul Siebert (University of Glasgow), Gerardo Aragon-Camarasa (University of Glasgow)  
  PDF  Poster  Video  Code 
 707 | SWIN-RIND: Edge Detection for Reflectance, Illumination, Normal and Depth Discontinuity with Swin Transformer    
  LUN MIAO (The University of Tokyo),* Takeshi Oishi (The University of Tokyo), Ryoichi Ishikawa (The university of Tokyo)  
  PDF  Poster  Video  Code 
 709 | Momentum Adapt: Robust Unsupervised Adaptation for Improving Temporal Consistency in Video Semantic Segmentation During Test-Time    
  Amirhossein Hassankhani (Tampere University),* Hamed Rezazadegan Tavakoli (Nokia Technologies), Esa Rahtu (Tampere University)  
  PDF  Poster  Video  Supplementary 
 715 | Bridging the Gap: Enhancing the Utility of Synthetic Data via Post-Processing Techniques    
  Eugenio Lomurno (Politecnico di Milano),* Andrea Lampis (Politecnico di Milano), Matteo Matteucci (Politecnico di Milano)  
  PDF  Poster  Video  Supplementary  Code 
 718 | Self-Supervised Adversarial Training for Robust Face Forgery Detection    
  Yueying Gao (Communication University of China),* Weiguo Lin (Communication University of China), junfeng xu (Communication University of China), Wanshan Xu (Communication University of China), Peibin Chen (Communication University of China)  
  PDF  Poster  Video 
 719 | EyeGuide - From Gaze Data to Instance Segmentation    
  Jacqueline Kockwelp (University of Münster), Joerg Gromoll (CeRA), Joachim Wistuba (Centre of Reproductive Medicine and Andrology), Benjamin Risse (University of Münster)*  
  PDF  Poster  Video  Code 
 721 | Convolution kernel adaptation to calibrated fisheye    
  Bruno Berenguel-Baeta (Universidad de Zaragoza),* Maria Santos-Villafranca (Universidad de Zaragoza), Jesus Bermudez-Cameo (Universidad de Zaragoza), Alejandro Perez Yus (Universidad de Zaragoza), Josechu Guerrero (Universidad de Zaragoza)  
  PDF  Video  Supplementary  Code 
 722 | Spatio-Temporal Graph Diffusion for Text-Driven Human Motion Generation    
  Chang Liu (University of Trento),* Mengyi Zhao (Beihang University), Bin Ren (University of Trento), Mengyuan Liu (Peking University, Shenzhen Graduate School), Nicu Sebe (University of Trento)  
  PDF  Video 
 730 | SA2-Net: Scale-aware Attention Network for Microscopic Image Segmentation    
  Mustansar Fiaz (MBZUAI),* Moein Heidari (Iran University of Science and Technology), Rao Muhammad Anwer (MBZUAI/AALTO), Hisham Cholakkal (MBZUAI)  
  PDF  Video  Code 
 739 | Robust Principles: Architectural Design Principles for Adversarially Robust CNNs    
  ShengYun Peng (Georgia Institute of Technology),* Weilin Xu (Intel), Cory Cornelius (Intel Corporation), Matthew Hull (Georgia Institute of Technology), Kevin Li (Georgia Institute of Technology), Rahul Duggal (Georgia Tech), Mansi Phute (Georgia Institute of Technology), Jason Martin (Intel Corporation), Duen Horng Chau (Georgia Institute of Technology)  
  PDF  Poster  Video  Supplementary  Code 
 741 | Motion-Bias-Free Feature-Based SLAM    
  Alejandro Fontan (Queensland University of Technology),* Michael Milford (ACRV and QUT, Australia), Javier Civera (Universidad de Zaragoza)  
  PDF  Poster  Video  Code 
 743 | A Comprehensive Crossroad Camera Dataset to Improve Traffic Safety of Mobility Aid Users    
  Ludwig Mohr (Institute of Computer Graphics and Vision, Graz University of Technology),* Nadezda Kirillova (Graz University of Technology), Horst Possegger (Graz University of Technology), Horst Bischof (Graz University of Technology)  
  PDF  Poster  Video  Supplementary  Code 
 744 | CoordGate: Efficiently Computing Spatially-Varying Convolutions in Convolutional Neural Networks    
  Sunny Howard (University of Oxford),* Peter Norreys (University of Oxford), Andreas Döpp (LMU Munich)  
  PDF  Supplementary 
 748 | Multi-CLIP: Contrastive Vision-Language Pre-training for Question Answering tasks in 3D Scenes    
  Alexandros Delitzas (ETH Zurich),* Maria Parelli (ETH Zurich), Nikolas Hars (ETH Zurich), Georgios Vlassis (ETH Zurich), Sotirios-Konstantinos Anagnostidis (ETH Zurich), Gregor Bachmann (ETH Zurich), Thomas Hofmann (ETH Zurich)  
  PDF  Video  Supplementary  Code 
 750 | A2V: A Semi-Supervised Domain Adaptation Framework for Brain Vessel Segmentation via Two-Phase Training Angiography-to-Venography Translation    
  Francesco Galati (EURECOM),* Daniele Falcetta (EURECOM), Rosa Cortese (University of Siena), Barbara Casolla (CHU Nice), Ferran Prados (University College London), Ninon Burgos (CNRS - Paris Brain Institute), Maria A. Zuluaga (EURECOM)  
  PDF  Poster  Video  Code 
 752 | Learnable Data Augmentation for One-Shot Unsupervised Domain Adaptation    
  Julio Ivan Davila Carrazco (Istituto Italiano di Tecnologia),* Pietro Morerio (Istituto Italiano di Tecnologia), Alessio Del Bue (Istituto Italiano di Tecnologia (IIT)), Vittorio Murino (Istituto Italiano di Tecnologia)  
  PDF  Poster  Video  Supplementary  Code 
 754 | Single-Landmark vs. Multi-Landmark Deep Learning Approaches to Brain MRI Landmarking: a Case Study with Healthy Controls and Down Syndrome Individuals    
  Jordi Malé (La Salle - Ramon Llull University),* Yann Heuzé (CNRS, Univ. Bordeaux, MC, PACEA, UMR5199), Juan Fortea (Hospital of Sant Pau), Neus Martinez Abadias (Universitat de Barcelona), Xavier Sevillano (La Salle - Universitat Ramon Llull)  
  PDF  Video  Code 
 761 | Laughing Matters: Introducing Audio-Driven Laughing-Face Generation with Diffusion Models    
  Antoni Bigata Casademunt (Imperial College London),* Rodrigo Mira (Imperial College London), Nikita Drobyshev (Imperial College London), Konstantinos Vougioukas (Imperial College London), Stavros Petridis (Imperial College London), Maja Pantic (Facebook / Imperial College London )  
  PDF  Poster  Video  Supplementary  Code 
 762 | Novel Regularization via Logit Weight Repulsion for Long-Tailed Classification    
  Taegil Ha (Seoul National University),* Seulki Park (Seoul National University), Jin Young Choi (Seoul National University)  
  PDF  Poster  Video 
 763 | BoIR: Box-Supervised Instance Representation for Multi-Person Pose Estimation    
  Uyoung Jeong (Ulsan National Institute of Science and Technology),* Seungryul Baek (UNIST), Hyung Jin Chang (University of Birmingham), Kwang In Kim (POSTECH)  
  PDF  Poster  Video  Supplementary  Code 
 765 | Reconstructing Synthetic Lensless Images in the Low-Data Regime    
  Abeer Banerjee (CSIR-CEERI),* Himanshu Kumar (CSIR-CEERI), Sumeet Saurav (CSIR-CEERI), Sanjay Singh (CSIR-CEERI, Pilani )  
  PDF  Poster  Video  Code 
 767 | Label-guided Real-time Fusion Network for RGB-T Semantic Segmentation    
  Zengrong Lin (Sun Yat-sen University), Baihong Lin (University of Electronic Science and Technology of China),* Yulan Guo (Sun Yat-sen University)  
  PDF  Poster  Video  Code 
 771 | Vision Transformers are Inherently Saliency Learners    
  YASSER ABDELAZIZ DAHOU DJILALI (TECHNOLOGY INNOVATION INSTITUTE),* Kevin McGuinness (DCU), Noel O Connor (Home)  
  PDF  Supplementary 
 775 | Towards Clip-Free Quantized Super-Resolution Networks: How to Tame Representative Images    
  Alperen Kalay (Aselsan Research),* Bahri Batuhan Bilecen (Aselsan Research), Mustafa Ayazoglu (Aselsan Research)  
  PDF  Poster  Video 
 781 | Adaptive Adversarial Norm Space for Efficient Adversarial Training    
  Hui Kuurila-Zhang (University of Oulu),* Haoyu Chen (University of Oulu), Guoying Zhao (University of Oulu)  
  PDF  Poster  Video  Code 
 787 | TD-GEM: Text-Driven Garment Editing Mapper    
  Reza Dadfar (KTH), Sanaz Sabzevari (KTH University),* Marten Bjorkman (KTH), Danica Kragic (KTH Royal Institute of Technology)  
  PDF  Video  Code 
 789 | Multi-Stain Self-Attention Graph Multiple Instance Learning Pipeline for Histopathology Whole Slide Images    
  Amaya Gallagher-Syed (Queen Mary University of London),* Luca Rossi (The Hong Kong Polytechnic University), Felice Rivellese (Queen Mary University of London), Costantino Pitzalis (Queen Mary University of London), Myles Lewis (Queen Mary University of London), Michael Barnes (Queen Mary University of London), Gregory Slabaugh (Queen Mary University of London)  
  PDF  Poster  Video  Supplementary  Code 
 792 | BEA: Revisiting anchor-based object detection DNN using Budding Ensemble Architecture    
  Qutub Syed (INTEL LABS),* Neslihan Kose Cihangir (Intel Deutschland GmbH), Rafael Rosales (Intel), Michael Paulitsch (Intel), Korbinian Hagn (Intel), Florian R Geissler (Intel), Yang Peng (Intel), Gereon Hinz (STTech GmbH), Alois C. Knoll (Robotics and Embedded Systems)  
  PDF  Poster  Video  Supplementary 
 798 | Cascade Sparse Feature Propagation Network for Interactive Segmentation    
  Chuyu Zhang (PLUS Lab, Shanghaitech University),* Hui Ren (ShanghaiTech), ChuanYang Hu (PLUS Lab, Shanghaitech University), Yongfei Liu (ShanghaiTech), Xuming He (ShanghaiTech University)  
  PDF  Supplementary  Code 
 799 | Discriminative Adversarial Privacy: Balancing Accuracy and Membership Privacy in Neural Networks    
  Eugenio Lomurno (Politecnico di Milano),* Alberto Archetti (Politecnico di Milano), Francesca Ausonio (Politecnico di Milano), Matteo Matteucci (Politecnico di Milano)  
  PDF  Poster  Video  Supplementary  Code 
 800 | Mobile Vision Transformer-based Visual Object Tracking    
  Goutam Yelluru Gopal (Concordia University),* Maria Amer (Concordia University)  
  PDF  Poster  Video  Code 
 806 | Adaptation of Distinct Semantics for Uncertain Areas in Polyp Segmentation    
  Quang Vinh Nguyen (Chonnam National University),* Van Thong Huynh (Chonnam National University), Soo-Hyung Kim (Chonnam National University)  
  PDF  Video 
 813 | Learning Tri-modal Embeddings for Zero-Shot Soundscape Mapping    
  Subash Khanal (Washington University in Saint Louis),* Srikumar Sastry (Washington University in St. Louis), Aayush Dhakal (Washington University in St Louis), Nathan Jacobs (Washington University in St. Louis)  
  PDF  Video  Supplementary  Code 
 815 | Text and Click inputs for unambiguous open vocabulary instance segmentation    
  Vighnesh N Birodkar (Google),* Jonathan Huang (Google), Meera Hahn (Google), Irfan Essa (Georgia Institute of Technology), Nikolai Warner (Georgia Tech)  
  PDF  Poster  Video  Supplementary 
 820 | Proposal-based Temporal Action Localization with Point-level Supervision    
  Yuan Yin (Institute of Industrial Science, The University of Tokyo),* Yifei Huang (The University of Tokyo), Ryosuke Furuta (The University of Tokyo), Yoichi Sato (University of Tokyo)  
  PDF  Poster  Video  Supplementary 
 822 | Differentiable SLAM Helps Deep Learning-based LiDAR Perception Tasks    
  Prashant Kumar (Indian Institute of Technology, Delhi),* Dheeraj Vattikonda (McGill University), Vedang Bhupesh Shenvi Nadkarni (Birla Institute of Technology and Science, Pilani), Erqun Dong (McGill University), Sabyasachi Sahoo (Université Laval, Mila)  
  PDF  Poster  Video  Code 
 823 | Improved Photometric Stereo through Efficient and Differentiable Shadow Estimation    
  Po-Hung Yeh (National Taiwan University), Pei-Yuan Wu (National Taiwan University), Jun-Cheng Chen (Academia Sinica)*  
  PDF  Poster  Video  Supplementary  Code 
 825 | RoomNeRF: Representing Empty Room as Neural Radiance Fields for View Synthesis    
  Mangyu Kong (Yonsei University),* Seongwon Lee (Yonsei university), Euntai Kim (Yonsei University)  
  PDF  Poster  Video  Supplementary 
 828 | SCAAT: Improving Neural Network Interpretability via Saliency Constrained Adaptive Adversarial Training    
  Rui Xu (Peking University), Wenkang Qin (Peking University), Peixiang Huang (Peking University), Hao Wang (National Institutes for Food and Drug Control), Lin Luo (Peking University)*  
  PDF  Poster  Supplementary 
 829 | PseudoCal: Towards Initialisation-Free Deep Learning-Based Camera-LiDAR Self-Calibration    
  Mathieu Cocheteux (Université de Technologie de Compiègne),* Julien Moreau (UTC, Heudiasyc-SyRI), Franck Davoine (Heudiasyc - CNRS - Université de technologie de Compiègne)  
  PDF  Video 
 832 | Feather: An Elegant Solution to Effective DNN Sparsification    
  Athanasios Glentis Georgoulakis (National Technical University of Athens),* George Retsinas (National Technical University of Athens), Petros Maragos (National Technical University of Athens)  
  PDF  Video  Supplementary  Code 
 837 | Domain-Adaptive Semantic Segmentation with Memory-Efficient Cross-Domain Transformers    
  Ruben Mascaro (ETH Zurich),* Lucas Teixeira (ETH Zurich), Margarita Chli (ETH Zurich)  
  PDF  Poster  Video  Supplementary  Code 
 846 | Topology-Preserving Hard Pixel Mining for Tubular Structure Segmentation    
  Guoqing Zhang (Tsinghua-Berkeley Shenzhen Institute, Tsinghua University),* Caixia Dong (The Second Affilated Hospital of Xi'an Jiaotong University), Yang Li (Tsinghua-Berkeley Shenzhen Institute, Tsinghua University)  
  PDF  Poster  Video  Supplementary  Code 
 854 | A Forward-backward Learning strategy for CNNs via Separation Index Maximizing at the First Convolutional Layer    
  Ali Karimi (University of Tehran), Ahmad Kalhor (University of Tehran),* Mona Ahmadian (University of Surrey)  
  PDF  Poster  Video 
 858 | Weakly-supervised Spatially Grounded Concept Learner for Few-Shot Learning    
  Gaurav Bhatt (The University of British Columbia),* Deepayan Das (IIT-H), Leonid Sigal (University of British Columbia), Vineeth N Balasubramanian (Indian Institute of Technology, Hyderabad)  
  PDF  Poster  Video  Supplementary 
 868 | Multi-Scale Cross Contrastive Learning for Semi-Supervised Medical Image Segmentation    
  Qianying Liu (University of Glasgow),* Xiao Gu (University of Oxford), Paul Henderson (University of Glasgow), Fani Deligianni (University of Glasgow)  
  PDF  Poster  Video  Supplementary  Code 
 870 | Data exploitation: multi-task learning of object detection and semantic segmentation on partially annotated data    
  Hoàng-Ân Lê (IRISA, University of South Brittany),* Minh-Tan Pham (IRISA-UBS)  
  PDF  Poster  Video  Code 
 871 | On the Lipschitz Constant of Deep Networks and Double Descent    
  Matteo Gamba (KTH),* Hossein Azizpour (KTH (Royal Institute of Technology)), Marten Bjorkman (KTH)  
  PDF  Video  Code 
 881 | Rethinking Transfer Learning for Medical Image Classification    
  Le Peng (University of Minnesota),* Hengyue Liang (University of Minnesota), Gaoxiang Luo (University of Minnesota), Taihui Li (University of Minnesota), Ju Sun (University of Minnesota)  
  PDF  Video  Supplementary  Code 
 889 | DeepliteRT: Computer Vision at the Edge    
  Saad Ashfaq (Deeplite),* Alexander Hoffman (McGill University), SAPTARSHI MITRA (Deeplite Inc.), Sudhakar Sah (Deeplite Inc), MohammadHossein AskariHemmat (Polytechnique Montreal), Ehsan Saboori (Deeplite Inc.)  
  PDF  Poster  Video 
 893 | VADOR: Real World Video Anomaly Detection with Object Relations and Action    
  Halil İbrahim Öztürk (Togg),* Ahmet Burak Can (Hacettepe University)  
  PDF  Poster  Video  Code 
 899 | C3: Cross-instance guided Contrastive Clustering    
  Mohammadreza Sadeghi (McGill University), Hadi Hojjati (McGill University), Narges Armanfard (McGill University; Mila - Quebec AI Institute)*  
  PDF  Poster  Video  Code 
 901 | On-Site Adaptation for Monocular Depth Estimation with a Static Camera    
  Huan Li (Bologna University),* Matteo Poggi (University of Bologna), Fabio Tosi (University of Bologna), Stefano Mattoccia (University of Bologna)  
  PDF  Code 
 908 | Class-Imbalanced Semi-Supervised Learning with Inverse Auxiliary Classifier    
  Tiansong Jiang (Nanjing University of Science and Technology),* Sheng Wan (Nanjing university of science and technology), Chen Gong (Nanjing University of Science and Technology)  
  PDF  Poster  Video  Supplementary  Code 
 911 | Masked Attention ConvNeXt Unet with Multi-Synthesis Dynamic Weighting for Anomaly Detection and Localization    
  SHIH CHIH LIN (National Tsing Hua University),* Ho Weng Lee (National Tsing Hua University), Yu-Shuan Hsieh (National Tsing Hua University), Cheng Yu Ho (National Tsing Hua University), Shang-Hong Lai (National Tsing Hua University)  
  PDF  Poster  Video 
 912 | Group Orthogonalization Regularization for Vision Models Adaptation and Robustness    
  Yoav Kurtz (Tel Aviv University), Noga Bar (Tel Aviv University), Raja Giryes (Tel Aviv University)*  
  PDF  Video  Supplementary  Code 

 © 2023 The BMVA    
  Imprint  Data Protection    
 The British Machine Vision Conference is organised by The British Machine Vision Association and Society for Pattern Recognition  . The Association is a Company limited by guarantee, No.2543446, and a non-profit-making body, registered in England and Wales as Charity No.1002307 (Registered Office: Dept. of Computer Science, Durham University, South Road, Durham, DH1 3LE, UK).

5. BMVC_2 conference:
BMVC 2023      
 Home 
  Dates 
  Attending | About the City  Registration  Student Funding  Plan Your Visit  Venue 
  Programme | Conference Schedule  Keynotes  Oral Presentations  Poster Presentations  Workshops  Proceedings  Programme (PDF)  Workshop Proceedings 
  Authors | Call for Papers  Call for Workshops  Call for Papers - Doctoral Consortium  Frequently Asked Questions  Rebuttal Instructions  Reviewing Guidelines  Submit Your Paper 
  People | Organisers  Volunteers  Area Chairs  Emergency Reviewers  Reviewers 
  Sponsors 

 Important Dates  

 Please note all deadlines are at 23:59 UK Time.   
  
 Subject | Date (all deadlines 23:59 UK Time) 
 Workshop Submission Deadline  Authors | Friday, 5 May 2023 
 Paper Submission Deadline  Authors | Friday, 12 May 2023 
 Supplementary Material Submission  Authors | Friday, 26 May 2023 
 Workshop Acceptance Notification  Authors | Tuesday, 30 May 2023 
 Review Period Starts  Reviewers | Tuesday, 6 June 2023 
 Reviews Submitted  Reviewers | Thursday, 13 July 2023 
 Doctoral Consortium Submission Deadline  Authors | Friday, 14 July 2023 
 Start of Rebuttal Period  Authors | Friday, 14 July 2023 
 End of Rebuttal Period  Authors | Friday, 21 July 2023 
 Reviewer Discussion & Final Revs  Reviewers  AC | Monday, 31 July 2023 
 Meta-Reviews Submitted  AC | Sunday, 6 August 2023 
 Paper Decisions & Meta-Rev Consolidation  AC | Sunday, 13 August 2023 
 Author Notifications  Authors | Monday, 21 August 2023 
 Camera Ready  Authors | Sunday, 17 September 2023 
 Camera Ready for Workshops  Authors (workshops) | Sunday, 1 October 2023 
 Poster Submissions  Authors | Wednesday, 1 November 2023 
 Video Submissions  Authors | Wednesday, 1 November 2023 
 In-Person Conference Starts Everyone | Monday, 20 November 2023 
 In-Person Conference Ends Everyone | Thursday, 23 November 2023 
 Workshops Start Everyone | Thursday, 23 November 2023 
 Workshops End Everyone | Friday, 24 November 2023 

 © 2022-2023 The BMVA    
  [email protected]     
 The British Machine Vision Conference is organised by The British Machine Vision Association and Society for Pattern Recognition  . The Association is a Company limited by guarantee, No.2543446, and a non-profit-making body, registered in England and Wales as Charity No.1002307 (Registered Office: Dept. of Computer Science, Durham University, South Road, Durham, DH1 3LE, UK).

6. BMVC_3 conference:
BMVC 2023      
 Home 
  Dates 
  Attending | About the City  Registration  Student Funding  Plan Your Visit  Venue 
  Programme | Conference Schedule  Keynotes  Oral Presentations  Poster Presentations  Workshops  Proceedings  Programme (PDF)  Workshop Proceedings 
  Authors | Call for Papers  Call for Workshops  Call for Papers - Doctoral Consortium  Frequently Asked Questions  Rebuttal Instructions  Reviewing Guidelines  Submit Your Paper 
  People | Organisers  Volunteers  Area Chairs  Emergency Reviewers  Reviewers 
  Sponsors 

 Conference Schedule  

 Mon 20th | Tue 21st | Wed 22nd | Thu 23rd | Fri 24th | ROOMS 
 08:00 | Registration | Registration | Registration | Registration | Workshops ARIA, VUA, MVEO and AI&CV-NDS different venues in the city. | 08:00 | P&J-MF | Main Foyer | Registration (Mon-Thu) 
 CS1 | Conference Suite 1 | Posters, Tea Breaks & Lunch (Mon-Thu) 
 CS2 | Conference Suite 2 | Oral Presentations (Mon to Wed) 
 09:00 | Keynote  
    
   The Future of Recognition is 3D  
    
   Georgia Gkioxari | Keynote  
    
   How I Learned to Love Plants  
    
   Michael Pound | Keynote  
    
   Self-supervised Learning for 3D Computer Vision  
    
   Daniel Cremers | 09:00 | CS3 | Conference Suite 3 | Oral Presentations (Thu) 
 MR2 | Meeting Room 2 | Doctoral Consortium (Wed) 
 MR8 | Meeting Room 8 | CVG Half-Day Workshop (Thu) 
 09:45 | Welcome | MR9 | Meeting Room 9 | CADL Half-Day Workshop (Thu) 
 10:00 | Keynote  
    
   Faces, Avatars, and GenAI  
    
   Maja Pantic | Oral Presentations  
    
   Efficient and Scalable Vision  
   (Papers 19-22) | Oral Presentations  
    
   Action and Event Understanding  
   (Papers 36-39) | Oral Presentations  
    
   Human/Object Pose Estimation  
   (Papers 53-56) | 10:00 |  
 11:00 | Tea Break | Tea Break | Tea Break | Tea Break | 11:00 |  
 11:45 | Oral Presentations  
    
   Architectures and Techniques I  
   (Papers 1-5) | Oral Presentations  
    
   Explainable AI & Representation Learning  
   (Papers 23-27) | Oral Presentations  
    
   Recognition/Identification/Detection  
   (Papers 40-44) | Oral Presentations  
    
   Transfer, Low-shot Learning & Segmentation  
   (Papers 57-61) | 11:45 |  
 13:00 | Lunch | Lunch | Lunch | Doctoral Consort. | Lunch | 13:00 |  
 13:30 | 13:30 |  
 14:00 | Oral Presentations  
    
   Architectures and Techniques II  
   (Papers 6-10) | Poster Session 1  
    
  (Papers 1-65) | Poster Session 2   
   
  (Papers 66-131) | Poster Session 3  
    
  (Papers 132-200) | Workshops CVG and CADL, concurrent in 50 people meeting rooms in the same venue | 14:00 |  
 15:00 | Tea Break | 15:00 |  
 15:15 | Tea Break | Tea Break | Tea Break |  
 15:30 | Oral Presentations  
    
   Medical and Biological Vision  
   (Papers 45-52) |  
 15:45 | Oral Presentations  
    
   3D Analysis I  
   (Papers 11-14) | Orals Presentations  
    
   Vision and Language I  
   (Papers 28-31) | Oral Presentations  
    
   Faces and Gestures  
   (Papers 62-67) | 15:45 |  
 16:45 | Tea Break | Tea Break |  
 17:00 | Oral Presentations  
    
   3D Analysis II  
   (Papers 15-18) | Orals Presentations  
    
   Vision and Language II  
   (Papers 32-35) |  
 Awards & Closing | 17:15 |  
 17:30 |  
 18:00 | 18:00 |  
 20:00 to 21:30  - Welcoming Reception (Town & County Hall Civic Room, Town House) | 20:00 to 01:00  - Awards & Gala Dinner (P&J Live) |  

 © 2022-2023 The BMVA    
  [email protected]     
 The British Machine Vision Conference is organised by The British Machine Vision Association and Society for Pattern Recognition  . The Association is a Company limited by guarantee, No.2543446, and a non-profit-making body, registered in England and Wales as Charity No.1002307 (Registered Office: Dept. of Computer Science, Durham University, South Road, Durham, DH1 3LE, UK).

7. AISC_0 conference:
Home 
  Invited Speakers 
  Registration 
  HOD and Professors Meeting/CORE AGM 
  Accommodation 
  Past ACSW | 2024 ACSW | 2024 Program 
  2024 Workshops 
  2023 ACSW | 2023 Program 
  2023 Tutorials & Workshops 
  2023 CORE HOD and Professors Meeting 
  2022 ACSW | 2022 Program 
  2022 Posters 
  2022 Speakers 
  2022 HOD and Professors Meeting 
  2021 ACSW | 2021 Program 
  2021 Speakers 
  2021 HOD & Professors Meeting 
  2020 ACSW | 2020 ACSW 
  2020 Program 
  2020 Speakers 
  2020 Lightning Talks and Posters 
  2019 ACSW | 2019 ACSW 
  2019 Program 
  2019 Speakers 
  2019 Posters 
  2018 ACSW | 2018 ACSW 
  2018 Program | 2018 Posters 
  2018 Hods & Professors Meeting 
  ACE 2018 
  AISC 2018 
  APCCM 2018 
  AUIC 2018 
  AUSPDC 2018 
  AWC 2018 
  IE 2018 
  HIKM 2018 
  2018Speakers 
  2017 ACSW | ACSW 2017 
  Proceedings 
  Special Issue Journals 
  Speakers 
  2016 ACSW | ACSW 2016 
  Program | AUSPDC 2016 
  AISC 2016 
  AUIC 2016 
  APCCM 2016 
  ACSC 2016 
  HIKM 2016 
  IE 2016 
  2014 ACSW | ACSW 2014 
  Program 
  Speakers 
  Sponsors 

 Home 
  Invited Speakers 
  Registration 
  HOD and Professors Meeting/CORE AGM 
  Accommodation 
  Past ACSW | 2024 ACSW | 2024 Program 
  2024 Workshops 
  2023 ACSW | 2023 Program 
  2023 Tutorials & Workshops 
  2023 CORE HOD and Professors Meeting 
  2022 ACSW | 2022 Program 
  2022 Posters 
  2022 Speakers 
  2022 HOD and Professors Meeting 
  2021 ACSW | 2021 Program 
  2021 Speakers 
  2021 HOD & Professors Meeting 
  2020 ACSW | 2020 ACSW 
  2020 Program 
  2020 Speakers 
  2020 Lightning Talks and Posters 
  2019 ACSW | 2019 ACSW 
  2019 Program 
  2019 Speakers 
  2019 Posters 
  2018 ACSW | 2018 ACSW 
  2018 Program | 2018 Posters 
  2018 Hods & Professors Meeting 
  ACE 2018 
  AISC 2018 
  APCCM 2018 
  AUIC 2018 
  AUSPDC 2018 
  AWC 2018 
  IE 2018 
  HIKM 2018 
  2018Speakers 
  2017 ACSW | ACSW 2017 
  Proceedings 
  Special Issue Journals 
  Speakers 
  2016 ACSW | ACSW 2016 
  Program | AUSPDC 2016 
  AISC 2016 
  AUIC 2016 
  APCCM 2016 
  ACSC 2016 
  HIKM 2016 
  IE 2016 
  2014 ACSW | ACSW 2014 
  Program 
  Speakers 
  Sponsors 

 University of Queensland, Brisbane, 10 – 14 February   
 2025 Australasian Computer Science Week    

 Join us for the 2025 Australasian Computer Science Week (ACSW)  
 We are excited to invite you to the 2025 Australasian Computer Science Week (ACSW) from 10 – 14 February.  
 The premier event for CS academics across Australasia, ACSW 2025 will be co-hosted by the Computing Research and Education Association of Australasia (CORE) and the Australian Council of Deans of ICT (ACDICT).  
 Event Highlights   
 The in-person activities  will take place from Monday, 10 February, to Thursday, 13 February  at the University of Queensland, St Lucia Campus  in Brisbane and will include:  
 The CORE and ACDICT Heads of Departments and Professors Meeting 
  CORE Annual General Meeting 
  Invited Talks and Panel Sessions with leading experts 
  Keynote Addresses from CORE Award Winners 
  The Australasian Computing Education Conference (ACE 2025) 
  The Australasian Symposium on Parallel and Distributed Computing (AusPDC 2025) 
  In addition, the 2025 Australasian Information Security Conference (AISC)  will be co-located as a fully online event  , running from Thursday, 13 February, to Friday, 14 February  .  
 Further details, including the program and registration, will be available soon. We look forward to welcoming you to ACSW 2025.  
 Rachel Cardell-Oliver, President, CORE  
   Stewart Von Itzstein, President, ACDICT   

 Conference Websites  
 For more information about each conference and to submit papers, visit the websites below:  
 Australasian Computing Education Conference (ACE 2025): | https://aceconference2025.github.io/ 
  Australasian Symposium on Parallel and Distributed Computing (AusPDC 2025): | https://sites.google.com/monash.edu/auspdc2025 
  Australasian Information Security Conference (AISC 2025): | https://sites.google.com/view/aisc2025/home 
  Important Dates  
 Registration Open | November 2024 
  ACE 2025 Submission Deadline | 1 November 2024 
  AISC 2025 Submission Deadline | 15 November 2024 
  AusPDC 2025 | Submission Deadline | 1 | December | 2024 
  Program Available | December 2024 
  CORE and ACDICT Heads of Departments and Professors Meeting | 10 February 2025 
  CORE Annual General Meeting | 11 February 2025 
  Invited Talks, Panel Sessions, Keynote Addresses, ACE 2025, AusPDC 2025 | 11 – 13 February 2025 
  AISC 2025 Online Conference | 13 – 14 February 2024 

 Call for Papers – ACE 2025, AusPDC 2025, AISC 2025  
 For paper submissions, including templates, submission portals, and important dates, please visit the dedicated websites for each conference:  
 Australasian Computing Education Conference (ACE 2025): | https://aceconference2025.github.io/ 
  Australasian Symposium on Parallel and Distributed Computing (AusPDC 2025): | https://sites.google.com/monash.edu/auspdc2025 
  Australasian Information Security Conference (AISC 2025): | https://sites.google.com/view/aisc2025/home 

 Enquiries  
 Conference Design has been appointed to assist with conference management. Please contact them directly for any questions.  
 mail@conferencedesign.com.au   
  +03 6231 2999  
  International +61 3 6231 2999  

 Invited Speakers    

 Terry Rudolph    
 Co-founder and Chief Architect,PsiQuantum   

 Bojie Shen    
 Winner, Australasian Distinguished Doctoral Dissertation Award   

 Jia Wu    
 Winner, Outstanding Research Contribution Award   

 Alan Fekete    
 Winner, Distinguished Service Award   

 Nicole Herbert    
 Winner, CORE Teaching Award   

 Shaanan Cohney    
 Winner, CORE Teaching Award Early Career   

 About ACSW  
 ACSW is the premier event for CS academics across Australasia. ACSW consists of several conferences covering a wide range of Computer Science topics. The annual conference is attended by many national and international delegates comprising HDR students, distinguished academics and Industry representatives from across Australasia in computer science.  

 About CORE  
 The Computing Research and Education Association of Australasia, CORE, is an association of university departments of computer science in Australia and New Zealand.  
 The purposes for which the Association is established are:  
 to create a professional association of those engaged in computer science and information technology in higher education and research institutes and to facilitate their professional development; 
  to assist and advance research in computer science and information technology in higher education and research institutes; 
  to assist and advance teaching in computer science and information technology in higher education; 
  to provide a forum for those interested in computer science and information technology so as to stimulate discussion of relevant issues; and 
  to promote co-operation and liaison with other groups and organizations which have related or complementary purposes and activities. 

 About ACDICT  
 ACDICT is the association of deans of computing in Australian and New Zealand universities, whose mission is to promote and advance ICT education, research and scholarship on behalf of Australasian universities.  
 Objectives:  
 To provide a forum for leaders of computing education to discuss and address matters of common concern and national importance. 
  To be a voice for the tertiary computing education sector, communicating as appropriate with universities, government, professional organisations in computing, other councils of deans, and other relevant groups. 
  To help ensure that the role of computing education and research is appropriately recognised throughout the education sector and the community. 
  To monitor the state of computing education in Australasia and to promote related research and research training. 

 Venue   
 The University of Queensland – St Lucia Campus    
  280-284 Sir Fred Schonell Dr   
  St Lucia QLD 4067   
  https://campuses.uq.edu.au/st-lucia    
 The St Lucia campus is only seven kilometres from Brisbane’s city centre, and conveniently serviced by more than 10 direct bus routes from the Brisbane CBD and outer suburbs.   

 ABOUT THE ASSOCIATION   
 The Computing Research and Education Association of Australasia, CORE, is an association of university departments of computer science in Australia and New Zealand. Prior to 2004 it was known as the Computer Science Association, CSA.   
 The purposes for which the Association is established are:    
 to create a professional association of those engaged in computer science and information technology in higher education and research institutes and to facilitate their professional development; 
  to assist and advance research in computer science and information technology in higher education and research institutes; 
  to assist and advance teaching in computer science and information technology in higher education; 
  to provide a forum for those interested in computer science and information technology so as to stimulate discussion of relevant issues; and 
  to promote co-operation and liaison with other groups and organizations which have related or complementary purposes and activities. 

 CONFERENCE MANAGERS   
 Please contact the team at Conference Design with any questions regarding the conference.   
 mail@conferencedesign.com.au    
  +61 3 6231 2999   
  www.conferencedesign.com.au    

 LINKS   
 Code of Conduct    
  Privacy and Data Policy    

 ACKNOWLEDGEMENT OF COUNTRY   
 In the spirit of reconciliation we acknowledge the Traditional Custodians of country throughout Australia and their connections to land, sea and community. We pay our respect to their Elders past and present and extend that respect to all Aboriginal and Torres Strait Islander peoples today.   

 This site uses cookies. Find out more about cookies and how you can refuse them.  
   
 I Accept

8. CHI PLAY_0 conference:
Skip to content  Home      
     Menu   Authors | Full Papers 
  Work in Progress 
  Perspectives on Play 
  Student Game Design Competition 
  Interactivity 
  Connections 
  Doctoral Consortium 
  EA Submission Guidelines 
  Video Guidelines and Technical Requirements 
  Sensitive Content in Conference Presentations 
  Attend | Registration 
  Getting to Stratford 
  Around Stratford 
  Accommodation 
  Venue 
  Student Volunteer 
  Visa Support Letter 
  Travel Funding 
  Mentoring Event 
  CHI PLAY COVID Policy 
  Code of Conduct 
  Accessibility FAQ 
  Program | Schedule 
  Opening Keynote 
  Banquet Keynote 
  Student Game Design Competition 
  Connections “Amuse-bouche” 
  Proceedings 
  Organizers 
  Sponsoring 
  PACM 
  Blog 
  CHI PLAY Series | 2022 
  2021 
  2020 
  2019 
  2018 
  2017 
  2016 
  2015 
  2014 
  CHI PLAY Steering Committee 
  Calls for Hosting CHI PLAY 2025 and beyond 
    
 Open search bar      
 Search for:  Search for:   Search      Close search bar       

 Home     

 The Annual Symposium on Computer-Human Interaction in Play (CHI PLAY) is the international and interdisciplinary conference (by ACM SIGCHI) for researchers and professionals across all areas of play, games and human-computer interaction (HCI). We call this area “player-computer interaction”.  
 Visit CHI PLAY 2024 in Tampere, Finland    
   
 10-13 October 2023 – Stratford, Canada   
    
    In 2023, CHI PLAY will be hosted at the Stratford School of Interaction Design and Business  , located in Stratford, Ontario Canada, with a hybrid format.  

 CHI PLAY highlights and fosters discussion of current high-quality research in games and human-computer interaction as a foundation for the future of digital play. To this end, the conference blends streams of academic research papers, interactivities, interactive play demos, a student game design competition, a poster session and industry insights.  
 CHI PLAY grew out of the increasing work around games and play emerging from the ACM annual conference on Human Factors in Computing Systems (CHI) as well as smaller conferences such as Fun and Games and Gamification. CHI PLAY is sponsored by the ACM Special Interest Group for Computer-Human Interaction (SIGCHI). All accepted submissions will be distributed in the CHI PLAY Conference Proceedings available in the ACM Digital Library, where they will remain accessible to thousands of researchers and practitioners worldwide.  
 Important Dates  
 (all times are 23:59 Anywhere on Earth or AoE  ):   
  
 Submission Deadline | Notification | Camera-Ready Deadline | Track 
 February 21st, 2023 | July 7th, 2023 | August 10th, 2023 | Full (journal) papers 
 June 22nd, 2023 | August 3rd, 202  3 | August 24th, 202  3 | Work in Progress 
 June 22nd, 2023 | August 3rd, 202  3 | August 24th, 202  3 | Perspectives on Play 
 June 22nd, 2023 | August 3rd, 202  3 | August 24th, 202  3 | Student Game Design Competition 
 June 22nd, 2023 | August 3rd, 202  3 | August 24th, 202  3 | Interactivity 
 June 22nd, 2023 | August 3rd, 202  3 | August 24th, 202  3 | Connections 
 June 22nd, 2023 | August 3rd, 202  3 | August 31st, 202  3 | Doctoral Consortium    (Revised Video) 
 August 6th, 2023 | August 11th, 2023 | — | Student Volunteer application 

 Copyright © 2024 CHI PLAY 2023    
 @acmchiplay 
  Privacy Policy 

 Scroll to top

9. AISC_1 conference:
Please enable cookies.   
 Sorry, you have been blocked  
 You are unable to access  asidevops.com  

 Why have I been blocked?  
 This website is using a security service to protect itself from online attacks. The action you just performed triggered the security solution. There are several actions that could trigger this block including submitting a certain word or phrase, a SQL command or malformed data.  
   
 What can I do to resolve this?  
 You can email the site owner to let them know you were blocked. Please include what you were doing when this page came up and the Cloudflare Ray ID found at the bottom of this page.  

 Cloudflare Ray ID: 8ea885a8fb932101   •  Your IP: Click to reveal  1.54.87.107  •   Performance & security by  Cloudflare

10. OZCHI_3 conference:
QUT Home  Contact    

 Home  Browse  About    
 Login 

 Browse By Publication: OzCHI '23: Proceedings of the 35th Australian Conference on Human-Computer Interaction  
  
 Up a level 

 Export as ASCII Citation  Access and License Indicators  BibTeX  Download and Citation Statistics (CSV)  Dublin Core  EP3 XML  EndNote  JSON-LD  Simple eprint (JSON) | Atom     RSS 1.0     RSS 2.0 
  
  Group by: Authors/Creators  | Volume    
 Jump to: J    
   
 Number of items: 1  .   
  J  
  
 Johansen, Stine   , Senaratne, Hashini  , Burden, Alan   , Mcgrath, Melanie  , Mason, Claire  , Caldwell, Glenda   , Donovan, Jared   , Duenser, Andreas  , Guertler, Matthias  , Howard, David  , Jiang, Yanran  , Paris, Cecile  , Rittenbruch, Markus   ,  & Roberts, Jonathan   (2023) Empowering People in Human-Robot Collaboration: Why, How, When, and for Whom.  In Bowen, Judy  , Pantidi, Nadia  , McKay, Dana  , Ferreira, Jennifer  , Soro, Alessandro  , Blagojevic, Rachel  , et al. (Eds.) OzCHI '23: Proceedings of the 35th Australian Conference on Human-Computer Interaction.  Association for Computing Machinery (ACM), New York, NY, pp. 684-688.   

 This list was generated on Mon Nov 25 20:08:25 2024 AEST  .   

 Home 
  Browse research 
  About 
    
 TEQSA | Provider ID: | PRV12079 | (Australian University) 
  CRICOS | No. 00213J 
  ABN | 83 791 724 622 
  Accessibility 
  Copyright 
  Disclaimer 
  Privacy 
  Right to Information

11. CTW_0 conference:
Skip to main content    

 CTW2023  19th Cologne-Twente Workshop on Graphs and Combinatorial Optimization   

 Navigation  Call for Papers 
  Submissions 
  Program 
  Registration 
  Venue 
  Committees 
  Contact 

 19th Cologne-Twente Workshop on  
  Graphs and Combinatorial Optimization   
 June 20 - 22, 2023, Garmisch-Partenkirchen, Germany   

 Welcome  
   The Cologne-Twente Workshop on Graphs and Combinatorial Optimization 2023 welcomes contributions on theory and applications of discrete algorithms, graphs and combinatorial optimization in the wider sense.  
 The series of Cologne-Twente Workshops on Graphs and Combinatorial Optimization started with meetings organized every two years by the universities of Cologne and Twente. The organizational base was later expanded by other universities. Since 2003 the workshop is held (almost) every year.  
 CTWs are especially intended to let doctoral students and young researchers present the results of their research activities in a friendly and highly interactive atmosphere.  
 Call for Papers  
 PLENARY SPEAKERS:   
  Prof. Peter Gritzmann, TU München  
  Prof. Janny Leung, The University of Macau  
  Prof. Maximilian Moll, Universität der Bundeswehr München   
  Prof. Anne Remke, Universität Münster   
  
 PAPER SUBMISSION   
  There will be two types of submissions:  
  Standard papers  (from 8 to 12 pages) that will be selected for publication in a volume of the AIRO Springer series  .  
  Traditional CTW Extended abstracts  (up to 4 pages) that will be published on the workshop webpage (subject to author’s approval).  
 Please download the call for papers  that can be printed in A4 page format and distributed.  

 The CTW2023 is organized by Research Group  
    
 and  

 Scientific Partners:  

 News  
 24.04.23 - | CTW2023 Registration is open. | https://ctw2023.comtessa.org/registration 
  27.01.23 - | Submission deadline extended to February 19 
  01.12.22 - | Paper Submission is open | Link to EquinOCS 

 Important Dates  
 Standard papers submission: | JANUARY 29, 2023 | FEBRUARY 19, 2023 (extended) 
  Notification of acceptance for standard papers : | APRIL 3, 2023 | APRIL 10, 2023 
  Deadline for Extended abstract submission: | APRIL 16, 2023 | APRIL 23, 2023 
  Notification of acceptance for extended abstracts: | MAY 2, 2023 
  Early Registration deadline: | MAY 16, 2023 
  Workshop dates: | JUNE 20 - 22, 2023 

 Past Conferences  
 Online (planned in Ischia, I), 2020   
  Twente (NL), 2019   
  Paris (F), 2018   
  Cologne (D), 2017   
  Milano (I), 2016   
  Istanbul (TR), 2015   
  Enschede (NL), 2013   
  Munich (D), 2012   
  Frascati (I), 2011   
  Cologne (D), 2010  
  Paris F), 2009   
  Gargnano (I), 2008   
  Enschede (NL), 2007   
  Lambrecht (D), 2006   
  Cologne (D), 2005  
  Menaggio (I), 2004   
  Enschede (NL), 2003   
  Cologne (D), 2001   

 Download CfP  

 Impressum | Datenschutz | Barrierefreiheit   

 © 2024 CTW2023. All Rights Reserved.   

 Design by Zymphonies

12. CHI PLAY_1 conference:
Please enable JavaScript to continue using this application.

13. AISC_2 conference:
Platform | PRODUCTS   
   1st Party 
  3rd Party 
  Boardview 
          USE-CASES   
   Risk Management 
  Compliance Management 
  3rd Party Risk Management 
  Executive Reporting 
  Cyber Insurance Risk Management 
  More 
              STANDARDS   
   NIST CSF 
  NIST 800-171 
  ISO 27001 
  CMMC 
  PCI DSS 
  More 
              INDUSTRIES   
   Financial 
  Insurance 
  Higher Education 
  Energy 
  Retail 
  More 
  Partners | Overview 
  Become a Partner 
    Partner Login 
                      With Centraleyes it feels natural to manage your cyber risk and compliance levels, visualize  
  them and even present them in a live environment 
  Resources | Media 
  Whitepapers 
  News & Updates 
  Feature Reviews 
  On-demand Webinars 
  Blog 
    Cyber Leaders 
  Glossary 
  Questions 
  Guides 
  US Privacy Laws Tracker 
  Global Privacy Laws Tracker 
  About | Our Story 
  Leadership 
  Careers 
  Contact Us 
  Support 
  Secure Africa 

 See it in Action      

 Australasian Conference on Information Security and Privacy  

 Security Conferences 
  Australasian Conference on Information Security and Privacy 

 Location:  Brisbane, Australia   

 Date:  July 5, 2023   

 Venue:  QUT Gardens Point   

 Organizer:  Queensland University of Technology (QUT)   

 ACISP 2023 invites the submission of original papers that present novel research results across various aspects of information security and privacy. The conference eagerly welcomes papers covering theories, techniques, implementations, applications, and practical experiences, encompassing a diverse range of topics. ACISP 2023 aims to foster the exchange of knowledge and exploration of cutting-edge research findings, enabling researchers and practitioners to stay at the forefront of information security and privacy advancements.  

 Sign up for our security event Tracker with monthly updates on upcoming events and conferences  

     Your Email     
 Subscribe      

 For more security events this month  

 July 3, 2023   

 International Conference on Cybersecurity, Situational Awareness, and Social Media   

 The Cyber Science 2023 conference, known as the International Conference on Cybersecurity, Situational Awareness, and Social Media, serves as a...   

 July 3, 2023   

 Pass the SALT 2023   

 The 2023 edition of the conference will feature a collection of 22 high-quality talks, delving into 9 key security topics...   

 July 3, 2023   

 Automotive Cyber Security Workshop (ACSW) 2023   

 The upcoming edition of the Automotive Cyber Security Workshop (ACSW) will be held in collaboration with IEEE EuroS&P 2023, marking...   

 All Events 

 500 7th Avenue New York, NY 10018    

 +1-212-655-3023 
  [email protected] 

 Contact Us      

 PLATFORM   

 1st Party 
  3rd Party 
  Boardview 

 USE CASES   

 Internal Risk  
  Management 
  Compliance  
  Management 
  Vendor Risk  
  Management 
  Executive  
  Reporting 
  More 

 STANDARDS   

 NIST 
  NIST 800-53 
  ISO 27001 
  CMMC 
  PCI 
  More 

 INDUSTRIES   

 Financial 
  Insurance 
  Higher Education 
  Energy 
  Retail 
  More 

 PARTNERS   

 Become a Partner 
  Partner Resources 

 RESOURCES   

 Blog 
  Glossary 
  Q&A 
  US Privacy Laws Tracker 
  Global Privacy Laws Tracker 
  More 

 ABOUT   

 Our Story 
  Leadership 
  Careers 
  Support 
  Secure Africa 

 GUIDES  

 Security Events 
  Vendor Risk Management 
  Compliance Management 
  Compliance Automation 
  NIST CSF 
  More 

     Sign up for our Centraleyes Intelligence Report     
  Please click to confirm your consent to receive our email updates in accordance with GDPR. You can access our privacy policy here       
   
 Submit      

 © Copyright 2024 by Centraleyes Tech Ltd | Privacy Policy    

 Sign up for our Centraleyes  
  Intelligence Report  

     Email     
  Please click to confirm your consent to receive our email updates in accordance with GDPR. You can access our privacy policy here       
   
 Submit      

 500 7th Avenue New York, NY 10018  

 +1-212-655-3023 
  [email protected] 

 Contact Us      

 PLATFORM   

 1st Party 
  3rd Party 
  Boardview 

 STANDARDS   

 NIST 
  NIST 800-53 
  ISO 27001 
  CMMC 
  PCI 
  More 

 INDUSTRIES   

 Financial 
  Insurance 
  Higher Education 
  Energy 
  Retail 
  More 

 USE CASES   

 Internal Risk  
  Management 
  Compliance  
  Management 
  Vendor Risk  
  Management 
  Executive Reporting 
  More 

 ABOUT   

 Our Story 
  Leadership 
  Careers 
  Support 
  Secure Africa 

 RESOURCES   

 Blog 
  Glossary 
  Q&A 
  US Privacy Laws Tracker 
  Global Privacy Laws Tracker 
  More 

 GUIDES  

 Security Events 
  Vendor risk management 
  Compliance management 
  Compliance Automation 
  NIST CSF 
  More 

 PARTNERS   

 Become a partner 
  Partner Resources 

 © Copyright 2024 by Centraleyes Tech Ltd |  Privacy Policy     

 Watch  
  Demo      

 Partner Login      

 Platform     
  1st Party     
 3rd Party     
 Boardview     
 Use Cases Lobby     
  Internal Risk Management     
 Compliance Management     
 Vendor Risk Management     
 Executive Reporting     
 Cyber Insurance Risk Management     
 More      

 Standards     
  NIST CSF     
 NIST 800-171     
 ISO 27001     
 CMMC     
 PCI DDS     
 More      

 Industries     
  Financial     
 Insurance     
 Energy     
 Higher Education     
 Retail     
 More      

 Partners     
  Overview     
 Become a Partner     
 Find a Partner     
 Partner Resources     

 Resources     
  Media     
 Whitepapers     
 News & Updates     
 Feature Reviews     
 On-demand Webinar     
 Blog     
 Cyber Leaders     
 Glossary     
 Questions     
 Guides     
 US Privacy Laws Tracker     
 Global Privacy Laws Tracker     

 About     
  Our Story     
 Leadership     
 Careers     
 Contact Us     
 Support     
 Secure Africa     

 Platform     
  1st Party     
 3rd Party     
 Boardview     
 Use Cases Lobby     
  Internal Risk Management     
 Compliance Management     
 Vendor Risk Management     
 Executive Reporting     
 Cyber Insurance Risk Management     
 More      

 Standards     
  NIST CSF     
 NIST 800-171     
 ISO 27001     
 CMMC     
 PCI DDS     
 More      

 Industries     
  Financial     
 Insurance     
 Energy     
 Higher Education     
 Retail     
 More      

 Partners     
  Overview     
 Become a Partner     
 Find a Partner     
 Partner Resources     

 Resources     
  Media     
 Whitepapers     
 News & Updates     
 Feature Reviews     
 On-demand Webinar     
 Blog     
 Cyber Leaders     
 Glossary     
 Questions     
 Guides     
 US Privacy Laws Tracker     
 Global Privacy Laws Tracker     

 About     
  Our Story     
 Leadership     
 Careers     
 Contact Us     
 Support     
 Secure Africa     

 Try the Centraleyes  
  Risk & Compliance   
 Free for 30 Days  

             Skip to content  Open toolbar  Accessibility Tools       
 Accessibility Tools  
 Increase Text     Increase Text 
  Decrease Text     Decrease Text 
  Grayscale     Grayscale 
  High Contrast     High Contrast 
  Negative Contrast     Negative Contrast 
  Light Background     Light Background 
  Links Underline     Links Underline 
  Readable Font     Readable Font 
  Reset     Reset

14. CTW_1 conference:
Members Only: Update Your Annual Return  | Cast Your Vote  | Virtual Meetings   

 News | IFORS Newsletter 
  IFORS Announcements 
  IFORS Journal Call for Papers | ITOR Call for Papers 
  SAM Journal Call for Papers 
  Call for Papers 
  Conference Announcements 
  About Us | IFORS History 
  What is OR? 
  Message from the President 
  Officers 
  Regional Groupings 
  National Societies 
  Statutes 
  Equity, Diversity & Inclusion 
  Publications | IFORS Newsletter 
  ITOR 
  IAOR 
  Sustainability Analytics and Modeling (SAM) 
  Conference Proceedings 
  Resources | Developing Countries Online Resources | Search for papers relevant to developing countries 
  Submit papers/articles relevant to developing countries 
  Free Software 
  MOOCs – free OR courses 
  Careers 
  OR Practice Survey 
  Member Society Links 
  Conferences | IFORS Triennial 
  IFORS Global Webinar Series 
  ALIO 
  APORS 
  EURO 
  NORAM: CORS 
  NORAM: INFORMS 
  Awards | Distinguished Lecturers 
  Fellows 
  Hall of Fame 
  Prize for OR in Development 
  Tutorial Lecturers 
  Scholarships 
  Contact Us | Comments / Inquiries 
  Application for Membership 

 News | IFORS Newsletter 
  IFORS Announcements 
  IFORS Journal Call for Papers | ITOR Call for Papers 
  SAM Journal Call for Papers 
  Call for Papers 
  Conference Announcements 
  About Us | IFORS History 
  What is OR? 
  Message from the President 
  Officers 
  Regional Groupings 
  National Societies 
  Statutes 
  Equity, Diversity & Inclusion 
  Publications | IFORS Newsletter 
  ITOR 
  IAOR 
  Sustainability Analytics and Modeling (SAM) 
  Conference Proceedings 
  Resources | Developing Countries Online Resources | Search for papers relevant to developing countries 
  Submit papers/articles relevant to developing countries 
  Free Software 
  MOOCs – free OR courses 
  Careers 
  OR Practice Survey 
  Member Society Links 
  Conferences | IFORS Triennial 
  IFORS Global Webinar Series 
  ALIO 
  APORS 
  EURO 
  NORAM: CORS 
  NORAM: INFORMS 
  Awards | Distinguished Lecturers 
  Fellows 
  Hall of Fame 
  Prize for OR in Development 
  Tutorial Lecturers 
  Scholarships 
  Contact Us | Comments / Inquiries 
  Application for Membership 

  January 27, 2023     In Call for Papers     
 Call for Papers: 19th Cologne-Twente Workshop on Graphs and Combinatorial Optimization (CTW2023  
  
 Date:  June 20 – 23, 2023  
  Venue:  Garmisch-Partenkirchen, Germany  
   
  Invited Speakers:   
  • Peter Gritzmann, TU München  
  • Janny Leung, The University of Macau  
  • Maximilian Moll, Universität der Bundeswehr München  
  • Anne Remke, Universität Münster  
 The Cologne-Twente Workshop on Graphs and Combinatorial Optimization 2023 welcomes contributions on theory and applications of discrete  
  algorithms, graphs and combinatorial optimization in the wider sense.  
 The series of Cologne-Twente Workshops on Graphs and Combinatorial Optimization started with meetings organized every two years by the universities of Cologne and Twente. The organizational base was later expanded by other universities. Since 2003 the workshop is held (almost) every year. CTWs are especially intended to let doctoral students and young researchers present the results of their research activities in a friendly and highly interactive atmosphere.  
 There will be two types of submissions:  
  • Standard papers (from 8 to 12 pages) that will be selected for publication in a volume of the AIRO Springer series.  
  • Traditional CTW Extended abstracts (up to 4 pages) that will be published on the workshop webpage (subject to authors’ approval).  
 Important Dates   
  • Standard papers submission (EXTENDED!) : FEBRUARY 19, 2023  
  • Notification of acceptance for standard papers: APRIL 3, 2023  
  • Deadline for Extended abstract submission: APRIL 16, 2023  
  • Notification of acceptance for extended abstracts: MAY 2, 2023  
  • Early Registration deadline: MAY 16, 2023  
  • Workshop dates: JUNE 20 – 23, 2023  
 Program Committee Chairs:   
  • Andreas Brieden (Universität der Bundeswehr München)  
  • Stefan Pickl (Universität der Bundeswehr München)  
  • Markus Siegle (Universität der Bundeswehr München)  
   
  Website:  www.ctw2023.de   

  Previous Story  Call for Papers: Special Issue of International Journal of Supply and Operations Management (IJSOM) on Optimization in Supply Chain, Real Cases Studies    
   
   Next Story  Special Issue: Ensemble AI-Driven Metaheuristic Optimization in OR: Newest Contributions in Theory, Methods, and Applications    

 Related Articles   
 Call for Papers: IFIP Performance 2025 Conference 
  2025 ACM SIGMETRICS: Call for Papers (Fall Deadline) 
  Journal of Dynamics and Games Special Issue at the Occasion of EURO 2024 

 Copyright ©2020 The International Federation of Operational Research Societies. All Rights Reserved.

15. CPM_0 conference:
CPM 2023  
 34 th  Annual Symposium on Combinatorial Pattern Matching  
 Marne-la-Vallée, France, June 26–28, 2023  

 Conference  
 Main page 
  Important dates 
  Keynote speakers 
  Highlights of CPM 
  Programme 
  Committees 
  Call for papers 
  Registration 
  Excursion and Gala Dinner 
  Summer school  
 Summer school 
  Papers and proceedings  
 Accepted papers 
  Proceedings 
  Local information  
 Venue 
  Travel  
 Arrival 
  Accommodation 
  Practicalities 
  Other  
 CPM Archive 
  SafeTOC code of conduct 
    
 Welcome to the website of the 34 th  Annual Symposium on Combinatorial Pattern Matching (CPM 2023) to be held in Marne-la-Vallée, France June 26–28, 2023.  
 Timeline  
 See the | Important dates 
  Paper submissions  
 See the | Call for papers 
  Registration  
 Registration is | open | ! 
  Contact  
 You can reach us by email at contact.cpm.2023[at]gmail.com  .  
 Partners  

 Last updated on 13 th  January 2023  
 Contact: contact.cpm.2023[at]gmail.com

16. CHI PLAY_2 conference:
Please enable cookies.   
 Sorry, you have been blocked  
 You are unable to access  research.com  

 Why have I been blocked?  
 This website is using a security service to protect itself from online attacks. The action you just performed triggered the security solution. There are several actions that could trigger this block including submitting a certain word or phrase, a SQL command or malformed data.  
   
 What can I do to resolve this?  
 You can email the site owner to let them know you were blocked. Please include what you were doing when this page came up and the Cloudflare Ray ID found at the bottom of this page.  

 Cloudflare Ray ID: 8ea885db4f1f4488   •  Your IP: Click to reveal  14.237.32.203  •   Performance & security by  Cloudflare

17. CPM_1 conference:
CPM 2023  
 34 th  Annual Symposium on Combinatorial Pattern Matching  
 Marne-la-Vallée, France, June 26–28, 2023  

 Conference  
 Main page 
  Important dates 
  Keynote speakers 
  Highlights of CPM 
  Programme 
  Committees 
  Call for papers 
  Registration 
  Excursion and Gala Dinner 
  Summer school  
 Summer school 
  Papers and proceedings  
 Accepted papers 
  Proceedings 
  Local information  
 Venue 
  Travel  
 Arrival 
  Accommodation 
  Practicalities 
  Other  
 CPM Archive 
  SafeTOC code of conduct 
    
 Call for papers  
 Papers on original research unpublished elsewhere in all areas related to combinatorial pattern matching and its applications are sought.  
 The proceedings will be published by LIPIcs (of Dagstuhl).  
 Topics of Interest  
 Papers are solicited on, but not limited to, the following topics:  
 Bioinformatics and computational biology 
  Coding and data compression 
  Combinatorics on words 
  Data mining 
  Information retrieval 
  Natural language processing 
  Pattern discovery 
  String algorithms 
  String processing in databases 
  Symbolic computing 
  Text searching and indexing 
  Keynote speakers  
 Olgica Milenkovic (University of Illinois Urbana-Champaign, USA) 
  Tatiana Starikovskaya (École Normale Supérieure, France) 
  Virginia Vassilevska Williams (Massachusetts Institute of Technology, USA) 
  Important dates  
 Submission deadline: January 27, 2023 (AoE) 
  Notification: March 27, 2023 
  Conference: June 26–28, 2023 
  Submission  
 Submission is through the EasyChair conference system, by using the link below. The submission process requires registration to create an EasyChair account prior to submission.  
 Submission format  
 The authors should submit an extended abstract not exceeding 15 single-spaced pages on A4 (or US letter) paper excluding the title page (containing title, authors, affiliations, e-mail addresses, a short abstract, and keywords) and the references. Please note that 15 pages is an upper bound and shorter submissions are more than welcome. The authors are required to use the LaTeX style file supplied by Dagstuhl (LIPIcs). Papers must be submitted as a single file in PDF format.  
 Additional material intended for the referees but not for publication in the final version – for example details of proofs – may be placed in a clearly marked appendix that is not included in the page limit. The program code of experimental papers should be made public, with reasonable documentation, such that the PC may evaluate replicability of experimental results.  
 Papers submitted for review should represent original, previously unpublished work and surveys of important results. At the time the extended abstract is submitted to CPM, and for the entire review period, the paper (or essentially the same paper) should not be under review by any other conference with published proceedings or by a scientific journal.  
 At least one author of an accepted paper is expected to present the paper at the conference as a registered participant. We are planning an in-person event, with online presentations in exceptional cases (e.g., authors with difficulties to travel). Should the pandemic situation change, we will move to hybrid or fully online.  
 Links  
 Submission page: | https://easychair.org/conferences/?conf=cpm2023 
  LIPiCS Latex format: | https://submission.dagstuhl.de/series/details/5#author 

 Last updated on 9 th  February 2023  
 Contact: contact.cpm.2023[at]gmail.com

18. CTW_2 conference:
4TU.   
 Applied Mathematics Institute   

 Home 
  About us | About us 
  Organisation 
  Goals 
  Reports 
  Education | Education projects 
  Blended Learning 
  InterTU Study Days 
  Mathekalender 
  Open Up Math | Open Up Match project 
  Open Up Math project plan 
  Teacher training 
  Pre-university project 
  Research | Research 
  Current projects 
  AMI research groups 
  Collaboration 
  Funding 
  News | News 
  Newsletter 
  Events 
  Contact 
  Account | Profile 

 Part of the 4TU.Federation    
 4TU.   
 Applied Mathematics Institute   

 4TU.   
 Applied Mathematics Institute   

 Home 
  About us | About us 
  Organisation 
  Goals 
  Reports 
  Education | Education projects 
  Blended Learning 
  InterTU Study Days 
  Mathekalender 
  Open Up Math | Open Up Match project 
  Open Up Math project plan 
  Teacher training 
  Pre-university project 
  Research | Research 
  Current projects 
  AMI research groups 
  Collaboration 
  Funding 
  News | News 
  Newsletter 
  Events 
  Contact 

 Close   
   
 4TU.Federation  
 +31(0)6 48 27 55 61  
 secretaris@4tu.nl   
 Website: 4TU.nl    
   
 4TU.Research   
 Applied Mathematics Institute   Built Environment   Design United   Energy   Ethics & Technology   Health   High-Tech Materials   History of Technology   NIRICT (ICT)   Resilience Engineering   ResearchData   HTSF I (high tech research)   HTSF II (high tech research)     
   
 4TU.Education   
 Centre for Engineering Education   4TU.VO (secondary education)   SAI (Engineering Doctorate)   Education programmes     
   
 4TU.Valorisation   
 4TU.IMPACT   Thematic Technology Transfer   Spin-off Stories   4TU Impact Challenge     

 Cologne-Twente Workshop on Graphs and Combinatorial Optimization  
 Tuesday 20 - 22 June 2023   

 All events    

 Cologne-Twente Workshop on Graphs and Combinatorial Optimization 2023  
 Location: Garmisch-Partenkirchen, Germany  
  Date: June 20-23, 2032  
 The Cologne-Twente Workshop on Graphs and Combinatorial Optimization 2023 welcomes contributions on theory and applications of discrete algorithms, graphs and combinatorial optimization in the wider sense.  
 The series of Cologne-Twente Workshops on Graphs and Combinatorial Optimization started with meetings organized every two years by the universities of Cologne and Twente. The organizational base was later expanded by other universities. Since 2003 the workshop is held (almost) every year.  
 CTWs are especially intended to let doctoral students and young researchers present the results of their research activities in a friendly and highly interactive atmosphere.  
 More information  
 For more information and registration, visit the CTW 2023 conference website  .  
   
 Home   Events   Cologne-Twente Workshop on Graphs and Combinatorial Optimization    

 4TU.   
 Applied Mathematics Institute   
   
 Home 
  About us 
  Education 
  Research 
  Collaboration 
  Funding 
  News 
  Events 
  Contact 
   
 Stay up-to-date   
     Thanks for subscribing to our newsletter.   

  Part of the 4TU.Federation    
 Close   
   
  4TU.Research   
 Applied Mathematics Institute   Built Environment   Design United   Energy   Ethics & Technology   Health   High-Tech Materials   History of Technology   NIRICT (ICT)   Resilience Engineering   ResearchData   HTSF I (high tech research)   HTSF II (high tech research)     
   
 4TU.Education   
 Centre for Engineering Education   4TU.VO (secondary education)   SAI (Engineering Doctorate)   Education programmes     
   
 4TU.Valorisation   
 4TU.IMPACT   Thematic Technology Transfer   Spin-off Stories   4TU Impact Challenge     

 © 2024 4TU.Federation

19. CHI PLAY_3 conference:
Event Series    
 Events    
 Academic Fields    

  Discussion    
 View source    
 History    

  Log in    
 Request account    

 CHI PLAY - Annual Symposium on Computer-Human Interaction in Play  
 From ConfIDent   
 Jump to: navigation  , search    

 Event Series    
 Acronym   
 CHI PLAY   
   
 Title   
 Annual Symposium on Computer-Human Interaction in Play   
   
 Recurrence Period   
 1   
   
 Recurrence Unit   
 year   
   
 Academic Field   
 Human Computer Interaction    
   
 DOI   
 https://doi.org/10.25798/krdx-vp13  10.25798/krdx-vp13     

 Related Identifiers   
 DBLP Series ID   
 chiplay     
   
 Wikidata Series ID   
 Q105696537     

 Maintainer   
 Organization   
 Special Interest Group on Computer-Human Interaction, Association for Computing Machinery 

  organization   
 Special Interest Group on Computer-Human Interaction, Association for Computing Machinery    
 Events   

 List   
   
 CHI PLAY 2023   
   
 2023-10-10 → 2023-10-13  

 Human Computer Interaction    

 CHI PLAY 2022   
   
 2022-11-02 → 2022-11-05  

 Human Computer Interaction    

 CHI PLAY 2021   
   
 2021-10-18 → 2021-10-21  

 Human Computer Interaction    

 CHI PLAY 2020   
   
 2020-11-02 → 2020-11-05  

 Human Computer Interaction    

 CHI PLAY 2019   
   
 2019-10-22 → 2019-10-25  

 Human Computer Interaction    

 CHI PLAY 2018   
   
 2018-10-28 → 2018-10-31  

 Human Computer Interaction    

 CHI PLAY 2017   
   
 2017-10-15 → 2017-10-18  

 Human Computer Interaction    

 CHI PLAY 2016   
   
 2016-10-16 → 2016-10-19  

 Human Computer Interaction    

 CHI PLAY 2015   
   
 2015-10-05 → 2015-10-07  

 Human Computer Interaction    

 CHI PLAY 2014   
   
 2014-10-19 → 2014-10-22  

 Human Computer Interaction    

 Retrieved from " https://www.confident-conference.org:443/index.php?title=Event_Series:A0bbc3ab-5c2f-40a1-b4ec-840a1b1bcdd9&oldid=109349  "   
 Cookies help us deliver our services. By using our services, you agree to our use of cookies.    
  More information      OK       

 Category  : Event Series 

 Tools  What links here    
 Related changes    
 Special pages    
 Printable version    
 Permanent link    
 Page information    
 Browse properties    

 This page was last edited on 1 March 2023, at 12:12.   
 Content is available under CC0  unless otherwise noted.   
   
 Privacy policy    
 About ConfIDent    
 Terms of Use    
 Data Protection Info    
 Declaration on Accessibility    
 Imprint    
   
 OpenResearchStack: 0.0.32  Confident: 1.9.11

20. CiE_0 conference:
CiE 2023   
   
 Home 
  Speakers 
  Submissions 
  Program 
  Committees 
  Venue 
  Hotels 
  Gallery 
  Sponsors 
  Registration 
  Contact 

 Computability in Europe 2023  
 Unity of Logic and Computation  
 24-28 July 2023, Batumi, Georgia  

 About CiE 2023  
 The event is the 19th conference organized by CiE (Computability in Europe)  , a European association of mathematicians, logicians, computer scientists, philosophers, physicists and others interested in new developments in computability and their underlying significance for the real world. The conference will be held in hybrid mode.   
 Previous meetings have taken place in Amsterdam (2005), Swansea (2006), Siena (2007), Athens (2008), Heidelberg (2009), Ponta Delgada (2010), Sofia (2011), Cambridge (2012), Milan (2013), Budapest (2014), Bucharest (2015), Paris (2016), Turku (2017), Kiel (2018), Durham (2019), Salerno (2020, virtually), Ghent (2021, virtually), and Swansea (2022).  
   
 Where  
 Batumi Shota Rustaveli State University, Rustaveli str. 32, Batumi, Georgia  
   
 When  
 Monday to Friday  
  24-28 July, 2023  

 Speakers  
 Confirmed Tutorial and Plenary Speakers  
   
  Ludovic Perret   
 Sorbonne University, France  
 Impact of Quantum Computing to Cryptography   

  Ludovic Levy Patey   
 Université Paris Diderot, France  
 Ramsey's theory computes through sparsity   

  Mark Steedman   
 University of Edinburgh, UK  
 Inference in the Time of GPT   

  Andrei Bulatov   
 Simon Fraser University, Canada  
 The Complexity of CSP-Based Ideal Membership Problems   

  Anne Condon   
 The University of British Columbia, Canada  
 Towards more robust schemes for programming molecules   

  Neil Lutz   
 Swarthmore College, USA  
 Applying Algorithmic Dimensions to Classical Problems   

  Stephanie Dick   
 Simon Fraser University, Canada  
 God Has More Disk Space Than We Do   

  Kirsten Eisenträger   
 The Pennsylvania State University, USA  
 Undecidability and undefinability in algebraic extensions of the rationals   

 Submissions  
   
 Conference Topics | The CiE conferences serve as an interdisciplinary forum for research in all aspects of computability, foundations of computer science, logic, and theoretical computer science, as well as the interplay of these areas with practical issues in computer science and with other disciplines such as biology, mathematics, philosophy, or physics. 
  Paper Submission | THE PROGRAM COMMITTEE cordially invites all researchers, European and non-European, to submit their papers in all areas related to the above for presentation at the conference and inclusion in the proceedings of CiE 2023 at EasyChair  .  
 Papers submitted to the conference proceedings should represent original work, not simultaneously submitted to another journal or conference with formal proceedings. The Program Committee will rigorously review and select submitted papers. Accepted papers will be published as a proceedings volume in the Lecture Notes in Computer Science (LNCS) series from Springer-Verlag.  
 Papers to be considered in the conferences proceedings must be submitted in PDF format, using the LNCS style (see Springer conference proceedings guidelines  ) and must have a maximum of 12 pages, including references but excluding a possible appendix in which one can include proofs and other additional material. Papers building bridges between different parts of the research community are particularly welcome. 
  Informal Presentations | Continuing the tradition of past CiE conferences, we invite researchers to present informal presentations of their recent work. A proposal for an informal presentation must be submitted via EasyChair  , using the LNCS style (see Springer conference proceedings guidelines  ), and be 1 page long; a brief description of the results suffices and an abstract is not required. Informal presentations will not be published in the LNCS conference proceedings. Results presented as informal presentations at CiE 2023 may appear or may have appeared in other conferences with formal proceedings and/or in journals. 
  Important Dates | Article submission deadline: | February 15, 2023 | (AoE) 
  Author notification: | April 20, 2023 
  Camera-ready due: | May 1, 2023 
  Informal presentations deadline: | June 8, 2023 | (acceptance notifications will be sent a few days after submission) 
  Early registration deadline: | June 18, 2023 

 Travel Grants  
 Application for travel grants is overdue.  
   
 Women in Computability | We are happy to announce that within the framework of the Women in Computability program, we are able to offer some grants for junior women researchers who want to participate in CiE 2023. Applications for this grant should be sent to Liesbeth de Mol, liesbeth.de-mol@univ-lille.fr  , before May 15, 2023  and include a short cv (at most 2 pages) and contact information for an academic reference. Preference will be given to junior women researchers who are presenting a paper (including informal presentations) at CiE 2023. 
  ASL Student Travel Award | We are happy to announce that the Association for Symbolic Logic (ASL) is offering Student Travel Awards  for ASL members  who want to participate in CiE 2023. Applications for this award should be submitted to the ASL office before April 24, 2023  . For more details, please consult the Student Travel Awards page  or contact Shannon Miller, the ASL administrator, at asl@uconn.edu  . 

 Program  
 The conference proceedings are officially available since July 18, 2023.  
 The participants can have free access until August 20, 2023  to the proceedings via the link: https://link.springer.com/book/10.1007/978-3-031-36978-0   
   
 Accepted Papers | Merlin Carl | . | All Melodies are Lost -- Recognizability for weak and strong α-ITRMs 
  Victor Selivanov | . | Extending Wagner's hierarchy to Deterministic Visibly Pushdown Automata 
  Alexey Milovanov | . | Some Games on Turing Machines and Power from Random Strings 
  Alexey Barsukov | and | Florent Madelaine | . | On guarded extensions of MMSNP 
  Alexander Shen | . | Inequalities for entropies and dimensions 
  Guohua Wu | and | Hong Hanh Tran | . | Cupping computably enumerable degrees simultaneously 
  Zeev Nutov | . | An O(√k)-approximation algorithm for minimum power k edge disjoint st-paths 
  Ivan Georgiev | . | Subrecursive Graphs of Representations of Irrational Numbers 
  Russell Miller | . | A directed system of Scott ideals 
  Lorenzo Galeotti | , | Ethan Lewis | and | Benedikt Loewe | . | Symmetry for transfinite computability 
  Suthee Ruangwises | . | Physical Zero-Knowledge Proof for Ball Sort Puzzle 
  Daniil Musatov | and | Georgii Potapov | . | Structural Complexity of Rational Interactive Proofs 
  Keita Hiroshima | and | Akitoshi Kawamura | . | Elementarily traceable irrational numbers 
  Vladislav Orekhovskii | and | Victor Selivanov | . | Logic vs topology on regular ω-languages 
  Pablo Arrighi | , | Amélia Durbec | and | Pierre Guillon | . | Graph subshifts 
  Takayuki Kihara | and | Arno Pauly | . | The de Groot dual of represented spaces 
  Gabriele Buriola | , | Peter Schuster | and | Ingo Blechschmidt | . | A Constructive Picture of Noetherianity and Well Quasi-Orders. 
  Sam Sanders | . | The non-normal abyss in Kleene's computability theory 
  Pacôme Perrotin | and | Sylvain Sené | . | Turning block-sequential automata networks into smaller parallel networks with isomorphic limit dynamics 
  Vittorio Cipriani | and | Arno Pauly | . | The Weihrauch complexity of the supergraph problem 
  Paweł Parys | and | Aleksander Wiącek | . | Improved Complexity Analysis of Quasi-Polynomial Algorithms Solving Parity Games 
  Informal Presentations | Zhansaya Tleuliyeva | . | Rogers Semilattice of Limitwise Monotonic Numberings 
  Djamel Eddine Amir | and | Mathieu Hoyrup | . | Products do not preserve computable type 
  Juvenal Murwanashyaka | . | On a First-Order Theory of Building Blocks and its Relation to Arithmetic and Set Theory 
  Konstantinos Papafilippou | . | An expressively complete tangle operator for the topological μ-calculus 
  Lars Kristiansen | . | On a Lattice of Degrees of Representations of Irrational Numbers 
  Arno Pauly | and | Sam Ruggles | . | The Lebesgue Universal Covering Problem is computable 
  Elvira Mayordomo | . | A point to set principle for finite-state dimension 
  Giovanni Soldà | . | A version of the minimax theorem in reverse mathematics 
  Alexander Shekhovtsov | and | Georgii Zakharov | . | Kolmogorov Complexity of Infinite Sets 
  Suthee Ruangwises | . | The Landscape of Computing Symmetric n-Variable Functions with 2n Cards 
  Minha Lee | , | Soyeon Jeong | and | Seongbin Park | . | On hypotheses under which P = NP 
  Gabriel Istrate | . | Efficient (Propositional) Proofs of Statements in Combinatorial Topology and Related Areas 
  Tomoyuki Yamakami | . | Complexity Classification of Complex-Weighted Counting Acyclic Constraint Satisfaction Problems 
  Jiale Chen | , | Dima Grigoriev | and | Vladimir Shpilrain | . | Digital signature schemes using non-square matrices or scrap automorphisms 
  Special Sessions | Classical Theories of Degrees   ( organizers  : Keng Meng Ng, Andrea Sorbi)  
 Klaus Ambos-Spies | . | Multiple Permitting Notions For The Not Totally ω-C.A. Computably Enumerable Degrees 
  Wu Guohua | . | Simultaneous cupping and continuity in bounded Turing degrees 
  Iskander Kalimullin | . | Primitive recursive degree spectra of structures 
  Mariya Soskova | . | The relationship between local and global structure in the enumeration degrees 
   
 Computational Sciences   ( organizers  : Jonathan Gryak, V Anne Smith)  
 Franziska Matthäus | . | Understanding Collective Phenomena in Multicellular Systems through Agent-based Models 
  Jon Paul Janet | . | Accelerating Drug Design with AI & Simulation 
  Karianne Bergen | . | Earthquake monitoring, Deep Learning and Explainable AI 
  Arjen Hommersom | . | Learning Temporal Bayesian Networks for Understanding Effects of Health Interventions 
   
 Proof Theory   ( organizers  : Anupam Das, Gilda Ferreira)  
 Sam Sanders | . | Exploring the abyss in Reverse Mathematics and Computability theory 
  Emil Jeřábek | . | Disjunction-free disjunction property 
  Marie Kerjean | . | Gödel's Dialectica transformation is reverse differentiation 
  Willem Heijltjes | . | Willem's Adventures in Curry-Howard Land 
   
 Scalable Computational Genomics   ( organizers  : Giovanna Rosone, Alexandru Tomescu)  
 Camille Marchet | . | Hashing-based data-structures for querying large k-mer (collections of) sets 
  Jasmijn Baaijens | . | AmpliVar: an Optimized Amplicon Sequencing Approach to Estimating Lineage Abundances in Viral Metagenomes 
  Erik Garrison | . | Building and understanding the human pangenome 
  Chirag Jain | . | Revisiting Graph-theoretic Models for Genome Assembly in the Era of Long Reads 
   
 Weihrauch Complexity  ( organizers  : Damir Dzhafarov, Arno Pauly)  
 Manlio Valenti | . | Is there a jump in the Weihrauch lattice? 
  Tonicha Crook | . | Exploring the Non-Computability of Machine Learning Classifiers 
  Vasco Brattka | . | On the complexity of learning programs 
  Andrej Bauer | . | Variations on Weihrauch degrees 
  Poster Session: Logic and Computability in Georgia | Besik Dundua | . | PpLog: Logic Programming, Rules, and Strategies 
  Anriette Bishara | , | Lia Kurtanidze | , | Mikheil Rukhaia | and | Lali Tibua | . | Unranked Probabilistic Logic 
  Temur Kutsia | , | Mircea Marin | and | Mikheil Rukhaia | . | Tolerance-Based Techniques for Approximate Reasoning 
  Tentative Schedule | Times / Days | Monday, July 24 | Tuesday, July 25 | Wednesday, July 26 | Thursday, July 27 | Friday, July 28 
 09:00-09:30 | registration/coffee | Levy Patey 2 slides | Levy Patey 3 slides | Bulatov slides | Lutz 
 09:30-10:00 | opening 
 10:00-10:30 | Levy Patey 1 slides | coffee break | Barry Cooper prize announcement / coffee break | coffee break | coffee break 
 10:30-11:00 | special sessions  
  D: Kalimullin slides  / Wu slides   
  G: Garrison/Baaijens | special session  
  P: Sanders slides  / Kerjean slides | special sessions  
  C: Hommersom/Janet  
  W: Valenti slides  / Brattka slides | contributed talks 
 11:00-11:30 | Perret 1 slides 
 11:30-12:00 
 12:00-12:30 | lunch | lunch | lunch | lunch | lunch 
 12:30-13:00 
 13:00-13:30 
 13:30-14:00 | contributed talks /  
  Poster Session | Perret 2 slides | Perret 3 slides | Steedman 
 14:00-14:30 | excursion to Batumi botanical garden and Makhuntseti waterfall 
 14:30-15:00 | contributed talks | special session  
  P: Jeřábek slides  /Heijltjes | contributed talks 
 15:00-15:30 | coffee break 
 15:30-16:00 | special sessions  
  D: Soskova / Ambos-Spies slides   
  G: Marchet slides  / Jain slides | coffee break | coffee break 
 16:00-16:30 | contributed talks | coffee break | special sessions  
  C: Matthäus slides  / Bergen  
  W: Bauer slides  / Crook 
 16:30-17:00 | Eisenträger slides 
 17:00-17:30 | Condon slides | Dick 
 17:30-18:00 | ACiE | closing 
 18:00-18:30 | Welcome Party | WiC |  
 18:30-19:00 |  
 19:00-19:30 | Dinner |  
 19:30-20:00 |  
 20:00-20:30 |  
 20:30-21:00 |  

 Color code | tutorial | plenary talks | special sessions | contributed talks | social/administrative 
 Special sessions | C = computational sciences | D = degree theory | G = scalable genomics | P = proof theory | W = Weihrauch degrees 
  Contributed Talk Schedule | Day | Time | Room 1 | Room 2 | Room 3 
 Monday,  
  July 24 | 13:30-14:00 | Merlin Carl  
  All Melodies are Lost -- Recognizability for weak and strong α-ITRMs | Alexey Milovanov  
  Some Games on Turing Machines and Power from Random Strings   
  slides | Suthee Ruangwises  
  Physical Zero-Knowledge Proof for Ball Sort Puzzle   
  slides 
 14:00-14:30 | Lorenzo Galeotti, Ethan Lewis and Benedikt Loewe  
  Symmetry for transfinite computability | Djamel Eddine Amir and Mathieu Hoyrup  
  Products do not preserve computable type | Suthee Ruangwises  
  The Landscape of Computing Symmetric n-Variable Functions with 2n Cards   
  slides 
 14:30-15:00 | Poster Session    
  poster 1  poster 2  poster 3 | Alexander Shen  
  Inequalities for entropies and dimensions   
  slides | Jiale Chen, Dima Grigoriev and Vladimir Shpilrain  
  Digital signature schemes using non-square matrices or scrap automorphisms   
  slides 
 Tuesday,  
  July 25 | 14:30-15:00 | Zhansaya Tleuliyeva  
  Rogers Semilattice of Limitwise Monotonic Numberings   
  slides | Alexander Shekhovtsov and Georgii Zakharov  
  Kolmogorov Complexity of Infinite Sets | Ivan Georgiev  
  Subrecursive Graphs of Representations of Irrational Numbers   
  slides 
 15:00-15:30 | Elvira Mayordomo  
  A point to set principle for finite-state dimension   
  slides | Daniil Musatov and Georgii Potapov  
  Structural Complexity of Rational Interactive Proofs   
  slides | Pablo Arrighi, Amélia Durbec and Pierre Guillon  
  Graph subshifts 
 16:00-16:30 | Vittorio Cipriani and Arno Pauly  
  The Weihrauch complexity of the supergraph problem   
  slides | Paweł Parys and Aleksander Wiącek  
  Improved Complexity Analysis of Quasi-Polynomial Algorithms Solving Parity Games   
  slides  video | Victor Selivanov  
  Extending Wagner's hierarchy to Deterministic Visibly Pushdown Automata   
  slides 
 16:30-17:00 | Russell Miller  
  A directed system of Scott ideals   
  slides | Zeev Nutov  
  An O(√k)-approximation algorithm for minimum power k edge disjoint st-paths   
  slides | Alexey Barsukov and Florent Madelaine  
  On guarded extensions of MMSNP   
  slides 
 Friday,  
  July 28 | 10:30-11:00 | Juvenal Murwanashyaka  
  On a First-Order Theory of Building Blocks and its Relation to Arithmetic and Set Theory   
  slides | Giovanni Soldà  
  A version of the minimax theorem in reverse mathematics | Gabriel Istrate  
  Efficient (Propositional) Proofs of Statements in Combinatorial Topology and Related Areas   
  slides 
 11:00-11:30 | Takayuki Kihara and Arno Pauly  
  The de Groot dual of represented spaces | Keita Hiroshima and Akitoshi Kawamura  
  Elementarily traceable irrational numbers | Tomoyuki Yamakami  
  Complexity Classification of Complex-Weighted Counting Acyclic Constraint Satisfaction Problems   
  slides 
 11:30-12:00 | Arno Pauly and Sam Ruggles  
  The Lebesgue Universal Covering Problem is computable | Gabriele Buriola, Peter Schuster and Ingo Blechschmidt  
  A Constructive Picture of Noetherianity and Well Quasi-Orders.   
  slides | Minha Lee, Soyeon Jeong and Seongbin Park  
  On hypotheses under which P = NP   
  slides 
 14:30-15:00 | Konstantinos Papafilippou  
  An expressively complete tangle operator for the topological μ-calculus | Sam Sanders  
  The non-normal abyss in Kleene's computability theory   
  slides | Vladislav Orekhovskii and Victor Selivanov  
  Logic vs topology on regular ω-languages 
 15:00-15:30 | Lars Kristiansen  
  On a Lattice of Degrees of Representations of Irrational Numbers   
  slides | Guohua Wu and Hong Hanh Tran  
  Cupping computably enumerable degrees simultaneously   
  slides | Pacôme Perrotin and Sylvain Sené  
  Turning block-sequential automata networks into smaller parallel networks with isomorphic limit dynamics   
  slides 

 Committees  
   
 PC Chairs | Gianluca Della Vedova, The University of Milano-Bicocca, Italy 
  Steffen Lempp, University of Wisconsin-Madison, USA 
  Program Committee | Nikolay Bazhenov, Novosibirsk State University, Russia 
  Manuel Bodirsky, TU Dresden, Germany 
  Vasco Brattka, University of the Bundeswehr Munich, Germany 
  Liesbeth De Mol, University of Lille, France 
  Besik Dundua, Kutaisi International University, Georgia 
  Juan Luis Gastaldi, ETH Zurich, Switzerland 
  Thomas Graf, Stony Brook, USA 
  Delaram Kahrobaei, New York University, USA 
  Ekaterina Komendantskaya, Heriot-Watt University, UK 
  Angeliki Koutsoukou-Argyraki, University of Cambridge, UK 
  Florin Manea, The University of Göttingen, Germany 
  Klaus Meer, Brandenburgische Technische Universität Cottbus – Senftenberg, Germany 
  Isabel Oitavem, NOVA University Lisbon, Portugal 
  Roland Omanadze, Tbilisi State University, Georgia 
  Daniel Paulusma, Durham University, UK 
  Elaine Pimentel, University College London, UK 
  Markus Schmid, Humboldt University of Berlin, Germany 
  Shinnosuke Seki, The University of Electro-Communications, Japan 
  Sebastiaan Terwijn, Radboud University Nijmegen, Netherlands 
  Dan Turetsky, Victoria University of Wellington, New Zealand 
  Linda Westrick, The Pennsylvania State University, USA 
  Organizing Committee | Anzor Beridze, Batumi Shota Rustaveli State University, Georgia 
  Mikheil Donadze, Batumi Shota Rustaveli State University, Georgia 
  Besik Dundua (chair), Kutaisi International University and Institute of Applied Mathematics, Tbilisi State University, Georgia 
  Mikheil Rukhaia (co-chair), Institute of Applied Mathematics, Tbilisi State University, Georgia 
  Lela Turmanidze, Batumi Shota Rustaveli State University, Georgia 
  Student Volunteers | Giorgi Bakradze, Kutaisi International University, Georgia 
  Nino Bolkvadze, Tbilisi State University, Georgia 
  Tatia Dundua, Tbilisi State University, Georgia 
  Tsotne Mikadze, Kutaisi International University, Georgia 
  Alexander Oniani, Kutaisi International University, Georgia 

 Venue  
 Conference venue is located in the Batumi city center. The conference will be held in hybrid mode.   

 Batumi Shota Rustaveli State University  
 Rustaveli str. 32, Batumi, Georgia  

 Hotels  
 Scam emails warning:  with our past experience, sometimes conference participants are receiving emails (sent e.g. from "support@ehotelservices.org" or "ops@travellerpoint.org"), offering the booking of hotel accomodation for conference dates. This is a scam!  You will find some unpleasant stories  about such companies if you google their name. Be careful  - the company name and email can change while the phishing method stays the same.  
 We do not have arrangements with hotels or agencies other than is listed below and these hotels do not ask credit card information!   

 Era Palace Hotel   
       
 1 KM from the Venue (10-15 minutes walking)  
 Special offer  
 Double/twin room with breakfast - 230 GEL   
  Triple room with breakfast - 250 GEL   
  Family room with breakfast - 280 GEL   
 To reserve a room, please send details to erapalace@gmail.com  with subject "CiE 2023 reservation".  

 Hotel Chao   
      
 1 KM from the Venue (10-15 minutes walking)  
 Special offer  
 Double/twin room with breakfast - 195 GEL   
  Triple room with breakfast - 235 GEL   
 To reserve a room, please send details to info@hotelchao.ge  with subject "CiE 2023 reservation".  

 Hilton Batumi   
        
 50 Meters from the Venue  
 We do not have special arrangements for this hotel, but we are listing it here because it is right next to the venue  .  
 There are some other well-known brand hotels in Batumi, like Sheraton   , Radisson Blu   , Best Western   , Wyndham   , Le Meridien   , etc.  

 Gallery  
 Some pictures from excursion  

 Sponsors  

 Registration  
 Please note that the Early registration deadline is June 18, 2023  (included) and the Late registration deadline is July 10, 2023  (included)  
 Online participation registration deadline is extended to July 20, 2023  (included)  

 At least one author of accepted paper should register with regular/student fee.   

 Refund policy:   
  no refund of online participation fee.  
  Regular/Student registration is eligible for a refund with a 50 Euro cancellation fee, which includes online participation fee (i.e. person will receive a conference sessions link to attend online).  
  Refund will be possible for requests received until July 10, 2023 (included).  
  No refund is possible for requests received after July 10, 2023.   
   
 Online Participation  
 20 EUR  
  Online access link to conference sessions 
   Register on EasyChair     

 Student Early/Late  
 100/150 EUR  
  Onsite Participation 
  Conference Materials 
  Coffee Breaks 
   Register on EasyChair     

 Regular Early/Late  
 200/250 EUR  
  Onsite Participation 
  Conference Materials 
  Coffee Breaks 
   Register on EasyChair     

 Social Events Early/Late  
 100/150 EUR  
  Excursion 
  Conference Dinner 
  This ticket can be bought as an add-on to regular registration, or separately for accompanying persons 
   Register on EasyChair     

 Contact Us  
   
  Address  
 Institute of Applied Mathematics, Tbilisi State University  
  University str. 11, 0186 Tbilisi, Georgia    
   
  Phone Number  
 +995 555 373 216   

  Email  
 cie2023@acie.eu   

 © Created by Mikheil Rukhaia  . All Rights Reserved. Website Designed by BootstrapMade

21. CPM_2 conference:
CPM 2023  
 34 th  Annual Symposium on Combinatorial Pattern Matching  
 Marne-la-Vallée, France, June 26–28, 2023  

 Conference  
 Main page 
  Important dates 
  Keynote speakers 
  Highlights of CPM 
  Programme 
  Committees 
  Call for papers 
  Registration 
  Excursion and Gala Dinner 
  Summer school  
 Summer school 
  Papers and proceedings  
 Accepted papers 
  Proceedings 
  Local information  
 Venue 
  Travel  
 Arrival 
  Accommodation 
  Practicalities 
  Other  
 CPM Archive 
  SafeTOC code of conduct 
    
 Programme  
 Skip to day: Monday 
  Tuesday 
  Wednesday 
    
 PDF version    
 Monday, June 26, 2023  
  
 08:50 - 09:00 | Opening remarks 
 Keynote Talk 1  (Chair: Zsuzsanna Lipták) 
 09:00 - 10:00 | Olgica Milenkovic  
 Load Balancing for Distributed Storage Codes with Dynamically Changing File Popularities 
 10:00 - 10:20 | Break 
 Session 1  (Chair: Gonzalo Navarro) 
 10:20 - 10:45 | Grigorios Loukides, Solon Pissis, Sharma V. Thankachan and Wiktor Zuba  
 Suffix-Prefix Queries on a Dictionary Paper #21 
 10:45 - 11:10 | Pawel Gawrychowski, Garance Gourdel, Tatiana Starikovskaya and Teresa Anna Steiner  
 Compressed Indexing for Consecutive Occurrences Paper #12 
 11:10 - 11:35 | Philip Bille, Johannes Fischer, Inge Li Gørtz, Max Rishøj Pedersen and Tord Joakim Stordalen  
 Sliding Window String Indexing in Streams (Best student paper)  Paper #4 
 11:35 - 12:00 | Shinya Nagashita and Tomohiro I  
 PalFM-index: FM-index for Palindrome Pattern Matching Paper #23 
 12:00 - 13:30 | Lunch 
 Session 2  (Chair: Golnaz Badkobeh) 
 13:30 - 14:00 | Zachary Chase  
 Separating words and trace reconstruction (Highlight Talk 1) 
 14:00 - 14:25 | Estéban Gabory, Moses Njagi Mwaniki, Nadia Pisanti, Solon Pissis, Jakub Radoszewski, Michelle Sweering and Wiktor Zuba  
 Comparing Elastic-Degenerate Strings: Algorithms, Lower Bounds, and Applications Paper #11 
 14:25 - 14:50 | Sung-Hwan Kim, Francisco Olivares and Nicola Prezza  
 Faster Prefix-Sorting Algorithms for Deterministic Finite Automata Paper #16 
 14:50 - 15:20 | Break 
 Session 3  (Chair: Marinella Sciortino) 
 15:20 - 15:45 | Pawel Gawrychowski, Samah Ghazawi and Gad M. Landau  
 Order-Preserving Squares in Strings Paper #13 
 15:45 - 16:10 | Costas Iliopoulos, Tomasz Kociumaka, Jakub Radoszewski, Wojciech Rytter, Tomasz Waleń and Wiktor Zuba  
 Linear Time Computation of Cyclic Roots and Cyclic Covers of a String Paper #15 
 16:10 - 16:35 | Manuel Cáceres  
 Parameterized Algorithms for String Matching to DAGs: Funnels and Beyond (Best paper)  Paper #7 
 16:35 - 17:00 | Aaron Boussidan, Pierre Bourhis and Philippe Gambette  
 On Distances between Words with Parameters Paper #6 
 17:00 - 17:20 | Break 
 17:20 - 18:10 | Business meeting 
  
 Back to top    
   
 Tuesday, June 27, 2023  
  
 Keynote Talk 2  (Chair: Laurent Bulteau) 
 09:00 - 10:00 | Tatiana Starikovskaya  
 Approximate membership in formal languages 
 10:00 - 10:20 | Break 
 Session 4  (Chair: Yuto Nakashima) 
 10:20 - 10:45 | Gonzalo Navarro  
 Computing MEMs on Repetitive Text Collections Paper #24 
 10:45 - 11:10 | Igor Tatarnikov, Ardavan Shahrabi Farahani, Sana Kashgouli and Travis Gagie  
 MONI can find k  -MEMs Paper #26 
 11:10 - 11:35 | Dominik Köppl  
 Encoding Hard String Problems with Answer Set Programming Paper #17 
 11:35 - 12:00 | Massimo Equi, Arianne Meijer van de Griend and Veli Mäkinen  
 From Bit-Parallelism to Quantum String Matching for Labelled Graphs Paper #9 
 12:00 - 13:30 | Lunch 
 Session 5  (Chair: Hideo Bannai) 
 13:30 - 14:00 | Zoe Xi and William Kuszmaul  
 Approximating Dynamic Time Warping Distance Between Run-Length Encoded Strings (Highlight Talk 2) 
 14:00 - 14:25 | Yuichi Asahiro, Hiroshi Eto, Mingyang Gong, Jesper Jansson, Guohui Lin, Eiji Miyano, Hirotaka Ono and Shunichi Tanaka  
 Approximation Algorithms for the Longest Run Subsequence Problem Paper #2 
 14:25 - 14:50 | Matan Kraus, Moshe Lewenstein, Alexandru Popa, Ely Porat and Yonathan Sadia  
 String Factorization via Prefix Free Families Paper #19 
 15:00 | Excursion and conference dinner 
  
 Back to top    
   
 Wednesday, June 28, 2023  
  
 Keynote Talk 3  (Chair: Inge Li Gørtz) 
 09:00 - 10:00 | Virginia Vassilevska Williams  
 Fredman’s Trick Meets Dominance Product: counting and detection equivalences and more 
 10:00 - 10:20 | Break 
 Session 6  (Chair: Avivit Levy) 
 10:20 - 10:45 | Christopher Hampson, Daniel J. Harvey, Costas S. Iliopoulos, Jesper Jansson, Zara Lim and Wing-Kin Sung  
 MUL-Tree Pruning for Consistency and Compatibility Paper #14 
 10:45 - 11:10 | Christian Komusiewicz, Simone Linz, Nils Morawietz and Jannik Schestag  
 On the Complexity of Parameterized Local Search for the Maximum Parsimony Problem Paper #18 
 11:10 - 11:35 | Itai Boneh, Dvir Fried, Adrian Miclăuș and Alexandru Popa  
 Faster algorithms for computing the hairpin completion distance and minimum ancestor Paper #5 
 11:35 - 12:00 | Panagiotis Charalampopoulos, Bartlomiej Dudek, Pawel Gawrychowski and Karol Pokorski  
 Optimal Heaviest Induced Ancestors Paper #8 
 12:00 - 13:30 | Lunch 
 Session 7  (Chair: Pawel Gawrychowski) 
 13:30 - 13:55 | Eugene Myers  
 Merging Sorted Lists of Similar Strings Paper #22 
 13:55 - 14:20 | Gregory Kucherov and Steven Skiena  
 Improving the Sensitivity of MinHash Through Hash-Value Analysis Paper #20 
 14:20 - 14:45 | Diego Arroyuelo and Juan Pablo Castillo  
 Trie-Compressed Adaptive Set Intersection Paper #1 
 14:45 - 15:15 | Break 
 Session 8  (Chair: Marie-Pierre Béal) 
 15:15 - 15:40 | Gabriele Fici, Giuseppe Romana, Marinella Sciortino and Cristian Urbina  
 On the impact of morphisms on BWT-runs Paper #10 
 15:40 - 16:05 | Gonzalo Navarro and Cristian Urbina  
 L-systems for measuring repetitiveness Paper #25 
 16:05 - 16:30 | Hideo Bannai, Mitsuru Funakoshi, Kazuhiro Kurita, Yuto Nakashima, Kazuhisa Seto and Takeaki Uno  
 Optimal LZ-End Parsing is Hard Paper #3 
 16:30 - 16:40 | Closing remarks 
  
 Back to top    

 Last updated on 10 th  May 2023  
 Contact: contact.cpm.2023[at]gmail.com

22. CTW_3 conference:
Skip to main content    

 CTW2023  19th Cologne-Twente Workshop on Graphs and Combinatorial Optimization   

 Navigation  Call for Papers 
  Submissions 
  Program 
  Registration 
  Venue 
  Committees 
  Contact 

 You are here  
 Home  » Registration  
   
 Registration  
   Registration is closed.  

 Tickets | Price EUR 
 CTW 2023 Full Package   
  In Full Package is included Conference Fee 
  Conference Dinner 
  Social Event 
  Meals | 440 
 CTW 2023 Full Package Early Bird   
  Early Bird is valid until 16. May 2023 | 380 
 Student Rate   
  (available upon approval from the organisers) | 220 

 Payments can be made by bank transfer or PayPal.  
 Students will be asked for a copy of their student ID as proof.  

 News  
 24.04.23 - | CTW2023 Registration is open. | https://ctw2023.comtessa.org/registration 
  27.01.23 - | Submission deadline extended to February 19 
  01.12.22 - | Paper Submission is open | Link to EquinOCS 

 Important Dates  
 Standard papers submission: | JANUARY 29, 2023 | FEBRUARY 19, 2023 (extended) 
  Notification of acceptance for standard papers : | APRIL 3, 2023 | APRIL 10, 2023 
  Deadline for Extended abstract submission: | APRIL 16, 2023 | APRIL 23, 2023 
  Notification of acceptance for extended abstracts: | MAY 2, 2023 
  Early Registration deadline: | MAY 16, 2023 
  Workshop dates: | JUNE 20 - 22, 2023 

 Download CfP  

 Impressum | Datenschutz | Barrierefreiheit   

 © 2024 CTW2023. All Rights Reserved.   

 Design by Zymphonies

23. CAV_0 conference:
CAV 2023   
 35th International Conference on Computer Aided Verification  

 Menu  
 Skip to content  Home 
  Attending 
  Organisation 
  Keynotes 
  Proceedings 
  Program 
  Workshops | Mentoring 
  Accepted Papers 
  CAV Award 
  Call for Papers 
  Artifact Evaluation 

   35th International Conference on Computer Aided Verification  
 Paris, France   
 July 17th-22nd, 2023  . The first two days (July 17th-18th) will be dedicated to affiliated workshops.  
 Keynote recordings   
 CAV 2023 is the 35th in a series dedicated to the advancement of the theory and practice of computer-aided formal analysis methods for hardware and software systems. The conference covers the spectrum from theoretical results to concrete applications, with an emphasis on practical verification tools and the algorithms and techniques that are needed for their implementation. CAV considers it vital to continue spurring advances in hardware and software verification while expanding to new domains such as machine learning, autonomous systems, and computer security.  
 Submission site  
 The submission site is https://cav23.hotcrp.com   
 Keynotes  
     
 Analogical Reasoning Engines: Flash Fill vs GPT-4    
 Sumit Gulwani   , Microsoft Research  

 Privacy-preserving Automated Reasoning    
 Ruzica Piskac   , Yale University  

 Verified Software Security Down to Gates    
 Caroline Trippel   , Stanford University  

 Venue  
 CAV 2023 will be held in Paris. The conference will take place in Maison de la Chimie  at the heart of Paris. The venue is easily accessible by public transport from all parts of the city.  

 Sponsors    

 Platinum sponsors  

 Gold sponsors  

 Silver sponsors  

 Bronze sponsors  

 Institutional support  

 Proudly powered by WordPress  |  Theme: Expound by Konstantin Kovshenin

24. CPM_3 conference:
Skip to content      
   
 models and algorithms: from the discrete to the continuous    
   
 Home 
  Presentation | Access and contacts 
  Members 
  Academic environment 
  Highlights 
  Organization 
  Bézout Research Federation 
  Bézout SFRI Graduate Program 
  Research | Research areas | Overview 
  Images and geometry 
  High-dimensional phenomena 
  Discrete mathematics and algorithms 
  Stochastic and deterministic models 
  Smart cities 
  Invited professors 
  Post-doctoral positions 
  Conferences 
  Seminars 
  Working groups 
  Publications 
  Education | Master’s scholarships 
  PhD positions 
  Math+CS master’s track 
  Alumni 
  Testimonials 

 Search | Search     Search … 

 models and algorithms: from the discrete to the continuous    
 Search | Search     Search … | Search     Search … 
  Menu 

 Home 
  Presentation | Access and contacts 
  Members 
  Academic environment 
  Highlights 
  Organization 
  Bézout Research Federation 
  Bézout SFRI Graduate Program 
  Research | Research areas | Overview 
  Images and geometry 
  High-dimensional phenomena 
  Discrete mathematics and algorithms 
  Stochastic and deterministic models 
  Smart cities 
  Invited professors 
  Post-doctoral positions 
  Conferences 
  Seminars 
  Working groups 
  Publications 
  Education | Master’s scholarships 
  PhD positions 
  Math+CS master’s track 
  Alumni 
  Testimonials 

 June 26-28, 2023 CPM 2023 34th Annual Symposium on Combinatorial Pattern Matching  

 The conference CPM 2023  takes place in the building Copernic, located in the middle of the Descartes campus of the Université Gustave Eiffel  . Highlights of CPM is a special session, introduced for the first time in CPM 2019, for presenting the highlights of recent developments in combinatorial pattern matching published in other venues.  

 News   

 Visit of Professor Andrew PHILPOTT | - | November-December 2024 : Professor Andrew Philpott is hosted at the CERMICS Laboratory Ecole Nationale des ... 
  Visit of Professor Alexandre Xavier FALCÃO | - | November 2024 : Alexandre Xavier Falcão is a Professor in Computer Science at the Institute of ... 
  Visit of Professor Dan Timotin | - | November-December 2024 . Dan Timotin is Professor at Institut de Mathématiques Simion Stoilow, Bucarest, Roumanie. ... 
  Colloquium Professor Andreas HOLMSEN | - | Tuesday, October 29th, 4pm, Andreas Holmsen will give a “Bézout colloquium” talk in the seminar ... 
  Visit of Professor Andreas HOLMSEN | - | October-November 2024 . Andreas Holmsen is a professor at KAIST, Daejeon, South Korea. He is ... 
  Geometry and Computing | - | October 21-25, 2024 : The conference Geometry and Computing aims to gather a broad spectrum ... 

 (all the news)    

 Legal information  — Contact  — Admin    

 © 2024  Bézout Labex  – All rights reserved   
 Powered by  WP   – Designed with the Customizr theme

25. CiE_1 conference:
Skip to content    Association Computability in Europe   
 Menu and widgets    
  
 Governance | Current Governance Structure 
  History of the Governance Structure 
  Constitution 
  Members 
  CiE Conference Series | CiE Conference Proceedings 
  Guidelines for organizing a CiE conference 
  Code of Conduct 
  Book Series 
  Computability — The Journal 
  Special Interest Groups | Women in Computability 
  History and Philosophy of Computing (HaPoC) 
  Transfinite Computations (TraC) 
  Bio-inspired Computation (BiC) 
  In Memoriam S. Barry Cooper 
  S. Barry Cooper Prize | 2020 S. Barry Cooper Prize awarded to Bruno Courcelle 
  2023 S. Barry Cooper Prize awarded to Rod G. Downey 
  Links | ACiE Sponsored Events 
  ACiE Related Events 
  Women in Computability Mentorship Programme 
  Support ACiE | Alan Turing Year Events 
  Newsletter 

 Search for:       
 Follow @acie  on Mastodon  

 Loading Mastodon feed...   

 Recent Posts  
 CiE 2024 CALL FOR PAPERS [Deadline Extension] 
  CiE 2024 First Call for Papers 
  CIE2023: Final Call For Papers 
  CIE2023: First Call For Papers 
  Call for Nominations for 2023 S. Barry Cooper Prize 

 Archives  
 February 2024 
  October 2023 
  January 2023 
  October 2022 
  April 2022 
  March 2022 
  October 2021 
  May 2021 
  April 2021 
  October 2020 
  June 2020 
  April 2020 
  March 2020 
  February 2020 
  December 2019 
  October 2019 
  July 2019 
  March 2019 
  January 2019 
  November 2018 
  September 2018 
  May 2018 
  April 2018 
  January 2018 
  December 2017 
  October 2017 
  July 2017 
  June 2017 
  April 2017 

 CiE Conference Series  
  
 The conference CiE 2005 was the start of a new conference series Computability in Europe  . Since 2008 it is the conference series of the Association Computability in Europe.   The series is coordinated by the CiE Conference Series Steering Committee  .  The following events have taken place or are planned in the series:  
 CiE 2023: Unity of Logic and Computation | Batumi, Georgia; 24-28 July 2023. | Organizing Committee Chairs | : | Besik Dundua | (Tblisi) | Programme Committee Chairs | : | Gianluca Della Vedova | (Milan), | Steffen Lempp | (Madison, WI) 
    CiE 2022: Revolutions and Revelations in Computability | Swansea, UK; 11-15 July 2022. | Organizing Committee Chairs | : | Arno Pauly | (Swansea) | Programme Committee Chairs | : | Ulrich Berger | (Swansea), | Johanna Franklin | (Hempstead, NY) 
    CiE 2021: Connecting with Computability | Ghent, Belgium; 5-9 July 2021. | Organizing Committee Chairs | : | David Fernández Duque | (Ghent) | Programme Committee Chairs | : | Liesbeth De Mol | (Lille), | Andreas Weiermann | (Ghent) 
    CiE 2020: Beyond the horizon of computability | Virtually in Salerno, Italy; 29 June – 3 July 2020. | Organizing Committee Chairs | : | Marcella Anselmo | (Salerno), | Gianluca Della Vedova | (Milan). | Programme Committee Chairs | : | Marcella Anselmo | (Salerno), | Arno Pauly | (Swansea) 
    CiE 2019: Computing with Foresight and Industry | Durham, UK; 15-19 July 2019. | Organizing Committee Chairs | : | Matthew Johnson | , | Barnaby Martin | and | Daniel Paulusma | (Durham University), | Giuseppe Primiero | (Milan). | Programme Committee Chairs | : | Daniel Paulusma | (Durham University), | Giuseppe | Primiero | (Milan). 
    CiE 2018: Sailing Routes in the World of Computation. | Kiel, Germany; 30 July – 3 August 2018. | Organizing Committee Chairs | : | Dirk Nowotka | (Kiel), | Florin Manea | (Kiel). | Programme Committee Chairs | : | Russell Miller | (New York), | Dirk Nowotka | (Kiel). 
    CiE 2017: Unveiling Dynamics and Complexity  .  
  Turku, Finland; 12-16 June 2017. | Organizing Committee Chairs  : Jarkko J Kari  (Turku), Ion Petre  (Turku). | Programme Committee Chairs  : Jarkko J Kari  (Turku), Ion Petre  (Turku). 
     CiE 2016: Pursuit of the Universal  . | Paris, France, 27 June – 1 July 2016. | Organizing Committee Chair  : Paulin de Naurois  (Paris13). | Programme Committee Chairs  : Laurent Bienvenu  (Paris 7), Nataša Jonoska  (Tampa FL) 
          
 CiE 2015: Evolving Computability  . | Bucharest, Romania, 29 June – 3 July 2015. | Organizing Committee Chairs:  Radu Gramatovici (Bucharest), Liviu Marin (Bucharest). | Programme Committee Chairs  : Victor Mitrana  (Bucharest), Mariya Soskova  (Sofia) 
          
 CiE 2014: Language, Life, Limits  . | Budapest, Hungary, 23-28 June 2014. | Organizing Committee Chair:  Erzsébet Csuhaj-Varjú  (Budapest) | Programme Committee Chairs  : Erzsébet Csuhaj-Varjú  (Budapest), Klaus Meer  (Cottbus) 
          
 CiE 2013  : The Nature of Computation: Logic, Algorithms, Applications  . | Milano, Italy, 1-5 July 2013. | Organizing Committee Chair:  Paola Bonizzoni  (Milano) | Programme Committee Chairs  : Paola Bonizzoni  (Milano), Vasco Brattka  (München). 
          
 CiE 2012  : How the World Computes  . | Cambridge, England, 18-23 June 2012. | Organizing Committee Chair:  Anuj Dawar  (Cambridge) | Programme Committee Chairs  : Barry Cooper  (Leeds), Anuj Dawar  (Cambridge) 
          
 CiE 2011  : Models of Computation in Context  . | Sofia, Bulgaria, 27 June – 2 July 2011. | Organizing Committee Chair:  Alexandra Soskova  (Sofia) | Programme Committee Chairs:  Dag Normann  (Oslo), Ivan Soskov  (Sofia) 
          
 CiE 2010  : Programs, Proofs, Processes  . | Ponta Delgada (Açores), Portugal. 30 June – 4 July 2010. | Organizing Committee Chair:  Luis Antunes  (Porto), Fernando Ferreira  (Lisbon) | Programme Committee Chairs:  Fernando Ferreira  (Lisbon), Elvira Mayordomo Cámara  (Zaragoza) 
          
 CiE 2009  : Mathematical Theory and Computational Practice  . | Heidelberg  , Germany. 19-24 July 2009. | Organizing Committee Chair:  Klaus Ambos-Spies  (Heidelberg) | Programme Committee Chairs:  Klaus Ambos-Spies  (Heidelberg), Wolfgang Merkle  (Heidelberg) 
          
 CiE 2008  : Logic and Theory of Algorithms  . | Athens, Greece. 15-20 June 2008 | Organizing Committee Chair:  Costas Dimitracopoulos  (Athens) | Programme Committee Chairs:  Arnold Beckmann  (Swansea), Costas Dimitracopoulos  (Athens) 
          
 CiE 2007  : Computation and Logic in the Real World  . | Siena  , Italy. 18-23 June 2007. | Organizing Committee Chair:  Andrea Sorbi  (Siena) | Programme Committee Chairs:  Barry Cooper  (Leeds), Andrea Sorbi  (Siena) 
          
 CiE 2006  : Logical approaches to computational barriers  .   
 Swansea  , Wales, 30 June – 5 July 2006. | Organizing Committee Chair:  Arnold Beckmann  (Swansea) | Programme Committee Chairs:  Arnold Beckmann  (Swansea), John Tucker  (Swansea) 
          
 CiE 2005  : New computational paradigms  .   
 Amsterdam  , The Netherlands, 8-12 June 2005. | Organizing Committee Chair:  Benedikt Löwe  (Amsterdam) | Programme Committee Chairs:  Barry Cooper  (Leeds), Benedikt Löwe  (Amsterdam) 

 Proudly powered by WordPress    

 Loading Comments...    

 Write a Comment...   Email (Required)    Name (Required)    Website

26. CASC_0 conference:
Computer Algebra in Scientific Computing    
 Menu    

 25th International Workshop on Computer Algebra in Scientific Computing  
 CASC 2023 · Aug. 28 - Sept. 1, Havana, Cuba  

  Invited Talks at CASC 2023  
 We are proud to present the invited speakers of CASC conference. Please find here the invited talks at CASC 2023.   

 All submissions should be done via EasyChair: https://easychair.org/conferences/?conf=casc2023    
 Poster  

  CASC 2023: Poster  
 Please find here  the poster of CASC 2023  

 Sponsors  

 Computer Algebra Research Group   

 © 2022-23 Computer Algebra in Scientific Computing.  
   
 Privacy Policy 
  Contact Webmaster

27. CASC_1 conference:
Computer Algebra in Scientific Computing    
 Menu    

 CASC 2024 · Sept. 2 - 6, Rennes, France  

  Invited Talks at CASC 2024  
 We are proud to present the invited speakers of CASC conference. Please find here the invited talks at CASC 2024.   

 All submissions should be done via EasyChair: https://easychair.org/conferences/?conf=casc2024    
 Poster  

  CASC 2024: Poster  
 Please find here  the poster of CASC 2024  

 © 2023-24 Computer Algebra in Scientific Computing.  
  All rights reserved.  
 Privacy Policy 
  Contact Webmaster

28. CAV_1 conference:
CAV 2023   
 35th International Conference on Computer Aided Verification  

 Menu  
 Skip to content  Home 
  Attending 
  Organisation 
  Keynotes 
  Proceedings 
  Program 
  Workshops | Mentoring 
  Accepted Papers 
  CAV Award 
  Call for Papers 
  Artifact Evaluation 

 Accepted Papers  
  
 Research papers   
 Compositional Probabilistic Model Checking with String Diagrams of MDPs | Kazuki Watanabe (The Graduate University for Advanced Studies (SOKENDAI)), Clovis Eberhart (National Institute of Informatics), Kazuyuki Asada (Tohoku University), Ichiro Hasuo (National Institute of Informatics) 
  Incremental Dead State Detection in Logarithmic Time | Caleb Stanford (UC San Diego and UC Davis), Margus Veanes (MSR Redmond) 
  Hybrid Controller Synthesis for Nonlinear Systems Subject to Reach-avoid Constraints | Zhengfeng Yang (East China Normal University), Li Zhang (East China Normal University), Xia Zeng (Southwest University), Xiaochao Tang (East China Normal University), Chao Peng (East China Normal University), Zhenbing Zeng (Shanghai University) 
  Verifying the Verifier: eBPF Range Analysis Verification | Harishankar Vishwanathan (Rutgers University), Matan Shachnai (Rutgers University), Srinivas Narayana (Rutgers University), Santosh Nagarakatte (Rutgers University) 
  Certified Verification for Algebraic Abstraction | Ming-Hsien Tsai (National Institute of Cyber Security), Yu-Fu Fu (Georgia Institute of Technology), Jiaxiang Liu (Shenzhen University), Xiaomu Shi (Shenzhen University), Bow-Yaw Wang (Academia Sinica), Bo-Yin Yang (Academia Sinica) 
  Fast Termination and Workflow Nets | Philip Offtermatt (Université de Sherbrooke & University of Warsaw), Filip Mazowiecki (University of Warsaw), Piotr Hofman (University of Warsaw) 
  QEBVerif: Quantization Error Bound Verification of Neural Networks | Yedi Zhang (Shanghaitech University), Fu Song (ShanghaiTech University), Jun Sun (Singapore Management University) 
  Formula Normalizations in Verification | Simon Guilloud (EPFL), Mario Bucev (EPFL), Dragana Milovancevic (EPFL), Viktor Kunčak (EPFL) 
  Search and Explore: Symbiotic Policy Synthesis in POMDPs | Roman Andriushchenko (Brno University of Technology, Czech Republic), Alexander Bork (RWTH-Aachen University, Germany), Milan Ceska (Brno University of Technology, Czech Republic), Sebastian Junges (Radboud University, Netherlands), Joost-Pieter Katoen (RWTH-Aachen University, Germany), Filip Macak (Brno University of Technology, Czech Republic) 
  Satisfiability Modulo Finite Fields | Alex Ozdemir (Stanford University), Gereon Kremer (Stanford University, Certora), Clark Barrett (Stanford University), Cesare Tinelli (The University of Iowa) 
  Automated Verification of Correctness for Masked Arithmetic Programs | Mingyang Liu (ShanghaiTech University), Fu Song (ShanghaiTech University), Taolue Chen (Birkbeck, University of London) 
  Efficient Sensitivity Analysis for Parametric Robust Markov Chains | Thom Badings (Radboud University), Sebastian Junges (Radboud University), Ahmadreza Marandi (Eindhoven University of Technology), Ufuk Topcu (The University of Texas at Austin), Nils Jansen (Radboud University) 
  Active Learning of Deterministic Timed Automata with Myhill-Nerode Style Characterization | Masaki Waga (Kyoto University) 
  Complete Multiparty Session Type Projection with Automata | Elaine Li (New York University), Felix Stutz (MPI-SWS), Thomas Wies (New York University), Damien Zufferey (Unaffiliated) 
  Process Equivalence Problems as Energy Games | Benjamin Bisping (TU Berlin) 
  Boolean Abstractions for Realizability Modulo Theories | Andoni Rodriguez (IMDEA Software Institute), Cesar Sanchez (IMDEA Software Institute) 
  Decision Procedures for Sequence Theories | Artur Jeż (University of Wroclaw), Anthony Lin (Technische Universität Kaiserslautern and Max-Planck Institute for Software Systems), Oliver Markgraf (Technische Universität Kaiserslautern), Philipp Ruemmer (University of Regensburg) 
  Policy Synthesis and Reinforcement Learning for Discounted LTL | Rajeev Alur (University Of Pennsylvania), Osbert Bastani (University of Pennsylvania), Kishor Jothimurugan (University of Pennsylvania), Mateo Perez (University of Colorado Boulder), Fabio Somenzi (University of Colorado Boulder), Ashutosh Trivedi (University of Colorado Boulder) 
  Automatic Program Instrumentation for Automatic Verification | Distinguished paper | Jesper Amilon (KTH Royal Institute of Technology), Zafer Esen (Uppsala University), Dilian Gurov (KTH Royal Institute of Technology), Christian Lidström (KTH Royal Institute of Technology), Philipp Rümmer (University of Regensburg) 
  Model Checking Race-freedom When “Sequential Consistency for Data-race-free Programs” is Guaranteed | Wenhao Wu (University of Delaware), Jan Hueckelheim (Argonne National Laboratory), Paul Hovland (Argonne National Laboratory), Ziqing Luo (University of Delaware), Stephen F. Siegel (University of Delaware) 
  Rely-Guarantee Reasoning for Causally Consistent Shared Memory | Ori Lahav (Tel Aviv University), Brijesh Dongol (University of Surrey), Heike Wehrheim (University of Oldenburg) 
  Safe Environmental Envelopes of Discrete Systems | Romulo Meira-Goes (Pennsylvania State University), Ian Dardik (Carnegie Mellon University), Eunsuk Kang (Carnegie Mellon University), Stéphane Lafortune (University of Michigan, Ann Arbor), Stavros Tripakis (Northeastern University) 
  Partial Quantifier Elimination And Property Generation | Eugene Goldberg (None) 
  Online Causation Monitoring of Signal Temporal Logic | Zhenya Zhang (Kyushu University), Jie An (National Institute of Informatics), Paolo Arcaini (National Institute of Informatics), Ichiro Hasuo (National Institute of Informatics) 
  Second-Order Hyperproperties | Raven Beutner (CISPA Helmholtz Center for Information Security, Germany), Bernd Finkbeiner (CISPA Helmholtz Center for Information Security), Hadar Frenkel (CISPA Helmholtz Center for Information Security), Niklas Metzger (CISPA Helmholtz Center for Information Security) 
  Bounded Verification for Finite-Field-Blasting (in a Compiler for Zero Knowledge Proofs) | Alex Ozdemir (Stanford University), Riad Wahby (Carnegie Mellon University), Fraser Brown (Carnegie Mellon University), Clark Barrett (Stanford University) 
  Exploiting Adjoints in Property Directed Reachability Analysis | Distinguished paper | Mayuko Kori (National Institute of Informatics), Flavio Ascari (University of Pisa), Filippo Bonchi (University of Pisa), Roberto Bruni (University of Pisa), Roberta Gori (University of Pisa), Ichiro Hasuo (National Institute of Informatics) 
  Ownership guided C to Rust translation | Hanliang Zhang (University of Bristol), Cristina David (University of Bristol), Yijun Yu (The Open University), Meng Wang (University of Bristol) 
  Synthesizing Trajectory Queries from Examples | Stephen Mell (University of Pennsylvania), Favyen Bastani (Allen Institute for AI), Steve Zdancewic (University of Pennsylvania), Osbert Bastani (University of Pennsylvania) 
  SR-SFLL: Structurally Robust Stripped Functionality Logic Locking | Gourav Takhar (Indian Institute of Technology Kanpur), Subhajit Roy (Indian Institute of Technology Kanpur) 
  Synthesizing Permissive Winning Strategy Templates for Parity Games | Ashwani Anand (Max Planck Institute for Software Systems), Satya Prakash Nayak (Max Planck Institute for Software Systems), Anne-Kathrin Schmuck (Max Planck Institute for Software Systems) 
  Solving String Constraints using SAT | Kevin Lotz (Kiel University), Amit Goel (AWS), Bruno Dutertre (AWS), Benjamin Kiesl-Reiter (AWS), Soonho Kong (AWS), Rupak Majumdar (AWS), Dirk Nowotka (Kiel University) 
  Local Search for Solving Satisfiability of Polynomial Formulas | Haokun Li (Peking University), Bican Xia (Peking University), Tianqi Zhao (Peking University) 
  Fast Approximations of Quantifier Elimination | Distinguished paper | Isabel Garcia-Contreras (University of Waterloo), Hari Govind V K (University of Waterloo), Sharon Shoham (Tel Aviv University), Arie Gurfinkel (University of Waterloo) 
  Monitoring Algorithmic Fairness | Thomas A. Henzinger (Instititue of Science and Technology Austria), Mahyar Karimi (University of Tehran), Konstantin Kueffner (Instititue of Science and Technology Austria), Kaushik Mallik (Instititue of Science and Technology Austria) 
  Automated Tail Bound Analysis for Probabilistic Recurrence Relations | Yican Sun (Peking University), Hongfei Fu (Shanghai Jiao Tong University), Krishnendu Chatterjee (IST Austria), Amir Kafshdar Goharshady (Hong Kong University of Science and Technology) 
  MDPs as Distribution Transformers: Affine Invariant Synthesis for Safety Objectives | S. Akshay (IIT Bombay), Krishnendu Chatterjee (Institute of Science and Technology Austria (ISTA)), Tobias Meggendorfer (Institute of Science and Technology Austria (ISTA)), Đorđe Žikelić (Institute of Science and Technology Austria (ISTA)) 
  Learning Assumptions for Compositional Verification of Timed Automata | Hanyue Chen (Tongji University), Yu Su (Tongji University), Miaomiao Zhang (Tongji University), Zhiming Liu (Southwest University), Junri Mi (Tongji University) 
  Early Verification of Legal Compliance via Bounded Satisfiability Checking | Nick Feng (University of Toronto), Lina Marsso (University of Toronto), Mehrdad Sabetzadeh (EECS, University of Ottawa), Marsha Chechik (University of Toronto) 
  Unblocking Dynamic Partial Order Reduction | Michalis Kokologiannakis (MPI-SWS), Iason Marmanis (MPI-SWS), Viktor Vafeiadis (MPI-SWS) 
  Commutativity For Concurrent Program Termination Proofs | Azadeh Farzan (University of Toronto), Danya Lette (University of Toronto) 
  Certifying the Fairness of KNN in the Presence of Dataset Bias | Yannan Li (University of Southern California), Jingbo Wang (University of Southern California), Chao Wang (University of Southern California) 
  Making IP=PSPACE Practical: Efficient Interactive Protocols for BDD Algorithms | Eszter Couillard (Technische Universität München), Philipp Czerner (Technische Universität München), Javier Esparza (Technische Universität München), Rupak Majumdar (Max Planck Institute for Software Systems) 
  A Unified Model for Real-Time Systems: Symbolic Techniques and Implementation | S. Akshay (Indian Institute of Technology Bombay), Paul Gastin (Université Paris-Saclay, ENS Paris-Saclay, CNRS), R Govind (Indian Institute of Technology Bombay), Aniruddha Joshi (Indian Institute of Technology Bombay), B Srivathsan (Chennai Mathematical Institute, India) 
  Overcoming Memory Weakness with Unified Fairness | Parosh Aziz Abdulla (Uppsala University), Mohamed Faouzi Atig (Uppsala University), Adwait Godbole (University of California, Berkeley), Shankaranarayanan Krishna (IIT Bombay), Mihir Vahanwala (MPI-SWS, Saarbrücken) 
  Rounding Meets Approximate Model Counting | Distinguished paper | Jiong Yang (National University of Singapore), Kuldeep S. Meel (National University of Singapore) 
  Searching for i-Good Lemmas to Accelerate Safety Model Checking | Yechuan Xia (East China Normal University), Anna Becchi (Fondazione Bruno Kessler), Alessandro Cimatti (FBK), Alberto Griggio (Fondazione Bruno Kessler), Jianwen Li (East China Normal University), Geguang Pu (East China Normal University) 
  Guessing Winning Policies in LTL Synthesis by Semantic Learning | Jan Kretinsky (Technische Universität München), Max Prokop (Technische Universität München), Tobias Meggendorfer (Institute of Science and Technology Austria), Sabine Rieder (Technische Universität München) 
  Counter-Example Guided Knowledge Compilation for Boolean Functional Synthesis | S. Akshay (IIT Bombay), Supratik Chakraborty (IIT Bombay), Sahil Jain (IIT Bombay) 
   Tool papers   
 Formally Verified EVM Block-Optimizations | Elvira Albert (Universidad Complutense de Madrid), Samir Genaim (Universidad Complutense de Madrid), Daniel Kirchner (Ethereum Foundation & University of Bamberg), Enrique Martin-Martin (Universidad Complutense de Madrid) 
  Symbolic Quantum Simulation with Quasimodo | Meghana Sistla (The University of Texas at Austin), Swarat Chaudhuri (UT Austin), Thomas Reps (University of Wisconsin) 
  Lincheck: A Practical Framework for Testing Concurrent Data Structures on JVM | Nikita Koval (JetBrains), Alexander Fedorov (IST Austria), Maria Sokolova (JetBrains), Dmitry Tsitelov (Devexperts), Dan Alistarh (IST Austria) 
  Verse: A Python library for reasoning about multi-agent hybrid system scenarios | Yangge Li (University of Illinois at Urbana-Champaign), Haoqing Zhu (University of Illinois at Urbana-Champaign), Katherine Braught (University of Illinois at Urbana-Champaign), Keyi Shen (University of Illinois at Urbana-Champaign), Sayan Mitra (University of Illinois at Urbana-Champaign) 
  CoqCryptoLine: A Verified Model Checker with Certified Results | Ming-Hsien Tsai (National Institute of Cyber Security), Yu-Fu Fu (Georgia Institute of Technology), Jiaxiang Liu (Shenzhen University), Xiaomu Shi (Shenzhen University), Bow-Yaw Wang (Academia Sinica), Bo-Yin Yang (Academia Sinica) 
  The Golem Horn Solver | Distinguished paper | Martin Blicha (Università della Svizzera italiana), Konstantin Britikov (Università della Svizzera italiana), Natasha Sharygina (Università della Svizzera italiana) 
  Bitwuzla | Distinguished paper | Aina Niemetz (Stanford University), Mathias Preiner (Stanford University) 
  AutoQ: An Automata-based Quantum Circuit Verifier | Yu-Fang Chen (Academia Sinica), Kai-Min Chung (Academia Sinica), Ondřej Lengál (Brno University of Technology), Jyun-Ao Lin (Academia Sinica), Wei-Lun Tsai (Academia Sinica) 
  Kratos2: an SMT-Based Model Checker for Imperative Programs | Alberto Griggio (Fondazione Bruno Kessler), Martin Jonáš (Masaryk University, Czech Republic) 
  3D Environment Modeling for Falsification and Beyond with Scenic 3.0 | Eric Vin (University of California, Santa Cruz), Shun Kashiwa (University of California, Santa Cruz), Matthew Rhea (SentinelOne), Daniel J. Fremont (University of California, Santa Cruz), Edward Kim (University of California, Berkeley), Tommaso Dreossi (insitro), Shromona Ghosh (Waymo LLC), Xiangyu Yue (The Chinese University of Hong Kong), Alberto L. Sangiovanni-Vincentelli (University of California, Berkeley), Sanjit A. Seshia (University of California, Berkeley) 
  nekton: a linearizability proof checker | Roland Meyer (TU Braunschweig), Anton Opaterny (TU Braunschweig), Thomas Wies (New York University), Sebastian Wolff (New York University) 
  nl2spec: Interactively Translating Unstructured Natural Language to Temporal Logics with Large Language Models | Matthias Cosler (CISPA Helmholtz Center for Information Security), Christopher Hahn (Stanford University), Daniel Mendoza (Stanford University), Frederik Schmitt (CISPA Helmholtz Center for Information Security), Caroline Trippel (Stanford University) 
  NNV 2.0: The Neural Network Verification Tool | Diego Manzanas Lopez (Vanderbilt University), Sung Woo Choi (University of Nebraska), Hoang Dung Tran (University of Nebraska), Taylor T. Johnson (Vanderbilt University) 
  A Flexible Toolchain for Symbolic Rabin Games under Fairness and Stochastic Uncertainties | Rupak Majumdar (MPI-SWS), Kaushik Mallik (ISTA), Mateusz Rychlicki (University of Leeds), Anne-Kathrin Schmuck (Max Planck Institute for Software Systems), Sadegh Soudjani (Newcastle University) 
  R2U2 Version 3.0: Re-imagining a Toolchain for Specification, Resource Estimation, and Optimized Observer Generation for Runtime Verification in Hardware and Software | Chris Johannsen (Iowa State University), Phillip Jones (Iowa State University), Brian Kempa (Iowa State University), Kristin Yvonne Rozier (Iowa State University), Pei Zhang (Google) 
   Industrial Experience Report or Case Study   
 Automated Analyses of IOT Event Monitoring Systems | Andrew Apicelli (Amazon Web Services, Inc.), Sam Bayless (Amazon Web Services, Inc.), Ankush Das (Amazon Web Services, Inc.), Andrew Gacek (Amazon Web Services, Inc.), Dhiva Jaganathan (Amazon Web Services, Inc.), Saswat Padhi (Google LLC), Vaibhav Sharma (Amazon.com Services LLC), Michael W. Whalen (Amazon Web Services, Inc.), Raveesh Yadav (Amazon Web Services, Inc.) 
  Closed-loop Analysis of Vision-based Autonomous Systems: A Case Study | Corina Pasareanu (KBR Inc., NASA Ames, Carnegie Mellon University), Ravi Mangal (Carnegie Mellon University), Divya Gopinath (KBR Inc., NASA Ames), Sinem Getir Yaman (University of York), Calum Imrie (University of York), Radu Calinescu (University of York), Huafeng Yu (Boeing Research and Technology) 
  Verifying Generalization in Deep Learning | Guy Amir (The Hebrew University of Jerusalem), Osher Maayan (The Hebrew University of Jerusalem), Tom Zelazny (The Hebrew University of Jerusalem), Guy Katz (The Hebrew University of Jerusalem), Michael Schapira (The Hebrew University of Jerusalem) 

 Sponsors    

 Platinum sponsors  

 Gold sponsors  

 Silver sponsors  

 Bronze sponsors  

 Institutional support  

 Proudly powered by WordPress  |  Theme: Expound by Konstantin Kovshenin

29. CiE_2 conference:
Skip to content    Association Computability in Europe   
 Menu and widgets    
  
 Governance | Current Governance Structure 
  History of the Governance Structure 
  Constitution 
  Members 
  CiE Conference Series | CiE Conference Proceedings 
  Guidelines for organizing a CiE conference 
  Code of Conduct 
  Book Series 
  Computability — The Journal 
  Special Interest Groups | Women in Computability 
  History and Philosophy of Computing (HaPoC) 
  Transfinite Computations (TraC) 
  Bio-inspired Computation (BiC) 
  In Memoriam S. Barry Cooper 
  S. Barry Cooper Prize | 2020 S. Barry Cooper Prize awarded to Bruno Courcelle 
  2023 S. Barry Cooper Prize awarded to Rod G. Downey 
  Links | ACiE Sponsored Events 
  ACiE Related Events 
  Women in Computability Mentorship Programme 
  Support ACiE | Alan Turing Year Events 
  Newsletter 

 Search for:       
 Follow @acie  on Mastodon  

 Loading Mastodon feed...   

 Recent Posts  
 CiE 2024 CALL FOR PAPERS [Deadline Extension] 
  CiE 2024 First Call for Papers 
  CIE2023: Final Call For Papers 
  CIE2023: First Call For Papers 
  Call for Nominations for 2023 S. Barry Cooper Prize 

 Archives  
 February 2024 
  October 2023 
  January 2023 
  October 2022 
  April 2022 
  March 2022 
  October 2021 
  May 2021 
  April 2021 
  October 2020 
  June 2020 
  April 2020 
  March 2020 
  February 2020 
  December 2019 
  October 2019 
  July 2019 
  March 2019 
  January 2019 
  November 2018 
  September 2018 
  May 2018 
  April 2018 
  January 2018 
  December 2017 
  October 2017 
  July 2017 
  June 2017 
  April 2017 

 CIE2023: Final Call For Papers  

 CiE 2023: FINAL CALL FOR PAPERS  
  Computability in Europe 2023  
 Unity of Logic and Computation   
 Batumi, Georgia  
  July 24-28, 2023  
  https://www.viam.science.tsu.ge/cie2023/   
 Submission link: https://easychair.org/conferences/?conf=cie2023   
  IMPORTANT DATES:  
 Deadline for article submission: | February 15, 2023 | (AOE) 
  Notification of acceptance: | April 20, 2023 
  Final versions due: | May 1, 2023 
  Deadline for informal presentations submission: | June 8, 2023 | (The notifications of acceptance for informal presentations will be sent a few days after submission.) 
  Early registration before: | June 10, 2023 | . 
   GENERAL INFORMATION  
 CiE 2023 is the 19th conference organized by CiE (Computability in Europe), a European association of mathematicians, logicians, computer scientists, philosophers, physicists and others interested in new developments in computability and their underlying significance for the real world.  
 Previous meetings have taken place in Amsterdam (2005), Swansea (2006), Siena (2007), Athens (2008), Heidelberg (2009), Ponta Delgada (2010), Sofia (2011), Cambridge (2012), Milan (2013), Budapest (2014), Bucharest (2015), Paris (2016), Turku (2017), Kiel (2018), Durham (2019), Salerno (2020, virtually), Ghent (2021, virtually), and Swansea (2022).  
  TUTORIAL SPEAKERS  
 Ludovic Perret (Sorbonne University) 
  Ludovic Patey (Université Paris Diderot) 
   INVITED SPEAKERS  
 Andrei Bulatov (Simon Fraser University) 
  Anne Condon (University of British Columbia) 
  Stephanie Dick (University of Pennsylvania) 
  Kirsten Eisenträger (Pennsylvania State University) 
  Neil Lutz (Iowa State University) 
  Mark Steedman (University of Edinburgh) 
   SPECIAL SESSIONS  
 We are going to have 6 special sessions.  
  The topics of the special sessions will be announced soon.  
  CONFERENCE TOPICS  
 The CiE conferences serve as an interdisciplinary forum for research in all aspects of computability, foundations of computer science, logic, and theoretical computer science, as well as the interplay of these areas with practical issues in computer science and with other disciplines such as biology, mathematics, philosophy, or physics.  
  PAPER SUBMISSION  
 THE PROGRAM COMMITTEE cordially invites all researchers, European and non-European, to submit their papers in all areas related to the above for presentation at the conference and inclusion in the proceedings of CiE 2023 at https://easychair.org/conferences/?conf=cie2023   
  CONFERENCE PROCEEDINGS  
 Papers submitted to the conference proceedings should represent original work, not simultaneously submitted to another journal or conference with formal proceedings.  
  The Program Committee will rigorously review and select submitted papers. Accepted papers will be published as a proceedings volume in the Lecture Notes in Computer Science (LNCS) series from Springer-Verlag.  
 Papers to be considered in the conferences proceedings must be submitted in PDF format, using the LNCS style (available at https://www.springer.com/gp/computer-science/lncs/conference-proceedings-guidelines  ) and must have a maximum of 12 pages, including references but excluding a possible appendix in which one can include proofs and other additional material. Papers building bridges between different parts of the research community are particularly welcome.  
  INFORMAL PRESENTATIONS  
 Continuing the tradition of past CiE conferences, we invite researchers to present informal presentations of their recent work. A proposal for an informal presentation must be submitted via EasyChair ( https://easychair.org/conferences/?conf=cie2023  ), using the LNCS style file (available at https://www.springer.com/gp/computer-science/lncs/conference-proceedings-guidelines  ), and be 1 page long; a brief description of the results suffices and an abstract is not required. Informal presentations will not be published in the LNCS conference proceedings. Results presented as informal presentations at CiE 2023 may appear or may have appeared in other conferences with formal proceedings and/or in journals.  
  PROGRAM COMMITTEE  
 Contributed papers will be selected from submissions received by the PROGRAM COMMITTEE consisting of:  
 Nikolay Bazhenov (Novosibirsk State University) 
  Manuel Bodirsky (TU Dresden) 
  Vasco Brattka (Munich) 
  Liesbeth De Mol (University of Lille) 
  Gianluca Della Vedova (University of Milano-Bicocca, co-chair) 
  Besik Dundua (Kutaisi Intl University) 
  Giudittta Franco (University of Verona) 
  Juan Luis Gastaldi (ETH Zurich) 
  Thomas Graf (Stony Brook University) 
  Delaram Kahrobaei (CUNY) 
  Ekaterina Komendantskaya (Heriot-Watt University Edinburgh) 
  Angeliki Koutsoukou-Argyraki (Cambridge University) 
  Steffen Lempp (University of Wisconsin-Madison, co-chair) 
  Florin Manea (Goettingen University) 
  Klaus Meer (University Cottbus) 
  Isabel Oitavem (Nova University Lisbon) 
  Roland Omanadze (Ivane Javakhishvili Tbilisi State University) 
  Daniel Paulusma (Durham University) 
  Elaine Pimentel (University College London) 
  Markus Schmid (Humboldt University Berlin) 
  Shinnosuke Seki (University Electro Comm Tokyo) 
  Sebastiaan Terwijn (Radboud University Nijmegen) 
  Dan Turetsky (Victoria University Wellington) 
  Linda Westrick (Pennsylvania State University) 
   WOMEN IN COMPUTABILITY  
 We are very happy to announce that within the framework of the Women in Computability program, we are able to offer some grants for junior women researchers who want to participate in CiE 2023. Applications for this grant should be sent to Liesbeth de Mol, liesbeth.de-mol@univ-lille.fr  , before May 15, 2023 and include a short cv (at most 2 pages) and contact information for an academic reference. Preference will be given to junior women researchers who are presenting a paper (including informal presentations) at CiE 2023.  
 Association CiE   
 CiE Conference Series   
  HOSTED BY  
 Batumi Shota Rustaveli State University  
  Rustaveli str. 32, Batumi,  
 We are grateful for support from Batumi Shota Rustaveli State University and Institute of Applied Mathematics, Tbilisi State University.  
  ORGANIZING COMMITTEE  
 Davit Begashvili (Kutaisi International University) 
  Mikheil Donadze (Batumi Shota Rustaveli State University) 
  Besik Dundua (chair, Kutaisi International University and Institute of Applied Mathematics, Tbilisi State University) 
  Tsotne Mikadze (Kutaisi International University) 
  Mikheil Rukhaia (co-chair, Institute of Applied Mathematics, Tbilisi State University) 
  Lela Turmanidze (Batumi Shota Rustaveli State University) 
    
 Posted on  January 27, 2023  February 9, 2023    Author  admin    Categories  Uncategorized   Tags  conference    
  
 Leave a Reply Cancel reply    
 Your email address will not be published.  Required fields are marked *    
 Comment *     
 Name *     
 Email *     
 Website    
  Notify me of follow-up comments by email.   
  Notify me of new posts by email.   

 Δ     
    
 This site uses Akismet to reduce spam. Learn how your comment data is processed  .  
   
 Post navigation  
 Previous  Previous post:  CIE2023: First Call For Papers     
 Next  Next post:  CiE 2024 First Call for Papers     

 Proudly powered by WordPress

30. CAV_2 conference:
CAV 2023   
 35th International Conference on Computer Aided Verification  

 Menu  
 Skip to content  Home 
  Attending 
  Organisation 
  Keynotes 
  Proceedings 
  Program 
  Workshops | Mentoring 
  Accepted Papers 
  CAV Award 
  Call for Papers 
  Artifact Evaluation 

 CAV Award  
  
 This years CAV Award winners are  
  
 Jakob Rehof | TU Dortmund 
 Thomas Reps | UW-Madison 
 Akash Lal | Microsoft Research 
 Shaz Qadeer | Meta Research 
 Madan Musuvathi | Microsoft Research 
  
  For the introduction of context-bounded analysis and its application to the systematic testing of concurrent programs  
 Nomination  
 Anyone can submit a nomination. The Award Committee can originate a nomination. Anyone, with the exception of members of the Award Committee, is eligible to receive the Award. A nomination must state clearly the contribution(s), explain why the contribution is fundamental or the series of contributions is outstanding, and be accompanied by supporting letters and other evidence of worthiness.  
 Nominations should include a proposed citation (up to 25 words), a succinct (100-250 words) description of the contribution(s), and a detailed statement to justify the nomination. The cited contribution(s) must have been made not more recently than five years ago and not over twenty five years ago. In addition, the contribution(s) should not yet have received recognition via a major award, such as the ACM Turing or Kanellakis Awards. The nominee may have received such an award for other contributions.  
 For previous winners of the award, please see the main CAV award page  . Nominations should be submitted by e-mail to a member of the committee.  
 Important Dates  
 Nomination deadline: March 1, 2023    
 Award Committee  
  
 Parosh Abdulla  (Chair) | Uppsala University 
 Corina Pasareanu | NASA 
 Rupak Majumdar | MPI-SWS 
 Ranjit Jhala | University of California, San Diego 

 Sponsors    

 Platinum sponsors  

 Gold sponsors  

 Silver sponsors  

 Bronze sponsors  

 Institutional support  

 Proudly powered by WordPress  |  Theme: Expound by Konstantin Kovshenin

31. CAivDE_0 conference:
Not Found  
 The requested URL was not found on this server.  
 Additionally, a 404 Not Found error was encountered while trying to use an ErrorDocument to handle the request.

32. CAV_3 conference:
CAV 2023   
 35th International Conference on Computer Aided Verification  

 Menu  
 Skip to content  Home 
  Attending 
  Organisation 
  Keynotes 
  Proceedings 
  Program 
  Workshops | Mentoring 
  Accepted Papers 
  CAV Award 
  Call for Papers 
  Artifact Evaluation 

 Workshops  
  
 The following workshops will be held before the main conference.  
 Single day workshops  
 Meeting on String Constraints and Applications (MOSCA 2023)  , July 17th   
  Organizers: Yu-Fang Chen  ( Academia Sinica  , Taiwan), Lukáš Holík  (BRNO University of Technology, Czechia) and Zhilin Wu  (Chinese Academy of Sciences, China)  
 1st Workshop on Verification Witnesses and Their Validation (VeWit 2023)   , July 17th   
  Organizers: Dirk Beyer  (LMU Munich, Germany) and Jan Strejček  (Masaryk University, Czechia)  
 Workshop on Verification of Probabilistic Programs (VeriProP 2023)  , July 17th   
  Organizers: Michele Chiari  (TU Wien, Austria), Fredrik Dahlqvist  (Queen Mary University of London, UK), Sebastian Junges  (Radboud University, the Netherlands), Benjamin Kaminski  (Saarland University, Germany and University College London, UK) and Christoph Matheja  (Technical University of Denmark, Denmark)  
 Workshop on Open Problems in Learning and Verification of Neural Networks (WOLVERINE 2023)  , July 17th   
  Organizers: Anna Lukina  (TU DELFT, the Netherlands), Guy Avni  (University of Haifa, Isreal), Mirco Giacobbe  (University of Birmingham, UK) and Christian Schilling  (Aalborg University, Denmark)  
 Deep Learning-aided Verification (DAV 2023)   , July 18th   
  Organizers: Christopher Hahn  (Stanford University, USA) and Markus N. Rabe  (Google Research, USA)  
 Workshop on Hyperproperties: Advances in Theory and Practice (HYPER 2023)   , July 18th   
  Organizers: Rayna Dimitrova  (CISPA, Germany), Daniel Fremont  (University of California, Santa Cruz, USA) and Hazem Torfah  (University of California, Berkeley, USA)  
 12th Workshop on Synthesis (SYNT 2023)   , July 18th   
  Organizers: Bettina Könighofer  (Graz University of Technology, Austria) Andrew Reynolds  (University of Iowa, USA)  
 Tom Henzinger Festschrift birthday  , July 18th   
  Organizers: Jean-François Raskin  (Université Libre de Bruxelles, Belgium), Krishnendu Chatterjee  (Institute of Science and Technology, Austria), Laurent Doyen  (École Normale Supérieure Paris-Saclay, France), Rupak Majumdar  (MPI for Software Systems, Germany)  
 Verification Mentoring Workshop  , July 18th   
  Organizers: Ankush Densai  (AWS, CA), Eric Koskinen  (Stevens Institute of Technology), Burcu Kulahcioglu Ozkan  (TU Delft, the Netherlands) and Marijana Lazic  (TU Munich, Germany), Matteo Sammartino  (Royal Holloway University of London)  
 Two day workshops  
 6th Workshop on Formal Methods for ML-Enabled Autonomous Systems (FoMLAS 2023)  , July 17th-18th   
  Organizers: Guy Amir  (The Hebrew University of Jerusalem, Isreal), Omri Isac  (The Hebrew University of Jerusalem, Isreal), Guy Katz  (The Hebrew University of Jerusalem, Isreal) and Nina Narodytska  (VMware Research, USA)  

 Sponsors    

 Platinum sponsors  

 Gold sponsors  

 Silver sponsors  

 Bronze sponsors  

 Institutional support  

 Proudly powered by WordPress  |  Theme: Expound by Konstantin Kovshenin

33. CiE_3 conference:
JavaScript must be enabled to use the system

34. CASC_3 conference:
Anmelden 
  Registrierung 
  Deutsch  English 
  Español 
  Português 
  Français 

     Dom 
  Najlepsze kategorie | CAREER & MONEY 
  PERSONAL GROWTH 
  POLITICS & CURRENT AFFAIRS 
  SCIENCE & TECH 
  HEALTH & FITNESS 
  LIFESTYLE 
  ENTERTAINMENT 
  BIOGRAPHIES & HISTORY 
  FICTION 
  Najlepsze historie 
  Najlepsze historie 
  Dodaj historię 
  Moje historie 

 Home 
  Computer Algebra in Scientific Computing. 25th International Workshop, CASC 2023 Havana, Cuba, August 28 – September 1, 2023 Proceedings 9783031417238, 9783031417245 

 Computer Algebra in Scientific Computing. 25th International Workshop, CASC 2023 Havana, Cuba, August 28 – September 1, 2023 Proceedings 9783031417238, 9783031417245   
   
  197    41    13MB    
  English   Pages [441]   Year 2023    
  Report DMCA / Copyright    
  DOWNLOAD FILE   
   
 Polecaj historie   

 Computer Algebra in Scientific Computing: 24th International Workshop, CASC 2022, Gebze, Turkey, August 22–26, 2022, Proceedings (Lecture Notes in Computer Science) 3031147871, 9783031147876  
 This book constitutes the proceedings of the 24th International Workshop on Computer Algebra in Scientific Computing, CA  
  139    60    10MB    Read more   

 Computer Algebra in Scientific Computing: 23rd International Workshop, CASC 2021, Sochi, Russia, September 13–17, 2021, Proceedings (Lecture Notes in Computer Science, 12865) [1st ed. 2021] 3030851648, 9783030851644  
 This book constitutes the proceedings of the 23rd International Workshop on Computer Algebra in Scientific Computing, CA  
  848    63    12MB    Read more   

 Computer Algebra in Scientific Computing: 23rd International Workshop, CASC 2021, Sochi, Russia, September 13–17, 2021, Proceedings (Theoretical Computer Science and General Issues) 3030851648, 9783030851644  
 This book constitutes the proceedings of the 23rd International Workshop on Computer Algebra in Scientific Computing, CA  
  140    37    12MB    Read more   

 Computer Algebra in Scientific Computing : 19th International Workshop, CASC 2017, Beijing, China, September 18-22, 2017, Proceedings 978-3-319-66320-3, 3319663208, 978-3-319-66319-7  
 This book constitutes the proceedings of the 19th International Workshop on Computer Algebra in Scientific Computing, CA  
  480    99    14MB    Read more   

 Human-Computer Interaction – INTERACT 2023: 19th IFIP TC13 International Conference, York, UK, August 28 – September 1, 2023, Proceedings, Part III (Lecture Notes in Computer Science) 3031422856, 9783031422850  
 The four-volume set LNCS 14442 -14445 constitutes the proceedings of the 19th IFIP TC 13 International Conference on Hum  
  186    34    Read more   

 Human-Computer Interaction – INTERACT 2023: 19th IFIP TC13 International Conference, York, UK, August 28 – September 1, 2023, Proceedings, Part II (Lecture Notes in Computer Science) 3031422821, 9783031422829  
 The four-volume set LNCS 14442 -14445 constitutes the proceedings of the 19th IFIP TC 13 International Conference on Hum  
  190    60    Read more   

 Computer Algebra in Scientific Computing: 22nd International Workshop, CASC 2020, Linz, Austria, September 14–18, 2020, Proceedings [1st ed.] 9783030600259, 9783030600266  
 This book constitutes the refereed proceedings of the 22nd International Workshop on Computer Algebra in Scientific Comp  
  357    34    28MB    Read more   

 Big Data Analytics and Knowledge Discovery: 25th International Conference, DaWaK 2023, Penang, Malaysia, August 28–30, 2023, Proceedings 3031398300, 9783031398308  
  
  165    54    Read more   

 Collaboration Technologies and Social Computing: 29th International Conference, CollabTech 2023, Osaka, Japan, August 29–September 1, 2023, Proceedings (Lecture Notes in Computer Science) 303142140X, 9783031421402  
 This book constitutes the refereed proceedings of the 29th International Conference on Collaboration Technologies and So  
  142    30    16MB    Read more   

 HCI International 2023 Posters: 25th International Conference on Human-Computer Interaction, HCII 2023, Copenhagen, Denmark, July 23–28, 2023, Proceedings, Part IV 9783031360015, 9783031360008, 303136001X  
 The five-volume set CCIS 1832-1836 contains the extended abstracts of the posters presented during the 25th Internationa  
  189    47    91MB    Read more   

 Author / Uploaded 
  François Boulier 
  Matthew England 
  Ilias Kotsireas 
  Timur M. Sadykov 
  Evgenii V. Vorozhtsov 

 Table of contents :  
  Preface  
  Acknowledgments  
  Organization  
  Abstracts of Invited Talks  
  Normal Forms of Integer Matrices  
  On the Performance of Local Search Algorithms for K-SAT Problems in Random Graphs  
  Contents  
  Computing GCDs of Multivariate Polynomials over Algebraic Number Fields Presented with Multiple Extensions  
  1 Introduction  
  1.1 Motivation for the Algorithm  
  1.2 Preliminaries  
  1.3 Paper Outline  
  2 Converting Q(1,…,n) to a Single Extension Q()  
  2.1 Computing a Primitive Element and its Minimal Polynomial  
  2.2 The Isomorphism  
  3 The Modular Gcd Algorithm  
  3.1 PGCD  
  3.2 MGCD  
  4 Complexity  
  5 Implementation  
  5.1 Maple Implementation  
  5.2 Benchmark  
  6 Conclusion and Future Work  
  References  
  Generating Elementary Integrable Expressions  
  1 Introduction  
  1.1 Machine Learning and Computer Algebra  
  1.2 Symbolic Integration Meta-Algorithms  
  1.3 Motivation  
  1.4 Contributions and Plan  
  2 Existing Datasets and Data Generation Methods  
  2.1 Deep Learning for Symbolic Mathematics  
  2.2 Other Existing Datasets  
  3 The Risch Algorithm  
  3.1 The Rational Part  
  3.2 The Polynomial Part  
  4 Data Generation Based on the Risch Algorithm  
  4.1 Polynomial Integrable Expressions  
  4.2 Rational Integrable Expressions  
  5 Discussion  
  5.1 Risch Data Generation Benefits  
  5.2 Future Work  
  References  
  How to Automatise Proofs of Operator Statements: Moore–Penrose Inverse; A Case Study  
  1 Introduction  
  2 From Operator Identities to Noncommutative Polynomials  
  3 Treating Existential Statements  
  4 Treating Common Properties  
  4.1 Real Matrices  
  4.2 Identity Operators  
  4.3 Injectivity, Surjectivity, and Full Matrix Ranks  
  4.4 Range Inclusions  
  5 Logical Framework  
  6 Case Study  
  A The Software Package Operator_gb  
  A.1 Certifying Operator Statements  
  A.2 Useful Auxiliary Functions for Treating Operator Statements  
  A.3 Quivers and Detecting Typos  
  A.4 Gröbner Basis Computations  
  A.5 Heuristics for Finding Polynomials of Certain Form  
  References  
  A Modular Algorithm for Computing the Intersection of a One-Dimensional Quasi-Component and a Hypersurface  
  1 Introduction  
  2 Preliminaries  
  3 Genericity Assumptions  
  4 The Modular Method  
  4.1 The Fumber of Bad Specializations is Finite  
  4.2 Number of Bad Specializations and Other Degree Estimates  
  4.3 A Modular Algorithm  
  5 Relaxing the Hypotheses  
  6 Implementation  
  7 Experimentation and Discussion  
  References  
  Certified Study of Internal Solitary Waves  
  1 Introduction  
  2 Improved Serre-Like Model  
  3 Steady Motions  
  4 Algebraic Analysis and Symbolic Computations  
  4.1 Improved SGN  
  4.2 Expressions Related to D, with 1 and 2  
  4.3 Illustrative Case  
  4.4 Classical SGN, i.e., 1 =2=0  
  5 Partition of the Parameters Space  
  6 Phase Plane Analysis  
  6.1 Local Analysis  
  6.2 Global Analysis  
  7 An Explicit Example of Slug  
  8 Conclusion  
  References  
  Root-Squaring for Root-Finding  
  1 Introduction  
  1.1 Polynomial Root-Finding  
  1.2 Classical Root-Squaring Iterations  
  1.3 Related Works on Root-Squaring and Its Applications  
  1.4 The Two Nearly Optimal Polynomial Root-Finders  
  1.5 Our Contribution  
  1.6 Organization of Our Paper  
  2 Background and Motivation  
  2.1 Definitions  
  2.2 Extension of the DLG Iterations  
  2.3 NIRp, Root-Squaring, and Estimation of Extremal Root Radii  
  2.4 NIRp, Root-Squaring, and Recent E/i Tests  
  2.5 Recovery of Complex Roots  
  3 Our Root-Squaring Algorithm  
  3.1 Implementation Details  
  3.2 Analysis  
  4 Experimental Results  
  4.1 Setup  
  4.2 Our Findings  
  4.3 Alternative Bounds on Extremal Root Radii  
  5 Conclusion  
  A Additional Tables  
  References  
  Symbolic-Numerical Algorithm for Solving the Problem of Heavy Ion Collisions in an Optical Model with a Complex Potential  
  1 Introduction  
  2 Optical Model and IWBC Model in the Single-Channel Approximation  
  3 The Optical Model Algorithm  
  4 Benchmark Calculations  
  5 Conclusions  
  References  
  On the Complexity of Linear Algebra Operations over Algebraic Extension Fields  
  1 Introduction  
  2 Preliminaries  
  3 Complexity Results  
  3.1 Multiplication Table  
  3.2 Algebraic Inverse  
  3.3 Gaussian Elimination  
  3.4 Minimal Polynomial  
  4 Notes on Implementation and Experimental Results  
  4.1 Dependence on Matrix Dimension  
  4.2 Dependence on Normal Set Size  
  References  
  Range Functions of Any Convergence Order and Their Amortized Complexity Analysis  
  1 Introduction  
  1.1 Why We Must Extend the CL Framework  
  1.2 Overview  
  1.3 Terminology and Notation  
  2 Generalized CL Framework  
  2.1 Achieving Any Order of Convergence  
  2.2 Strong Box Functions  
  3 A Practical Range Function of Order 4  
  4 Holistic Complexity Analysis of Range Functions  
  4.1 Amortized Complexity of  
  4.2 Amortized Complexity of  
  4.3 Amortized Complexity for Hermite Schemes  
  5 Experimental Results  
  5.1 Non-maximal Recursion Levels  
  6 Conclusions and Future Work  
  References  
  Stability and Zero-Hopf Bifurcation Analysis of the Lorenz–Stenflo System Using Symbolic Methods  
  1 Introduction and Main Results  
  2 Preliminary Results  
  3 Stability Conditions of the Lorenz–Stenflo System  
  4 Zero-Hopf Bifurcation of the Lorenz–Stenflo System  
  5 Zero-Hopf Bifurcation in a Special Lorenz–Stenflo System  
  6 Conclusions  
  References  
  Non-principal Branches of Lambert W. A Tale of 2 Circles  
  1 Introduction  
  1.1 Definitions  
  1.2 Expansions  
  1.3 Branch Structure  
  1.4 Asymptotic Expansions  
  1.5 Outline  
  2 de Bruijn Series for Large z  
  3 de Bruijn Series for Small z  
  4 A Surprising Convergence  
  5 A Further Variation  
  6 Concluding Remarks  
  References  
  On the Qualitative Analysis of the Equations of Motion of a Nonholonomic Mechanical System  
  1 Introduction  
  2 Problem Statement  
  3 On Stationary Sets in the Case of Absence of External Forces  
  4 On Stationary Sets in the Case of the Presence of External Forces  
  5 On Pendulum-Like Motions  
  6 On the Stability of Stationary Sets  
  6.1 The Case of Absence of External Forces  
  6.2 The Case of the Presence of External Forces  
  7 Conclusion  
  References  
  Solving Parametric Linear Systems Using Sparse Rational Function Interpolation  
  1 Introduction  
  2 Sparse Multivariate Rational Function Interpolation  
  2.1 Cuyt and Lee's Algorithm  
  2.2 Using a Kronecker Substitution on the Parameters  
  3 The Algorithm  
  4 Analysis  
  4.1 Failure Probability Analysis  
  4.2 Complexity Analysis  
  5 Implementation and Benchmarks  
  References  
  On the Distance to the Nearest Defective Matrix  
  1 Introduction  
  2 Algebraic Preliminaries  
  3 Complex Matrix  
  4 Real Matrix  
  5 Conclusions  
  References  
  Effective Algorithm for Computing Noetherian Operators of Positive Dimensional Ideals  
  1 Introduction  
  2 Noetherian Operators of Zero Dimensional Ideals  
  3 Mathematical Basics  
  3.1 Extension and Contraction  
  3.2 Noetherian Operators of a Primary Ideal qe K(U)[Y]  
  4 Main Results  
  4.1 Generalization  
  4.2 Comparisons  
  4.3 Computing Noetherian Representations  
  References  
  On the Structure and Generators of Differential Invariant Algebras  
  1 Introduction  
  2 Multi-indices  
  3 The Jet Calculus  
  4 Invariantization  
  5 The Recurrence Formulae  
  6 The Symbolic Invariant Calculus  
  7 The Extended Symbolic Invariant Calculus  
  8 Independence  
  9 Generating Differential Invariants  
  10 The Algorithm  
  References  
  An Algorithm for the Intersection Problem of Planar Parametric Curves  
  1 Introduction  
  2 Reduction Strategy  
  2.1 Reduction Strategy  
  2.2 Preconditioner  
  3 Uniqueness and Existence  
  3.1 An Opposite Monotone System in a Box  
  3.2 How to Transform a System to an Opposite Monotone System in a Box  
  3.3 How to Check the Existence  
  4 Some Singular Cases  
  4.1 Cusp Cases  
  4.2 Self-intersection Cases  
  4.3 Tangential Cases  
  4.4 Mixed Cases  
  5 Algorithm  
  6 Experiments  
  7 Conclusion  
  References  
  A Symbolic-Numeric Method for Solving the Poisson Equation in Polar Coordinates  
  1 Introduction  
  2 The CLS Method for the Numerical Solution of the Poisson Equation in Polar Coordinates  
  3 Computational Results  
  4 Conclusions  
  References  
  Two Variants of Bézout Subresultants for Several Univariate Polynomials  
  1 Introduction  
  2 Preliminaries  
  2.1 The Bézout-Type Subresultant and Its Variants for Two Polynomials  
  2.2 Subresultant in Roots for Several Polynomials  
  3 Main Results  
  4 Proof  
  4.1 Proof of Theorem 2-(1)  
  4.2 Proof of Theorem 2-(2)  
  5 Experimental Results  
  6 Conclusion  
  References  
  Efficient Quotients of Non-commutative Polynomials  
  1 Introduction  
  2 Background  
  2.1 Notation  
  2.2 Division  
  2.3 Whole Shift and Whole Shifted Inverse  
  3 Division in Non-Commutative R[x]  
  3.1 Definitions and Classical Algorithms  
  3.2 Whole Shift and Whole Shifted Inverse in R[x]  
  3.3 Quotients from the Whole Shifted Inverse in R[x]  
  4 Generic Algorithm for the Whole Shifted Inverse  
  5 Non-commutative Polynomial Example  
  6 Division in R[x; , ]  
  6.1 Definitions and Classical Algorithms  
  6.2 Whole Shift and Inverse in R[x; , ]  
  6.3 Quotients from Whole Shifted Inverses in R[x; , ]  
  7 Skew Polynomial Examples  
  7.1 Differential Operators  
  7.2 Difference Operators  
  7.3 Difference Operators with Matrix Coefficients  
  8 Conclusions  
  References  
  Inverse Kinematics and Path Planning of Manipulator Using Real Quantifier Elimination Based on Comprehensive Gröbner Systems  
  1 Introduction  
  2 Inverse Kinematics of a 3-DOF Robot Manipulator  
  3 Real Quantifier Elimination Based on CGS  
  3.1 CGS  
  3.2 Real Root Counting  
  3.3 CGS-QE Algorithm  
  4 Solving the Inverse Kinematic Problem  
  4.1 Removing a Segment Not Existing in R3  
  4.2 Calculating the Number of Real Roots  
  4.3 Calculation for Non-Zero Dimensional Ideals  
  4.4 Experiments  
  5 Path and Trajectory Planning  
  5.1 Path and Trajectory Planning for a Path Expressed as a Function of Time  
  5.2 Trajectory Planning with Verification of the Feasibility of the Inverse Kinematic Solution  
  6 Concluding Remarks  
  References  
  Author Index   
 Citation preview   
  LNCS 14139  
   
  François Boulier · Matthew England · Ilias Kotsireas · Timur M. Sadykov · Evgenii V. Vorozhtsov (Eds.)  
   
  Computer Algebra in Scientific Computing 25th International Workshop, CASC 2023 Havana, Cuba, August 28 – September 1, 2023 Proceedings  
   
  Lecture Notes in Computer Science Founding Editors Gerhard Goos Juris Hartmanis  
   
  Editorial Board Members Elisa Bertino, Purdue University, West Lafayette, IN, USA Wen Gao, Peking University, Beijing, China Bernhard Steffen , TU Dortmund University, Dortmund, Germany Moti Yung , Columbia University, New York, NY, USA  
   
  14139  
   
  The series Lecture Notes in Computer Science (LNCS), including its subseries Lecture Notes in Artificial Intelligence (LNAI) and Lecture Notes in Bioinformatics (LNBI), has established itself as a medium for the publication of new developments in computer science and information technology research, teaching, and education. LNCS enjoys close cooperation with the computer science R & D community, the series counts many renowned academics among its volume editors and paper authors, and collaborates with prestigious societies. Its mission is to serve this international community by providing an invaluable service, mainly focused on the publication of conference and workshop proceedings and postproceedings. LNCS commenced publication in 1973.  
   
  François Boulier · Matthew England · Ilias Kotsireas · Timur M. Sadykov · Evgenii V. Vorozhtsov Editors  
   
  Computer Algebra in Scientific Computing 25th International Workshop, CASC 2023 Havana, Cuba, August 28 – September 1, 2023 Proceedings  
   
  Editors François Boulier University of Lille, CRIStAL Villeneuve d’Ascq, France  
   
  Matthew England Coventry University Coventry, UK  
   
  Ilias Kotsireas Wilfrid Laurier University Waterloo, ON, Canada  
   
  Timur M. Sadykov Plekhanov Russian University of Economics Moscow, Russia  
   
  Evgenii V. Vorozhtsov Institute of Theoretical and Applied Mechanics Novosibirsk, Russia  
   
  ISSN 0302-9743 ISSN 1611-3349 (electronic) Lecture Notes in Computer Science ISBN 978-3-031-41723-8 ISBN 978-3-031-41724-5 (eBook) https://doi.org/10.1007/978-3-031-41724-5 © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2023 This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction on microfilms or in any other physical way, and transmission or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed. The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication does not imply, even in the absence of a specific statement, that such names are exempt from the relevant protective laws and regulations and therefore free for general use. The publisher, the authors, and the editors are safe to assume that the advice and information in this book are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors give a warranty, expressed or implied, with respect to the material contained herein or for any errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. This Springer imprint is published by the registered company Springer Nature Switzerland AG The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland  
   
  Preface  
   
  One of the main goals of the International Workshops on Computer Algebra in Scientific Computing, which started in 1998 and since then have been held annually, is the timely in-depth presentation of progress in all major disciplines of Computer Algebra (CA). The second goal of the CASC Workshops is to bring together both researchers in theoretical computer algebra and engineers as well as other allied professionals applying computer algebra tools for solving problems in industry and in various branches of scientific computing.  
   
  CASC 2023 in Havana, Cuba This year, the 25th CASC conference was organized by the Cuban Society of Mathematics and Computing and the Institute of Cryptography of the University of Havana (UH). A few years ago, symbolic computing and computer algebra were almost non-existent in Cuba, but today there are several groups of professors and researchers who successfully apply the methods and systems of computer algebra to solve various teaching and research tasks. The Programming and Algorithms courses include an introduction to the Python library for symbolic mathematics, SymPy. The Mathematical Analysis and Algebra courses use this knowledge to illustrate advanced concepts in their topics. The Mechanics of Materials research group has used Computer Algebra Systems (CASs), such as Maplesoft’s Maple and Wolfram Mathematica, for the management of tensors and for computations in the calculation of effective properties of composite materials using the asymptotic homogenization method. The Numerical Analysis and Imaging research group has also used the high-precision arithmetic capabilities of Maple in numerical inversions of the Laplace transform for oil well flow problems. In the field of Computer Science and Data Science, various CAS or CAS-type software libraries are used. In these cases, libraries like SymPy or Octave are the most common. Software or software libraries that directly or indirectly use CAS-type libraries, especially in the field of machine learning, are also employed. The Computational Algebra research group at Universidad de Oriente (the Eastern University in the city of Santiago de Cuba, a thousand kilometers away from Havana) works on the study of Gröbner Basis representations associated with linear codes and generalizations, and other related structures such as the set of leading words and the weakly ordered ideal of the linear code. In relation to Cryptography, block encryption attack methodologies have been designed using a genetic algorithm. For this purpose, a collection of programs has been developed in the GAP system that has been called Gröbner Bases for Linear Algebra of Linear Codes, in which a Möller-type algorithm has been implemented to calculate Gröbner representations associated with group code ideals. Group codes include linear codes, binary matroids, and lattice codes. On the other hand, the Maple system has been used to implement block cipher attack methodologies adapting genetic algorithms to this context. At the Center for Complex Systems  
   
  vi  
   
  Preface  
   
  and Statistical Physics in the UH School of Physics, computer simulations (especially the discrete element method) are used for computational experiments in various fields including biologically oriented Physics.  
   
  Participation Options and Reviewing This year, the CASC International Workshop had two categories of participation: (1) talks with accompanying full papers to appear in these proceedings, and (2) talks with accompanying extended abstracts for distribution locally at the conference only. The latter was for work either already published, or not yet ready for publication, but in either case still new and of interest to the CASC audience. The former was strictly for new and original research results or review articles, ready for publication. All submissions received a minimum of three reviews by either program committee members or nominated external reviewers. Reviewing was conducted using the singleblind system, with reviewers anonymous but authors not. The whole PC was invited to comment and debate on all papers after reviews were received. For these proceedings, 29 manuscripts were submitted, which received an average of 3.17 reviews each. After the thorough reviewing process and debates, and in some cases an additional round of peer review, 21 revised papers were accepted for publication in this volume.  
   
  Invited Talks Along with the contributed talks, CASC 2023 had two invited speakers. The invited talk of George Labahn was on the topic of normal forms of integer matrices. Normal forms for integer matrices, such as Hermite and Smith normal forms, have a long history both in terms of algorithms for computation and use in applications. In this talk, a number of algorithms were discussed including two recent approaches for fast Smith normal form computation along with a new algorithm for computation of the Hermite normal form. The new notion of Smith Massager, a relaxed version of a right Smith multiplier, which plays an important role in all three algorithms, was introduced. The invited talk of Roberto Mulet was devoted to the problem of the performance of local search algorithms for K-SAT problems in random graphs. K-SAT is one of the most studied NP-complete problems. Early in this century a new version of this problem received a lot of attention. In this version, the K-SAT Problem is defined through a bipartite random graph. Variables and logical clauses form the nodes of the graph and they are connected if the variable belongs to the clause. The main parameter of the problem is α = M /N , which is the ratio between the number of clauses and the number of variables. When α is small the problem is satisfiable; when α is large it is unsatisfiable. However, for intermediate values of α, the problem becomes statistically hard. Theoretical results, obtained using techniques from the statistical physics of disordered systems, predict a range of α in which most K-SAT problems are still satisfiable, but where local search algorithms cannot find a solution. The talk reviewed these results and tested them showing the actual performance of three different local search algorithms on this problem. The concluding part presented analytical approximations derived from a microscopic theory for the dynamics of these algorithms.  
   
  Preface  
   
  vii  
   
  Overview of Selected Papers The CASC 2023 program covered a wide range of topics. Polynomial algebra, which is at the core of computer algebra, was represented by contributions devoted to the development of new root-squaring algorithms for finding the roots of univariate polynomials, a new algorithm for solving parametric linear systems where the entries of the matrix are polynomials in several parameters with integer coefficients, two new variants of Bézout subresultants for several univariate polynomials, computing GCDs of multivariate polynomials with the aid of a modular algorithm and isomorphisms, the efficient computation of quotients in non-commutative polynomial rings with the CAS Maple, a recently developed algebraic framework for computation with non-commutative polynomials, and the effective algorithm for computing Noetherian operators of positive dimensional ideals. Polynomial computer algebra was also the foundation of the contributions to the present proceedings that exposed a new algorithm for finding the Frobenius distance in the matrix space from a given square matrix to the set of defective matrices, which are the complex matrices with multiple eigenvalues, and a novel approach for handling the intersection of two plane curves defined by rational parametrization involving univariate polynomials. The development of the theory of Gröbner bases and their computer implementation is an outstanding achievement of the twentieth century in the field of polynomial algebra, which also strongly affected the development of Algebraic Geometry. In the present volume, Gröbner bases were used in the development of modular methods for computing Gröbner bases for triangular decomposition, in the stability and zero-Hopf bifurcation analysis of the Lorenz–Stenflo system, and in the study of the complexity of linear algebra operations. Comprehensive Gröbner systems were applied for inverse kinematics computation and path planning of a manipulator. Two papers were devoted to the applications of symbolic-numerical algorithms for solving with the aid of the CAS Maple the problem of heavy ion collisions in an optical model with a complex potential and for solving with the aid of the CAS Mathematica the Poisson equation in polar coordinates. Applications of computer algebra systems in mechanics were represented by the following themes: qualitative analysis of the equations of motion of a nonholonomical mechanical system with the aid of the CAS Mathematica and the study of internal gravity solitary waves in shallow water with the aid of symbolic computations. The remaining topics included the computation of range functions of any convergence order and their amortized complexity analysis, the investigation of non-principal branches of the Lambert W function with the aid of asymptotic expansions, the use  
   
  viii  
   
  Preface  
   
  of the Risch algorithm for symbolic integration to create a dataset of elementary integrable expressions, and the application of computer algebra for generating all differential invariants in differential geometry of Euclidean surfaces in three-dimensional space. July 2023  
   
  François Boulier Matthew England Ilias Kotsireas Timur M. Sadykov Evgenii V. Vorozhtsov  
   
  Acknowledgments  
   
  We want to thank all the members of the CASC 2023 Program Committee for their thorough work in selecting and preparing the technical program. We also thank the external referees who provided reviews as a part of this process. We are grateful to the members of the technical support team headed by Timur Sadykov for their extensive work on the preparation of the camera-ready files for this volume. We owe our deepest gratitude to Dmitry Lyakhov (King Abdullah University of Science and Technology, Kingdom of Saudi Arabia), the publicity chair of the event, for the management of the conference web page (see http://www.casc-conference.org/.) and for the design of the conference poster. Our particular thanks are due to the members of the CASC 2023 local organizing committee at the University of Havana, in particular Luis Ramiro Piñeiro Díaz, Valentina Badía Albanés, and Alejandro Piad Morffis, who ably handled the local arrangements. In addition, Luis Ramiro Piñeiro kindly provided us with the above information about computer algebra activities at the University of Havana and at Universidad de Oriente. Finally, we acknowledge the sponsorship of the CARGO Lab, based in Waterloo, Ontario, Canada, which contributed to the success of CASC 2023 in Havana.  
   
  Organization  
   
  General Chairs François Boulier Ilias Kotsireas Timur M. Sadykov  
   
  Université de Lille, France Wilfrid Laurier University, Canada Plekhanov Russian University of Economics, Russia  
   
  Program Committee Chairs Matthew England Chenqi Mou Evgenii V. Vorozhtsov  
   
  Coventry University, UK Beihang University, China Khristianovich Institute of Theoretical and Applied Mechanics, Russia  
   
  Program Committee Tulay Ayyildiz Akoglu François Boulier Changbo Chen Jin-San Cheng Victor F. Edneral Matthew England Jaime Gutierrez Sergey Gutnik Amir Hashemi Gabriela Jeronimo Rui-Juan Jing Fatma Karaoglu Ilias Kotsireas Wen-Shin Lee François Lemaire Viktor Levandovskyy Marc Moreno Maza Dominik L. Michels  
   
  Karadeniz Technical University, Turkey University of Lille, France Chinese Academy of Sciences, China Academy of Mathematics and Systems Science, China Lomonosov Moscow State University, Russia Coventry University, UK University of Cantabria, Spain Moscow State Inst. of International Relations, Russia Isfahan University of Technology, Iran University of Buenos Aires, Argentina Jiangsu University, China Gebze Technical University, Turkey Wilfrid Laurier University, Canada University of Stirling, UK University of Lille, France University of Kassel, Germany University of Western Ontario, Canada KAUST, Saudi Arabia  
   
  xii  
   
  Organization  
   
  Chenqi Mou Sonia Perez-Diaz Veronika Pillwein Alexander Prokopenya Hamid Rahkooy Daniel Robertz Timur Sadykov Svetlana Selivanova Ekaterina Shemyakova Thomas Sturm Bertrand Teguia Tabuguia Akira Terui Ali Kemal Uncu Jan Verschelde Evgenii V. Vorozhtsov  
   
  Beihang University, China Universidad de Alcalá, Spain JKU Linz, Austria Warsaw University of Life Sciences, Poland University of Oxford, UK RWTH Aachen, Germany Plekhanov Russian University, Russia KAIST, South Korea University of Toledo, USA CNRS, France Max Planck Institute for Mathematics in the Sciences, Germany University of Tsukuba, Japan University of Bath, UK, and Austrian Academy of Sciences RICAM, Austria University of Illinois, USA Khristianovich Institute of Theoretical and Applied Mechanics, Russia  
   
  Local Organization Luis Ramiro Piñeiro Díaz Valentina Badía Albanés Alejandro Piad Morffis  
   
  University of Havana, Cuba University of Havana, Cuba University of Havana, Cuba  
   
  Publicity Chair Dmitry Lyakhov  
   
  KAUST, Saudi Arabia  
   
  Advisory Board Wolfram Koepf Ernst W. Mayr Werner M. Seiler  
   
  Website http://casc-conference.org/. (Webmaster: Timur Zhukov)  
   
  Universität Kassel, Germany Technische Universität München, Germany Universität Kassel, Germany  
   
  Abstracts of Invited Talks  
   
  Normal Forms of Integer Matrices  
   
  George Labahn Cheriton School of Computer Science, University of Waterloo, Ontario N2L-2T6, Waterloo, Canada [email protected]  Abstract. Normal forms for integer matrices, such as Hermite and Smith normal forms, have a long history both in terms of algorithms for computation and use in applications. In this talk we discuss a number of algorithms including two recent approaches for fast Smith normal form computation along with a new algorithm for computation of the Hermite normal form. The new notion of Smith Massager, a relaxed version of a right Smith multiplier, plays an important role in all three algorithms. Keywords: Hermite form · Smith form · Matrix multiplication  
   
  1 Introduction Let A ∈ Z n×n be a nonsingular integer matrix. There are two well known normal forms corresponding to transforming A into triangular and diagonal form. For triangularization one has the (row) Hermite normal form H where one has a unimodular matrix U ∈ Z n×n such that ⎤ ⎡ h1 h12 · · · h1n ⎢ h2 · · · h2n ⎥ ⎥ ⎢ H = UA = ⎢ . . .. ⎥ ⎣ . . ⎦ hn with all the entries of H being nonnegative, and with off-diagonal entries h*j being strictly smaller than the diagonal entry hj in the same column. The Hermite normal form of A is unique (as is U since A is nonsingular) with its existence dating back to Hermite [12] in 1851. The matrix U represents the row operations required to put A into the triangular form. There are also other variations such as lower triangular or column rather than row forms (with the unimodular matrix U then being on the right). In the case of diagonalization, there is the Smith normal form S where one has unimodular matrices U , V ∈ Z n×n with  
   
  xvi  
   
  G. Labahn  
   
  ⎡ ⎢ ⎢ UAV = S = ⎢ ⎣  
   
  ⎤  
   
  S1 S2  
   
  ..  
   
  ⎥ ⎥ ⎥ ∈ Z n×n ⎦  
   
  . Sn  
   
  and where si |si+1 for all i. The Smith normal form dates back to Smith [20] in 1861, with U and V describing the row and column operations transforming A into diagonal form. In this case the multipliers U , V are not unique. The Hermite and Smith forms have numerous applications. This includes solving systems of linear and linear diophantine equations [7], integer programming [19] and determining rational invariants and rewriting rules of scaling invariants [13], to name just a few. In the latter application, the Hermite forms transform the integer exponents of multivariate terms. The Smith form applied to a matrix of relations for an abelian group tells how to classify the group into a direct sum of cyclic groups [8,18]. Other applications include those in combinatorics [21] and integration quadrature rules [17]. History of Computation: Algorithms for computing the Hermite normal forms were initially based on triangularizing the input matrix using variations of Gaussian elimination that used the extended Euclidean algorithm to eliminate entries below the diagonal. However, such methods can be prone to exponential expression swell, that is, the problem of rapid growth of intermediate integer operands. The first algorithm which was provably polynomial time was given by [16]. This was followed by an algorithm of [7] 1+o(1)  bit operations1 , with A denoting the which gave a running time of n6 log ||A|| 1+o(1)  . largest entry of A in absolute value [9,14,11] later improved these to n4 log ||A|| 1+o(1)  ω+1 log ||A|| New algorithms in [24] and then [22] subsequently reduced this to n bit operations. Here ω is the exponent of matrix multiplication, with ω < 2.37286 being the current best known upper bound given by [1]. Early algorithms for Smith form computation such as [20] and [6] were also modelled on Gaussian elimination where greatest common divisors and the associated solutions of linear diophantine equations replaced division. These have been replaced by faster methods including those of . Recent fast methods includes that of and [15,22]. The latter algorithm computes both the Smith form and unimodular multiplier matrices U and V satisfying AV = US while the former computes the Smith form S alone. It does this by combining a Las Vegas algorithm for computing the characteristic polynomial with ideas 1+o(1)  of, to obtain a Monte Carlo algorithm for the Smith form in time n2.695591 log A assuming the currently best upper bound for ω. Recent Results. A natural goal for many computations on integer matrices is to design algorithms that have about the same cost as multiplying together two matrices of the same dimension and size of entries as the input matrix, a target complexity therefore being (nω log ||A||)1+o(1) bit operations. Examples where this has been the case include a Las  
   
  1 The exponent 1 + o(1) indicates some missing logn and loglog ||A|| factors  
   
  Normal Forms of Integer Matrices  
   
  xvii  
   
  Vegas probabilistic algorithm for determinant computation [23] and a recent deterministic algorithm for integer linear system solving by [2], both of which utilize a “dimension × precision ≤ invariant” compromise. In the case of Smith form there are two new algorithms, both probabilistic of Las Vegas type. The algorithm in [3] computes only the Smith form while the second algorithm in [4], computes both the Smith form and its multiplier, both in time (nω log A)1+o(1) . The latter is somewhat surprising as the Smith form with multiplier problem has long been considered to be more challenging than just computing the Smith form alone, at least in practical computations. This is somewhat similar to comparing the problem of solving an Extended Euclidean problem for computing a gcd versus just solving the gcd problem alone. In the case of Hermite forms the reduction to matrix multiplication has not been achieved. However there is a new Las Vegas algorithm for Hermite form computation 1+o(1)  using standard integer and matrix [5] with running time bounded by n3 log ||A|| arithmetic, giving the first significant improvement in the computational complexity of computing the Hermite form in the last 25 years. In this talk we give some details on how these recent new algorithms for Hermite, Smith and Smith with multiplier problems.  
   
  References 1. Alman, J., Williams, V.V.: A refined laser method and faster matrix multiplication. In: Proceedings of the 2021 ACM-SIAM Symposium on Discrete Algorithms (SODA), pp. 522–539 (2021) 2. Birmpilis, S., Labahn, G., Storjohann, A.: Deterministic reduction of integer nonsingular linear system solving to matrix multiplication, In: Proceedings of the 2019 on International Symposium on Symbolic and Algebraic Computation: ISSAC’19, pages 58-65, New York, NY, USA, ACM (2019) 3. Birmpilis, S., Labahn, G., Storjohann, A.: A Las Vegas algorithm for computing the Smith form of a nonsingular integer matrix. In : Proceedings of the 2019 on International Symposium on Symbolic and Algebraic Computation: ISSAC’20, pages 38-45, New York, NY, USA, ACM (2020) 4. Birmpilis, S., Labahn, G., Storjohann, A.: A fast algorithm for computing the Smith normal form with multipliers for a nonsingular integer matrix. J. Symbolic Comput. 116, 146–182 (2023) 5. Birmpilis, S., Labahn, G., Storjohann, A.: A cubic algorithm for computing the Hermite normal form of a nonsingular integer matrix (2023). https://arxiv.org/abs/ 2209.10685 6. Bradley, G.H.: Algorithm and bound for the greatest common divisor of n integers. Commun. ACM 13(7):433–436, July 1970. 7. Chou, T.-W.J., Collins, G.E.: Algorithms for the solutions of systems of linear diophantine equations. SIAM J. Comput. 11, 687–708 (1982) 8. Cohen, H.: A Course in Computational Algebraic Number Theory. Springer-Verlag (1996). https://doi.org/10.1007/978-3-662-02945-9 9. Domich, P.D., Kannan, R., Trotter, L.E.: Jr. ermite normal form computation using modulo determinant arithmetic. Math. Oper. Res. 12(1), 50–59 (1987)  
   
  xviii  
   
  G. Labahn  
   
  10. Giesbrecht, M.: Fast computation of the Smith form of a sparse integer matrix. Comput. Complex. 10(1), 41–69 (2001) 11. Hafner, J.L., McCurley, K.S.: A rigorous subexponential algorithm for computation of class groups. J. Amer. Math. Soc. 2, 837–850 (1989) 12. Hermite, C.: Sur l’introduction des variables continues dans la théorie des nombres. J. Reine Angew. Math., 41, 191–216 (1851) 13. Hubert, E., Labahn, G.: Scaling invariants and symmetry reduction of dynamical systems. Found. Comput. Math. 13(4), 479–516 (2013) 14. Iliopoulos, C.S.: Worst-case complexity bounds on algorithms for computing the canonical structure of finite abelian groups and the Hermite and Smith normal forms of an integer matrix. SIAM J. Comput. 18(4), 658–669 (1989) 15. Kaltofen, E., Villard, G.: On the complexity of computing determinants. Comput. Complex. 13(3–4), 91–130 (2005) 16. Kannan, R., Bachem, A.: Polynomial algorithms for computing the Smith and Hermite normal forms of an integer matrix. SIAM J. Comput. 8(4), 499–507 (1979) 17. Lyness, J.N., Keast, P.: Application of the smith normal form to the structure of lattice rules. SIAM J. Matrix Anal. Appl. 16 (1), 218–231 (1995) 18. Newman, M.: The Smith normal form. Linear Algebra Appl. 254, 367–381 (1997) 19. Schrijver, A.: Theory of Linear and Integer Programming. John Wiley and Sons (1998) 20. Smith, H.J.S.: On systems of linear indeterminate equations and congruences. Phil. Trans. Roy. Soc. London, 151, 293–326 (1861) 21. Stanley, R.: Smith normal form in combinatorics. J. Comb. Theory Series A 144, 476–495 (2016) 22. Storjohann, A.: Algorithms for Matrix Canonical Forms. PhD thesis, Swiss Federal Institute of Technology, ETH–Zurich, 2000. 23. Storjohann, A.: The shifted number system for fast linear algebra on integer matrices. J. Complex. 21(4), 609–650 (2005). Festschrift for the 70th Birthday of Arnold Schönhage. 24. Storjohann, A., Labahn, G.: Asymptotically fast computation of Hermite normal forms of integer matrices. In: Lakshman, Y.N., eds., In Proceedings of the 1996 international symposium on Symbolic and algebraic computation: ISSAC’96, pp. 259–266. ACM Press, New York (1996)  
   
  On the Performance of Local Search Algorithms for K-SAT Problems in Random Graphs  
   
  Roberto Mulet University of Havana, Cuba [email protected]  K-SAT is one of the most studied NP-complete problems. Early this century a new version of this problem received a lot of attention. In this version the K-SAT is defined through a bipartite random graph. Variables and logical clauses form the nodes of the graph and they are connected if one variable belongs to one clause. The main parameter of the problem is α = M /N the ratio between the number of clauses and the number of variables. When α is small the problem is satisfiable, when α is large it is unsatisfiable. However, for intermediate values of α the problem becomes statistically hard. Theoretical results, obtained using techniques from the statistical physics of disordered systems, predict a range of α in which most K-SAT problems are still satisfiable, but where local search algorithms can’t find a solution. In this talk I will review these results and test them showing the actual performance of three different local search algorithms on this problem. I will conclude by presenting analytical approximations, derived from a microscopic theory, for the dynamics of these algorithms.  
   
  Contents  
   
  Computing GCDs of Multivariate Polynomials over Algebraic Number Fields Presented with Multiple Extensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Mahsa Ansari and Michael Monagan Generating Elementary Integrable Expressions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Rashid Barket, Matthew England, and Jürgen Gerhard How to Automatise Proofs of Operator Statements: Moore–Penrose Inverse; A Case Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Klara Bernauer, Clemens Hofstadler, and Georg Regensburger A Modular Algorithm for Computing the Intersection of a One-Dimensional Quasi-Component and a Hypersurface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Alexander Brandt, Juan Pablo González Trochez, Marc Moreno Maza, and Haoze Yuan Certified Study of Internal Solitary Waves . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . André Galligo and Didier Clamond  
   
  1  
   
  21  
   
  39  
   
  69  
   
  90  
   
  Root-Squaring for Root-Finding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107 Soo Go, Victor Y. Pan, and Pedro Soto Symbolic-Numerical Algorithm for Solving the Problem of Heavy Ion Collisions in an Optical Model with a Complex Potential . . . . . . . . . . . . . . . . . . . . 128 A. A. Gusev, O. Chuluunbaatar, V.L. Derbov, R.G. Nazmitdinov, S.I. Vinitsky, P.W. Wen, C.J. Lin, H. M. Jia, and L. L. Hai On the Complexity of Linear Algebra Operations over Algebraic Extension Fields . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141 Amir Hashemi and Daniel Lichtblau Range Functions of Any Convergence Order and Their Amortized Complexity Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162 Kai Hormann, Chee Yap, and Ya Shi Zhang Stability and Zero-Hopf Bifurcation Analysis of the Lorenz–Stenflo System Using Symbolic Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183 Bo Huang, Xiaoliang Li, Wei Niu, and Shaofen Xie  
   
  xxii  
   
  Contents  
   
  Non-Principal Branches of Lambert W. A Tale of Two Circles . . . . . . . . . . . . . . . 199 Jacob Imre and David J. Jeffrey On the Qualitative Analysis of the Equations of Motion of a Nonholonomic Mechanical System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213 Valentin Irtegov and Tatiana Titorenko Solving Parametric Linear Systems Using Sparse Rational Function Interpolation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233 Ayoola Jinadu and Michael Monagan On the Distance to the Nearest Defective Matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . 255 Elizaveta Kalinina, Alexei Uteshev, Marina Goncharova, and Elena Lezhnina Effective Algorithm for Computing Noetherian Operators of Positive Dimensional Ideals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272 Katsusuke Nabeshima and Shinichi Tajima On the Structure and Generators of Differential Invariant Algebras . . . . . . . . . . . 292 Peter J. Olver An Algorithm for the Intersection Problem of Planar Parametric Curves . . . . . . . 312 Ling Tan, Bo Li, Bingwei Zhang, and Jin-San Cheng A Symbolic-Numeric Method for Solving the Poisson Equation in Polar Coordinates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 330 Evgenii V. Vorozhtsov Two Variants of Bézout Subresultants for Several Univariate Polynomials . . . . . 350 Weidong Wang and Jing Yang Efficient Quotients of Non-commutative Polynomials . . . . . . . . . . . . . . . . . . . . . . . 370 Stephen M. Watt Inverse Kinematics and Path Planning of Manipulator Using Real Quantifier Elimination Based on Comprehensive Gröbner Systems . . . . . . . . . . . 393 Mizuki Yoshizawa, Akira Terui, and Masahiko Mikawa Author Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 421  
   
  Computing GCDs of Multivariate Polynomials over Algebraic Number Fields Presented with Multiple Extensions Mahsa Ansari(B) and Michael Monagan Department of Mathematics, Simon Fraser University, Burnaby, BC V5A 1S6, Canada {mansari,mmonagan}@sfu.ca Abstract. Let Q(α1 , · · · , αn ) be an algebraic number ﬁeld. In this paper, we present a modular gcd algorithm for computing the monic gcd, g, of two polynomials f1 , f2 ∈ Q(α1 , . . . , αn )[x1 , . . . , xk ]. To improve the eﬃciency of our algorithm, we use linear algebra to ﬁnd an isomorphism between Q(α1 , . . . , αn ) and Q(γ), where γ is a primitive element of Q(α1 , . . . , αn ). This conversion is performed modulo a prime to prevent expression swell. Next, we use a sequence of evaluation points to convert the multivariate polynomials to univariate polynomials, enabling us to employ the monic Euclidean algorithm. We currently use dense interpolation to recover x2 , . . . , xk in the gcd. In order to reconstruct the rational coeﬃcients in g, we apply the Chinese remaindering and the rational number reconstruction. We present an analysis of the expected time complexity of our algorithm. We have implemented our algorithm in Maple using a recursive dense representation for polynomials. Keywords: Polynomial greatest common divisors · Modular GCD algorithms · Algebraic number ﬁelds · Primitive elements  
   
  1 1.1  
   
  Introduction Motivation for the Algorithm  
   
  Computing the gcd of polynomials is a fundamental problem in Computer Algebra, and it arises as a subproblem in many applications. For instance, computing the gcd of two polynomials plays a prominent role in polynomial factorization [14]. While the Euclidean algorithm is one of the most important algorithms for computing the gcd of two polynomials, it has a fundamental ﬂaw for problems arising over R[x] where R is not a ﬁnite ﬁeld, namely, the size of the coeﬃcients of the remainders in the Euclidean algorithm grows signiﬁcantly. Especially, the Euclidean algorithm is slow when the degree of the gcd is much smaller than the degree of the inputs. The worst case occurs when the gcd of the inputs is 1. This ineﬃciency has led computer algebraists to develop modular gcd algorithms. Collins [3] (for univariate polynomials) and Brown [2] (for c The Author(s), under exclusive license to Springer Nature Switzerland AG 2023  F. Boulier et al. (Eds.): CASC 2023, LNCS 14139, pp. 1–20, 2023. https://doi.org/10.1007/978-3-031-41724-5_1  
   
  2  
   
  M. Ansari and M. Monagan  
   
  multivariate polynomials) developed an algorithm to compute gcds by applying homomorphic reductions and Chinese remaindering. Through homomorphic reduction, they converted the gcd problem over Z to a simpler domain Zp where the coeﬃcients do not grow. Let α and α1 , . . . , αn be algebraic numbers. In 1989, Langemyr and MaCallum [7] designed a modular gcd algorithm for Q(α)[x]. In 1989 Smedley [13], using a diﬀerent approach, designed a modular gcd algorithm for Q(α)[x1 , . . . , xk ]. In 1995, Encarnacion [4] used rational number reconstruction [9,18] to make Langemyr and MaCallum’s algorithm for Q(α)[x] output sensitive. In 2002, Monagan and Van Hoeij [17] generalized Encarnacion’s algorithm to treat polynomials in Q(α1 , · · · , αn )[x] for n ≥ 1. In 2009 Li, Moreno Maza and Schost [8] used the FFT to speed up arithmetic in Q(α1 , · · · , αn ) modulo a prime in Monagan and Van Hoeij’s algorithm. State of the art algorithms for computing primitive element representations of triangular sets in softly linear time includes the works of Poteaux and Schost [11,12]. State of the art algorithms for computing in algebraic towers in softly linear time includes the work of van der Hoeven and Lecerf [15,16]. Building upon this previous work, our modular gcd algorithm, called MGCD, computes the monic gcd of two polynomials f1 , f2 ∈ Q(α1 , . . . , αn )[x1 , . . . , xk ] where n ≥ 1 and k ≥ 1. It is the ﬁrst modular gcd algorithm that speeds up the computation by mapping Q(α1 , · · · , αn ) to Q(γ) where γ is a primitive element. 1.2  
   
  Preliminaries  
   
  First, we explain relevant details and notations. Let Q(α1 , · · · , αn ) be our number ﬁeld. We build the ﬁeld L as follows. Let L0 = Q. For i = 1, 2, . . . , n let Li = Li−1 [zi ]/Mi (zi ) where Mi (zi ) is the monic minimal polynomial nof αi over Li−1 . Let L = Ln . The ﬁeld L is a Q-vector space of dimension d = i=1 di where di = deg(Mi , zi ). Furthermore, n BL = { i=1 (zi )ei | 0 ≤ ei < di } ∼ Q(α1 , · · · , αn ), we can perform computation over is a basis of L. Since L = Q(α1 , · · · , αn ) by replacing α1 , . . . , αn with variables z1 , . . . , zn , respectively, and then doing the computation over L. In our algorithm, we suppose that we are (zn ) of the algebraic numbers given the minimal polynomials M1 (z1 ), . . . , Mn α1 , . . . , αn so that we can construct L. If f = ei ∈Zk aei X ei ∈ L[x1 , . . . , xk ], ≥0 d then aei = j=1 Cei j bj for bj ∈ BL and Cei j ∈ Q. We deﬁne the coordinate vector of f w.r.t B L as the vector of dimension d, denoted by [f ]BL =  [v1 , . . . , vd ]T , where vj = ei ∈Zk Cei j X ei . ≥0  
   
  Example 1. We are given the ﬁeld L = Q[z1 , z2 ]/z12 − 2, z22 − 3 with basis BL = {1, z2 , z1 , z1 z2 }. If f = 2z1 x+y+z1 +z1 z2 ∈ L[x, y], then [f ]BL = [y, 0, 2x+1, 1]T . Let R be a commutative ring with identity 1 = 0. Let us ﬁx a monomial ordering in R[x1 , . . . , xk ]. Let f ∈ R[x1 , . . . , xk ] and let lc(f ) denote the leading coeﬃcient of f and lm(f ) denote the leading monomial of f . If f = 0 we deﬁne  
   
  Computing the GCDs of Multivariate Polynomials  
   
  3  
   
  monic(f ) = 0. If f = 0 and lc(f ) is a unit in R then monic(f ) = lc(f )−1 f . Otherwise, monic(f ) = f ailed. Let f1 , f2 ∈ R[x1 , . . . , xk ] and suppose a monic g = gcd(f1 , f2 ) exists. Then g is unique and there exist polynomials p and q such that f1 = p · g and f2 = q · g. We call p and q the cofactors of f1 and f2 . Example 2. Let L be as in Example 1 and f1 = (z2 x+z1 y)(x+y) and f2 = (z2 x+ z1 y)(x − y) be polynomials in L[x, y]. By inspection, z2 x + z1 y is a gcd(f1 , f2 ). In lexicographical order with x > y we have lc(f1 ) = z2 , lm(f1 ) = x2 and the monic gcd(f1 , f2 ) is x + 13 z1 z2 y. Let LZ = Z[z1 , . . . , zn ]. For any f ∈ L[x], the denominator of f , denoted by den(f ), is the smallest positive integer such that den(f )f ∈ LZ [x]. In addition, the associate of f is deﬁned as f˜ = den(h)h where h = monic(f ). The semiassociate of f , denoted by fˇ, is deﬁned as rf , where r is the smallest positive rational number for which den(rf ) = 1. Example 3. Let L be as in Example 1 and f = 32 z1 x + z2 ∈ L[x]. Then den(f ) = 2, fˇ = 3z1 x + 2z2 , monic(f ) = x + 13 z1 z2 and f˜ = 3x + z1 z2 . To improve computational eﬃciency, in a preprocessing step, our modular gcd algorithm MGCD ﬁrst clears fractions by replacing the input polynomials f1 and f2 with their semi-associates. Computing associates can be expensive when lc(f1 ) and lc(f2 ) are complicated algebraic numbers. Thus, we prefer to use semiassociates instead of associates to remove fractions. Then, MGCD computes gcd(f1 , f2 ) modulo a sequence of primes. n ˇ i ) · lc(fˇ1 ). Let mi (zi ) = Definition 1. Let p be a prime such that p  i=1 lc(M Mi mod p for 1 ≤ i ≤ n. Deﬁne Lp = Zp [z1 , . . . , zn ]/m1 , . . . , mn . Lp is a ﬁnite ring with pd elements which likely has zero divisors. We give an example of MGCD to illustrate the treatment of zero-divisors in Lp and to motivate the use a primitive element. Example 4. We continue Example 2 where L = Q[z1 , z2 ]/z12 − 2, z22 − 3, f1 = (z2 x + z1 y)(x + y), f2 = (z2 x + z1 y)(x − y) and g = x + 13 z1 z2 y is the monic gcd(f1 , f2 ). Suppose MGCD picks p = 3. Then m1 = z12 + 1, m2 = z22 and L3 = Z3 [z1 , z2 ]/ z12 + 1, z22 . Notice that z2 is a zero divisor in L3 . Next, MGCD picks an evaluation point α ∈ Zp and attempts to compute gcd(f1 (x, α), f2 (x, α)) in L3 [x] using the monic Euclidean algorithm (MEA) (see [17]). The MEA will try to compute r1 = monic(f2 (x, α)) and then divide r0 = f1 (x, α) by r1 but monic(f2 (x, α)) fails as lc(f2 (x, α)) = z2 is a zero-divisor in L3 . Since MGCD does know whether this is because of the choice of p or α, it stops the computation of gcd(f1 , f2 ) modulo p = 3 and tries another prime, for example, p = 5. We have L5 = Z5 [z1 , z2 ]/ z12 + 3, z22 + 2 .  
   
  4  
   
  M. Ansari and M. Monagan  
   
  Once again, MGCD chooses α ∈ Z5 and computes gcd(f1 (x, α), f2 (x, α)) in L5 [x] using the MEA. This time lc(f2 (x, α)) = z2 is a unit in L5 with inverse 2z2 and monic(f2 (x, α)) succeeds. The MEA also succeeds and outputs g5 = x + 2αz1 z2 . Notice g5 = g(x, α) mod 5. MGCD repeats this process for more α’s and primes and recovers g = x + 13 z1 y using polynomial interpolation for y and Chinese remaindering and rational number reconstruction [9,18] for the fraction 13 . Most of the computational work in MGCD occurs in the ﬁnite ring Lp . To speed up MGCD we use a primitive element to speed up arithmetic in Lp . We note that our Maple implementation of MGCD uses 31-bit primes which avoids zero divisors in Lp with high probability. 1.3  
   
  Paper Outline  
   
  Our paper is organized as follows. In Sect. 2, we use the fact that Q(α1 , . . . , αn ) can be speciﬁed as a Q-vector space to compute a primitive element γ for Q(α1 , . . . , αn ). We also construct a ring isomorphism φγ between the quotient ¯ p = Zp [z]/M (z) where p is a prime and M (z) ∈ Zp [z] is the rings Lp and L minimal polynomial for γ mod p. In our modular gcd algorithm, we apply φγ to speed up arithmetic in Lp . In Sect. 3, we describe the PGCD algorithm for com¯ p [x1 , . . . , xk ], where k ≥ 2. puting the monic gcd of two polynomials f1 , f2 ∈ L We then present our modular gcd algorithm, MGCD. In Sect. 4, we study the expected time complexity of our MGCD algorithm. Finally, in Sect. 5, we present an implementation of our algorithm in Maple which uses the recursive dense polynomial data structure described in [17]. We then present a timing benchmark for running Algorithm MGCD. Our Maple code is available at http://www.cecm. sfu.ca/∼mmonagan/code/MGCD.  
   
  2  
   
  Converting Q(α1 , . . . , αn ) to a Single Extension Q(γ)  
   
  The main goal of this section is to identify a primitive element for Q(α1 , . . . , αn ) called γ and compute its minimal polynomial. We then proceed to reduce the computation of ﬁnding γ modulo a prime p, which allows us to form the quotient ¯ p = Zp [z]/M (z) where M (z) is the minimal polynomial of γ modulo p. ring L ¯ p , we determine the ring isomorphism φγ : Lp −→ Once we have constructed L ¯ p . We use φγ in our MGCD algorithm to map a polynomial over the multiple L ¯p. extension Lp to its corresponding polynomial over the simple extension L 2.1  
   
  Computing a Primitive Element and its Minimal Polynomial  
   
  In order to ﬁnd a primitive element for Q(α1 , . . . , αn ), we start by choosing ranprime. Using dom integers C1 , . . . , Cn−1 from the interval [1, p), where p is a large n these integers, we create a potential primitive element γ = α1 + i=2 Ci−1 αi . To determine whether γ is a primitive element or not we use Theorem 1.  
   
  Computing the GCDs of Multivariate Polynomials  
   
  5  
   
  Theorem 1. Let Q(α1 , . . . , αn ) have degree d and let C1 , . . . , Cn−1 Z be cho∈ n sen randomly from [1, p) where p is a large prime. Deﬁne γ = α1 + i=2 Ci−1 αi , and let B be a basis for Q(α1 , . . . , αn ) as a Q-vector space. Let A be the d × d matrix whose ith column is [γ i−1 ]B for 1 ≤ i ≤ d. Then, γ is a primitive element for Q(α1 , · · · , αn ) ⇐⇒ det(A) = 0. Proof. (=⇒) If γ is a primitive element for Q(α1 , . . . , αn ), then we have [Q(γ) : Q] = [Q(α1 , . . . , αn ) : Q] = d. Let BK = {1, γ, . . . , γ d−1 } be a basis for K = Q(γ) as a Q-vector space. Since Q(α1 , . . . , αn ) = K, any element of BK can be expressed as a linear combination of elements of B. Thus, the d × d linear system 1 = c11 b1 + c12 b2 + . . . + c1d bd γ = c21 b1 + c22 b2 + . . . + c2d bd ... γ  
   
  d−1  
   
  = cd1 b1 + cd2 b2 + . . . + cdd bd  
   
  has a unique solution. We can form the d × d matrix D, whose ith row is [γ i−1 ]TB for 1 ≤ i ≤ d. Since the above system of equations has a unique solution, the matrix D is invertible, and thus det(D) = 0. On the other hand, D = AT so 0 = det(D) = det(AT ) = det(A). (⇐=) Given det(A) = 0, we can conclude that A is invertible and the linear system A · q = −[γ d ]B has a unique solution q = [q1 , . . . , qd ]T . If we prove that the polynomial of degree d M (z) = z d +  
   
  d   
   
  qi z i−1  
   
  i=1  
   
  is the minimal polynomial of γ, then [Q(γ) : Q] = [Q(α1 , . . . , αn ) : Q] = d which implies that γ is a primitive element as required. By construction, M (z) is monic, deg(M (z)) = d, and M (γ) = 0. Hence, we only need to prove that M (z) is irreducible over Q. Suppose that M (z) is reducible. Since Q[z] is a UFD, M (z) can be expressed as a product of monic irreducible polynomials over Q, i.e. M (z) = p1 (z) · · · pk (z) where each pi (z) ∈ Q[z] is irreducible for 1 ≤ i ≤ n. Since M (γ) = 0, there exists 1 ≤ i ≤ k such that pi (γ) = 0 which implies that pi (z) is the minimal polynomial of γ. Let deg(pi (z)) = h so {1, γ, . . . , γ h−1 } forms a basis for Q(γ). Hence, {1, γ, . . . , γ d−1 } ⊆ Span({1, γ, . . . , γ h−1 }) where h < d. That is, the set {1, γ, . . . , γ d−1 } is a linearly dependant set, equivalently, the matrix A has two or more linearly dependent columns which means det(A) = 0. This contradicts the assumption that det(A) = 0. Therefore, M (z) must be irreducible over Q, and hence it is the minimal polynomial of γ. We can employ Theorem 1 to compute the minimal polynomial of the primitive element γ.  
   
  6  
   
  M. Ansari and M. Monagan  
   
  Corollary 1. Under the assumptions of Theorem 1, if det(A) = 0 and q = [q1 , . . . , qd ]T be the solution of the linear system A · q = −[γ d ]B , the polynomial d M (z) = z d + i=1 qi z i−1 is the minimal polynomial of γ. Proof. Corollary 1 follows directly from the proof of Theorem 1. We n present Algorithm 1, LAminpoly, which is used to verify if γ = α1 + i=2 Ci−1 αi , where Ci ∈ Z for 2 ≤ i ≤ n, is a primitive element for Q(α1 , . . . , αn ). LAminpoly can be run over two diﬀerent ground ﬁelds: F = Q and F = Zp , where p is a prime. If LAminpoly does not fail over F = Q, according to Theorem 1 and Corollary 1, γ is a primitive element for Q(α1 , . . . , αn ) and the output M (z) is the minimal polynomial of γ. In the following example, we execute the LAminpoly algorithm over F = Q. Algorithm 1: LAminpoly  
   
  1 2 3 4 5 6 7 8 9 10 11 12 13  
   
  Input: A list of the minimal polynomials [M1 (z1 ), . . . , Mn (zn )], the ground ﬁeld F over which the computation is performed, and γ = z1 + C1 z2 + . . . + Cn−1 zn where Ci ∈ Z for 1 ≤ i ≤ n − 1 Output: Either a message “FAIL” or a polynomial M (z) ∈ F [z] such that (γ) = 0, the matrix A and A−1 . M n ei BL = { i=1 (zi ) 0 ≤ ei < di } s.t di = deg(Mi (zi )) // A basis for L d= n d i=1 i Initialize A to be a d × d zero matrix over F . g0 = 1 for i = 1 to d do Set column i of A to be [gi−1 ]BL gi = γ · gi−1 if det(A) = 0 then return(FAIL) Compute A−1 Solve the d × d linear system A · q = −[gd ]BL for q Construct the polynomial M (z) := q1 + q2 z + . . . + qd z d−1 + z d return( M (z), A, A−1 )  
   
  √ Example 5. Let M1 (z1 ) = z12 − 2 be the minimal polynomial of 2 over Q and √ M2 (z2 ) = z22 − 3 be the minimal polynomial of 3 over Q[z1 ]/z12 − 2. Let L = Q[z1 , z2 ]/z12 − 2, z22 − 3. Let C1 = 1 so that γ = z1 + z2 . We wish to test if γ is a primitive element. Let BL = {1, z2 , z1 , z1 z2 } and BK = {1, z, z 2 , z 3 } be the bases for L and K = Q[z]/M (z) respectively, where M (z) is the minimal polynomial of γ. Let ai = [γ i ]BL be the coordinate vector of γ i relative to BL for 0 ≤ i ≤ 4. Then we have ⎡ ⎤ ⎡ ⎤ ⎡ ⎤ ⎡ ⎤ ⎡ ⎤ 1 0 5 0 49 ⎢0⎥ ⎢1⎥ ⎢0⎥ ⎢ 9 ⎥ ⎢ 0 ⎥ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ ⎢ ⎥ a0 , a1 , a2 , a3 , a4 = ⎢ ⎣0⎦ , ⎣1⎦ , ⎣0⎦ , ⎣11⎦ , ⎣ 0 ⎦ . 0 0 2 0 20  
   
  Computing the GCDs of Multivariate Polynomials  
   
  7  
   
  The coeﬃcient matrix A is the 4×4 matrix containing a0 , a1 , a2 , a3 as its columns ⎤ ⎡ 1 0 0 − 25 ⎡ ⎤ 105 0 ⎥ ⎢ 11 9 ⎢0 −2 0 ⎥ ⎢0 1 0 9 ⎥ 2 ⎥ ⎢ −1 ⎥ A=⎢ ⎥. ⎣0 1 0 11⎦ , A = ⎢ ⎢0 0 0 1 ⎥ 2 ⎦ ⎣ 002 0 0 − 12 12 0 As det(A) = −4, we conclude that C1 = 1 is an appropriate constant and γ = z1 + z2 is a primitive element. The next step is to compute M (z). Applying Corollary 1 we have q = A−1 (−a4 ) = [1, 0, −10, 0]T thus M (z) = z 4 − 10z 2 + 1. If we execute Algorithm 1 over F = Zp , then we can use the resulting poly¯ p = Zp [z]/M (z) such that Lp ∼ ¯p. nomial M (z) and matrix A to construct L =L However, if we execute LAminpoly over F = Zp , it is likely that one or more of mi will be reducible over Zp [z1 , . . . , zi−1 ]/m1 , . . . , mi−1  in which case M (z) is reducible over Zp . We give an example. Example 6. Let M1 (z1 ) = z12 − 2 and M2 (z2 ) = z22 − 3 and L = Q[z1 , z2 ]/M1 , M2 . Let p = 113, F = Zp , C1 = 101 and Lp = Z113 [z1 , z2 ]/z12 + 111, z22 + 110. Lp is not a ﬁeld since m1 = (z1 + 51)(z1 + 62) in Lp . Let BLp = {1, z2 , z1 , z1 z2 }. Applying LAminpoly for γ = z1 + 101z2 ∈ Lp we have ⎡ ⎤ 1 0 95 0 ⎢0 101 0 55⎥ ⎥ A=⎢ ⎣0 1 0 55⎦ . 0 0 89 0 Since det(A) = 0, we solve the system A q = −[γ 4 ]BLp and construct the gen4 2 erator polynomial 2M (z) = z + 36z + 32. M (z) factors over Zp as M (z) = 2 ¯ z + 11z + 22 z + 102z + 22 so Lp = Zp [z]/M (z) is not a ﬁeld. Remark 1. In MGCD, we choose a prime p and C1 , . . . , Cn−1 ∈ [1, p) at random. Then we call algorithm LAminpoly with F = Zp and γ = z1 + C1 z2 + . . . Cn−1 zn in Lp . If LAminpoly returns FAIL, because the failure may be due to the choice of p or C1 , . . . , Cn−1 , MGCD selects a new prime p and a new set of random integers C1 , . . . , Cn−1 ∈ [1, p) and calls LAminpoly again. 2.2  
   
  The Isomorphism φγ  
   
  ¯p. We are now well-equipped to introduce the isomorphism φγ : Lp −→ L n Let BLp = { i=1 (zi )ei s.t 0 ≤ ei < di } and BL¯ p = {1, z, z 2 , . . . , z d−1 } be ¯ p , respectively. Let C : Lp −→ Zdp be a bijection such that bases for Lp and L ¯ p −→ Zdp be another bijection such that D(b) = [b]B ¯ . C(a) = [a]BLp and D : L Lp ¯ p such that φγ (a) = D−1 (A−1 · C(a)), where A is the Deﬁne φγ : Lp −→ L matrix obtained from the LAminpoly algorithm over F = Zp . The inverse of φγ −1 −1 ¯ is φ−1 (A · D(b)). γ : Lp −→ Lp such that φγ (b) = C  
   
  8  
   
  M. Ansari and M. Monagan  
   
  Lemma 1. If det(A) = 0, then the mapping φγ deﬁned above is a ring isomorphism. Proof. Since A−1 exists and both C and D are bijections, we can conclude that φγ is well-deﬁned and bijective. Additionally, if γ = z1 +C1 z2 +· · ·+Cn−1 zn is the element obtained from the LAminpoly algorithm, then φ−1 γ can be expressed as an evaluation homomorphism that substitutes z for z1 +C1 z2 +. . .+Cn−1 zn . The fact that φ−1 γ is a homomorphism implies that φγ is also a ring homomorphism. Isomorphism φγ induces the natural isomorphism φγ : Lp [x1 , . . . , xk ] −→ ¯ p [x1 , . . . , xk ]. The following example illustrates how we can compute φγ (f ) for L f ∈ Lp [x1 , . . . , xk ]. Example 7. Given the quotient rings Lp = Z113 [z1 , z2 ]/z12 + 111, z22 + 110 and ¯ p = Z113 [z]/z 4 + 36z 2 + 32 from Example 6, we aim to compute φγ (f ) where L f = 2x1 z1 + x2 + z1 z2 ∈ Lp [x1 , x2 ]. Let BLp = {1, z2 , z1 , z1 z2 } and A be the matrix computed in Example 6. We have [f ]Lp = [x2 , 0, 2x1 , 1]T and b = A−1 · [f ]BLp = [x2 + 84, 61x1 , 80, 77x1 ]  
   
  T  
   
  as the coordinate vector of φγ (f ) relative to BL¯ p = {1, z, z 2 , z 3 }. Consequently, ¯ p [x1 , x2 ]. φγ (f ) = x2 + 84 + 61x1 z + 80z 2 + 77x1 z 3 ∈ L  
   
  3  
   
  The Modular Gcd Algorithm  
   
  Modular gcd algorithms for Q(α1 , · · · , αn )[x] work by computing the gcd modulo a sequence of primes and applying Chinese remaindering and rational number reconstruction to recover the rational coeﬃcients of the gcd. However, not all primes can be used. Our modular gcd algorithm for Q(α1 , · · · , αn )[x1 , . . . , xn ] applies Theorem 2 below to identify the primes that cannot be used. In Theorem 2, R may have zero-divisors. Examples 8 and 9 illustrate this. Theorem 2. Let R and R be commutative rings with 1 = 0 and φ : R −→ R be a ring homomorphism. Let f1 and f2 be two non-zero polynomials in R[x1 , . . . , xk ]. Let us ﬁx a monomial ordering on R[x1 , . . . , xk ]. Suppose that the monic g = gcd(f1 , f2 ) and the monic gφ = gcd(φ(f1 ), φ(f2 )) exist. If φ(lc(f1 )) = 0, then (i) lm(gφ ) ≥ lm(g) and (ii) If lm(gφ ) = lm(g), then gφ = φ(g). Proof. (i) Let p, q ∈ R[x1 , . . . , xk ] be the cofactors of f1 and f2 , respectively. That is, f1 = p · g and f2 = q · g. Using the ring homomorphism property of φ, we have φ(f1 ) = φ(p) · φ(g) and φ(f2 ) = φ(q) · φ(g). By assumption, φ(lc(f1 )) = 0 which implies that φ(f1 ) = 0. Furthermore, since φ(lc(g)) = φ(1) = 1, we have φ(g) = 0. Thus, φ(g) is a common factor of  
   
  Computing the GCDs of Multivariate Polynomials  
   
  9  
   
  φ(f1 ) and φ(f2 ), and hence φ(g) | gφ . In other words, there exists a non-zero polynomial h ∈ R [x1 , . . . , xk ] such that gφ = h · φ(g). If lc(h) · lc(φ(g)) = 0, then lc(h) · 1 = 0, which implies that lc(h) = 0, contradicting the assumption that h = 0. Accordingly, lm(gφ ) = lm(h) · lm(φ(g)) which implies that lm(gφ ) ≥ lm(φ(g)). Moreover, since φ(lc(g)) = φ(1) = 1, we have lm(φ(g)) = lm(g) and hence lm(gφ ) ≥ lm(φ(g)) = lm(g). (ii) To prove the second part, we use the fact that gφ = h · φ(g) and the assumption that lm(gφ ) = lm(g) to conclude that lm(h) = 1. Thus, h is a constant and since both φ(g) and gφ are monic, h = 1. Hence, gφ = φ(g). 3.1  
   
  PGCD  
   
  Algorithm PGCD (see Algorithm 2) computes the monic gcd(f1 , f2 ), where ¯ p [x1 , . . . , xk ] for k ≥ 1. We use evaluation and dense interpolation f1 , f2 ∈ L as in [2]. PGCD is recursive. When k = 1 we employ the monic Euclidean ¯ p [x1 ]. Otherwise, PGCD reduces f1 , f2 algorithm [17] to ﬁnd gcd(f1 , f2 ) ∈ L ¯ to polynomials in Lp [x1 , . . . , xk−1 ] by evaluating xk = bk where bk is chosen randomly from Zp . Then, PGCD computes gcd(f1 (x1 , x2 , . . . , xk−1 , bk ), f2 (x1 , x2 , . . . , xk−1 , bk )) recursively. Subsequently, PGCD interpolates xk in g. It interpolates xk incrementally until the interpolated polynomial H does not change. The condition in line 30 implies this. ¯ p . We deﬁne the evaluation homomorphism ¯ p [xk ] and R = L Let R = L  φxk =b : R[x1 , . . . , xk−1 ] −→ R [x1 , . . . , xk−1 ] such that φxk =b (f ) = f (b). The chosen evaluation points may cause several problems, including the possibility of hitting a zero divisor. Here, we identify four types of evaluation points. ¯ p [xk ][x1 , . . . , xk−1 ] so Definition 2. We consider f1 and f2 as polynomials in L ¯ that lc(f1 ) ∈ Lp [xk ] and lm(f1 ) is a monomial in x1 , . . . , xk−1 . Assume that the monic g = gcd(f1 , f2 ) exists. Let b ∈ Zp be an evaluation point. We distinguish the following cases: – Lc-bad Evaluation Points. We call b an lc-bad evaluation point if lc(f1 )(b)=0. – Zero-Divisor Evaluation Points. If b is not an lc-bad evaluation point, and the monic Euclidean algorithm (see [17]) tries to invert a zero-divisor ¯ p , for the evaluated f1 and f2 at xk = b, then b is called a zero-divisor in L evaluation point. – Unlucky Evaluation Points. Assume the monic gcd(φxk =b (f1 ),φxk =b (f2 )), denoted by gb , exists. We call b an unlucky evaluation point if lm(gb ) > lm(g). – Good Evaluation Points. If b is neither lc-bad, unlucky, nor zero-divisor evaluation point, we call b a good evaluation point.  
   
  10  
   
  M. Ansari and M. Monagan  
   
  Theorem 3. Let φxk =b : R[x1 , . . . , xk−1 ] −→ R [x1 , . . . , xk−1 ] be the evaluation ¯ p . Let f1 , f2 ∈ R[x1 , . . . , xk−1 ] ¯ p [xk ] and R = L homomorphism, where R = L and b ∈ Zp . Suppose that g = monic(gcd(f1 , f2 )) gb = monic(gcd(φxk =b (f1 ), φxk =b (f2 ))) h = monic(φxk =b (g)) all exist. If b is a good evaluation point, then h = gb . Proof. If b is a good evaluation point, then it is not lc-bad. Thus, we can infer that φxk =b (lc(f1 )) = 0. By a similar argument as in the proof of Theorem 2, we can conclude that h is a common factor of φxk =b (f1 ) and φxk =b (f2 ) so h | gb . In other words, there is a non-zero polynomial t ∈ R [x1 , . . . , xk−1 ] such that gb = t · h. Since h is monic, the same justiﬁcation in Theorem 2 leads us to conclude that lm(gb ) ≥ lm(h). On the other hand, by the deﬁnition of a good evaluation point, b is not an unlucky evaluation point. Thus, we can conclude that lm(gb ) = lm(h). Finally, by part (ii) of Theorem 2, we have h = gb . Remark 2. 1. If prime p is chosen to be suﬃciently large, the possibility of the PGCD failing is low. ¯ p , we abort PGCD and return 2. If PGCD tries to invert a zero-divisor in L control to MGCD and choose a new prime. 3. As we do not know lm(g) in advance, there is a question as to how we can detect unlucky evaluation points. We only keep images gi with the least lm(gi ) and discard the others. See lines 24 to 29 of Algorithm 2, PGCD. 4. Although lc-bad evaluation points can be ruled out in advance, we cannot detect zero-divisor or unlucky evaluation points beforehand. Therefore, we ¯ p [x1 ] with zero-divisor, will end up calling the monic Euclidean algorithm in L unlucky, and good evaluation points. Example 8. Let g = (6z+3)(y+2)x, f1 = g·(x+z+1), and f2 = g·(x+2y+z+10) ¯ 11 [x, y] listed in the lexicographic order with x > y where be two polynomials in L 2 ¯ L11 = Z11 [z]/z + 8. By inspection, we can see that the monic gcd(f1 , f2 ) = (y + 2)x. In this example, y = 9 is an lc-bad evaluation point, y = 1 is an unlucky evaluation point, and y = 0 is a zero-divisor evaluation point since z 2 + 8 mod 11 = (z + 6)(z + 5) and lc(f1 (x, 0)) = z + 6. ¯ p [x1 , . . . , xk ]. Let Xk = [x1 , . . . , xk−1 ]. The content Let f be a polynomial in L of f w.r.t Xk, denoted by cont(f, Xk) is the monic gcd of coeﬃcients of f in Xk ¯ p [xk ]. The primitive part of f , w.r.t X, is deﬁned which is a polynomial in L as pp(f, Xk) = f /cont(f, Xk). PGCD uses the property gcd(f1 , f2 ) = gcd(cont(f1 , Xk), cont(f2 , Xk)) · gcd(pp(f1 , Xk), pp(f2 , Xk)).  
   
  Computing the GCDs of Multivariate Polynomials  
   
  11  
   
  Algorithm 2: PGCD  
   
  1 2 3 4 5 6 7 8 9 10  
   
  11 12 13 14 15 16  
   
  17 18 19 20 21 22  
   
  23 24 25  
   
  26  
   
  ¯ p [x1 , . . . , xk ] Input: f1 , f2 ∈ L ¯ p [x1 , . . . , xk ] or FAIL Output: gcd(f1 , f2 ) ∈ L Xk := [x1 , . . . , xk−1 ] prod := 1 if k = 1 then ¯ p [x1 ] return(H) H := gcd(f1 , f2 ) ∈ L ¯ p [xk ] if c = F AIL then c := gcd(cont(f1 , Xk), cont(f2 , Xk)) ∈ L return(FAIL) f1p = pp(f1 , Xk) and f2p = pp(f2 , Xk) if f1p = F AIL or f2p = F AIL then return(FAIL) ¯ p [xk ] if Γ = F AIL then Γ := gcd(lc(f1p , Xk), lc(f2p , Xk)) ∈ L return(FAIL) while true do Take a new random evaluation point, j ∈ Zp , which is not lc-bad. F1j := f1p (x1 , . . . , xk−1 , xk = j) and F2j := f2p (x1 , . . . , xk−1 , xk = j) ¯ p [x1 , . . . , xk−1 ] // lc(Gj ) = 1 in lex Gj := P GCD(F1j , F2j , p) ∈ L order with x1 > x2 > . . . > xk−1 if Gj = F AIL then return(FAIL) lm := lm(Gj , Xk) // in lex order with x1 > x2 > . . . > xk−1 Γj := Γ (j) ∈ Zp gj := Γj · Gj // Solve the leading coefficient problem if prod = 1 or lm < least then // First iteration or all the previous evaluation points were unlucky. least, H, prod := lm, gj , xk − j else if lm > least then // j is an unlucky evaluation point Go back to step 12. else if lm = least then // Interpolate xk in the gcd H incrementally Vj := prod(xk = j)−1 · (gj − H(xk = j)) H := H + Vj · prod prod := prod · (xk − j) if deg(prod, xk ) > deg(H, xk ) + 1 then H := pp(H, Xk) // Test if H is the gcd of f1 and f2 . Choose b2 , . . . , bk ∈ Zp at random such that lc(H)(x1 , b2 , . . . , bk ) = 0 A, B, C := f1 (x1 , b2 , . . . , bk ), f2 (x1 , b2 , . . . , bk ), H(x1 , b2 , . . . , bk ) if C | A and C | B then return(c · H)  
   
  For k > 1 algorithm PGCD recursively computes monic images of the gcd in ¯ p [x1 , . . . , xk−1 ]. Let β1 , . . . , βj ∈ Zp be the evaluation points chosen by PGCD. L  
   
  12  
   
  M. Ansari and M. Monagan  
   
  To recover the leading coeﬃcient of g in xk , we follow Brown [2] and scale by Γ (xk ) = gcd(lc(f1 , Xk), lc(f2 , Xk)) evaluated at the current evaluation point xk = βj . Thus, after interpolating the gcd H we have lc(H, Xk) = Γ (xk ). based on the Newton form The interpolation of xk in PGCD lines 27–29 is  j−1 for H, namely, H = V1 + V2 (xk − β1 ) + · · · + Vj i=1 (xk − βi ) where Vi ∈ ¯ p [x1 , . . . , xk−1 ] for 1 ≤ i ≤ j. To compute the new H from the previous H we L need only compute Vj . In the ﬁnal phase of PGCD, we need to verify whether the primitive part of H is the gcd of pp(f1 , Xk) and pp(f2 , Xk). To do this, we reduce the poly¯ p [x1 ] by evaluating them nomials f1 , f2 , and H to univariate polynomials in L at x2 = b2 , . . . , xk = bk , where b2 , . . . , bk are chosen at random from Zp until lc(H)(x1 , b1 , . . . , bk ) = 0. Then, we check if the evaluated H divides the evaluated f1 and f2 . If this is the case, then H is the gcd of f1 and f2 with high probability. Hence, PGCD is a Monte Carlo algorithm. Alternatively, if we do ¯ p [x1 ], then PGCD would be a ¯ p [x1 , . . . , xk ] rather than in L the division test in L Las Vegas algorithm. However, in this case, the complexity of PGCD would be ¯ p [x1 , . . . , xk ]. dominated by the cost of the divisions in L 3.2  
   
  MGCD  
   
  The MGCD algorithm, as presented in Algorithm 3, is a Monte Carlo algorithm for computing the monic g = gcd(f1 , f2 ) where f1 , f2 ∈ L[x1 , . . . , xk ]. MGCD begins with a preprocessing step where the input polynomials, f1 , f2 , and the minimal polynomials M1 , . . . , Mn are replaced with their semi-associates. Let φp denote the modular homomorphism, that is, φp (f ) = f mod p. MGCD chooses a prime p and applies φp to map the coeﬃcients in L to Lp . Subsequently, it employs the isomorphism φγ to convert the polynomials over Lp to their ¯ p . Then MGCD calls PGCD to ﬁnd the monic corresponding polynomials over L ¯ gcd in Lp [x1 , . . . , xk ]. Let Gp be the output of PGCD. If Gp = F AIL, either p is a zero-divisor prime or the PGCD algorithm encounters a zero-divisor evaluation point. In both cases, the algorithm goes back to step 4 to choose a new prime. ¯ p [x1 , . . . , xk ] will be converted to its corresponding polynomial In step 14, Gp ∈ L over Lp . Applying Theorem 2, MGCD just keeps the gcd images Gp with the least leading monomial for Chinese remaindering. For instance, if Gpi is the output of PGCD at the ith iteration, and if lm(Gpi ) > lm(Gpi−1 ), then pi is an unlucky prime and we simply ignore its result Gpi and choose another prime. After Chinese remaindering, MGCD employs rational number reconstruction (RNR) [9,18] to recover the coeﬃcients of the potential gcd in L. Failure in the RNR call means the product of the primes is not large enough to recover the rational coeﬃcients. If RNR does not fail, then we follow the same strategy as in PGCD to verify if H could be the gcd of f1 and f2 or not. Remark 3. For the eﬃciency of the MGCD algorithm, it is necessary to apply φp before φγ . This eliminates expression swell in Q.  
   
  Computing the GCDs of Multivariate Polynomials  
   
  Algorithm 3: MGCD  
   
  1 2 3 4 5 6 7 8 9 10  
   
  11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  
   
  Input: f1 , f2 ∈ L[x1 , . . . , xk ] where L = Q[z1 , . . . , zn ]/M1 (z1 ), . . . , Mn (zn ) Output: gcd(f1 , f2 ) M := 1 f1 := fˇ1 and f2 := fˇ2 // Clear fractions while true do Choose a new random prime p, that is not, lc-bad.  Choose C1 , . . . , Cn−1 ∈ [1, p) at random and set γ = z1 + n i=2 Ci−1 zi ˇ 1 ), . . . , φp (M ˇ n )], Zp and φp (γ) to Call Algorithm 1 with inputs [φp (M compute M (z), A, and A−1 if Algorithm 1 fails then Go back to step 4 ¯p // Apply Algorithm 2 to get the monic gcd over L ¯ p [x1 , . . . , xk ] Gp = P GCD(φγ (φp (f1 )), φγ (φp (f2 ))) ∈ L if Gp = FAIL then // p is a zero-divisor prime or PGCD has encountered a zero-divisor evaluation point. Go back to step 4. if deg(Gp ) = 0 then return(1) ¯ p to its corresponding polynomial over Lp // Convert Gp ∈ L −1 Gp := φγ (Gp ) lm := lm(Gp ) w.r.t lexicographic order with x1 > x2 . . . > xk if M = 1 or lm < least // First iteration or all the previous primes were unlucky. then G, least, M := Gp , lm, p else if lm = least then Using CRT, compute G ≡ G mod M and G ≡ Gp mod p set G = G and M = M · p else if lm > least then // p is an unlucky prime Go back to step 4 H := Rational Number Reconstruction of G mod M if H = FAIL then Choose a new prime q and b2 , . . . , bn ∈ Zq at random such that lc(H)(x1 , b2 , . . . , bk ) = 0 A, B, C := f1 (x1 , b2 , . . . , bk ), f2 (x1 , b2 , . . . , bk ), H(x1 , b2 , . . . , bk ) // A, B, C are polynomials in Lq [x1 ] if C | A and C | B then return(H)  
   
  13  
   
  14  
   
  M. Ansari and M. Monagan  
   
  In step 4 of the Algorithm 3, we choose a prime to reduce inputs modulo it. However, not all the primes result in the successful reconstruction of the monic gcd. We distinguish ﬁve types of primes in the following deﬁnition. Definition 3. Let f1 , f2 ∈ L[x1 , . . . , xk ] and p be a prime. We distinguish the following cases: ˇ1 (z1 )), . . . , lc(M ˇ n (zn )), then – Lc-bad Prime: If p divides lc(fˇ1 ) or any lc(M we call p an lc-bad prime. – Det-bad Prime: If det(A) mod p = 0, where A is the coeﬃcient matrix of powers of γ obtained from the LAminpoly algorithm, then p is called a det-bad prime. – Zero-Divisor Prime: If p is neither an lc-bad nor a det-bad prime and the PGCD algorithm fails for p, in steps 4, 6, 8, 10, 31, then p is called a zerodivisor prime. – Unlucky Prime: Let gp = gcd(φp (fˇ1 ), φp (fˇ2 )). If lm(gp ) > lm(gcd(f1 , f2 )), then we call p an unlucky prime. Considering Theorem 2, the results of these primes must be ignored. – Good Prime: If prime p is not an lc-bad, det-bad, unlucky, or zero-divisor prime, we deﬁne it as a good prime. Theorem 4. Let f1 , f2 ∈ L[x1 , . . . , xk ] and g be the monic gcd(f1 , f2 ). If p is a good prime and the monic gcd(φp (f1 ), φp (f2 )), gp , exists, then gp = φp (g). Proof. If p is good then p is not lc-bad so we may apply Theorem 2 with R = L and R = Lp so lm(gp ) ≥ lm(g). But p is not unlucky so lm(gp ) = lm(g). By part (ii) of Theorem 2 we have gp = φp (g) as required. Example 9. Let L = Q[z, w]/z 2 −2, w2 −3, and f1 = (x+w)(5x+2w+z)xw and f2 = (x + w)(5x + 9w + z) be polynomials in L[x]. By inspection, gcd(f1 , f2 ) = (x + w). In this example p = 5 is an lc-bad prime, p = 7 is an unlucky prime, and p = 3 is a zero-divisor prime since w2 − 3 mod 3 = w2 .  
   
  4  
   
  Complexity  
   
  Let H(f ) denote the height of f ∈ L[x1 , . . . , xk ] which is the magnitude of the largest integer coeﬃcient of fˇ. Let #f denote the number of terms of f . Let f1 , f2 ∈ L[x1 , · · · , xk ] and g be the monic gcd(f1 , f2 ). The quantities involved in the running time of the MGCD algorithm are as follows: – – – –  
   
  N is the number of good primes needed to reconstruct the monic gcd g Tf = max(#f1 , #f2 ) and Tg = #g ˇi ) and C = log max(H(fˇ1 ), H(fˇ2 )). M = log maxni=1 H(m D = maxki=1 max(deg(f1 , xi ), deg(f2 , xi )) and d = [L : Q].  
   
  ¯ p cost O(d2 ) as our implemenWe assume that multiplication and inverses in L tation currently uses classical quadratic polynomial arithmetic.  
   
  Computing the GCDs of Multivariate Polynomials  
   
  15  
   
  Theorem 5. The expected time complexity of our MGCD algorithm is O(N (M + CTf )d + N d2 (d + Tf + Tg ) + N d2 Dk+1 + N 2 dTg ) Proof. In the MGCD algorithm, the most dominant operations are as follows: 1. Modular homomorphism: The MGCD algorithm reduces the minimal ˇ n and the input polynomials fˇ1 and fˇ2 mod a prime. ˇ 1, . . . , M polynomials M For N primes this costs O(N (M + CTf )d). 2. φγ isomorphism: The time complexity of building the matrix A is O(d3 ), and the running time complexity of applying φγ to the Tf non-zero terms of f1 and f2 for N primes is O(N d2 Tf ). Additionally, let Gp be the output of the PGCD algorithm in step 9. The time complexity of calling φ−1 γ for Gp in step 14 for N primes is O(N d2 Tg ). 3. PGCD: Brown’s PGCD algorithm [2] does O(Dk+1 ) arithmetic operations in Zp . Accordingly, our PGCD algorithm does O(Dk+1 ) arithmetic operations ¯ p each of which costs O(d2 ). Overall, our PGCD costs O(d2 Dk+1 ). The in L dominating step is the O(Dk−1 ) calls to the monic Euclidean algorithm in ¯ p [x1 ] each of which does O(D2 ) arithmetic operations in L ¯p. L 4. CRT and RNR: Reconstructing O(dTg ) rational coeﬃcients in step 21 and 25 costs O(N 2 ) each hence O(N 2 dTg ) in total. The theorem follows by adding the four costs explained above. Remark 4. Theorem 5 describes the cost of our implementation of algorithms MGCD and PGCD. We are currently working on replacing Brown’s dense interpolation with a sparse interpolation approach. In the case where we interpolate g (when lc(g, x1 ) = gcd(lc(f1 , x1 ), lc(f2 , x1 ))), the number of calls to the monic ¯ p [x1 ] is reduced from O(Dk−1 ) to O(kDTg ) using ZipEuclidean algorithm in L pel’s algorithm from [19] and O(Tg ) using Hu and Monagan’s algorithm [6]. The latter is based on the work of Ben-Or and Tiwari [1] and others.  
   
  5  
   
  Implementation  
   
  We have implemented algorithms MGCD and PGCD in Maple [10]. We use the recursive dense data structure from [17] to represent elements of L = Q(α1 , · · · , αn ) and polynomials in L[x1 , . . . , xk ]. See Fateman [5] for a comparison of the recursive dense data structure with other sparse polynomial data structures. The rpoly command below converts from Maple’s polynomial representation to the recursive dense representation. For usability, this representation is automatically converted back to Maple’s polynomial representation for display. In Maple [ 1, 2, 3 ] is a Maple lists which is a read only array. > f:=rpoly(2*x^2+3*x*y^2,[x,y]); f := 2x2 + 3xy 2  
   
  16  
   
  M. Ansari and M. Monagan  
   
  > lprint(f);  
   
  # print the actual data value P OLY N OM IAL( [0, [x, y], []], [0, [0, 0, 3], [2]] )  
   
  As it is shown, the POLYNOMIAL data structure has two ﬁelds. – The ﬁrst, [0, [x, y], [ ]], is the ring. The ﬁrst entry, 0, indicates the characteristic of the ring. The second entry, [x, y], is the list of variables. The third entry [ ], which is an empty list, indicates that there are no extensions. – The second ﬁeld, [0, [0, 0, 3], [2]], represents the polynomial recursively. To do so, it uses the fact that Q[x1 , . . . , xk ] ∼ = Q[xk ][xk−1 ] . . . [x1 ]. In this example, x is the main variable and rpoly maps f ∈ Q[x, y] to f := 2x2 + (3y 2 )x ∈ Q[y][x]. Consequently, the entries 0, [0, 0, 3], [2] are the coeﬃcients of x0 , x1 , and x2 , and correspond to 0, 0 + 0 · y + 3y 2 , and 2 respectively. Example 10. Let L = Q[z, w]/z 2 − 2, w2 − 3 and f = 2x3 + 3xy 2 − 5wz + 4. In the following we construct the ﬁeld of L, the polynomial f ∈ L[x, y], and compute φ7 (f )(x, 2). > L:=rring([z,w],[z^2-2,w^2-3]);  
   
  # L=Q[z,w]/  
   
  L := [0, [z, w], [[[−2], 0, [1]], [−3, 0, 1]]] > Lxy:=rring(L,[x,y]);  
   
  # Construct L[x,y] from L  
   
  Lxy := [0, [x, y, z, w], [[[−2], 0, [1]], [−3, 0, 1]]] > f:=rpoly(2*x^3+3*x*y^2-5*z*w+2*z^2,Lxy); f := 2x3 + 3xy 2 − 5wz + 4 > getpoly(f);  
   
  mod < z 2 − 2, w2 − 3 >  
   
  # The recursive dense representation of f [[[[4], [0, −5]]], [0, 0, [[3]]], 0, [[[2]]]]  
   
  > g := phirpoly(f,7);  
   
  # Apply the modular homomorphism with p = 7  
   
  g := 2x3 + 3xy 2 + 2wz + 4  
   
  mod z 2 + 5, w2 + 4, 7  
   
  > h := evalrpoly(g,y=2); h := 2x3 + 2wz + 5x + 4 mod z 2 + 5, w2 + 4, 7 > getring(h);  
   
  # The ring Lp[x] [7, [x, z, w], [[[5], 0, [1]], [4, 0, 1]]]  
   
  > getpoly(h); [[[4], [0, 2]], [[5]], 0, [[2]]]  
   
  Computing the GCDs of Multivariate Polynomials  
   
  5.1  
   
  17  
   
  Maple Implementation  
   
  In this section, we demonstrate an application of our MGCD algorithm. First, we construct the ﬁeld of L = Q[z, w]/z 2 − 2, w2 − 3. Then, we convert two polynomials f1 and f2 from Maple’s native representation to the recursive dense representation and compute their gcd using MGCD. MGCD prints all the used primes, lc-bad, zero-divisor, unlucky, and det-bad primes. We tell MGCD to start with a very small prime, 5, for illustrative purposes only. By default MGCD uses 31 bit primes. This is because for polynomial arithmetic in Zp [x], Maple uses hardware integer arithmetic for Zp for primes less than 231.5 , otherwise Maple uses GMP’s multi-precision integer arithmetic which is a lot slower. > L:=rring([z,w],[z^2-2,w^2-3]): > Lxy:=rring(L,[x,y]): > f1:=rpoly((w+5)*(x+y+w)*(14*x+2*w+z),Lxy);  
   
  f 1 := (14w + 70) x2 + ((14w + 70) y + (w + 5) z + 80w + 48) x + ((w + 5) z + 10w + 6) y + (5w + 3) z + 6w + 30  
   
  mod w2 − 3, z 2 − 2  
   
  > f2:=rpoly((x+y+w)*(x+2*w+z),Lxy); f 2 := x2 + (y + 3w + z) x + (2w + z) y + zw + 6 mod w2 − 3, z 2 − 2 > mgcd:=MGCD(f1,f2,5); MGCD:prime=5 gamma:=4*w+z and M(z)=z^4+1 p=5 is a ZD prime ZD=z^2+3 MGCD:prime=7 p=7 is an lc-bad prime MGCD:prime=11 gamma:=3*w+z and M(z)=z^4+8*z^2+9 p=11 is a ZD prime ZD=z^2+8*z+3 MGCD:prime=13 gamma:=z+10*w and M(z)=z^4+7*z^2+1 MGCD:prime=17 gamma:=z+13*w and M(z)=z^4+2*z^2+8 p=17 and All the previous primes were unlucky MGCD:prime=19 gamma:=z+17*w and M(z)=z^4+10*z^2+5  
   
  mgcd := x + y + w  
   
  mod z 2 − 2, w2 − 3  
   
  18  
   
  5.2  
   
  M. Ansari and M. Monagan  
   
  Benchmark  
   
  We give√one√benchmark for gcd computations in L[x, y] where the number ﬁeld √ √ √ L = Q( 2, 3, 5, 7, 11) has degree 32. In the Table 1, the input polynomials f1 and f2 have degree d in x and y and their gcd g has degree 2 in x and y. Table 1. timings in CPU seconds for gcds in the ring L[x, y] where √ √ √ √ √ Computation L = Q( 2, 3, 5, 7, 11). d  
   
  New MGCD Old MGCD time LAMP PGCD time PGCD  
   
  4  
   
  0.119 0.023  
   
  0.027  
   
  0.114 0.100  
   
  6  
   
  0.137 0.016  
   
  0.034  
   
  0.184 0.156  
   
  8  
   
  0.217 0.018  
   
  0.045  
   
  0.330 0.244  
   
  10 0.252 0.018  
   
  0.087  
   
  0.479 0.400  
   
  12 0.352 0.018  
   
  0.078  
   
  0.714 0.511  
   
  16 0.599 0.017  
   
  0.129  
   
  1.244 1.008  
   
  20 0.767 0.017  
   
  0.161  
   
  1.965 1.643  
   
  24 1.103 0.019  
   
  0.220  
   
  2.896 2.342  
   
  28 1.890 0.023  
   
  0.358  
   
  4.487 3.897  
   
  32 2.002 0.020  
   
  0.392  
   
  5.416 4.454  
   
  36 2.461 0.017  
   
  0.595  
   
  6.944 5.883  
   
  40 3.298 0.019  
   
  0.772  
   
  9.492 7.960  
   
  Column New MGCD is the time for our new algorithm using a primitive ¯ p . Column Old MGCD is the time for MGCD element and computing over L if we do not use a primitive element and compute over Lp . Column LAMP is the time spent in Algorithm LAminpoly. For both algorithms, column PGCD is the time spent in Algorithm PGCD. The speedup gained by using φγ is seen by comparing columns PGCD. These preliminary timings show a speedup of PGCD of a factor of 10 which is promising. The benchmark was run on an Intel Gold 6342 CPU running at 2.8 GHz. We used Maple 2022. For the details of the benchmark, see http://www.cecm.sfu.ca/∼mmonagan/code/MGCD .  
   
  6  
   
  Conclusion and Future Work  
   
  Let f1 , f2 ∈ Q(α1 , · · · , αn )[x1 , . . . , xn ], and let g be their monic gcd. We have designed a multivariate modular gcd algorithm, MGCD, to compute g. For each prime p chosen by MGCD, to speed up the coeﬃcient arithmetic in Q(α1 , · · · , αn ) mod p, we use a primitive element γ modulo p.  
   
  Computing the GCDs of Multivariate Polynomials  
   
  19  
   
  For future work, we need to compute the probability that MGCD obtains an incorrect answer, as well as the probabilities of getting unlucky, zero-divisor, ¯ p = Zp [z]/M (z), lc-bad primes, and evaluation points. For arithmetic in L our Maple implementation currently uses classical O(d2 ) algorithms where ¯ p by using fast d = deg(M ). For large d, we can speed up multiplication in L multiplication and division for Zp [z]. Acknowledgment. This work was supported by Maplesoft and the National Science and Engineering Research Council (NSERC) of Canada.  
   
  References 1. Ben-Or, M., Tiwari, P.: A deterministic algorithm for sparse multivariate polynomial interpolation. In: Proceedings of STOC 1988, pp. 301–309. ACM (1988) 2. Brown, W.S.: On Euclid’s algorithm and the computation of polynomial greatest common divisors. J. ACM 18, 478–504 (1971) 3. Collins, G.E.: Subresultants and reduced polynomial remainder sequences. J. ACM 14, 128–142 (1967) 4. Encarnaci´ on, M.J.: Computing GCDs of polynomials over algebraic number ﬁelds. J. Symb. Comput. 20, 299–313 (1995) 5. Fateman, R.: Comparing the speed of programs for sparse polynomial multiplication. SIGSAM Bull. 37(1), 4–15 (2003) 6. Jiaxiong, H., Monagan, M.: A fast parallel sparse polynomial GCD algorithm. Symb. Comput. 105(1), 28–63 (2021) 7. Langemyr, L., McCallum, S.: The computation of polynomial greatest common divisors over an algebraic number ﬁeld. J. Symb. Comput. 8(5), 429–448 (1989) ´ Fast arithmetic for triangular sets: from theory 8. Lin, X., Maza, M.M., Schost, E.: to practice. J. Symb. Comput. 44(7), 891–907 (2009) 9. Monagan, M.: Maximal quotient rational reconstruction: an almost optimal algorithm for rational reconstruction. In: Proceedings of ISSAC 2004, pp. 243–249. ACM (2004) 10. Monagan, M., et al.: Maple 8 Introductory Programming Guide (2003) ´ Modular composition modulo triangular sets and applica11. Poteaux, A., Schost, E.: tions. Comput. Complex. 22, 463–516 (2013) ´ On the complexity of computing with zero-dimensional 12. Poteaux, A., Schost, E.: triangular sets. J. Symb. Comput. 50, 110–138 (2013) 13. Smedley, T.: A new modular algorithm for computation of algebraic number polynomial GCDs. In: Proceedings of ISSAC 1989, pp. 91–94. ACM (1989) 14. Trager, B.M.: Algebraic factoring and rational function integration. In: Proceedings of the Third ACM Symposium on Symbolic and Algebraic Computation, SYMSAC 1976, pp. 219–226. ACM (1976) 15. van der Hoeven, J., Lecerf, G.: Accelerated tower arithmetic. J. Complex. 55, 101402 (2019) 16. van der Hoeven, J., Lecerf, G.: Directed evaluation. J. Complex. 60, 101498 (2020) 17. van Hoeij, M., Monagan, M.: A modular GCD algorithm over number ﬁelds presented with multiple extensions. In: Proceedings of the 2002 International Symposium on Symbolic and Algebraic Computation, ISSAC 2002, pp. 109–116. ACM (2002)  
   
  20  
   
  M. Ansari and M. Monagan  
   
  18. Wang, P., Guy, M.J.T., Davenport, J.H.: P-adic reconstruction of rational numbers. SIGSAM Bull. 16(2), 2–3 (1982) 19. Zippel, R.: Probabilistic algorithms for sparse polynomials. In: Ng, E.W. (ed.) Symbolic and Algebraic Computation. LNCS, vol. 72, pp. 216–226. Springer, Heidelberg (1979). https://doi.org/10.1007/3-540-09519-5 73  
   
  Generating Elementary Integrable Expressions Rashid Barket1 , Matthew England1(B) , and Jürgen Gerhard2 1  
   
  Coventry University, Coventry, UK {barketr,matthew.england}@coventry.ac.uk 2 Maplesoft, Waterloo, Canada [email protected]   
   
  Abstract. There has been an increasing number of applications of machine learning to the field of Computer Algebra in recent years, including to the prominent sub-field of Symbolic Integration. However, machine learning models require an abundance of data for them to be successful and there exist few benchmarks on the scale required. While methods to generate new data already exist, they are flawed in several ways which may lead to bias in machine learning models trained upon them. In this paper, we describe how to use the Risch Algorithm for symbolic integration to create a dataset of elementary integrable expressions. Further, we show that data generated this way alleviates some of the flaws found in earlier methods. Keywords: Computer algebra learning · Data generation  
   
  1 1.1  
   
  · Symbolic integration · Machine  
   
  Introduction Machine Learning and Computer Algebra  
   
  A key feature of a Computer Algebra System (CAS) is its exactness: when prompted for a calculation, a CAS is expected to return the exact answer (or no answer if the calculation is not feasible), as opposed to an approximation to an answer. Due to this restraint, it seems as though Machine Learning (ML) and Computer Algebra do not work well together due to the probabilistic nature of ML: no matter how well-trained an ML model is, it can never guarantee perfect predictions. However, rather than trying to use ML to predict a calculation in place of a CAS, we can instead use ML in conjunction with a CAS to help optimize and/or select the symbolic computation algorithms implemented within. Such a combination of ML and symbolic computation preserves the unique selling point of a CAS. The earliest examples of such ML for CAS optimisation known to the authors are: Hunag et al. [3] which used a support vector machine to choose the variable ordering for cylindrical algebraic decomposition; and Kuipers et al. [5] which used a Monte-Carlo tree search to ﬁnd the representation of polynomials that are most eﬃcient to evaluate. c The Author(s), under exclusive license to Springer Nature Switzerland AG 2023  F. Boulier et al. (Eds.): CASC 2023, LNCS 14139, pp. 21–38, 2023. https://doi.org/10.1007/978-3-031-41724-5_2  
   
  22  
   
  R. Barket et al.  
   
  1.2  
   
  Symbolic Integration Meta-Algorithms  
   
  Our interest is the integrate function of a CAS, which takes an integrand and produces an integral (either deﬁnite or indeﬁnite). In most CASs, and certainly in Maple where the authors focus their work, the integrate function is essentially a meta-algorithm: it accepts a mathematical expression as an input, does some preprocessing on the expression, and then passes the processed problem to one of a selection of available sub-algorithms. In Maple, the function will try a list of such sub-algorithms in turn until one is found that can integrate the expression, in some cases ﬁrst querying a guard as to whether that sub-algorithm is applicable to the input in question. If none of these methods work, the function simply returns the input back as an unevaluated integral (implying that Maple cannot integrate it). Currently, as of Maple 2023, these sub-algorithms for int are tried in the same pre-set order for every input, and int outputs the answer of the ﬁrst subalgorithm that works. There are currently 11 sub-algorithms to choose from. The list of sub-algorithms is available on the Maple help page1 for the function. The ﬁrst motivation to use ML is to improve the integrate function’s eﬃciency. A similar approach was taken by Simpson et al. [9] for the resultant function (see Deﬁnition 3 later). After applying a neural network to classify which algorithm (of four possible choices) to use, the authors test their model on a random sample of several thousand inputs. Maple’s existing meta-algorithm took 37,783 s to ﬁnish its computations, whereas the sub-algorithm choices from the neural network took only 12,097 s – a signiﬁcant improvement with a 68% decrease in runtime. There were also gains against Mathematica with a 49% decrease in runtime. We hope to achieve similar results with the integrate function. The second motivation to use ML is in optimizing the output. To gain a better understanding of this, consider what happens in Fig. 1 when you integrate the function f (x) = x sin(x) in Maple and ask it to try all possible sub-algorithms. When f (x) is integrated, there are three successful outputs that come from three diﬀerent sub-algorithms. Each output is expressed diﬀerently but are all mathematically correct  and equivalent. We wish to choose the simplest output, which in this case is f (x) = sin(x) − x cos(x). 1.3  
   
  Motivation  
   
  The goal of the data generation method described in this paper is to be able to produce many integrable expressions to train a ML model on. There is not enough benchmark/real-world data to train a model on, hence why these data generation methods are needed. There does currently exists data generation methods. Lample & Charton [6] produce three methods for developing integrable expressions: FWD, BWD, and IBP (described in detail in Sect. 2.1). These methods have drawbacks which the data generation method we propose will handle. 1  
   
  www.maplesoft.com/support/help/maple/view.aspx?path=int%2fmethods+.  
   
  Generating Elementary Integrable Expressions  
   
  23  
   
   Fig. 1. The output of x sin(x) from each successful sub-algorithm. The main output chosen in this case is the shortest expression chosen by an ML model, from subalgorithm 2.  
   
  The FWD method, which generates a random expression and calculates its integral, tends to produce short integrands and long integrals. Furthermore, the FWD method will typically not have an elementary integral. This is especially evident for longer randomly generated expressions and/or expressions with denominators. This means the FWD method will take numerous attempts before ﬁnding a valid (integrand, integral) pair. The BWD method, which generates an expression and calculates its derivative, has the opposite problem of long integrands and short integrals. The IBP, or integration by parts method, produces expressions that are too similar (meaning that the expressions only diﬀer by their coeﬃcients) which is discussed in Sect. 2.1. Hence, a dataset of (integrand, integral) pairs is needed for this method to work. We propose generating (integrand, integral) pairs based on the Risch Algorithm. For one, the method will always produce an elementary integrable expression, something FWD cannot guarantee. This data generation method also does not have the issue of varied lengths between the integrands and integrals because of various parameters available from the data generation method, alleviating the length issues in the FWD and BWD methods. Lastly, this method does not require a dataset of known integrals and also does not produce expressions too similar to the rest of the dataset, which IBP suﬀers from. Data generation based on the Risch algorithm produces a variety of non-trivial, unique expressions that current data generation methods do not oﬀer. Further discussion of current methods and the new method presented are discussed in Sects. 2.1 and 5. 1.4  
   
  Contributions and Plan  
   
  This paper will focus on how to generate suﬃcient data for our planned application of ML. In Sect. 2, we overview the existing methods of data generation for the problem that we found in the literature, explaining why they are not suitable alone for our needs. Then in Sect. 3, we review the classical Risch algorithm which will be the basis of our new data generation method introduced in Sect. 4 which identiﬁes constructive conditions for an integrand to be elementary inte-  
   
  24  
   
  R. Barket et al.  
   
  grable. We ﬁnish in Sect. 5 with a discussion on the advantages of this approach over the existing methods and what future steps still need to be undertaken.  
   
  2  
   
  Existing Datasets and Data Generation Methods  
   
  An important aspect of a successful ML model is that it is generalisable. That is, the model should perform well on all inputs it receives and not just inputs that look very similar to the training data. There are existing datasets and data generation methods for symbolic integration. However, each comes with its own sets of limitations that prevent an ML model trained on them to generalise well on all real-world data. 2.1  
   
  Deep Learning for Symbolic Mathematics  
   
  In their paper (with the same name of this subsection), Lample and Charton [6] experiment on using deep learning to perform the tasks of symbolic integration and solving ordinary diﬀerential equations directly. To achieve this, they used a seq2seq model − a neural network architecture used in natural language processing for mapping sequences of tokens (usually words to another such sequence) − in the form of a transformer2 . There are diﬀerent classes of integrals that can be output based on its complexity. Definition 1 (Elementary Function). A function, that is, deﬁned as the sum, product, root, or composition of ﬁnitely many polynomial, rational, trigonometric, hyperbolic, and exponential functions (and their inverses) is considered elementary. An elementary function that, when integrated, produces an elementary function is said to be elementary integrable. Most expressions one encounters in a ﬁrst-year calculus class will be elementary integrable. An example of an expression that is not elementary integrable is f (x) = log1 x . When f (x) is integrated, the result usually produced is li(x), a non-elementary function known as the Logarithmic Integral special function3 . The authors of [6] created a novel way of generating data to train a transformer. Expressions are viewed as trees, where the internal nodes are operators or function names (+, sin, etc.), and the leaves are constants and variables as exempliﬁed in Fig. 2. An algorithm is developed to generate trees of varying length so that these expressions can be used for training the model. They added structure to the trees in the form of restriction on internal nodes and leaves such that every random tree created is a valid symbolic expression. They treated this as a supervised learning problem, generated the following three methods to take such symbolic expressions and produced labelled training pairs: 2 3  
   
  the same model which is the basis for ChatGPT. https://dlmf.nist.gov/6.2.  
   
  Generating Elementary Integrable Expressions  
   
  25  
   
  – FWD: Integrate an expression f through a CAS to get F and add the pair (f, F ) to the dataset. – BWD: Diﬀerentiate an expression f to get f  and add the pair (f  , f ) to the dataset.  – IBP: Given two expressions f and g, calculate f  and g  . If f  g is known then the following holds (integration-by-parts):    f g = f g − f  g. Thus we add the pair (f g  , f g −  
   
    
   
  f  g) to the dataset.  
   
  While these three methods can generate plenty of elementary integrable expressions, they come with many limitations that can cause an ML model to overﬁt on the training data. For both the FWD and BWD methods, they tend to create expressions with patterns in the length. For FWD, the integrand is on average shorter than the resulting integral. BWD suﬀers from the opposite problem: long integrands and short integrals. Individually, these cause problems when training the transformer as the model is ﬁtted too closely to these patterns, leading to overﬁtting. For example, the results from Lample & Charton show that when a model is trained on only FWD data and tested on BWD data, it only achieves an accuracy of 17.2%, and similar results are shown for training on BWD and testing on FWD. They of course train the model on all three data generation methods, but it is not clear if this addresses all the overﬁtting or simply encodes both sets of patterns.  
   
  Fig. 2. Tree representation for 3x2 + cos(2x) − 1 and 2 + 3 × (5 + 2) from [6]. With some restrictions as to how the trees are constructed, there is a one-to-one mapping between an expression and its tree.  
   
  26  
   
  R. Barket et al.  
   
  Furthermore, these data generation methods suﬀer from producing expressions that are far too similar between the training and testing data. Piotrowski et al. [7] perform a simple analysis of substituting all coeﬃcients with a symbolic CONST token. They examine how many expressions show up in the training set that are also the same in the testing set modulo constant and sign. For the FWD, BWD, and IBP methods, the percentage of unique data were 35%, 75% and 24%, respectively. A key principle of machine learning is that the testing data should be independent of the training data but this casts doubt on whether this is possible through the partition of a dataset containing such similar examples. This may be considered an example of ML “data leakage”. Data leakage is a signiﬁcant issue in machine learning. It happens when the training data we use contains the information that the model is trying to predict. This can result in unpredictable and poor predictions once the model is deployed. 2.2  
   
  Other Existing Datasets  
   
  Currently, there are not that many (public) benchmark datasets in the ﬁeld of symbolic integration, or indeed Computer Algebra more broadly. Maplesoft, the developer of Maple, has an in-house test suite of integrable functions that they use to ensure software quality is maintained when making changes to int. There are 47,745 examples in the Maple test suite. Of these, only 8,174 had elementary integrands with elementary integrals which we currently study. We provide some information from the remaining (integrand, integral) pairs in Table 1. Table 1. A summary of the (integrand, integral) pairs in the Maple test suite (total 8174). We only kept functions with elementary integrands which had elementary integrals Integrand Integral Average Number of Operands  
   
  2.59  
   
  6.52  
   
  Largest Number of Operands  
   
  16  
   
  300  
   
  Is a Polynomial  
   
  996  
   
  1221  
   
  Average Polynomial Degree  
   
  1.80  
   
  2.79  
   
  Largest Polynomial Degree  
   
  199  
   
  200  
   
  Contains Exponentials  
   
  932  
   
  1072  
   
  Contains Logarithms  
   
  756  
   
  Contains Trig or Arctrig functions 2080  
   
  3136 2512  
   
  Contains Radicals  
   
  2024  
   
  2274  
   
  Contains Complex Numbers  
   
  558  
   
  685  
   
  This number of examples would not be suﬃcient to train a deep learning model; for reference, Lample and Charton [6] have access to 88 million examples in Deep Learning for symbolic Mathematics. One great property about the Maple dataset is that it was partly developed as a continuous response to feature requests and bug reports that users would make when using int in Maple. Thus,  
   
  Generating Elementary Integrable Expressions  
   
  27  
   
  it can be said to represent the range of examples of interest to Maple users. Using this dataset to evaluate any models trained would help provide evidence that the model generalizes well for our planned use. Rich et al. [8] developed a Rule-Based Integrator, more commonly known as RUBI. RUBI integrates an expression by applying a collection of symbolic integration rules in a systematic way. Along with RUBI, the authors have compiled a dataset of 72,000 integration problems. There are 9 diﬀerent main categories of functions that exist in the dataset with many examples coming from various textbooks and papers. Similar to the Maple test suite, this dataset would be good for evaluating a model but due to the size of the dataset, it would not be suﬃcient for training a model, at least not a deep learning based model. We thus use the rest of our paper to describe a new method.  
   
  3  
   
  The Risch Algorithm  
   
  The data generation method in this paper is based on the Risch algorithm. To explain the entire Risch algorithm would need us to introduce a lot of theory before even getting to the algorithm explanation. Instead, we will focus on the key parts of the algorithm to help the reader get an intuitive understanding of how it works and refer to [2] or [4, Ch. 11, 12] for a more detailed explanation. For the Risch algorithm to work, we allow elementary extensions over a differential ﬁeld K. A diﬀerential ﬁeld is a ﬁeld with the derivative operator D such that D(a + b) = D(a) + D(b) and D(ab) = aD(b) + bD(a). A constant c is deﬁned as Dc = 0. We usually write the derivative Da = a . Let G be an extension ﬁeld of a diﬀerential ﬁeld F . For an element θ ∈ G, We say that G is an elementary extension of F if θ is one of the following: 1. logarithmic: θ = log(u), u ∈ F . 2. exponential: θ = eu , u ∈ F . 3. algebraic: ∃p ∈ F such that p(θ) = 0. An arbitrary amount of extensions are allowed. Rather than using G to represent the extension, we instead denote Fn−1 = K(θ1 , · · · , θn−1 ) as the previous diﬀerential ﬁeld and Fn = Fn−1 (θn ) as the current elementary extension. Typically, we have K = Q(x) as the base diﬀerential ﬁeld. This paper will focus solely on logarithmic and exponential extensions. We now introduce Liouville’s theorem that states exactly what the form of the integral will be, if it exists. Theorem 1 (Liouville’s Theorem: Thm 5.5.1 in [2]). Let K be a diﬀerential ﬁeld and f ∈ K. Let E be an elementary extension of K. If f ∈ E exists, then there are v0 , · · · , vm ∈ K and constants c0 , · · · , cm ∈ K such that  f = v0 +  
   
  m  i=0  
   
  ci log(vi ).  
   
  28  
   
  R. Barket et al.  
   
  Liouville’s Theorem gives an explicit representation for the integral of f if it is elementary integrable. The Risch algorithm and the subsequent algorithms for computing an integral are based on Liouville’s Theorem. The Risch algorithm will divide the input into two diﬀerent parts. Then, the integral for both parts will take the form of Theorem 1. Risch Algorithm (Chap. 12 in [4]): Let Fn = Fn−1 (θn ) be a diﬀerential ﬁeld of characteristic 0 where θn is elementary over Fn−1 , and θi = 0, 1 ≤ i ≤ n. For any rational function f = g/b with respect to θn , you can divide the numerator with remainder g = P b + R where degθn (R) < degθn (b), and have f = P + Rb .    If f is elementary integrable, it follows that f = P + Rb . We call P the polynomial part and Rb the rational part. We study these two parts for the rest of the section and then develop ways to generate elementary integrable expressions from both these parts in Sect. 4. 3.1  
   
  The Rational Part  
   
  Suppose we wish to integrate Rb , R, b ∈ F = K(x)(θ1 , · · · , θn ). There are two algorithms used to compute this integral: Hermite Reduction and the TragerRothstein (TR) method. Which algorithm is used depends on whether the denominator b is square-free or not. Definition 2 (Square-free). We say a ∈ K[x] is square-free if a has no repeated factors i.e. b ∈ K[x] such that deg(b) > 0 and b2 |a. Equivalently, gcd(a, a ) = 1 When our denominator is not square-free, we use Hermite Reduction. Theorem 2 (Hermite Reduction: Thm 5.3.1 in [2]). Suppose we want to integrate Rb , where R,b ∈ F [θ] and degθ (R) < degθ (b). Use the square-free factorization b = b1 b22 · · · bkk where bi is square-free. Let T = b/bkk . Let σ and τ be the solutions to the diophantine equation σbk T + τ bk = R. Then Hermite reduction tells us that   σ τ + k−1 T R −σ(k − 1) = + . k−1 b b bk bk The main part to notice is that the resulting integral on the right hand side of the equation has a denominator, that is, at least one degree less than the input denominator (because we divide b with its highest degree factor bk ). This algorithm is used recursively until the resulting integral’s denominator has degree one, allowing us to conclude that it is square-free. When this point is reached then the TR-method is used on the remaining integral. This method makes use of the following tool from computational algebra. Definition 3 (Resultant). Suppose we have the following two polynomials with roots αi and βj , αm = 0 = βn :  
   
  Generating Elementary Integrable Expressions  
   
  A = a0 + · · · + am xm = am  
   
  m   
   
  29  
   
  (x − αi ),  
   
  i=1  
   
  B = b0 + · · · + bn xn = bn  
   
  n   
   
  (x − βj ).  
   
  j=1 n Then their resultant is deﬁned as resx (A, B) = (−1)mn bm n am  
   
  n  m  j=1 i=1  
   
  (βj − αi ).  
   
  This implies that 1. res(A, B) = ±res(B, A) 2. res(A, BC) = res(A, B)res(A, C) for all nonzero polynomials A, B, C. Note that the resultant can be calculated without ﬁnding the roots of each polynomial by using Sylvester’s Matrix described on page 285 of [4]. Given an integral with square free denominator Rb , we deﬁne the TragerRothstein resultant polynomial (TR-resultant) as resθ (R − zb , b). We will forego the details of the rest of the algorithm and focus on a key theorem involving the TR-resultant polynomial.  Theorem 3 (Thm 12.7 in [4]). Suppose we are integrating R(x) b(x) , where R(x),  R(x) b(x) ∈ F [x] and b(x) is square-free. Then we have that b(x) is elementary integrable if and only if all the roots in z of the TR-resultant are constants. Theorem 3 is the key theorem that tells us whether a rational expression will be elementary integrable or not, either in application to itself if the denominator is square free, or in application to the ﬁnal integral from Hermite reduction if not. This theorem will also be the key theorem to create the data generation method for rational expressions. 3.2  
   
  The Polynomial Part  
   
  Suppose we are integrating P , a polynomial in F [θ]. We again only focus on logarithmic and exponential extensions from our ﬁeld. There are two diﬀerent procedures to integrate P based on if the extension is logarithmic or exponential. Logarithmic Extension: Let P = p0 +p1 θ+· · ·+pl θm where θ = log(u), u, pi ∈ Fn−1 . It can then be shown that  p0 + · · · + pm θm = q0 + · · · + qm+1 θm+1 +  
   
  k   
   
  ci log(vi ),  
   
  (1)  
   
  i=1  
   
  where qm+1 ∈ K, qi ∈ Fn−1 (1 ≤ i ≤ m), cj ∈ K, vj ∈ Fn−1 (1 ≤ j ≤ k). The idea behind integrating P is to diﬀerentiate Eq. (1) and then equate the coeﬃcients of like powers of θ to solve for each qi . The details of this can be found in [4, page 540].  
   
  30  
   
  R. Barket et al.  
   
  Exponential Extension: The exponential case is similar to the logarithmic case, however a couple of adjustments need to be made. The ﬁrst adjustment is that polynomial exponents are allowed to be negative for exponential extensions. Thus, P = p−l θ−l + · · · + p0 + · · · + pm θm and Eq. (1) becomes:   
   
  p−l θ−l + · · · + p0 + · · · + pm θm = q−l θ−l + · · · + q0 + · · · + qm θm +  
   
  k   
   
  ci log(vi ).  
   
  i=1  
   
  (2) Note that in Eq. (2), the answer has a highest degree of m instead of m + 1.  
   
  4  
   
  Data Generation Based on the Risch Algorithm  
   
  In order to generate elementary integrable expressions, we will do what the Risch algorithm does as an initial step: generate polynomial expressions and rational expressions separately. Polynomial expressions and rational expressions can then be combined together through the additive property of integrals. We ﬁrst focus our attention on the simpler case: the polynomial part. Then, we will show how to generate rational expressions. 4.1  
   
  Polynomial Integrable Expressions  
   
  Generating polynomial expressions (in θ) that are elementary integrable requires choosing the coeﬃcients qi from Eq. (1) or (2) ourselves. We diﬀerentiate the equation and equate coeﬃcients of like powers of θ, resulting in a system of diﬀerential equations. The randomly chosen qi ’s are substituted into this system to generate the integrable expression. It turns out that this is no better than just using the BWD method, i.e., we select a random polynomial in θ with random coeﬃcients in Fn−1 and take its derivative. This is not as general as it could be; one would also have to generate a random integrable expression in the smaller ﬁeld Fn−1 . For the sake of simplicity, we omit this step here, which could be done recursively or by using the BWD method. We provide a small example of the BWD method for polynomials in θ to show how the data is generated. Example 1. Suppose we want to generate a degree 2 polynomial in Q(x)[θ] where θ = ln( x1 ). The coeﬃcients in θ must be in the previous ﬁeld Q(x). For simplicity, the logarithms in Eq. (1) are omitted. The following coeﬃcients are generated randomly: – q0 = −7 + 8x + – q1 = −5 + 4x − – q2 = 1 + 2x  
   
  2 x 6 x  
   
  which results in the polynomial  2     1 1 6 2 P = (1 + 2x) ln + −5 + 4x − ln − 7 + 8x + . x x x x  
   
  Generating Elementary Integrable Expressions  
   
  31  
   
  When diﬀerentiated, we get  
   
  P  = 2 ln  
   
   2     −5 + 4x − 1 1 6 2 (1 + 2x) + 4 + 2 ln + − − x x x x x  
   
  6 x  
   
  +8−  
   
  2 x2  
   
  and the pair (P  , P ) is added to our dataset. 4.2  
   
  Rational Integrable Expressions  
   
  As we will see in a moment, generating rational integrable expressions is more complex than the polynomial case. We will introduce some strategies to generate integrable expressions with square-free denominators (using the TR-method) as well as non square-free denominators (using a combination of Hermite reduction and the TR-method). Note that most of the examples shown here will be using the extension θ = log(u) as this is the harder case to solve. However, extensions with θ = eu will also appear in the dataset produced. Square-Free Denominators: In the normal use of the TR-method, the input is a rational elementary function Rb such that degθ (R) < degθ (b) and b is squarefree. The method then outputs the elementary integral of Rb , or fails if Theorem 3 does not hold. Our goal is to discover polynomials R, b ∈ F [θ] such that Rb is guaranteed to be elementary integrable. The main idea behind the process is to fulﬁll the conditions of Theorem 3 so that we know for sure that the expression is elementary integrable. To accomplish this, the general outline is as follows. 1. Randomly generate the denominator b in its square-free factorization, and keep that ﬁxed. 2. Create a partial fraction decomposition where the denominators are all factors of b, and the numerators are polynomials in θ of degree 1 less than the denominator, with symbolic coeﬃcients. 3. Compute the TR-resultant. 4. The symbolic coeﬃcients of R must be chosen in a way that ensures the roots of the resultant are constant. (a) If the resultant only has factors of degree 2 or less, solve directly for the roots and set each root equal to a constant. (b) Otherwise, the resultant has irreducible factors of degree 3 or higher. Divide the resultant by the leading coeﬃcient to make it monic. Then, the symbolic coeﬃcients must be chosen in such a way that each coeﬃcient of this is constant. We ﬁrst put our input into partial fraction form with symbolic coeﬃcients because when the resultant is calculated, the TR-resultant factors in a way similar to how b factors (See Deﬁnition 3). We can see this with the following example.  
   
  32  
   
  R. Barket et al.  
   
  Example 2. Let b = θ4 − 2θ3 − 2θ2 − 2θ − 3 where θ = log(x), F = Q(x)(log(x)) and we have only done a single extension so n = 1. We wish to discover a class of numerators R so that Rb integrates. – Note that b factors into b = (θ + 1)(θ − 3)(θ2 + 1). – We create the partial fraction representation of our input: a(x) b(x) c(x)θ + d(x) + + , θ+1 θ−3 θ2 + 1 where a, b, c, d ∈ Fn−1 = Q(x). – The factored form of the TR-resultant of  
   
  R b  
   
  is  
   
  −(a(x)x − z)(b(x)x − z)(c(x)2 x2 − 4c(x)xz + d(x)2 x − 2d(x)xz + xz 2 + 4z 2 ). – Recall that by Theorem 3, we need the roots of the resultant to be constant. Setting each factor of the resultant equal to a constant and solving for the symbolic coeﬃcients, we get that a(x) = Cx1 , b(x) = Cx2 , c(x) = Cx3 , and d(x) = Cx4 for any C1 , C2 , C3 , C4 ∈ Q. C1 C2 3 θ+C4 – Therefore, Rb = x(θ+1) + x(θ−3) + C x(θ 2 +1) is elementary integrable for any choice of those constants. We ﬁnd that:  
   
  2  C3 log log(x) + 1 R = + C4 arctan(log(x)) b 2 + C1 log(log(x) + 1) + C2 log(log(x) − 3) . In Example 2, take note that the factored form of the resultant is similar to the factored form of the denominator b: that is, the degree in z of each factor of the resultant is the same as the degree in θ of each factor of b. As well, each symbolic coeﬃcient in the numerator of each partial fraction were also the same unknowns that show up in each factor of the resultant. Example 2 only had linear and quadratic irreducible factors. These are quite easy to solve by just isolating the unknown or using the quadratic formula. In general, degree 3 and higher irreducible factors in the resultant will be much harder to solve. Trying to solve for the roots of an irreducible degree 3 resultant means using the Cardano formula, which produces huge answers for the root. We ﬁnd that when trying to equate any of the roots to a constant and solving for the conditions of R like in Example 2, the expression size blows up and the solution starts to involve many radicals. Since radicals do not lie within our ﬁeld, the symbolic coeﬃcients then need to be chosen in a way such that the radicals disappear which adds an extra layer of complexity. The formulae size is even worse in degree 4 and then there is not even any such formula in surds for higher degree. So instead when the resultant has factors of degree higher than two, we look at two alternative options: assume the numerator to be of a speciﬁc form or analyse the resultant qualitatively to ﬁgure out the conditions of the numerator. We show the former with the following example.  
   
  Generating Elementary Integrable Expressions  
   
  33  
   
  Example 3. Suppose θ = ln(x), F = Q(x)(ln(x)) and b = x(θ3 − x). Note that b is square-free in F . The ﬁrst step is to create a partial fraction decomposition with denominator b and symbolic coeﬃcients for the numerator. Let a(x)θ2 + b(x)θ + c(x) R = . b x(θ3 − x) The TR-resultant is computed as 3 −x − 27x2 z 3 + 27x2 a(x) + 9x2 b(x) + 3x2 c(x) z 2  
   
  2 2 + −9x2 a(x) − 3x2 a(x) b(x) − 9xb(x) c(x) − 3xc(x) z 3  
   
  3  
   
  3  
   
  + a(x) x2 + 3a(x) b(x) c(x) x − b(x) x + c(x) . Finding the solution to the roots explicitly produces huge expressions for a(x), b(x) and c(x) and involve radicals outside our ﬁeld. Instead, we assume the form of the symbolic coeﬃcients to ﬁnd a set of solutions. We will assume they are quadratic polynomials (an arbitrary choice). Let • a(x) = a2 x2 + a1 x + a0 , • b(x) = b2 x2 + b1 x + b0 , • c(x) = c2 x2 + c1 x + c0 , for ai , bi , ci ∈ Q, 0 ≤ i ≤ 2. Since the resultant is cubic in z, it will have three roots. First, substitute the assumed form of the three coeﬃcients into the resultant. Note the leading coeﬃcient of the resultant is (−x3 − 27x2 ). Then, let our resultant be equal to (−x3 − 27x2 )(z − r0 )(z − r1 )(z − r2 ), r1 , r2 , r3 ∈ Q. Consider the equation formed by setting the TR-resultant computed earlier equal to the form just above. Let us move the terms to one side so we have an expression equal to 0. We may now solve for each coeﬃcient of z to be 0 giving the following solution {a0 = 3c1 , a1 = 0, a2 = 0, b0 = 0, b1 = 0, b2 = 0, c0 = 0, c1 = c1 , c2 = 0, r1 = c1 , r2 = c1 , r3 = c1 }. This can now be substituted into R to produce    
   
  R 3c1 ln(x)2 + c1 x 3 = = c ln ln(x) + x . 1 b x(ln(x)3 + x) In Example 3, we assumed a particular form for the symbolic coeﬃcients to ﬁnd a solution. This is a quick way to ﬁnd a set of solutions, however this  
   
  34  
   
  R. Barket et al.  
   
  does not mean we have found all the solutions like with the linear and quadratic cases. Instead, we should try to fulﬁll the conditions of 4(b). That is, the symbolic coeﬃcients are chosen in a way such that all of the coeﬃcients of the TR-resultant are constant. To see why this is true, we give an informal proof. Let the TR-resultant be f ∈ K[z]. We can assume f is monic because if it were not, we will divide out the leading coeﬃcient from the resultant to make f monic. Let Fbe the algebraic closure of K(x), so that f ∈ F [z]. Factor f over F to get f = i (z − ai ), ai ∈ F . Each ai is a root of f . If we want the roots ai ¯ In that case, the to be constant, they should belong to the algebraic closure K. ¯ because they are the polynomials of ai , coeﬃcients of f should also belong to K and they belong to K[x] because of how we deﬁned f . Thus, they belong to ¯ ∩ K[x] which is K. Therefore, f must have constant coeﬃcients for the roots K to be constant. Non Square-Free Denominators: When computing the elementary integral of a rational function Rb , the ﬁrst step is to check whether b is square free or not. Similarly, what technique used to generate an elementary integrable expression depends on whether the ﬁxed denominator b starts as square-free or not. Let us now assume b is not square-free, so the TR-method cannot be used currently. We ﬁrst set up the problem just as with the square-free case: put b in partial fraction form and set symbolic coeﬃcients for each partial fraction. The diﬀerence is that before, we would invoke the TR-method. However, b is not square free yet. Thus, we use Theorem 2, Hermite Reduction, recursively until we get a resulting integral whose denominator is square-free. Then, we use Theorem 3 just as before to ﬁnd the conditions on R that make the whole expression Rb elementary integrable. The main beneﬁt of non square-free denominators is that there will be more choices of freedom in choosing the symbolic coeﬃcients compared to the square-free case. This is shown with the example below. Example 4. Let θ = log(x) and F = Q(x)(log(x)). Let b = θ3 + 2xθ2 + x2 θ + θ2 + 2xθ + x2 . We wish to ﬁnd all R ∈ F such that Rb is elementary integrable. As with Theorem 2, we ﬁrst compute the square-free factorization of b to ﬁnd b = (θ + 1)(θ + x)2 . The partial fraction representation in this case will be R a(x) b(x) c(x) = + + b (θ + 1) (θ + x) (θ + x)2 and we wish to ﬁnd a, b, c ∈ Fn−1 that makes the entire expression elementary integrable. Since b is not square-free, one iteration of Hermite Reduction is done to produce:  c(x) x R =− b (1 + x) (θ + x)    (a(x) + b(x)) θ + a(x) x + b(x) + ( dxd c(x))x + c(x) − c(x)x (θ + 1) 1+x 1+x (1+x)2 . + (θ + 1) (θ + x)  
   
  Generating Elementary Integrable Expressions  
   
  35  
   
  Let us focus on the resulting integral: the denominator is (θ + 1)(θ + x) which is now square-free. Thus, Hermite Reduction is no longer needed and instead, the TR-method is used on it. When the resultant is calculated and the roots of the TR-resultant are solved for (so that Theorem 3 is true), we get that the distinct roots are:  
   
  d  d c(x) x2 + b(x) x2 + dx c(x) x + 2b(x) x + b(x) + c(x) x dx . xa(x) , x3 + 3x2 + 3x + 1 Setting the ﬁrst root to a constant is trivial to solve: a(x) = Cx1 , C1 ∈ Q. The second root condition contains the unknowns b(x) and c(x). This can also be set equal to a constant and then solved for b(x) obtaining d − dx c(x) x2 − c(x) x + C2 , C2 ∈ Q. b(x) = x This means c(x) can be any function from Fn−1 . Let us demonstrate this by trying some values that are arbitrarily chosen: • C1 = 2 =⇒ a(x) = x2 • C2 = 4 and c(x) = x2 + • •  
   
  1 −10x4 +5x3 +60x2 +61x+20 5x =⇒ b(x) = 5x(1+x)2 1 x2 + 5x R 2 −10x4 +5x3 +60x2 +61x+20 + (ln(x)+x)2 b = x(ln(x)+1) + 5x(1+x)2 (ln(x)+x) Then when we integrate Rb , we get:  
   
    
   
  5x3 + 1 R =− + 2 ln(ln(x) + 1) + 4 ln(ln(x) + x) . b 5 (1 + x) (ln(x) + x) Example 4 gives us a much stronger freedom of choice because unlike with the square-free case, we actually get that our coeﬃcient c(x) can be any function in Fn−1 . This eﬀectively means that we have three choices of freedom: one for a(x) (the choice of the constant C1 ), one for b(x) (the choice of C2 ), and one for c(x) (any expression in the previous ﬁeld). In contrast, the only choices of freedom we had in the square-free case were the constants. Additionally, Example 4 had one functional degree of freedom c(x) since one factor from the denominator b was quadratic. In general, we will have more functional degrees of freedom for higher degree factors in the denominator.  
   
  5  
   
  Discussion  
   
  The Risch algorithm is an integral part of any CAS (pun intended). This data generation method discusses how to create expressions that are guaranteed to be elementary integrable by using the Risch algorithm. To understand the beneﬁt of this data generation method, we create a simple dataset of 10,000 (integrand, integral) pairs. To compare against our dataset, we take a sample of 10,000 data points from each of the FWD, BWD, and IBP datasets. Of the 10,000 we created, a third comes from generating polynomial expressions in Sect. 4.1, another third comes from generating rational expressions from Sect. 4.2, and the ﬁnal third comes from combining the two sections together (similar to how the Risch algorithm separates the two parts from each other).  
   
  36  
   
  5.1  
   
  R. Barket et al.  
   
  Risch Data Generation Benefits  
   
  One criticism of the data generation method in [6] was that there were patterns within how the expressions are made, speciﬁcally in the FWD and BWD datasets. Recall from Sect. 2, the BWD method produced long integrands and short integrals whereas the FWD had the opposite problem. We take a closer look by examining the lengths of the integrands and integrals in their testing datasets. Note that the authors represent the mathematical expression in preﬁx (or normal Polish) notation. The length is then just the number of tokens from this representation. The lengths of the (integrand, integral) pairs are shown for all three data methods in Fig. 3.  
   
  Fig. 3. Lengths of the Integrands and Integrals from the three test datasets in [6] as well as our generated dataset.  
   
  Based on Fig. 3, we can see quite the diﬀerence in lengths from the FWD and BWD methods. Suppose we consider an (integrand, integral) pair close in length if the absolute value between the length of the integrand and integral is less than 10. For the FWD and BWD methods, only 29% and 9% of pairs were considered close respectively. The IBP and Risch methods do considerably  
   
  Generating Elementary Integrable Expressions  
   
  37  
   
  better at generating close pairs with 65% and 86% of pairs being considered close respectively. As mentioned earlier in Sect. 2, the presence of these patterns mean that there is a risk of bias in an ML model trained on such data. Recall also from Sect. 2 how much of the data only diﬀered by the choice of constants in the expression, making IBP a weaker generation method. However, because of the choices of freedom we have in making our integrable expressions from the Risch algorithm, we can alleviate the two problems shown. This is true for both the polynomial expressions, the rational expressions, and a combination of the two. The only patterns present in our dataset are those required for the expression to be elementary integrable. With the dataset generated, Fig. 3d shows the lengths of the produced (integrand, integral) pairs through the Risch algorithm in preﬁx notation. Figure 3d shows that the lengths between the integrands and integrals are much more evenly distributed, ﬁxing the problem of the FWD and BWD datasets. Recall that the FWD method is also not able to generate (integrand, integral pairs) often, leading to a slow data generation method. Our method guarantees integrands that are elementary integrable 100% of the time, making it more eﬃcient. Furthermore, we do the same analysis of examining the dataset by substituting the integer coeﬃcients with a CONST token, and ﬁnd that 97% of the data remains unique. The reason it did not reach 100% is due to data generated in Sect. 4.2, the rational square-free case. The choices of freedom in this case is usually only the choice of the constant. Some randomly generated denominators happened to be the same through chance and since the solutions only diﬀer by a constant, they end up being the same when replaced with a CONST token. If wanted, these can be removed from the dataset. 5.2  
   
  Future Work  
   
  We have presented a novel method of creating elementary integrable functions. However, there is much work that could still be done. Bronstein [2], when ﬁrst introducing the Risch algorithm, separates the algorithm into four diﬀerent cases: logarithmic transcendental, exponential transcendental, pure algebraic and mixed algebraic/transcendental cases. So far, we have only explored the ﬁrst two cases. It would be beneﬁcial to understand the latter two cases as radicals are something that should not be excluded from the dataset. To understand the latter two cases, one can read [1] or [10]. As with the present paper, the idea would be to ﬁnd the conditions in the polynomial and rational cases that make the entire expression elementary integrable. Furthermore, the current data generation method proposed can be further explored in a number of ways. For one, towers of extensions (i.e. Fn , n ≥ 2) have only been considered for polynomial expressions thus far. This can also be done with the rational expression generation method to create a greater variety of elementary integrable expressions. Also, working with irreducible cubic and higher degree polynomials (in θ) for the rational case should further be examined. We have shown that when we assume the form of the numerator (Example 3), we can ﬁnd solutions. However, it would be desirable to ﬁnd all possible numerators  
   
  38  
   
  R. Barket et al.  
   
  that make the entire expression integrable. The key to this would be examining the TR-resultant and instead of explicitly solving for the roots, qualitatively analysing the resultant and ﬁguring out the conditions of the generic coeﬃcients would help overcome the computational cost of explicitly solving for the solution as discussed at the end of Sect. 4.2. Acknowledgements. The authors would like to thank James Davenport and Gregory Sankaran for helpful discussion on conditions around constant roots of polynomials. They would also like to thank John May for help understanding Maple’s integration command and testing data and the anonymous reviewers for their comments which improved the paper. Matthew England is supported by EPSRC Project EP/T015748/1, Pushing Back the Doubly-Exponential Wall of Cylindrical Algebraic Decomposition (DEWCAD). Rashid Barket is supported on a scholarship provided by Maplesoft and Coventry University.  
   
  References 1. Bronstein, M.: Integration of elementary functions. J. Symb. Comput. 9(2), 117– 173 (1990). https://doi.org/10.1016/S0747-7171(08)80027-2 2. Bronstein, M.: Symbolic Integration I: Transcendental Functions, Algorithms and Computation in Mathematics, vol. 1. Springer, Heidelberg (2005). https://doi.org/ 10.1007/978-3-662-03386-9 3. Huang, Z., England, M., Wilson, D., Davenport, J.H., Paulson, L.C., Bridge, J.: Applying machine learning to the problem of choosing a heuristic to select the variable ordering for cylindrical algebraic decomposition. In: Watt, S.M., Davenport, J.H., Sexton, A.P., Sojka, P., Urban, J. (eds.) CICM 2014. LNCS (LNAI), vol. 8543, pp. 92–107. Springer, Cham (2014). https://doi.org/10.1007/978-3-31908434-3_8 4. Geddes, K.O., Czapor, S.R. Labahn, G.: Algorithms for Computer Algebra. Springer, New York (1992). https://doi.org/10.1007/b102438 5. Kuipers, J., Ueda, T., Vermaseren, J.: Code optimization in FORM. Comput. Phys. Commun. 189, 1–19 (2015). https://doi.org/10.1016/j.cpc.2014.08.008 6. Lample, G., Charton, F.: Deep learning for symbolic mathematics. In: Proceedings of the International Conference on Learning Representations (ICLR) (2020). https://doi.org/10.48550/arxiv.1912.01412 7. Piotrowski, B., Urban, J., Brown, C.E., Kaliszyk, C.: Can neural networks learn symbolic rewriting? In: Proceedings of the Artificial Intelligence and Theorem Proving (AITP) (2019). https://doi.org/10.48550/arXiv.1911.04873 8. Rich, A., Scheibe, P., Abbasi, N.: Rule-based integration: an extensive system of symbolic integration rules. J. Open Source Softw. 3(32), 1073 (2018). https://doi. org/10.21105/joss.01073 9. Simpson, M.C., Yi, Q., Kalita, J.: Automatic algorithm selection in computational software using machine learning. In: 15th IEEE International Conference on Machine Learning and Applications (ICMLA), pp. 355–360 (2016). https://doi. org/10.1109/ICMLA.2016.0064 10. Trager, B.M.: Integration of algebraic functions. Ph.D. thesis, Massachusetts Institute of Technology (1984). https://dspace.mit.edu/handle/1721.1/15391  
   
  How to Automatise Proofs of Operator Statements: Moore–Penrose Inverse; A Case Study Klara Bernauer1 , Clemens Hofstadler2(B) , and Georg Regensburger2 1 Johannes Kepler University Linz, Linz, Austria Institute of Mathematics, University of Kassel, Kassel, Germany {clemens.hofstadler,regensburger}@mathematik.uni-kassel.de 2  
   
  Abstract. We describe a recently developed algebraic framework for proving ﬁrst-order statements about linear operators by computations with noncommutative polynomials. Furthermore, we present our new SageMath package operator_gb, which oﬀers functionality for automatising such computations. We aim to provide a practical understanding of our approach and the software through examples, while also explaining the completeness of the method in the sense that it allows to ﬁnd algebraic proofs for every true ﬁrst-order operator statement. We illustrate the capability of the framework in combination with our software by a case study on statements about the Moore-Penrose inverse, including classical facts and recent results, presented in an online notebook. Keywords: Linear operators · First-order statements procedure · Noncommutative polynomials  
   
  1  
   
  · Semi-decision  
   
  Introduction  
   
  In its section on the Moore-Penrose inverse, the Handbook of Linear Algebra [20, Sec. I.5.7] lists, besides the deﬁning identities of the Moore-Penrose inverse (1), a number of classical facts: 1. Every A ∈ Cm×n has a unique pseudo-inverse A† . 2. If A ∈ Rm×n , then A† is real. 3. If A ∈ Cm×n [. . . ] has a full rank decomposition A = BC [. . . ], then A† can be evaluated using A† = C ∗ (B ∗ AC ∗ )−1 B ∗ . 4. If A ∈ Cm×n [. . . ] has an SVD A = U ΣV ∗ , then its pseudo-inverse is A† = V Σ † U ∗ [. . . ]. .. .  
   
  The second author was supported by the Austrian Science Fund (FWF): P32301. c The Author(s), under exclusive license to Springer Nature Switzerland AG 2023  F. Boulier et al. (Eds.): CASC 2023, LNCS 14139, pp. 39–68, 2023. https://doi.org/10.1007/978-3-031-41724-5_3  
   
  40  
   
  K. Bernauer et al.  
   
  Now, imagine the following task: Prove as many of these facts as possible, using only the deﬁning identities and no additional references. Trying to do this by hand is a non-trivial task for any non-expert. However, a recently developed framework [17,29] allows to reduce proving such statements to computations with noncommutative polynomials, which can be fully automated, using for example our newly developed software package operator_gb. These polynomial computations yield algebraic proofs that are not only valid for matrices but for any setting where the statement can be formulated (e.g., linear operators on Hilbert spaces, homomorphisms of modules, C ∗ -algebras, rings, etc.). Based on this, starting only from the deﬁning equations, the ﬁrst author was able to prove a majority of the facts on the Moore-Penrose inverse in the Handbook in a fully automated way in form of her Bachelor’s thesis [1]. Various examples of automated proofs of matrix and operator identities based on computations with noncommutative polynomials are also given in [30,31]. In this paper, we describe this approach of using computer algebra to automatise the process of proving ﬁrst-order statements of matrices or linear operators like the ones listed above. The goal of the paper is twofold. Firstly, readers will be able to gain a practical understanding of the framework by reading Sect. 2 and 3, learning how to translate operator statements into polynomial computations and how to use the software to compute algebraic proofs. In Sect. 2, we also discuss previous work on using noncommutative polynomials for proving operator identities. Secondly, we explain that the framework allows to prove every universally true ﬁrst-order operator statement using the semi-decision Procedure 1, showing that the approach is complete in this sense. In particular, in Sect. 5, we give a self-contained description of the framework developed in [17], with a particular focus on applicability. We focus on the simple, yet in practice most common, case of so-called ∀∃-statements, which drastically reduces the complexity of the presentation compared to [17] where arbitrary ﬁrst-order formulas are treated. We note that this is in fact no restriction as any ﬁrst-order formula can be transformed into an equivalent ∀∃-formula using the concept of Herbrandisation and Ackermann’s reduction, as detailed in [17, Sec. 2.2, 2.3]. We also present our new SageMath package operator_gb1 , which provides functionality for Gröbner basis computations in the free algebra, similar to [21]. In addition, our package oﬀers dedicated methods for automatising the proofs of operator statements. Most importantly, it provides methods for ﬁnding elements of speciﬁc form in polynomial ideals [16]. This not only allows to automatically prove existential statements, but also to eﬀectively model many properties of operators (e.g., conditions on ranges and kernels, injectivity and surjectivity, cancellability properties, etc.). For further details, we refer to Sect. 4, and to Appendix A for the corresponding commands. Finally, in Sect. 6, we illustrate the capability of the framework in combination with our software in form of a case study on statements regarding the Moore-Penrose inverse. We have successfully automated the proofs of a variety 1  
   
  Available at https://github.com/ClemensHofstadler/operator_gb.  
   
  How to Automatise Proofs of Operator Statements  
   
  41  
   
  of theorems, ranging from the classical facts in the Handbook [20, Sec. I.5.7] over important characterisations of the reverse order law for the Moore-Penrose inverse [6] to very recent improvements of Hartwig’s triple reverse order law [5] that were found with the help of our software. We have assembled a Jupyter notebook containing the automated proofs of all statements, which is available at https://cocalc.com/georeg/Moore-Penrose-case-study/notebook.  
   
  2  
   
  From Operator Identities to Noncommutative Polynomials  
   
  In 1920, E.H. Moore [23] generalised the notion of the inverse of a matrix from nonsingular square matrices to all, also rectangular, matrices. This generalised inverse, by Moore also called “general reciprocal”, was later rediscovered by Roger Penrose [26], leading to the now commonly used name Moore-Penrose inverse. Moore established, among other main properties, existence and uniqueness of his generalised inverse and justiﬁed its application to linear equations. However, Moore’s work was mostly overlooked during his lifetime due to his peculiar and complicated notations, which made his results inaccessible for all but very dedicated readers. In contrast, Penrose characterised this generalised inverse by four simple identities, yielding the following deﬁnition: The Moore-Penrose inverse of a complex matrix A is the unique matrix B satisfying the four Penrose identities ABA = A,  
   
  BAB = B,  
   
  B ∗ A∗ = AB,  
   
  A∗ B ∗ = BA,  
   
  (1)  
   
  where P ∗ denotes the Hermitian adjoint of a complex matrix P . Typically, the Moore-Penrose inverse of A is denoted by A† . Using the Penrose identities, and their adjoint versions that follow, makes basic computations involving the Moore-Penrose inverse very simple. For example, uniqueness can be showed as follows. If B and C both satisfy (1), then B = BAB = BACAB = BACB ∗ A∗ = BC ∗ A∗ B ∗ A∗ = BC ∗ A∗ = BAC = A∗ B ∗ C = A∗ C ∗ A∗ B ∗ C ∗  
   
  (2)  
   
  ∗  
   
  = A C BAC = CABAC = CAC = C. At the end of the last century, people realised that matrix identities, or more generally identities of linear operators, can be modelled by noncommutative polynomials, and that computations like (2) can be automated using algebraic computations involving such polynomials. For example, in the pioneering work [12,13] polynomial techniques were used to simplify matrix identities in linear systems theory, and in [11] similar methods allowed to discover operator identities and to solve matrix equations. Noncommutative polynomials are elements in a free (associative) algebra RX with coeﬃcients in a commutative ring R with unity and noncommutative indeterminates in a (typically ﬁnite) set X. Monomials are given by words over X, that is elements in the free monoid X, and multiplication is given by  
   
  42  
   
  K. Bernauer et al.  
   
  concatenation of words. In particular, indeterminates still commute with coeﬃcients, but not with each other. Intuitively, a matrix or operator identity B = C, or equivalently B − C = 0, can be identiﬁed with the polynomial f (b, c) = b − c. More generally, identities of composite operators can be translated into noncommutative polynomials by introducing a noncommutative indeterminate for each basic non-zero operator, and by uniformly replacing each operator by the respective indeterminate in the diﬀerence of the left and right hand side of each identity. Potentially present zero operators are simply replaced by the zero in RX. For example, to express the Penrose identities (1), we introduce indeterminates a, b, a∗ , b∗ to represent the matrices A, B, and their adjoints, and form the polynomials aba − a,  
   
  bab − b,  
   
  b∗ a∗ − ab,  
   
  a∗ b∗ − ba.  
   
  (3)  
   
  With this, the computation (2) corresponds to the polynomial statement b − c = − (bab − b) − b(aca − a)b − bac(b∗ a∗ − ab) − b(c∗ a∗ − ac)b∗ a∗ − bc∗ (a∗ b∗ a∗ − a∗ ) + b(c∗ a∗ − ac) − (a∗ b∗ − ba)c − (a∗ c∗ a∗ − a∗ )b∗ c + a∗ c∗ (a∗ b∗ − ba)c + (a∗ c∗ − ca)bac + c(aba − a)c + (cac − c). (4) This shows that b − c can be represented as a two-sided linear combination of the polynomials encoding that B and C satisfy the Penrose identities for A. Remark 1. To model the involution ∗ on the polynomial level, we introduce an additional indeterminate for the adjoint of each basic operator and simplify all operator expressions using the following identities before translating them into polynomials. (P + Q)∗ = P ∗ + Q∗ ,  
   
  (P Q)∗ = Q∗ P ∗ ,  
   
  (P ∗ )∗ = P.  
   
  (5)  
   
  Furthermore, whenever an identity P = Q holds, then so does the adjoint identity P ∗ = Q∗ , and these additional identities have to be translated into polynomials as well. Thus, to express that B is the Moore-Penrose inverse of A on the polynomial level, we have to add to (3) the polynomials corresponding to the adjoint identities. Since the last two Penrose identities are self-adjoint, this yields the two additional elements a∗ b∗ a∗ − a∗ and b∗ a∗ b∗ − b∗ . We note that these additional polynomials can be essential for proofs and also appear in (4). Algebraically, the relation (4) means that the polynomial b−c lies in the (twosided) ideal generated by the polynomials encoding that B and C are MoorePenrose inverses of A. We call such a representation of an ideal element in terms of the ideal’s generators a cofactor representation. It is always the case, that, if an operator identity follows from given identities by arithmetic operations with operators (i.e., addition, composition, and scaling), then the polynomial corresponding to this identity is contained in the ideal.  
   
  How to Automatise Proofs of Operator Statements  
   
  43  
   
  However, not all polynomials that lie in the ideal correspond to valid operator identities, because, in contrast to computations with actual operators, computations with polynomials are not restricted and all sums and products can be formed. Obviously, elements of the ideal that do not comply with the formats of the matrices (or, more generally, the domains and codomains of the operators) cannot correspond to identities of operators. Thus, a priori, when proving an operator identity by verifying ideal membership like in (4), one has to ensure that every term appearing in a cofactor representation respects the restrictions imposed by the operators. Algorithmically, ideal membership of commutative polynomials can be decided by Buchberger’s algorithm [3] computing a Gröbner basis of the ideal. In contrast, ideal membership of noncommutative polynomials is only semidecidable in general. This is a consequence of the undecidability of the word problem. More precisely, verifying ideal membership of noncommutative polynomials is always possible, using a noncommutative analog of Buchberger’s algorithm [22,24] to enumerate a (possibly inﬁnite) Gröbner basis. However, disproving ideal membership is generally not possible. Nevertheless, if a polynomial can be veriﬁed to lie in an ideal, then, as a byproduct, a cofactor representation of the polynomial in terms of the generators can be obtained. This representation serves as a certiﬁcate for the ideal membership and can be checked independently. Our SageMath software package operator_gb allows to certify ideal membership of noncommutative polynomials by computing cofactor representations. We illustrate its usage to compute the representation given in (4). To generate the polynomials encoding the Penrose identities, the package provides the command pinv. Furthermore, it allows to automatically add to a set of polynomials the corresponding adjoint elements, using the command add_adj. # load the package sage: from operator_gb import * # create free algebra sage: F. = FreeAlgebra(QQ) # generate Moore-Penrose equations for b and c sage: Pinv_b = pinv(a, b, a_adj, b_adj) sage: Pinv_c = pinv(a, c, a_adj, c_adj) # add the corresponding adjoint statements sage: assumptions = add_adj(Pinv_b + Pinv_c) # form a noncommutative ideal sage: I = NCIdeal(assumptions) # verify ideal membership of the claim sage: proof = I.ideal_membership(b-c) # print the found cofactor representation  
   
  44  
   
  K. Bernauer et al.  
   
  sage: pretty_print_proof(proof, assumptions) b-c = (-c + c*a*c) + b*c_adj*(-a_adj + a_adj*b_adj*a_adj) - b*a*c*(-a*b + b_adj*a_adj) - b*(-a + a*c*a)*b + b*(-a*c + c_adj*a_adj) - b*(-a*c + c_adj*a_adj)*b_adj*a_adj - (-b + b*a*b) + (-c*a + a_adj*c_adj)*b*a*c - (-a_adj + a_adj*c_adj*a_adj)*b_adj*c + c*(-a + a*b*a)*c - (-b*a + a_adj*b_adj)*c + a_adj*c_adj*(-b*a + a_adj*b_adj)*c Remark 2. The computed representation is equal to (4) up to a reordering of summands. The correctness of a computed cofactor representation can be veriﬁed easily by expanding it, which only requires basic polynomial arithmetic. Our package allows to do this using the command expand_cofactors. # reusing the assumptions and proof from above sage: expand_cofactors(proof, assumptions) b - c The pioneering work mentioned above exploited the fact that the operations used in the noncommutative version of Buchberger’s algorithm respect the restrictions imposed by domains and codomains of operators, cf. [12, Thm. 25] or [31, Thm. 1]. Thus, using Buchberger’s algorithm, proving an operator identity can be reduced to verifying ideal membership of the corresponding polynomial. Only recently it was observed that in fact any veriﬁcation of ideal membership, even one that does not comply with the domains and codomains of the operators, allows to deduce a correct statement about linear operators, provided that all initial polynomials correspond to actual operator identities [29]. This implies that the veriﬁcation of the ideal membership can be done completely independently of the operator context. In particular, this also means that the cofactor representation given in (4) immediately yields the uniqueness statement of the Moore-Penrose inverse of a complex matrix. Moreover, since the polynomial computation is independent of the concrete operator context, this representation also proves a corresponding statement in every setting where it can be formulated. For example, we immediately obtain an analogous result for bounded linear operators between Hilbert spaces or for elements in C ∗ -algebras. In fact, the most general setting, that is, covered by the polynomial computation is that of morphisms in a preadditive semicategory.  
   
  How to Automatise Proofs of Operator Statements  
   
  45  
   
  Definition 1. A semicategory C (also called semigroupoid) consists of – a class Ob(C) of objects; – for every two objects U, V ∈ Ob(C), a set Mor(U, V ) of morphisms from U to V ; for A ∈ Mor(U, V ), we also write A : U → V ; – for every three objects U, V, W ∈ Ob(C), a binary operation ◦ : Mor(V, W ) × Mor(U, V ) → Mor(U, W ) called composition of morphisms, which is associative, that is, if A : V → W , B : U → V , C : T → U , then A ◦ (B ◦ C) = (A ◦ B) ◦ C; A semicategory C is called preadditive if every set Mor(U, V ) is an abelian group such that composition of morphisms is bilinear, that is, A ◦ (B + C) = (A ◦ B) + (A ◦ C)  
   
  and  
   
  (A + B) ◦ C = (A ◦ C) + (B ◦ C),  
   
  where + is the group operation. A semicategory can be thought of as a collection of objects, linked by arrows (the morphisms) that can be composed associatively. Preadditive semicategories have the additional property that arrows with the same start and end can be added, yielding an abelian group structure, that is, compatible with the composition of morphisms. Formally, a (preadditive) semicategory is just a (preadditive) category without identity morphisms. For further information, see for example [8, Sec. 2] or [33, App. B]. We also note that the words object and morphism do not imply anything about the nature of these things. Intuitively, however, one can think of objects as sets and of morphisms as maps between those sets. We list some classical examples of preadditive semicategories. Example 1. In the following, R denotes a ring (not necessarily with 1). 1. The ring R can be considered as a preadditive semicategory with only one object, and thus, only a single set of morphisms consisting of the underlying abelian group of R. Composition of morphisms is given by the ring multiplication. 2. The set Mat(R) of matrices with entries in R can be considered as a preadditive category by taking as objects the sets Rn for all positive natural numbers n and letting Mor(Rn , Rm ) = Rm×n . Composition is given by matrix multiplication. 3. The category R-Mod of left modules over R is a preadditive semicategory. Here, objects are left R-modules and morphisms are module homomorphisms between left R-modules. As a special case, we see that K-Vect, the category of vector spaces over a ﬁeld K, is a preadditive semicategory. Note that the objects in these categories form proper classes and not sets. 4. More generally, every preadditive category is a preadditive semicategory, thus so are, in particular, abelian categories. Using preadditive semicategories, we can summarise the discussion of this section in the following theorem. In Sect. 5, we provide with Theorem 4 a theoretical justiﬁcation for this conclusion. In the following, we identify each identity  
   
  46  
   
  K. Bernauer et al.  
   
  of morphisms P = Q with the noncommutative polynomial p−q using the translation described above. Furthermore, for noncommutative polynomials f1 , . . . , fr , we denote by (f1 , . . . , fr ) the (two-sided) ideal generated by f1 , . . . , fr , consisting of all two-sided linear combinations of the fi ’s with polynomials as coeﬃcients. Theorem 1. An identity S = T of morphisms in a preadditive semicategory follows from other identities A1 = B1 , . . . , An = Bn if and only if the ideal membership of noncommutative polynomials s − t ∈ (a1 − b1 , . . . , an − bn ) holds in the free algebra ZX. Thus, based on Theorem 1 and the representation (4), we can conclude this section with the following result concerning the uniqueness of the Moore-Penrose inverse. To this end, we recall that a semicategory is involutive if it is equipped with an involution ∗ that sends every morphism A : U → V to A∗ : V → U and that satisﬁes (5). Theorem 2. Let A be a morphism in an involutive preadditive semicategory. If there exist morphisms B and C satisfying (1), then B = C. Thus far, our software package only supports computations in the free algebra QX. To ensure that the computations are also valid over ZX, as required by Theorem 1, one has to check whether all coeﬃcients that appear in the computed cofactor representation are in fact integers. The following routine certify builds a user-friendly wrapper around the ideal membership veriﬁcation that also includes these checks. It raises a warning if non-integer coeﬃcients appear in the computed cofactor representation. sage: F. = FreeAlgebra(QQ) sage: Pinv_b = pinv(a, b, a_adj, b_adj) sage: Pinv_c = pinv(a, c, a_adj, c_adj) sage: assumptions = add_adj(Pinv_b + Pinv_c) sage: proof = certify(assumptions, b-c) Computing a (partial) Gröbner basis and reducing the claim... Done! Ideal membership of all claims could be verified! Remark 3. We note that the computed proof is the same as that computed by the ideal_membership routine before. In many situations, all involved identities are of the form P = Q, where P and Q are compositions of basic operators or zero, as, for example, in case of the Penrose identities (1). In such cases, all involved polynomials are binomials of the form p − q, where p and q are monomials in X or zero. For these scenarios, certify is guaranteed to compute a cofactor representation with integer coefﬁcients, provided that one exists. However, for arbitrary polynomials, it could happen that certify only discovers a cofactor representation with rational coefﬁcients, even if an alternative representation with integer coeﬃcients exists. We note, however, that in all the examples we have considered thus far, this situation has never occurred.  
   
  How to Automatise Proofs of Operator Statements  
   
  3  
   
  47  
   
  Treating Existential Statements  
   
  Theorem 1 provides a method to verify whether an operator identity follows from other identities by checking ideal membership of noncommutative polynomials. Although this technique is useful for proving various non-trivial statements, it still has its limitations. Speciﬁcally, it does not cover existential statements that arise, for example, when solving operator equations. This type of statement requires a slightly extended approach and cannot be proven solely by checking ideal membership. In this section, we discuss how to treat existential statements. As an illustrative example, we consider the existence of the Moore-Penrose inverse for complex matrices. More precisely, we show that every complex matrix has a Moore-Penrose inverse, using polynomial computations. In more general settings (e.g., bounded linear operators on Hilbert spaces, C ∗ algebras), not every element has a Moore-Penrose inverse. Therefore, a crucial step in proving the desired statement is to characterise the fact that we are considering (complex) matrices. In particular, since the polynomial framework can only deal with identities of operators, we have to express this fact in terms of identities. One possibility to do this is via the singular value decomposition, which implies that, for every complex matrix A, there exist matrices P, Q with P A∗ A = A  
   
  and  
   
  AA∗ Q = A.  
   
  (6)  
   
  For example, if A = U ΣV ∗ is a singular value decomposition of A, then P = Q = U Σ + V ∗ is a possible choice, where Σ + is obtained from Σ by replacing the non-zero diagonal entries by their reciprocals, and thus satisﬁes ΣΣ + Σ ∗ = Σ ∗ Σ + Σ = Σ. Using this property of matrices, we can formalise the statement we consider in this section as the ﬁrst-order formula ∀A, P, Q ∃B : (P A∗ A = A ∧ AA∗ Q = A) =⇒ (1). In the polynomial framework, the only possibility to prove such an existential statement is to derive an explicit expression for the existentially quantiﬁed objects. Once such an explicit expression is obtained, the statement can be reformulated as a basic statement concerning identities, to which Theorem 1 can be applied. For our example, this means ﬁnding an expression for B in terms of A, P, Q and their adjoints, modulo the assumptions (6). Algebraically, this corresponds to ﬁnding a polynomial b = b(a, p, q, a∗ , p∗ , q ∗ ) such that the elements (3), representing the Penrose identities (1), lie in the ideal generated by pa∗ a − a,  
   
  aa∗ q − a,  
   
  a∗ ap∗ − a∗ ,  
   
  q ∗ aa∗ − a∗ ,  
   
  (7)  
   
  encoding the assumptions (6). Through the use of Gröbner basis techniques, it is possible to employ a number of heuristics for ﬁnding elements of certain form in noncommutative polynomial ideals [16]. One such approach involves introducing a dummy variable x for the desired expression b. With this dummy variable, we consider the ideal I  
   
  48  
   
  K. Bernauer et al.  
   
  generated by the assumptions (in our example given by (7)) and by the identities that b shall satisfy, but with b replaced by x (in our example these are the MoorePenrose identities (3) for x). Every polynomial of the form x−b in I corresponds to a candidate expression b for b, and by applying the elimination property of Gröbner bases [2], we can systematically search for such candidate expressions. Our software package oﬀers a user-friendly interface that simpliﬁes the process of searching for expressions of this nature. sage: sage: sage: sage: sage:  
   
  F. = FreeAlgebra(QQ) assumptions = add_adj([a - p*a_adj*a, a - a*a_adj*q]) Pinv_x = add_adj(pinv(a, x, a_adj, x_adj)) I = NCIdeal(Pinv_x + assumptions) I.find_equivalent_expression(x) [- x + a_adj*q*x, - x + a_adj*p*x, - x + a_adj*q*p_adj, - x + a_adj*x_adj*x]  
   
  Three out of the four candidate expressions for b found by the heuristic still contain the dummy variable x or its adjoint, and are thus useless. However, the third polynomial x − a∗ qp∗ shows that b = a∗ qp∗ is a desired representation. We use our software to show that b satisﬁes the Moore-Penrose equations under the assumptions (7). sage: MP_candidate = a_adj * q * p_adj sage: MP_candidate_adj = p * q_adj * a sage: claims = pinv(a, MP_candidate, a_adj, MP_candidate_adj) sage: proof = certify(assumptions, claims) Computing a (partial) Gröbner basis and reducing the claims... Done! Ideal membership of all claims could be verified! We note that, here, claims is a list consisting of four polynomials, one for each of the four Penrose identities. In such cases, certify veriﬁes the ideal membership of each element in the list and returns a list, here assigned to proof, providing a cofactor representation for each polynomial in claims. Thus, we can conclude that every complex matrix A has a Moore-Penrose inverse A† , given by A† = A∗ QP ∗ with P, Q as in (6). More generally, by Theorem 1, we have proven the following statement. Theorem 3. Let A be a morphism in an involutive preadditive semicategory. If there exist morphisms P and Q satisfying (6), then A has a Moore-Penrose inverse A† , given by A† = A∗ QP ∗ . Remark 4. Typically, under the assumptions (6) the Moore-Penrose inverse is expressed by the formula A† = Q∗ AP ∗ , cf. [28, Lem. 3]. We note that this expression is equivalent to ours, and can be found using our software by changing the monomial order underlying the polynomial computation.  
   
  How to Automatise Proofs of Operator Statements  
   
  49  
   
  sage: I.find_equivalent_expression(x, ....: order=[[q,q_adj,a,a_adj,p,p_adj],[x,x_adj]])[0] - q_adj*a*p_adj + x This gets to show that the output of the polynomial heuristics depends strongly on several parameters, and in particular, on the used monomial order. We could prove Theorem 3 by explicitly constructing an expression for the existentially quantiﬁed operator. This now raises the question whether this is always possible or whether we just got lucky in this example. Herbrand’s theorem [4,14], a fundamental result in mathematical logic, provides an answer to this question. It states that such an explicit representation always exists and can be constructed as a polynomial expression in terms of the basic operators appearing in the statement, provided that the operator statement is true in every preadditive semicategory. We refer to Theorem 5 for the precise statement. Thus, by enumerating all such polynomial expressions, we are guaranteed to ﬁnd a correct instantiation if the considered statement is correct. Of course, naively enumerating all possible polynomial expressions quickly becomes infeasible. Therefore, it is important to have good heuristics that allow to systematically search for suitable candidate expressions. Our software package implements, apart from the heuristic described above, several such techniques for ﬁnding polynomials of special form in noncommutative ideals. We refer to Appendix A for further information and the corresponding commands. Most importantly, it provides methods for ﬁnding factorisations of given operators. This allows to eﬀectively model many properties of operators, including conditions on ranges and kernels, as well as injectivity and surjectivity, or more generally, cancellability properties. In the following section, we discuss how properties like these can be treated within the framework.  
   
  4 4.1  
   
  Treating Common Properties Real Matrices  
   
  A property that appears regularly in matrix statements, especially in combination with the Hermitian adjoint A∗ , is that of having matrices over the reals. It can be encoded by decomposing the Hermitian adjoint A∗ into an entrywise complex conjugation, denoted by AC , followed by a transposition, that is, A∗ = (AC )T . With this, a matrix A being real can be expressed algebraically by the identity A = AC , exploiting the fact that the conjugate of a real number is the number itself. To model the complex conjugation and the transposition on the polynomial level, we proceed analogous to modelling the involution (see Remark 1). We introduce additional variables aC and aT for the complex conjugate and the transpose, respectively, of each basic operator A. Additionally, for every assumption P = Q, we have to translate, next to the corresponding adjoint identity  
   
  50  
   
  K. Bernauer et al.  
   
  P ∗ = Q∗ , now also the transposed identity P T = QT as well as the conjugated identity P C = QC into polynomials. These additional identities ﬁrst have to be simpliﬁed using the following rules that relate the diﬀerent function symbols to each other.  P if α = β α α α α β (P ) = , (P + Q) = P + Q , P γ if α = β (P Q)C = P C QC ,  
   
  (P Q)δ = Qδ P δ ,  
   
  with α, β, γ, δ ∈ {∗, C, T } such that γ = α, β and δ = C. As an illustrative example, we consider the statement that the Moore-Penrose inverse B of a real matrix A is real as well. With the help of our software package, it can be proven as follows. sage: F. = FreeAlgebra(QQ) # the basic assumptions sage: Pinv_b = add_adj(pinv(a, b, a_adj, b_adj)) # the transposed and conjugated assumptions sage: Pinv_b_tr = [a_tr*b_tr*a_tr - a_tr, b_tr*a_tr*b_tr - b_tr, ....: a_tr*b_tr - b_c*a_c, b_tr*a_tr - a_c*b_c] sage: Pinv_b_c = [a_c*b_c*a_c - a_c, b_c*a_c*b_c - b_c] # assumption that a is real sage: a_real = [a - a_c, a_tr - a_adj] sage: assumptions = Pinv_b + Pinv_b_tr + Pinv_b_c + a_real sage: proof = certify(assumptions, b - b_c) Computing a (partial) Gröbner basis and reducing the claims... Done! Ideal membership of all claims could be verified! 4.2  
   
  Identity Operators  
   
  Next, we discuss how to handle identity matrices or operators. While zero operators have a natural translation into the zero polynomial, identity operators cannot be directly mapped to the multiplicative identity 1 in the free algebra, as this would constitute a many-to-one mapping and a loss of information. We note that this is not an issue when mapping all zero operators to the zero polynomial, as the zero polynomial does not aﬀect any polynomial computations. Instead, identity operators have to be treated like any other basic operator, which means introducing a new indeterminate iu for every identity operator IU and explicitly adding the identities satisﬁed by IU to the assumptions. In particular, these are the idempotency of IU , the fact that IU is self-adjoint, and the identities AIU = A and IU B = B for all basic operators A, B for which these expressions are well-deﬁned. We illustrate the handling of identity operators in the next section.  
   
  How to Automatise Proofs of Operator Statements  
   
  4.3  
   
  51  
   
  Injectivity, Surjectivity, and Full Matrix Ranks  
   
  Injectivity and surjectivity of operators appear regularly as properties in statements. They can be encoded by exploiting the following classical fact. Lemma 1. Let U, V be non-empty sets. A function A : U → V is 1. injective if and only if A has a left inverse B : V → U ; 2. surjective if and only if A has a right inverse C : V → U . Thus, an assumption of injectivity of an operator A can be encoded via the identity BA = IU , where B is a new operator that does not satisfy any additional hypotheses and IU is the identity on U . Analogously, surjectivity of A corresponds to the identity AC = IV . For proving injectivity or surjectivity of an operator in our setting, we have to show the existence of a left or right inverse by ﬁnding an explicit expression for such an operator. As a special case of the discussion above, we also obtain a way to encode the property of a matrix having full row or column rank. This follows from the fact that a matrix A has full row rank if and only if the associated linear function is surjective, which, by Lemma 1, is the case if and only if A has a right inverse. Dually, A has full column rank if and only if A has a left inverse. To illustrate the handling of full rank assumptions as well as of identity matrices, we consider the statement: If A = BC is a full rank decomposition of a matrix A, i.e., B has full column rank and C has full row rank, then A† = C † B † . Using the software, it can be proven as follows. sage: F. = FreeAlgebra(QQ) sage: Pinv_a = pinv(a, x, a_adj, x_adj) sage: Pinv_b = pinv(b, y, b_adj, y_adj) sage: Pinv_c = pinv(c, z, c_adj, z_adj) # full ranks encoded via one-sided inverses sage: rank_decomp = [a - b*c, u*b - i, c*v - i] # encode identity i sage: id = [i*i - i, i - i_adj, b*i - b, i*y - y, i*c - c, ....: z*i - z, i*u - u, v*i - v] sage: assumptions = add_adj(Pinv_a + Pinv_b + Pinv_c + ....: rank_decomp + id) sage: claim = x - z*y sage: proof = certify(assumptions, claim) Computing a (partial) Groebner basis and reducing the claims... Starting iteration 5... Done! Ideal membership of all claims could be verified!  
   
  52  
   
  K. Bernauer et al.  
   
  Remark 5. We note that the certify routine (more precisely, the Gröbner basis computation underlying this command) is an iterative procedure. By default, the package informs about the computational progress of this procedure by printing an update message Starting iteration n... every ﬁfth iteration, see also Sect. A.1. 4.4  
   
  Range Inclusions  
   
  Another common class of properties are conditions on ranges and kernels, like the inclusion of ranges R(A) ⊆ R(B) of operators A, B. In case of linear operators over a ﬁeld, such a range inclusion can be translated into the existence of a factorisation A = BX for some operator X. We note that, in Hilbert and Banach spaces, this is the well-known factorisation property in Douglas’ lemma [7]. Thus, also facts like R(A† ) = R(A∗ ) can be treated within the framework by ﬁnding explicit factorisations of A† and A∗ in terms of the other. Using our software, such factorisations can be found easily. We refer to Sect. A.5 for the available heuristics to do this, and to [16] for a more thorough explanation of these techniques. sage: F. = FreeAlgebra(QQ) sage: Pinv_a = add_adj(pinv(a, a_dag, a_adj, a_dag_adj)) sage: I = NCIdeal(Pinv_a) # R(A^\dag) \subseteq R(A^*) sage: I.find_equivalent_expression(a_dag, prefix=a_adj, ....: heuristic=’naive’)  
   
  [- a_dag + a_adj*a_dag_adj*a_dag] # R(A^*) \subseteq R(A^\dag) sage: I.find_equivalent_expression(a_adj, prefix=a_dag, ....: heuristic=’naive’) [- a_adj + a_adj*a*a_dag]  
   
  5  
   
  Logical Framework  
   
  In the following, we describe the theory developed in [17] from a practical point of view, focusing on ∀∃-statements. For the reduction from arbitrary ﬁrst-order formulas to this case, as well as for all proofs and additional resources, we refer to the corresponding sections in [17]. To model statements about linear operators, or more generally about morphisms in preadditive semicategories, we consider a subset of many-sorted ﬁrstorder logic. Many-sorted ﬁrst-order logic extends classical ﬁrst-order logic by  
   
  How to Automatise Proofs of Operator Statements  
   
  53  
   
  assigning a sort to each term. These sorts allow to represent objects from diﬀerent universes and restrict which expressions can be formed. In our context, they are used to represent domains and codomains of operators. To formally introduce operator statements, we ﬁx an enumerable set of object symbols Ob = {v1 , v2 , . . . }. We call a pair (u, v) ∈ Ob × Ob a sort. We also ﬁx an enumerable set of variables {x1 , x2 , . . . } as well as, for each sort (u, v), a zero constant 0u,v . Furthermore, we ﬁx a sort function σ mapping each variable x to a sort σ(x) ∈ Ob × Ob and each zero constant 0u,v to σ(0u,v ) = (u, v). Intuitively, variables correspond to basic operators and the zero constants model distinguished zero operators. The images of these symbols under the sort function σ represent their domains and codomains. Using these basic symbols, we can construct terms, and building upon that, operator statements. Note that the following deﬁnition also extends the sort function from variables and constants to terms. Definition 2. A term is any expression that can be built up inductively using the following rules: 1. 2. 3. 4.  
   
  each variable x is a term of sort σ(x); each zero constant 0u,v is a term of sort (u, v); if s, t are terms of sort σ(s) = σ(t), then s+t is a term of sort σ(s+t) := σ(s); if s, t are terms of sort σ(s) = (v, w), σ(t) = (u, v), then st is a term of sort σ(st) := (u, w).  
   
  Terms are simply all noncommutative polynomial expressions that can be formed from the variables and the zero constants under the restrictions imposed by the sort function. They correspond to all operators that can be formed from the basic operators with the arithmetic operations of addition and composition. Definition 3. An operator statement is a first-order formula that can be built up inductively using the following rules: 1. 2. 3. 4.  
   
  if if if if P  
   
  s, t are terms of sort σ(s) = σ(t), then s = t is an operator statement; ϕ is an operator statement, then so is ¬ϕ; ϕ, ψ are operator statements, then so is ϕ ∗ ψ for ∗ ∈ {∨, ∧, →}; ϕ is an operator statement, then so is P x : ϕ for any variable x and ∈ {∃, ∀}.  
   
  Remark 6. We consider ∧ and ∨ as associative and commutative operations, i.e., ϕ ∧ (ψ ∧ ρ) = (ϕ ∧ ψ) ∧ ρ and ϕ ∧ ψ = ψ ∧ ϕ, and analogously for ∨. Furthermore, we abbreviate ¬(s = t) by s = t in the following. We recall some standard deﬁnitions and notation. In the last point of Deﬁnition 3, P is called the quantifier of x and ϕ is the scope of P x. If all variables occurring in an operator statement ϕ are in the scope of a quantiﬁer, then ϕ is closed. We abbreviate a block of consecutive equally quantiﬁed variables P x1 P x2 . . . P xk , with P ∈ {∃, ∀}, by P x1 . . . xk , or simply by P x. Furthermore, to indicate the scope of a quantiﬁer, we also write P x : ϕ(x).  
   
  54  
   
  K. Bernauer et al.  
   
  An operator statement without any quantiﬁers is called quantifier-free. Moreover, any operator statement of the form ∀x : ϕ(x) (resp. ∃x : ϕ(x)) with ϕ quantiﬁer-free is called universal (resp. existential ), and any operator statement of the form ∀x∃y : ϕ(x, y) with ϕ quantiﬁer-free is a ∀∃-operator statement. An interpretation I allows to interpret an operator statement ϕ as a statement about morphisms in a preadditive semicategory C. It assigns to each object symbol u ∈ Ob an object I(u) ∈ Ob(C) and to each variable x of sort σ(x) = (u, v) a morphism I(x) : I(u) → I(v). Each zero constant 0u,v is mapped to the zero morphism in the abelian group Mor(I(u), I(v)). This ensures that the terms in ϕ are translated into well-formed morphisms in C. Then ϕ can be evaluated to a truth value by interpreting the boolean connectives and the quantiﬁers like in classical ﬁrst-order logic. Definition 4. An operator statement ϕ is universally true if ϕ evaluates to true under all possible interpretations in every preadditive semicategory C. Note that an interpretation of ϕ depends implicitly on the sort function σ, and thus, so does the semantic evaluation of ϕ. An operator statement may be universally true w.r.t. one sort function but not w.r.t. another sort function. For instance, statements that hold for square matrices may not hold for rectangular matrices. Therefore, we should only refer to universal truth w.r.t. a speciﬁc sort function. For the sake of brevity, we assume a ﬁxed sort function σ and disregard this dependency in the following. Remark 7. For a formal deﬁnition of interpretation and universal truth of operator statements, we refer to [17, Sec. 2.1.2]. In the remainder of this section, we characterise universal truth of operator statements by ideal membership of noncommutative polynomials. To this end, we recall that every quantiﬁer-free operator statement ϕ can be transformed into a logically equivalent formula of the form ⎛ ⎞ ni ni m    ⎝ (8) ai,j = bi,j ∨ si,k = ti,k ⎠ . i=1  
   
  j=1  
   
  k=1  
   
  In the above formula, either of the two disjunctions can also be empty, i.e., it is possible that either ni = 0 or ni = 0, but not both. We recall that a formula of the form (8) is in conjunctive normal form (CNF) [27]. It is a conjunction of clauses, where a clause is a disjunction of equalities and disequalities. A formula can have several CNFs. One way to obtain a CNF of a quantiﬁer-free operator statement ϕ is to apply to ϕ exhaustively each of the following sets of rewrite rules, in the given order: 1. Eliminate implications: ψ1 → ψ2  ¬ψ1 ∨ ψ2 2. Move ¬ inwards (i.e., compute a negation normal form): ¬¬ψ  ψ  
   
  ¬(ψ1 ∧ ψ2 )  ¬ψ1 ∨ ¬ψ2  
   
  ¬(ψ1 ∨ ψ2 )  ¬ψ1 ∧ ¬ψ2  
   
  How to Automatise Proofs of Operator Statements  
   
  3. Distribute ∨ over ∧:  
   
  55  
   
  ψ ∨ (ψ1 ∧ ψ2 )  (ψ ∨ ψ1 ) ∧ (ψ ∨ ψ2 )  
   
  We note that the above rules apply modulo associativity and commutativity of ∧, ∨. This process yields a unique normal form, which we denote by CNF(ϕ). Also note that this transformation preserves the semantics of ϕ, that is, CNF(ϕ) is logically equivalent to ϕ. Based on the conjunctive normal form, we deﬁne a translation of operator statements into ideal theoretic statements. This process is called idealisation. We ﬁrst discuss the special case of clauses. To this end, we associate to each equality s = t or disequality s = t of terms the noncommutative polynomial s − t using the same translation as for identities of operators described in Sect. 2. n n Definition 5. Let C = j=1 aj = bj ∨ k=1 sk = tk be a clause. The idealisation I(C) of C is the following predicate considered as a statement in the free algebra ZX: I(C) :≡ sk − tk ∈ (a1 − b1 , . . . , an − bn ) for some 1 ≤ k ≤ n .  
   
  To motivate this deﬁnition, write C in the equivalent form j aj = bj → k sk = tk . This shows that C is true if and only if at least one of the identities sk = tk can be derived from all the aj = bj . Precisely this fact is described by I(C). The process of idealisation extends to universal operator statements as follows. Definition 6. Let ϕ = ∀x : ψ(x) be a universal operator statement. The idealisation I(ϕ) of ϕ is the predicate  I(C). I(ϕ) :≡ C clause of CNF(ψ)  
   
  The following theorem links the universal truth of universal operator statements to their idealisation. Theorem 4 ([17, Thm. 27]). A universal operator statement ϕ is universally true if and only if the idealisation of ϕ is true. Remark 8. Theorem 4 is a formalisation of the informal Theorem 1. It is a generalisation of [29, Thm. 32], which only considers a restricted form of universal operator statements and only provides a suﬃcient condition for the universal truth of the operator statement. Theorem 4 reduces universal truth of universal operator statements to the veriﬁcation of ﬁnitely many polynomial ideal memberships. Since the latter problem is semi-decidable, this immediately yields a semi-decision procedure for universal truth of this kind of statements. In the following, we describe how to treat operator statements involving existential quantiﬁers. Although the subsequent results can be phrased for arbitrary  
   
  56  
   
  K. Bernauer et al.  
   
  ﬁrst-order formulas, we focus on the more practical and important case of closed ∀∃-operator statements. It is worth noting that any operator statement can be transformed into a logically equivalent formula of this form. For more information on this conversion, we refer to [17, Sec. 2.2 and 2.3]. The following result is an adaptation of one of the most fundamental theorems of mathematical logic, Herbrand’s theorem [14], to our setting. It essentially allows to eliminate existential quantiﬁers, reducing the treatment of ∀∃-operator statements to universal ones. To state the theorem, we recall the concept of Herbrand expansion. The Herbrand expansion H(ϕ) of a closed ∀∃-operator statement ϕ = ∀x∃y1 , . . . , yk : ψ(x, y) is the set of all instantiations of the existentially quantiﬁed variables of ϕ, that is, H(ϕ) := {ψ(x, t1 , . . . , tk ) | ti terms only involving x s.t. σ(ti ) = σ(yi )} . We note that H(ϕ) is an inﬁnite yet enumerable set of quantiﬁer-free operator statements. Theorem 5. A closed ∀∃-operator statement ϕ = ∀x∃y : ψ(x, y) is universally true if and only if there exist finitely many ϕ1 (x), . . . , ϕn (x) ∈ H(ϕ) such that n the universal operator statement ∀x : i=1 ϕi (x) is universally true. Remark 9. Theorem 5 is a special case of the more general [17, Cor. 15]. It can also be found in [4] for classical unsorted ﬁrst-order logic. The following steps give an overview on how Herbrand’s theorem can be used algorithmically to reduce the treatment of a closed ∀∃-operator statement ϕ to a universal one. They can be considered as an adaptation of Gilmore’s algorithm [9]. 1. 2. 3. 4.  
   
  Let ϕ1 , ϕ2 , . . . be an enumeration of H(ϕ). Let n = 1. n Form the formula ψn = ∀x : i=1 ϕi (x). If the idealisation I(ψn ) is true, then ϕ is universally true. Otherwise, increase n by 1 and go to step 3.  
   
  Since ﬁrst-order logic is only semi-decidable, we cannot expect to obtain an algorithm that terminates on any input. The best we can hope for is a semidecision procedure that terminates if and only if an operator statement ϕ is universally true. However, the steps above, as phrased now, still have a subtle ﬂaw that stops them from even being a semi-decision procedure. The conditional check in step 4 requires to decide certain ideal memberships. While verifying ideal membership of noncommutative polynomials is always possible in ﬁnite time, disproving it is generally not. Consequently, verifying that the condition in step 4 is false is generally not possible in ﬁnite time. In cases where this is required, the procedure cannot terminate – even if ϕ is indeed universally true. To overcome this ﬂaw and to obtain a true semi-decision procedure, we have to interleave the computations done for diﬀerent values of n. Procedure 1 shows  
   
  How to Automatise Proofs of Operator Statements  
   
  57  
   
  one way how this can be done. It essentially follows the steps described above, except that it only performs ﬁnitely many operations to check if I(ψn ) is true for each n. Procedure 1: Semi-decision procedure for verifying operator statements Input: A closed ∀∃-operator statement ϕ Output: true if and only if ϕ is universally true; otherwise inﬁnite loop 1 ϕ1 , ϕ2 , . . . ← an enumeration of H(ϕ); 2 for n ← 1, 2, . . . : n 3 ψn ← ∀x : i=1 ϕi (x) ; 4 for k ← 1, . . . , n : 5 if I(ψk ) = true can be veriﬁed with n operations of an ideal membership semi-decision procedure : 6 return true;  
   
  Line 5 of Procedure 1 contains the term operation of a procedure. Thereby we mean any (high- or low-level) set of instructions of the procedure that can be executed in finite time. Theorem 6 ([17, Thm. 36]). Let ϕ be a closed ∀∃-operator statement. Procedure 1 terminates and outputs true if and only if ϕ is universally true. Remark 10. Procedure 1 is a special case of the more general semi-decision procedure [17, Proc. 2] that allows to treat arbitrary operator statements.  
   
  6  
   
  Case Study  
   
  For our case study, we considered the ﬁrst 25 facts in the section on the MoorePenrose inverse in the Handbook of Linear Algebra [20, Sec. I.5.7]. Among these 25 statements, we found that ﬁve cannot be treated within the framework, as they contain properties that cannot be expressed in terms of identities of operators (e.g., properties of the matrix entries, norms, or statements that require induction). Additionally, three statements can only be partially handled for the same reason. The remaining 17 statements, along with those parts of the three statements mentioned before that can be treated within the framework, can all be translated into polynomial computations and proven fully automatically with the help of our software. The corresponding polynomial computations take place in ideals generated by up to 70 polynomials in up to 18 indeterminates. The proof of each statement takes less than one second and the computed cofactor representations, certifying the required ideal memberships, consist of up to 226 terms. As part of our case study, we also examined Theorems 2.2–2.4 in [6], which provide several necessary and suﬃcient conditions for the reverse order law (AB)† = B † A† to hold, where A, B are bounded linear operators on Hilbert spaces with closed ranges. Our software can automatically prove all of these statements in less than ﬁve seconds altogether, yielding algebraic proofs that  
   
  58  
   
  K. Bernauer et al.  
   
  consist of up to 279 terms. We note that, in contrast to the original proofs in [6], which rely on matrix forms of bounded linear operators that are induced by some decompositions of Hilbert spaces, our proofs do not require any structure on the underlying spaces except basic linearity and a certain cancellability assumption. This implies that our proofs generalise the results from bounded operators on Hilbert spaces to morphisms in arbitrary preadditive semicategories, meeting the cancellability requirement. Finally, our case study contains fully automated proofs of Theorem 2.3 and 2.4 in the recent paper [5], which provide necessary and suﬃcient conditions for the triple reverse order law (ABC)† = C † B † A† to hold, where A, B, C are elements in a ring with involution. These results, which provide several improvements of Hartwig’s classical triple reverse order law [10], were motivated and partly discovered by a predecessor of our software package [15]. Our new software can automate all aspects of the proofs, relying heavily on the heuristics for ﬁnding polynomials of special form in ideals. We note that, while an initial implementation of our package took several days to complete the computations required for proving these theorems, the version discussed here now performs the task in approximately 15 s. The assumptions in the proof of Theorem 2.3 consist of up to 24 polynomials in 22 indeterminates and the computed cofactor representations certifying the ideal membership have up to 80 terms. The software also allows for easy experimentation with relaxing the assumptions of a theorem. This led us, among other simpliﬁcations, to discover that a condition in the original theorem [10] requiring equality of certain ranges R(A∗ AP ) = R(Q∗ ) can be replaced with the weaker condition of a range inclusion R(A∗ AP ) ⊆ R(Q∗ ). Acknowledgements. We thank the anonymous referees for their careful reading and valuable suggestions which helped to improve the presentation of this work.  
   
  A  
   
  The Software Package Operator_gb  
   
  In this appendix, we give an introduction to the functionality provided by the SageMath package operator_gb for Gröbner basis computations in the free algebra, with a particular focus on methods that facilitate proving statements about linear operators. We assume that readers are already familiar with SageMath and, for reading Sect. A.4 and A.5, with the theory of Gröbner bases in the free algebra. For further information on these topics, we refer to [32] and to [25,34], respectively. At the time of writing, the package is still under development and not part of the oﬃcial SageMath distribution. The current version, however, can be downloaded from https://github.com/ClemensHofstadler/operator_gb and installed as described on the webpage. The code can then be loaded into a SageMath session by the following command. sage: from operator_gb import *  
   
  How to Automatise Proofs of Operator Statements  
   
  59  
   
  For now, the package only oﬀers functionality for computations over the coefﬁcient domain Q. In the future, we will extend the functionality to other (ﬁnite) ﬁelds and subsequently also to coeﬃcient rings such as Z. Furthermore, we also plan on integrating noncommutative signature-based Gröbner algorithms [18] and, based on them, newly developed methods to compute cofactor representations of minimal length [19]. A.1  
   
  Certifying Operator Statements  
   
  The basic use-case of the package is to compute proofs of operator statements by certifying ideal membership of noncommutative polynomials. To this end, the package provides the command certify(assumptions, claim), which allows to certify whether a noncommutative polynomial claim lies in the ideal generated by a list of polynomials assumptions. For example, to certify that abc − d lies in the ideal generated by ab − d and c − 1, proceed as follows. sage: F. = FreeAlgebra(QQ) sage: assumptions = [a*b - d, c - 1] sage: proof = certify(assumptions, a*b*c - d) Computing a (partial) Groebner basis and reducing the claims... Done! Ideal membership of all claims could be verified! Remark 11. Note that noncommutative polynomials are entered using the FreeAlgebradata structure provided by SageMath. The computed proof provides a cofactor representation of claim in terms of the elements in assumptions. More precisely, it is a list of tuples (ai , ji , bi ) with terms ai , bi in the free algebra and integers ji such that |proof|  
   
  claim =  

  ai · assumptions[ji ] · bi .  
   
  i=1  
   
  The package provides a pretty_print_proof command to visualise the proof in form of a string. It also allows to expand a cofactor representation using the command expand_cofactors. sage: proof  
   
  [(1,0,c), (d,1,1)] sage: pretty_print_proof(proof, assumptions) -d + a*b*c = (-d + a*b)*c + d*(-1 + c)  
   
  60  
   
  K. Bernauer et al.  
   
  sage: expand_cofactors(proof, assumptions) -d + a*b*c Remark 12. The certify command also checks if the computed cofactor representation is valid over Z as well, i.e., if all coeﬃcients that appear are integers. If this is not the case, it produces a warning, but still continues the computation and returns the result. It is also possible to give certify a list of polynomials as claim. In this case, a cofactor representation of each element in claim is computed. sage: claims = [a*b*c - d, a*b - c*d] sage: proof = certify(assumptions, claims) Computing a (partial) Groebner basis and reducing the claims... Done! Ideal membership of all claims could be verified! sage: pretty_print_proof(proof[0], assumptions) -d + a*b*c = (-d + a*b)*c + d*(-1 + c) sage: pretty_print_proof(proof[1], assumptions) a*b - c*d = (-d + a*b) - (-1 + c)*d If ideal membership cannot be veriﬁed, certify returns False. This outcome can occur because of two reasons. Either claim is simply not contained in the ideal generated by assumptions, or certify, which is an iterative procedure, had not been run for enough iterations to verify the ideal membership. To avoid the latter situation, certify can be passed an optional argument maxiter to determine the maximal number of iterations it is run. By default this value is set to 10. sage: assumptions = [a*b*a - a*b] sage: claim = a*b^20*a - a*b^20 sage: certify(assumptions, claim) Computing a (partial) Groebner basis and reducing the claims... Starting iteration 5... Starting iteration 10... Failed! Not all ideal memberships could be verified.  
   
  False  
   
  How to Automatise Proofs of Operator Statements  
   
  61  
   
  sage: proof = certify(assumptions, claim, maxiter=20) Computing a (partial) Groebner basis and reducing the claims... Starting iteration 5... Starting iteration 10... Starting iteration 15... Done! Ideal membership of all claims could be verified! Remark 13. Ideal membership in the free algebra is undecidable in general. Thus, we can also not decide whether the number of iterations of certify was simply too low or whether claim is really not contained in the ideal. A.2  
   
  Useful Auxiliary Functions for Treating Operator Statements  
   
  The package provides some auxiliary functions which help in constructing polynomials that commonly appear when treating operator statements. – pinv(a, b, a_adj, b_adj): generate the polynomials (3) encoding the four Penrose identities for a with Moore-Penrose inverse b and respective adjoints a_adj and b_adj. – adj(f): compute the adjoint f∗ of a polynomial f. Each variable x is replaced by x_adj. Note that all variables x and x_adj have to be deﬁned as generators of the same FreeAlgebra. – add_adj(F): add to a list of polynomials F the corresponding adjoint elements. A.3  
   
  Quivers and Detecting Typos  
   
  When encoding operator identities, the resulting polynomials can become quite intricate and it can easily happen that typos occur. To detect typos, it can help to syntactically check if entered polynomials correspond to correctly translated operator identities, respecting the restrictions imposed by the domains and codomains. To this end, the package allows to encode the domains and codomains in form of a directed labelled multigraph, called (labelled) quiver. B  
   
  A U  
   
  V D  
   
  W C  
   
  Fig. 1. Quiver encoding domains and codomains of operators  
   
  Computationally, a quiver is given by a list of triplets (u, v, a), where u and v can be any symbols that encode the domain U and the codomain V of the basic  
   
  62  
   
  K. Bernauer et al.  
   
  operator A and a is the indeterminate representing A. For example, a quiver encoding the situation of operators A, B, C, D on spaces U, V, W as in Fig. 1, can be constructed as follows. sage: F. = FreeAlgebra(QQ) sage: Q = Quiver([(’U’,’V’,a), (’V’,’W’,b), (’W’,’V’,c), (’V’,’U’,d)]) sage: Q  
   
  Labelled quiver with 3 vertices in the labels {a, b, c, d} One can easily check if a polynomial is compatible with the situation of operators encoded by a quiver. sage: Q.is_compatible(a*b + c*d)  
   
  False sage: Q.is_compatible(a*d + c*b) True A quiver can be handed as an optional argument to certify, which then checks all input polynomials for compatibility with the given quiver and raises an error if required. sage: assumptions = [a*d, c*b] # typo in the claim, c*b -> b*c sage: claim = a*d - b*c sage: certify(assumptions, claim, quiver=Q)  
   
  ValueError: The claim a*d - b*c is not compatible with the quiver  
   
  A.4  
   
  Gröbner Basis Computations  
   
  Behind the scenes, the certify command computes Gröbner bases in the free algebra. In this section, we present the methods of the package that allow to do such computations.  
   
  How to Automatise Proofs of Operator Statements  
   
  63  
   
  Ideals and Monomial Orders. The main data structure provided by the package is that of a (two-sided) ideal in the free algebra, called NCIdeal. Such an ideal can be constructed from any ﬁnite set of noncommutative polynomials. sage: F. = FreeAlgebra(QQ) sage: gens = [x*y*z - x*y, y*z*x*y - y] sage: NCIdeal(gens)  
   
  NCIdeal (-x*y + x*y*z, -y + y*z*x*y) of Free Algebra on 3 generators (x, y, z) over Rational Field with x < y < z Attached to an NCIdeal also comes a monomial order w.r.t. which further computations are done. By default, this is a degree left lexicographic order, where the indeterminates are sorted as in the parent FreeAlgebra. The order of the variables can be individualised by providing a list as an optional argument order. Furthermore, by providing a list of lists, block orders (also known as elimination orders) can be deﬁned. The order within each block is still degree left lexicographic and blocks are provided in ascending order. sage: NCIdeal(gens, order=[y,x,z])  
   
  NCIdeal (-x*y + x*y*z, -y + y*z*x*y) of Free Algebra on 3 generators (x, y, z) over Rational Field with y < x < z sage: NCIdeal(gens, order=[[y,x],[z]]) NCIdeal (-x*y + x*y*z, -y + y*z*x*y) of Free Algebra on 3 generators (x, y, z) over Rational Field with y < x « z  
   
  Gröbner Bases and Normal Forms. For computing Gröbner bases, the class NCIdeal provides the method groebner_basis with the following optional arguments: – maxiter (default: 10): Maximal number of iterations executed. – maxdeg (default: ∞): Maximal degree of considered ambiguities. – trace_cofactors (default: True): If cofactor representations of each Gröbner basis element in terms of the generators should be computed. – criterion (default: True): If Gebauer-Möller criteria [34] should be used to detect redundant ambiguities. – reset (default: True): If all internal data should be reset. If set to False, this allows to continue previous (partial) Gröbner basis computations.  
   
  64  
   
  K. Bernauer et al.  
   
  – verbose (default: 0): ‘Verbosity’ value determining the amount of information about the computational progress that is printed. sage: sage: sage: sage:  
   
  F. = FreeAlgebra(QQ) gens = [x*y*x - x*y, y*x*x*y - y] I = NCIdeal(gens) G = I.groebner_basis(); G  
   
  [- x*y + x*y*x, - y + y*x2 *y, - y + y*x, - x*y + x*y2 , - x*y + x*y2 *x, - y + y2 , - y + y3 ] We note that the polynomials output by the groebner_basis routine are not SageMath noncommutative polynomials but our own NCPolynomials. They provide similar functionality as the native data structure (basic arithmetic, equality testing, coeﬃcient/monomial extraction), but can additionally also store a cofactor representation. In particular, the elements output by the groebner_basis command all hold a cofactor representation w.r.t. the generators of the NCIdeal. sage: f = G[2] sage: pretty_print_proof(f.cofactors(), I.gens()) -y + y*x = y*x*(-x*y + x*y*x) + (-y + y*x2 *y) - (-y + y*x2 *y)*x Remark 14. To convert an NCPolynomial back into SageMath’s native data structure, our class provides the method to_native. Conversely, to convert a SageMath noncommutative polynomial f into an NCPolynomial, one can use NCPolynomial(f). The package also allows to interreduce a set of NCPolynomials using the command interreduce. sage: interreduce(G) [- y + y*x, - y + y2 ] To compute the normal form of an element f w.r.t. the generators of an NCIdeal, the class provides the method reduced_form. The output of this method is an NCPolynomial g holding a cofactor representation of the diﬀerence f - g w.r.t. the generators of the NCIdeal The method reduced_form accepts the same optional arguments as groebner_basis. sage: f = I.reduced_form(y^2 - y); f  
   
  How to Automatise Proofs of Operator Statements  
   
  65  
   
  0 sage: pretty_print_proof(f.cofactors(), I.gens()) -y + y2 = (-y + y*x2 *y) - y*x*(-x*y + x*y*x)*y - (-y + y*x2 *y)*y - y*x*(-x*y + x*y*x)*x*y + (-y + y*x2 *y)*x2 *y sage: I.reduced_form(y^2) y  
   
  A.5  
   
  Heuristics for Finding Polynomials of Certain Form  
   
  One of the main functionalities provided by the package are dedicated heuristics for systematically searching for polynomials of certain form in an NCIdeal. To this end, the class NCIdeal provides the method find_equivalent_expression(f), which searches for elements of the form f g with arbitrary g in an NCIdeal. It accepts the following optional arguments: – All optional arguments that also groebner_basis accepts with the same eﬀects. – order: A monomial order w.r.t. which the computation is executed. The argument has to be provided like a custom order when deﬁning an NCIdeal (see Sect. A.4). – heuristic (default: ‘groebner’): Determines the heuristic used. Available are • ‘naive’: Try exhaustively all monomials m up to a degree bound and check if f - m is in the ideal. • ‘groebner’: Enumerate a Gröbner basis and search in the Gröbner basis for suitable elements containing f. • ‘subalgebra’: Intersect the two-sided ideal with a subalgebra to ﬁnd suitable elements. • ‘right-ideal’/‘left-ideal’: Intersect the two-sided ideal with a right/left ideal to ﬁnd suitable elements. – prefix (default: None): A term p providing the preﬁx of g, i.e., the heuristic looks for elements of the form f - p*h with arbitrary h (required for heuristic ‘right-ideal’). – suffix (default: None): A term s providing the suﬃx of g, i.e., the heuristic looks for elements of the form f - h*s with arbitrary h (required for heuristic ‘left-ideal’). – degbound (default: 5): Some heuristics only compute up to a ﬁxed degree bound. This argument allows to change this degree bound. – quiver (default: None): Use a quiver to restrict the search space only to polynomials that are compatible with this quiver.  
   
  66  
   
  K. Bernauer et al.  
   
  sage: sage: sage: sage:  
   
  F. = FreeAlgebra(QQ) gens = [a*b*a-a,b*a*b-b,a*b-c*d,b*a-d*c,c*d*c-c,d*c*d-d] I = NCIdeal(gens) I.find_equivalent_expression(a*b) [-a*b + c*d]  
   
  sage: I.find_equivalent_expression(a*b, heuristic=’naive’, ....: suffix=b) [a*b - c*d*a*b] sage: I.find_equivalent_expression(a*b, heuristic=’right-ideal’, ....: prefix=a*b) [- a*b + a*b*c*d, - a*b + a*b*a*b] Additionally, the class NCIdeal provides methods for applying cancellability. – I.apply_left_cancellability(a, b): Search for elements of the form a*b*f in I and return b*f. – I.apply_right_cancellability(a, b): Search for elements of the form f*a*b in I and return f*a. Both methods can be given an optional argument heuristic to determine the used search heuristic. Available are ‘subalgebra’, ‘one-sided’, and ‘two-sided’ (default: ‘subalgebra’). sage: I.apply_left_cancellability(c, a) [- a + a*b*a, - a2 + a*d*c*a] #verify ideal membership to check correctness of result sage: I.reduced_form(c*(-a^2 + a*d*c*a)) 0 sage: I.apply_right_cancellability(a*b, d*a, ....: heuristic=’two-sided’, maxiter=5) [- a*b + a*b*a*b, - a*b + c*d*a*b] #verify ideal membership to check correctness of result sage: I.reduced_form((-a*b + c*d*a*b)*c*d) 0  
   
  How to Automatise Proofs of Operator Statements  
   
  67  
   
  References 1. Bernauer, K.: Algebraic and automated proofs for Moore-Penrose inverses. Bachelor’s thesis, Johannes Kepler University Linz, Austria (2021) 2. Borges, M.A., Borges, M.: Groebner bases property on elimination ideal in the noncommutative case. London Math. Soc. Leture Note Ser. 1(251), 323–327 (1998) 3. Buchberger, B.: Ein Algorithmus zum Auﬃnden der Basiselemente des Restklassenringes nach einem nulldimensionalen Polynomideal. Ph.D. thesis, University of Innsbruck, Austria (1965) 4. Buss, S.R.: On Herbrand’s theorem. In: Leivant, D. (ed.) LCC 1994. LNCS, vol. 960, pp. 195–209. Springer, Heidelberg (1995). https://doi.org/10.1007/3-54060178-3_85 5. Cvetković-Ilić, D.S., Hofstadler, C., Hossein Poor, J., Milošević, J., Raab, C.G., Regensburger, G.: Algebraic proof methods for identities of matrices and operators: improvements of Hartwig’s triple reverse order law. Appl. Math. Comput. 409, 126357 (2021) 6. Djordjević, D.S., Dinčić, N.Č: Reverse order law for the Moore-Penrose inverse. J. Math. Anal. Appl. 361(1), 252–261 (2010) 7. Douglas, R.G.: On majorization, factorization, and range inclusion of operators on Hilbert space. Proc. Am. Math. Soc. 17(2), 413–415 (1966) 8. Garraway, W.D.: Sheaves for an involutive quantaloid. Cah. Topol. Géom. Diﬀér. Catég. 46(4), 243–274 (2005) 9. Gilmore, P.C.: A proof method for quantiﬁcation theory: its justiﬁcation and realization. IBM J. Res. Dev. 4(1), 28–35 (1960) 10. Hartwig, R.E.: The reverse order law revisited. Linear Algebra Appl. 76, 241–246 (1986) 11. Helton, J.W., Stankus, M.: Computer assistance for “discovering” formulas in system engineering and operator theory. J. Funct. Anal. 161(2), 289–363 (1999) 12. Helton, J.W., Stankus, M., Wavrik, J.J.: Computer simpliﬁcation of formulas in linear systems theory. IEEE Trans. Automat. Control 43(3), 302–314 (1998) 13. Helton, J.W., Wavrik, J.J.: Rules for computer simpliﬁcation of the formulas in operator model theory and linear systems. In: Feintuch, A., Gohberg, I. (eds.) Nonselfadjoint Operators and Related Topics. OT, vol. 73, pp. 325–354. Springer, Cham (1994). https://doi.org/10.1007/978-3-0348-8522-5_12 14. Herbrand, J.: Recherches sur la théorie de la démonstration. Ph.D. thesis, University of Paris (1930) 15. Hofstadler, C., Raab, C.G., Regensburger, G.: Certifying operator identities via noncommutative Gröbner bases. ACM Commun. Comput. Algebra 53(2), 49–52 (2019) 16. Hofstadler, C., Raab, C.G., Regensburger, G.: Computing elements of certain form in ideals to prove properties of operators. Math. Comput. Sci. 16(17) (2022) 17. Hofstadler, C., Raab, C.G., Regensburger, G.: Universal truth of operator statements via ideal membership. arXiv preprint arXiv:2212.11662 (2022) 18. Hofstadler, C., Verron, T.: Signature Gröbner bases, bases of syzygies and cofactor reconstruction in the free algebra. J. Symb. Comput. 113, 211–241 (2022) 19. Hofstadler, C., Verron, T.: Short proofs of ideal membership. arXiv preprint arXiv:2302.02832 (2023) 20. Hogben, L.: Handbook of Linear Algebra, 2nd edn. CRC Press, Boca Raton (2013) 21. Levandovskyy, V., Schönemann, H., Abou Zeid, K.: Letterplace - a subsystem of Singular for computations with free algebras via letterplace embedding. In: Proceedings of ISSAC 2020, pp. 305–311 (2020)  
   
  68  
   
  K. Bernauer et al.  
   
  22. Mikhalev, A.A., Zolotykh, A.A.: Standard Gröbner-Shirshov bases of free algebras over rings. I. Free associative algebras. Int. J. Algebra Comput. 8(6), 689–726 (1998) 23. Moore, E.H.: On the reciprocal of the general algebraic matrix. Bull. Am. Math. Soc. 26, 394–395 (1920) 24. Mora, F.: Groebner bases for non-commutative polynomial rings. In: Calmet, J. (ed.) AAECC 1985. LNCS, vol. 229, pp. 353–362. Springer, Heidelberg (1986). https://doi.org/10.1007/3-540-16776-5_740 25. Mora, T.: Solving Polynomial Equation Systems IV: Volume 4, Buchberger Theory and Beyond, vol. 158. Cambridge University Press (2016) 26. Penrose, R.: A generalized inverse for matrices. Math. Proc. Cambridge Philos. Soc. 51(3), 406–413 (1955) 27. Prestwich, S.: CNF encodings. In: Handbook of Satisﬁability, pp. 75–97. IOS Press (2009) 28. Puystjens, R., Robinson, D.W.: The Moore-Penrose inverse of a morphism with factorization. Linear Algebra Appl. 40, 129–141 (1981) 29. Raab, C.G., Regensburger, G., Hossein Poor, J.: Formal proofs of operator identities by a single formal computation. J. Pure Appl. Algebra 225(5), 106564 (2021) 30. Schmitz, L.: Varieties over Module Homomorphisms and their Correspondence to free Algebras. Master’s thesis, RWTH Aachen (2021) 31. Schmitz, L., Levandovskyy, V.: Formally verifying proofs for algebraic identities of matrices. In: Benzmüller, C., Miller, B. (eds.) CICM 2020. LNCS (LNAI), vol. 12236, pp. 222–236. Springer, Cham (2020). https://doi.org/10.1007/978-3-03053518-6_14 32. The Sage Developers: SageMath, the Sage Mathematics Software System (Version 9.8) (2023). https://www.sagemath.org 33. Tilson, B.: Categories as algebra: an essential ingredient in the theory of monoids. J. Pure Appl. Algebra 48(1), 83–198 (1987) 34. Xiu, X.: Non-commutative Gröbner bases and applications. Ph.D. thesis, University of Passau, Germany (2012). http://www.opus-bayern.de/uni-passau/ volltexte/2012/2682/  
   
  A Modular Algorithm for Computing the Intersection of a One-Dimensional Quasi-Component and a Hypersurface Alexander Brandt(B) , Juan Pablo Gonz´ alez Trochez, Marc Moreno Maza, and Haoze Yuan Department of Computer Science, The University of Western Ontario, London, Canada {abrandt5,jgonza55,hyuan46}@uwo.ca, [email protected]  Abstract. Computing triangular decompositions of polynomial systems can be performed incrementally with a procedure named Intersect. This procedure computes the common zeros (encoded as regular chains) of a quasi-component and a hypersurface. As a result, decomposing a polynomial system into regular chains can be achieved by repeated calls to the Intersect procedure. Expression swell in Intersect has long been observed in the literature. When the regular chain input to Intersect is of positive dimension, intermediate expression swell is likely to happen due to spurious factors in the computation of resultants and subresultants. In this paper, we show how to eliminate this issue. We report on its implementation in the polynomial system solver of the BPAS (Basic Polynomial Algebra Subprogram) library. Our experimental results illustrate the practical beneﬁts. The new solver can process various systems which were previously unsolved by existing implementations of regular chains. Those implementations were either limited by time, memory consumption, or both. The modular method brings orders of magnitude speedup. Keywords: Polynomial system solving · Triangular decomposition Modular method · Regular chains · Intersection · Quasi-component  
   
  1  
   
  ·  
   
  Introduction  
   
  Since the early works of Ritt [35], Wu [42], and Yang and Zhang [45], the Characteristic Set Method has been extended and improved by many researchers. This eﬀort has produced more powerful decomposition algorithms, and now applies to diﬀerent types of polynomial systems or decompositions: parametric algebraic systems [18,22,44], diﬀerential systems [8,19,26], diﬀerence systems [24], unmixed decompositions and primary decomposition [38] of polynomial ideals, intersection multiplicities [31], cylindrical algebraic decomposition [16,28], quantiﬁer elimination [17], parametric [44] and non-parametric [14] semi-algebraic systems. Today, triangular decomposition algorithms are available in several software packages [4,13,40,41,43]. Moreover, they provide c The Author(s), under exclusive license to Springer Nature Switzerland AG 2023  F. Boulier et al. (Eds.): CASC 2023, LNCS 14139, pp. 69–89, 2023. https://doi.org/10.1007/978-3-031-41724-5 4  
   
  70  
   
  A. Brandt et al.  
   
  back-engines for computer algebra system front-end solvers, such as Maple’s solve command. Despite of their successful application in various areas (automatic theorem proving, dynamical systems, program veriﬁcation, to name a few), solvers based on triangular decompositions are sometimes put to challenge with input polynomial systems that appear to be easy to solve by other methods, based on Gr¨ obner bases. Of course, one should keep in mind that diﬀerent solvers may have diﬀerent speciﬁcations, not always easy to compare. Nevertheless, for certain classes of systems, say zero-dimensional systems, one can expect that a triangular decomposition on one hand, and the computation of a lexicographical Gr¨ obner basis (followed by the application of Lazard’ s Lextriangular algorithm [29]) on the other, produce essentially the same thing. While the development of modular methods for computing Gr¨ obner bases took oﬀ in the 1980’s thanks to Traverso [39] and Faug`ere [23], with follow-up works by Arnold [1] and others, the development of such methods for triangular decompositions started only in 2005 with the paper [21] by Dahan, Moreno Maza, Schost, Wu and Xie. This latter method computes a triangular decomposition Δ of a zero-dimensional polynomial system V (F ) over the rational numbers by 1. ﬁrst computing a triangular decomposition, say Δp , of that system modulo a suﬃciently large prime number p; 2. transforming Δp into a canonical triangular decomposition of V (F mod p), called the equiprojectable decomposition, Ep of V (F mod p); and 3. ﬁnally, lifting Ep (using the techniques of Schost [37]) into the equiprojectable decomposition of V (F ). Hence, this method helps to control the eﬀect of expression swell at the level of the numerical coeﬃcients, which resulted in a signiﬁcant eﬃciency improvement on a number of famous test systems. However, this modular method has no beneﬁts on expression swell when expression swell manifests as an (unnecessary) inﬂation on the number of terms. This phenomenon is generally caused by the so-called extraneous or spurious factors in resultants, which have been studied in the case of Dixon resultants [27]. Most algorithms for computing triangular decompositions compute iterated resultants, either explicitly or implicitly. In broad terms, the iterated resultant res(f, T ) between f and a regular chain1 T ⊆ k[X1 < . . . Xn ] encodes conditions for the hypersurface V (f ) and the quasi-component W (T ) to have a non-empty intersection. To be precise, we recall some of the results in Sect. 6 of [15]. Assume that T is a zero-dimensional regular chain. We denote by VM (T ) the multiset of the zeros of T , where each zero of T appears a number of times equal to its local multiplicity as deﬁned in Chap. 4 of [20]. If T is normalized, that is, the initial of every polynomial in T is a constant, then we have:  f (α). res(f, T ) = α∈VM (T ) 1  
   
  See Sect. 2 for a review of regular chain theory, including deﬁnitions of the terms quasi-component, initial, etc.  
   
  A Modular Algorithm for Computing the Intersection  
   
  71  
   
  This Poisson Formula tells us that, if T is normalized, then res(f, T ) is “fully meaningful”. In other words, it does not contain extraneous factors. Now, let us relax the fact that T is normalized. For i = 1, . . . , n, we denote respectively by ti , hi , ri : (1) the polynomial of T whose main variable is Xi , (2) the initial of ti , (3) the iterated resultant res({t1 , . . . , ti−1 }, hi ). In particular, we have r1 = h1 . We also deﬁne: (1) en = deg(f, Xn ), (2) fi = res({ti+1 , . . . , tn }, f ), for 0 ≤ i ≤ n − 1, (3) ei = deg(fi , xi ), for 1 ≤ i ≤ n − 1. Then, res(T, f ) is given by: ⎛ ⎞ e2 ⎛ ⎞ en ⎛ ⎞    he11 ⎝ h2 (β1 )⎠ · · · ⎝ hn (βn−1 )⎠ ⎝ f (α)⎠ β1 ∈VM (t1 )  
   
  βn−1 ∈VM (t1 ,...,tn−1 )  
   
  α∈VM (T )  
   
  From that second Poisson formula, we can see that all factors but the rightmost one (that is, the one from the ﬁrst Poisson formula) are extraneous. Indeed, in the intersection V (f ) ∩ W (T ) there are no points cancelling the initials h2 , . . . , hn . These observations generalize to regular chains of positive dimension (just seeing the ﬁeld k as a ﬁeld of rational functions) and can explain how the calculation of iterated resultants can cause expression swells in triangular decomposition algorithms. To deal with that problem, the authors of [15] study a few trivariate systems consisting of a polynomial f (X1 , X2 , X3 ) and a regular chain T = {t2 (X1 , X2 ), t3 (X1 , X2 , X3 )}. They compute res(T, f ) by 1. specializing X1 at suﬃciently many well-chosen values a, 2. computing R(a) := res(N (a), f (a)) where f (a) = f (a, X2 , X3 ) and N (a) is the normalized regular chain generating the ideal t2 (a, X2 ), t3 (a, X2 , X3 ) in k[X2 , X3 ], and 3. combining the R(a)’s and applying rational function reconstruction. The numerator of the reconstructed fraction is essentially the desired non-extraneous factor of res(T, f ). In this paper, we extend the ideas of [15] so that one can actually compute V (f ) ∩ W (T ) and not just obtain conditions on the existence of those common solutions for f and T . Computing such intersections is the core routine of the incremental triangular decomposition method initiated by Lazard in [28] and further developed by Chen and Moreno Maza [15,33]. Consequently, we have implemented the proposed techniques and measured the beneﬁts that they bring to the solver presented in [4]. We stress the fact that our objective is to optimize the Intersect algorithm [15] for computing intersections of the form V (f ) ∩ W (T ). Moreover, one of the main applications of our work in this area is to support algorithms in diﬀerential algebra, as in the articles [10,11]. With the challenges of that application2 in mind and noting the success obtained in applying regular chain theory to diﬀerential algebra, our approach to optimize the Intersect algorithm must remain free of (explicit) Gr¨ obner basis computations. 2  
   
  The diﬀerential ideal generated by ﬁnitely many diﬀerential polynomials is generally not ﬁnitely generated, when regarded as an algebraic ideal.  
   
  72  
   
  A. Brandt et al.  
   
  We observe that if Gr¨ obner basis computations are to be used to support triangular decompositions, eﬃcient algorithms exist since the 1990’s. As shown in [34], applying Lazard’ s Lextriangular to the lexicographical Gr¨ obner basis G(F ) of a zero-dimensional polynomial ideal F  produces a triangular decomposition of the algebraic variety V (F ) in a time which is negligible comparing to that of computing G(F ). This eﬃciency follows from the structure of a lexicographical Gr¨ obner basis as stated by the Gianni-Kalkbrener theorem [29]. The presentation of our modular method for computing V (f ) ∩ W (T ) is dedicated to the case where T is one-dimensional. The cases where T is of dimension higher than one are work in progress but not reported here. Our approach to the design of such a modular method is as follows. In Sect. 3, we identify hypotheses under which V (f ) ∩ W (T ) is given by a single zero-dimensional regular chain C, such that V (f ) ∩ W (T ) = W (C) holds. We call those hypotheses genericity assumptions because C is shape lemma in the sense of [7]. In Sect. 4, we develop a modular method which computes C, if the genericity assumptions hold, and detects which assumption does not hold otherwise. One intention of that algorithm is that, whenever a genericity assumption fails, one should be able to recycle the computations performed by the modular method, in order to ﬁnish the computations, see Sect. 5 for details. Section 6 gathers some notes about a preliminary implementation of the modular algorithm presented in Sect. 4. The experimentation, reported in Sect. 7, contains very promising results. Indeed, our solver based on this modular method can process various systems which were previously unsolved by our solver (without the modular method) and unsolved by the RegularChains library of Maple.  
   
  2  
   
  Preliminaries  
   
  This section is a short review of concepts from the theory of regular chains and triangular decompositions of polynomial systems. Details can be found in [15]. This paper also relies on the theory of subresultants and we refer the unfamiliar reader to the concise preliminaries section of [5]. Polynomials. Throughout this paper, let k be a perfect ﬁeld, K be its algebraic closure, and k[X] be the polynomial ring over k with n ordered variables X = X1 < · · · < Xn . Let p ∈ k[X] \ k. Denote by mvar(p), init(p), and mdeg(p), respectively, the greatest variable appearing in p (called the main variable of p), the leading coeﬃcient of p w.r.t. mvar(p) (called the initial of p), and the degree of p w.r.t. mvar(p) (called the main degree of p). For F ⊆ k[X], we denote by F  and V (F ) the ideal generated by F in k[X] and the algebraic set of Kn consisting of the common roots of the polynomials of F , respectively. Triangular Sets. Let T ⊆ k[X] be a triangular set, that is, a set of non-constant polynomials with pairwise distinct main variables. Denote by mvar(T ) the set of main variables of the polynomials in T . A variable v ∈ X is called algebraic w.r.t. T if v ∈ mvar(T ), otherwise it is said free w.r.t. T . For v ∈ mvar(T ), we denote by Tv and Tv− (resp. Tv+ ) the polynomial f ∈ T with mvar(f ) = v and the  
   
  A Modular Algorithm for Computing the Intersection  
   
  73  
   
  polynomials f ∈ T with mvar(f ) < v (resp. mvar(f ) > v). Let hT be the product of the initials of the polynomials of T . We denote by sat(T ) the saturated ideal of T : if T = ∅ holds, then sat(T ) is deﬁned as the trivial ideal 0, otherwise it is the ideal T  : h∞ T . The quasi-component W (T ) of T is deﬁned as V (T ) \ V (hT ). For f ∈ k[X], we deﬁne Z(f, T ) := V (f ) ∩ W (T ). The Zariski closure of W (T ) in Kn , denoted by W (T ), is the intersection of all algebraic sets V ⊆ Kn such that W (T ) ⊆ V holds; moreover we have W (T ) = V (sat(T )). For f ∈ k[X], we denote by res(f, T ) the iterated resultant of f w.r.t. T , that is: if f ∈ k or T = ∅ then f itself, else res(res(f, Tv , v), Tv− ) if v ∈ mvar(T ) and v = mvar(f ) hold, or res(f, Tv− ) otherwise. Regular Chains, Triangular Decomposition. A triangular set T ⊆ k[X] is a regular chain if either T is empty, or letting v be the largest variable occurring in T , the set Tv− is a regular chain, and the initial of Tv is regular (that is, neither zero nor a zero divisor) modulo sat(Tv− ). Let H ⊆ k[X]. The pair [T, H] is a regular system if each polynomial in H is regular modulo sat(T ). The dimension of T , denoted by dim(T ), is by deﬁnition, the dimension of its saturated ideal and, as a property, equals n − |T |, where |T | is the number of elements of T . If T has dimension zero, then T generates sat(T ) and we have V (T ) = W (T ). The saturated ideal sat(T ) enjoys important properties, in particular the following, proved in [9]. Let U1 , . . . , Ud be all the free variables of T . Then sat(T ) is unmixed of dimension d. Moreover, we have sat(T ) ∩ k[U1 , . . . , Ud ] = 0. Another property is the fact that a polynomial p belongs to sat(T ) if and only if p reduces to 0 by pseudo-division w.r.t. T , see [6]. Last but not least, a polynomial p is regular modulo sat(T ) if and only if we have res(p, T ) = 0. Specialization and Border Polynomial. Let [T, H] be a regular system of k[X]. Let U = U1 , . . . , Ud be the free variables of T . Let a = (a1 , . . . , ad ) ∈ Kd . We say that [T, H] specializes well at a if: (i) for each t ∈ T the polynomial init(t) is not zero modulo the ideal U1 − a1 , . . . , Ud − ad ; and (ii) the image of [T, H] modulo U1 − a1 , . . . , Ud − ad  is a regular system. Let BT,H be the primitive and square-free part of the product of all res(h, T ) for h ∈ H ∪ {hT }. We call BT,H the border polynomial of [T, H]. From the specialization property of sub-resultants, one derives the following [32]: The system [T, H] specializes well at a ∈ Kd if and only if BT,H (a) = 0 holds. Normalized Regular Chain. The regular chain T ⊆ k[X] is said to be normalized if, for every v ∈ mvar(T ), none of the variables occurring in init(Tv ) is algebraic w.r.t. Tv− . Let d = dim(T ), Y = mvar(T ), and U = U1 , . . . , Ud be X \ Y . Then, T normalized means that for every t ∈ T we have init(t) ∈ k[U ]. It follows that if T is normalized, then T is a lexicographical Gr¨ obner basis of the ideal that T generates in k(U )[Y ] (that is, over the ﬁeld k(U ) of rational functions), and we denote by nf(p, T ) the normal form of a polynomial p ∈ k(U )[Y ] w.r.t. T as a Gr¨ obner basis. Importantly, if T is normalized and has dimension zero, then init(t) ∈ k for every t ∈ T .  
   
  74  
   
  A. Brandt et al.  
   
  Regular GCD. Let T ⊆ k[X] be a regular chain. Let i be an integer with 1 ≤ i ≤ n. Let p, t ∈ k[X] \ k be polynomials with the same main variable Xi , and g ∈ k or g ∈ k[X] with mvar(g) ≤ Xi . Assume that: 1. Xi > Xj holds for all Xj ∈ mvar(T ); and 2. both init(p) and init(t) are regular w.r.t. sat(T ).  For the residue class ring k[X1 , . . . , Xi−1 ]/ sat(T ), denote its total ring of fractions as A. Note that A is isomorphic to a direct product of ﬁelds. We say that g is a regular GCD of p, t w.r.t. T whenever the following conditions hold: (G1 ) the leading coeﬃcient of g in Xi is invertible in A; (G2 ) g belongs to the ideal generated by p and t in A[Xi ]; and (G3 ) if deg(g, Xi ) > 0, then g dividesboth p and t in A[Xi ], that is, both prem(p, g) and prem(t, g) belong to sat(T ). When Conditions (G1 ), (G2 ), (G3 ) and deg(g, Xi ) > 0 hold:   (G4 ) if mdeg(g) = mdeg(t), then sat(T ∪ t) = sat(T ∪ g) and W (T ∪ t) ⊆ Z(hg , T ∪ t) ∪ W (T ∪ g) ⊆ W (T ∪ t); (G5 ) if mdeg(g) < mdeg(t), let q = pquo(t, g), then T ∪ q is a regular chain and we have    sat(T ∪ t) = sat(T ∪ g) ∩ sat(T ∪ q) and (a) (b) W (T ∪ t) ⊆ Z(hg , T ∪ t) ∪ W (T ∪ g) ∪ W (T ∪ q) ⊆ W (T ∪ t); (G6 ) W (T ∪ g) ⊆ V (p); and (G7 ) V (p) ∩ W (T ∪ t) ⊆ W (T ∪ g) ∪ V (p, hg ) ∩ W (T ∪ t) ⊆ V (p) ∩ W (T ∪ t). Intersect and Regularize. Let p ∈ k[X] and let T ⊆ k[X] be a regular chain. The function Intersect(p, T ) computes regular chains T1 , . . . , Te such that: V (p)∩ W (T ) ⊆ W (T1 ) ∪ · · · ∪ W (Te ) ⊆ V (p) ∩ W (T ). The function call Regularize(p, T ) computes regular chains T1 , . . . , Te such that: (1) for each i = 1, . . . , e, either p ∈ sat(Ti ) holds or p is regular w.r.t. sat(Ti ); and (2) we have W (T ) = W (T1 ) ∪ · · · ∪ W (Te ), and mvar(T ) = mvar(Ti ) holds for i = 1, . . . , e. Triangular Decomposition. Let F ⊆ k[X]. The regular chains T1 , . . . , Te of k[X] form a triangular decomposition of V (F ) in ethe sense of Kalkbrener (resp. Wu and Lazard) whenever we have V (F ) = i=1 W (Ti ) (resp. V (F ) = e W (T )). Hence, a triangular decomposition of V (F ) in the sense of Wu i i=1 and Lazard is necessarily a triangular decomposition of V (F ) in the sense of Kalkbrener, while the converse is not true. Note that a triangular decomposition can thus be computed from repeated calls to Intersect; see [15].  
   
  3  
   
  Genericity Assumptions  
   
  Let k be a ﬁeld of characteristic zero or a prime ﬁeld of suﬃciently large characteristic, where that latter condition will be speciﬁed later. Let f, t2 , . . . , tn ∈ k[X] be non-constant polynomials in the ordered variables X = X1 < · · · < Xn .  
   
  A Modular Algorithm for Computing the Intersection  
   
  75  
   
  Assume that T := {t2 , . . . , tn } is a regular chain with mvar(ti ) = Xi for 2 ≤ i ≤ n. Assume also mvar(f ) = Xn . Our goal is to compute the intersection V (f )∩W (T ) in the sense of the function call Intersect(f, T ), as speciﬁed in Sect. 2. We shall show that, under some assumptions, one can compute a regular chain C ⊆ k[X] so that C is zero-dimensional and we have: V (f ) ∩ W (T ) = W (C). For convenience, we deﬁne rn := f . Regarding tn and rn as polynomials in (k[X1 , . . . , Xn−1 ])[Xn ], let S(tn , rn , Xn ) be the subresultant chain of tn and rn , if mdeg(tn ) ≥ mdeg(rn ), or the subresultant chain of rn and tn otherwise. Let S0 (tn , rn , Xn ) and S1 (tn , rn , Xn ) be the subresultants of index 0 and 1 from S(tn , rn , Xn ). We let rn−1 := S0 (tn , rn , Xn ) and gn := S1 (tn , rn , Xn ). Continuing in this manner, for 2 ≤ i ≤ n − 1, let S(ti , ri , Xi ) be the subresultant chain of ti and ri (resp. ri and ti ) regarded as polynomials in (k[X1 , . . . , Xi−1 ])[Xi ] if mdeg(ti ) ≥ mdeg(ri ) (resp. mdeg(ti ) < mdeg(ri )) holds. Let S0 (ti , ri , Xi ) and S1 (ti , ri , Xi ) be the subresultants of index 0 and 1 from S(ti , ri , Xi ). We let ri−1 := S0 (ti , ri , Xi ) and gi := S1 (ti , ri , Xi ). To make the problem generic, we assume the following: Hypothesis 1:  
   
  ri ∈ k and mvar(ri ) = Xi , for 1 ≤ i ≤ n − 1  
   
  (1)  
   
  Hypothesis 2: Hypothesis 3:  
   
  gi ∈ k, for 2 ≤ i ≤ n, C := {s, g2 , . . . gn } is a regular chain,  
   
  (2) (3)  
   
  Hypothesis 4:  
   
  (∀i ∈ {2, . . . , n}) res(init(ti ), {s, g2 , . . . , gi−1 }) = 0,  
   
  (4)  
   
  where s is the squarefree part of s := r1 , that is, s/gcd(s, der(s)). Hypothesis 3 has a number of consequences which, essentially, rephrase the fact that C is a regular chain. Proposition 1 gathers those consequences. Building on that, Proposition 2 yields Eq. (5) which plays a key role in our method for computing Intersect(f, T ). Proposition 1. The polynomials s, g2 , . . . gn are non-constant and have main variables X1 , X2 , . . . , Xn , respectively. Moreover, the initial of gi is invertible modulo the ideal s, g2 , . . . , gi−1  generated by s, g2 , . . . , gi−1 in k[X1 , . . . , Xi−1 ]. Hypothesis 4 expresses the fact that the initial of the polynomial ti is invertible modulo the ideal s, g2 , . . . , gi−1 , for i = 2 · · · n. We note that from Hypothesis 4, the set {s, g2 , . . . , gi−1 , ti } is also a regular chain, for 2 ≤ i ≤ n. Proposition 2. Fix an integer i such that 2 ≤ i ≤ n holds. Then, the polynomial gi is a regular GCD of ri and ti modulo the regular chain {s, g2 , . . . , gi−1 }. Moreover, we have: V (s, g2 , . . . , gi−1 , ri , ti ) = V (s, g2 , . . . , gi−1 , gi ).  
   
  (5)  
   
  76  
   
  A. Brandt et al.  
   
  Proof. We ﬁrst prove that gi is a regular GCD of ri and ti modulo the regular chain {s, g2 , . . . , gi−1 }. Since {s, g2 , . . . , gi−1 , gi } is a regular chain, Property (G1 ) of a regular GCD clearly holds. We prove (G2 ). Subresultant theory tells us that there exist polynomials ui , vi ∈ k[X1 , . . . , Xi ] so that we have: ui ri + vi ti = gi . Let Ai be the total ring of fractions of k[X1 , . . . , Xi ]/s, g2 , . . . , gi . Since s is squarefree and since mdeg(g2 ) = · · · = mdeg(gi−1 ) = 1, the ring Ai−1 is actually a direct product of ﬁelds which tells us that gi is the GCD (in the sense of a Euclidean domain) of ri and ti over each of those ﬁelds. Therefore, Property (G2 ) holds. In particular, both ri and ti belong to the ideal generated by gi in Ai−1 [Xi ]. Thus, there exist polynomials qri , qti ∈ Ai−1 [Xi ] so that the following hold in Ai−1 [Xi ]: ri = qri gi and ti = qti gi . Every polynomial p ∈ Ai−1 [Xi ] can be written as the fraction of a polynomial n ∈ k[X1 , . . . , Xi ] over a polynomial d ∈ k[X1 , . . . , Xi−1 ] so that d is invertible modulo s, g2 , . . . , gi−1 . Therefore, there exist polynomials in Ai−1 [Xi ], that we denote again qri and qti for convenience, so that the following hold in k[X1 , . . . , Xi ]: ri ≡ qri gi mod s, g2 , . . . , gi−1  and ti ≡ qti gi mod s, g2 , . . . , gi−1 . From the above, it is clear that gi pseudo-divides (actually divides) both ri and ti modulo s, g2 , . . . , gi−1 . Therefore, Property (G3 ) holds and we have proved that gi is a regular GCD of ri and ti modulo the regular chain {s, g2 , . . . , gi−1 }. The second claim of this proposition follows from the ﬁrst one and Lemma 1. Lemma 1. Fix an integer i such that 2 ≤ i ≤ n holds. Let gˆi ∈ k[X1 , . . . , Xi ] be a non-constant polynomial with mvar(ˆ gi ) = Xi . Assume that gˆi is a regular GCD of ri and ti modulo the regular chain {s, g2 , . . . , gi−1 }. Then, we have: V (s, g2 , . . . , gi−1 , ri , ti ) = V (s, g2 , . . . , gi−1 , gˆi ).  
   
  (6)  
   
  Proof. We denote by Ti the regular chain {s, g2 , . . . , gi−1 , ti }. It follows from Property (G7 ) of a regular GCD that: V (ri ) ∩ W (Ti ) ⊆ W ({s, g2 , . . . , gi−1 , gˆi }) ∪ V (ri , hgˆi ) ∩ W (Ti ) ⊆ V (ri ) ∩ W (Ti ). Since hgˆi , the initial of gˆi , is invertible modulo s, g2 , . . . , gi−1 , we have: V (ri , hgˆi ) ∩ W (Ti ) = ∅. Since V (Ti ) and V ({s, g2 , . . . , gi−1 , gˆi }) are both zero-dimensional, we have: V (s, g2 , . . . , gi−1 , ti ) = W (Ti ) = W (Ti ) and V (s, g2 , . . . , gi−1 , gˆi ) = W ({s, g2 , . . . , gi−1 , gˆi }). Therefore, we have: V (ri , s, g2 , . . . , gi−1 , ti ) = V (s, g2 , . . . , gi−1 , gˆi ). Theorem 1 tells us that, under our genericity assumptions, the result of Intersect(f, T ) is given by the regular chain C = {s, g2 , . . . , gn }. Theorem 1. With our four Hypotheses 1, 2, 3 and 4, we have: V (f, t2 , . . . , tn ) = V (s, g2 , . . . , gn ).  
   
  (7)  
   
  Proof. This follows immediately from Proposition 2 and Lemma 2. Lemma 2. For each integer i, such that 2 ≤ i ≤ n holds, let gˆi ∈ k[X1 , . . . , Xi ] be a non-constant polynomial with mvar(ˆ gi ) = Xi so that gˆi is a regular GCD of ri and ti w.r.t. the regular chain {s, gˆ2 , . . . , gˆi−1 }. Then, we have: V (f, t2 , . . . , tn ) = V (s, gˆ1 , . . . , gˆn ).  
   
  (8)  
   
  A Modular Algorithm for Computing the Intersection  
   
  77  
   
  Algorithm 1. GenericIntersectDimOne Require: (f, T ) as in Theorem 1. Recall: f ∈ k and mvar(f ) = Xn . Ensure: C as in Theorem 1. 1: rn := f 2: for i := n . . . 1 do 3: ri−1 := S0 (ti , ri , Xi ) 4: gi := S1 (ti , ri , Xi ) 5: if ri−1 ∈ k or mvar(ri−1 ) = Xi−1 then 6: throw Hypothesis 1 not met 7: if gi ∈ k then 8: throw Hypothesis 2 not met 9: s:= squareFreePart(r1 ) 10: C := {s, g2 , . . . gn } 11: if C is not a regular chain then 12: throw Hypothesis 3 not met 13: for i := 2 ... n do 14: if hi is not regular w.r.t. C then 15: throw Hypothesis 4 not met 16: return C  
   
  Proof. Since rn = f and since ri−1 belongs to the ideal generated by ri and ti , we have: V (f, t2 , . . . , tn ) = V (r1 , t2 , r2 , . . . , tn , rn ). Since s is the squarefree part of s = r1 , we also have: V (f, t2 , . . . , tn ) = V (s, t2 , r2 , . . . , tn , rn ). With repeated application of Lemma 1, we deduce: V (f, t2 , . . . , tn ) = V (s, gˆ1 , . . . , gˆn ). Algorithm 1 summarizes the results of this section. Note that Algorithm 1 computes Intersect(f, T ) only if Hypotheses 1, 2, 3, 4 hold, and throws an exception otherwise. The general task of computing Intersect(f, T ) can be achieved by the algorithms presented in [15]. In fact, these exceptions can be caught by a wrapper algorithm, which can then call the general Intersect procedure. Moreover, one can attach to these exceptions the data already computed by Algorithm 1 so that the wrapper algorithm can avoid unnecessary computations. We will return to the handling of the exceptions of Algorithm 1 in Sect. 5.  
   
  4  
   
  The Modular Method  
   
  We use the same notations as in Sect. 3. The objective of this section is to turn Algorithm 1 into a modular algorithm where: 1. we evaluate f and T at suﬃciently many values of X1 so that: (a) T specializes well at X1 = a to a zero-dimensional regular chain T (a), (b) T (a) is replaced with a normalized regular chain Na generating the same ideal, (c) the images of gn , . . . , g2 , r1 at X1 = a are computed eﬃciently; and 2. the polynomials gn , . . . , g2 , r1 are reconstructed from their images by means of interpolation and rational function reconstruction.  
   
  78  
   
  A. Brandt et al.  
   
  Let ri (a) be the polynomial ri evaluated at X1 = a and ti (a) be the polynomial from Na with main variable Xi . The beneﬁt of this modular algorithm is that the computation of the subresultants S0 (ti (a), ri (a), Xi ) and S1 (ti (a), ri (a), Xi ) avoid the expression swell described in Sect. 1. Indeed, the regular chain Na is normalized. This modular algorithm leads to the usual questions: 1. Can all computed modular images be combined in order to retrieve the desired result, or are there some specializations that must be discarded? 2. If so, how do we detect those specializations that must be discarded? 3. How many modular images do we need in order to obtain the desired result? We detail the answers to these three questions in the following three subsections, respectively. Luckily, there are only ﬁnitely many bad specializations which must be discarded. 4.1  
   
  The Fumber of Bad Specializations is Finite  
   
  Let a ∈ k and let Φa be the evaluation homomorphism from k[X1 , . . . , Xn ] to k[X2 , . . . , Xn ] which evaluates X1 at a. Recall that C stands for {s, g2 , . . . , gn }. Assume that a is not a root of the border polynomial BC ∈ k[X1 ] of C. Therefore, for 2 ≤ i ≤ n, the polynomial Φa (ti ) is not constant and has main variable Xi . Moreover, the set {Φa (t2 ), . . . , Φa (tn )} is a zero-dimensional regular chain in k[X2 , . . . , Xn ]. Let S(Φa (ti ), Φa (ri ), Xi ) be the subresultant chain of Φa (ti ) and Φa (ri ) regarded as polynomials in (k[X2 , . . . , Xi−1 ])[Xi ]. From this subresultant chain, let S0 (Φa (ti ), Φa (ri ), Xi ) and S1 (Φa (ti ), Φa (ri ), Xi ) be the subresultants of index 0 and 1. Proposition 3. With Hypothesis 1, there exists a ﬁnite subset D(f, T ) ⊆ k such that, for all a ∈ D(f, T ), for all 2 ≤ i ≤ n, we have: Φa (gi ) = S1 (Φa (ti ), Φa (ri ), Xi ), and Φa (r1 ) = S0 (Φa (t2 ), Φa (r2 ), X2 ). Proof. Fix i ∈ N such that 2 ≤ i ≤ n From Hypothesis 1, we have ri ∈ k and mvar(ri ) = Xi . Using the lexicographical term order induced by X2 < · · · < Xi , let ci−1 be the leading coeﬃcient of ri regarded as a multivariate polynomial in k[X1 ][X2 , . . . , Xi ], such that ci−1 ∈ k[X1 ]. If a is not a root of ci−1 then Φa (ri ) and ri have the same degree in Xi . Since BT (a) = 0, the polynomials Φa (ti ) and ti have the same degree in Xi too. It follows from the specialization property of subresultants that Φa (gi ) and S1 (Φa (ti ), Φa (ri ), Xi ) are equal. Therefore, the desired set is: D(f, T ) = {a ∈ k | (BT · c1 · · · cn−1 )(a) = 0}, which is ﬁnite. 4.2  
   
  Number of Bad Specializations and Other Degree Estimates  
   
  We start by giving an estimate of the cardinality of D(f, T ) based on considerations directly derived from subresultant theory. This estimate is pessimistic and, in a second phase, we will revisit it to derive a modular algorithm computing the regular chain C = {s, g2 , . . . , gn }, as stated in Theorem 1.  
   
  A Modular Algorithm for Computing the Intersection  
   
  79  
   
  (n)  
   
  Let di be the maximum of the degrees of f, tn , . . . , t2 w.r.t. Xi , for 1 ≤ i ≤ n. Using the determinantal formulation of subresultants, it follows that the degree of any subresultant of S(tn , rn , Xn ) w.r.t. Xi , for 1 ≤ i ≤ n−1, is bounded (n) (n) (n−1) over by deg(tn , Xn ) deg(rn , Xi ) + deg(rn , Xn ) deg(tn , Xi ) ≤ 2dn di =: di . Using again the determinantal formulation, it follows that the degree of any subresultant of S(tn−1 , rn−1 , Xn−1 ) w.r.t. Xi for 1 ≤ i ≤ n − 2, is bounded over by deg(tn−1 , Xn−1 ) deg(rn−1 , Xi ) + deg(rn−1 , Xn−1 ) deg(tn−1 , Xi ), yielding (n−2)  
   
  di  
   
  (n)  
   
  (n−1)  
   
  := dn−1 di  
   
  (n−1) (n)  
   
  + dn−1 di  
   
  (n)  
   
  (n)  
   
  = 2dn(n) di (di  
   
  (n)  
   
  + dn−1 ).  
   
  Continuing, the degree of any subresultant of S(tn−j , rn−j , Xn−j ) w.r.t. Xi for (n−j−1) (n) (n−j) (n−j) (n) 1 ≤ i ≤ n − j, is bounded above by di = dn−j di + dn−j di . To (n)  
   
  (n)  
   
  obtain a concise result, let d be the maximum of d1 , . . . , dn . Then, we have (n−1) (n−2) (n−j−1) = 2d2 , di = 4d3 and di = 2j+1 dj+2 , for 0 ≤ j ≤ n − 2. di Returning to the polynomial BT ·c1 · · · cn−1 , we are now ready to estimate its (n−j−1) , thus we have deg(cn−j−1 ) ≤ degree. First, we note that deg(cn−j−1 ) ≤ di 2j+1 dj+2 . Second, let hi be the initial of ti , for 2 ≤ i ≤ n. The border polynomial BT of the regular chain T is the product of the iterated resultants res(hi , T ), for (n−j−1) 2 ≤ i ≤ n. Observe that, in the above discussion, the degree estimates di remain valid when we replace f by each of h2 , . . . , hn . Therefore, we have: (1) deg(BT ) = deg(res(h2 , T ))+· · ·+deg(res(hn , T )) ≤ (n−1)d1 = (n− 1)2n−1 dn . Finally, we deduce: deg(BT c1 · · · cn−1 ) ≤ (n − 1)2n−1 dn + 2n−1 dn + · · · + 2d2 ≤ n2n dn+1 . Proposition 4. With the hypotheses and notations of Proposition 3, the cardinality of D(f, T ) is at most n2n dn+1 , where d is the maximum partial degree of f, t2 , . . . , tn in any variable X1 , . . . , Xn . Of course, this estimate is not sharp, particularly if the product of the par(n) (n) tial degrees d1 , . . . , dn exceeds the total degree of either f or tn . Therefore, in order to design a modular method for computing the regular chain C = {s, g2 , . . . , gn } of Theorem 1, by means of an evaluation and interpolation strategy, we take advantage of the B´ezout inequality (see Theorem 3 in [36]). Since V (f, t2 , . . . , tn ) is a zero-dimensional aﬃne variety, the number of its elements is bounded over by the product of the total degrees of the polynomials f, t2 , . . . , tn , that we denote by B(f, t2 , . . . , tn ). Thus, the degree of the univariate polynomial s ∈ k[X1 ] cannot exceed B(f, t2 , . . . , tn ). Furthermore, assume that the call Intersect(f, T ) (with T = {t2 , . . . , tn }) was made as part of the triangular decomposition of a zero-dimensional system, say {f1 , . . . , fm }. Then, one can use the B´ezout bound B(f1 , . . . , fm ) instead of B(f, t2 , . . . , tn ), since the former is likely to be (much) smaller than the latter. In fact, any bound B on the number of points of V (f1 , . . . , fm ) can be used as an upper bound for deg(s). Moreover, our experimentation suggests that the degrees of the univariate polynomials c1 , . . . , cn−1 are not likely to exceed the degree of r1 . Hence, the number of specializations X1 = a which do not cancel  
   
  80  
   
  A. Brandt et al.  
   
  the border polynomial BC but cancel one of c1 , . . . , cn−1 are likely to be bounded over by (n − 1)B. Therefore, using nB + 1 specializations X1 = a is likely to be suﬃcient for computing s, assuming that we have a practically eﬃcient criterion for avoiding the specialization cancelling BC . This latter observation leads us to the algorithm of Sect. 4.3. In fact, we shall see that, in practice, the quantity nB + 1 can often be reduced to 2B + 1 or 3B + 1, even when n > 3 holds. 4.3  
   
  A Modular Algorithm  
   
  In addition to the strategy presented in Sect. 4, the other key ingredients of our modular algorithm are the following ones: (1) Monagan’s probabilistic strategy for computing resultants via evaluation and interpolation [30], (2) the small prime modular algorithm for computing the GCD of two univariate polynomials over Z, see Chap. 6 in [25], and (3) rational function reconstruction, see Sect. 5.7 in [25]. Algorithm 2 takes as input the same arguments f and T as Algorithm 1. In addition, Algorithm 2 takes three other arguments B, s, D which are positive integers with the following respective roles: 1. B is an estimate of the degree of r1 . 2. e controls the behavior of Monagan’s probabilistic strategy: once 2B + e + 1 images (of the polynomials gn , . . . , g2 , r1 ) are computed then the recombination of the ﬁrst 2B + 1 images is compared to the recombination of the ﬁrst 2B + e + 1; if they are equal, then rational function reconstruction is attempted. If rational function reconstruction fails, then e more images are collected and the next comparison uses the ﬁrst 2B + e + 1 and the ﬁrst 2B + 2e + 1 images, and so on. 3. D is an estimate for the number of bad specializations deﬁned in Sect. 4.1. As we shall see, if B is an upper bound for the degree of r1 , and if D is an upper bound for the number of bad specializations, then the algorithm is deterministic, otherwise it is probabilistic. In practice, a smaller B and a small e makes the algorithm check for termination (in the sense Monagan’s probabilistic strategy) more frequently, which may have an impact on performance, positive or negative. In practice, if B is believed to be a sharp estimate for deg(r1 ), then e can be small, even a small percentage of B, without negative performance impact. Similarly, a smaller D makes the algorithm check earlier whether C has the required properties, that is, whether Hypotheses 2, 3, 4 hold or not. This may also have an impact on performance, positive or negative. In practice, if B is believed to be a sharp estimate for deg(r1 ), then D can be small, say a percentage of B. Algorithm 2 uses two simple sub-procedures speciﬁed below: – InitializeImageCollection initializes A and G to the empty list, and d to a list of n zeros. A will store the evaluation points and G the corresponding images of gn , . . . , g2 , r1 .  
   
  A Modular Algorithm for Computing the Intersection  
   
  81  
   
  Algorithm 2. ModularGenericIntersectDimOne Require: (f, T, B, e, D), where f, T are as in Theorem 1 with f ∈ k and mvar(f ) = Xn , B is a positive integer which estimates deg(r1 ), e is a positive integer, and D estimates the number of bad specializations. Ensure: C as in Theorem 1, provided Hypotheses 1, 2, 3 and 4 are met, otherwise an exception is raised. 1: a := Random(); P := {a}  a random element of k used as a seed 2: M := 2B + 1  Twice the bound is necessary for rational function reconstruction 3: c := 0  counts the number of specializations used so far 4: b := 0  counts the number of bad specializations met so far 5: (A, G, d) := InitializeImageCollection(f, T ) 6: CM := {}; CM +e := {} 7: while c < M + e + D do 8: (a, T (a), f (a), P) := FindCandidateSpecialization(f, T, P) 9: c := c + 1 10: i := n 11: ri (a) := f (a) 12: Na := Normalize(T (a))  normalize the regular chain 13: ti (a) := Polynomial(Xi , Na )  The poly. of Na with main var. Xi 14: while i > 1 do 15: ri−1 (a) := S0 (ti (a), ri (a), Xi ) 16: if ri−1 ∈ k or mvar(ri−1 ) < Xi−1 then  Bad specialization or Hypothesis 1 not met 17: b := b + 1; Goto Line 8 18: if #A > 0 and deg(ri−1 (a), Xi−1 ) > d[i − 1] then  Every specialization in A is bad 19: b := b + #A; Goto Line 5 20: if #A > 0 and deg(ri−1 (a), Xi−1 ) < d[i − 1] then  The specialization X1 = a is bad 21: b := b + 1; Goto Line 8 22: d[i − 1] = deg(ri−1 (a), Xi−1 ) 23: gi (a) := S1 (ti (a), ri (a), Xi ) 24: i := i − 1 25: G := Append(G, [gn (a), . . . , g2 (a), r1 (a)]) 26: A := Append(A, a) 27: if #A = M and CM = {} then 28: CM := Interpolate(A, G, X1 )  Recover X1 in gn , . . . , g2 , r2 29: if #A = M + e and CM +s = {} then 30: CM +e := Interpolate(A, G, X1 )  
   
  31:  
   
  if CM = CM +e = {} and c > D then  If M and M + e images produce the same recombination and those are expected to have the correct degrees C := RationalFunctionReconstruction(CM , A, X1 ) if C = Failure then if one of gn , . . . , g2 is constant then throw Hypothesis 2 not met if C is not a regular chain then throw Hypothesis 3 not met if one of h2 , . . . , hn is not regular w.r.t. C then throw Hypothesis 4 not met return (C)  
   
  32: 33: 34: 35: 36: 37: 38: 39: 40: 41: M := M + e ; CM := CM +e ; CM +e := {} 42: throw Hypothesis 1 not met  
   
  82  
   
  A. Brandt et al.  
   
  – FindCandidateSpecialization(f, T, P): (1) randomly chooses a ∈ k such that a ∈ P, a does not cancel BT and init(f ), and (2) returns f and T specialized at X1 = a. Finally, P is replaced with P ∪ {a}. To avoid the use of a couple more sub-procedures (which would have many arguments and complicated speciﬁcations), the pseudo-code of Algorithm 2 uses Goto statements in three places: – At Line 19, the Goto statement forces the algorithm to resume from Line 5, thus discarding all images that have been computed up to that point. – At Lines 17 and 21, the Goto statement forces the algorithm to resume from Line 8, thus discarding the image that is currently being computed. A few more observations about the pseudo-code of Algorithm 2: – Between Lines 14 and 24, the while-loop is used to compute and collect the images of gn , . . . , g2 , r1 for X1 = a. – Between Lines 7 and 41, the main loop is located. Each iteration of that loop starts with the selection of a new specialization point. If the images of gn , . . . , g2 , r1 at that speciﬁcation are successfully collected, then the algorithm checks whether the desired result has been reached. When this is not the case, more images may be computed. Note that this while-loop runs until c ≥ M + s + D holds, or until an exception is raised, or until the result is returned. The quantity M is replaced by M + s during the loop. However, as we shall see in Theorem 2 the algorithm always terminates. Finally, note that pseudo-code uses two counters c and b. They, respectively, count the total number of specializations used and the number of bad specializations hit during the execution of the algorithm. The counter b is not used by the algorithm, but it is an interesting information that the algorithm can return. Theorem 2. Algorithm 2 always terminates. This is a probabilistic algorithm for computing the regular chain C as deﬁned in Theorem 1, if Hypotheses 1, 2, 3, and 4 all hold, or detecting which Hypothesis does not hold, otherwise. If the input arguments B and D are upper bounds for deg(r1 ) and the number of bad speciﬁcations, respectively, then the algorithm is deterministic. Proof. We ﬁrst prove termination. Suppose that Hypothesis 1 does not hold. Then, the while-loop between Lines 14 and 24 will never succeed in reaching i = 0. Indeed, each time this while-loop is entered the Goto statement at Line 17 will force the algorithm to exit this while-loop and resume at Line 8. As a result, the counter c will reach the bound M + s + D of the outer while-loop (between Lines 7 and 41) and the algorithm will terminate by throwing the exception Hypothesis 1 not met. Suppose now that Hypothesis 1 holds. Then, the while-loop between Lines 14 and 24 will exit before reaching i = 0 if and only if bad specializations are discovered: 1. at Line 19, because all previous specializations were bad, 2. or at Line 21, because the current specialization is bad.  
   
  A Modular Algorithm for Computing the Intersection  
   
  83  
   
  Thus, when the while-loop between Lines 14 and 24 reaches i = 0, a new image of (gn , . . . , g2 , r1 ) is added to G. Once the total number of images of (gn , . . . , g2 , r1 ) is greater than or equal to M + e and D, the algorithm: 1. tests at Line 31 whether the recombination of those images has stabilized, and, if so, 2. attempts rational function reconstruction at Line 32, and, if successful, 3. checks whether Hypotheses 2, 3 and 4 all hold When the condition c > D holds, the current recombination of the images of gn , . . . , g2 , r1 are believed to have the correct degrees. And, in fact, they do have the correct degrees whenever D is an upper bound for the number of bad specializations. Now, if c ≤ D holds or if rational function reconstruction fails, the value of M is replaced by M + e, and thus the while-loop bound M + e + D is increased. Nevertheless, after combining suﬃciently images of gn , . . . , g2 , r1 (not using bad specializations) both conditions CM = CM +e and c > D will be true together, and, moreover, rational function reconstruction will succeed. Consequently, the section of code between Lines 34 and 40 will be entered and, therefore, the algorithm will terminate. Clearly, if the input arguments B and D are upper bounds for deg(r1 ) and the number of bad speciﬁcations, respectively, then the Algorithm 2 satisﬁes its speciﬁcations in a deterministic way.  
   
  5  
   
  Relaxing the Hypotheses  
   
  The previously described modular method works well to avoid expression swell and makes certain problems tractable, see Sect. 7. However, when one of the Hypotheses 1, 2, 3 or 4 does not hold, the algorithm will fail to produce a result. We take this section to sketch how a wrapper algorithm handles the cases where Algorithm 2 throws an exception. When Hypothesis 1 Fails. If ri ∈ k or mvar(ri ) = Xi , for some i, three cases must be considered. First, if ri = 0 then the polynomials ri+1 and ti+1 have a GCD with a positive degree in Xi . Let us call this GCD d. The computations thus split into two cases: d = 0 and d = 0. This leads, in principle, to two recursive calls to the Intersect algorithm; see [15]: one to compute the intersection of f and {t2 , . . . , ti , ti+1 /d, ti+2 , . . . , tn } and one to compute the intersection of f and {t2 , . . . , ti , d, ti+2 , . . . , tn }. We note that the ﬁrst one may be attempted by our modular algorithm. Meanwhile in the second one, we have ri+1 null modulo sat(T ), thus the computations performed in the original call can be recycled in order to complete Intersect(f, T ). Second, if ri ∈ k \ {0} then V (f ) ∩ W (T ) = ∅ and the empty set should be returned. Third, If mvar(ri ) = Xi , say mvar(ri ) = Xj for j < i. Then, one simply needs to “skip” computing the subresultant chain of ri and ti and instead compute the subresultant chain between ri and tj with respect to Xj . Then, the corresponding gi−1 , . . . , gj+1 are set to be ti−1 , . . . , tj+1 , respectively. When Hypothesis 2 Fails. If one of the g2 , . . . , gn is constant, say gi , then a regular GCD for ri and ti can be found using a subresultant of index higher than  
   
  84  
   
  A. Brandt et al.  
   
  1 from S(ri , ti , Xi ). Since Algorithm 2 has computed S(ri , ti , Xi ) (by computing modular images of it), one can recycle the computations performed by that algorithm in order to obtained a regular GCD for ri and ti . When Hypothesis 3 Fails. When this happens, the set C := {¯ s, g2 , . . . , gn } is not a regular chain. As in the previous case, one of the polynomials g2 , . . . , gn , s, g2 , . . . , gi−1 . Here again, say gi , fails to be a regular GCD of ri and ti modulo ¯ one can recycle the modular images S(ri , ti , Xi ) to obtain a correct regular GCD. Recovering from the failure of Hypotheses 2 or 3 can be accomplished by means of a task-pool scheme where each task consists of an integer i and a proposed regular chain C  . The general idea is to process the regular chain “bottom-up”, replacing any oﬀending gi with a new regular GCD, and splitting computations as necessary. For gi to be a regular GCD of ri and ti modulo s, g2 , . . . , gi−1 ; this can easily ¯ s, g2 , . . . , gi−1 , init(gi ) must be regular modulo ¯ be checked with a call to the function Regularize. As soon as we hit a gi such that its initial is not regular modulo Ci := ¯ s, g2 , . . . , gi−1 , the regular chain Ci is split in two (or more) regular chains Ci,1 and Ci,2 . For one of these regular chains, say Ci,1 , we have that the initial of gi is regular modulo Ci,1 . This implies that in this particular branch of the computations, gi is a regular GCD of ri and ti . For the second branch, gi is zero modulo Ci,2 and thus gi is not a regular GCD of ri and ti . Hence, we need to replace gi with the next non-zero polynomial in the subresultant chain between ri and ti , say gi . We replace the previous task with two new ones: one in which we want to check the regularity of the initial of gi+1 , . . . , gn modulo Ci,1 , and another one in which we want to check the regularity of gi , gi+1 , . . . , gn modulo Ci,2 . A task is considered complete once gn is found to be regular. We repeat this process until the task pool is empty. When Hypothesis 4 Fails. Lastly, consider Hypothesis 4. This hypothesis says that the resulting regular chain C := {¯ s, g2 , . . . , gn } must maintain the inequalities deﬁned by the initials of the polynomials ti in the regular chain T , that is, none of those initials must vanish on V (f ) ∩ W (T ). Hypothesis 4 fails if and only if (at least) one of the init(ti )’s is not invertible modulo the ideal ¯ s, g2 , . . . , gn . Rectifying this issue is handled easily by a call to Regularize. Let ti be a polynomial whose initial is not regular modulo C. Since C, after passing Hypothesis 3, is a regular chain, one can call Regularize(init(ti ), C) to compute regular chains C1 , . . . , Ce such that init(ti ) is either regular or zero modulo Cj . Then, one simply discards any Cj for which init(ti ) is zero. A similar “discarding process” is applied by the CleanChain procedure in the non-modular case [15].  
   
  6  
   
  Implementation  
   
  In the preceding sections we have discussed a modular algorithm based on evaluation-interpolation. In fact, we employ two separate modular methods. In practice, triangular decompositions are often performed over the rational numbers. Thus, k should be Q in all of the previous algorithms.  
   
  A Modular Algorithm for Computing the Intersection  
   
  85  
   
  Algorithm 2 is actually implemented and executed over a ﬁnite ﬁeld. Our implementation is written in the C programming language as part of the BPAS Library [2] and follows [3] for its implementation of sparse multivariate polynomials over the rationals and ﬁnite ﬁelds. Moreover, our implementation actually implements a wrapper function, as detailed in Sect. 5. This function is able to catch the exceptions of Hypotheses 2, 3, or 4, recover from them, and produce a correct output. The implementation does not yet handle when Hypothesis 1 fails, instead falling back to the non-modular implementation of Intersect in BPAS [4,12]. This is left to future work. The implementation of Algorithm 2 is broken into three main phases: computing subresultants, interpolation and reconstruction of the regular chain C (see Sect. 3 for notations), and lifting the coeﬃcients from a ﬁnite ﬁeld to Q. Interpolation and rational function reconstruction are standard algorithms. Thus, we describe the other two main parts. Subresultants are computed in three diﬀerent ways depending of the degrees of the input polynomials. All three methods are detailed in [5]. First, an optimized version of Ducos’ subresultant chain algorithm handles the general case. Second, when degrees are high, one can compute each subresultant itself using evaluation-interpolation. We can evaluate the variables X2 , . . . , Xi−1 , compute strictly univariate subresultants, and then recover the true subresultants through interpolation. We implement this multivariate evaluation-interpolation using a multi-dimensional truncated Fourier transform (TFT). Third, when computations are univariate (either when computing s¯ or as univariate images in the evaluation-interpolation scheme), one can use an algorithm based on Half-GCD to compute only the subresultants of index 0 and 1 rather than the entire subresultant chain. Recovering the rational number coeﬃcients is an implementation of the technique based on Hensel-lifting described in [21]. With an implementation of this Hensel lifting for triangular sets, notice that a modular algorithm for a zerodimensional intersect is immediate. Algorithm 2 can be transformed to compute the intersection between f and a zero-dimensional regular chain T as follows. Working modulo a prime p, do not specialize any variables and directly normalize T . Compute the iterated subresultants of f and T , do not interpolate any variables, and directly construct C. Then, perform Hensel lifting to reconstruct the coeﬃcients of C over Q. This method is very eﬀective in practice to reduce expression swell in the coeﬃcients, as we describe next.  
   
  7  
   
  Experimentation and Discussion  
   
  Our experimentation was collected on a desktop running 20.04.1-Ubuntu with an Intel Core i7-7700K processor at 4.20GHz, and 16GB DDR4 memory at 2.4 GHz. We ﬁrst show that the modular method is eﬀective in practice to signiﬁcantly reduce the computational time of computing a triangle decomposition, and even solves some polynomial systems which were infeasible for previous solvers. Table 1 summarizes these results by describing the structure of these wellknown systems, as well as the execution time to solve the system using the  
   
  86  
   
  A. Brandt et al. Table 1. Running times of Maple vs. BPAS(non-modular) vs. BPAS(modular)  
   
  System  
   
  Number of Number of B´ezout Variables Equations Bound  
   
  Number of Maple BPAS(non-modular) BPAS(modular) Solutions Time (s) Time (s) Time (s)  
   
  noon5  
   
  5  
   
  5  
   
  243  
   
  233  
   
  1.46  
   
  0.61  
   
  0.42  
   
  eco8  
   
  8  
   
  8  
   
  1458  
   
  64  
   
  N/A  
   
  N/A  
   
  60.63  
   
  Cassou-Nogues  
   
  4  
   
  4  
   
  1344  
   
  16  
   
  1.43  
   
  5.60  
   
  0.42  
   
  childDraw-2  
   
  10  
   
  10  
   
  256  
   
  42  
   
  12.70  
   
  2.83  
   
  2.48  
   
  Issac97  
   
  4  
   
  4  
   
  16  
   
  16  
   
  156.33  
   
  101.16  
   
  1.92  
   
  Themos-net-2  
   
  6  
   
  6  
   
  32  
   
  24  
   
  55.10  
   
  57.60  
   
  1.37  
   
  Uteshev-Bikker  
   
  4  
   
  4  
   
  36  
   
  36  
   
  N/A  
   
  N/A  
   
  362.97  
   
  Theomes-net-3  
   
  5  
   
  5  
   
  32  
   
  24  
   
  54.93  
   
  57.01  
   
  1.36  
   
  Noonburg-5  
   
  5  
   
  5  
   
  243  
   
  233  
   
  2011.24  
   
  314.72  
   
  6.43  
   
  cohn2  
   
  4  
   
  4  
   
  900  
   
  Positive Dimension  
   
  145.39  
   
  1322.98  
   
  1315.34  
   
  rabno  
   
  9  
   
  9  
   
  36000  
   
  16  
   
  3.77  
   
  2.97  
   
  2.97  
   
  tangents0  
   
  6  
   
  6  
   
  64  
   
  24  
   
  3.69  
   
  2.40  
   
  0.39  
   
  Cassou-Nogues-2 4  
   
  4  
   
  450  
   
  8  
   
  N/A  
   
  N/A  
   
  2145.28  
   
  Table 2. Runtime analysis of the subroutines of the modular method System  
   
  Call Number  
   
  Number of Evaluations  
   
  B´ezout Bound  
   
  Time (s) for Collect Images  
   
  Time (s) for Time (s) for Subresultants Interpolation  
   
  Time (s) for Time (s) for Modular Intersect  
   
  Time (s) for Hensel lifting  
   
  noon5  
   
  1st  
   
  161  
   
  243  
   
  0.01  
   
  0.01  
   
  0.02  
   
  0.00  
   
  0.03  
   
  0.02  
   
  noon5  
   
  2nd  
   
  161  
   
  243  
   
  0.00  
   
  0.01  
   
  0.02  
   
  0.00  
   
  0.03  
   
  0.00  
   
  noon5  
   
  3rd  
   
  161  
   
  243  
   
  0.00  
   
  0.01  
   
  0.02  
   
  0.00  
   
  0.03  
   
  0.01  
   
  eco8  
   
  1st  
   
  289  
   
  1458  
   
  0.07  
   
  0.06  
   
  0.31  
   
  0.12  
   
  0.63  
   
  2.56  
   
  Cassou-Nogues  
   
  1st  
   
  161  
   
  1344  
   
  0.02  
   
  0.04  
   
  0.02  
   
  0.01  
   
  0.08  
   
  0.08  
   
  Issac97  
   
  1st  
   
  161  
   
  16  
   
  0.01  
   
  0.01  
   
  0.02  
   
  0.00  
   
  0.05  
   
  0.33  
   
  Themos-net-2  
   
  1st  
   
  161  
   
  32  
   
  0.02  
   
  0.02  
   
  0.03  
   
  0.01  
   
  0.09  
   
  0.74  
   
  Uteshev-Bikker  
   
  1st  
   
  193  
   
  36  
   
  0.02  
   
  0.03  
   
  0.04  
   
  0.01  
   
  0.12  
   
  58.91  
   
  Themos-net-3  
   
  1st  
   
  161  
   
  32  
   
  0.02  
   
  0.02  
   
  0.03  
   
  0.01  
   
  0.09  
   
  0.75  
   
  Noonburg-5  
   
  1st  
   
  257  
   
  243  
   
  0.02  
   
  0.64  
   
  1.22  
   
  0.01  
   
  3.04  
   
  2.93  
   
  tangents0  
   
  1st  
   
  161  
   
  64  
   
  0.02  
   
  0.02  
   
  0.02  
   
  0.00  
   
  0.00  
   
  0.13  
   
  Cassou-Nogues-2 1st  
   
  161  
   
  450  
   
  0.01  
   
  0.03  
   
  0.02  
   
  0.00  
   
  0.07  
   
  0.04  
   
  modular method and not using the modular method, if the latter is possible. The non-modular implementation is the (serial) version described in [4,12]. As a point of comparison, we also present the time to compute a triangular decomposition using the RegularChains library of Maple 2022. In particular, the systems eco8, Uteshev-Bikker, and Cassou-Nogues-2, could not be solved within two hours of computation time. However, the modular method allows the ﬁrst two to be solved on the order of minutes, and Cassou-Nogues-2 on the order of 10s of minutes. In Table 2, we describe a detailed analysis of the modular intersect in dimension one. Observe that the running time for each main task is provided. Additionally, it is important to mention that in some cases, the number of collected images is far below the B´ezout bound of the input systems. Therefore, this shows the importance of stabilization techniques in the implementation. Among our works-in-progress is, of course, is the adaptation and implementation of this modular method for Intersect(f, T ) for T in dimension higher than 1. This is necessary in order to tackle even harder polynomial systems. Moreover, recovering from cases where Hypothesis 1 fails must also be implemented.  
   
  A Modular Algorithm for Computing the Intersection  
   
  87  
   
  References 1. Arnold, E.A.: Modular algorithms for computing Gr¨ obner bases. J. Symb. Comput. 35(4), 403–419 (2003) 2. Asadi, M., et al.: Basic Polynomial Algebra Subprograms (BPAS) (2023). https:// www.bpaslib.org 3. Asadi, M., Brandt, A., Moir, R.H.C., Moreno Maza, M.: Algorithms and data structures for sparse polynomial arithmetic. Mathematics 7(5), 441 (2019) 4. Asadi, M., Brandt, A., Moir, R.H.C., Moreno Maza, M., Xie, Y.: Parallelization of triangular decompositions: techniques and implementation. J. Symb. Comput. 115, 371–406 (2023) 5. Asadi, M., Brandt, A., Moreno Maza, M.: Computational schemes for subresultant chains. In: Boulier, F., England, M., Sadykov, T.M., Vorozhtsov, E.V. (eds.) CASC 2021. LNCS, vol. 12865, pp. 21–41. Springer, Cham (2021). https://doi.org/10. 1007/978-3-030-85165-1 3 6. Aubry, P., Lazard, D., Moreno Maza, M.: On the theories of triangular sets. J. Symb. Comput. 28(1–2), 105–124 (1999) 7. Becker, E., Mora, T., Marinari, M.G., Traverso, C.: The shape of the shape lemma. In: MacCallum, M.A.H. (ed.) Proceedings of ISSAC 1994, pp. 129–133. ACM (1994) 8. Boulier, F., Lazard, D., Ollivier, F., Petitot, M.: Representation for the radical of a ﬁnitely generated diﬀerential ideal. In: Proceedings of the International Symposium on Symbolic and Algebraic Computation, pp. 158–166. ACM (1995) 9. Boulier, F., Lemaire, F., Moreno Maza, M.: Well known theorems on triangular systems and the D5 principle. In: Proceedings of the Transgressive Computing (2006) 10. Boulier, F., Lazard, D., Ollivier, F., Petitot, M.: Computing representations for radicals of ﬁnitely generated diﬀerential ideals. Appl. Algebra Eng. Commun. Comput. 20(1), 73–121 (2009) 11. Boulier, F., Lemaire, F., Moreno Maza, M.: Computing diﬀerential characteristic sets by change of ordering. J. Symb. Comput. 45(1), 124–149 (2010) 12. Brandt, A.: The design and implementation of a high-performance polynomial system solver. Ph.D. thesis, University of Western Ontario (2022) 13. Chen, C., et al.: Computing the real solutions of polynomial systems with the regularchains library in maple. ACM Commun. Comput. Algebra 45(3/4) (2011) 14. Chen, C., Davenport, J.H., May, J.P., Moreno Maza, M., Xia, B., Xiao, R.: Triangular decomposition of semi-algebraic systems. J. Symb. Comput. 49, 3–26 (2013) 15. Chen, C., Moreno Maza, M.: Algorithms for computing triangular decomposition of polynomial systems. J. Symb. Comput. 47(6), 610–642 (2012) 16. Chen, C., Moreno Maza, M.: An incremental algorithm for computing cylindrical algebraic decompositions. In: Feng, R., Lee, W., Sato, Y. (eds.) Computer Mathematics, pp. 199–221. Springer, Heidelberg (2014). https://doi.org/10.1007/978-3662-43799-5 17 17. Chen, C., Moreno Maza, M.: Quantiﬁer elimination by cylindrical algebraic decomposition based on regular chains. J. Symb. Comput. 75, 74–93 (2016) 18. Chou, S., Gao, X.: Computations with parametric equations. In: Proceedings of the ISSAC 1991, pp. 122–127 (1991) 19. Chou, S., Gao, X.: A zero structure theorem for diﬀerential parametric systems. J. Symb. Comput. 16(6), 585–596 (1993)  
   
  88  
   
  A. Brandt et al.  
   
  20. Cox, D.A., Little, J., O’Shea, D.: Ideals, Varieties, and Algorithms: An Introduction to Computational Algebraic Geometry and Commutative Algebra. UTM, Springer, Cham (2015). https://doi.org/10.1007/978-3-319-16721-3 ´ Wu, W., Xie, Y.: Lifting techniques 21. Dahan, X., Moreno Maza, M., Schost, E., for triangular decompositions. In: Proceedings of the International Symposium on Symbolic and Algebraic Computation, pp. 108–115 (2005) 22. Dong, R., Lu, D., Mou, C., Wang, D.: Comprehensive characteristic decomposition of parametric polynomial systems. In: Proceedings of the International Symposium on Symbolic and Algebraic Computation, pp. 123–130. ACM (2021) 23. Faug`ere, J.C.: R´esolution des syst`emes d’´equations alg´ebriques. Ph.D. thesis, Universit´e Paris 6 (1994) 24. Gao, X., van der Hoeven, J., Yuan, C., Zhang, G.: Characteristic set method for diﬀerential-diﬀerence polynomial systems. J. Symb. Comput. 44(9) (2009) 25. von zur Gathen, J., Gerhard, J.: Modern Computer Algebra, 2nd edn. Cambridge University Press, Cambridge (2003) 26. Hu, Y., Gao, X.S.: Ritt-Wu characteristic set method for Laurent partial diﬀerential polynomial systems. J. Syst. Sci. Complex. 32(1), 62–77 (2019) 27. Kapur, D., Saxena, T.: Extraneous factors in the Dixon resultant formulation. In: Proceedings of the ISSAC 1997, pp. 141–148. ACM (1997) 28. Lazard, D.: A new method for solving algebraic systems of positive dimension. Discret. Appl. Math. 33(1–3), 147–160 (1991) 29. Lazard, D.: Solving zero-dimensional algebraic systems. J. Symb. Comput. 13(2), 117–132 (1992) 30. Monagan, M.B.: Probabilistic algorithms for computing resultants. In: Proceedings of the ISSAC, pp. 245–252. ACM (2005) 31. Moreno Maza, M., Sandford, R.: Towards extending Fulton’s algorithm for computing intersection multiplicities beyond the bivariate case. In: Boulier, F., England, M., Sadykov, T.M., Vorozhtsov, E.V. (eds.) CASC 2021. LNCS, vol. 12865, pp. 232–251. Springer, Cham (2021). https://doi.org/10.1007/978-3-030-85165-1 14 32. Moreno Maza, M., Xia, B., Xiao, R.: On solving parametric polynomial systems. Math. Comput. Sci. 6(4), 457–473 (2012) 33. Moreno Maza, M.: On triangular decompositions of algebraic varieties. Technical report. TR 4/99, NAG Ltd, Oxford, UK (1999). Presented at the MEGA-2000 Conference 34. Maza, M.M., Rioboo, R.: Polynomial GCD computations over towers of algebraic extensions. In: Cohen, G., Giusti, M., Mora, T. (eds.) AAECC 1995. LNCS, vol. 948, pp. 365–382. Springer, Heidelberg (1995). https://doi.org/10.1007/3-54060114-7 28 35. Ritt, J.F.: Diﬀerential Algebra. Dover Publications Inc., New York (1966) 36. Schmid, J.: On the aﬃne Bezout inequality. Manuscr. Math. 88(1), 225–232 (1995) ´ Degree bounds and lifting techniques for triangular sets. In: Proceedings 37. Schost, E.: of the ISSAC 2002, pp. 238–245. ACM (2002) 38. Shimoyama, T., Yokoyama, K.: Localization and primary decomposition of polynomial ideals. J. Symb. Comput. 22(3), 247–277 (1996) 39. Traverso, C.: Gr¨ obner trace algorithms. In: Gianni, P. (ed.) ISSAC 1988. LNCS, vol. 358, pp. 125–138. Springer, Heidelberg (1989). https://doi.org/10.1007/3-54051084-2 12 40. Wang, D.K.: The Wsolve package. www.mmrc.iss.ac.cn/∼dwang/wsolve.html 41. Wang, D.M.: Epsilon 0.618. http://wang.cc4cm.org/epsilon/index.html 42. Wu, W.T.: A zero structure theorem for polynomial equations solving. MM Res. Preprints 1, 2–12 (1987)  
   
  A Modular Algorithm for Computing the Intersection  
   
  89  
   
  43. Xia, B.: DISCOVERER: a tool for solving semi-algebraic systems. ACM Commun. Comput. Algebra 41(3), 102–103 (2007) 44. Yang, L., Hou, X., Xia, B.: A complete algorithm for automated discovering of a class of inequality-type theorems. Sci. China Ser. F Inf. Sci. 44(1), 33–49 (2001) 45. Yang, L., Zhang, J.: Searching dependency between algebraic equations: an algorithm applied to automated reasoning. In: Artiﬁcial Intelligence in Mathematics, pp. 147–156. Oxford University Press (1994)  
   
  Certified Study of Internal Solitary Waves André Galligo(B) and Didier Clamond Université Côte d’Azur, CNRS, LJAD UMR 7351 and INRIA, Parc Valrose, 06108 Nice, France {andre.galligo,didier.clamond}@univ-cotedazur.fr  
   
  Abstract. We apply computer algebra techniques and drawing with a guaranteed topology of plane curves, to the study of internal gravity solitary waves in shallow water, relying on an improved framework of the Serre-Green-Naghdi equations. By a diﬀerential elimination process, the study reduces to describing the solutions of a special type of ordinary non linear ﬁrst order diﬀerential equation, depending on parameters. The analysed constraints imply a reduction of the allowed conﬁgurations, and we can provide a topological classiﬁcation of the phase plane curves. So, special behaviors are detected even if they appear in tiny domain of the parameter space. The paper is illustrated with examples and pictures. Keywords: Serre-Green-Naghdi equations · Internal gravity solitary waves · Ordinary non linear ﬁrst order diﬀerential equation · Drawing with a guaranteed topology  
   
  1  
   
  Introduction  
   
  Computer algebra has made tremendous progresses in the last 6 decades and has been successfully applied in numerous other ﬁelds. We note that very often Symbolic computations are used to provide useful close form formulas to deal with precise objects. Such an example is the exact expression, relying on the “sech” function, computed by Maple for a soliton of the KDV equation. See the corresponding “Maplesoft” entry (https://www.maplesoft.com) which also explains: “A solitary wave, or soliton, is a wave-packet that propagates through space without a change in its shape. Such a phenomenon can be observed on the surface of shallow water, as ﬁrst described by John Scott Russell in 1844 in his “Report on Waves”. This phenomenon is not only studied in hydrodynamics, but also e.g. in ﬁber optics, neuroscience and particle physics. Furthermore, there are various realizations of solitary waves.” However, researchers in applied ﬁelds may need symbolic computations for more “open” qualitative questions, e.g. in designing their models. Therefore it is useful that researchers in Computer algebra collaborate with them and understand their approaches, in order to tackle arising technical challenges. In this article, we will prove that the introduction of new parameters in the (classical in Fluid Mechanics) two-layer SGN Partial Diﬀerential Equations, c The Author(s), under exclusive license to Springer Nature Switzerland AG 2023  F. Boulier et al. (Eds.): CASC 2023, LNCS 14139, pp. 90–106, 2023. https://doi.org/10.1007/978-3-031-41724-5_5  
   
  Certiﬁed Study of Internal Solitary Waves  
   
  91  
   
  designed to improve dispersion characteristics, allow a special type of soliton called slugs. These slugs are observed in the “real word” but are not solutions of the classical equations. This phenomena appears only for some choices of parameters which are not obvious and that we delimited thanks to symbolic computations, inspired by our previous works [5,6]. So, we apply computer algebra techniques, certiﬁed drawing (with a guaranteed topology) of plane curves, to an important problem in ﬂuid dynamics. Internal waves are omnipresent in geophysical and industrial contexts, as they appear at the interface between two media with diﬀerent densities. This situation can be stable only if the layer with the heavy ﬂuid lies below the light one. Otherwise, it would lead to the so-called Rayleigh-Taylor instability [8]. We consider situations where the smaller density is comparable to the heavy one, more precisely, an idealised situation where two liquid layers are bounded from below and above by rigid impermeable horizontal surfaces, the so-called rigid lid approximation. Additionally, the ﬂuids are assumed to be perfect and the waves are long compared to both layer thicknesses. The celebrated SerreGreenNaghdi (SGN) type model [11] was ﬁrst derived for internal waves in [9,10] to approximately model this situation. A variational derivation of the SGN equations was given in [1] and their multi-symplectic structure was highlighted in [4]. These equations are fully nonlinear but only weakly dispersive. Consequently, some attempts were made to improve the dispersion introducing a free parameter into SGN equations using various tricks [3]. In this study, the same goals are achieved by manipulating the Lagrangian density instead of working directly with the equations. In “real life” internal gravity waves, one observes slugs, which are solitary waves with special proﬁles, see the illustration in Fig. 1 and a recent survey in applied ﬂuid dynamics [2]. However, these kind of waves are not obtain as solutions of the classical SGN equations. Therefore, a natural question to rise is: can we obtain similar steady waves solutions for our improved SGN equations, (with theses proﬁles) for a controlled choice of parameters? Our study answers positively, explains the diﬀerent behaviors and provides the tools for a practical classiﬁcation of all possible cases. Our methodology is rather general and could be extended (at the cost of more technicality) to deal with the situations where the lids are not horizontal. The article is organised as follows. In Sect. 2, we present a variational derivation of classical two-layer SGN equations and modify this system by introducing free parameters into the model. The approach is similar to the one used in [7] for surface waves. The steady solutions to the classical and improved SGN equations are studied in Sect. 3. In Sect. 4, we simplify the expressions and notations, and perform symbolic computations. In Sect. 5, we provide a partition of the parameters space, crucial for our analysis. Section 6 presents the local and the global phase plane analysis. Section 7 sketches typical examples, while Sect. 8 presents an explicit example of a slug wave solution of the improved SGN equations. Finally, the main conclusions and perspectives are outlined.  
   
  92  
   
  A. Galligo and D. Clamond  
   
  Fig. 1. Slug and its representation.  
   
  Fig. 2. Deﬁnition sketch.  
   
  2  
   
  Improved Serre-Like Model  
   
  We consider a two-dimensional irrotational ﬂow of an incompressible ﬂuid stratiﬁed in two homogeneous layers of densities ρj (j = 1, 2). The lower layer is labeled with subscripts 1 and the upper one with subscripts 2; for obvious physical reasons, we consider ρ1 > ρ2 ≥ 0. The ﬂuid is bounded below by a horizontal impermeable bottom at y = −d1 and above by a rigid lid at y = d2 , y being the upward vertical coordinate such that y = η(x, t) is the equation of the interface and y = 0 is the equation of the still interface level. The lower and upper total thicknesses are, respectively, h1 = d1 + η and h2 = d2 − η, so h1 + h2 = d1 + d2 = D is a constant. x is the horizontal coordinate, t is the time, g is the downward acceleration due to gravity and surface tensions are neglected. Finally, we denote uj = (uj , vj ) the velocity ﬁelds in the j-th layer. See Fig. 2. In order to model long waves in shallow layers with rigid horizontal bottom and lid, one can consider the shallow water ansatz ¯1 (x, t), u1 (x, y, t) ≈ u u2 (x, y, t) ≈ u ¯2 (x, t),  
   
  v1 (x, y, t) ≈ − (y + d1 ) u ¯1x , v2 (x, y, t) ≈ − (y − d2 ) u ¯2x ,  
   
  Certiﬁed Study of Internal Solitary Waves  
   
  93  
   
  and the Serre-like (i.e., fully nonlinear, weakly dispersive) approximate equations of the Euler–Lagrange equations for the Lagrangian density L = K −V + ρ1 { h1t + [ h1 u ¯1 ]x } φ1 + ρ2 { h2t + [ h2 u ¯ 2 ]x } φ2 , where φj are Lagrange multipliers and where K and V satisfy     ¯2 ¯2 h3 u h3 u 2K = ρ1 h1 u ¯12 + 1 1x + ρ2 h2 u ¯22 + 2 2x , 3 3 2V = (ρ1 − ρ2 ) g h12 + ρ2 g D2 , and are respectively, the kinetic and potential energies (V is measured from the bed y = −d1 ). An improved Lagrangian density is obtained using two parameters βj , j = 1, 2. L∗ = K ∗ − V ∗ + ρ1 { h1t + [ h1 u ¯1 ]x } φ1 + ρ2 { h2t + [ h2 u ¯ 2 ]x } φ2 , where (omitting an additional constant in the deﬁnition of V ∗ ) 2 K ∗ = ρ1 h1 u ¯12 + ρ2 h2 u ¯22  1 1   2 2 + 3 + 2 β1 ρ1 h13 u ¯1x + 13 + 12 β2 ρ2 h23 u ¯2x   2 2 , + 12 h1 h2 β1 ρ2 h1 u ¯2x + β2 ρ1 h2 u ¯1x  2  2 V ∗ = (ρ1 − ρ2 ) g h12 + 12 (ρ1 − ρ2 ) g β1 h12 + β2 h22 h1x .  
   
  3  
   
  Steady Motions  
   
  We consider steady motions, i.e. the frame of reference moving with the wave ¯j = u ¯j (x) and the motion is independent of the time t. Therefore, h1 = h1 (x), u φj = Φj (x) − 12 Bj t where Bj are Bernoulli constants (see [7] for explanations on the time dependence of φj ). Calling −cj the mean velocity in the j-th layer, the mass conservation yields u ¯1 = −  
   
  c1 d1 , h1  
   
  u ¯2 = −  
   
  c2 d2 , h2  
   
  c1 d1 + c2 d2 = − Q.  
   
  Thus, cj is the wave phase velocity observed in the frame of reference without mean ﬂow in the j-th layer, and cj > 0 if the ﬂuid travels toward the increasing x-direction in a ‘ﬁxed’ frame of reference. For steady ﬂows, the Euler–Lagrange equations for the Lagrangian L ∗ imply  
   
  94  
   
  A. Galligo and D. Clamond  
   
  ρ1 B1 − ρ2 B2 =   2 − (β1 h12 + β2 h22 )h1xx (ρ1 − ρ2 ) g 2h1 − (β1 h1 − β2 h2 )h1x + ρ1 c12 d12 h1−2 − ρ2 c22 d22 h2−2    2 − ρ1 c12 d12 h1−4 1 + 32 β1 h12 + 12 β2 h2 (h2 − 2h1 ) h1x    2 + ρ2 c22 d22 h2−4 1 + 32 β2 h22 + 12 β1 h1 (h1 − 2h2 ) h1x     + ρ1 c12 d12 h1−2 23 + β1 [ h1 h1x ]x + β2 h1−1 h22 h1x x     + ρ2 c22 d22 h2−2 23 + β2 [ h2 h1x ]x + β1 h2−1 h12 h1x x . The (constant) left-hand side is determined averaging its right-hand side. For solitary waves hj (±∞) = dj and u ¯j (±∞) = −cj , one gets ρ1 B1 − ρ2 B2 = 2 (ρ1 − ρ2 ) g d1 + ρ1 c12 − ρ2 c22 . After multiplication by h1x and integration, one obtains ( ρ1 B1 − ρ2 B2 ) h1 =  

  β1 h12 + β2 h22 2 h1x C + (ρ1 − ρ2 ) g − 2   
   
  2 ρj cj2 dj2 hj2 ρj cj2 dj2 β1 h12 + β2 h22 2 + + h − , 1x hj3 3 2 hj j=1 h12  
   
  where C is an integration constant determined averaging the equation. For solitary waves, we have C = (ρ1 − ρ2 ) g d12 + 2 ρ1 c12 d1 + ρ2 c22 (d2 − d1 ). In that case and with h1 = d1 + η(x) and h2 = d2 − η(x), the previous ordinary diﬀerential equation can be rewritten   
   
  dη dx  
   
  2  
   
  2  
   
  =  
   
  2  
   
  6 (d1 + η) (d2 − η) η 2 N (η) , D(η)  
   
  where N and D are two polynomials of degree two and eight,   N (η) = ρ1 d2 c12 + ρ2 d1 c22 − (ρ1 − ρ2 )gd1 d2   + (ρ1 − ρ2 )g(d1 − d2 ) − ρ1 c12 + ρ2 c22 η + (ρ1 − ρ2 )gη 2 ,  
   
  (1)  
   
  Certiﬁed Study of Internal Solitary Waves  
   
  95  
   
  and D(η) =  
   
     2 2 2 (d1 + η) (d2 − η) ρ1 d12 d2 c12 + ρ2 d1 d22 c22 − ρ1 c12 d12 − ρ2 c22 d22 η    − 3 β1 d12 + β2 d22 (ρ1 − ρ2 )gd1 d2 − ρ1 c12 d2 − ρ2 c22 d1 d12 d22  + 3 (10β1 + β2 )d13 − 15(2β1 + β2 )d12 d2 + 15(β1 + 2β2 )d1 d22    −(β1 + 10β2 )d23 (ρ1 − ρ2 )gη 5 − 3(β1 + β2 ) ρ1 c12 d12 − ρ2 c22 d22 η 5   + 3 (10β1 + 3β2 )d12 − 15(β1 + β2 )d1 d2 + (3β1 + 10β2 )d22 (ρ1 − ρ2 )gη 6 + 3 {(5β1 + 3β2 )d1 − (3β1 + 5β2 )d2 } (ρ1 − ρ2 )gη 7 + 3(β1 + β2 )(ρ1 − ρ2 )gη 8 .  
   
  Our study concentrates on solitary waves.  
   
  4  
   
  Algebraic Analysis and Symbolic Computations  
   
  Notations The previous equations depends on too many parameters for the algebraic computations aimed in this paper. Therefore, for the sake of simplicity, from now on without loss of generality, we choose dimensionless units such that ρ1 = g = d1 = 1. To simplify further the notations we let with ρ < 1, d :=  
   
  ρ2 d2 ; ρ := ; p := ηx . d1 ρ1  
   
  Two important scaling parameters also arise, the Froude numbers, (F1 , F2 ), with c21 = F1 > 0, c22 = dF2 > 0. 4.1  
   
  Improved SGN  
   
  After performing these transformations, we obtain the dimensionless counterpart of the diﬀerential Eq. (1), which now has the following form: ηx2 =  
   
  2  
   
  2  
   
  6 (1 + η) η 2 (d − η) N (η) . D(η)  
   
  The polynomial N can be written either N (η) = (1 − ρ)(η 2 + γη + δ), γ = −(d − 1) +  
   
  (−F1 + ρdF2 ) (F1 + ρF2 ) ; δ = −d + d . 1−ρ 1−ρ  
   
  (2)  
   
  96  
   
  A. Galligo and D. Clamond  
   
  or equivalently N (η) = (1 − ρ)(η − d)(η + 1) − (η − d)F1 + (η + 1)ρdF2 . The denominator D(η) is a polynomial of degree 8 with respect to η (see below). We would like to stress out that the free modeling parameters βj appear only in the denominator D(η). In the latter, the points on the (p, η) plane satisfying relation (2) with p := ηx = 0 are important for our analysis. These points are the roots of the numerator of (2) right hand side: they include η = 0, η = −1, η = d and the two roots of the quadratic polynomial N (η) to be studied below. We emphasize that if they do not depend on the (η) parameters β, their multiplicities may depend on β. The fraction in η, N D(η) , is irreducible iﬀ a resultant polynomial in the parameter does not vanish; the eﬀective analysis of D(η) and of this assumption are done in the next subsection where we will also consider the conditions on the parameters in order that D vanishes at η = −1, η = 0 or η = d. Our classiﬁcation method will depend on the relative positions of the roots of N (η) with respect to −1, 0, d which we will analyse in Sect. 5. We assume that, the derivatives ηx remains ﬁnite, this implies that after simpliﬁcation, the denominator of (2) does not vanish between −1 and d. This condition could be checked symbolically, relying on Sturm algorithm, or directly by computing the real roots for a given choice of parameters. For ﬁxed (d, ρ), the expressions of δ and γ deﬁne an aﬃne change of coordinates which maps lines and parabola to other lines and parabola. We recall that 1 − ρ > 0 and we have, N (0) = (1 − ρ)δ = d(F1 + ρF2 − (1 − ρ)) ; N  (0) = (1 − ρ)γ = −F1 + ρdF2 − (d − 1)(1 − ρ); N (−1) = (1 − ρ)(1 − γ + δ) = (d + 1)F1   
   
  N (−1) = (1 − ρ)(−2 + γ) = −(d + 1)(1 − ρ) − F1 + ρdF2 ; N (d) = (1 − ρ)(d2 + dγ + δ) = d(d + 1)ρF2 N  (d) = (1 − ρ)(2d + γ) = (d + 1)(1 − ρ) − F1 + ρdF2 . The solution of N (0) = N  (0) = 0 is [F1 =  
   
  1−ρ d(1 − ρ) , F2 = ] d+1 (d + 1)ρ  
   
  while the solution of N (−1) = N  (−1) = 0 is [F1 = 0 , F2 =  
   
  (d + 1)(1 − ρ) ] ρd  
   
  and the solution of N (d) = N  (−d) = 0 is [F1 = (d + 1)(1 − ρ) , F2 = 0].  
   
  Certiﬁed Study of Internal Solitary Waves  
   
  4.2  
   
  97  
   
  Expressions Related to D, with β1 and β2  
   
  Here, the expressions of D is given in dimension less units, it is a polynomial of degree 1 in F1 and F2 and degree 8 in η,    2 2 D(η) = 2 (1 + η) (d − η) dF1 + ρd 3 F2 − F1 − ρ F2 d 3 η   − 3 β1 + β2 d 2 (1 − ρ − F1 − ρ F2 )d 3  + 3 (10β1 + β2 ) − 15(2β1 + β2 )d + 15(β1 + 2β2 )d 2    −(β1 + 10β2 )d 3 (1 − ρ)η 5 − 3(β1 + β2 ) F1 − ρF2 d 3 η 5   + 3 (10β1 + 3β2 ) − 15(β1 + β2 )d + (3β1 + 10β2 )d 2 (1 − ρ)η 6 + 3 {(5β1 + 3β2 ) − (3β1 + 5β2 )d} (1 − ρ)η 7 + 3(β1 + β2 )(1 − ρ)η 8 . We deduce D(0) = d3 [2(F1 + ρd2 F2 ) − 3(β1 + β2 d2 )(1 − ρ − F1 − ρF2 )]. and notice that D(−1) and D(d), vanish when β1 = β2 = 0, D(−1) = 3F1 (β1 d3 + β2 d5 + β1 + β2 ) + 3ρF2 β2 (1 − d2 )d3 + 3(1 − ρ)[5β1 + (18β1 − 5β2 )d − (12β1 + 21β2 )d2 + (β1 + 10β2 )d3 ].  
   
  D(d) = 3F1 (1 − d2 )d3 β1 + 3ρF2 d3 [(β1 + β2 d2 + (β1 + β2 )d5 )] 3(1 − ρ)[β1 (−d3 + 10d5 − 20d6 + 5d7 ) + β2 (9d5 − 12d6 + 18d7 + 16d8 )]. We computed the resultant between D and N . It is a large expression, a polynomial in (F1 , F2 ) of degree 9, easily stored in a computer ﬁle, but displaying this general expression is not material for our article. 4.3  
   
  Illustrative Case  
   
  To illustrate our graphics, we choose some values for β1 , β2 , d, ρ, and specialise our formulas.D becomes Ds, N becomes N s. Here we choose β1 = 0.2, β2 = 0.1, d = 2, ρ = 0.5 then N s(η) = 0.5(η 2 − (1 − 2F2 + F1 )η + 4F2 + 4F1 − 2.  
   
  Ds(η) = 0.45η 8 − 1.35η 7 − 0.45η 6 + (−2.9F1 + 11.60F2 + 2.25)η 5 + (8F1 − 8F2 )η 4 + (−2F1 − 40F2 )η 3 + (−20F1 + 8F2 )η 2 + (8F1 + 64F2 )η + 30.4F1 + 39.20F2 − 7.20. We deduce  
   
  98  
   
  A. Galligo and D. Clamond  
   
  Ds(0) = 30.4F1 + 39.20F2 − 7.20 ; Ds (0) = 8F1 + 64F2 ; Ds(−1) = −8.1F1 + 15.3F2 + 3.6 ; Ds (−1) = −4.5F1 + 18F2 + 0.9; Ds(2) = −14.4F1 + 122.4F2 − 21.6 ; Ds (2) = −4.5F1 + 18F2 + 0.9. These two last lines in the parameter space (F1 , F2 ) intersect (approximately) at an admissible point [F1 = 0.01111111111, F2 = 0.1777777778]. We notice that the conditions Ds(2) = 0 and Ds (2) < 0, that we will consider in a next section, correspond to the half-line deﬁned by Ds(2) = 0 and F1 > 0.01111111111, F2 > 0.1777777778. 4.4  
   
  Classical SGN, i.e., β1 = β2 = 0  
   
  In the classical (i.e. not improved) SGN equations, we have β1 = 0 β2 = 0, the polynomial N does not change but the previous expressions simplify as follows. D becomes a new polynomial of degree 5 instead of 8 which factors D = 2(1 + η)2 (d − η)2 ((F2 d3 ρ − F1 )η + ρd3 F2 + dF1 ), while the expression of ηx2 becomes after simpliﬁcation ηx2 =  
   
  (F2  
   
  d3 ρ  
   
  3 η 2 N (η) , − F1 )η + ρd3 F2 + dF1  
   
  (3)  
   
  the denominator is now a polynomial of degree one in η, DC := (F2 d3 ρ − F1 )η + ρd3 F2 + dF1 . We notice that more simpliﬁcations could appear when DC(0) = 0 i.e. when F1 = −ρd2 F2 , but this is not allowed since F1 and F2 should be positive. The resultant of N and DC is a polynomial RC(F1 , F2 ) of degree 3. It is divisible by F2 since when F2 = 0 both N and DC vanish at η = d. When this N and replace it by a polynomial in η of resultant vanishes, we can simplify DC degree 1, whose root can be computed by noticing that the sum of the two roots of N is −γ. We display the specialisation of RC for (d = 2, ρ = 0.5) RC (d=2,ρ=0.5) = −3F2 (2F12 − 4F22 − 7F1 F2 − 4.5F1 + 4.5F2 ).  
   
  5  
   
  Partition of the Parameters Space  
   
  In this subsection we classify the parameters space (F1 , F2 ) with respect to the possible position of the real roots of N with respect to −1, 0, d. We recall that N has no real root iﬀ its discriminant is negative, i.e., Δ := 4δ − γ 2 < 0, in the parameters space. This relation describes the interior of a  
   
  Certiﬁed Study of Internal Solitary Waves  
   
  99  
   
  parabola, while the parabola itself corresponds to the cases when N has a real double root. We recall that N (−1) = 0 means F1 = 0, N (d) = 0 means F2 = 0 and N (0) = 0 means F1 + ρF2 − (1 − ρ) = 0, and that we already computed the intersections of these lines with the parabola deﬁned by the discriminant. We are mainly interested by the partition of the complementary of these sets in R2 , into the following semi algebraic open sets and their borders, that we design by roman numbers from I to IV in the graphics of Fig. 3. 1. 2. 3. 4.  
   
  N N N N  
   
  has no root in the interval [−1, d] i.e., Δ < 0 or N  (−1) > 0, or N  (d) < 0; has 2 roots in ] − 1, 0[ i.e., N (0) > 0, N  (−1) < 0, N  (0) > 0; has 2 roots in ]0, d[ i.e., N (0) > 0, N  (0) < 0, N  (d) > 0; has 1 root in ] − 1, 0[ and one in ]0, d[, i.e., N (0) < 0.  
   
  Notice that the partition is only delimited by a parabola and 3 lines. Since the graphical aspect of the partitions does not change when (d, ρ) varies, we only present the graphics for d = 2, ρ = 0.5 in Fig. 3. Then, the intersections of the three lines with the parabola are the points [0, 32 ], [ 32 , 0], [ 16 , 13 ].  
   
  Fig. 3. Partition of the parameters space.  
   
  6  
   
  Phase Plane Analysis  
   
  We are now ready for the phase plane analysis of Eq. (2). Since the internal solitary wave is bounded by −1 ≤ η ≤ d, we also assume that the derivative p = ηx is also bounded, i.e., D does not vanish (or only to decrease the multiplicities of the roots of the numerator of the fraction). Therefore the topology of the phase plane curve deﬁned by (2) in the (p, η)-plane can be deduced from the local analysis near the axis p = 0.  
   
  100  
   
  6.1  
   
  A. Galligo and D. Clamond  
   
  Local Analysis  
   
  We provide a case by case study of the situations at the values where p vanishes, i.e., at η = −1, η = 0, η = d and at the roots of the polynomial N , of degree 2, already considered at the previous section. Let us start by a simple observation on the “shapes” of the solutions of the diﬀerential equation y 2 = y m . If m = 2 we get an exponential. While, up to a 2 constant and a sign, if m = 0 we get y = x; if m = 1 we get y = x4 ; if m = 3 we −1 get y = −4 x2 ; if m = 4 we get y = x . Our local analysis for ηx = 0 must focus near the points x at inﬁnity for η = 0, and near the points x ﬁnite for η equals −1, 0, d or the roots of N . Near η = 0. – If  
   
  N (0) D(0)  
   
  > 0 then ηx2  η 2 d2 (d + 1)2  
   
  N (0) D(0)  
   
   (0) can be locally solved into η  k exp(±αx), where α = d(d + 1) N D(0) . This local solution is admissible, since it corresponds to a solitary wave, with an exponential decay when x tends to ±∞. It is not admissible if this happens for a ﬁnite value of x. – If N (0) = 0 and N  (0) = 0, and D(0) = 0 then ηx2  η 3 d2 (d + 1)2  
   
  N  (0) D(0)  
   
  can be locally solved into η  ±(αx + β)−2 , where α, and β are two numbers. This local solution is admissible, since it corresponds to a solitary wave with an algebraic decay when x tends to ±∞. It is not admissible if this is happens for a ﬁnite value of x. – If N (0) = 0 and N  (0) = 0 and D(0) > 0 then ηx2  η 4 d2 (d + 1)2  
   
  2(1 − ρ) D(0)  
   
  can be locally solved into η  ±(αx + β)−1 , where α, and β are two numbers. This local solution is admissible, since it corresponds to a solitary wave with an algebraic decay when x tends to ±∞. It is not admissible if this is happens for a ﬁnite value of x. – If N (0) = 0 and D(0) = 0, and D (0) = 0 then ηx2  ηd2 (d + 1)2  
   
  N (0) D (0)  
   
  can be locally solved into η  ±(αx + β)2 , where α, and β are two numbers. This cannot happen near x = ±∞, hence it is not admissible.  
   
  Certiﬁed Study of Internal Solitary Waves  
   
  101  
   
  Near η = d , or near η = −1. By symmetry of the roles of the two walls, it is enough to analyse what happens near η = d. We proceed exactly like near η = 0 but for ﬁnite values of x, also the wave is allowed to not reach the level η = d. Notice that N (d) = d(d + 1)ρF2 > 0. – If D(d) = 0 and D (d) < 0, then ηx2  (η − d)d2 (d + 1)2  
   
  N (d) D (d)  
   
  can be locally solved into η−d  −(αx+β)2 , where α, and β are two numbers. It is admissible. – If D(d) = 0 and and D (d) = 0 and D (d) = 0, then ηx does not vanish at η = −1. – If D(d) = 0, this situation is not admissible. Near a double root of N in ]0,d [. Call a this double root, assumed in ]0, d[ or similarly in ] − 1, 0[. – If D(a) = 0 and D (a) < 0, then ηx2  (η − a)a2 (d − a)2 (a + 1)2  
   
  2(1 − ρ) D (a)  
   
  which can be locally solved into η − a  (αx + β)2 , where α, and β are two numbers. It is admissible. – If D(a) = 0, this situation is not admissible. – If D(a) = 0 and and D (a) = 0 and D (a) = 0, then ηx does not vanish at η = a. Near a simple root of N . Call a this simple root. – If D(a) = 0 and  
   
  N  (a) D(a)  
   
  < 0 then  
   
  ηx2  (η − a)a2 (d − a)2 (a + 1)2  
   
  N  (a) D(a)  
   
  can be locally solved into η−a  −(αx+β)2 , where α, and β are two numbers. It is admissible. – If D(a) = 0 and and D (a) = 0, then ηx does not vanish at η = a.  
   
  102  
   
  6.2  
   
  A. Galligo and D. Clamond  
   
  Global Analysis  
   
  The task is to determine the admissible solitary waves with proﬁle η(x) or equivalently paths (η(x), p(x)) in the phase space where p stands for ηx , starting from x = −∞, η = 0, p = 0 and ending at x = ∞, η = 0, p = 0 which obey the local constraints of the previous subsection. In the half sector where p > 0 (resp. p < 0), η(x) must increase (resp. decrease). Before ending at x = ∞, a priori the path is allowed to loop several times, following admissible sub paths, but this situation will not happen in our setting. Since in the classiﬁcation of admissible proﬁles, η = −1 and η = d play symmetric roles, to avoid redundancy, we will present only half of the admissible cases. So, we start from the point (0, 0) (corresponding to x = −∞) in the (η, p) plane, and end at the same point. The path goes up on the right till it reaches a value of η where p = 0 then we rely on the local analysis for the next move, and so on. The classiﬁcation relies on the partition presented in the previous section. From the local analysis, we deduce that there are only 3 allowed loops in the (η, p) plane, we denoted them Λ1 , Λ2 , Λ3 : – Λ1 starts at (0, 0) and loops smoothly around a point (0, a) between (0, 0) and (0, d). – Λ2 starts at (0, 0) and loops smoothly around the point (0, d). – Λ3 starts at (0, 0) and goes up to a point (p1 , d) then travel left to the point (−p2 , d) then goes back to (0, 0). Note that the path Λ3 gives rise to a non smooth solitary wave. We can also consider another generalised situation where the loops Λ2 and Λ3 are allowed to “pause” on a segment [x1 , x2 ] of the x axis when they arrive at (0, d). This will give rise to a so called slug solitary wave (see example 2bis below). Improved SGN Now let see to what constraints on the parameters corresponds each of theses paths for improved SGN equations. – Λ1 corresponds to a generic case: the parameters associated to the open domains III, IV, in the parameter space, and the condition that the roots between 0 and d do not disappear, i.e., the fraction does not simplify. – Λ2 corresponds to special situations when D(d) = 0,D (d) < 0 and there are no root of N between 0 and d, i.e. the parameters associated to the open domains I, and II. – Λ3 corresponds to more special situations when D(d) = 0, D (d) = 0,D (d) = 0 and there are no root of N between 0 and d, i.e. the parameters associated to the open domains I and II.  
   
  Certiﬁed Study of Internal Solitary Waves  
   
  103  
   
  Classical SGN For classical SGN, i.e., β1 = β2 = 0, the conditions are diﬀerent – Λ1 corresponds to two generic cases. Either the parameters are associated to the open domain III in the image parameter space, or they are associated to IV with the additional condition that the roots of N between 0 and d do not disappear, i.e. DC(a) = 0. This last condition is generically satisﬁed since it is implied by the non vanishing the resultant between N and DC. – Λ2 cannot happen in this context. – Λ3 corresponds to a generic situation when there are no root of N between 0 and d, i.e., the parameters associated to the open domains I and II.  
   
  7  
   
  An Explicit Example of Slug  
   
  We ﬁx the same ﬁrst parameters d = 2, ρ = 0.1, β1 = 0.2, β2 = 0.1, as in our previous illustrative example. Following our analysis, we expect a slug wave solution of the improved twolayer Serre–Green–Naghdi model, for parameters [F1 , 10, F2 ] satisfying the following conditions: – [F1 , 10, F2 ] lies on the half-line deﬁned by Ds(2) = −14.4F1 + 122.4F2 − 21.6 = 0 and Ds (2) = −4.5F1 + 18F2 + 0.9 < 0; – N ∫ has no root in [0, 2]; – D∫ has no root in [0, 2]. We illustrate the two ﬁrst conditions on Fig. 4 they deﬁne a new half-line, starting at the intersection point between the ﬁrst line and the parabola, approximately F1 = 0.54, F2 = 0.24.  
   
  Fig. 4. Half-line domain for a slug.  
   
  104  
   
  A. Galligo and D. Clamond  
   
  We chose F1 = 0.6, F2 = 0.2470588235. Then the polynomials N and D in Eq. 2 become (in factored form): N (η) = 0.5η 2 − 0.8529411765η + 0.4470588235. and D(η) = 0.45(η − 2.00000000035639)(η − 2.24323907282581) (η 2 + 2.11640966529855η + 1.16068410277303) (η 2 + 1.98358517862098η + 2.30370705616395) (η 2 − 2.85675577073733η + 3.83909639362947) As expected η = 2 is a root of the polynomial D(η), and then we can divide it by (η − 2). Hopefully there are no other root in [0, d]. Then, as expected the phase proﬁle in Fig. 5 is of type Λ2 .  
   
  Fig. 5. A slug in the phase plane  
   
  We also pictured the wave, that we computed by integrating numerically the corresponding ODE 2, in the physical space in Fig. 6.  
   
  Fig. 6. The slug in the physical plane  
   
  Certiﬁed Study of Internal Solitary Waves  
   
  8  
   
  105  
   
  Conclusion  
   
  In this paper, as in [5], we have presented for the computer algebra community, an application to actual problem coming from the ﬂuid mechanics community. It is devoted to the study of a dispersive system of equations, which governs the dynamics of long waves taking place at the interface between two immiscible ﬂuids, with a simplifying rigid lid assumption. More precisely in our variant of the two-layer Serre–Green–Naghdi model, which is known to possess excellent nonlinear properties, the dispersion relation had be improved. We rely on Computer algebra to precise the study by analyzing nonlinear travelling solitary wave solutions of our model. More precisely, adapted coordinates changes, geometric interpretation and computations of resultants and discriminants, certiﬁed graph drawing allow us to provide a classiﬁcation of all the possible shapes of the phase diagram curves and all possible solitary waves. The travelling wave solutions are described using the phase plane analysis language. Namely, we determine the regimes where one has localized slug solitary waves. This model can be used to study internal waves with higher physical accuracy and with a larger stability limit. A similar study, with the same methodology can be developed with the same equation but other boundary conditions corresponding to the so called bores, i.e., η(−∞) = 0 but η(+∞) = 0. One can also extend the study to singular waves as we did in [6]. Acknowledgements. We thank our colleague Denys Dutykh for useful discussions and his important involvement in a preliminary version of this work four years ago.  
   
  References 1. Barros, R., Gavrilyuk, S., Teshukov, V.M.: Dispersive nonlinear waves in two-layer ﬂows with free surface. I. Model derivation and general properties. Stud. Appl. Math. 119(3), 191–211 (2007) 2. Thaker, J., Banerjee, J.: Characterization of two-phase slug ﬂow sub-regimes using ﬂow visualization. J. Pet. Sci. Eng. 135, 561–576 (2015) 3. Castro-Orgaz, O., Hager, W.H.: Boussinesq and Serre type models with improved linear dispersion characteristics: applications. J. Hydraul. Res. 53(2), 282–284 (2015) 4. Chhay, M., Dutykh, D., Clamond, D.: On the multi-symplectic structure of the Serre- Green-Naghdi equations. J. Phys. A Math. Theor. 49, 03LT01 (2016) 5. Clamond, D., Dutykh, D., Galligo, A.: Algebraic method for constructing singular steady solitary waves: a case study. Proc. R. Soc. Lond. A 472, 20160194 (2016) 6. Clamond, D., Dutykh, D., Galligo, A.: Computer algebra applied to a solitary waves study. In: ISSAC’15, ACM Proceedings (2015) 7. Clamond, D., Dutykh, D., Mitsotakis, D.: Conservative modiﬁed Serre-GreenNaghdi equations with improved dispersion characteristics. Commun. Nonlinear Sci. Numer. Simul. 45, 245–257 (2017) 8. Glimm, J., Grove, J., Sharp, D.H.: A critical analysis of Rayleigh-Taylor growth rates. J. Comput. Phys. 169, 652–677 (2001)  
   
  106  
   
  A. Galligo and D. Clamond  
   
  9. Mal’tseva, Z.L.: Unsteady long waves in a two-layer ﬂuid. Dinamika Sploshn. Sredy 93(94), 96–110 (1989) 10. Miyata, M.: Long internal waves of large amplitude. In: Horikawa, K., Maruo, H. (eds.) Nonlinear Water Waves. International Union of Theoretical and Applied Mechanics. Springer, Berlin, Heidelberg (1988). https://doi.org/10.1007/978-3642-83331-1_44 11. Serre, F.: Contribution à l’étude des écoulements permanents et variables dans les canaux. Houille Blanche 8, 374–388 (1953)  
   
  Root-Squaring for Root-Finding Soo Go2(B) , Victor Y. Pan1,2 , and Pedro Soto3 1 Department of Computer Science, Lehman College of the City University of New York, Bronx, NY 10468, USA [email protected]  2 Ph.D. Programs in Mathematics and Computer Science, The Graduate Center of the City University of New York, New York, NY 10016, USA [email protected]  3 The Mathematical Institute, University of Oxford, Oxford, UK [email protected]  http://comet.lehman.cuny.edu/vpan  
   
  Abstract. The root-squaring iterations of Dandelin (1826), Lobachevsky (1834), and Gräﬀe (1837) recursively produce the coeﬃcients of polynomials ph (x) whose zeros are the 2h th powers of the zeros of an input polynomial p(x) for h = 1, 2, 3, . . . The iterations have been the main tool for univariate polynomial root-ﬁnding in the 19th century and well beyond but became obsolete later because of severe numerical stability problems observed already in a few iterations. To circumvent this deﬁciency we apply root-squaring to Newton’s Inverse Ratios p (x)/p(x) and compute no coeﬃcients of p(x) or ph (x) for h > 0, assuming that p(x) is a black box polynomial, represented by an oracle or subroutine for its evaluation rather than by its coeﬃcients. Accordingly, our algorithm accelerates root-squaring for a polynomial p(x) that can be evaluated ) for a complex number fast as well as for polynomial tc,ρ (x) = p( x−c ρ c and a positive ρ by performing root-squaring without computing the coeﬃcients of tc,ρ (x). Our extensive experiments demonstrate eﬃciency of application of our algorithms to estimation of extremal root radii, that is, the maximal and minimal distances from a point on the complex plane to the zeros of p(x). This is a well-known ingredient of various eﬃcient polynomial root-ﬁnders, immediately extended to deciding whether a ﬁxed disc on the complex plane contains any zero of p(x). The latter decision, called exclusion test for a disc, is the basic step of all eﬃcient root-ﬁnders using subdivision iterations, in particular, of the recent polynomial root-ﬁnder by the second author, made nearly optimal due to a distinct application of root-squaring iterations.  
   
  Keywords: Symbolic-numeric computing algorithms · Computer algebra  
   
  · Root-ﬁnding · Polynomial  
   
  c The Author(s), under exclusive license to Springer Nature Switzerland AG 2023  F. Boulier et al. (Eds.): CASC 2023, LNCS 14139, pp. 107–127, 2023. https://doi.org/10.1007/978-3-031-41724-5_6  
   
  108  
   
  1 1.1  
   
  S. Go et al.  
   
  Introduction Polynomial Root-Finding  
   
  Given a polynomial p(x) with complex coeﬃcients p0 , p1 , . . . , pd such that p(x) = pd xd + pd−1 xd−1 + · · · + p0 = pd  
   
  d   
   
  (x − zj ), pd = 0,  
   
  (1)  
   
  j=1  
   
  we seek its complex zeros z1 , . . . , zd , that is, the roots of the polynomial equation p(x) = 0, within a ﬁxed tolerance  = 1/2b . This problem of univariate polynomial root-ﬁnding has venerable history of four millennia [17] and is highly important for Computer Algebra in Scientiﬁc Computing. 1.2  
   
  Classical Root-Squaring Iterations  
   
  The DLG root-squaring iterations proposed by Dandelin in 1826 and independently by Lobachevsky in 1834 and Gräﬀe in 1837 (see [10]) have been the dominant approach to polynomial root-ﬁnding in the 19th century and well beyond. The iterations are recursively deﬁned as follows. p0 (x) :=  
   
  √ √ 1 p(x), ph+1 (x) := (−1)d ph ( x )ph (− x), h = 0, 1, . . . pd (h)  
   
  For each h, the hth DLG iteration squares the zeros zj radii  
   
  (h) rj  
   
  :=  
   
  (h) |zj |,  
   
  ph (x) :=  
   
  (2)  
   
  of ph (x) and the root  
   
  j = 1, . . . , d, that is, d  i=0  
   
  (h)  
   
  pi xi =  
   
  d   
   
  (h)  
   
  (h)  
   
  (x − zj ), zj  
   
  = zj2 , j = 1, . . . , d. h  
   
  (3)  
   
  j=1 (h)  
   
  Hence Vieta’s formulas imply that zj minij |zi | < |zj |  
  m equally spaced points of C(0, 1) but also for any q ≥ 1 with a high probability if |NIR(x)| ≤ 1/dν for any large constant ν under the model of random roots of p(x) and for random choice of x on C(0, 1). Under these conditions paper [29] certiﬁes exclusion at a low cost, but not so if a computed√value v = |NIR(x)| exceeds 1, say. Could we certify σ-soft inclusion for σ < 2 in this case? Not really, bound (10) would only imply that rd ≤ d/v ≤ d, thus certifying d-soft inclusion. Now root-squaring comes to rescue. We apply the same e/i test to the polynomial ph (x) for a suﬃciently large integer h of order log(log(d)). If v = |NIRph (x)| is small, we can still certify exclusion for the polynomial ph (x), but then also for p(x) because #(D) is the same for both ph (x) and p(x). Unless the value v is small, paper [29] proves that #(D(0, σ)) > 0 for σ = h (d/v)1/2 , and then σ < 1.2 for suﬃciently large integers h of order log(d).  
   
  114  
   
  S. Go et al.  
   
  The paper [29] extends these observations to devise root-ﬁnders running in expected Boolean time which is optimal, up to poly-logarithmic factors. With probability 1 a random x is non-zero, and we avoid troubles with the computation of NIRph (0) at root-squaring.5 In sum, our generalization of DLG iterations together with some additional recipes enable fast approximation of extremal root radii of a black box polynomial; this is immediately extended to devising e/i tests, which are a basic step of nearly optimal subdivision root-ﬁnders of [29]. 2.5  
   
  Recovery of Complex Roots  
   
  Given rd2 and r12 , we can readily compute the radii rd and r1 by computing the 2h th roots of these quantities. In addition, we can recover zj from yj := h  
   
  (h)  
   
  h  
   
  1/2h  
   
  1/2h  
   
  zj = zj2 as follows: check whether p(yj ) = 0 for each of 2h candidates yj and weed out up to 2h − 1 “false” candidates. 2h tests are expensive if 2h is large, but by extending the descending process of [23] we can manage with only 2h tests by recursively applying the following recipe for i = h − 1, . . . , 1, 0: given a (i+1) (i+1) 1/2 of pi+1 (x), select one of the two candidates ±(zj ) for being a zero zj zero of pi (x); then decrease i by 1 and repeat until i vanishes.  
   
  3  
   
  h  
   
  Our Root-Squaring Algorithm  
   
  3.1  
   
  Implementation Details  
   
  In this section we present our algorithm for computing NIRph (x). There are two main stages, in which the computations ﬁrst travel down and then back up the rational root tree. The downward traversal (Fig. 2a) splits the evaluation of NIRph (x) into 2h evaluations of NIRp (x) and the upward traversal (Fig. 2b) combines the values according to the recursive formula (7). We use Polar Representation of Evaluation Points. Polar Representation of Evaluation Points. Evaluating NIRph (x) at x = x0 , ﬁrst approximate complex number x0 in polar coordinate (γ, θ) such that   x0 1 s ln γ = |x0 |, θ = ≈ t 2πi |x0 | for some nonnegative integers s and t, t = 0 and x0 ≈ γ exp(2πiθ).  
   
  5  
   
  We can approximate NIRph (0) as limx→0 NIRph (x) for x = |x| exp(φi), |x| converging to 0, and a random value φ in the range [0, 2π), but this is more costly than just computing NIR(x) for x = 0.  
   
  Root-Squaring for Root-Finding  
   
  115  
   
  Fast compute the square roots of an exponential with fractional exponents:     a exp 2πi 2b if a mod b ≡ 0, a = exp 2πi (12) b 1 if a mod b ≡ 0. Eﬃciently perform negation operation as follows:    exp 2πi 2a+b if a mod b ≡ 0, a 2b = − exp 2πi b −1 if a mod b ≡ 0.  
   
  (13)  
   
  Recursively apply this strategy to quickly generate the 2h nodes at the hth level of the tree, which are the values NIRpk (x) for   h s x = γ 1/2 exp 2πi h , = 0, ..., 2h − 1, t2 being 2h equally spaced points on the circle C(0, γ 1/2 ). Algorithm 1 computes the recursive angle splitting, and Algorithm 2 shows how the points of evaluation are recovered from the fractions. h  
   
  Remark 1. In our implementation, we choose t to be a power of 2, so that t = 2 for some positive integer . Then NIRp (x) is evaluated at the points x of the form  k sh . This enables us to control the precision of approximation γ 1/2 exp 2πi 2+k and to apply fast divisions by 2. Combining Evaluations. A key ingredient in the upward traversal through the rational root tree portion of our algorithm is our combination of the evaluations of NIRpk at these nodes, as in Eq. 7; we perform recursion by applying dynamic programming. Algorithm 3 speciﬁes recursive recombination of the NIR evaluations via dynamic programming. k k k The algorithm ﬁrst computes NIRp (x 2h ) = p (x 2h )/p(x 2h ), k = 0, ..., 2h − 1,  (root[j]) for the base layer of the recursion Eq. 7, in the line “NIR[0][j] := pp(root[j]) ”. Then it recursively combines the computed values via dynamic programming until it ﬁnally computes NIRp(h) (x), as stated in line “NIR[i + 1][j]:= NIR[i][2j]−NIR[i][2j+1] ”; the desired output NIRph (x) is returned in the line 2 root[2j] “NIR[h][0]”. Remark 2. Roots is called at every level of the recombination process in this presentation of the algorithm, but we can save memory by modifying Algorithm 2 to store all nodes in a single array in one call that generates the root tree.  
   
  116  
   
  S. Go et al.  
   
  Algorithm 1. Circle_Roots_Rational_Form(s, t, k) Require: s and t that represent the angle of a complex number and number k of recursions to be performed   Ensure: a list of pairs representing the fractional part of all kth roots of exp 2πi st if s mod t ≡ 0 then a, b := 1, 1 else a, b := s, 2t end if if a mod b ≡ 0 then c, d := 1, 2 else c, d := 2r + s, 2s end if if k == 1 then return [(a, b),(c, d)] else if k != 0 then left := Circle_Roots_Rational_Form(a, b, k − 1) right := Circle_Roots_Rational_Form(c, d, k − 1) return left ∪ right else return [(s, t)] end if  
   
  Algorithm 2. Roots(γ, s, t, k) Require: γ ≥ 0, integers s, t, and k, k ≥ 0 k Ensure: list of 2k equally spaced points on the circle C(0, γ 1/2 ) root_tree := Circle_Roots_Rational_Form(s, t, k)   circ_root := [exp 2πi ab for (a, b) in root_tree] k  
   
  roots := [γ 1/2 ·root for root in circ_root] return roots  
   
  3.2  
   
  Analysis  
   
  Correctness Lemma 1. If p(0) = 0, then limx→0 DLG(p, p , h, x) is well-deﬁned. Proof. Induction on Eq. 6 yields that ph (0) = 0 if p(0) = 0, and so it suﬃces to consider the behavior of the numerator in Eq. 6. √ L’Hopital’s rule implies the lemma where h = 1 or where x divides the √ √ √ p ( x ) numerator of phh (√x ) even where h = 1. Otherwise, ph ( x ) = c0 + c1 x + ... + √ ck ( x )k for some ci with c0 = 0, but then  
   
  Root-Squaring for Root-Finding  
   
  117  
   
  Algorithm 3. DLG_Rational_Form(p, p , γ, s, t, k) Require: a polynomial p(x), the derivative p (x) of p(x), a positive integer k, γ ≥ 0, two integers s and t Ensure: NIRpk (x) evaluated at x = γ exp(2πi st ) root := Roots(γ, s, t, k) for j = 0, ..., 2k − 1 do  (root[j]) NIR[0][j] := pp(root[j]) end for for i = 0, ..., k − 1 do for j = 0, ..., 2k−i − 1 do NIR[i + 1][j]:= NIR[i][2j]−NIR[i][2j+1] 2 root[2j] end for root := Roots(γ, s, t, k − 1 − i) end for return NIR[k][0]  
   
  Algorithm 4. DLG(p, p , h, x, ) Require: a polynomial p, its derivative p , a positive integer h, γ ≥ 0, a point of evaluation x ∈ C, and a positive integer  deﬁning a desired binary precision Ensure: NIRph (x) up to precision  1 ln(x) θ := 2πi  t := 2 s := θ · t γ := |x| return DLG_Rational_Form(p, p , γ, s, t, h)  
   
  Algorithm 5. DLG_Root_Radius(p, p , prev , prev , h, ,  ) Require: polynomials p and prev , their derivatives p and prev , number of squarings h, an integer  for determining the radius of the circle on which we choose evaluation points, and an integer that determines the binary precision  for the angle of the point Ensure: bounds r˜d and r˜1 on the extremal root radii of p with r˜d ≥ rd and r˜1 ≤ r1 Choose a point x on the unit circle C(0, 1) at random under the uniform probability distribution. d := deg(p)  1/2h   r˜d := d/ DLG(p, p , h, x · 2− ,  )  1/2h  r˜1 := DLG(prev , prev , h, x · 2− ,  ) /d return r˜d , r˜1  
   
  √   √ √  ph+1 ( x ) 1 ph ( x ) ph (− x ) √ √ √ = √ − ph+1 ( x ) 2 x ph ( x ) ph (− x ) √ √ √ √ 1 b0 c0 + x · N1 ( x ) − b0 c0 − x · N2 ( x ) √ √ = √ 2 x p ( x )ph (− x ) √ √h 1 N1 ( x ) − N 2 ( x ) √ √ = 2 ph ( x )ph (− x )  
   
  118  
   
  S. Go et al.  
   
  Fig. 2. traversal of the rational root tree  
   
  for some polynomials N1 and N2 with b0 = ph (0). Therefore, once again, the limit at zero is well-deﬁned. Lemma a complex number x with a rational angle st , i.e., x =  2.s For |x| exp 2πi t for some integers s and t, Algorithm 1 correctly computes the roots in Eq. 7. Proof. Equations 12 and 13 give the base case, and the theorem follows by induction. Theorem 1. If p(0) = 0, then Algorithm 5 computes the bounds given by Eq. 11 with probability 1 under both random root and random coeﬃcient models. Proof. Apply Lemma 1 and recall that p(x) has only ﬁnitely many d zeros. Complexity Theorem 2. One can compute NIRph (x) at a single point x = 0 at the cost of computing all the 2h th roots of x, evaluation of NIR(x) at these roots, 2h − 1 subtractions, and 2h − 1 divisions by these roots, and as many divisions by 2. Proof. The computational tree for Algorithm 3 is a binary tree with 2h+1 − 1 nodes. The tree has 2h leaves corresponding to the base case for the recursive computation, which consists of one evaluation of NIRp ; the recombination of the individual computations via Algorithm 3 requires 2h − 1 subtractions and 2h − 1 divisions to compute the top node shown in Fig. 2b.  
   
  Root-Squaring for Root-Finding  
   
  4  
   
  119  
   
  Experimental Results  
   
  4.1  
   
  Setup  
   
  In this section we present the results of our numerical experiments for Algorithm 5, which we implemented by applying the DLG root-squaring to Newton’s Inverse Ratios. The algorithm estimated the minimal root radius of standard test polynomials (from the MPSolve software [3,4], which is user’s choice polynomial root-ﬁnder). We compute NIR(x) = p (x)/p(x) for p(x) given as a function and compute p (x) with a built-in routine (mpmath.diff) using the [default] option for numerical diﬀerentiation. We use the formula |˜ rd − rd | Errrd = |rd | to measure the accuracy of the estimates r˜d by the relative error Errrd in comparison to the extremal roots obtained by MPSolve. Here rd and r˜d denote the root radii output by MPSolve and in our estimate, respectively, for the same set of polynomials. All estimates r˜d were computed using Python 3.9.6 on MacOS 12.5 with Apple M2 chip (8-core CPU) and 16 GB memory. We used the mpmath python package to control the arithmetic precision. We evaluated p(x) by using the mpmath.polyval command in the case of dense representation and combinations of mpmath arithmetic commands (power, fmul, and fadd) in the case of sparse representation. We computed with 200 decimals, which is equivalent to the 668-bit binary precision. The points of evaluation for NIRph were chosen randomly from the circle C(0, 2−b ), for b = 634. These points are close to the origin but still signiﬁcant enough to avoid zeroing out during the computations.6 The most important application of our work is in the nearly optimal polynomial root-ﬁnders of [29], where we need to apply root-squaring iterations to NIR(x) for random x on a ﬁxed circle, but we tested our root-squaring in the even more challenging and more diﬃcult case where x = 0. 4.2  
   
  Our Findings  
   
  Overall the test results indicate that our root radii approximation is quite accurate where p(x) has no roots extremely close to zero, and we observed this for many polynomial families already for relatively small h = log log(d) + ν, ν = 0, 1, 2, involving evaluation of NIRp at order of log(d) points x. In Fig. 3 we display a small portion of our results to show their overarching trend for h = log log d , . . . , log log d + 2. The ﬁrst row are Errrd of the Chebyshev, Curz, and Wilkinson polynomials of varying degrees, the second row shows overall runtime of our computations. 6  
   
  The code used for these tests is available in the ﬁles DLG_alg.py and benchmark.py in the repository https://github.com/PedroJuanSoto/Root-SquaringFor-Root-Finding/.  
   
  120  
   
  S. Go et al.  
   
  Fig. 3. Accuracy of the bounds on rd computed using NIRph for various polynomial families and h = O(log log d)  
   
  The Appendix covers tests for almost all polynomials of the MPSolve test suite speciﬁed in https://numpi.dm.unipi.it/mpsolve-2.2/mpsolve.pdf. The relative errors for the minimal root radius estimates r˜d are less than 1 for roots lying away from the origin by more than 10−20 . That is, the diﬀerence between the minimal root radius bound we compute and rd tends to be less than |zd |, i.e., r˜d − rd ≤ rd . In view of Eq. 11, we obtain the crude heuristic bound rd ≤ r˜d ≤ 2rd if rd > 10−20 . The relative errors tend to decrease as degree of the polynomial p(x) grow, which may seem to be counter-intuitive at ﬁrst glance. However, this can occur where we perform extra root-squaring iterations for p(x) of higher degree as the step function log log d increases with d. E.g., for d = 160, log log d = 3, whereas for d = 320, log log d = 4. (Recall that the estimates tend to get sharper as h grows.) Some notable exceptions to this performance include the known worst case input nroots and nrooti of the form p(x) = xd − 1 and p(x) = xd − i, respec tively (see Sect. 2.3). The ratio of pp(0)  (0) is inﬁnite, and so our estimates for the minimal root radius tend to be much larger than the actual root radius. Likewise, the algorithm outputs a lower estimate close to 0 for r1 . In the next subsection, however, we greatly improve these estimates by applying an alternative estimator for extremal root radii (See Table 1). The runtime of the computations reﬂects the exponential growth of the number of evaluations, which is order of 2h for h iterations as the degree of the polynomial p(x) increases.  
   
  Root-Squaring for Root-Finding  
   
  4.3  
   
  121  
   
  Alternative Bounds on Extremal Root Radii  
   
  Suppose p(x) is monic. Then the factorization in Eq. (1) implies that |p(0)| = d 1/d ≤ r1 , which provides simple estimates for r1 i=1 |xj |, and so rd ≤ |p(0)| and rd . If p(x) is not monic, we can obtain the leading coeﬃcient by computing pd = limR→∞ p(R)/Rd and then scale p(x) by this number. Once we obtain r˜1 and r˜d by running Algorithm 5, we reﬁne these estimates by using the formulas 1  
   
  r˜1 = max{˜ r1 , |p(0)/pd | d },  
   
  1  
   
  r˜d = min{˜ rd , |p(0)/pd | d }.  
   
  (14)  
   
  In particular, this strategy is eﬀective for the worst case input xd − v d , v = 0, with r1 = rd = |v|. Whereas the NIR-based estimates are trivial: r˜d = ∞ and r˜1 = 0, the reﬁnement outputs the exact value of the extremal root radii at a low cost of two evaluations of NIR and performing few additional arithmetic operations. Table 1 shows the resulting improvement of our estimates for rd . Table 1. Examples of improvements gained by using Eq. 14 Polynomial Family d  
   
  5  
   
  rd  
   
  Errrd Before  
   
  After  
   
  easy  
   
  100 0.949 0.718 400 0.983 0.416 1600 0.995 0.526  
   
  0.028 0.00351 4.33e-6  
   
  exp  
   
  100 200 400  
   
  28.9 1.31e+6 56.8 7.27e+5 113.0 1.03  
   
  0.315 0.318 0.32  
   
  nrooti  
   
  100 400 1600 6400  
   
  1.0 1.0 1.0 1.0  
   
  1.7e+746 2.88e+713 9.19e+2942 9.48e+11860  
   
  2.75e-14 9.73e-14 6.9e-13 2.86e-12  
   
  nroots  
   
  100 400 1600 6400  
   
  1.0 1.0 1.0 1.0  
   
  1.7e+746 2.88e+713 9.19e+2942 9.48e+11860  
   
  1.81e-14 1.18e-13 1.01e-12 2.85e-12  
   
  Conclusion  
   
  The DLG classical root-squaring iterations are practically useless because of severe problems of numerical stability, but we avoid these problems by applying the iterations to Newton’s Inverse Ratio of a black box polynomial. In this way, we yield additional acceleration in the important case where an input polynomial can be evaluated fast. Furthermore, this enables fast and numerically safe shifts  
   
  122  
   
  S. Go et al.  
   
  and scaling of the variable x, while in the known subdivision root-ﬁnders those operations are most expensive and are prone to numerical stability problems. In our extensive tests our algorithm runs fast and closely approximates the extremal (that is, the smallest and the largest) root radii for a very large class of input polynomials. This implies valuable support for the implementation of soft e/i tests, which are the basis of nearly optimal subdivision root-ﬁnders of [29].  
   
  A  
   
  Additional Tables  
   
  In this section, we present more detailed information about the results of our numerical tests of Algorithm 5 with settings described in Sect. 4, with 200-decimal (668-bit) precision and the points of evaluation chosen randomly from the circle C(0, 2−634 ). We estimate the minimal radius rd (computed via MPSolve)7 and relative error Errrd as well as the number h = log log d of iterations used and the runtime of both our implementation and of MPSolve. These polynomials cover a large portion of the unisolve test suite of MPSolve software package. The descriptions of the polynomials can be found in the MPSolve documentation.8 Our implementation is done entirely in Python, whereas the MPSolve package is written in C. Even with accounting for the extra overhead due to using Python, our runtimes are often competitive, in that our computations ﬁnish at the same time or earlier. Furthermore, as the polynomial degrees increase, the runtime of MPSolve starts to exceed our runtime dramatically, and this occurs for polynomials of degrees as low as 160. That eﬀect is particularly well demonstrated in the results for the Kir1, Mig1, and Partition families. Moreover, the rough heuristic expectation that Errrd < 1 if rd > 10−20 in Sect. 4.2 is well supported by these ﬁgures.  
   
  7 8  
   
  Polynomial Family  
   
  d  
   
  h rd  
   
  Errrd Our Runtime  
   
  MPSolve Runtime  
   
  Chebyshev  
   
  20 40 80 160 320  
   
  3 3 3 3 4  
   
  0.333 0.454 0.586 0.729 0.373  
   
  0.006 0.010 0.017 0.033 0.148  
   
  0.003 0.006 0.016 0.089 0.301  
   
  Chrm_a  
   
  21 3 1.0 85 3 1.0 341 4 0.884  
   
  0.343 0.608 0.498  
   
  0.006 0.019 0.160  
   
  0.003 0.019 0.494  
   
  0.0785 0.0393 0.0196 0.00982 0.00491  
   
  MPSolve has been devised for approximation of all d zeros of p(x), but we apply it to our narrow task of estimation of extremal root-radii. https://numpi.dm.unipi.it/mpsolve-2.2/mpsolve.pdf.  
   
  Root-Squaring for Root-Finding Polynomial Family  
   
  d  
   
  h rd  
   
  Errrd Our Runtime  
   
  MPSolve Runtime  
   
  Chrm_c  
   
  11 43 683  
   
  2 1.27 3 1.02 4 0.519  
   
  0.35 0.817 0.522  
   
  0.002 0.010 0.317  
   
  0.003 0.008 4.921  
   
  Chrm_d  
   
  20 22 84 340 342  
   
  3 3 3 4 4  
   
  1.3 1.0 1.1 0.741 0.897  
   
  0.257 0.421 0.587 0.386 0.414  
   
  0.006 0.006 0.019 0.157 0.161  
   
  0.005 0.009 0.024 0.658 1.258  
   
  curz  
   
  20 40 80 160  
   
  3 3 3 3  
   
  0.452 0.379 0.318 0.271  
   
  0.34 0.71 0.557 0.83  
   
  0.006 0.010 0.018 0.035  
   
  0.003 0.007 0.013 0.050  
   
  easy  
   
  100 200 400 800 1600 3200  
   
  3 3 4 4 4 4  
   
  0.949 0.971 0.983 0.991 0.995 0.997  
   
  0.718 0.832 0.416 0.468 0.526 0.59  
   
  0.644 0.640 1.461 1.459 1.456 1.460  
   
  0.005 0.008 0.015 0.055 0.176 2.857  
   
  geom1  
   
  10 15 20 40  
   
  2 2 3 3  
   
  1.0 1.0 1.0 1.0  
   
  0.778 0.968 0.454 0.586  
   
  0.002 0.003 0.006 0.011  
   
  0.002 0.003 0.003 0.004  
   
  geom2  
   
  10 15  
   
  2 1.0e-18 2 1.0e-28  
   
  0.778 0.968  
   
  0.002 0.003  
   
  0.003 0.003  
   
  geom3  
   
  10 20  
   
  2 9.54e-7 0.777 3 9.09e-13 0.454  
   
  0.002 0.006  
   
  0.003 0.003  
   
  geom4  
   
  10 20 40 80  
   
  2 3 3 3  
   
  4.0 4.0 4.0 4.0  
   
  0.777 0.454 0.586 0.729  
   
  0.002 0.006 0.010 0.018  
   
  0.003 0.003 0.003 0.006  
   
  hermite  
   
  20 40 80 160 320  
   
  3 3 3 3 4  
   
  0.245 0.175 0.124 0.0877 0.062  
   
  0.333 0.454 0.586 0.729 0.373  
   
  0.006 0.010 0.017 0.033 0.145  
   
  0.003 0.004 0.010 0.039 0.194  
   
  123  
   
  124  
   
  S. Go et al. Polynomial Family kam1 kam2 kam3 kats kir1  
   
  kir1_mod  
   
  laguerre  
   
  legendre  
   
  lsr  
   
  mig1  
   
  d  
   
  h rd  
   
  Errrd  
   
  Our Runtime 7 2 3.0e-12 0.368 0.004 0.004 7 2 3.0e-40 0.368 9 2 1.73e-6 0.225 0.005 0.005 9 2 1.73e-20 0.225 9 2 1.73e-6 0.225 0.005 0.005 9 2 1.73e-20 0.225 256 3 0.137 0.886 0.053 8 2 0.5 0.000244 0.005 4.43e-5 0.010 44 3 0.5 2.32e-5 0.100 84 3 0.5 1.19e-5 0.201 164 3 0.5 44 3 0.5 0.000983 0.011 0.00364 0.100 84 3 0.498 0.00735 0.200 164 3 0.496 20 3 0.0705 0.454 0.006 0.586 0.010 40 3 0.0357 0.729 0.018 80 3 0.018 0.034 160 3 0.00901 0.886 0.151 320 4 0.00451 0.434 20 3 0.0765 0.333 0.006 0.454 0.010 40 3 0.0388 0.586 0.017 80 3 0.0195 0.032 160 3 0.00979 0.729 0.373 0.142 320 4 0.0049 24 3 1.0e-20 0.251 0.007 0.019 52 3 1.0e-20 0.639 0.157 224 3 1.0e-20 0.654 0.377 0.118 500 4 0.0001 0.062 500 4 3.33e-5 0.475 0.503 0.054 500 4 0.0916 20 3 0.01 0.268 0.011 0.127 50 3 0.00999 0.0622 0.55 0.010 100 3 0.01 0.158 0.126 100 3 0.01 0.69 0.010 200 3 0.01 0.262 0.129 200 3 0.01 0.377 0.021 500 4 0.01 0.19 0.298 500 4 0.01  
   
  MPSolve Runtime 0.003 0.002 0.003 0.003 0.007 0.003 0.483 0.008 0.024 7.542 100.163 0.009 0.071 17.281 0.004 0.006 0.017 0.066 0.409 0.003 0.01 0.013 0.053 0.296 0.007 0.003 0.202 0.886 0.168 0.118 0.003 0.239 0.004 5.398 0.184 36.607 0.828 849.063  
   
  Root-Squaring for Root-Finding Polynomial Family  
   
  d  
   
  h rd  
   
  Errrd  
   
  Our Runtime  
   
  MPSolve Runtime  
   
  mult  
   
  15 20 68  
   
  2 0.869 3 0.01 3 0.25  
   
  0.447 0.162 0.504  
   
  0.016 0.006 0.150  
   
  0.006 0.009 0.052  
   
  partition  
   
  199 399 799 1599 3199 6399 12799 25599  
   
  3 4 4 4 4 4 4 4  
   
  0.0182 0.00914 0.00458 0.00229 0.00115 0.000573 0.000287 0.000143  
   
  0.938 0.454 0.518 0.586 0.656 0.729 0.806 0.886  
   
  0.043 0.185 0.365 0.728 1.485 2.940 5.900 11.66  
   
  0.039 0.099 0.381 1.743 7.994 45.759 305.707 1967.376  
   
  sendra  
   
  20 40 80 160 320  
   
  3 3 3 3 4  
   
  0.9 0.95 0.975 0.987 0.994  
   
  0.388 0.329 0.302 0.289 0.19  
   
  0.006 0.010 0.018 0.034 0.157  
   
  0.005 0.011 0.031 0.141 0.939  
   
  sparse  
   
  100 400 800 6400  
   
  3 4 4 4  
   
  0.968 0.969 0.969 0.969  
   
  0.836 0.501 0.568 0.785  
   
  0.009 0.044 0.062 0.089  
   
  0.003 0.013 0.034 2.034  
   
  spiral  
   
  10 15 20 25 30  
   
  2 2 3 3 3  
   
  1.0 1.0 1.0 1.0 1.0  
   
  3.30e-7 2.24e-7 2.65e-7 2.14e-7 1.79e-7  
   
  0.002 0.003 0.006 0.007 0.009  
   
  0.006 0.009 0.016 0.028 0.053  
   
  toep  
   
  128 128  
   
  3 1.31 3 0.4  
   
  0.834 0.708  
   
  0.030 0.032  
   
  0.023 0.033  
   
  wilk  
   
  20 40 80 160 320  
   
  3 3 3 3 4  
   
  1.0 1.0 1.0 1.0 1.0  
   
  0.453 0.585 0.728 0.885 0.434  
   
  0.006 0.010 0.018 0.034 0.150  
   
  0.005 0.008 0.021 0.118 0.673  
   
  wilk_mod  
   
  30  
   
  3 1.0  
   
  0.529  
   
  0.008  
   
  0.005  
   
  125  
   
  126  
   
  S. Go et al.  
   
  References 1. Ahlfors, L.: Complex Analysis. McGraw-Hill series in Mathematics, McGraw-Hill, New York (2000) 2. Bialas, S., Górecki, H.: Generalization of Vieta’s formulae to the fractional polynomials, and generalizations the method of Gräﬀe-Lobachevsky. Bull. Pol. Acad. Sci.-Tech. Sci. 58, 624–629 (2010) 3. Bini, D.A.: Fiorentino, Giuseppe, design, analysis, and implementation of a multiprecision polynomial rootﬁnder. Numer. Algorithms 23(2–3), 127–173 (2000) 4. Bini, D.A., Robol, L.: Solving secular and polynomial equations: a multiprecision algorithm. J. Comput. Appl. Math. 272, 276–292 (2014) 5. Becker, R., Sagraloﬀ, M., Sharma, V., Xu, J., Yap, C.: Complexity analysis of root clustering for a complex polynomial. In: roceedings of the ACM on International Symposium on Symbolic and Algebraic Computation (ISSAC 2016), pp. 71–78. ACM Press, New York (2016) 6. Becker, R., Sagraloﬀ, M., Sharma, V., Yap, C.: A near-optimal subdivision algorithm for complex root isolation based on the Pellet test and Newton iteration. J. Symb. Comput. 86, 51–96 (2018) 7. Grau, A.A.: On the reduction of number range in the use of the Graeﬀe process. J. Assoc. Comput. Mach. 10(4), 538–544 (1963) 8. Grau, A.A.: Algorithm 256: modiﬁed Graeﬀe method [C2]. Commun. ACM 8(6), 379–380 (1965) 9. Grenet, B., van der Hoeven, J., Lecerf, G.: Deterministic root-ﬁnding over ﬁnite ﬁelds using Graeﬀe transforms. Appl. Algebra Eng. Commun. Comput. 27, 237– 257 (2015) 10. Householder, A.S.: Dandelin, Lobachevskii, or Graeﬀe? Am. Math. Monthly 66, 464–466 (1959). https://doi.org/10.2307/2310626 11. Henrici, P.: Applied and Computational Complex Analysis, vol. 1: Power Series, Integration, Conformal Mapping, Location of Zeros. Wiley, NY (1974) 12. Hoeven, van der, J.V.: Eﬃcient root counting for analytic functions on a disk, hal-00583139 (2011) 13. van Der Hoeven, J., Monagan, M.: Computing one billion roots using the tangent Graeﬀe method. ACM Commun. Comput. Algebra 54(3), 65–85 (2020). https:// doi.org/10.1145/3457341.3457342 14. Imbach, R., Pan, V.Y.: New progress in univariate polynomial root-ﬁnding. In: Proceedings of ISSAC 2020, pp. 249–256 (2020) 15. Imbach, R., Pan, V.Y.: Accelerated subdivision for clustering roots of polynomials given by evaluation oracles. In: Boulier, F., England, M., Sadykov, T.M., Vorozhtsov, E.V. (eds.) Computer Algebra in Scientiﬁc Computing. CASC 2022. LNCS, vol. 13366, pp. 143–164. Springer, Cham (2022). arXiv:2206.08622, https:// doi.org/10.1007/978-3-031-14788-3_9 16. Imbach, R., Pan, V.Y., Yap, C.: Implementation of a near-optimal complex root clustering algorithm. In: Davenport, J.H., Kauers, M., Labahn, G., Urban, J. (eds.) ICMS 2018. LNCS, vol. 10931, pp. 235–244. Springer, Cham (2018). https://doi. org/10.1007/978-3-319-96418-8_28 17. Merzbach, U.C., Boyer, C.B.: A History of Mathematics, ﬁfth edn. Wiley, New York (2011) 18. McNamee, J.M.: Numerical Methods for Roots of Polynomials, Part I, XIX+354 pages. Elsevier (2007). ISBN: 044452729X; ISBN13: 9780444527295  
   
  Root-Squaring for Root-Finding  
   
  127  
   
  19. McNamee, J.M., Pan, V.Y.: Numerical Methods for Roots of Polynomials, Part 2 (XXII + 718 pages). Elsevier (2013) 20. Malajovich, G., Zubelli, J.P.: Tangent Graeﬀe iteration. Numer. Math. 89, 749–782 (1999) 21. Malajovich, G., Zubelli, J.P.: On the geometry of Graeﬀe iteration. J. Complex. 17(3), 541–573 (2001). https://doi.org/10.1006/jcom.2001.0585 22. Pan, V.Y.: Optimal (up to polylog factors) sequential and parallel algorithms for approximating complex polynomial zeros. In: Proceedings of the 27th Annual ACM Symposium on Theory of Computing (STOC’95), pp. 741–750. ACM Press, New York (1995) 23. Pan, V.Y.: Optimal and nearly optimal algorithms for approximating polynomial zeros. Comput. Math. (with Applications) 31(12), 97–138 (1996) 24. Pan, V.Y.: Solving a polynomial equation: some history and recent progress. SIAM Rev. 39(2), 187–220 (1997) 25. Pan, V.Y.: Approximation of complex polynomial zeros: modiﬁed quadtree (Weyl’s) construction and improved Newton’s iteration. J. Complex. 16(1), 213– 264 (2000) 26. Pan, V.Y.: Univariate polynomials: nearly optimal algorithms for factorization and rootﬁnding. J. Symb. Comput. 33(5), 701–733 (2002). Proc. version in Proc. ISSAC’01, 253–267, ACM Press, New York (2001) 27. Pan, V.Y.: Old and new nearly optimal polynomial root-ﬁnders. In: England, M., Koepf, W., Sadykov, T.M., Seiler, W.M., Vorozhtsov, E.V. (eds.) CASC 2019. LNCS, vol. 11661, pp. 393–411. Springer, Cham (2019). https://doi.org/10.1007/ 978-3-030-26831-2_26 28. Pan, V.Y.: Acceleration of subdivision root-ﬁnding for sparse polynomials. In: Boulier, F., England, M., Sadykov, T.M., Vorozhtsov, E.V. (eds.) CASC 2020. LNCS, vol. 12291, pp. 461–477. Springer, Cham (2020). https://doi.org/10.1007/ 978-3-030-60026-6_27 29. Pan, V.Y.: Good news for polynomial root-ﬁnding and matrix eigen-solving. arXiv 1805.12042, last revised in 2023 30. Pan, V.Y., Go, S., Luan, Q., Zhao, L.: Fast approximation of polynomial zeros and matrix eigenvalues. In: Proceedings of the 13th International Symposium on Algorithms and Complexity (CIAC 2023), Mavronicolas, M. (ed.), LNCS, vol. 13898, pp. 336–352. Springer Nature, Switzerland, AG (2023) 31. Renegar, J.: On the worst-case arithmetic complexity of approximating zeros of polynomials. J. Complex. 3(2), 90–113 (1987) 32. Weyl, H.: Randbemerkungen zu Hauptproblemen der Mathematik. II. Fundamentalsatz der Algebra und Grundlagen der Mathematik. Mathematische Zeitschrift 20, 131–151 (1924)  
   
  Symbolic-Numerical Algorithm for Solving the Problem of Heavy Ion Collisions in an Optical Model with a Complex Potential A. A. Gusev1,2(B) , O. Chuluunbaatar1,3 , V.L. Derbov4 , R.G. Nazmitdinov1,2 , S.I. Vinitsky1,5 , P.W. Wen6 , C.J. Lin6,7 , H.M. Jia6 , and L.L. Hai8 1  
   
  3  
   
  7  
   
  Joint Institute for Nuclear Research, 141980 Dubna, Russia [email protected]  2 Dubna State University, 141982 Dubna, Russia Institute of Mathematics and Digital Technology, Mongolian Academy of Sciences, 13330 Ulaanbaatar, Mongolia 4 Chernyshevsky Saratov National Research State University, Saratov, Russia 5 Peoples’ Friendship University of Russia (RUDN University), 117198 Moscow, Russia 6 China Institute of Atomic Energy, 102413 Beijing, China College of Physics and Technology & Guangxi Key Laboratory of Nuclear Physics and Technology, Guangxi Normal University, 541004 Guilin, China 8 Ho Chi Minh City University of Education, Ho Chi Minh City, Vietnam  
   
  Abstract. We present an original algorithm in the MAPLE system for solving the scattering problem in single-channel approximation of the coupled-channel method of the optical model (OM) described by a second-order ordinary diﬀerential equation (ODE) with a complexvalued potential and regular boundary conditions. The complex-valued potential consists of the known real part, which is a sum of the nuclear potential, the Coulomb potential, and the centrifugal potential, and the imaginary part, which is a product of the unknown coupling constant g(E), depending on the collision energy E of a pair of ions, and the derivative of the real part of the known nuclear potential with respect to the ODE independent variable. The presented algorithm implements the solution of the inverse problem, i.e., calculates the unknown coupling constant g(E) and scattering matrix S(g(E), E) from condition |S(g(E), E)|2 = 1 − |T (E)|2 by means of the secant method. The required amplitudes of transmission T (E) and reﬂection R(E) subject also to the condition |R(E)|2 = 1 − |T (E)|2 of the model with incoming wave boundary conditions (IWBCs) are previously calculated by the standard MAPLE implemented KANTBP 4M program. The algorithm provides a one-to-one correspondence between the OM with a complex-valued potential and the model of IWBCs with a realvalued potential. c The Author(s), under exclusive license to Springer Nature Switzerland AG 2023  F. Boulier et al. (Eds.): CASC 2023, LNCS 14139, pp. 128–140, 2023. https://doi.org/10.1007/978-3-031-41724-5_7  
   
  Symbolic-Numerical Algorithm for Solving the Heavy Ion Collisions Problem  
   
  129  
   
  The eﬃciency of the proposed approach is shown by solving numerically the scattering problem and calculating the reference fusion cross section for a pair of heavy ions 16 O+144 Sm in the single-channel approximation of the close-coupling method. Keywords: Symbolic-numerical algorithm · Optical model with complex-valued potential · Incoming wave boundary conditions model Heavy ion collision problem  
   
  1  
   
  ·  
   
  Introduction  
   
  In the coupled-channel (CC) method for describing sub-barrier reactions with heavy ions, the scattering problem is solved for a system of second-order ordinary diﬀerential equations (ODEs) with complex-valued optical model (OM) potentials and the ODE solutions subjected to regular boundary conditions (BCs). This approach has started from [1–3] and was continued in [4–6]. The alternative incoming wave boundary condition (IWBC) model uses realvalued potentials, each of them being a sum of a short-range nuclear potential of interaction between two heavy particles, a long-range real Coulomb potential, and a long-range real centrifugal potential [7–13]. In the IWBC model, to formulate correctly the Robin BCs with the correct set of threshold energies in the coupled channel method, it was required to diagonalize the coupling matrix of the eﬀective potentials of coupled channels at the potential minimum point inside the potential barrier [14–16]. Such a formulation of the IWBCs with diagonalization of the potential channel coupling matrix at the minimum point inside the potential barrier was reported in recent papers [17,18] and implemented in the KANTBP 3.0, KANTBP 3.1 programs [19,20]. This circumstance allowed us to return to considering the OM with the complex-valued potential [2]. For simplicity, it is speciﬁed by the real-valued spherical Wood–Saxon nuclear potential and the imaginary part of the surface nuclear potential of the OM given as a product of the unknown coupling constant and derivative of the known nuclear potential with respect to the ODE independent variable, which is suﬃcient for low collision energies [21]. In the OM with a complex-valued potential, one of the main problems is to ﬁnd the coupling constant parameter, which depends on the collision energy of two heavy ions. The problem of including the imaginary part into the nuclear potential is traditionally solved by ﬁtting the coupling constant value to the experimental data on the cross section of the reaction, which depends on the collision energy of the pair of heavy ions. To specify the real part of the nuclear potential, it is suﬃcient to use the well-known tabulated parameters of the Wood–Saxon nuclear potential and its multipole deformation in the collective nuclear model [22], which correspond to the experimental data on the reaction cross sections depending on the collision energy [23]. Thus, to calculate the coupling constants for the imaginary part of the nuclear potential in OMs, it is suﬃcient to construct an algorithm that uses  
   
  130  
   
  A. A. Gusev et al.  
   
  as the initial data the transmission and reﬂection coeﬃcients of the IWBC model previously calculated by the KANTBP 4M program [24] implementing the ﬁnite element method in MAPLE [25]. This paper presents an original algorithm implemented in the MAPLE system for calculating the parameter g(E) > 0, the coupling constant of the imaginary part of the complex-valued potential depending on the collision energy E of a pair of ions, in the OM of the scattering problem described by the second-order ODEs with complex-valued potential using the KANTBP 4M program. In OM, the coupling constant g(E) > 0 is calculated from the condition 1 − |SL (g(E), E)|2 = |TL (E)|2 , where SL (g(E), E) is the scattering matrix depending on g(E) and E, and TL (E) is the transmission amplitude depending only on E of the IWBC model with the real-valued potential. The scattering matrix SL (g(E), E) is determined by solving the ODE subject to regular BCs of a scattering problem for the OM with complex-valued potential with given g(E). The transmission amplitude TL (E) = TLIWBC (E) is extracted from the solution of the ODE subject to IWBC. Thus, the proposed algorithm provides a one-to-one correspondence between the OM with a complex-valued potential and the IWBC model with a real-valued potential announced in the pioneer paper [1]. The eﬃciency of the proposed algorithm is shown by solving the scattering problem and calculating the reference fusion cross section of a pair of heavy ions 16 O+144 Sm in the single-channel approximation of the coupled-channel method with the complex-valued potential. The paper is organized as follows. In Sect. 2, we formulate the OM in the single-channel approximation. Section 3 presents the OM algorithm. Section 4 presents a numerical example, in which the solutions of the scattering problem and the reference cross section for the fusion of a pair of heavy ions 16 O+144 Sm and the coupling constant of the imaginary part of the surface nuclear potential are calculated. In Conclusion, the main results are summarized and further prospects for applying the proposed approach are outlined.  
   
  2  
   
  Optical Model and IWBC Model in the Single-Channel Approximation  
   
  First, we compare the single-channel approximation of the OM [2] and the IWBC model [10,20] without nuclear deformation coupling described by the equation   2  (1) − r + V (g, r) − E Ψ (r) = 0, 2μ  where Ψ (r) = r−1 Lm ΨL (r)YLm (θ, ϕ), YLm (θ, ϕ) is a spherical harmonic [21], and ΨL (r) satisﬁes the radial equation   2 2  d + VL (g, r) − E ΨL (r) = 0. (2) − 2μ dr2  
   
  Symbolic-Numerical Algorithm for Solving the Heavy Ion Collisions Problem  
   
  131  
   
  In the OM and IWBC model, the radial wave function ΨL (r) is subjected to difmin max , rL ] presented ferent BCs in the boundary points of diﬀerent intervals r ∈ [rL in Sect. 3. For the OM in Eq. (2), VL (g, r) is the complex-valued potential given by a sum of four terms: 2 L(L + 1) 2μ r2 dVN (r) ¯ 2 L(L + 1) + VC (r) + = VN (r) − ıg(E) , dr 2μ r2  
   
  VL (g, r) = V (g, r) +  
   
  (3)  
   
  namely, the real-valued nuclear Woods–Saxon potential VN (r) = −  
   
  V0 , 1 + exp((r − R0 )/a)  
   
  (4)  
   
  the imaginary part of the surface nuclear potential including the unknown realvalued coupling constant g(E) depending on collision energy E − ıg(E)  
   
  dVN (r) , dr  
   
  (5)  
   
  the Coulomb potential [26] describing the interaction of the projectile charge ZP with the target charge ZT , uniformly distributed over a ball of radius RC depending on the masses of the projectile AP and the target AT , and parameter R00  1/r, r ≥ RC , ¯ VC (r) = ZP ZT (6) 2 3 − r2 )/(2RC ), r < RC , (3RC 1/3  
   
  1/3  
   
  RC = R0 = R00 (AP + AT ). The last term in Eq. (3) is a rotation centrifugal potential. For solving a scattering problem in the IWBC model in Eq. (2), the complexvalued potential VL (g, r) is replaced to the real-valued potential VL (r) determined by the following:   min  VL (r) = VL g = 0, max r, rL , (7) min depends on the angular momentum L and is determined where the value of rL by the condition  
   
   dVLmin (g = 0, r)  
   
  min min (8) E > VL = VL g = 0, rL ,  
   
  min = 0. dr r=r L  
   
  The value of Lmax is restricted by the limited value of the incident energy E in min min ), where VL (rL ) is the potential minimum, the entrance channel: E = VL (rL L = 0, . . . , Lmax .  
   
  132  
   
  A. A. Gusev et al.  
   
  Fig. 1. OM potential V (x, z) = V (g, r) in the xz-plane (a) and VL (g, r) and its components at g = 1 and L = 0 (b) for a pair of heavy ions 16 O+144 Sm  
   
  Fig. 2. Real and imaginary parts of the potentials VL (g, r) of OM (a) and the realvalued potential VL (r) of IWBC model (b) for a pair of heavy ions 16 O+144 Sm  
   
  In the IWBC model, the nuclear potential VN (r) having a constant value of min min min ) for r ≤ rL , the value of rL is determined by the condition (8). VN (r = rL In Fig. 1 (a), we show the real part V (g, r) of the OM potential in the xz-plane. Figure 1 (b) shows the components of the potential VL (g, r) at L = 0 and g = 1. The real and imaginary parts of the potentials VL (g, r) and VL (r) for 16 O+144 Sm are shown in Fig. 2 (a) for the OM model and in Fig. 2 (b) for the IWBC model, respectively. The parameters of the problem for the 16 O+144 Sm reaction are: AP = 16,  
   
  AT = 144.0, ZP = 8, ZT = 62, μ = AP AT /(AP + AT ); V0 = 105 MeV, R00 = 1.1 fm, A0 = 0.75 fm; 1/3  
   
  1/3  
   
  R0 = R00 (AP + AT )  
   
  3  
   
  in the zeroth approximation.  
   
  The Optical Model Algorithm  
   
  The following algorithm calculates the unknown coupling constant g(E) > 0 for a given value of energy E from the condition 1 − |SL (g(E), E)|2 = |TL (E)|2 .  
   
  Symbolic-Numerical Algorithm for Solving the Heavy Ion Collisions Problem  
   
  133  
   
  The transmission TL (E) amplitude and the reﬂection RL (E) amplitude and the eigenfunction ΨL (r) are calculated in advance by numerically solving the ODE (2) with the real-valued potential VL (r) from (7) subject to IWBCs for a given value of energy E. The scattering matrix SL (g(E), E) and eigenfunction ΨL (r) are calculated by numerically solving the ODE (2) subject to regular BCs of a scattering problem for the OM with complex-valued potential VL (g(E), r) from (3) with given g(E). Algorithm OMCCG. Input E ∈ {E1 , . . . , En } is a grid of real values of collision energies E. Step 1. Finding the parameter g(E) > 0 on the grid E ∈ {E1 , . . . , En } by the secant method with a given tolerance 0 <   1  (10−8 , 10−13 ). Step 1.1. We put g = 0 and calculate G0 = −|TL (Ei )|2 using Algorithm IWBCM. Step 1.2. We choose the initial values of g0 = {0, i = 1, 2; g(Ei−2 ), i = 3, 4, . . . , n}, g1 = {10−4 , i = 1; g(Ei−1 ), i = 2, 3, . . . , n}, and calculate G1 = 1 − |SL (g1 , Ei )|2 − |TL (Ei )|2 , where SL (g1 , Ei ) is computed using the OM algorithm and the value of |TL (Ei )|2 is calculated at Step 1.1. Step 1.3. For k = 1, 2, . . . while |gk − gk−1 | > : we put gk+1 = gk − Gk  
   
  gk − gk−1 , Gk − Gk−1  
   
  and calculate Gk+1 = 1 − |SL (gk+1 , Ei )|2 − |TL (Ei )|2 . Step 1.4. The fusion cross section σfus (E) is calculated using the formula π L L σfus (E) = σfus (E), σfus (E) = 2 (2L + 1)(1 − |SL (g, E)|2 ). (9) k L=0  
   
  L (E) of scattering states at the given Output. Sets g(E), ΨL (r), SL (g, E), and σfus real energy E: on the grid E ∈ {E1 , . . . , En } in the OM.  
   
  End of Algorithm OMCCG Algorithm IWBCM. min max Input r = [rL , rL ] is the interval of independent variable of ODE of the IWBC model; E is the collision energy; VL (r) is the real-valued potential from (7). Solving the scattering problem for Eq. (2) of the IWBC model with the real-valued potential VL (r) from (7) and Robin BC at the boundary min max , rL ], points of the interval r = [rL  
   
  134  
   
  A. A. Gusev et al.  
   
  dΨL (r) = R(r)ΨL (r), dr  
   
  R(r) =  
   
  dΨLas (r) 1 dr ΨLas (r)  
   
  (10)  
   
  which follows from the asymptotic solution [20] 2μ exp(−ıKr) IWBC as min min ), (11) √ ΨL (rL ) = TL (E), K = E − VL (rL 2 K 2μ √ 1 ˆ− + IWBC as max ˆ (kr)RL ΨL (rL ) = √ (HL (kr)−H E. (E)), k = L 2 k ˆ ± (kr) are the normalized outgoing and incoming Coulomb parHere H L tial wave functions, ˆ ± (kr) = [±ıFL (η, kr) + GL (η, kr)] exp(∓ıδ C ) H L L  
   
  (12)  
   
  and FL (η, kr) and GL (η, kr) are the regular and irregular Coulomb partial wave functions, η = kZP ZT e2 /(2E) is the Sommerfeld parameter, C = arg Γ (L + 1 + ıη) is the Coulomb phase shift [27,28]. δL IWBC (E), Calculating ΨL (r), TL (E) ≡ TLIWBC (E) and RL (E) ≡ RL testiﬁed to the following condition: |TL (E)|2 + |RL (E)|2 = 1. Output. ΨL (r) and TL (E), and RL (E) of scattering states at the given real energy E in the IWBC model. End of Algorithm IWBCM Algorithm OM Input. KeyOM = 0 is computing scattering states; KeyOM = 1 is computing metastable states; 0 max r = [rL , rL ] is the interval of the independent variable of ODE (2) of the IWBC model; E is the collision energy; g(E) is the given coupling constant depending on E; VL (g(E), r) is the real-valued potential from (3). If KeyOM = 0 then go to 1 else go to 2 ﬁ. 1. Solving the scattering problem for Eq. (2) with respect to Ψ (r) and SL (g, E) of the OM with the complex-valued potential VL (g, r) (3) for a given value of g(E) calculated at Step 1.3 of OMCCG algorithm and 0 max , rL ]: mixed BCs at the boundary points of interval r ∈ [rL 0 the Neumann BC at r = rL ,  
   
  dΨLas (r)  
   
  0 min = 0, rL ≤ rL , dr r=r0 L  
   
  and the Robin BC at r =  
   
  max rL ,  
   
  dΨL (r) = R(r)ΨL (r), dr  
   
  R(r) =  
   
  dΨLas (r) 1 dr ΨLas (r)  
   
  Symbolic-Numerical Algorithm for Solving the Heavy Ion Collisions Problem  
   
  135  
   
  Fig. 3. Collision energy dependence of the parameter g(E), the fusion probability L = |TL (E)|2 , the reﬂection (scattering) coeﬃcient |RL (E)|2 = |SL (g(E), E)|2 , as Pfus L (E) (in mb) of sub-barrier fusion well as the smooth fusion partial cross section σfus 16 144 reaction for a pair of heavy ions O+ Sm for L = 0 (a) and L = 5 (b)  
   
  which follows from the asymptotic solution [20] ˆ − (kr) − H ˆ + (kr)SL (g, E) H L L √ . k 2. Calculating the eigenfunctions ΨLν (r) and the complex-valued eigenenM of metastable states at a given value g(E) > 0 calculated at ergies EL,ν Step 1.3 of OMCCG algorithm with the outgoing wave at the boundary max [29], point r = rL 2μ 1 ˆ+ as max M OM M , EL,ν ΨLν (rL ) = √ HL (kr)OL (EL,ν ), k = 2 k max ΨLas (rL )=  
   
  OM (E M ) is the amplitude of outgoing wave. where OL L,ν Output. ΨL (r) and SL (g, E) of scattering states at the given real energy E in M of the OM or eigenfunctions ΨLν (r) and complex eigenenergies EL,ν metastable states in the OM. End of Algorithm OM 0 , Remark. Instead of the Neumann BC, one can use also the Robin BC r = rL which follows from the regular asymptotic solution 2μ rL+1 exp(−ıKr) OM as 0 0 ), √ AL (E), K = E − VL (rL ΨL (rL ) = 2 K where AOM L (E) is a normalization factor.  
   
  4  
   
  Benchmark Calculations  
   
  An example of sub-barrier fusion reaction for a pair of heavy ions 16 O+144 Sm is numerically studied using the IWBC model and the OM. To solve the scattering problem and to calculate the metastable states, we use the KANTBP 4M program [24] implementing the ﬁnite element method in MAPLE [25].  
   
  136  
   
  A. A. Gusev et al.  
   
  Fig. 4. Eigenfunctions Ψ0 (r) = ΨL (r) of scattering states of sub-barrier fusion reaction for a pair of heavy ions 16 O+144 Sm at a non resonance energy of E = 61 MeV, L = 0. IWBC (a) in comparison with OM at g = 0 (b) and g = 0.00429 (c)  
   
  Fig. 5. Eigenfunctions Ψ0 (r) = ΨL (r) of the OM scattering states of sub-barrier fusion reaction for a pair of heavy ions 16 O+144 Sm at L = 0 in the vicinity of resonance (the second peak of g(E) in Fig. 3), E = E res ≈ 57.7330 MeV at g = 0.001 (b) and E = E res ≈ 57.7375 MeV at g = 0 (e), in comparison with the eigenfunctions of scattering states at E = E res ± 0.1 MeV (a,c,d,f)  
   
  Figure 3 illustrates the collision energy dependence of the parameter g(E), L = |TL (E)|2 , the reﬂection (scattering) coeﬃcient the fusion probability Pfus 2 2 |RL (E)| = |SL (g(E), E)| , as well as the smooth fusion partial cross section L (E) (in mb) at L = 0 (a) and L = 5 (b). The resonance structure of the couσfus pling constant g(E) is seen, which testiﬁes for the existence of metastable states, manifesting themselves as resonances in the elastic scattering in the interval of energies E ∈ [52, 68] MeV. Figure 4 (a) shows the eigenfunctions of the IWBC scattering states for comparison with OM ones at g = 0 (Fig. 4 (b)) and at g = 0.00429 (Fig. 4 (c)) for a non-resonance energy of E = 61 MeV. At ﬁrst glance, these functions have similar behavior, but the real part of the IWBC function has v = 18 nodes in the interval r ∈ [0, 10] and the transmission coeﬃcient equal to |T0 |2 = 0.411 that corresponds to a partial transmission, whereas the OM function has v = 17 nodes in the interval r ∈ [0, 10] and the transmission coeﬃcient equal to |T0 |2 = 0, i.e., |R0 |2 = 1, which corresponds to a total reﬂection.  
   
  Symbolic-Numerical Algorithm for Solving the Heavy Ion Collisions Problem  
   
  137  
   
  Fig. 6. Eigenfunctions Ψ0 (r) = ΨLν (r) of the three metastable states at L = 0 and ν = 16, 17, 18 with complex energies EL,ν = Eν : E16 = 53.773 − 0.012ı (a), E17 = 57.732 − 0.013ı (b) and E18 = 61.162 − 0.166ı (c) at g = 0.001 in the vicinity of the ﬁrst, second, and third peaks of g(E), in comparison with three metastable states E16 = 53.773 − 10−6 ı (d), E17 = 57.732 − 0.001ı (e) and E18 = 61.163 − 0.155ı (f) at g = 0 for a pair of heavy ions 16 O+144 Sm min max Note that the IWBC function is calculated in the interval r ∈ [rL , rL ] min ] with Robin BCs. Here we continue this function over the interval r ∈ (0, rL using its asymptotic behavior (10). The latter is known because the nuclear min ) in this interval, as shown by horizontal lines in potential VN (r) = VN (rL Fig. 2 (b). However, in all papers exploiting the IWBC model, the behavior of wave functions in this interval is not discussed. This is because of the diﬀerence in the deﬁnition of potentials and BCs in these two models. Indeed, the OM 0 min  rL and the regular Neumann BC potential is prolonged till the vicinity rL 0 min and are used at rL , while in the IWBC model, the potential is cut oﬀ at r = rL the Robin BC is used at this point. To compensate for this principal diﬀerence, the imaginary part of the optical potential is switched on with the help of the initially unknown coupling constant g(E) > 0. The corresponding scattering state eigenfunction of OM at g = 0.00429 has the same v = 17 nodes in the interval r ∈ [0, 10] and yields the transmission coeﬃcient |T0 |2 = 0.412, as shown in Fig. 4 (c). This observation gave us an opportunity to propose the above algorithm, in which the agreement of OM and IWBC wave functions at L = 0 is achieved by solving an inverse problem, namely, by calculating the unknown coupling constant g(E) from the reﬂection R0 (E) and transmission T0 (E) amplitudes, determined in advance together with the required wave functions of the IWBC model. The resonance peaks of g(E) correspond to the appearance of metastable M M at EL,ν < 0, such that the real part of a states with complex energy EL,ν M . metastable state energy is close to the resonance scattering energy E res ≈ EL,ν res The eigenfunctions of scattering states with the resonance energy E ≈ 57.73 at g = 0.001 and g = 0 in the vicinity of the second peak of g(E) are shown  
   
  138  
   
  A. A. Gusev et al.  
   
  M M M Table 1. The complex energy EL,ν = EL,ν + ıEL,ν of metastable states and the res M ≈ EL,ν of scattering problem OM at corresponding shape resonance energies E L = 0, g = 0 and g = gres for a pair of heavy ions 16 O+144 Sm  
   
  ν  
   
  M EL,ν (g = 0)  
   
  16 53.7731 − 10−6 ı  
   
  E res (g = 0) g = gres 53.7729  
   
  M EL,ν (g = gres )  
   
  E res (g = gres )  
   
  5 · 10−13 53.7731 − 1.2 · 10−6 ı 53.7731  
   
  17 57.7328 − 0.0012ı 57.7326  
   
  1 · 10−7  
   
  57.7328 − 0.0012ı  
   
  57.7329  
   
  18 61.1639 − 0.1558ı 61.0675  
   
  0.0023  
   
  61.1614 − 0.1801ı  
   
  61.1645  
   
  in Figs. 5 (b) and 5 (e), and for the near-resonance energy E res ± 0.1 in Fig. 5. At g = 0.001 and g = 0, the resonance eigenfunctions, in contrast to the nonresonance ones, are localized in the potential well. At g(E) > 0, the degree of localization is less than at g = 0. Three metastable states correspond to three peaks of g(E) in Fig. 3 (a), as shown in Fig. 6. So, at g(E) > 0, the absolute value of the imaginary part of energy is larger than at g = 0. We show in M of metastable states and corresponding shape Table 1 the complex energy EL,ν res M of the elastic scattering at L = 0 and g = 0, resonance energies E ≈ EL,ν M increase and g(E) > 0. One can see that the imaginary parts of energy EL,ν with increasing value of the coupling constant g(E) > 0, that means decreasing a life time of metastable states.  
   
  5  
   
  Conclusions  
   
  The algorithm implemented in the MAPLE system for solving the scattering problem for a second-order ordinary diﬀerential equation of the OM with a complex-valued potential and regular BCs is presented. The complex-valued potential is a sum of the known real part of the potential, which includes the nuclear potential, the Coulomb potential, and the centrifugal potential, and the imaginary part of the potential, represented as a product of the unknown coupling constant parameter g(E) depending on the collision energy E of a pair of ions and the derivative of the real part of the known nuclear potential with respect to the independent variable of the ODE. The algorithm implements the solution of the inverse problem: the calculation of the unknown coupling constant g(E) by means of secant method using as input the amplitudes of reﬂection R(E) and transmission T (E) of the model with IWBCs, calculated in advance using the standard MAPLE-implemented program KANTBP 4M [24]. The proposed algorithm is shown to provide oneto-one correspondence between the OM with a complex-valued potential and the model of IWBCs with a real-valued potential. The eﬃciency of the proposed approach was illustrated by a numerical example of solving the scattering problem of a pair of heavy ions 16 O+144 Sm in the single-channel approximation of the coupled-channel method of the test desk given in Ref. [20]. The behavior of the coupling constant g(E) is shown to possess a resonance structure that corresponds to the existence of metastable states, that manifest themselves as resonances in the elastic scattering in the region of energy, where the fusion cross section smoothly increases.  
   
  Symbolic-Numerical Algorithm for Solving the Heavy Ion Collisions Problem  
   
  139  
   
  A generalization of the algorithm over the solution of the scattering problem in OM for a system of second-order ODEs using the updated KANTBP 4M and KANTBP 3.1 programs will allow a description of the experimental data on the cross section for deep sub-barrier fusion of a pair of heavy ions. We hope that the proposed algorithm will provide a wider application of the extended OM in a description of sub-barrier reactions of heavy ions. Acknowledgments. The present research beneﬁted from computational resources of the HybriLIT heterogeneous platform of the JINR. This publication has been supported by the Russian Foundation for Basic Research and Ministry of Education, Culture, Science and Sports of Mongolia (the grant 20-51-44001) and the Peoples’ Friendship University of Russia (RUDN) Strategic Academic Leadership Program, project No.021934-0-000. This research is funded by Ho Chi Minh City University of Education Foundation for Science and Technology (grant No. CS.2021.19.47). OCH acknowledges ﬁnancial support from the Ministry of Education and Science of Mongolia (grant No. ShuG 2021/137). The work of PWW, CJL, and HMJ is supported by the National Key R&D Program of China (Contract No. 2022YFA1602302), the National Natural Science Foundation of China (Grants Nos. 12235020, 12275360, 12175314, 12175313, and U2167204), the Leading Innovation Project (Grant No. LC192209000701), and the project supported by the Directors Foundation of Department of Nuclear Physics, China Institute of Atomic Energy (12SZJJ-202305).  
   
  References 1. Feshbach, H., Porter, C.E., Weisskopf, V.F.: Model for nuclear reactions with neutrons. Phys. Rev. 96, 448–464 (1954) 2. Buck, B., Stamp, A.P., Hodgson, P.E.: The excitation of collective states by inelastic scattering the extended optical model. Phil. Mag. J. Theor. Exp. Appl. Phys. 8, 1805–1826 (1963) 3. Tamura, K.: Analyses of the scattering of nuclear particles by collective nuclei in terms of the coupled-channel calculation. Rev. Mod. Phys. 37, 679–708 (1965) 4. Guenther, P.T., Havel, D.G., Smith, A.B.: Neutron scattering and the optical model near A = 208 and implications on the inelastic scattering cross section of uranium238. Nucl. Sci. Eng. 65, 174–180 (1978) 5. Mişicu, Ş, Esbensen, H.: Signature of shallow potentials in deep sub-barrier fusion reactions. Phys. Rev. C 75, 034606 (2007) 6. Esbensen, H., Tang, X., Jiang, C.L.: Eﬀects of mutual excitations in the fusion of carbon isotopes. Phys. Rev. C 84, 064613 (2011) 7. Rawitscher, G.H.: Ingoing wave boundary condition analysis of alpha and deuteron elastic scattering cross sections. Nucl. Phys. 85, 337–364 (1963) 8. Christensen, P.R., Switkowski, Z.E.: IWB analysis of scattering and fusion cross sections for the 12 C+12 C, 13 C+16 O and 16 O+16 O reactions for energies near and below the Coulomb barrier. Nucl. Phys. A 280, 205–216 (1977) 9. Krappe, H.J., Shring, K.M., Nemes, M.C., Rossner, H.: On the interpretation of heavy-ion sub-barrier fusion data. Z. Phys. A. 314, 23–31 (1983) 10. Hagino, K., Rowley, N., Kruppa, A.T.: A program for coupled-channel calculations with all order couplings for heavy-ion fusion reactions. Comput. Phys. Commun. 123, 143–152 (1999)  
   
  140  
   
  A. A. Gusev et al.  
   
  11. Hagino, K., Takigawa, N.: Subbarrier fusion reactions and many-particle quantum tunneling. Prog. Theor. Phys. 128, 1061–1106 (2012) 12. Back, B.B., Esbensen, H., Jiang, C.L., Rehm, K.E.: Recent developments in heavyion fusion reactions. Rev. Mod. Phys. 86, 317–360 (2014) 13. Hagino, K., Ogata, K., Moro, A.M.: Coupled-channels calculations for nuclear reactions: from exotic nuclei to super heavy elements. Prog. Part. Nucl. Phys. 125, 103951 (2022) 14. Samarin, V.V., Zagrebaev, V.I.: Channel coupling analysis of initial reaction stage in synthesis of super-heavy nuclei. Nucl. Phys. A 734, E9–E12 (2004) 15. Zagrebaev, V.I., Samarin, V.V.: Near-barrier fusion of heavy nuclei: coupling of channels. Phys. Atom. Nucl. 67, 1462–1477 (2004) 16. Zagrebaev, V.: Heavy Ion Reactions at Low Energies. In: Denikin, A., Karpov, A., Rowley, N. (eds.) Lecture Notes in Physics, vol. 963. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-27217-3 17. Wen, P.W., et al.: Near-barrier heavy-ion fusion: role of boundary conditions in coupling of channels. Phys. Rev. C 101, 014618 (2020) 18. Wen, P.W., Lin, C.J., Nazmitdinov, R.G., Vinitsky, S.I., Chuluunbaatar, O., Gusev, A.A., Nasirov, A.K., Jia, H.M., Góźdź, A.: Potential roots of the deep subbarrier heavy-ion fusion hindrance phenomenon within the sudden approximation approach. Phys. Rev. C 103, 054601 (2021) 19. Gusev, A.A., Chuluunbaatar, O., Vinitsky, S.I., Abrashkevich, A.G.: KANTBP 3.0: new version of a program for computing energy levels, reﬂection and transmission matrices, and corresponding wave functions in the coupled-channel adiabatic approach. Comput. Phys. Commun. 185, 3341–3343 (2014) 20. Chuluunbaatar, O., Gusev, A.A., Vinitsky, S.I., Abrashkevich, A.G., Wen, P.W., Lin, C.J.: KANTBP 3.1: a program for computing energy levels, reﬂection and transmission matrices, and corresponding wave functions in the coupled-channel and adiabatic approaches. Comput. Phys. Commun. 278, 108397 (2022) 21. Bohr, A., Mottelson, B.R.: Nuclear Structure. Single Particle Motion. V. I, W.A. Benjamin. New York, Amsterdam (1969) 22. Bohr, A., Mottelson, B.R.: Nuclear Structure. Nuclear Deformation. V. II, W.A. Benjamin. New York, Amsterdam (1974) 23. Karpov, A.V., et al.: NRV web knowledge base on low-energy nuclear physics. Nucl. Instr. Meth. Phys. Res. A 859, 112–124 (2017) 24. Gusev, A.A., Hai, L.L., Chuluunbaatar, O., Vinitsky, S.I.: KANTBP 4M - program for solving boundary problems of the self-adjoint system of ordinary second order diﬀerential equations. http://wwwinfo.jinr.ru/programs/jinrlib/kantbp4m/indexe. html. Accessed 17 May 2023 25. https://www.maplesoft.com 26. Takigawa, N., Rumin, T., Ihara, N.: Coulomb interaction between spherical and deformed nuclei. Phys. Rev. C 61, 044607 (2000) 27. Abramowitz, M., Stegun, I.A.: Handbook of Mathematical Functions. Dover, NY (1965) 28. Chuluunbaatar, O., et al.: Calculation of a hydrogen atom photoionization in a strong magnetic ﬁeld by using the angular oblate spheroidal functions. J. Phys. A 40, 11485–11524 (2007) 29. Gusev, A.A.: Symbolic-numeric solution of boundary-value problems for the Schrödinger equation using the ﬁnite element method: scattering problem and resonance states. In: Gerdt, V.P., Koepf, W., Seiler, W.M., Vorozhtsov, E.V. (eds.) CASC 2015. LNCS, vol. 9301, pp. 182–197. Springer, Cham (2015). https://doi. org/10.1007/978-3-319-24021-3_14  
   
  On the Complexity of Linear Algebra Operations over Algebraic Extension Fields Amir Hashemi1,2(B) and Daniel Lichtblau3 1  
   
  2  
   
  Department of Mathematical Sciences, Isfahan University of Technology, 84156-83111 Isfahan, Iran [email protected]  School of Mathematics, Institute for Research in Fundamental Sciences (IPM), 19395-5746 Tehran, Iran 3 Wolfram Research, 100 Trade Center Dr, Champaign, IL 61820, USA [email protected]   
   
  Abstract. In this paper, we study the complexity of performing some linear algebra operations such as Gaussian elimination and minimal polynomial computation over an algebraic extension ﬁeld. For this, we use the theory of Gr¨ obner bases to employ linear algebra methods as well as to work in an algebraic extension. We show that this has good complexity. Finally, we report an implementation of our algorithms in Wolfram Mathematica and illustrate its eﬀectiveness via several examples. Keywords: Gaussian elimination · Minimal polynomial · Polynomial obner bases · FGLM algorithm · Algebraic extension ﬁelds · ideals · Gr¨ Complexity analysis  
   
  1  
   
  Introduction  
   
  In ﬁeld theory, a ﬁeld extension K ⊂ L is called algebraic if every element of L is a root of some non-zero and monic polynomial over K. In this paper, we are interested in analysing the complexity of performing some linear algebra operations over an algebraic extension ﬁeld L. In this direction, we concentrate only on carrying out Gaussian elimination on a matrix over L as well as computing the minimal polynomial of a square matrix over L. More precisely, assume that f1 ∈ K[x1 ] is a monic polynomial of degree d1 ≥ 2 over the ﬁeld K. Then, additions in K[x1 ]/f1  need d1 operations whereas multiplications require O(d1 log(d1 ) log(log(d1 ))) operations. We refer to [9] for more details. If α1 denotes the class of x1 in K[x1 ]/f1 , then this quotient ring is denoted by K[α1 ]. Doing an induction, assume that for each 2 ≤ i ≤ n, fi is a monic and reduced polynomial of degree di ≥ 2 in xi , over the ring K[x1 , . . . , xi−1 ]/f1 , . . . , fi−1 . Thus, we obtain the multiple algebraic extension K[x1 , . . . , xn ]/f1 , . . . , fn  which is denoted by L := K[α1 , . . . , αn ] for c The Author(s), under exclusive license to Springer Nature Switzerland AG 2023  F. Boulier et al. (Eds.): CASC 2023, LNCS 14139, pp. 141–161, 2023. https://doi.org/10.1007/978-3-031-41724-5_8  
   
  142  
   
  A. Hashemi and D. Lichtblau  
   
  simplicity. Let D = d1 · · · dn . Performing additions and multiplications in L require O(D) and O(4n D log(D) log(log(D))) operations respectively; see [23, Theorem 1] and [18] for more details. Lebreton [22] showed that in the latter bound the number 4 can be replaced by 3. We will mostly be concerned with doing linear algebra over L. Unless stated otherwise, we will work with square matrices of dimension m × m. In prior work, Moreno Maza et al. [26, Theorem 2] proposed an algorithm to compute the inverse of a matrix over L using O(4n D(mω+1/2 + n max{d1 , . . . , dn }(ω−1)/2 ) log(D) log(log(D))) operations, where ω < 2.3728639 denotes the optimal exponent of matrix multiplication (see [2,21]). If in this bound, we remove the term mω+1/2 , then one gets the cost of calculating the inverse of an element in L, see [26, Theorem 1]. Our focus will be on straightforward but practical implementations of linear algebra on matrices with elements in L. As such, we will not attempt to use asymptotically fast matrix multiplication (so our exponent will be 3), but much of the analysis that follows can be carried over to the asymptotic regime. An important issue that we address in this paper is the computation of the minimal polynomial of a matrix over an algebraic extension ﬁeld. The best deterministic approach to compute the minimal polynomial of an m × m over K is due to Storjohann [29] (by computing the Frobenius normal form of the matrix) which needs O(m3 ) ﬁeld operations. Note that in the setting of [9,23,26] (and indeed in much of the literature), the ideal f1 , . . . , fn  is generated by a triangular set. In this paper we instead consider an arbitrary zero-dimensional ideal which is not necessarily represented by a triangular set, and show how one is able to perform various kinds of linear algebra computations in L. In consequence, the complexity bounds that we present may not be comparable with the existing bounds for ideals generated by triangular sets. If we assume that, for each i, fi is irreducible over K[x1 , . . . , xi ]/f1 , . . . , fi−1  then L becomes a ﬁeld. However this additional assumption is not required in the sequel, and we can work with L as an extension ring (in which case we do not always have invertibility of ring elements, and hence might be unable to make polynomials in the ring monic). We will note when more restrictive assumptions are being made, such as a ﬁeld given by a tower of irreducible algebraic extensions or by a primitive element. In the latter case, when the base ﬁeld is prime, computations can be particularly fast, as we will see in the experimental results. Since an algebraic extension L can be represented more generally as a quotient of a polynomial ring by a zero-dimensional ideal, Gr¨ obner bases are a basic tool for doing eﬀective computations in L. Thus, in this paper, by applying particular tools developed for zero-dimensional Gr¨ obner bases, we investigate the complexity of performing some linear algebra operations over the ﬁeld L. We note that [17] presented an eﬃcient algorithm for computing the minimal polynomial of a matrix over L by using Gr¨ obner bases. In this paper we will discuss the arithmetic complexity of the method given in [17]. The notion of Gr¨ obner bases as well as the ﬁrst algorithm for their construction were introduced by Buchberger in 1965 in his Ph.D. thesis [7,8]. In 1979,  
   
  Linear Algebra over Algebraic Extension Fields  
   
  143  
   
  he improved this algorithm by applying two criteria (known as Buchberger’s criteria) to remove some of the superﬂuous reductions, [5]. Later, [14] described an eﬃcient algorithm to install these criteria on Buchberger’s algorithm. Since then, several improvements have been proposed to speed-up the computation of Gr¨ obner bases. In particular, in [13], using linear algebra techniques, the FGLM algorithm was proposed to convert a Gr¨ obner basis (of a zero-dimensional ideal) with respect to any term ordering into a Gr¨ obner basis for the same ideal with respect to another ordering. We exploit FGLM techniques in analyzing worstcase complexity for algorithms we present in this paper. In [6], Buchberger also showed how one might employ Gr¨ obner bases to do computations in algebraic number ﬁelds. This general technique plays a role in our implementation section. The paper [27] also describes a method for computing a matrix minimal polynomial over a ﬁnite ﬁeld. In contrast to the present work, they count ﬁeld operations as units. This is regardless of whether the ﬁeld is prime or a power of a prime. The present work, in contrast, accounts for all operations in the base ring (that is, the rationals or underlying prime ﬁeld). Thus this also takes into consideration the complexity of the extension ﬁeld representation. The structure of the paper is as follows. Section 2 reviews the basic notations and terminologies used throughout the paper. In Sect. 3, we discuss the complexity of performing some linear algebra operations over an algebraic extension ﬁeld. Section 4 describes implementations of our approach presented in Sect. 3 along with experimental results.  
   
  2  
   
  Preliminaries  
   
  Throughout this article, we use the following notations. Let P = K[x1 , . . . , xn ] be the polynomial ring where K is a ﬁeld. We consider a sequence f1 , . . . , fk of nonzero polynomials in P and the ideal I = f1 , . . . , fk  generated by this sequence. We assume that each fi has total degree di ≥ 2. Furthermore, we denote by R the quotient ring P/I. Any element of this ring is given by [f ] := f + I where f ∈ P. αn 1 For us, a term is a power product xα := xα 1 · · · xn of the variables x1 , . . . , xn where α = (α1 , . . . , αn ). Let us ﬁx a term ordering ≺. The leading term of a polynomial f ∈ P, denoted by LT(f ), is the greatest term (with respect to ≺) appearing in f . The coeﬃcient of LT(f ) in f is called the leading coeﬃcient of f and is denoted by LC(f ). The product LM(f ) := LC(f ) · LT(f ) is the leading monomial of f . The leading term ideal of I is deﬁned as LT(I) = LT(f ) | 0 = f ∈ I. For a ﬁnite set G ⊂ P, LT(G) denotes the set {LT(g) | g ∈ G}. A ﬁnite subset G ⊂ I is called a Gr¨ obner basis for I with respect to ≺, if LT(I) = LT(G). A Gr¨ obner basis is called minimal if all leading coeﬃcients are unity and in addition it contains no redundant elements, that is, no leading term is divisible by the leading term of a diﬀerent element. From here on we assume all Gr¨obner bases to be minimal. A minimal Gr¨ obner basis is called reduced if no term in any polynomial in the basis is divisible by the leading term of a diﬀerent element. One of the most immediate and important applications  
   
  144  
   
  A. Hashemi and D. Lichtblau  
   
  of Gr¨ obner bases is the following result (which is referred to in the literature as Macaulay’s theorem) allowing us to ﬁnd a basis for R as a K-vector space. Proposition 1 ([11, Proposition 4, page 250]). Let G be a Gr¨ obner basis of the ideal I ⊂ P. Then, the normal set N (G) := {[u] | u is a term and u ∈ / LT(G)} forms a basis for R as a K-vector space. This is known as the normal set for the basis G. By abuse of notation, we will refer to basis elements of N (G) by the minimal terms that generate them. It is well-known that the remainder of the division a polynomial f by a Gr¨ obner basis G with respect to ≺ is unique and is denoted by NFG (f ). We shall notice that NFG provides a K-linear map from P to R and in consequence we have R = {[NFG (f )] | f ∈ P}. From the ﬁniteness theorem (see [11, Theorem 6, page 251]), we know that if I is zero-dimensional then N (G) is ﬁnite and its size is the dimension of R as a K-vector space. Subsequently, this size will be considered as a factor in our complexity analysis. An immediate corollary to the above proposition is that if the product of terms t1 t2 belongs to N (G) then each factor lies in N (G). Definition 1 ([15, page 52]). Let I ⊂ P be any zero-dimensional ideal. We deﬁne the degree of I as the cardinality of N (G); and we denote it by deg(I). Definition 2. Let t be a power product in the normal set N (G) and x be a variable in the deﬁning ideal. If xt does not lie in N (G) then we call it a boundary term. The set of all boundary terms associated to G is denoted by B(G). Since all elements of LT(G) lie in B(G), we see that |G| ≤ |B(G)| ≤ n|N (G)|. Also recall a simple result in Proposition 2.1 of [13]: each element of B(G) is either an element of LT(G) or else a product of the form xi t where t ∈ B(G). We refer to [4,11] for more details on the theory of Gr¨ obner bases. Now let us recall some facts concerning algebraic extension ﬁelds. A ﬁnite algebraic extension ﬁeld L of K is a ﬁeld K(α1 , . . . , αn ) where the αi ’s are algebraic over K. According to Kronecker’s construction, we have the K-algebra homomorphism ψ : P → K(α1 , . . . , αn ) deﬁned by xi → αi . It is well-known that there exist polynomials f1 , . . . , fn ∈ P such that Ker(ψ) = f1 , . . . , fn . From now on, we denote this ideal by I; it is a maximal (and zero-dimensional) ideal of P. It is clear that K(α1 , . . . , αn ) is isomorphic to K[x1 , . . . , xn ]/I as a K-algebra (with each αi being the equivalence obner bases to class of xi modulo I). For more details on the relation of the Gr¨ the algebraic extension ﬁelds, we refer to [1,6]. In the subsequent sections we work with the quotient ring K[x1 , . . . , xn ]/I where I is not necessarily represented by a triangular set. Instead it will be represented by the reduced Gr¨ obner basis G = {g1 , . . . , gt } with respect to a given term ordering ≺. In some cases this might include ﬁnding a primitive element that generates I (in which case there is an obvious equivalence to a  
   
  Linear Algebra over Algebraic Extension Fields  
   
  145  
   
  triangular set representation). We deﬁne D to be deg(I) (that is, D is the size of the normal set). By the well-known B´ezout theorem, we have D ≤ dn where d is the maximum degree of a generating set of I. We give some indication of the complexity of computing a primitive element that generates I in Sect. 4. We shall note that in our complexity analysis in the next section, we do not take into account the complexity of computing the reduced Gr¨ obner basis G. Dickenstein et al. [12] have shown that if the zero-dimensional ideal I is generated by polynomials of degree at most d then its reduced Gr¨ obner basis with respect 2 to ≺ can be computed within the arithmetic complexity dO(n ) , see also [16]. For reasons that will be clariﬁed later in this paper, we may also assume that algebraic extensions have primitive elements, that is, can be generated by a single algebraic element of the multiplicative group of the ﬁeld (in practice this will be a linear combination of the given set of generating elements). See [4,19] for details regarding computation and use of primitive elements. A common way of deﬁning an extension ﬁeld using multiple elements is to have the i-th element deﬁned as a solution of a monic polynomial fi in the new variable xi , with coeﬃcients of the non-leading terms being polynomials in the prior elements. In particular, if {f1 , . . . , fn } forms a triangular set then we have such a representation. In the setting of triangular sets, the size D of the extension is easily seen to be the product of the degrees of the fi in the corresponding main variables xi . So we have n ≤ log2 (D) or, stated diﬀerently, D ≥ 2n (we tacitly assume no extension elements are trivial, that is, linear combinations of previous elements, so all generators are algebraic elements of degree at least 2). In the case that {f1 , . . . , fn } is a triangular set, we will refer to the corresponding extension as a “tower extension”. Note that algebraic ﬁelds need not be given as tower extensions, as the next example shows. Example 1. The ideal given by the polynomials {x2 + xy + 2, y 2 + yz − 3, z 2 − zx + zy + 4x + 3y + 5} is in terms of n = 3 variables and hence 2n = 8. A Gr¨ obner basis for this ideal is {2004 − 1656z + 83z 2 + 210z 3 − 90z 4 + 61z 5 − 6 3z + 3z 7 , 356844 + 252448y + 202412z − 27327z 2 + 35961z 3 − 14627z 4 + 834z 5 − 807z 6 , − 166836 + 378672x − 205968z − 11873z 2 − 58193z 3 − 857z 4 − 2934z 5 + 219z 6 }. So the normal set has the size D = 7 and this is less than 2n .  
   
  3  
   
  Complexity Results  
   
  In this section, we discuss the complexity analysis of computing the inverse of an algebraic number as well as performing some of the well-known linear algebra operations over an algebraic extension ﬁeld. We assume unless stated otherwise that the extension ﬁeld is deﬁned by n algebraic elements and represented by a Gr¨ obner basis G. 3.1  
   
  Multiplication Table  
   
  In some of the theorems that follow we will require a fast means of reducing products of pairs of elements in the normal set N (G) into linear combinations  
   
  146  
   
  A. Hashemi and D. Lichtblau  
   
  of elements in N (G). To this end we create a table of these products and their corresponding reduced forms. We will assume that table elements can be stored and found in O(n) time; in implementations this might be accomplished using for example a hash table on the exponent vectors. Once we have such a table, every reduction of such a product is O(nD) operations where n is the number of algebraic elements deﬁning the ideal (this is simply the cost of writing that many terms). Given a polynomial p1 of length l1 and a reducing polynomial p2 of length l2 , where terms in p1 are comprised of products of two normal set elements and those in p2 are only normal set elements, we make the assumption that the reduction can be performed in O(nl2 ) steps, that is, the length of the polynomial being reduced does not matter. In practice this can be achieved for example by using a dense data structure for the elements in N (G) and hashing all exponent vectors to locate their position in that structure; we regard this as a preprocessing step. Since we will also need to look up term reductions after we compute them, we have another cost of O(nD2 ). For our purposes we will assume n ≤ D. In the theorem below we ignore these costs because they are smaller than the actual complexity. We now give the complexity of computing a multiplication table, as we will use this in the sequel (in particular in Subsect. 3.2). Moreover, as this is an extension of the FGLM method of basis conversion [13], it is thus of interest in its own right. Theorem 1. Given a reduced Gr¨ obner basis G for an ideal I deﬁned by n algebraic elements, with normal set N (G) of size D, we can compute a multiplication table for all pairs in N (G) in O(D4 ) arithmetic operations. Proof. Denote the elements of N (G) as u1 , u2 , . . . , uD with u1 ≺ u2 ≺ · · · ≺ uD . We have at most O(D2 ) distinct power products in the set of product pairs. As the ﬁrst step, we order these products. We consider ﬁrst the elements of N (G), then the elements of LT(G), next the elements of B(G) \ LT(G) and ﬁnally the remaining term products. For this ordering, we use the same term ordering ≺ as was used for the computation of G. It is well known that sorting a set of size k comprised of elements of size n in this way is no worse than O(nk log(k)), so this will not dominate the complexity analysis. Now, we hash this sorted list of terms and it costs O(nD2 ) arithmetic operations (for simplicity we can use e.g. natural numbers 1, 2, 3, . . . as the range of the hash function). Within the complexity O(n) we can determine whether a term u belongs to LT(G) or not. The same holds for membership in other subsets of term products. Below, we keep the normal form of each term in the form b1 u1 + · · · + bD uD and assume that each elements g ∈ G is represented of the form LT(g) − b1 u1 + · · · − bD uD . Now assume that we are given a product u. Then four cases may occur: Case (1) u ∈ N (G): This case comprises a “base case”, that is, we need no replacements for them. Case (2) u ∈ LT(G): Testing for membership in LT(G) is O(n). In this case, we have the normal form of u with no calculations other than to list the O(D) terms.  
   
  Linear Algebra over Algebraic Extension Fields  
   
  147  
   
  Case (3) u ∈ B(G) \ LT(G): In this case, we are able to write u as xt for a variable x and a term t with t ∈ B(G). Since t ≺ u, it already has a rewrite as a sum of elements in N (G). Thus we have u = xt = x(b1 u1 + · · · + bD uD ). As each xui ≺ u we have xui = ci,1 u1 + · · · + ci,D uD . Thus we can rewrite u at cost O(n2 + nD + D2 ). Here the D2 contribution is for the actual rewriting, the n2 is the cost of ﬁnding such t ∈ B(G) (we have to check up to n variables, and each check is O(n) to compute the exponent vector of u/xj and then to do a lookup on that vector), and the nD component comes from having to locate D reductions for the xui terms. Case (4) u ∈ / N (G) ∪ B(G): Then we can ﬁnd a variable x and term t such that u = xt and t ∈ / N (G). Since t ≺ u it already has a reduction and thus we have u = x(b1 u1 + · · · + bD uD ) for base ring elements ai and terms ui ∈ N (G). For each such product we have xui ∈ B(G). Since we already handled terms from B(G) in case (3), by applying an induction, we have xui = ci,1 u1 + · · · + ci,D ud . Here the main point is also the choice of the variable x. Indeed, any variable x appearing in u will work, and the corresponding term t = u/x will already have a reduction due to the order in which we compute these. The cost of ﬁnding x and the lookup cost for the reduction of t are both clearly O(n). Similarly the cost of ﬁnding reductions for the O(D) terms xui is O(nD). Thus we can reduce u at cost O(n + nD + D2 ). As we have O(nD) terms for case (3) and O(D2 ) terms for case (4), and   
   
  n ≤ D, the total cost is bounded by O(D4 ). We shall note that this proof is in essence the same argument as in the FGLM reference [13], except that, in our paper, we also take into account the number of generators n. However, since we have n ≤ D the overall complexity given in [13] does not require this accounting. We remark that this bound is pessimistic. Indeed, it is commonly the case that |G| is O(D) rather than O(nD). Also we need not consider elements in B(G) that are not also in the set of products of pairs in N (G). This is relevant for instance when G is a lexicographic Gr¨ obner basis and the smallest variable is in general position (so the shape lemma applies). In this case the set of products is actually O(D) and only one Gr¨ obner basis reduction is needed since only one element from B(G) appears in the set of products. In the special case where we have a tower extension, we can work with a lexicographical ordering. In this case the original polynomials deﬁning the extension are already a Gr¨ obner basis although possibly not fully reduced. Thus we have |G| = n, so we can drop a factor of D in the complexity analysis. Also in this case we have D = d1 d2 · · · dn where di is the degree in the extension-generating variable xi of the ith polynomial fi , and by assumption of nontriviality we have di ≥ 2. The set of products from N (G) lies in the Minkowski sum of N (G) with itself, and as the normal set lies in a rectangular prism in Zn , this sum has cardinality 2n D ≤ D2 . Thus we compute rewrites for strictly fewer than D2 terms in computing the multiplication table. Speciﬁcally, for any di ≥ 3 we have a factor di /2 reduction in the number of operations for the largest component of the complexity.  
   
  148  
   
  3.2  
   
  A. Hashemi and D. Lichtblau  
   
  Algebraic Inverse  
   
  Based on the structure of the FGLM algorithm, Noro [28] presented a simple and eﬀective method for computing the inverse of an algebraic number (another method is given in [6]). To explain Noro’s method, let N (G) = {b1 , . . . , bD } be a basis for the K-vector space P/I with I = f1 , . . . , fn  (recall we take as basis the normal set for a given Gr¨ obner basis G of the extension ideal I). Furthermore, let σ be an element of K(α1 , . . . , αn ). There exists a polynomial f such that f = ψ −1 (σ), where ψ is the map from Sect. 2 taking xi to αi . D Then the inverse of σ is i=1 ci ψ(bi ), where the ci ’s belong to K and satisfy D i=1 ci NFG (f bi ) = 1. Let d = deg(f ) and τ be the number of non-zero terms of f . To simplify the ﬁnal complexity bounds, we assume here and throughout that d and τ are less than or equal to D. If these inequalities do not hold, then it suﬃces to compute the normal form of f with respect to G, and this does not change the correctness of this approach. These simpliﬁcations are considered in the following subsections. In the next theorem we assume we have already precomputed a multiplication table, so that cost is not included in the complexity analysis. Theorem 2. The arithmetic complexity of computing the inverse of σ is O(nD3 ). Proof. First we Dform a generic linear combination p of the normal set elements, that is, p = i=1 ci ψ(bi ). This will be our inverse and so we must determine values of the parameters. We next multiply by σ at cost O(nD2 ). We now reduce σp − 1. Using the precomputed multiplication table (see Theorem 1) we rewrite each of the O(D2 ) terms as a linear combination of N (G) at cost O(nD). Thus the total of reducing this product is O(nD3 ). We set each coeﬃcient to zero. This gives a linear system of D equations in D unknowns. The arithmetic cost of solving is bounded by O(D3 ) and so the O(nD3 ) reduction is the dominating term in the complexity.   
   
  Theorem 3. Keeping the above notations, and assuming our extension is given by a primitive element, the arithmetic complexity of computing the inverse of σ is O(D3 ). D Proof. As before, we form a generic linear combination p = i=1 ci ψ(bi ). Again we must determine values of the parameters. We next multiply by σ at cost O(D2 ). The primitive element representation implies that the product has fewer than 2D = O(D) distinct terms. We now reduce σp − 1 by the polynomial that deﬁnes our primitive element. Since each reduction of the top monomial reduces the degree, this entails O(D) reduction steps. As the reducing polynomial has at most O(D) terms, the complexity of each reducing step is also O(D), so the total cost of reducing σp − 1 is O(D2 ). Setting the reduced polynomial to zero coeﬃcient-wise gives D linear equations in the D unknown parameters. Solving this system is O(D3 ) operations in the base ﬁeld. As this dominates the prior parts we achieve the claimed bound.   
   
  Linear Algebra over Algebraic Extension Fields  
   
  149  
   
  We remark that if the ﬁeld in question is an algebraic extension of a prime ﬁeld by a single irreducible polynomial (hence has a primitive element), well known asymptotically fast methods for computing products and inverses (e.g. based on Fourier-type transforms and the half-GCD respectively) become quite practical. In such cases these are in fact what we use. When the base ﬁeld is a prime ﬁeld but the extension is not given by a primitive element, then some of the linear algebra analysis from the next subsection, which uses the multiplication table, will still apply for converting to a primitive element representation and back again. In the rest of this subsection, we compare our complexity bound presented in Theorem 2 to the bound that one can obtain using the FGLM techniques. In doing so, let us recall some useful results regarding the FGLM algorithm, see [13] for more details. Let I ⊂ P be a zero-dimensional ideal and D := deg(I). The FGLM algorithm receives as input the reduced Gr¨ obner basis G1 with respect obner basis G2 with respect to another term to ≺1 , and outputs the reduced Gr¨ ordering ≺2 . The main advantage of this algorithm is the use of linear algebra techniques that make it very eﬃcient in practice. The basic ingredient of this algorithm is the eﬃcient computation of the normal form of a polynomial with respect to G1 . For this, one needs to construct the matrix corresponding to the linear map φi : N (G) → N (G) with φi (b ) = NFG1 (xi b ) for each  where N (G) = {b1 , . . . , bD }. This leads to the construction of the FGLM table T (G) = (tij ) where tij denotes the j-coordinate with respect to N (G) of φi (xi b ). It is shown that cost of computing the FGLM table is O(nD3 ), [13, Proposition 3.1] and this complexity is the dominant factor in the complexity analysis of transforming G1 to G2 . Theorem 4. The arithmetic complexity of computing the inverse of σ, by using the FGLM table, is O(nD5 ). Proof. Using the Noro’s method, we shall compute NFG (f b ) for an arbitrary . For this, we consider the complexity of computing NFG (xi b ) where xi is a variable. Using the FGLM table, it is equal to ti1 b1 + · · · + tiD bD . One can see easily that the cost of computing NFG (xr xi b ) is O(D2 ) ﬁeld operations. In consequence, the complexity of computing NFG (mb ) is O(ndD2 ) where m is a term of degree d. Since f has τ ≤ D terms then the complexity of NFG (f b ) is O(nD4 ). Performing these operations for all  has the complexity O(nD5 ). Note that the bound O(nD5 ) includes also the complexity O(nD3 ) for computing the FGLM table. D Finally, ﬁnding the inverse of σ is equivalent to ﬁnding the ci ’s  such that i=1 ci NFG (f bi ) = 1 and this has the cost D3 , ending the proof. Corollary 1. By taking into account the complexity of computing a multiplication table (Theorem 1), the worst-case complexity of computing an algebraic inverse by using Theorem 2 is O(nD4 ) which is lower than the corresponding worst-case bound that one obtains using the FGLM techniques (Theorem 4). Remark 1. By applying dynamic evaluation and modular techniques, Langemyr in [20] gave an almost optimal algorithm, i.e. in computing time O(S δ+1 ) for all  
   
  150  
   
  A. Hashemi and D. Lichtblau  
   
  δ > 0, where S is the best known a priori bound on the length of the output, for computing the inverse of σ. 3.3  
   
  Gaussian Elimination  
   
  In this subsection, we discuss the complexity of performing Gaussian elimination on a given matrix over K(α1 , . . . , αn ). Theorem 5. Let A be a matrix of size s × t over K(α1 , . . . , αn ). Keeping the notations presented in Subsect. 3.2, and assuming either that we have a primitive element or that we have precomputed a multiplication table for N (G), the arithmetic complexity of performing Gaussian elimination on A is given by O(min(s, t)stnD3 ). Proof. We know that for each i, j there exists polynomial fi,j such that fi,j = ψ −1 (A[i, j]). Let d be the maximum of deg(fi,j )’s and τ the maximum number of non-zero terms of the fi,j ’s. From the above discussion we have n, d, τ ≤ D. Let Row(i, A) denote the i-th row of A. Assume that we want to reduce the ﬁrst column of A by using A[1, 1]. Let σ be A[1, 1]. Now, to perform a row reduction operation, one can ﬁrst compute σ −1 (see Theorem 2 and corollaries), multiply all the entries of Row(1, A) by σ −1 and then expand each entry of σ −1 Row(1, A). Recall the cost of inverting σ was bounded by O(nD3 ). Then the number of ﬁeld operations for this part is O(nD3 + tnD2 ). Note that σ −1 and each entry in the ﬁrst row have length at most D in terms of the elements of N (G), hence all products have length bounded by D2 . Reducing each term in such a product under the assumption of a table or a primitive element is O(nD) and gives rise to a result of length O(D), so the full reduction cost is no worse than O(nD3 ). As there are t elements to consider, the complexity of making the pivot 1 is O(tnD3 ) (and, as with element inversion, using a primitive element can bring this step to O(tD2 ) since product lengths become bounded by 2D). Finally, we shall reduce Row(i, A) with i > 1 by using the new row; i.e. σ −1 Row(1, A). The number of ﬁeld operations to reduce one row is easily seen to be the same as the step of making the pivot equal to 1. We shall repeat this operation for i = 2, . . . , s. All in all, reducing s − 1 rows by the ﬁrst row costs O(nD3 + tnD3 + (s − 1)tnD3 ) which is dominated by O(stnD3 ). The number of pivots to reduce beneath is equal to the rank of the matrix, which is bounded by min(s, t) and this ends the proof.   
   
  We remark that for many purposes one need not make pivots equal to 1, and so the complexity of inverting an element can be avoided. If we work with a primitive element extension and also avoid computing inverses then the complexity above is reduced by a factor of nD, to O(min(s, t)stD2 ), excluding costs of pre- and post-processing for using a primitive element. If asymptotically fast methods are used for multiplying algebraic elements, this reduces further to o˜(min(s, t)stD) (where the ”soft-Oh” notation hides logarithmic factors in D).  
   
  Linear Algebra over Algebraic Extension Fields  
   
  3.4  
   
  151  
   
  Minimal Polynomial  
   
  In this subsection, we analyse the complexity of computing the minimal polynomial of a square matrix over K(α1 , . . . , αn ) by using the algorithm presented in [17]. For the reader’s convenience, we recall it here (see Algorithm 1). To explain the complexity of this algorithm, let A be an m × m matrix over K(α1 , . . . , αn ). Then for each i, j there exists a polynomial fi,j such that fi,j = ψ −1 (A[i, j]). In order to reduce the complexity, we ﬁrst replace each fi,j by its normal form with respect to G. Without loss of generality, assume that fi,j = NFG (fi,j ). Let d be the maximum of deg(fi,j )’s and τ the maximum number of non-zero terms of the fi,j ’s. In consequence we have n, d, τ ≤ D. Furthermore let p(s) = am sm +am−1 sm−1 +· · ·+a0 be the minimal polynomial of A where each ai ∈ K(α1 , . . . , αn ) will be determined. We shall need to compute the sequence A2 , A3 , . . . , Am . From p(A) = 0 we can derive m2 algebraic equations between the ai ’s, say g1,1 , . . . , gm,m . As we interleave reductions with each step, it is easy to see that these polynomials have degree at most D (in terms of the xi ’s). In Algorithm 1, |X| denotes the size of a set X. Algorithm 1 MinPoly Require: Am×m a non-zero matrix, and G a Gr¨ obner basis for the ideal I Ensure: The minimal polynomial p(s) of A  t 1: gi,j := m t=0 at A [i, j] for i, j = 1, . . . , m 2: J := q1,1 , . . . , qm,m  where qi,j = NFG (gi,j ) for each i and j obner basis for I + J with respect to the lexicographical 3: G1 := A minimal Gr¨ ordering with xj ≺plex a0 ≺lex · · · ≺lex am for each j 4:  := The highest integer i such that ai appears in a polynomial in G1 5: if a0 , . . . , a ∈ G1 then 6: Return (s+1 ) 7: end if / G1 (if a0 ∈ / G1 , set r := 0) 8: r := The integer i with a0 , . . . , ai−1 ∈ G1 and ai ∈ 9: G2 := G1 |ar =1 10: p := NFG2 (xr + ar+1 sr+1 + · · · + a s ) 11: σ := AlgebraicInverse(a ) 12: p := σ · p 13: Return (p)  
   
  We note that the costly step of Algorithm 1 is the computation of a Gr¨ obner basis of the ideal I + J with respect to the mentioned ordering (see the line 2). Below we present a simple and eﬃcient way to compute such a basis. The ﬁrst point is that we need only a minimal Gr¨ obner basis for I + J , rather than the reduced one. Let qi,j = NFG (gi,j ) for each i, j. Order the qi,j ’s from the highest leading term to the lowest. Assume that q1 , . . . , qm2 is this sequence of polynomials. We want to construct recursively, for each i, the polynomials hi ˜ i . At the beginning, we let h1 = q1 . Suppose that h1 as a polynomial and h in terms of the ai ’s can be written as p a + · · · + p0 a0 where p = 0. Since  
   
  152  
   
  A. Hashemi and D. Lichtblau  
   
  ˜ 1 = w h1 where [w p ] = [1]. Thus, LT(h ˜ 1 ) = a . [p ] ∈ R is invertible, we let h Now, for each i = 2, . . . , m2 , we deﬁne hi = NF{h˜ 1 ,...,h˜ i−1 } (qi ). Consider hi as a polynomial in terms of the ai ’s of the form hi = pi0 ai0 +· · ·+p0 a0 where pi0 = 0. ˜ i = wi hi where [wi pi ] = [1]. We know that [pi0 ] ∈ R is invertible. Deﬁne h 0 0 0 ˜ i ) = ai . It yields that LT(h 0 ˜ 1, . . . , h ˜ m2 } \ {0} is a minimal Gr¨ Proposition 2. G ∪ {h obner basis for I + J . ˜ 1, . . . , h ˜ i−1 } forms Proof. Proceeding by induction, we ﬁrst show that if G ∪ {h ˜ i } is a minimal Gr¨ ˜ 1, . . . , h obner basis for a minimal Gr¨ obner basis, then G ∪ {h the ideal it generates. Since we have ˜ i ), LT(h)) = 1 ∀h ∈ G ∪ {h ˜ 1, . . . , h ˜ i−1 } gcd(LT(h the claim follows immediately from Buchberger’s ﬁrst criterion. From the con˜ i ’s, it follows that the ideal generated by G∪{h ˜1, . . . , h ˜ m2 }\{0} struction of the h is equal to I + J , which ends the proof.   
   
  Remark 2. For the proof of the correctness of Algorithm 1, we refer to [17, Theorem 1]. Our presentation of this algorithm is slightly diﬀerent from the original version. Example 2. In this example we illustrate the above process step by step to compute the minimal polynomial of a given matrix. Let us consider the matrix presented in [17, Example 2]. We wish to compute the minimal polynomial of the following matrix over the ﬁeld Z5 (α1 , α2 ) = Z5 [x1 , x2 ]/x21 + 1, x22 + x1 . Let ⎤ ⎡ 1 0 α1 ⎦. 1 A = ⎣ α1 + α2 2 1 3 α1 α2 + 1 It is easy to see that G = {x21 + 1, x22 + x1 } is a Gr¨ obner basis with respect to x1 ≺lex x2 for the ideal I it generates. Let p(s) = a3 s3 + a2 s2 + a1 s + a0 be a polynomial vanishing on A. Then, with the above notations, we have q1,1 q1,2 q1,3 q2,1 q2,2 q2,3 q3,1 q3,2 q3,3  
   
  = a0 + x1 a1 + (x1 + x2 + 4)a2 + (2x1 x2 + x1 + 2x2 + 4)a3 = a1 + (x1 + 2)a2 + (3x1 + x2 + 1)a3 = a2 + (x1 x2 + x1 + 3)a3 = (x1 + x2 )a1 + (x1 x2 + 2x1 + 2x2 )a2 + (x1 + x2 )a3 = a0 + 2a1 + (x1 + x2 + 2)a2 + (4x1 x2 + 4x1 + 4x2 + 3)a3 = a1 + (x1 x2 + 3)a2 + (4x1 x2 + 2x1 + x2 )a3 = a1 + (x1 x2 + 4x1 + 3x2 + 1)a2 + (2x1 + x2 + 3)a3 = 3a1 + 3x1 x2 a2 + (3x1 x2 + 2x1 + 3x2 + 3)a3 = a0 + (x1 x2 + 1)a1 + (2x1 x2 + x1 + 4)a2 + (4x1 x2 + 3x1 + 4x2 + 4)a3 .  
   
  Now, we set h1 = q1,1 . The coeﬃcient of this polynomial in terms of the ai ’s is 2x1 x2 + x1 + 2x2 + 4. The inverse of this polynomial is −x1 x2 − 3 = 4x1 x2 + 2.  
   
  Linear Algebra over Algebraic Extension Fields  
   
  153  
   
  ˜ 1 = (4x1 x2 + 2)a0 + (2x1 + x2 )a1 + (x1 x2 + 2x1 + 3x2 + 2)a2 + a3 . Therefore, h Following the similar approach, we get ˜ 2 = (x1 x2 + x1 + 4x2 + 3)a0 + (x1 x2 + 4x1 + x2 + 4)a1 + a2 h ˜ h3 = (2x1 + 2x2 + 1)a0 + a1 . ˜ 1, h ˜2, h ˜ 3 } is the desired One observes that h4 = · · · = h9 = 0. Thus G ∪ {h Gr¨ obner basis for I + J . By the notations used in the algorithm we have r = 0 and  = 3. Putting a0 = 1 in this basis, and computing the normal form of p(s) with respect to this basis leads to q(s) := (4x1 x2 + x1 + 4x2 + 4)s3 + (4x1 + 3x2 )s2 + (3x1 + 3x2 + 4)s + 1. The inverse of 4x1 x2 + x1 + 4x2 + 4 is σ := 2x2 + 2x1 . By multiplying q(s) with σ, we get the minimal polynomial s3 + (4α1 α2 + 4α1 + 2)s2 + (2α1 α2 + 2α1 + 3α2 + 4)s + 2α1 + 2α2 for A. Remark 3. We remark that we can emulate linear algebra by computing a module Gr¨ obner basis (see for example [24,25]). The ai ’s can be seen as deﬁning the matrix columns (these are sometimes called “tag variables” in the literature, and no S-polynomials are formed between distinct pairs of these. This can be enforced either by using a basis algorithm that provides for degree bounds, or else by the expedient of adding relations that all products of ai pairs vanish. Computing a module Gr¨ obner basis is one means of implementing the approach described in the remarks preceding Proposition 2. We use this as one of the methods in the implementation section. Remark 4. Following the notations used in Algorithm 1, assume that a0 , . . . , a belong to G1 . Since a+1 does not appear in G1 then A+1 = 0 and in turn we have a0 = · · · = a = 0. In this case, the minimal polynomial of A is p(s) = s+1 . For example, if we consider the matrix   01 A= 00 over the ﬁeld Z5 (α1 , α2 ) (see the above example) then we have A2 = 02×2 and in turn G1 = {x21 + 1, x22 + x1 , a0 , a1 }. Thus, p(s) = s2 . Remark 5. For the eﬃciency of the algorithm, we can apply Algorithm 1 in an iterative way by enumerating the matrices I, A, A2 , . . . and stopping whenever a linear dependency is detected. Theorem 6. Keeping the above notations, and assuming either that we have a primitive element or that we have precomputed a multiplication table for N (G), the arithmetic complexity of computing the minimal polynomial of the matrix A is O(m4 nD3 ). Proof. As the ﬁrst step, we shall compute A2 , A3 , . . . , Am . From linear algebra, it is well-known that the arithmetic complexity of computing X 2 where X is a matrix of size m × m is bounded by O(m3 ). However, since the entries of A are polynomials containing at most D non-zero terms, then we shall take  
   
  154  
   
  A. Hashemi and D. Lichtblau  
   
  into account the cost of expanding the entries of A2 . The cost of multiplying two polynomials in n variables with D terms is O(nD2 ). Thus, to compute A2 , we need O(m3 nD2 ) ﬁeld operations. Next we compute the normal form with respect to G of the entries of A2 . Recall from the proof of Theorem 2 that reducing an individual product in A2 has complexity O(nD3 ). Therefore the total complexity of this operation for all entries of A2 is O(m3 nD2 + m2 nD3 ). In consequence, the number of ﬁeld operations to calculate A2 , A3 , . . . , Am is O(m4 nD2 + m3 nD3 ). Within this complexity, we obtain the gi,j ’s and each gi,j has at most D terms. The complexity of the rest of the computation is equivalent to the cost of performing Gaussian elimination on a matrix of dimensions m2 ×m,  which we showed in Theorem 5 to be O(m4 nD3 ) and this ﬁnishes the proof. Remark 6. Assume that p(s) = am sm + am−1 sm−1 + · · · + a0 is the minimal polynomial of the matrix A. It is well-known that if a0 is non-zero then A is invertible and its inverse can be compute using the equality A−1 = m−1 + am−1 Am−2 + · · · + a1 ). Thus the complexity of Theorem 6 −a−1 0 (am A holds true for computing the inverse of A as well. In this case, the determinant of A is a0 . One of our implementations does division-free linear algebra directly. In this case Gr¨obner basis usage is restricted to interleaving extension ﬁeld reductions with the matrix operations. We avoid inverting elements in this implementation (and thus typically do not obtain a monic minimal polynomial). As mentioned earlier, this helps to reduce the complexity. We (mostly) avoid a factor of n if we work with a primitive element. The factor will instead appear in pre- and post-processing steps, where we ﬁrst replace the n original deﬁning elements by polynomials in the primitive element, and at the end reverse this replacement. We will say more about this when we describe experiments. Another advantage, as noted before, is that we also reduce the complexity of the linear algebra by a factor of D. A further probabilistic complexity improvement is to work not with powers At but instead with At v where v is a random vector in the base ﬁeld (this appears to be a folklore approach and we have not found a deﬁnitive reference for its origin). This gives rise to a Monte Carlo algorithm that reduces the complexity of the deterministic one by a factor of m. This works reliably when the base ﬁeld is either inﬁnite or a prime ﬁeld, that is, large compared to the matrix dimension. We remark that similar ideas are used in [27] and in some of the references cited in that work.  
   
  4  
   
  Notes on Implementation and Experimental Results  
   
  As mentioned earlier, a reasonable way to work with linear algebra over an algebraic ﬁeld is to compute a Gr¨ obner basis over a module, with new variables for the matrix columns and a Position-over-Term (POT) term ordering to enforce left-to-right reduction. An implementation of matrix minimal polynomial computation over an algebraic number ﬁeld can be found in the Wolfram Function Repository:  
   
  Linear Algebra over Algebraic Extension Fields  
   
  155  
   
  https://resources.wolframcloud.com/FunctionRepository/resources/Matrix MinimalPolynomial This way of computing the basis is the one described following Algorithm 1. There are several ways the computations can be made more eﬃcient than the most naive implementation would provide. One improvement is to use a degreebased Gr¨ obner basis for handling the algebraic numbers. This is incorporated into the overall Gr¨ obner basis computations as follows. In order to do linear algebra row reduction, the module variables need to be ordered lexicographically, so we use a block ordering with these ranked highest and lexically between one another. The variables representing the algebraics deﬁning the extension ﬁeld come lexically after the module variables, and are ordered between themselves by the graded reverse lexicographic (GRL) term order. Again as noted earlier, sizes (degree and number of terms) in the step of taking matrix products are controlled by interleaving reductions in each powering step. When the base ﬁeld is the rationals Q and n and D are ﬁxed, integer sizes grow as O(m) (and it is straightforward to show that this is a worst-case upper bound). Since the arithmetic complexity in terms of matrix dimension m is O(m4 ) (again holding all else constant, that is, ignoring the eﬀect of the algebraic extension), we expect the bit complexity to scale as O(m6 ) if the bit sizes are too small to allow for arithmetic operations using asymptotically fast methods. 4.1  
   
  Dependence on Matrix Dimension  
   
  In order to assess complexity empirically we conducted a simple experiment. We construct a family of random examples and time them using the code mentioned in the implementation section. Each member of the family is indexed by dimension, from 6 to 34. Matrix elements are random integers between -5 and 5, except the (1, 1) element is x and the (2, 2) element is y, where (x, y) satisfy the algebraic relations 9x2 − 2, 8y 3 − 3. Timings in seconds are given below. 0.1514 1.9964 19.174 146.50 843.17  
   
  0.2596 2.7591 26.695 203.79 1091.1  
   
  0.4203 3.8360 39.879 264.15 1428.2  
   
  0.6413 5.8487 56.576 348.10 1758.3  
   
  0.9326 8.0759 78.567 492.03 2319.5  
   
  1.3277 11.994 108.49 643.46  
   
  We ﬁt these to polynomials of degree 5, 6, 7 and 8. This is done in a numerically stable way by reweighting the values (dividing by the dimension raised to the degree of the ﬁt), ﬁtting to a Laurent polynomial, and undoing the eﬀect of weighting to obtain an ordinary polynomial. We then assess relative errors between polynomial values vs. computed values. The maximum percentage relative errors for these four ﬁts, from degree 5 to 8, are 15.8, 7.2, 5.7 and 4.7 respectively. The norms of the relative errors show a similar drop between degrees 5 and 6, followed by a tapering: they are (.439, .172, .134, .124). The principal of parsimony argues in favor of degree 6 being optimal.  
   
  156  
   
  4.2  
   
  A. Hashemi and D. Lichtblau  
   
  Dependence on Normal Set Size  
   
  We now describe experiments to assess complexity in terms of size of the extension ﬁeld. For this purpose we chose to control coeﬃcient growth by working in an algebraic extension of the prime ﬁeld Z7919 . We used straightforward linear algebra code with division-free row reduction. At each step we interleaved reductions by the extension ﬁeld. In one variation we pre-process by (i) computing a primitive element, (ii) solving for all deﬁning algebraics in as polynomials in this element, and (iii) replacing them in the matrix by their equivalent primitive element polynomials. When the linear algebra is ﬁnished and we have our polynomial, we post-process by replacing powers of the primitive element with reduced polynomials in the original extension variables. We remark that we do not compute algebraic element inverses using this method. This saves a factor of D in the complexity, at the expense of obtaining a result, that is not monic. We also use the Monte Carlo probabilistic method since it makes for faster code. The goal is to show that experiments are consistent with the claimed complexity being no worse than cubic in D. For this purpose we removed the costly step of inversion in setting pivots to unity. By also taking advantage of the speed gain from the Monte Carlo variation, we are able to run the experiments over a fairly large range of extension degrees (recall that this speed gain applies to the matrix dimension component of the complexity and not the component due to D, so this does not interfere with the goal of these particular experiments). In the ﬁrst part of this experiment our algebraic extension is given by the polynomials (3j xj − j, 2j y j+1 − (j + 1)) where j varies from 16 to 45. We use the same input matrix for all extensions. It is comprised of random integers between -5 and 5, with the (1, 1) element replaced by x and the (1, 2) element replaced by y. The sizes D of the normal sets, and corresponding timings, are in the table below. ((272, 2.16) (462, 6.40) (702, 14.91) (992, 36.32) (1332, 64.01) (1722, 119.6)  
   
  (306, 2.77) (506, 7.90) (756, 18.01) (1056, 37.65) (1406, 69.76) (1806, 133.9)  
   
  (342, 3.57) (552, 9.05) (812, 21.06) (1122, 41.64) (1482, 77.50) (1892, 139.5)  
   
  (380, 4.24) (600, 11.10) (870, 26.24) (1190, 50.50) (1560, 100.1) (1980, 158.9)  
   
  (420, 5.16) (650, 12.79) (930, 29.19) (1260, 63.87) (1640, 109.6) (2070, 191.0))  
   
  This ﬁts reasonably well to a polynomial quadratic in D: 275.14 − 1.42894x + 0.004678x2 . The largest relative error is under 0.1 (so less than 10%), and the norm of the vector of relative errors is 0.28. These show but little change when we use a cubic or higher degree ﬁt. We show a log-log plot of times vs. D, translated to go through the origin, along with the line y = 2x. The experimental complexity in this case appears to be not much larger than O(D2 ) (in particular, if we adjust the slope in the graph from 2 to 2.2, we get even closer alignment), and this is better than the predicted value. This is in part due to the use of an extension that has a sparse Gr¨ obner basis. We mention also that in this experiment, cost is dominated by the Gr¨ obner basis  
   
  Linear Algebra over Algebraic Extension Fields  
   
  157  
   
  computation and the creation and use of a multiplication table to convert back from a primitive element to the algebraic elements that originally deﬁne the ﬁeld extension. A variant of this experiment uses the same extension, but works with a 20 digit prime modulus. The results were similar, with each data point typically around 50% slower than the corresponding one with the smaller prime modulus (Fig. 1).  
   
  Fig. 1. Translated log-log plot of normal set size vs. computation times, primitive element sparse case  
   
  Our next experiment uses dense polynomials to deﬁne the extension. Leading terms in the two variables are the same as in the last experiment, but now we ﬁll in with random coeﬃcients times lesser power products. In this example the complexities of diﬀerent steps vary considerably. The main costs (as D increases) are in (i) computing the primitive element Gr¨ obner basis, (ii) computing the table of replacements to rewrite powers of the primitive element in terms of the normal set for the basis using the original variables and (iii) performing the substitutions at the end (using this table) and expanding the result. Possibly these are due to speciﬁcs of the implementation so we note two details. We handle (i) using an implementation of the Gr¨ obner walk [10] that has path perturbation [3]. For (ii) we do repeated reductions of successive powers of the primitive element and create a substitution table that we apply in (iii) to the minimal polynomial; this is similar to how we create and utilise a multiplication table when not working with a primitive element. A log-log plot, now using a slope of 2.5, suggests an experimental complexity of O(D2.5 ). A ﬁt indicates that this gives a smaller relative error (by a factor of 2 or so) than a quadratic. If we ignore the cost of computing a primitive polynomial for the extension, translating the input to that form, and translating the result back to a form expressed in the original ﬁeld elements, the cost can be seen to be softly linear in the degree extension D. We show this in Fig. 4, now plotted against a line of slope 1.1. If we forego the use of a primitive element then the speed-limiting factors change. This must happen, since both the cost of computing a primitive element  
   
  158  
   
  A. Hashemi and D. Lichtblau  
   
  that of converting the resulting minimal polynomial to use the original variables are removed. The new speed bump is in computing the normal set replacements for products of all pairs of terms in the normal set. This is quite fast for the case where the Gr¨obner basis polynomials are sparse; in the case where they are dense it becomes the bottleneck. The plot in Fig. 3 indicates a plausible complexity scaling as O(D2 ) (Fig. 2).  
   
  Fig. 2. Translated log-log plot of normal set size vs. computation times, primitive element dense case plus computing and translating to-from primitive element representation  
   
  Fig. 3. Translated log-log plot of normal set size vs. computation times, primitive element dense case linear algebra only  
   
  Note that the plausible O(D2 ) complexity in no way contradicts the more conservative bounds from the theory presented in the last section, in particular Theorem 6. These examples have a ﬁxed number of generators at n = 2. Thus the Minkowski polytope for the sum of normal set elements is O(D) (rather than O(D2 )) and products of algebraic elements are likewise O(D) in length. Hence we remove two factors of D in the overall complexity analysis.  
   
  Linear Algebra over Algebraic Extension Fields  
   
  159  
   
  Fig. 4. Translated log-log plot of computation times vs. normal set size, dense case without primitive element  
   
  There is another idiosyncrasy of implementation that seems worthy of remark. Our implementation that uses a Gr¨ obner basis for the linear algebra step has no need to compute algebraic inverses. Setting pivots to unity happens automatically as part of the Gr¨ obner computation, as S-polynomials are formed between leading row elements and the extension-deﬁning polynomials. On the one hand, this introduces an ineﬃciency as compared to straight linear algebra. On the other, it appears to vastly reduce coeﬃcient swell in the case where our base ﬁeld is the rationals. The practical trade-oﬀs of these implementations might warrant further study, independent of the theoretical bounds presented in this work. Acknowledgements. The authors would like to thank the reviewers for their many comments on our manuscript that helped us to improve it. The research of the ﬁrst author was in part supported by a grant from IPM (No. 14020413).  
   
  References 1. Adams, W.W., Loustaunau, P.: An Introduction to Gr¨ obner Bases, vol. 3. American Mathematical Society, Providence (1994) 2. Alman, J., Williams, V.V.: A reﬁned laser method and faster matrix multiplication. In: Proceedings of the 2021 ACM-SIAM Symposium on Discrete Algorithms (SODA), pp. 522–539. Society for Industrial and Applied Mathematics (2021) 3. Amrhein, B., Gloor, O., K¨ uchlin, W.: On the walk. Theor. Comput. Sci. 187, 179–202 (1997) 4. Becker, T., Weispfenning, V.: Gr¨ obner Bases: A Computational Approach to Commutative Algebra. In cooperation with Heinz Kredel, Springer, New York (1993). https://doi.org/10.1007/978-1-4612-0913-3 5. Buchberger, B.: A criterion for detecting unnecessary reductions in the construction of Gr¨ obner-bases. In: Ng, E.W. (ed.) EUROSAM 1979. LNCS, vol. 72, pp. 3–21. Springer, Heidelberg (1979). https://doi.org/10.1007/3-540-09519-5 52  
   
  160  
   
  A. Hashemi and D. Lichtblau  
   
  6. Buchberger, B.: Gr¨ obner bases: an algorithmic method in polynomial ideal theory. In: Multidimensional Systems Theory, Progress, Directions and Open Problems. Mathematics Application. vol.16, pp. 184–232. D. Reidel Publ. Co. (1985) 7. Buchberger, B.: Ein Algorithmus zum Auﬃnden der Basiselemente des Restklassenringes nach einem nulldimensionalen Polynomideal. Ph.D. thesis, Universit¨at Innsbruck (1965) 8. Buchberger, B.: Bruno Buchberger’s PhD thesis 1965: an algorithm for ﬁnding the basis elements of the residue class ring of a zero dimensional polynomial ideal. J. Symb. Comput. 41(3–4), 475–511 (2006) 9. Cantor, D.G., Kaltofen, E.: On fast multiplication of polynomials over arbitrary algebras. Acta Inf. 28(7), 693–701 (1991) 10. Collart, S., Kalkbrener, M., Mall, D., Solern´ o, P.: Converting bases with the Gr¨ obner walk. J. Symb. Comput. 24, 465–469 (1997) 11. Cox, D., Little, J., O’Shea, D.: Ideals, Varieties, and Algorithms. An Introduction to Computational Algebraic Geometry and Commutative Algebra, 3rd edn. Springer, New York (2007). https://doi.org/10.1007/978-0-387-35651-8 12. Dickenstein, A., Fitchas, N., Giusti, M., Sessa, C.: The membership problem for unmixed polynomial ideals is solvable in single exponential time. Discrete Appl. Math. 33(1–3), 73–94 (1991) 13. Faug`ere, J.C., Gianni, P., Lazard, D., Mora, T.: Eﬃcient computation of zerodimensional Gr¨ obner bases by change of ordering. J. Symb. Comput. 16(4), 329– 344 (1993) 14. Gebauer, R., M¨ oller, H.M.: On an installation of Buchberger’s algorithm. J. Symb. Comput. 6(2–3), 275–286 (1988) 15. Hartshorne, R.: Algebraic Geometry. Corr. 8rd printing, vol. 52. Springer, New York (1977). https://doi.org/10.1007/978-1-4757-3849-0 16. Hashemi, A., Heintz, J., Pardo, L.M., Solern´ o, P.: Intrinsic complexity for constructing zero-dimensional Gr¨ obner Bases. In: Boulier, F., England, M., Sadykov, T.M., Vorozhtsov, E.V. (eds.) CASC 2020. LNCS, vol. 12291, pp. 245–265. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-60026-6 14 17. Hashemi, A., M.-Alizadeh, B.: Computing minimal polynomial of matrices over algebraic extension ﬁelds. Bull. Math. Soc. Sci. Math. Roum. Nouv. S´er. 56(2), 217–228 (2013) 18. van der Hoeven, J., Lecerf, G.: Accelerated tower arithmetic. J. Complexity 55, 26 (2019). id/No 101402 19. Kreuzer, M., Robbiano, L.: Computational Commutative Algebra. II. Springer, Berlin (2005). https://doi.org/10.1007/3-540-28296-3 20. Langemyr, L.: Algorithms for a multiple algebraic extension II. In: Mattson, H.F., Mora, T., Rao, T.R.N. (eds.) AAECC 1991. LNCS, vol. 539, pp. 224–233. Springer, Heidelberg (1991). https://doi.org/10.1007/3-540-54522-0 111 21. Le Gall, F.: Powers of tensors and fast matrix multiplication. In: Proceedings of ISSAC 2014, pp. 296–303. ACM Press, New York (2014) 22. Lebreton, R.: Relaxed Hensel lifting of triangular sets. J. Symb. Comput. 68, 230– 258 (2015) ´ Fast arithmetic for triangular sets: from 23. Li, X., Moreno Maza, M., Schost, E.: theory to practice. J. Symb. Comput. 44(7), 891–907 (2009) 24. Lichtblau, D.: Practical computations with Gr¨ obner bases (2009). https://www. researchgate.net/publication/260165637 Practical computations with Grobner bases 25. Lichtblau, D.: Applications of strong Gr¨ obner bases over Euclidean domains. Int. J. Algebra 7(5–8), 369–390 (2013)  
   
  Linear Algebra over Algebraic Extension Fields  
   
  161  
   
  ´ Vrbik, P.: Inversion modulo zero-dimensional regular 26. Moreno Maza, M., Schost, E., chains. In: Gerdt, V.P., Koepf, W., Mayr, E.W., Vorozhtsov, E.V. (eds.) CASC 2012. LNCS, vol. 7442, pp. 224–235. Springer, Heidelberg (2012). https://doi.org/ 10.1007/978-3-642-32973-9 19 27. Neunh¨ oﬀer, M., Praeger, C.E.: Computing minimal polynomials of matrices. LMS J. Comput. Math. 11, 252–279 (2008) 28. Noro, M.: An eﬃcient implementation for computing Gr¨ obner bases over algebraic number ﬁelds. In: Iglesias, A., Takayama, N. (eds.) ICMS 2006. LNCS, vol. 4151, pp. 99–109. Springer, Heidelberg (2006). https://doi.org/10.1007/11832225 9 29. Storjohann, A.: An O(n3 ) algorithm for the Frobenius normal form. In: Proceedings of the 1998 International Symposium on Symbolic and Algebraic Computation, ISSAC 1998, Rostock, Germany, 13–15 August 1998, pp. 101–104. ACM Press, New York (1998)  
   
  Range Functions of Any Convergence Order and Their Amortized Complexity Analysis Kai Hormann1(B) , Chee Yap2 , and Ya Shi Zhang2 1  
   
  Università della Svizzera italiana, Lugano, Switzerland [email protected]  2 Courant Institute, NYU, New York City, USA [email protected]  , [email protected]   
   
  Abstract. We address the fundamental problem of computing range functions f for a real function f : R → R. In our previous work [9], we introduced recursive interpolation range functions based on the Cornelius–Lohner (CL) framework of decomposing f as f = g +R, which requires to compute g(I) “exactly” for an interval I. There are two problems: this approach limits the order of convergence to 6 in practice, and exact computation is impossible to achieve in standard implementation models. We generalize the CL framework by allowing g(I) to be approximated by strong range functions g(I; ε), where ε > 0 is a user-speciﬁed bound on the error. This new framework allows, for the ﬁrst time, the design of interval forms for f with any desired order of convergence. To achieve our strong range functions, we generalize Neumaier’s theory of constructing range functions from expressions over a Lipschitz class Ω of primitive functions. We show that the class Ω is very extensive and includes all common hypergeometric functions. Traditional complexity analysis of range functions is based on individual evaluation on an interval. Such analysis cannot diﬀerentiate between our novel recursive range functions and classical Taylor-type range functions. Empirically, our recursive functions are superior in the “holistic” context of the root isolation algorithm Eval. We now formalize this holistic approach by deﬁning the amortized complexity of range functions over a subdivision tree. Our theoretical model agrees remarkably well with the empirical results. Among our previous novel range functions, we identiﬁed a  Lagrange-type range function L 3 f as the overall winner. In this paper, we introduce a Hermite-type range function H 4 f that is even better. We further explore speeding up applications by choosing non-maximal recursion levels. Keywords: Range functions · Root isolation · Interval arithmetic EVAL algorithm · Taylor form · Lagrange form  
   
  1  
   
  ·  
   
  Introduction  
   
  Given a real function f : R → R, the problem of tightly enclosing its range f (I) = {f (x) : x ∈ I} on any interval I is a central problem of interval c The Author(s), under exclusive license to Springer Nature Switzerland AG 2023  F. Boulier et al. (Eds.): CASC 2023, LNCS 14139, pp. 162–182, 2023. https://doi.org/10.1007/978-3-031-41724-5_9  
   
  Range Functions of Any Convergence Order  
   
  163  
   
  and certiﬁed computations [11,13]. The interval form of f may be1 denoted f : R → R, where R is the set of compact intervals and f (I) contains the range f (I). Cornelius & Lohner [3] provided a general framework for constructing such f . First, choose a suitable g : R → R, such that for any interval I ∈ R, we can compute g(I) exactly. Then, f (I) = g(I)+Rg (I), where Rg (x) := f (x)−g(x) is the remainder function. The standard measure for the accuracy of approximate functions like f is their order of convergence n ≥ 1 on I0 ∈ R, i.e., there exists a constant C0 > 0, such that dH (f (I), f (I)) ≤ C0 w(I)n for all I ⊆ I0 , where dH is the Hausdorﬀ distance on intervals and w(I) := b − a is the width of I = [a, b]. Suppose Rg has an interval form Rg with convergence order n ≥ 1. Then, (1) g f (I) := g(I) + Rg (I) is an interval form for f with order of convergence n. This is an immediate consequence of the following theorem. Theorem A [3, Theorem 4]. The width of the remainder part satisfies dH (f (I),  
   
  g f (I))  
   
  ≤ w( Rg (I)).  
   
  Prior to [3], interval forms with convergence order larger than 2 were unknown. Cornelius & Lohner showed that there exists g such that Rg has convergence order up to 6 in practice and up to any n ≥ 1 in theory. Example 1. Let g(x) be the Taylor expansion of f (x) at x = m up to order n ≥ 1 and Rg (x) =  
   
  f (n+1) (ξx ) (n+1)! (x  
   
  − m)n+1 for some ξx between x and m. Then,  
   
  Rg (I) :=  
   
  | f (n+1) (I)| (I − m)n+1 (n + 1)!  
   
  (2)  
   
  is a range function for Rg (I), where I = [a, b] and m = (a + b)/2. Assuming that (n+1)  
   
  I ⊆ I0 for some bounded I0 , we have | f(n+1)!(I)| = O(1). Therefore, (2) implies that Rg (I) has convergence order n + 1, and so does the range function in (1). 1.1  
   
  Why We Must Extend the CL Framework  
   
  Unfortunately, there is an issue with the CL framework. To get arbitrary convergence order n ≥ 1, we must compute the exact range g(I) for a polynomial g of degree n−1. But the endpoints of g(I) might be extrema of g, which are generally irrational algebraic numbers when n ≥ 4. Hence, we cannot compute the “exact range g(I)” in any standard implementation models. Standard implementation models include (i) the IEEE arithmetic used in the majority of implementations, (ii) the Standard Model of Numerical Analysis [8,17], or (iii) bigNumber packages such as GMP [7], MPFR [6], and MPFI [14]. In practice, “real numbers” are represented by dyadic numbers, i.e., rational numbers of the form m2n where 1  
   
  Deﬁnitions of our terminology are collected in Sect. 1.3.  
   
  164  
   
  K. Hormann et al.  
   
  m, n ∈ Z. So, rational numbers like 1/3 cannot be represented √ exactly. Even if we allow arbitrary rational numbers, irrational numbers like 2 are not exact. See, e.g., [20] for an extended discussion of exact computation. In computer algebra systems, the largest set of real numbers which can be computed exactly are the algebraic numbers, but we do not include them under “standard implementation models” because of inherent performance issues. In [9], we (consciously) used the term “exact computation of g(I)” in a sense which is commonly understood by interval and numerical analysts, including Cornelius & Lohner. But ﬁrst let us address the non-interval case: the “exact computation of g(x)”. The common understanding amounts to: g(x) can be computed exactly if g(x) has a closed-f orm expression E(x) over a set Ω of primitive operations.  
   
  (3)  
   
  There is no universal consensus on the√set Ω, but typically all real constants, four rational operations (±, ×, ÷), and · are included. E.g., Neumaier [11, p. 6] allows these additional operations in Ω: |·|, sqr , exp, ln, sin, cos, arctan, where2 sqr denotes squaring. Next, how does the understanding (3) extend to the exact computation of g(I)? Cornelius & Lohner stated a suﬃcient condition that is well-known in interval analysis [3, Theorem 1]: g(I) can be computed exactly if there is an expression E(x) f or g(x) in which the variable x occurs at most once.  
   
  (4)  
   
  It is implicitly assumed in (4) that, given an expression E(x) for g(x), we can compute g(I) by evaluating the interval expression E(I), assuming all the primitive operators in E(x) have exact interval forms. But this theorem has very limited application, and cannot even compute the exact range of a quadratic polynomial g(x) = ax2 + bx + c with ab = 0. Example 2. To overcome the limitations of (4) in the case of a quadratic polynomial g(x) = ax2 +bx+c, we can proceed as follows: ﬁrst compute x∗ = −b/2a, the root of g  (x) = 2ax + b. If I = [x, x]), then g(I) = [min(S), max(S)], where  
   
   {g(x), g(x)}, S := {g(x∗ ), g(x), g(x)},  
   
  if x∗ ∈ I, otherwise.  
   
  We call this the “endpoints algorithm”, since we directly compute the endpoints of g(I). The details when g is a cubic polynomial are derived and implemented in our previous paper [9, Appendix]. How far can we extend this idea? Under the common understanding (3), we need two other ingredients: 2  
   
  The appearance of sqr may be curious, but that is because he will later deﬁne interval forms of the operations in Ω.  
   
  Range Functions of Any Convergence Order  
   
  165  
   
  (E1) The function g(x) must be exactly computable. (E2) The roots of g  (x) must be exactly computable. Note that (E1) is relatively easy to fulﬁll. For instance, g(x) can be any polynomial. However, (E2) limits g to polynomials of degree at most 5, since the roots of g  are guaranteed to have closed form expressions when g  has degree at most 4. Cornelius & Lohner appear to have this endpoint algorithm in mind when they stated in [3, p. 340, Remark 2] that their framework may reach up to order 6 convergence, namely one more than the degree of g. 1.2  
   
  Overview  
   
  In Sect. 2, we present our generalized CL framework for achieving range functions with any order of convergence.In Sect. 3, we provide  details for a new family H with quartic convergence of recursive range operators 3 4, :  = 0, 1, . . . order and recursion level  ≥ 0, based on Hermite interpolation. In Sect. 4, we present our “holistic” framework for evaluating the complexity of range functions. The idea is to amortize the cost over an entire computation tree. Experimental results are in Sect. 5. They show that in the context of the Eval algorithm, H 4  is superior to our previous favourite L . The theoretical model of Sect. 4 is also 3 conﬁrmed by these experiments. Another set of experiments explore the possible speed improvements by non-maximal convergence levels. We conclude in Sect. 6. 1.3  
   
  Terminology and Notation  
   
  This section reviews and ﬁxes some terminology. Let f : Rn → R be an n-variate real-valued function for some n ≥ 0. The arity of f is n. We identify 0-arity functions with real constants. In this paper, we do not assume that real functions are total functions. If f is undeﬁned at x ∈ Rn , we write f (x) ↑; otherwise f (x) ↓. If any component of x is undeﬁned, we also have f (x) ↑. Deﬁne the proper domain of f as dom(f ) := {x ∈ Rm : f (x) ↓}. If S ⊆ Rm , then f (S) ↑ if f is undeﬁned at some x ∈ S; otherwise f (S) := {f (x) : x ∈ S}. Deﬁne the magnitude of S ⊆ R as |S| := max{|x| : x ∈ S}. Note that we use bold font like x to indicate vector variables. The set of compact boxes in Rn is denoted Rn ; if n = 1, we simply write R. The Hausdorﬀ distance on boxes B, B  ∈ Rn is denoted dH (B, B  ). For n = 1, it is often denoted q(I, J) in the interval literature. A box form of f is any function F : Rn → R satisfying two properties: (1) conservative: f (B) ⊆ F (B) for all B ∈ Rn ; (2) convergent: for any sequence (Bi )∞ i=0 of boxes converging to a point, limi→∞ F (Bi ) = f (limi→∞ Bi ). In general, we indicate box forms by a preﬁx meta-symbol “ ”. Thus, instead of F , we write “ f ” for any box form of f . We annotate with subscripts and/or superscripts to indicate speciﬁc box forms. E.g., i f or L f or L i f are all box forms of f . In this paper, we mostly 3  
   
  Each H 4, is an operator that transforms any suﬃciently smooth function f : R → R into the range function H 4, f for f .  
   
  166  
   
  K. Hormann et al.  
   
  focus on n = 1. A subdivision tree is a ﬁnite tree T whose nodes are intervals satisfying this property: if interval [a, b] is a non-leaf node of T , then it has two children represented by the intervals [a, m] and [m, b]. If I0 is the root of T , we call the set D = D(T ) of leaves of T a subdivision of I0 . Let u = (u0 , . . . , um ) denote a sequence of m + 1 distinct points, where the ui ’s are called nodes. Let μ = (μ0 , . . . , μm ), where each μi ≥ 1 is called a multiplicity. The Hermite interpolant of f at u, μ is a polynomial hf (x) = 0, . . . , μi − hf (x; u, μ) such that hf (j) (ui ) = f (j) (ui ) for all i = 0, . . . , m and j = m 1. The interpolant hf (x) is unique and has degree less than d = i=0 μi . If m = 0, then hf (x) is the Taylor interpolant; if μi = 1 for all i, then hf (x) is the Lagrange interpolant.  
   
  2  
   
  Generalized CL Framework  
   
  In this section, we develop an approach to computing range functions of arbitrary convergence order. To avoid the exact range computation, we replace g(I) in (1) by a range function g(I) for g: f (I) := g(I) + Rg (I).  
   
  (5)  
   
  We now generalize Theorem A as follows. Theorem B. With f (I) defined as in (5), we have dH (f (I), f (I)) ≤ dH (g(I), g(I)) + w( Rg (I)).  
   
  Proof. Consider the endpoints of the intervals f (I), g(I), and Rg (I) as given by g(I) = [g(y), g(y)], Rg (I) = [a, b] f (I) = [f (x), f (x)], for some x, x, y, y ∈ I and a, b. We can also write g(I) = [g(y), g(y)] + [ε, ε] for some ε ≤ 0 ≤ ε. Thus we have dH (g(I), g(I)) = max{−ε, ε}, f (I) = [g(y), g(y)] + [ε, ε] + [a, b]. We write the inclusion f (I) ⊆ f (I) in terms of endpoints: [f (x), f (x)] ⊆ [g(y), g(y)] + [ε, ε] + [a, b]. Hence,       dH (f (I), f (I)) = max f (x) − g(y) + ε + a , g(y) + ε + b − f (x) .  
   
  (6)  
   
  Range Functions of Any Convergence Order  
   
  Since w( Rg (I)) = b − a and in view of (6), our theorem follows from   f (x) − g(y) + ε + a ≤ −ε + (b − a),   g(y) + ε + b − f (x) ≤ ε + (b − a).  
   
  167  
   
  (7) (8)  
   
  To show (7), we have, since f (x) ≤ f (y),     f (x) − g(y) + ε + a ≤ f (y) − g(y) + ε + a     = g(y) + Rg (y) − g(y) + ε + a = Rg (y) − ε − a ≤ −ε + (b − a). The proof for (8) is similar. 2.1  
   
  Achieving Any Order of Convergence  
   
  To apply Theorem B, we introduce precision-bounded range functions for g(x), denoted g(I; ε), where ε > 0 is an extra “precision” parameter. The output interval is an outer ε-approximation in the sense that g(I) ⊆ g(I; ε) and dH (g(I), g(I; ε)) ≤ ε. We also call g(I; ε) a strong box function, since it implies box forms in the original sense: e.g., a box form of g may be constructed as g(I) := g(I, w(I)).  
   
  (9)  
   
  The box form in (9) has the pleasing property that w(I) is an implicit precision parameter. Returning to the CL Framework, suppose that f = g + Rg , where g has a strong range function g(I; ε). We now deﬁne the following box form of f : pb f (I)  
   
  := g(I; ε) + Rg (I),  
   
  (10)  
   
  where ε = | Rg (I)|. The subscript in pb refers to “precision-bound”. To compute pb f (I), we ﬁrst compute JR ← Rg (I), then compute Jg ← g(I, |JR |), and ﬁnally return Jg + JR . Corollary 1. The box form Rg (I).  
   
  pb f (I)  
   
  of (10) has the same convergence order as  
   
  For any n ≥ 1, if g(x) is a Hermite interpolant of f of degree n, then Rg (I) has convergence order n + 1 (cf. Example 1). We have thus achieved arbitrary convergence order. Remark 1. Theorem B is also needed to justify the usual implementations of “exact g(I)” under the hypothesis (3) of the CL framework. Given an expression E(x) for g(x), it suﬃces to evaluate it with error at most | Rg (I)|. This can be automatically accomplished in the Core Library using the technique of “precisiondriven evaluation” [21, Sect. 2].  
   
  168  
   
  2.2  
   
  K. Hormann et al.  
   
  Strong Box Functions  
   
  Corollary 1 shows that the “exact computation of g(I)” hypothesis of the CL framework can be replaced by strong box functions of g. We now address the construction of such functions. We proceed in three stages: A. Lipschitz Expressions. Our starting point is the theory of evaluations of expressions over a class Ω of Lipschitz functions, following [11]. Let Ω denote a set of continuous real functions that includes R as constant functions as well as the rational operations. Elements of Ω are called primitive functions. Let Expr(Ω) denote the set of expressions over Ω ∪ X where X = {X1 , X2 , . . .} is a countable set of variables. An expression E ∈ Expr(Ω) is an ordered DAG (directed acyclic graph) whose nodes with outdegree m ≥ 0 are labelled by mary functions of Ω, with variables in X viewed as 0-ary. For simplicity, assume E has a unique root (in-degree 0). Any node of E induces a subexpression. If E involves only the variables in X = (X1 , . . . , Xn ), we may write E(X) for E. We can evaluate E at a ∈ Rn by substituting X ← a and evaluating the functions at each node in a bottom-up fashion. The value at the root is E(a) and may be undeﬁned. If f : Rn → R is a function, we call E an expression forf if the n−1 i symmetric diﬀerence dom(E)Δdom(f ) is a ﬁnite set. E.g., if f (x) = i=0 x , X1n −1 then E(X1 ) = X1 −1 is an expression for f , since f (a) = E(a) for a = 1, but f (1) = n and E(1) ↑. Similarly, we can deﬁne the interval value E(B) at the box B = (I1 , . . . , In ) ∈ Rn . If each f in E is replaced by a box form f , we obtain a box expression E(X). Following [11, pp. 33, 74], we say that E(X) is Lipschitz at B ∈ Rn if the following inductive properties hold: – (Base case) The root of E is labelled by a variable Xi or a constant function. This always holds. – (Induction) Let E = f (E1 , . . . , Em ), where each Ej is a subexpression of E. Inductively, each Ei is Lipschitz at B. Moreover, f (E1 (B), . . . , Em (B)) is deﬁned and f is Lipschitz4 in a neighbourhood U of (E1 (B), . . . , Em (B)) ⊆ Rm . Theorem C [11, p. 34]. If E(x) is a Lipschitz expression on B0 ∈ Rn , then there is a vector  = (1 , . . . , n ) of positive constants such that for all B, B  ⊆ B0 , dH (E(B), E(B  )) ≤  ∗ dH (B, B  ), where dH (B, B  ) = (dH (I1 , I1 ), . . . , dH (In , In )) and ∗ is the dot product. Theorem C can be extended to the box form E(X), and thus E(B) is an enclosure of E(B). To achieve strong box functions, we will next strengthen Theorem C to compute explicit Lipschitz constants. 4  
   
  The concept of a function f (not expression) being Lipschitz on a set U is standard: it means that there exists a vector  = (1 , . . . , m ) of positive constants, such that for all x, y ∈ U ⊆ Rm , |f (x) − f (y)| ≤  ∗ |x − y| where ∗ is the dot product and |x − y| = (|x1 − y1 |, . . . , |xm − ym |). Call  a Lipschitz constant vector for U .  
   
  Range Functions of Any Convergence Order  
   
  169  
   
  B. Lipschitz + Expressions. For systematic development, it is best to begin with an abstract model of computation that assumes f (B) and ∂i f (B) are computable. Eventually, we replace these by f (B) and ∂i f (B), and ﬁnally we make them Turing computable by using dyadic approximations to reals. This follows the “AIE methodology” of [19]. Because of our limited space and scope, we focus on the abstract model. Call Ω a Lipschitz + class if each f ∈ Ω is a Lipschitz+ function in this sense that f has continuous partial derivatives at its proper domain dom(f ) and both f and its gradient ∇f = (∂1 f, . . . , ∂m f ) are locally Lipschitz, i.e., for all a ∈ dom(f ), f is Lipschitz on some neighbourhood U of a. Given an expression E(X) over Ω, we can deﬁne ∇E := (∂1 E, . . . , ∂n E), where each ∂i E(X) is an expression, deﬁned inductively as ⎧ ⎪ if E = const, ⎨0, ∂i E(X) = δ(i = j), (11) if E = Xj , ⎪ ⎩m (∂ f )(E , . . . , E ) · ∂ E , if E = f (E , . . . , E ). 1 m i j 1 m j=1 j Here, δ(i = j) ∈ {0, 1} is Kronecker’s delta function that is 1 if and only if i = j. The above deﬁnition of E(X) being “Lipschitz at B ∈ Rn ” can be naturally extended to “Lipschitz + at B ”, i.e., the inductive properties must also hold for (∂j f )(E1 , . . . , Em ) as well as ∂i Ej (cf. (11)). C. Strong Box Evaluation. Let f : Rn → R be a Lipschitz+ function. Suppose it has a strong approximation function f˜, i.e., f˜: Rn × R>0 → R,  
   
  (12)  
   
  such that |f˜(a; − f (a)| ≤ ε. We show that f has a strong box function. Deﬁne ε) n Δ(f, B) := 12 i=1 |∂i f (B)| · wi (B). Then, for all a ∈ B, we have |f (a) − f (m(B))| ≤ Δ(f, B) by the Mean Value Theorem where m(B) is the midpoint of B. Lemma 1. Let  
   
  J = J(B, ε) := [f˜(m(B); ε/4) ± 12 ε],  
   
  (13)  
   
  where [m±ε] denotes the interval [m−ε, m+ε]. If Δ(f, B) ≤ ε/4, then f (B) ⊆ J and dH (J, f (B)) < ε. Motivated by Lemma 1, we say that a subdivision D of B0 is ε-fine if Δ(f, B) ≤ ε/4 for each B ∈ D. Given an ε-ﬁne subdivision D of B0 , let J(D) := B∈D J(B), where J(B) is deﬁned in (13). Corollary 2. If D is an ε-fine subdivision of B0 , then f (B0 ) ⊆ J(D) and dH (f (B0 ), J(D)) < ε.  
   
  170  
   
  K. Hormann et al.  
   
  Algorithm 1. Fine Subdivision Algorithm Input: (f, B0 , ε) Output: An ε-ﬁne subdivision D of B0 . 1: Let D, Q be queues of boxes, initialized as D ← ∅ and Q ← {B0 }. 2: while Q = ∅ do 3: B ← Q.pop() ← ∇f (B) 4: (J1 , . . . , Jn ) 5: Δ(f, B) ← n i=1 |Ji | · wi (B) 6: if Δ(f, B) ≤ ε/4 then 7: D.push(B) 8: else 9: i∗ ← argmaxi=1,...,n |Ji | · wi (B)  bisect dimension i∗ 10: Q.push(bisect(B, i∗ )) 11: Output D  
   
  Algorithm 1 shows how to compute an ε-ﬁne subdivision of any given B0 . Note that the value of Δ(f, B) is reduced by a factor less than or equal to 1 ) with each bisection, and therefore the subdivision depth is at most (1 − 2n 1 ln(ε/Δ(f, B0 ))/ ln(1− 2n ). This bound is probably overly pessimistic (e.g., |Ji | = |∂i f (B)| is also shrinking with depth). We plan to do an amortized bound of this algorithm. In any case, we are now able to state the key result. Theorem D. Let Ω be a Lipschitz + class, where each f ∈ Ω has a strong approximation function f˜ as in (12). If E(X) ∈ Expr(Ω) is Lipschitz + at B ∈ Rn , then the strong box function E(B; ε) is abstractly computable from the f˜’s. Proof (sketch). Use induction on the structure of E(X). The base case is trivial. If E(X) = f (E1 , . . . , Em ), then, by induction, I˜i = Ei (B; εi ) is abstractly computable (i = 1, . . . , m). Lemma 1 can be generalized to allow the evaluation ˜ ε), where B ˜ = (I˜1 , . . . , I˜m ). of f (B; Which functions satisfy the requirements of Theorem D? The hypergeometric functions (with computable parameters) is one of the most extensive class with Turing-computable strong approximation functions; Johansson [10] describes a state-of-the-art library for such functions. In [4,5], we focused on the real hypergeometric functions and provided a uniform strong approximation algorithm, with complexity analysis for rational input parameters. In this paper, we need strong box functions which were not treated in [5,10]; such extensions could be achieved, because hypergeometric functions are closed under diﬀerentiation. Our Theorem D shows how this is generally achieved under Lipschitz+ Expressions. A complete account of the preceding theory must replace the abstract computational model by box functions f , ﬁnally giving dyadic approximations ˜ f following the AIE methodology in [19]. An implementation of this approach remains future work, and we used the standard model in our experimental results.  
   
  Range Functions of Any Convergence Order  
   
  3  
   
  171  
   
  A Practical Range Function of Order 4  
   
  In this section, we consider a new recursive range function based on Hermite  interpolation, which will surpass the performance of L 3 f [9, Sec. 3.1]. Let h0 be the Hermite interpolant of f based on the values and ﬁrst derivatives at the endpoints of the interval I = [a, b], i.e., h0 is the unique cubic polynomial with h0 (a) = f (a),  
   
  h0 (a) = f  (a),  
   
  h0 (b) = f (b),  
   
  h0 (b) = f  (b).  
   
  With m = (a + b)/2 denoting the midpoint of I, it is not hard to show that h0 can be expressed in centred form as 2  
   
  3  
   
  h0 (x) = c0,0 + c0,1 (x − m) + c0,2 (x − m) + c0,3 (x − m) with coeﬃcients f (a) + f (b) f  (b) − f  (a) − r, 2 4 f  (b) − f  (a) , = 4r  
   
  f (b) − f (a) f  (a) + f  (b) − , 4r 4 f  (a) + f  (b) f (b) − f (a) = − , 4r2 4r3  
   
  c0,0 =  
   
  c0,1 = 3  
   
  c0,2  
   
  c0,3  
   
  where r = (b − a)/2 is the radius of I. Since the remainder Rh0 = f − h0 can be written as Rh0 (x) =  
   
  ω(x) (4) f (ξx ), 4!  
   
  2  
   
  2  
   
  ω(x) = (x − a) (x − b) ,  
   
  for some ξx ∈ I, we can upper bound the magnitude of Rh0 (I) as |Rh0 (I)| ≤ Ω|f (4) (I)|,  
   
  Ω=  
   
  r4 |ω(I)| = . 4! 24  
   
  To further upper bound |f (4) (I)|, following [9, Sec. 3], we consider the cubic Hermite interpolants hj of f (4j) for j = 1, 2, . . . , : 2  
   
  3  
   
  hj (x) = cj,0 + cj,1 (x − m) + cj,2 (x − m) + cj,3 (x − m) with coeﬃcients f (4j) (a) + f (4j) (b) f (4j+1) (b) − f (4j+1) (a) − r, 2 4 f (4j) (b) − f (4j) (a) f (4j+1) (a) + f (4j+1) (b) − , =3 4r 4 f (4j+1) (b) − f (4j+1) (a) , = 4r f (4j+1) (a) + f (4j+1) (b) f (4j) (b) − f (4j) (a) = − . 4r2 4r3  
   
  cj,0 = cj,1 cj,2 cj,3  
   
  172  
   
  K. Hormann et al.  
   
  Denoting the remainder by Rhj = f (4j) − hj and using the same arguments as above, we have |f (4j) (I)| ≤ |hj (I)| + |Rhj (I)| ≤ |hj (I)| + Ω|f (4j+4) (I)|.  
   
  (14)  
   
  By recursively applying (14), we get |f (4) | ≤ |h1 (I)| + Ω|f (8) (I)|   ≤ |h1 (I)| + Ω |h2 (I)| + Ω|f (12) (I)| ≤ · · · ≤  
   
    
   
  (15)  
   
  |hj (I)|Ω j−1 + Ω  | f (4+4) (I)|,  
   
  j=1  
   
  resulting in the remainder bound |Rh0 (I)| ≤ S ,  
   
  S :=  
   
    
   
  |hj (I)|Ω j + Ω +1 | f (4+4) (I)|.  
   
  j=1  
   
  Overall, we get the recursive Hermite form of order 4 and recursion level  ≥ 0, H 4, f (I)  
   
  = h0 (I) + [−1, 1]S ,  
   
  which depends on the 4 + 4 values f (4j) (a),  
   
  f (4j+1) (a),  
   
  f (4j) (b),  
   
  f (4j+1) (b),  
   
  j = 0, . . . , .  
   
  (16)  
   
  If f is analytic and r is suﬃciently small, or if f is a polynomial, then S∞ is a H convergent series, and we deﬁne H 4 f (I) := 4,∞ f (I) as the maximal recursive Hermite form. Clearly, if f is a polynomial of degree at most d − 1, then H 4 f = H f for  = d/4 − 1. 4, To avoid the rather expensive evaluation of the exact ranges hj (I), j = 1, . . . , , we can use the classical Taylor form for approximating them, resulting in the cheaper but slightly less tight range function H 4, f (I)  
   
  = h0 (I) + [−1, 1]S ,  
   
  where S =  
   
    
   
    
   
   |cj,0 | + r|cj,1 | + r2 |cj,2 | + r3 |cj,3 | Ω j + Ω +1 | f (4+4) (I)|.  
   
  j=1  
   
  In case we also have to estimate the range of f  , we can compute the 2 + 2 additional values f (4j+2) (a), and apply computing  
   
  f (4j+2) (b),  
   
  j = 0, . . . ,   
   
  (17)  
   
  H  4, to f . But we prefer to avoid (17) by re-using the data used for H 4, f (I) in the following way. A result by Shadrin [15] asserts that  
   
  Range Functions of Any Convergence Order  
   
  173  
   
  the error between the ﬁrst derivative of f and the ﬁrst derivative of the Lagrange polynomial L(x) that interpolates f at the 4 nodes x0 , . . . , x3 ∈ I satisﬁes |f  (x) − L (x)| ≤  
   
   (I)| (4) |ωL |f (I)|, 4!  
   
  x ∈ I,  
   
  |ω  (I)| (4) |f (I)|, 4!  
   
  x ∈ I.  
   
  3 for ωL (x) = i=0 (x − xi ). As noted by Waldron [18, Addendum], this bound is continuous in the xi , and so we can consider the limit as x0 and x1 approach a and x2 and x3 approach b to get the corresponding bound for the error between f  and the ﬁrst derivative of the Hermite interpolant h0 , |f  (x) − h0 (x)| ≤  
   
  √ Since a straightforward calculation gives ω  (I) = 89 3r3 [−1, 1], we conclude by (15) that √ √ √ 8 3 8 3 r3 (4) 8 3 r 3 S  |f (I)| ≤ = S , |Rh0 (I)| ≤ 9 4! 9 4! Ω 9r resulting in the recursive Hermite forms √ 8 3 H   [−1, 1]S and 3, f (I) = h0 (I) + 9r  
   
  H  3, f (I)  
   
  =  
   
  h0 (I) +  
   
  √ 8 3 [−1, 1]S , 9r  
   
  which have only cubic convergence, but depend on the same data as and  
   
  4  
   
  H 4, f (I).  
   
  H 4, f (I)  
   
  Holistic Complexity Analysis of Range Functions  
   
  By the “holistic complexity analysis” of f (I), we mean to analyse its cost over a subdivision tree, not just its cost at a single isolated interval. The cost for a node of the subdivision tree might be shared with its ancestors, descendants, or siblings, leading to cheaper cost per node. Although we have the Eval algorithm [9, Sec. 1.2] in mind, there are many applications where the algorithms produce similar subdivision trees, even in higher dimensions. 4.1  
   
  Amortized Complexity of  
   
  L 3 f   
   
  We ﬁrst focus on the range function denoted L 3 f in [9, Sec. 3.1]. This was our “function of choice” among the 8 range functions studied in [9, Table 1].  T Empirically, we saw that L 3 has at least a factor of 3 speedup over 2 . Note that T2 was the state-of-the-art range function before our recursive forms; see the last column of the Tables 3 and 4 in [9]. We now show theoretically that the speedup is also 3 if we only consider evaluation complexity. The data actually suggest an asymptotic speedup of at least 3.5—this may be explained by the  
   
  174  
   
  K. Hormann et al.   
   
  T fact that L 3 has order 3 convergence compared to order 2 for 2 . We now seek a theoretical account of the observed speedup5 . In the following, let d ≥ 2. Given any f and interval [a, b], our general goal is to construct a range function f ([a, b]) based on d derivatives of f at points  in [a, b]. In the case of L 3 f ([a, b]), we need these evaluations of f and its higher derivatives:  
   
  f (3j) (a),  
   
  f (3j) (m),  
   
  f (3j) (b),  
   
  j = 0, . . . , d/3 − 1,  
   
  where m = (a + b)/2. That is a total of 3d/3 derivative values. For simplicity,  assume d is divisible by 3. Then the cost for computing L 3 f ([a, b]) is 3d/3 = d. Note that the cost to compute T2 f (I), the maximal Taylor form of order 2, is also d. So there is no diﬀerence between these two costs over isolated intervals.  T over But in a “holistic context”, we see a distinct advantage of L 2 : the 3 L evaluation of 3 f (I) can reuse the derivative values already computed at the parent or sibling of I; no similar reuse is available to T2 .  Given a subdivision tree T , our goal is to bound the cost C3L (T ) of L 3 f  on T , i.e., the total number of derivative values needed to compute L 3 f (I) for all I ∈ T . We will write C3L (n) instead of C3L (T ) when T has n leaves. This is because it is n rather than the actual6 shape of T that is determinative for the complexity. We have the following recurrence  d, if n = 1, (18) C3L (n) = C3L (nL ) + C3L (nR ) − d3 , if n ≥ 2, where the left and right subtrees of the root have nL and nR leaves, respectively. Thus n = nL +nR . Let the intervals I, IL , IR denote the root and its left and right children. The formula for n ≥ 2 in (18) comes from summing three costs: (1) the cost d at the root I; (2) the cost C3L (nL ) but subtracting 2d/3 for derivatives shared with I; (3) the cost C3L (nR ) − 2d/3 attributed to the right subtree. Theorem 1. (Amortized Complexity of  
   
  L 3 )  
   
  The cost of computing  
   
  C3L (n) = (2n + 1) · d3 .  
   
  L 3 f (I)  
   
  is  
   
  (19)  
   
  Thus, the cost per node is ∼ d/3 asymptotically. Proof. The solution (19) is easily shown by induction using the recurrence (18). To obtain the cost per node, we recall that a full binary tree with n leaves has 2n+1 d 2n − 1 nodes. So the average cost per node is 2n−1 · 3 ∼ d/3. This factor of 3 improvement over 5  
   
  6  
   
  T 2  
   
  is close to our empirical data in [9, Sec. 5].   
   
  Note that in our Eval application, we must simultaneously evaluate L 3 f (I) as well    as its derivative L 2 f (I). But it turns out that we can bound the range of f for no additional evaluation cost. If d is not divisible by 3, we can ensure a total cost of d evaluations per interval of the tree but the tree shape will dictate how to distribute these evaluations on the m + 1 nodes.  
   
  Range Functions of Any Convergence Order  
   
  4.2  
   
  Amortized Complexity of  
   
  175  
   
  H 4 f  
   
  We do a similar holistic complexity analysis for the recursive range function H 4, f (I) from Sect. 3 for any given f and  ≥ 0. According to (16), our recursive scheme requires the evaluation of 4( + 1) derivatives of f at the two endpoints of I. Let d = 4( + 1), so that computing H 4, f (I) costs d derivative evaluations. For holistic analysis, let C4H (n) denote the cost of computing H 4, f (I) on a subdivision tree with n leaves. We then have the recurrence  d, if n = 1, H (20) C4 (n) = C4H (nL ) + C4H (nR ) − d2 , if n ≥ 2, where nL + nR = n. The justiﬁcation of (20) is similar to (18), with the slight diﬀerence that the midpoint of an interval J is not evaluated and hence not shared with the children of J. Theorem 2. (Amortized Complexity of  
   
  H 4 )  
   
  The cost of computing  
   
  C4H (n) = (n + 1) · d2 .  
   
  H 4, f (I)  
   
  is  
   
  (21)  
   
  Thus, the cost per node is ∼ d/4 asymptotically. Proof. The solution (21) follows from (20) by induction on n. Since a full binary n+1 tree with n leaves has 2n − 1 nodes, the average cost per node is 2n−1 · d2 ∼ d/4. Therefore, we expect a 4-fold speedup of  
   
  H 4,  
   
  when compared to the state-of-  
   
  T 2,  
   
  and a 4/3-fold or 33% speedup when compared to art our empirical data below. 4.3  
   
  L 3 .  
   
  This agrees with  
   
  Amortized Complexity for Hermite Schemes  
   
  We now generalize the analysis above. Recall from Sect. 1.3 that hf (x) = hf (x; u, μ) is the Hermite interpolant of f with node sequence u = (u0 , . . . , um ) and multiplicity μ = (μ0 , . . . , μm ). We ﬁx the function f : R → R. Assume m ≥ 1 and the nodes are equally spaced over the interval I = [u0 , um ], and all μi are equal to h ≥ 1. Then we can simply write h(x; I) for the interpolant on interval I. Note that h(x; I) has degree less than d := (m + 1)h. Our cost model for computing f (I) is the number of evaluations of derivatives of f at the nodes of I. Based on our recursive scheme, this cost is exactly d = (m + 1)h since I has m + 1 nodes. To amortize this cost over the entire subdivision tree T , deﬁne Nm (T ) to be the number of distinct nodes among all the intervals of T . In other words, if intervals I and J share a node u, then we do not double count u. This can happen only if I and J have an ancestor-descendant relationship or are siblings. Let Tn denote a tree with n leaves. It turns out that  
   
  176  
   
  K. Hormann et al.  
   
  Nm (Tn ) is a function of n, independent of the shape of Tn . So we simply write Nm (n) for Nm (Tn ). Therefore7 the cost of evaluating the tree Tn is Cdh (n) := h · Nm (n),  
   
  where d = (m + 1)h.  
   
  Since Tn has 2n − 1 intervals, we deﬁne the amortized cost of a recursive Hermite range function as C h (n) h . C d = lim d n→∞ 2n − 1 Theorem 3. For a recursive Hermite range function, the number of distinct nodes, the evaluation cost of Tn , and the amortized cost satisfy Nm (n) = mn + 1, Cdh (n) = h(mn + 1), h  
   
  C d = 12 hm = 12 (d − h). Proof. We claim that Nm (n) satisﬁes the recurrence  m + 1, if n = 1, Nm (n) = Nm (nL ) + Nm (nR ) − 1, if 1 < n = nL + nR .  
   
  (22)  
   
  The base case is clear, so consider the inductive case: the left and right subtrees of Tn are TnL and TnR , where n = nL + nR . Then nodes at the root of Tn are already in the nodes at the roots of TnL and TnR . Moreover, the roots of TnL and TnR share exactly one node. This justiﬁes (22). The solution Nm (n) = mn + 1 is immediate. The amortized cost is limn→∞ Cdh (n)/(2n − 1), since the tree Tn has 2n − 1 intervals. h  
   
  Remark 2. Observe that the amortized complexity C d = d−h is strictly less 2 than d, the non-amortized cost. For any given d, we want h as large as possible, but h is constrained to divide d. Hence for d = 4, we choose h = 2. We can also generalize to allow multiplicities μ to vary over nodes: e.g., for d = 5, μ = (2, 1, 2). Remark 3. The analysis of C3L (n) and C4H (n) appears to depend on whether m is odd or even. Surprisingly, we avoided such considerations in the above proof.  
   
  5  
   
  Experimental Results  
   
  To provide a holistic application for evaluating range functions, we use Eval, a simple root isolation algorithm. Despite its simplicity, Eval produces nearoptimal subdivision trees [1,16] when we use T2 f for real functions with simple 7  
   
  The notation “Cdh (n)” does not fully reproduce the previous notations of C3L (n) and  H C4H (n) (which were chosen to be consistent with L 3 and 4 ). Also, d is implicit in the previous notations.  
   
  Range Functions of Any Convergence Order  
   
  177  
   
  Table 1. Size of the Eval subdivision tree. Here, Eval is searching for roots in I0 = [−r(I0 ), r(I0 )]. f  
   
  r(I0 ) ET2  
   
  EL 3  
   
    
   
  EL 4  
   
    
   
    
   
    
   
    
   
  EL 3,10  
   
  EL 3,15  
   
  H EL 3,20 E4  
   
  EH 4  
   
    
   
    
   
    
   
    
   
  EH 4,10  
   
  H EH 4,15 E4,20  
   
  10  
   
  319 663 1379 2147 –  
   
  243 479 1007 1427 2679  
   
  231 463 955 1347 2575  
   
  243 479 1023 1543 3023  
   
  243 479 1007 1451 2699  
   
  243 479 1007 1427 2679  
   
  239 471 967 1351 2591  
   
  239 479 991 1359 2591  
   
  239 479 991 1439 2803  
   
  239 479 991 1363 2603  
   
  239 479 991 1359 2591  
   
  H20 H40 H80 40 H160 H320  
   
  283 539 891 1435 –  
   
  215 423 679 955 2459  
   
  207 415 655 923 2415  
   
  215 423 711 1083 45287  
   
  215 423 679 959 10423  
   
  215 423 679 955 4419  
   
  199 415 659 923 2455  
   
  207 419 683 927 2499  
   
  207 419 695 1023 15967  
   
  207 419 683 927 5195  
   
  207 419 683 927 3119  
   
  M21 M41 1 M81 M161  
   
  169 339 683 –  
   
  113 215 445 905  
   
  109 213 423 857  
   
  113 215 507 7245  
   
  113 215 445 1755  
   
  113 215 445 1047  
   
  105 219 427 861  
   
  105 223 431 861  
   
  105 223 443 2663  
   
  105 223 431 1079  
   
  105 223 431 905  
   
  331 613 1083 1935  
   
  353 633 2597 293509  
   
  353 633 1133 5073  
   
  353 633 1133 2005  
   
  331 615 1097 1959  
   
  335 617 1117 1993  
   
  335 617 1485 42413  
   
  335 617 1117 5289  
   
  335 617 1117 2817  
   
  621 1227 2399  
   
  625 613 613 595 1237 1231 1231 1165 2413 2467 2467 2289  
   
  T20 T40 T80 T160 T320  
   
  W20 485 353 901 633 W40 1000 1583 1133 W80 – 2005 W160 S100 S200 S400  
   
  10  
   
  973 633 609 611 1941 1281 1221 1211 – 2555 2435 2379  
   
  609 613 1187 1201 2319 2339  
   
  roots; see [9, Secs. 1.2, 1.3] for its description and history. We now implemented a version of Eval in C++ for range functions that may use any recursion level (unlike [9], which focused on maximal levels). We measured the size of the Eval subdivision tree as well as the average running time of Eval with ﬂoating point and rational arithmetic on various classes of polynomials. These polynomials have varying root structures: dense with all roots real (Chebyshev Tn , Hermite Hn , and Wilkinson’s Wn ), dense with only 2 real roots (Mignotte cluster M2k+1 ), and sparse without real roots (Sn ). Depending on the family of polynomials, we provide diﬀerent centred intervals I0 = [−r(I0 ), r(I0 )] for Eval to search in, but always such that all real roots are contained in I0 . Our experimental platform is a Windows 10 laptop with a 1.8 GHz Intel Core i7-8550U processor and 16 GB of RAM. We use two kinds of computer arithmetic in our testing: 1024-bit ﬂoating point arithmetic and multi-precision √ rational arithmetic. In rational arithmetic, 3 is replaced by the slightly larger 17320508075688773 × 10−16 . Our implementation, including data and Makeﬁle experiments, may be downloaded from the Core Library webpage [2].  
   
  178  
   
  K. Hormann et al.  
   
  Table 2. Average running time of Eval with 1024-bit ﬂoating point arithmetic in seconds. f  
   
  r(I0 ) ET2  
   
  EL 3  
   
    
   
  EL 4  
   
    
   
    
   
  EL 3,10  
   
  10  
   
  0.0288 0.0152 0.19 0.0669 1.35 0.379 8.23 1.82 – 12.7  
   
  0.0153 0.0663 0.363 1.71 12.1  
   
  0.0179 0.0723 0.366 1.23 5.11  
   
  H20 H40 H80 40 H160 H320  
   
  0.0242 0.0127 0.15 0.0575 0.881 0.259 5.47 1.22 – 11.6  
   
  0.013 0.058 0.255 1.16 11.4  
   
  0.0149 0.0632 0.26 0.854 77.4  
   
  M21 M41 1 M81 M161  
   
  0.0223 0.103 0.707 –  
   
  T20 T40 T80 T160 T320  
   
  W20 0.0492 0.282 W40 1000 1.82 W80 – W160 S100 S200 S400  
   
  10  
   
  1.33 9.55 –  
   
  0.00767 0.032 0.169 1.2  
   
  0.00726 0.0319 0.159 1.13  
   
  0.0222 0.0873 0.426 2.74  
   
  0.0201 0.0874 0.416 2.65  
   
  0.351 2.32 16.6  
   
  0.337 2.21 15.9  
   
  0.00826 0.0349 0.179 5.96  
   
    
   
  EL 3,15 0.0212 0.068 0.386 1.35 5.44  
   
    
   
  EL 3,20  
   
  EH 4  
   
  0.0243 0.0201 0.0726 0.078 0.397 0.398 1.45 1.61 6.19 10.4  
   
  0.0177 0.0204 0.0601 0.0652 0.263 0.266 0.872 0.953 21.2 10.3  
   
  EH 4  
   
    
   
  0.0157 0.0637 0.327 1.38 9.53  
   
    
   
  EH 4,10 0.023 0.0864 0.465 1.56 6.68  
   
    
   
  EH 4,15  
   
    
   
  EH 4,20  
   
      H    L  σ EH σ E4,15 σ E3,15 4  
   
  0.0316 0.102 0.49 2.04 9.29  
   
  0.97 1.05 1.16 1.31 1.33  
   
  0.57 0.71 0.77 1.02 1.62  
   
  0.72 0.98 0.98 1.35 2.34  
   
  0.0159 0.0709 0.273 1.1 9.88  
   
  0.0128 0.0191 0.0226 0.0256 0.0547 0.0862 0.092 0.0923 0.225 0.324 0.349 0.346 0.972 1.1 1.23 1.38 9.21 38.4 15.7 11.3  
   
  0.99 1.05 1.15 1.26 1.26  
   
  0.56 0.63 0.74 1.00 0.74  
   
  0.72 0.96 0.98 1.4 0.55  
   
  0.0101 0.0325 0.168 1.68  
   
  0.0123 0.035 0.173 1.09  
   
  0.00881 0.0391 0.174 1.05  
   
  0.0072 0.0309 0.14 0.898  
   
  0.0212 0.096 0.936 257  
   
  0.0211 0.0918 0.449 5.56  
   
  0.0211 0.0995 0.439 2.68  
   
  0.0261 0.114 0.467 2.52  
   
  0.0205 0.0256 0.0858 0.111 0.38 0.706 2.22 49.8  
   
  0.293 1.2 4.89  
   
  0.331 1.41 5.84  
   
  0.351 1.59 6.66  
   
  0.35 2.02 13.4  
   
  0.286 1.77 12.5  
   
  0.0104 0.0417 0.203 2.96  
   
  0.378 1.6 6.46  
   
  0.0274 0.0944 0.494 1.78 7.84  
   
  0.0125 0.0444 0.217 1.53  
   
  0.0143 0.0489 0.214 1.62  
   
  1.07 1.03 1.21 1.34  
   
  0.61 0.72 0.78 0.79  
   
  0.76 0.99 1.01 0.72  
   
  0.026 0.112 0.576 7.52  
   
  0.0256 0.111 0.562 4.59  
   
  1.08 1.02 1.12 1.23  
   
  0.85 0.78 0.74 0.37  
   
  1.05 0.95 0.95 0.49  
   
  0.436 1.98 8.28  
   
  0.461 2.31 9.98  
   
  1.23 1.31 1.34  
   
  0.81 1.18 2.01  
   
  1.06 1.65 2.85  
   
  We tested eleven versions of Eval that diﬀer by the range functions used for approximating the ranges of f and f  ; see Tables 1–3. Generally, EX k, (X = T, L , H, H  for Taylor, cheap Lagrange, Hermite, cheap Hermite forms) refers to using Eval with the corresponding forms of order k and level  ( may be  L omitted when the level is maximal). The ﬁrst three, ET2 , EL 3 , E4 , are the state of-the-art performers from [9], followed by three non-maximal variants of EL 3 , L H H namely E3, for  ∈ {10, 15, 20}. The next two, E4 and E4 , are based on the   
   
  H  H maximal recursive Hermite forms H 4 f and 3 f and their cheaper variants 4 f   and H 3 f , respectively, and the last three derive from the non-maximal variants of the latter, again for recursion levels  ∈ {10, 15, 20}. Table 1 reports the sizes of the Eval subdivision trees, which serve as a measure of the tightness of the underlying range functions. In each row, the smallest tree size is underlined. As expected, the methods based on range functions with quartic convergence order outperform the others, and in general the tree size decreases as the recursion level increases, except for sparse polynomials. It requires future research to investigate the latter. We further observe that the  H diﬀerences between the tree sizes for EL 4 and E4 are small, indicating that the tightness of a range function is determined mainly by the convergence order, but much less by the type of local interpolant (Lagrange or Hermite). However, as already pointed out in [9, Sec. 5], a smaller tree size does not necessarily cor respond to a faster running time. In fact, EL 3 was found to usually be almost  L as fast as EL 4 , even  though the subdivision trees of E3 are consistently bigL ger than those of E4 . In Tables 2 and 3 we report the running times for our eleven Eval versions and the diﬀerent families of polynomials. Times are given in seconds and averaged over at least four runs (and many more for small degree polynomials). The  
   
  Range Functions of Any Convergence Order  
   
  179  
   
  Table 3. Average running time of Eval with multi-precision rational arithmetic in seconds. f  
   
  r(I0 ) ET2  
   
  EL 3  
   
    
   
  EL 4  
   
    
   
    
   
    
   
    
   
  EL 3,10  
   
  EL 3,15  
   
  EL 3,20  
   
  EH 4  
   
  EH 4  
   
    
   
  EH 4,10  
   
  EH 4,15  
   
  EH 4,20  
   
      H    L  σ EH σ E4,15 σ E3,15 4  
   
    
   
    
   
    
   
  0.0411 0.261 1.76 11.3 –  
   
  0.0223 0.11 0.631 3.14 31.8  
   
  0.0245 0.111 0.611 2.87 30.8  
   
  0.0269 0.121 0.62 2.23 13.7  
   
  0.0325 0.109 0.644 2.36 14.1  
   
  0.0378 0.117 0.658 2.62 15.9  
   
  0.0417 0.146 0.824 3.82 36.2  
   
  0.0233 0.0959 0.524 2.41 21.8  
   
  0.0347 0.126 0.769 2.7 16.6  
   
  0.0429 0.141 0.805 2.96 18.5  
   
  0.0505 0.156 0.781 3.36 21.8  
   
  0.96 1.15 1.2 1.3 1.46  
   
  0.52 0.78 0.78 1.06 1.72  
   
  0.69 1.01 0.98 1.33 2.25  
   
  H20 H40 H80 40 H160 H320  
   
  0.03 0.185 1.1 7.51 –  
   
  0.0169 0.0858 0.399 1.99 29.5  
   
  0.0182 0.0885 0.391 1.89 28.9  
   
  0.0205 0.0956 0.41 1.5 303  
   
  0.025 0.0927 0.412 1.51 67  
   
  0.0296 0.106 0.423 1.65 27.7  
   
  0.0239 0.131 0.541 2.55 39.1  
   
  0.0176 0.0844 0.329 1.47 20.9  
   
  0.0273 0.109 0.495 1.81 123  
   
  0.0338 0.123 0.523 1.87 40.8  
   
  0.0402 0.136 0.504 2.13 26.2  
   
  0.96 1.02 1.21 1.35 1.41  
   
  0.50 0.70 0.76 1.06 0.72  
   
  0.68 0.93 0.97 1.32 0.44  
   
  M21 M41 10 M81 M161  
   
  0.0238 0.124 0.947 –  
   
  0.0115 0.0466 0.298 2.18  
   
  0.0119 0.0478 0.278 2.03  
   
  0.013 0.0529 0.321 13.6  
   
  0.0154 0.0488 0.288 3.29  
   
  0.0179 0.0537 0.293 2.08  
   
  0.015 0.07 0.381 2.64  
   
  0.0106 0.0471 0.236 1.57  
   
  0.0162 0.066 0.346 5.89  
   
  0.0198 0.0746 0.359 2.62  
   
  0.0233 0.0847 0.344 2.42  
   
  1.09 0.99 1.27 1.39  
   
  0.58 0.63 0.83 0.83  
   
  0.75 0.96 1.04 0.66  
   
  W20 0.0652 0.431 W40 1000 2.75 W80 – W160  
   
  0.0332 0.18 0.846 6.28  
   
  0.0346 0.176 0.826 6.1  
   
  0.0344 0.182 1.96 932  
   
  0.0343 0.163 0.877 14.6  
   
  0.0346 0.161 0.847 6.21  
   
  0.0491 0.225 1.15 8.22  
   
  0.0352 0.143 0.708 4.78  
   
  0.0445 0.191 1.41 155  
   
  0.0442 0.195 1.1 19  
   
  0.0452 0.191 1.09 10.6  
   
  0.94 1.26 1.2 1.31  
   
  0.75 0.92 0.77 0.33  
   
  0.97 1.1 0.97 0.43  
   
  0.474 3.65 44.8  
   
  0.457 3.49 42.7  
   
  0.451 2.28 16.4  
   
  0.483 2.59 18.9  
   
  0.477 2.83 21.5  
   
  0.663 4.79 51.8  
   
  0.419 2.68 30  
   
  0.603 2.73 19.6  
   
  0.591 3.13 24.2  
   
  0.57 3.59 28.3  
   
  1.13 1.36 1.50  
   
  0.80 1.17 1.85  
   
  0.98 1.41 2.37  
   
  T20 T40 T80 T160 T320  
   
  S100 S200 S400  
   
  10  
   
  10  
   
  1.35 12 –  
   
    
   
    
   
  L Fig. 1. Speedup σ of EH 4 with respect to E3 for diﬀerent families of polynomials and varying degree: raw (left) and smoothed with moving average over ﬁve points (right).  
   
    
   
    
   
  H last three columns in both tables report the speedup ratios σ(·) of EH 4 , E4,15 , L L and E3,15 with respect to E3 , which was identiﬁed as the overall winner in [9]. In Fig. 1, we provide a direct comparison of the Eval version based on our  L new range function EH 4 with the previous leader E3 : for the test polynomials in our suite, the new function is faster for polynomials of degree greater than 25, with the speedup approaching and even exceeding the theoretical value of 1.33 of Sect. 4.2. In terms of tree size they are similar (diﬀering by less than  5%, Table 1). Hence, EH 4 emerges as the new winner among the practical range functions from our collection.  
   
  180  
   
  5.1  
   
  K. Hormann et al.  
   
  Non-maximal Recursion Levels  
   
  High order of convergence is important for applications such as numerical differential equations. But a sole focus on convergence order may be misleading as noted in [9]: for any convergence order k ≥ 1, a subsidiary measure may be critical in practice. For Taylor forms, this is the refinement level n ≥ k and for our recursive range functions, it is the recursion level  ≥ 0. Note that Ratschek [12] has a notion called “order n ≥ 1” for box forms on rational functions that superﬁcially resembles our level concept. When restricted to polynomials, it diverges from our notion. In other words, we propose to use8 the pair (k, ) of convergence measures in evaluating our range functions. In [9] we focused on maximal levels T (for polynomials) after showing that the ˜ (the minimal level Taylor form of 2  
   
  order 2) is practically worthless for the Eval algorithm. We now experimentally explore the use of non-maximal levels.  
   
    
   
    
   
  H Fig. 2. Speedup σ() of EL 3, (left) and E4, (right) against their maximal level counterparts with respect to  for polynomials of degree 125 (top) and 250 (bottom) from diﬀerent families.  
   
  Figure 2 plots the (potential) level speedup factor σ() against level  ≥ 0. More precisely, consider the time for Eval to isolate the roots of a polynomial 8  
   
  This is a notational shift from our previous paper, where we indexed the recursion level by n ≥ 1. Thus, level  in this paper corresponds to n − 1 in the old notation.  
   
  Range Functions of Any Convergence Order  
   
  181  
   
  f in some interval I0 . Let k, f be a family of range functions of order k, but varying levels  ≥ 0. If Ek, (resp., Ek ) is the running time of Eval using k, f (resp., k,∞ f ), then σ() := Ek /Ek, . Of course, it is only a true speedup if σ() > 1. These plots support our intuition in [9] that minimal levels are rarely useful (except at low degrees). Most strikingly, the graph of σ() shows a characteristic shape of rapidly increasing to a unique maxima and then slowly tapering to 1, especially for polynomials f with high degrees. This suggests that for each polynomial, there is an optimal level to achieve the greatest speedup. In our tests (see Fig. 2), we saw that both the optimal level and the value of the corresponding greatest speedup factor depend on f . Moreover, we observed  L that the achievable speedup tends to be bigger for EH 4 than for E3 and that it increases with the degree of the polynomial f .  
   
  6  
   
  Conclusions and Future Work  
   
  We generalized the CL framework in order to achieve, for the ﬁrst time, range functions of arbitrarily high order of convergence. Our recursive scheme for such constructions is not only of theoretical interest, but are practical as shown by our implementations. Devising speciﬁc “best of a given order” functions like H 4, f (I) is also useful for applications. The amortized complexity model of this paper can be used to analyse many subdivision algorithms in higher dimensions. Moreover, new forms of range primitives may suggest themselves when viewed from the amortization perspective. We pose as a theoretical challenge to explain the observed phenomenon of the “unimodal” behaviour of the σ() plots of Fig. 2 and to seek techniques for estimating the optimal recursion level that achieves the minimum time. Moreover, we would like to better understand why the size of the Eval subdivision tree increases with  in the case of sparse polynomials (see Table 1), while it decreases for all other polynomials from our test suite. Finally, we emphasize that strong box functions have many applications. Another future work therefore is to develop the theory of strong box functions, turning the abstract model of Sect. 2.2 into an eﬀective (Turing) model in the sense of [19].  
   
  References 1. Burr, M., Krahmer, F.: SqFreeEVAL: an (almost) optimal real-root isolation algorithm. J. Symb. Comput. 47(2), 153–166 (2012) 2. Core Library homepage: Software download, source, documentation and links (1999). https://cs.nyu.edu/exact/core_pages/svn-core.html 3. Cornelius, H., Lohner, R.: Computing the range of values of real functions with accuracy higher than second order. Computing 33(3), 331–347 (1984) 4. Du, Z., Eleftheriou, M., Moreira, J., Yap, C.: Hypergeometric functions in exact geometric computation. In: Brattka, V., Schoeder, M., Weihrauch, K. (eds.) Proceedings of 5th Workshop on Computability and Complexity in Analysis, pp. 55–66 (2002)  
   
  182  
   
  K. Hormann et al.  
   
  5. Du, Z., Yap, C.: Uniform complexity of approximating hypergeometric functions with absolute error. In: Pae, S., Park, H. (eds.) Proceedings of 7th Asian Symposium on Computer Math, pp. 246–249 (2006) 6. Fousse, L., Hanrot, G., Lefèvre, V., Pélissier, P., Zimmermann, P.: MPFR: a multiple-precision binary ﬂoating-point library with correct rounding. ACM Trans. Math. Softw. 33(2), Article 13, 15 (2007). https://www.mpfr.org 7. Granlund, T.: The GMP development team: GNU MP: The GNU Multiple Precision Arithmetic Library, 6.2.1. edn. (2020). https://gmplib.org/ 8. Higham, N.J.: Accuracy and Stability of Numerical Algorithms, 2nd edn. Society for Industrial and Applied Mathematics, Philadelphia (2002) 9. Hormann, K., Kania, L., Yap, C.: Novel range functions via taylor expansions and recursive lagrange interpolation with application to real root isolation. In: International Symposium Symbolic and Algebraic Comp. (46th ISSAC), pp. 193– 200 (2021) 10. Johansson, F.: Computing hypergeometric functions rigorously. ACM Trans. Math. Softw. 45(3), 1–26 (2019) 11. Neumaier, A.: Interval Methods for Systems of Equations. Cambridge University Press, Cambridge (1990) 12. Ratschek, H.: Centered forms. SIAM J. Num. Anal. 17(5), 656–662 (1980) 13. Ratschek, H., Rokne, J.: Computer Methods for the Range of Functions. Horwood Publishing Limited, Chichester (1984) 14. Revol, N., Rouillier, F.: Motivations for an arbitrary precision interval arithmetic and the MPFI library. Reliable Comput. 11(4), 275–290 (2005). https://gitlab. inria.fr/mpﬁ/mpﬁ 15. Shadrin, A.: Error bounds for Lagrange interpolation. J. Approx. Theory 80(1), 25–49 (1995) 16. Sharma, V., Yap, C.: Near optimal tree size bounds on a simple real root isolation algorithm. In: 37th International Symposium Symbolic and Algebraic Computation (ISSAC 2012), pp. 319–326 (2012) 17. Trefethen, L.N., Bau, D.: Numerical Linear Algebra. Society for Industrial and Applied Mathematics, Philadelphia (1997) 18. Waldron, S.F.: Lp -error bounds for Hermite interpolation and the associated Wirtinger inequalities. J. Constr. Approx. 13(4), 461–479 (1997) 19. Xu, J., Yap, C.: Eﬀective subdivision algorithm for isolating zeros of real systems of equations, with complexity analysis. In: International Symposium Symbolic and Algebraic Computation (44th ISSAC), pp. 355–362 (2019) 20. Yap, C.K.: On guaranteed accuracy computation. In: Chen, F., Wang, D. (eds.) Geometric Computation, Chap. 12, pp. 322–373. World Scientiﬁc Publishing Co., Singapore (2004) 21. Yu, J., Yap, C., Du, Z., Pion, S., Brönnimann, H.: The design of core 2: a library for exact numeric computation in geometry and algebra. In: Fukuda, K., Hoeven, J., Joswig, M., Takayama, N. (eds.) ICMS 2010. LNCS, vol. 6327, pp. 121–141. Springer, Heidelberg (2010). https://doi.org/10.1007/978-3-642-15582-6_24  
   
  Stability and Zero-Hopf Bifurcation Analysis of the Lorenz–Stenflo System Using Symbolic Methods Bo Huang1 , Xiaoliang Li2 , Wei Niu3,4(B) , and Shaofen Xie5 1  
   
  5  
   
  LMIB – School of Mathematical Sciences, Beihang University, Beijing 100191, China [email protected]  2 School of Business, Guangzhou College of Technology and Business, Guangzhou 510850, China 3 Ecole Centrale de P´ekin, Beihang University, Beijing 100191, China [email protected]  4 Beihang Hangzhou Innovation Institute Yuhang, Hangzhou 310051, China Academy of Mathematics and Systems Science, The Chinese Academy of Sciences, Beijing 100190, China [email protected]   
   
  Abstract. This paper deals with the stability and zero-Hopf bifurcation of the Lorenz–Stenﬂo system by using methods of symbolic computation. Stability conditions on the parameters of the system are derived by using methods of solving semi-algebraic systems. Using the method of algorithmic averaging, we provide suﬃcient conditions for the existence of one limit cycle bifurcating from a zero-Hopf equilibrium of the Lorenz–Stenﬂo system. Some examples are presented to verify the established results. Keywords: Averaging method · Limit cycle Stability · Zero-Hopf bifurcation  
   
  1  
   
  · Symbolic computation ·  
   
  Introduction and Main Results  
   
  In 1963, Edward Lorenz introduced a simpliﬁed mathematical chaotic model for atmospheric convection [1]. The chaotic model is a system of three ordinary differential equations now known as the Lorenz system. Since then, the research on dynamical behaviors of the Lorenz system and its generalizations has attracted great interest of scholars from various ﬁelds; the essence of chaos, characteristics of the chaotic system, bifurcations, and routes to chaos have been extensively studied (see [2–5] for instance). The work was partially supported by National Natural Science Foundation of China (No. 12101032 and No. 12131004), Beijing Natural Science Foundation (No. 1212005), Philosophy and Social Science Foundation of Guangdong (No. GD21CLJ01), Social Development Science and Technology Project of Dongguan (No. 20211800900692). c The Author(s), under exclusive license to Springer Nature Switzerland AG 2023  F. Boulier et al. (Eds.): CASC 2023, LNCS 14139, pp. 183–198, 2023. https://doi.org/10.1007/978-3-031-41724-5_10  
   
  184  
   
  B. Huang et al.  
   
  Hyperchaos, as a dynamic behavior, is far more complex and has a greater potential than chaos in some non-traditional engineering and technological applications. It is well known that the minimal number of dimensions in which continuous-time hyperchaos can occur is 4; therefore, 4D autonomous diﬀerential systems are of main interest for research and applications of hyperchaos, especially 4D Lorenz-type hyperchaotic systems. In 1996, Stenﬂo [6] derived a system to describe the evolution of ﬁnite amplitude acoustic gravity waves in a rotating atmosphere. The Lorenz–Stenﬂo system is described by x˙ = a(y − x) + dw, y˙ = cx − y − xz, z˙ = −bz + xy, w˙ = −x − aw,  
   
  (1)  
   
  where a, b, c, and d are real parameters; a, c, and d are the Prandtl, the Rayleigh, and the rotation numbers, respectively, and b is a geometric parameter. This system is rather simple and reduces to the classical Lorenz system when the parameter associated with the ﬂow rotation, d, is set to zero. System (1) is chaotic as a = 1, b = 0.7, c = 25, and d = 1.5. Figure 1 shows the phase portraits of the system in 3D spaces. This paper focuses on symbolic and algebraic analysis of stability and zeroHopf bifurcation for the Lorenz–Stenﬂo system (1). We remark that, in the past few decades, symbolic methods have been explored extensively in terms of the qualitative analysis of dynamical systems (see [7–14] and the references therein). It should be mentioned that the zero-Hopf bifurcation of a generalized Lorenz– Stenﬂo system was already studied by Chen and Liang in [15]. However, the authors did not notice that the Lorenz–Stenﬂo system itself can exhibit a zeroHopf bifurcation. The main goal of this paper is to ﬁll this gap. Moreover, we study the zero-Hopf bifurcation of the Lorenz–Stenﬂo system in a parametric way by using symbolic methods. We recall that a (complete) zero-Hopf equilibrium of a 4D diﬀerential system is an isolated equilibrium point p0 such that the Jacobian matrix of the system at p0 has a double zero and a pair of purely imaginary eigenvalues. There are many studies of zero-Hopf bifurcations in 3D diﬀerential systems (see [16–21] and the references therein). The zero-Hopf bifurcations of hyperchaotic Lorenz systems can be found in [5,22]. Actually, there are very few results on the n-dimensional zero-Hopf bifurcation with n > 3. Our objective here is to study how many limit cycles can bifurcate from a zero-Hopf equilibrium of system (1) by using the averaging method. Unlike the usual analysis of zeroHopf bifurcation, by means of symbolic computation, we would like to compute a partition of the parametric space of the involved parameters such that, inside every open cell of the partition, the system can have the maximum number of limit cycles that bifurcate from a zero-Hopf equilibrium. On the number of equilibria of the Lorenz–Stenﬂo system, we recall from [6] that system (1) can have three equilibria, including the origin E0 = (x = 0, y = 0, z = 0, w = 0) and the two equilibria  
   
  Stability and Zero-Hopf Bifurcation of the Lorenz-Stenﬂo System  
   
  185  
   
  Fig. 1. The phase portraits of system (1) in diﬀerent 3D projection spaces: a = 1, b = 0.7, c = 25, d = 1.5  
   
    a2 + d 2 b(a2 c − a2 − d) a2 + d w, z = w , w=± x = −aw, y = − a b a2 (a2 + d)  
   
   E± = 2  
   
  2  
   
  −d) if b(aa2 c−a > 0. Otherwise, the origin is the unique equilibrium of the system. (a2 +d) In fact, the above results can be easily veriﬁed by computing the Gr¨ obner basis of the polynomial set {x, ˙ y, ˙ z, ˙ w} ˙ with respect to the lexicographic term ordering determined by x  y  z  w. The ﬁrst goal of this paper is to study conditions on the parameters under which the Lorenz–Stenﬂo system (1) has a prescribed number of stable equilibrium points. Our result on this question is the following, and its proof can be found in Sect. 3.  
   
  Proposition 1. The Lorenz–Stenﬂo system (1) can not have three stable equilibrium points; it has two stable equilibrium points if [a = 1] and one of the following two conditions C1 = [T1 < 0, 0 < T2 , 0 < T3 , T4 < 0, T5 < 0, 0 < T6 ], C2 = [0 < T1 , T2 < 0, 0 < T3 , 0 < T4 , T5 < 0, 0 < T6 ]  
   
  (2)  
   
  186  
   
  B. Huang et al.  
   
  holds; and it has one stable equilibrium point if [a = 1] and one of the following ﬁve conditions C3 = [0 < T1 , 0 < T2 , 0 < T3 , T5 < 0, 0 < T6 ], C4 = [0 < T1 , 0 < T2 , T3 < 0, T4 < 0, T6 < 0], C5 = [0 < T1 , 0 < T2 , 0 < T3 , 0 < T4 , 0 < T5 , 0 < T6 ], C6 = [0 < T1 , 0 < T2 , 0 < T3 , T4 < 0, 0 < T5 , 0 < T6 ],  
   
  (3)  
   
  C7 = [0 < T1 , 0 < T2 , 0 < T3 , T4 < 0, 0 < T5 , T6 < 0] holds. The explicit expressions of Ti are the following: T1 = b,  
   
  T2 = d − c + 1,  
   
  T3 = d + 1,  
   
  T4 = bc − cd + d + 2 d + 1, 2  
   
  T5 = −bcd + bd2 − 3 bc − 2 bd − 3 b − 12 d − 12, T6 = b2 c + 2 b2 d − bcd + bd2 + 2 b2 + 10 bd + 9 b + 6 d + 6. Remark 1. We remark that the condition [a = 1] is used to facilitate the computation of the resulting semi-algebraic system (see Sect. 3) since the algebraic analysis usually involves heavy computation; see [8,9]. Example 1. Let  
   
   1  (a, b, c, d) = 1, , −56, −29 ∈ C4 . 4 Then the Lorenz–Stenﬂo system (1) becomes x˙ = y − x − 29w, y˙ = −56x − y − xz, 1 z˙ = − z + xy, w˙ = −x − w. 4  
   
  (4)  
   
  Its three equilibria are: p1 = (0, 0, 0, 0), p2 = ( 12 , −14, −28, − 12 ) and p3 = (− 12 , 14, −28, 12 ). System (4) has only one stable equilibrium point p1 ; see Fig. 2 (a); (b). Example 2. Let  
   
   1 55 27  (a, b, c, d) = 1, , , − ∈ C2 . 4 32 64 Then the Lorenz–Stenﬂo system (1) becomes x˙ = y − x −  
   
  27 w, 64  
   
  y˙ =  
   
  55 x − y − xz, 32  
   
  (5) 1 z˙ = − z + xy, w˙ = −x − w. 4 Its three equilibria are: 1√ 1 √ 1√ 73 2701, p1 = (0, 0, 0, 0), p2 = ( 2701, , − 2701) 74 128 64 74 √ √ √ 1 1 1 and p3 = (− 74 2701, − 128 2701, 73 64 , 74 2701). System (5) has two stable equilibria p2 and p3 ; see Fig. 2 (c); (d).  
   
  Stability and Zero-Hopf Bifurcation of the Lorenz-Stenﬂo System  
   
  187  
   
  Fig. 2. Numerical simulations of local stability of the Lorenz–Stenﬂo system for the choice of parameter values given in Examples 1 and 2  
   
  Our second goal of this paper is to investigate the bifurcation of periodic solutions at the (complete) zero-Hopf equilibrium (that is, an isolated equilibrium with double zero eigenvalues and a pair of purely imaginary eigenvalues) of system (1). In the following, we characterize the periodic orbits bifurcating from the zero-Hopf equilibrium E0 = (0, 0, 0, 0) of system (1). The main techniques are based on the ﬁrst order averaging method and some algebraic methods, such as the Gr¨ obner basis [23] and real root classiﬁcations [24]. The techniques used here for studying the zero-Hopf bifurcation can be applied in theory to other high dimensional polynomial diﬀerential systems. In the next proposition, we characterize when the equilibrium point E0 = (0, 0, 0, 0) is a zero-Hopf equilibrium. Proposition 2. The origin E0 is a zero-Hopf equilibrium of the Lorenz–Stenﬂo system (1) if the conditions 2a + 1 = 0, b = 0, 3c − 4 > 0 and 12d − 1 > 0 hold.  
   
  188  
   
  B. Huang et al.  
   
  We consider the vector (a, b, c, d) given by 1 a = − + εa1 , b = εb1 , 2 4 2 1 1 + εd1 , c = (β + 1) + εc1 , d = β 2 + 3 3 12  
   
  (6)  
   
  where ε = 0 is a suﬃciently small parameter, the constants β = 0, a1 , b1 , c1 , and d1 are all real parameters. The next result gives suﬃcient conditions for the bifurcation of a limit cycle from the origin when it is a zero-Hopf equilibrium. Theorem 1. For the vector given by (6) and |ε| > 0 suﬃciently small, system (1) has, up to the ﬁrst order averaging method, at most 1 limit cycle bifurcates from the origin, and this number can be reached if one of the following two conditions holds: ¯ C8 = [b1 < 0, 8 β 2 a1 − 4 a1 + 3 c1 − 12 d1 < 0] ∧ C, 2 ¯ C9 = [0 < b1 , 0 < 8 β a1 − 4 a1 + 3 c1 − 12 d1 ] ∧ C,  
   
  (7)  
   
  where C¯ = [β = 0, b1 = 0, a1 = 0, 4β 2 + 1 = 0, 8 β 2 a1 − 4 a1 + 3 c1 − 12 d1 = 0]. Moreover, the only limit cycle that exists (under the condition C8 or C9 ) is unstable. Theorem 1 shows that the Lorenz–Stenﬂo system (1) can have exactly 1 limit cycles bifurcating from the origin if the condition in (7) holds. In the following, we provide a concrete example of system (1) to verify this established result. Corollary 1. Consider the special family of the Lorenz–Stenﬂo system   5 1 (x − y) + ε + w, x˙ = ε + 2 12   8 y˙ = ε + x − xz − y, 3 z˙ = xy + εz,  1 w˙ = −x + ε + w. 2  
   
  (8)  
   
  This system has exactly 1 limit cycle (x(t, ε), y(t, ε), z(t, ε), w(t, ε)) bifurcating from the origin by using the ﬁrst order averaging method, namely,  5 ¯ ¯ cos t + O(ε2 ), ε X3 − R 12  9  ¯ 2 ¯ ¯ y(t, ε) = ε 2X 3 − R cos t − R sin t + O(ε ), 5 ¯ 4 + O(ε2 ), z(t, ε) = εX  1  ¯ 2 ¯ ¯ w(t, ε) = ε 5X 3 − R cos t + 2R sin t + O(ε ), 6 x(t, ε) =  
   
  ¯ 4 ) is a real solution of a semi-algebraic system (see Sect. 5). ¯ X ¯3, X where (R, Moreover, the limit cycle is unstable.  
   
  Stability and Zero-Hopf Bifurcation of the Lorenz-Stenﬂo System  
   
  189  
   
  The rest of this paper is organized as follows. In Sect. 2, we recall the averaging method that we shall use for proving the main results. Section 3 is devoted to prove Proposition 1. The proofs of Proposition 2 and Theorem 1 are given in Sect. 4, and the proof of Corollary 1 is presented in Sect. 5. The paper is concluded with a few remarks.  
   
  2  
   
  Preliminary Results  
   
  The averaging method is one of the best analytical methods to study limit cycles of diﬀerential systems in the presence of a small parameter ε. The ﬁrst order averaging method introduced here was developed in [25]. Recently, this theory was extended to an arbitrary order in ε for arbitrary dimensional diﬀerential systems, see [26]. More discussions on the averaging method, including some applications, can be found in [27,28]. We deal with diﬀerential systems in the form x˙ = εF (t, x) + ε2 R(t, x, ε),  
   
  (9)  
   
  with x ∈ D ⊂ Rn , D a bounded domain, and t ≥ 0. Moreover we assume that F (t, x) and R(t, x, ε) are T -periodic in t. The averaged system associated to system (9) is deﬁned by y˙ = εf 0 (y), where f 0 (y) =  
   
  1 T  

  T  
   
  F (s, y)ds.  
   
  (10)  
   
  (11)  
   
  0  
   
  The next theorem says under what conditions the equilibrium points of the averaged system (10) provide T -periodic orbits for system (9). Theorem 2. We consider system (9) and assume that the functions F , R, Dx F , Dx2 F and Dx R are continuous and bounded by a constant M (independent of ε) in [0, ∞) × D, with −ε0 < ε < ε0 . Moreover, we suppose that F and R are T -periodic in t, with T independent of ε. (i) If p ∈ D is an equilibrium point of the averaged system (10) such that det(Dx f 0 (p)) = 0  
   
  (12)  
   
  then, for |ε| > 0 suﬃciently small, there exists a T -periodic solution x(t, ε) of system (9) such that x(0, ε) → p as ε → 0. (ii) If the equilibrium point y = p of the averaged system (10) has all its eigenvalues with negative real part then, for |ε| > 0 suﬃciently small, the corresponding periodic solution x(t, ε) of system (9) is asymptotically stable and, if one of the eigenvalues has positive real part x(t, ε), it is unstable.  
   
  190  
   
  B. Huang et al.  
   
  The proof of Theorem 2 can be found in [25,28]. It follows from Lemma 1 of [26] that the expression of the limit cycle associated to the zero y∗ of f 0 (y) can be described by x(t, y∗ , ε) = y∗ + O(ε). (13) The averaging method allows to ﬁnd periodic solutions for periodic nonautonomous diﬀerential systems (see (9)). However, here we are interested in using it for studying the periodic solutions bifurcating from a zero-Hopf equilibrium point of the autonomous diﬀerential system (1). The steps for doing that are the following. (i) First we must identify the conditions for which the system has a zero-Hopf equilibrium (see Proposition 2). (ii) We write the linear part of the resulting system (plugging in the conditions obtained in (i)) at the origin in its real Jordan normal form by linear change of variables (x, y, z, w) → (U, V, W, Z). (iii) We scale the variables by setting (U, V, W, Z) = (εX1 , εX2 , εX3 , εX4 ), because the zero-Hopf bifurcation and the averaging method needs such a small parameter  ε, and write the diﬀerential system in the form dR dθ dX3 dX4 where (X1 , X2 , X3 , X4 ) = (R cos θ, R sin θ, X3 , X4 ). , , , dt dt dt dt (iv) We take the angular variable θ as the new independent variable of the differential system. Obtaining a 3-dimensional periodic non-autonomous system dX3 dX4 dR dθ = · · · , dθ = · · · , dθ = · · · in the variable θ. In this way the diﬀerential system is written into the normal form of the averaging method for studying the periodic solutions. (v) Going back through the change of variables we get the periodic solutions bifurcating from the zero-Hopf equilibrium of system (1). Remark 2. A symbolic Maple program for the realization of certain steps on zeroHopf bifurcation analysis of polynomial diﬀerential systems is developed in [29]. The program can be used for computing the higher-order averaged functions of nonlinear diﬀerential systems. The source code of the Maple program is available at https://github.com/Bo-Math/zero-Hopf. More details on the outline of the program, including some applications, can be found in [29].  
   
  3  
   
  Stability Conditions of the Lorenz–Stenflo System  
   
  The goal of this section is to prove Proposition 1. Let (¯ x, y¯, z¯, w) ¯ be the equilibrium point of the Lorenz–Stenﬂo system (1). Namely, we have the algebraic system Ψ = {a(¯ y−x ¯ ) + dw ¯ = 0, c¯ x − y¯ − x ¯z¯ = 0, −b¯ z+x ¯y¯ = 0, −¯ x − aw ¯ = 0}. (14) The Jacobian matrix of the Lorenz–Stenﬂo system evaluated at (¯ x, y¯, z¯, w) ¯ is given by ⎛ ⎞ −a a 0 d ⎜ −¯ x 0 ⎟ ⎜ z + c −1 −¯ ⎟, ⎝ y¯ x ¯ −b 0 ⎠ −1 0 0 −a  
   
  Stability and Zero-Hopf Bifurcation of the Lorenz-Stenﬂo System  
   
  191  
   
  and the characteristic polynomial of this matrix can be written as P (λ) = t0 λ4 + t1 λ3 + t2 λ2 + t3 λ + t4 , where t0 = 1,  
   
  t1 = 2 a + b + 1,  
   
  z+x ¯2 + 2 a + b + d, t2 = a + 2 ab − ac + a¯ 2  
   
  z + 2 a¯ x2 + a¯ xy¯ + a2 + 2 ab + bd + d, t3 = a2 b − a2 c + a2 z¯ − abc + ab¯ z + a2 x ¯2 + a2 x ¯y¯ + a2 b + d¯ x2 + bd. t4 = −a2 bc + a2 b¯ By Routh–Hurwitz’s stability criterion (e.g., [30]), (¯ x, y¯, z¯, w) ¯ is a stable equilibrium point if the following algebraic system is satisﬁed D1 = t1 = 2 a + b + 1 > 0,   t1 t0 xy¯ + b¯ x2 + 4 a2 + 4 ab D2 = det = 2 a3 + 4 a2 b − a2 c + a2 z¯ + 2 ab2 − a¯ t3 t2 ¯2 + 2 a + b > 0, − ac + 2 ad + a¯ z + b2 + x ⎞ ⎛ t1 t0 0 D3 = det ⎝ t3 t2 t1 ⎠ = −7 a3 bc + 2 abd − 4 a2 bc − 2 a3 b2 c + 8 a2 bd − ab2 c 0 t4 t3  4 − 3 a bc + a3 bc2 − a2 b3 c − a2 x ¯2 y¯2 + 2 ad2 + a3 c2 + 2 a3 + a4 + a3 b + a3   + a2 b z¯2 + 2 a5 + 3 a4 b − 2 a4 c + 2 a3 b2 − 2 a3 bc + a2 b3 + 5 a4 + 7 a3 b − 2 a3 c + 2 a3 d + 3 a2 b2 − 2 a2 bc + 3 a2 bd + ab3 + 3 a3 + 4 a2 b + a2 d + ab2   + abd + ad z¯ + (2 ab + 2 a) x ¯4 + 4 a3 b − 2 a3 c + 4 a2 b2 − a2 bc − ab2 c  2 ¯ + 4 a4 + 4 a3 + 8 a2 b − 3 a2 c + 4 ab2 − abc − 4 abd + 4 a2 + 4 ab − 4 ad x   ¯y¯z¯ − 3 a2 bcd − 2 a5 c + a4 c2 + 2 a5 b + 4 a4 b2 + 2 a5 − abcd + −a2 b + a2 x + 2 ab3 + 4 a2 d + 2 ab2 + 2 ad + 8 a4 b − 5 a4 c + 10 a3 b2 − 3 a3 c + 4 a3 d + 8 a2 b2 + 10 a3 b + 4 a2 b + 4 a2 b3 − ab3 c + 2 ab3 d − a2 cd + 2 ab2 d + 2 abd2  + − 2a4 − a3 b + a2 b2 + a2 bc − a3 − a2 c + 2a2 d + ab2 − abd + a2 + ab   − ad x ¯y¯ + 4 a3 bd − 2 a3 cd − 3 a2 b2 c + 4 a2 b2 d + a2 bc2 + 2 a3 b3 + − 2 a2  3   2 + ab + a x ¯ y¯ + 2 a3 + a2 b + ab2 + 3 a2 + ab x ¯ z¯ − acd > 0, z + a2 x ¯2 + a2 x ¯y¯ + a2 b + d¯ x2 + bd > 0. D4 = t4 = −a2 bc + a2 b¯  
   
  (15)  
   
  Combining (14) and (15), we see that the Lorenz–Stenﬂo system has a prescribed number (say k) of stable equilibrium points if the following semi-algebraic system has k distinct real solutions:  a(¯ y−x ¯ ) + dw ¯ = 0, c¯ x − y¯ − x ¯z¯ = 0, −b¯ z+x ¯y¯ = 0, −¯ x − aw ¯ = 0, (16) D1 > 0, D2 > 0, D3 > 0, D4 > 0, where x ¯, y¯, z¯, and w ¯ are the variables. The above semi-algebraic system may be solved by the method of discriminant varieties of Lazard and Rouillier [31]  
   
  192  
   
  B. Huang et al.  
   
  (implemented as a Maple package by Moroz and Rouillier), or the method of Yang and Xia [24] for real solution classiﬁcation (implemented as a Maple package DISCOVERER by Xia [32]; see also the recent improvements in [33] as well as the Maple package RegularChains[SemiAlgebraicSetTools]). However, in the presence of several parameters, the Yang–Xia method may be more eﬃcient than that of Lazard–Rouillier, see [8]. Note that system (16) contains four free parameters a, b, c, d, and the total degree of the involved polynomials is 4, which makes the computation very difﬁcult. In order to obtain simple suﬃcient conditions for system (16) to have a prescribed number of stable equilibrium points, the computation is done under the constraint [a = 1]. By using DISCOVERER or RegularChains, we obtain that system (16) has exactly two distinct real solutions with respect to the variables x ¯, y¯, z¯, w ¯ if the condition C1 or C2 in (2) holds, and it has only one real solution if one of the conditions in (3) holds; system (16) can not have three distinct real solutions. This ends the proof of Proposition 1.  
   
  4  
   
  Zero-Hopf Bifurcation of the Lorenz–Stenflo System  
   
  This section is devoted to the proofs of Proposition 2 and Theorem 1. Proof (Proof of Proposition 2). The characteristic polynomial of the linear part of the Lorenz–Stenﬂo system at the origin E0 is   p(λ) = λ4 + (2 a + b + 1) λ3 + a2 + 2 ba − ac + 2 a + b + d λ2 (17)   + a2 b − a2 c − abc + a2 + 2 ba + db + d λ − a2 bc + a2 b + db. Imposing that p(λ) = λ2 (λ2 + β 2 ) with β = 0, we obtain a = − 12 , b = 0, 3c − 4 = 12d − 1 = 4β 2 > 0. This completes the proof. Proof (Proof of Theorem 1). Consider the vector deﬁned by (6), then the Lorenz–Stenﬂo system becomes     1 2 1 1 x˙ = − + εa1 (y − x) + β + + εd1 w, 2 3 12   4 2 (β + 1) + εc1 x − y − xz, y˙ = 3 (18) z˙ = −εb1 z + xy,   1 w˙ = −x − − + εa1 w. 2 We need to write the linear part of system (18) at the origin in its real Jordan normal form ⎛ ⎞ 0 −β 0 0 ⎜β 0 0 0⎟ ⎜ ⎟ (19) ⎝ 0 0 0 0⎠, 0 0 0 0  
   
  Stability and Zero-Hopf Bifurcation of the Lorenz-Stenﬂo System  
   
  193  
   
  when ε = 0. For doing that, we perform the linear change of variables (x, y, z, w) → (U, V, W, Z) given by  2  2   4β + 1 W 4β + 1 U + , x=− 12β 2 12β 2  2  2  2     4β + 1 U β + 1 4β 2 + 1 W 4β + 1 V y=− + − , 9β 2 9β 9β 2 (20) z = βZ,  2  4β + 1 W U V + w=− 2 + . 6β 3β 6β 2 In these new variables (U, V, W, Z), system (18) becomes a new system which ˙ , Z). ˙ By computing the second order Taylor expansion can be written as (U˙ , V˙ , W of expressions in this new system, with respect to ε, about the point ε = 0, we obtain 1 (U Z − W Z) + εF1,1 (U, V, W, Z), U˙ = −βV + 4β 1 V˙ = βU + (ZW − ZU ) + εF1,2 (U, V, W, Z), 2 ˙ = 1 (ZU − ZW ) + εF1,3 (U, V, W, Z), W 4β  2 2  4β + 1  2 2 2 2 ˙ Z= U + (β + 1)W − (β + 2)U W + β(U V − V W ) − εb1 Z, 108β 5 (21) where   1  1 16 β 4 a1 16 β 4 a1 + 8 β 2 a1 − 12 β 2 d1 + a1 − 6 d1 V − 2 3β (4 β + 1) 12β 2   1 16 β 4 a1 + 20 β 2 a1 + 24 β 2 d1 + 4 a1 − 3 c1 + 12 d1 W + 2 2 12β (4 β + 1)  + 20 β 2 a1 − 12 c1 β 2 + 24 β 2 d1 + 4 a1 − 3 c1 + 12 d1 U,  2  4 β 2 c1 + c1 − 2 d1 c1 − 2 d1 1 F1,2 = − 2 4 β a1 + a1 − 2 d1 V − W+ U, 4β + 1 2β 2β (4 β 2 + 1)  2  1  1 F1,3 = 4 β a1 + a1 − 6 d1 V − 16 β 2 a1 + 4 a1 − 3 c1 3β (4 β 2 + 1) 12β 2    1 16 β 2 a1 − 12 c1 β 2 + 4 a1 − 3 c1 + 12 d1 U. + 12 d1 W + 2 2 12β (4 β + 1) F1,1 =  
   
  After doing step (iii) and step (iv) (see Sect. 2), we write the diﬀerential system (21) into the normal form of the averaging method. By computing the ﬁrst order averaged functions f 0 (y) in (11) (where y = (R, X3 , X4 )), we obtain f 0 (y) = (f1,1 (y), f1,3 (y), f1,4 (y)), where  
   
  194  
   
  B. Huang et al.  
   
  R ¯ f1,1 (R, X3 , X4 ), 24β 3 1 ¯ f1,3 (y) = − f1,3 (R, X3 , X4 ), 12β 3 1 ¯ f1,4 (y) = f1,4 (R, X3 , X4 ), 216β 6  
   
  f1,1 (y) = −  
   
  (22)  
   
  with f¯1,1 (R, X3 , X4 ) = 8β 2 a1 − 3βX4 − 4a1 + 3c1 − 12d1 ,   f¯1,3 (R, X3 , X4 ) = X3 16β 2 a1 + 3βX4 + 4a1 − 3c1 + 12d1 ,     f¯1,4 (R, X3 , X4 ) = 16β 4 + 8β 2 + 1 R2 + 32β 6 + 48β 4 + 18β 2 + 2 X32 − 216β 5 X4 b1 . It is obvious that system (22) can have at most one real solution with R > 0. Hence, system (18) can have at most one limit cycle bifurcating from the origin. Moreover, the determinant of the Jacobian of (f1,1 , f1,3 , f1,4 ) is ⎛ ∂f1,1 ∂f1,1 ∂f1,1 ⎞ ∂R  
   
  ⎜ 1,3 D1 (R, X3 , X4 ) = det ⎝ ∂f∂R ∂f1,4 ∂R  
   
  ∂X3 ∂X4 ∂f1,3 ∂f1,3 ⎟ ∂X3 ∂X4 ⎠ ∂f1,4 ∂f1,4 ∂X3 ∂X4  
   
  =  
   
  1 ¯ 1 (R, X3 , X4 ), ·D 10368 β 11  
   
  where ¯ 1 (R, X3 , X4 ) = −4608 β 8 a1 2 b1 + 1152 β 6 a1 2 b1 − 864 β 6 a1 b1 c1 + 3456 β 6 a1 b1 d1 D + 576 β 4 a1 2 b1 − 864 β 4 a1 b1 c1 + 3456 β 4 a1 b1 d1 + 324 β 4 b1 c1 2 − 2592 β 4 b1 c1 d1  + 5184 β 4 b1 d1 2 + 256 β 6 a1 + 192 β 4 a1 − 48 β 4 c1 + 192 β 4 d1 + 48 β 2 a1   − 24 β 2 c1 + 96β 2 d1 + 4a1 − 3c1 + 12d1 R2 + 324β 6 X42 b1 + − 256β 8 a1 − 256β 6 a1 − 96β 6 c1 + 384β 6 d1 + 48β 4 a1 − 144β 4 c1 + 576β 4 d1 + 56β 2 a1  − 54β 2 c1 + 216β 2 d1 + 8a1 − 6c1 + 24d1 X32 + (864β 7 a1 b1 + 864β 5 a1 b1   − 648β 5 b1 c1 + 2592β 5 b1 d1 )X4 + 96 β 7 + 144 β 5 + 54 β 3 + 6 β X4 X3 2 + (48 β 5 + 24 β 3 + 3 β)X4 R2 . It follows from Theorem 2 that system (18) can have one limit cycle bifurcating from the origin if the semi-algebraic system has exactly one real solution:  f¯1,1 (R, X3 , X4 ) = f¯1,3 (R, X3 , X4 ) = f¯1,4 (R, X3 , X4 ) = 0, (23) ¯ 1 (R, X3 , X4 ) = 0, β = 0 R > 0, D where R, X3 , and X4 are the variables. Using DISCOVERER (or the package RegularChains[SemiAlgebraicSetTools] in Maple), we ﬁnd that system (18) has exactly one real solution if and only if the one of the conditions C8 and C9 in (7) holds.  
   
  Stability and Zero-Hopf Bifurcation of the Lorenz-Stenﬂo System  
   
  195  
   
  Remark that the stability conditions of the limit cycle may be derived by using the Routh–Hurwitz criterion to the characteristic polynomial of the Jacobian matrix of (f1,1 , f1,3 , f1,4 ). In other words, more constraints on the principal diagonal minors of the Hurwitz matrix should be added to the algebraic system (23). By using similar techniques we can verify that the resulting semialgebraic system has no real solution with respect to the variables R, X3 , X4 . Hence, we complete the proof of Theorem 1.  
   
  5  
   
  Zero-Hopf Bifurcation in a Special Lorenz–Stenflo System  
   
  Since the proof of Corollary 1 is very similar to that of Theorem 1, we omit some steps in order to avoid some long expressions.  dθ dX3 dX4 (step (iii) in , , , The corresponding diﬀerential system dR dt dt dt dt Sect. 2) associated to system (8) now becomes 1 dR =ε (−30 R cos θX4 − 154 R cos θ + 30 X3 X4 + 30 X3 ) sin θ dt 60 103 1 1 R cos2 θ − cos θX3 X4 + R cos2 θX4 − 4 60 4 7 7  2 cos θX3 + R + O(ε ), + 12 5   1  dθ =1+ε − 15R cos θX4 + 103R cos θ + 15X3 X4 − 35X3 sin θ dt 60R 1  − 30R cos2 θX4 − 154R cos2 θ + 30 cos θX3 X4 + 30 cos θX3 + 60R   + 172 R + O(ε2 ),  1  11 dX3 1 11 23 = ε − X3 X4 + R cos θX4 + X3 − R cos θ − R sin θ + O(ε2 ), dt 4 4 12 60 15  1   25 2 25 dX4 2 2 =ε 25 cos θR − 25RX3 sin θ + R cos θ − R cos θX3 dt 108 108 36  25 + X32 + X4 + O(ε2 ). 54 (24) Hence, we have the normal form of averaging (step (iv) in Sect. 2) dR dR/dt = , dθ dθ/dt  
   
  dX3 dX3 /dt = , dθ dθ/dt  
   
  dX4 dX4 /dt = . dθ dθ/dt  
   
  (25)  
   
  In order to ﬁnd the limit cycles of system (8), we must study the real roots of the ﬁrst order averaged functions 1 13 f1,1 (R, X3 , X4 ) = X4 R + R, 8 24 1 11 (26) f1,3 (R, X3 , X4 ) = − X4 X3 + X3 , 4 12 25 2 25 2 R + X + X4 . f1,4 (R, X3 , X4 ) = 216 54 3  
   
  196  
   
  B. Huang et al.  
   
  Moreover, the determinant of the Jacobian of (f1,1 , f1,3 , f1,4 ) is 325 2 1 2 1 25 2 143 X4 − X4 + X3 X4 + + X 32 48 864 288 2592 3 (27) 25 275 R 2 X4 − R2 . + 3456 10368 Using the built in Maple command RealRootIsolate (with the option ‘abserr’= 1/1010 ) to the semi-algebraic system  f1,1 (R, X3 , X4 ) = 0, f1,3 (R, X3 , X4 ) = 0, f1,4 (R, X3 , X4 ) = 0, (28) R > 0, D1 (R, X3 , X4 ) = 0, D1 (R, X3 , X4 ) = −  
   
  we obtain a list of one real solution:     ¯ ≈ 6.1185 ∈ 6265 , 50127 , X ¯ 3 = 0, X ¯ 4 = − 13 . R 1024 8192 3 This veriﬁes that system (8) has exactly one limit cycle bifurcating from the origin. Now we shall present the expression of the limit cycle. The limit cycles Λ ¯ X ¯3, X ¯4) of system (25) associated to system (8) and corresponding to the zero (R, given by (28) can be written as {(R(θ, ε), X3 (θ, ε), X4 (θ, ε)), θ ∈ [0, 2π]}, where from (13) we have ⎞ ⎛ ⎞ ⎛ ¯ R R(θ, ε) ¯ 3 ⎠ + O(ε). (29) Λ := ⎝X3 (θ, ε)⎠ = ⎝X ¯4 X X4 (θ, ε) ⎛ ∂f1,1 ∂f1,1 ∂f1,1 ⎞ ∂R  
   
  ⎜ 1,3 Moreover, the eigenvalues of the Jacobian matrix ⎝ ∂f∂R ∂f1,4 ∂R  
   
  ∂X3 ∂X4 ∂f1,3 ∂f1,3 ⎟ ∂X3 ∂X4 ⎠ ∂f1,4 ∂f1,4 ∂X3 ∂X4  
   
  at the  
   
  ¯ 4 ) are about (−0.6546509493, 1.6546509493, 2). We have the ¯ X ¯3, X point (R, corresponding limit cycles Λ is unstable. Further, in system (24), the limit cycle Λ writes as ⎞ ⎛ ⎞ ⎛ ¯ R R(t, ε) ⎜ θ(t, ε) ⎟ ⎜ t ⎟ ⎟ ⎜ ⎟ + O(ε). ⎜ (30) ¯3⎠ ⎝X3 (t, ε)⎠ = ⎝X ¯ X4 X4 (t, ε) Finally, going back through the changes of variables, (X1 , X2 , X3 , X4 ) → (R cos θ, R sin θ, X3 , X4 ), (U, V, W, Z) → (εX1 , εX2 , εX3 , εX4 ), and (x, y, z, w) → (U, V, W, Z) given by (20), we have for system (8) the limit cycle:  5 ¯ ¯ cos t + O(ε2 ), ε X3 − R x(t, ε) = 12  9  ¯ 2 ¯ ¯ y(t, ε) = ε 2X 3 − R cos t − R sin t + O(ε ), 5 (31) ¯ 4 + O(ε2 ), z(t, ε) = εX  1  ¯ 2 ¯ ¯ w(t, ε) = ε 5X 3 − R cos t + 2R sin t + O(ε ). 6 This completes the proof of Corollary 1.  
   
  Stability and Zero-Hopf Bifurcation of the Lorenz-Stenﬂo System  
   
  6  
   
  197  
   
  Conclusions  
   
  In this paper, using symbolic computation, we analyzed the conditions on the parameters under which the Lorenz–Stenﬂo diﬀerential system has a prescribed number of (stable) equilibrium points. Suﬃcient conditions for the existence of one limit cycle bifurcating from the origin of the Lorenz–Stenﬂo system are derived by making use of the averaging method, as well as the methods of real solution classiﬁcation. The special family of the Lorenz–Stenﬂo system (8) was provided as a concrete example to verify our established result. The algebraic analysis used in this paper is relatively general and can be applied to other ndimensional diﬀerential systems. The zero-Hopf bifurcation of limit cycles from the equilibrium point (other than the origin) of the Lorenz–Stenﬂo system is also worthy of study. We leave this as a future problem.  
   
  References 1. Lorenz, E.N.: Deterministic nonperiodic ﬂow. J. Atmos. Sci. 20, 130–141 (1963) 2. Sparrow, C.: The Lorenz Equations: Bifurcation, Chaos, Strange Attractors; Applied Mathematical Sciences. Strange Attractors; Applied Mathematical Sciences. Springer, New York (1982). https://doi.org/10.1007/978-1-4612-5767-7 3. Robinson, C.: Nonsymmetric Lorenz attractors from a homoclinic bifurcation. SIAM J. Math. Anal. 32, 119–141 (2000) 4. Yang, Q., Chen, G., Huang, K.: Chaotic attractors of the conjugate Lorenz-type system. Int. J. Bifurc. Chaos 17, 3929–3949 (2007) 5. Montiel, L., Llibre, J., Stoica, C.: Zero-Hopf bifurcation in a hyperchaotic Lorenz system. Nonlinear Dyn. 75, 561–566 (2014) 6. Stenﬂo, L.: Generalized Lorenz equations for acoustic-gravity waves in the atmosphere. Physica Scripta 53, 83–84 (1996) 7. Wang, D., Xia, B.: Stability analysis of biological systems with real solution classiﬁcation. In: Proceedings of ISSAC 2005, pp. 354–361. ACM Press, New York (2005) 8. Niu, W., Wang, D.: Algebraic approaches to stability analysis of biological systems. Math. Comput. Sci. 1, 507–539 (2008) 9. Li, X., Mou, C., Niu, W., Wang, D.: Stability analysis for discrete biological models using algebraic methods. Math. Comput. Sci. 5, 247–262 (2011) 10. Niu, W., Wang, D.: Algebraic analysis of stability and bifurcation of a selfassembling micelle system. Appl. Math. Comput. 219, 108–121 (2012) 11. Chen, C., Corless, R., Maza, M., Yu, P., Zhang, Y.: An application of regular chain theory to the study of limit cycles. Int. J. Bifur. Chaos 23, 1350154 (2013) 12. Boulier, F., Han, M., Lemaire, F., Romanovski, V.G.: Qualitative investigation of a gene model using computer algebra algorithms. Program. Comput. Softw. 41(2), 105–111 (2015). https://doi.org/10.1134/S0361768815020048 13. Boulier, F., Lemaire, F.: Finding ﬁrst integrals using normal forms modulo diﬀerential regular chains. In: Gerdt, V.P., Koepf, W., Seiler, W.M., Vorozhtsov, E.V. (eds.) CASC 2015. LNCS, vol. 9301, pp. 101–118. Springer, Cham (2015). https:// doi.org/10.1007/978-3-319-24021-3 8 14. Huang, B., Niu, W., Wang, D.: Symbolic computation for the qualitative theory of diﬀerential equations. Acta. Math. Sci. 42B, 2478–2504 (2022)  
   
  198  
   
  B. Huang et al.  
   
  15. Chen, Y., Liang, H.: Zero-zero-Hopf bifurcation and ultimate bound estimation of a generalized Lorenz-Stenﬂo hyperchaotic system. Math. Methods Appl. Sci. 40, 3424–3432 (2017) 16. Llibre, J., Buzzi, C.A., da Silva, P.R.: 3-dimensional Hopf bifurcation via averaging theory. Disc. Contin. Dyn. Syst. 17, 529–540 (2007) 17. Llibre, J., Makhlouf, A.: Zero-Hopf periodic orbits for a R¨ ossler diﬀerential system. Int. J. Bifurc. Chaos 30, 2050170 (2020) 18. Sang, B., Huang, B.: Zero-Hopf bifurcations of 3D quadratic Jerk system. Mathematics 8, 1454 (2020) 19. Tian, Y., Huang, B.: Local stability and Hopf bifurcations analysis of the Muthuswamy-Chua-Ginoux system. Nonlinear Dyn. (2), 1–17 (2022). https://doi. org/10.1007/s11071-022-07409-3 20. Guckenheimer, J., Holmes, P.: Nonlinear Oscillations, Dynamical Systems, and Bifurcations of Vector Fields. Springer, New York (1993). https://doi.org/10.1007/ 978-1-4612-1140-2 21. Kuznetsov, Y.: Elements of Applied Bifurcation Theory. Springer, New York (2004) 22. Llibre, J., Candido, M.R.: Zero-Hopf bifurcations in a hyperchaotic Lorenz system II. Int. J. Nonlinear Sci. 25, 3–26 (2018) 23. Buchberger, B.: Gr¨ obner bases: an algorithmic method in polynomial ideal theory. In: Bose, N.K. (ed.) Multidimensional Systems Theory, pp. 184–232. Reidel, Dordrecht (1985) 24. Yang, L., Xia, B.: Real solution classiﬁcations of parametric semi-algebraic systems. In: Dolzmann A., Seidl A., Sturm T. (eds.) Algorithmic Algebra and Logic. Proceedings of the A3L, Norderstedt, Germany, pp. 281–289 (2005) 25. Buicˇ a, A., Llibre, J.: Averaging methods for ﬁnding periodic orbits via Brouwer degree. Bull. Sci. Math. 128, 7–22 (2004) 26. Llibre, J., Novaes, D.D., Teixeira, M.A.: Higher order averaging theory for ﬁnding periodic solutions via Brouwer degree. Nonlinearity 27, 563–583 (2014) 27. Sanders, J.A., Verhulst, F., Murdock, J.: Averaging Methods in Nonlinear Dynamical Systems, 2nd edn. Applied Mathematical Sciences Series Volume 59. Springer, New York (2007). https://doi.org/10.1007/978-0-387-48918-6 28. Llibre, J., Moeckel, R., Sim´ o, C.: Central conﬁguration, periodic orbits, and hamiltonian systems. In: Advanced Courses in Mathematics-CRM Barcelona Series. Birkh¨ auser, Basel, Switzerland (2015) 29. Huang, B.: Using symbolic computation to analyze zero-Hopf bifurcations of polynomial diﬀerential systems. In: Proceedings of ISSAC 2023, pp. 307–314. ACM Press, New York (2023). https://doi.org/10.1145/3597066.3597114 30. Lancaster, P., Tismenetsky, M.: The Theory of Matrices: With Applications. Academic Press, London (1985) 31. Lazard, D., Rouillier, F.: Solving parametric polynomial systems. J. Symb. Comput. 42, 636–667 (2007) 32. Xia, B.: DISCOVERER: a tool for solving semi-algebraic systems. ACM Commun. Comput. Algebra 41, 102–103 (2007) 33. Chen, C., Davenport, J.H., May, J.P., Moreno Maza, M., Xia, B., Xiao, R.: Triangular decomposition of semi-algebraic systems. J. Symb. Compt. 49, 3–26 (2013)  
   
  Non-principal Branches of Lambert W. A Tale of 2 Circles Jacob Imre and David J. Jeﬀrey(B) Department of Mathematics, University of Western Ontario, London, ON, Canada [email protected]   
   
  Abstract. The Lambert W function is a multivalued function whose principal branch has been studied in detail. Non-principal branches, however, have been much less studied. Here, asymptotic series expansions for the non-principal branches are obtained, and their properties, including accuracy and convergence are studied. The expansions are investigated by mapping circles around singular points in the domain of the function into the range of the function using the new expansions. Diﬀerent expansions apply for large circles around the origin and for small circles. Although the expansions are derived as asymptotic expansions, some surprising convergence properties are observed.  
   
  Keywords: Multivalued functions functions · Convergence tests  
   
  1  
   
  · Asymptotic expansions · Special  
   
  Introduction  
   
  The Lambert W function owes its current status1 in no small part to computer algebra systems. Because W allowed algebra systems to return closed-form solutions to problems from all branches of science, computer users, whether mathematicians or non-specialists discovered W in ways that a conventional literature search could not. One diﬃculty for users has been that Lambert W is multivalued, like arctangent or logarithm, but with an important diﬀerence. The branches of the elementary multivalued functions are trivially related, for example the branches of arctangent diﬀer by π; similarly, the branches of logarithm diﬀer by 2πi. There are no simple relations, however, between the branches of W , and each branch must be labelled separately and studied separately. 1.1  
   
  Definitions  
   
  The branches of the Lambert W function are denoted Wk (z), where k is the branch index. Each branch obeys [1] Wk (z)eWk (z) = z , 1  
   
  Citations of [1] as of July 2023: Google scholar 7283; Scopus 4588.  
   
  c The Author(s), under exclusive license to Springer Nature Switzerland AG 2023  F. Boulier et al. (Eds.): CASC 2023, LNCS 14139, pp. 199–212, 2023. https://doi.org/10.1007/978-3-031-41724-5_11  
   
  (1)  
   
  200  
   
  J. Imre and D. J. Jeﬀrey  
   
  and the diﬀerent branches are distinguished by the deﬁnition Wk (z) → lnk z for |z| → ∞ .  
   
  (2)  
   
  Here, lnk z denotes the kth branch of logarithm [2], i.e. lnk z = ln z + 2πi, with ln z as deﬁned in [3]. The way in which condition (2) deﬁnes the branches of W is also illustrated in Fig. 1. The principal branch W0 (z) takes real values for z ≥ −e−1 and has been extensively studied. For example, the function T (z) = − W0 (−z) is the exponential generating function for labelled rooted trees [4]; the convex analysis of W0 was developed in [5]; it was shown in [6] that W0 is a Bernstein function, and a Stieltjes function, and its derivative is completely monotonic; a model of chemical kinetics in the human eye uses W0 (x) in [8]. Numerous papers have proposed numerical schemes for bounding or evaluating W0 (x) for x ∈ R, a recent example being [7]. In contrast, non-principal branches k = 0 have been less studied. They do have, nonetheless, some applications. The branch W−1 (z) takes real values for −e−1 ≤ z < 0. The real-valued function W−1 (− exp(−1 − 12 z 2 )) was used in [9] to obtain a new derivation of Stirling’s approximation to n! and Vinogradov has presented applications in statistics both for W−1 (x) [10] and W0 (x) [11]. 1.2  
   
  Expansions  
   
  In [12], de Bruijn obtained an asymptotic expansion for W0 (x) when x → ∞; this was extended to the complex plane in [1]. Having obtained an expansion for large x, [1] continued by stating ‘A similar but purely real-valued series is useful for the branch W−1 (x) for x < 0. We can get a real-valued asymptotic formula from the above by using log(−x) in place of Log(z) and log(− log(−x)) in place of log(Log(z)). [...] This series is not useful for complex x because the branch cuts of the series do not correspond to those of W .’ We improve upon this point by proposing new, explicit series for all non-principal branches k = 0, and testing them numerically. An important diﬀerence between W0 and all other branches is behaviour at the origin. W0 is analytic at the origin [13], and its Taylor expansion is known explicitly [13]; in contrast, all other branches are singular at the origin. Our interest here is to study asymptotic expansions both for |z| → ∞ and, for nonprincipal branches, the neglected case |z| → 0. 1.3  
   
  Branch Structure  
   
  To focus our discussion, we consider the plots shown in Fig. 1. The top set of axes show values of z in the domain of W (z). The bottom set show values of Wk , where the branch indicator k is important; that is, the bottom axes show  
   
  Non-principal Branches of Lambert W. A Tale of 2 Circles  
   
  201  
   
  Fig. 1. The domains (left axes) and ranges (right axes) of the branches of the Lambert W function. The branches of W collectively ﬁll all of the complex plane, although any one branch occupies only a disjoint strip of the plane. Each branch has a domain consisting of the entire complex plane, although the branch cuts diﬀer according to the branch. The continuous curves in the range are constructed piecewise by mapping the circles successively with the diﬀerent branches.  
   
  the ranges2 . Although only one set of axes is used to show the domain, this is a simpliﬁcation which avoids multiple ﬁgures. There are actually several diﬀerent domains, coinciding with the diﬀerent branches of W . In contrast to more familiar multi-valued functions, such as ln z, the diﬀerent branches Wk (z) do not share a single common domain. Speciﬁcally, the singular points and the branch cuts of Wk (z) vary from branch to branch. In Fig. 1, the diﬀerent branch cuts for diﬀerent branches are compressed onto the negative real axis (of the top set of axes) using dashed and solid lines. For the principal branch W0 , the branch cut consists only of the dashed portion of the axis, i.e. x ≤ −1/e, and the solid segment is not a branch cut; the point x = −1/e is the singular point. For the branches k = ±1, there are two branch cuts, both the dashed line and the solid line; they meet at x = −1/e. It is best to think of the cuts as distinct, even though they share a singular point and extend along the same axis. The distinction is that the dashed line for k = −1 maps to the boundary between W0 and W−1 , with the boundary belonging to W−1 , while the solid line maps to the boundary between W1 and W−1 , with the boundary belonging to W−1 . Similarly, the dashed line for k = 1 maps to the boundary between W0 and W1 , but now the boundary belongs to W0 . In contrast to the dashed-line cuts, the solid-line cut maps to the boundary between W1 and W−1 , with the boundary belonging to W−1 . The origin is a second singular point for W1 and W−1 . For all other branches, i.e. k ≥ 2 and k ≤ −2, the two cuts merge into a single cut extending along the 2  
   
  Note the plural. We regard each branch of Wk as a separate function with its own domain and range [14].  
   
  202  
   
  J. Imre and D. J. Jeﬀrey  
   
  whole of the negative real axis, with the point z = −1/e no longer being a singular point, and only the origin being singular. Two circles, both alike in dignity3 , are plotted in the domain; they are described by the equation z = reiθ with r = 200 and r = 0.05 and −π < θ ≤ π. The circles are drawn so that one end of each circle touches the branch cut, while the other end stops short of the cut. This plotting convention reﬂects that the θ interval is closed on the top of the cut, when θ = π. The bottom axes in Fig. 1 show the ranges of the branches Wk . The branch boundaries are shown as black dashed lines. The curves plotted are the results from applying successively W−2 , W−1 , W0 , W1 , W2 to the two circles shown in the top set of axes. The continuous curve in the positive-real half-plane corresponds to the large circle, while the small circle maps into two curves: the small closed curve around the origin and the continuous curve in the negative real half-plane. 1.4  
   
  Asymptotic Expansions  
   
  We brieﬂy summarize Poincar´e’s theory of asymptotic expansions [15, Ch.1]. We begin with an example.  ∞ −xt  ∞ e dt g(x) = = e−xt (1 − t + t2 − t3 + . . .) dt 1 + t 0 0 1! 1 2! 3! 4! = − 2 + 3 − 4 + 5 − ... (3) x x x x x The series in 1/x does not converge for any x, but if we substitute x = 10 into the equation, we obtain (evaluating the integral using Maple)  ∞ −10t e dt = 0.0915633 . . . = 0.1 − 0.01 + 0.002 − 0.0006 + 0.00024 − . . . (4) 1 + t 0 Adding the ﬁrst 4 terms, we obtain the approximation 0.0914, which approximates the integral with an error 0.00016. Our sum omitted the 5th term, and we note that its value, 0.00024, bounds the observed error. It is typical of asymptotic series that the error is bounded by the ﬁrst omitted term in the sum. The theory of asymptotic expansions generalizes the functions x−k used in the example, with a sequence of gauge, or scale, functions {φn (x)} obeying the condition φn+1 (x) = o(φn (x)) as x → ∞. The series formed from these functions, g(x) =  
   
  N   
   
  an φn (x) ,  
   
  (5)  
   
  n=1  
   
  has the property that it becomes more accurate as x → ∞. Typically, the error is bounded by the omitted term φN +1 (x). For an asymptotic expansion, the 3  
   
  This whimsical Shakespearian reference emphasises the mathematical point that previous investigations have concentrated on the large circle and neglected the equally important small circle.  
   
  Non-principal Branches of Lambert W. A Tale of 2 Circles  
   
  203  
   
  limit N → ∞ is of less interest than the limit x → ∞, and will not exist for a non-convergent expansion. This paper uses scale functions φn (z) = 1/ lnn (z). In order for the functions to decrease with n, we require that | ln z| > 1, which in turn requires |z| > e or |z| < e−1 . Then they form an asymptotic sequence both in the limit |z| → ∞ and |z| → 0. 1.5  
   
  Outline  
   
  In Sect. 2, we revisit the derivation of the expansion of W given in [1] for large arguments, replacing the imprecise notation Log with the precise notation lnk z deﬁned above. We then use graphical methods to add to earlier treatments by demonstrating the accuracy of the approximations for the diﬀerent branches. Although not all asymptotic expansions are convergent series, the expansions given here are convergent for some arguments. We show this convergence, but do not analyse the regions in detail. In Sect. 3, the main motivation for this paper is taken up: the expansions for non-principal branches of W around the origin. We show that the key idea is to deﬁne a shifted logarithm which matches the asymptotic behaviour at the origin. Again we also consider convergence, and we uncover an unexpected result that several series, although based on diﬀerent starting assumptions, none the less converge to correct values. The rates of convergence, however, are diﬀerent, with the series based on shifted logarithms being best.  
   
  2  
   
  de Bruijn Series for Large z  
   
  Since the branches of W are deﬁned so that Wk (z) asymptotically approaches lnk z, we consider Wk (z) = lnk z + v(z), and assume v = o(lnk z). Then (1) gives (lnk z + v(z)) elnk z+v = (lnk z + v(z)) zev = z . To leading order, e−v = lnk z, and assuming that v lies in the principal branch of logarithm, the approximation is (note the diﬀerent branches of logarithm) Wk (z) = lnk z − ln0 (lnk z) + u(z) .  
   
  (6)  
   
  Neglecting temporarily the u(z) term, we compare in Fig. 2 the one-term and two-term approximations to W . The line thickening shows where the approximations think the branch boundaries are. The term lnk z alone is a signiﬁcant over-estimate, and the branch boundaries are not close, but two terms, although under-estimating, are encouragingly closer. Our main interest, however, is the behaviour after including u(z). Substituting (6) into (1) and introducing σ=  
   
  1 , lnk z  
   
  and  
   
  τ=  
   
  ln(lnk z) , lnk z  
   
  (7)  
   
  we can show that u obeys (more details of this demonstration are given below) 1 − τ + σu − e−u = 0 .  
   
  (8)  
   
  204  
   
  J. Imre and D. J. Jeﬀrey  
   
  Fig. 2. A comparison between the exact value of W and the one-term and two-term approximations in (6). The dashed curve is the exact value. The straight line to the right is the one-term approximation; the central portion has been thickened to show where the approximation thinks the principal branch is. The solid curve to the left is the two-term approximation.  
   
  Equation (8) was solved for u by Comtet [16] as a series in σ: N   
   
  (−σ)n , n! n=1   −m m n  n σ τ n−m cn = , (−1) n − m + 1 m! m=1 u=  
   
  cn  
   
  (9) (10)  
   
   n  where n−m+1 is a Stirling Cycle number [17, p. 259], and we have written the series going to N terms, for later reference. The form of the expansion appears to be unchanged from the principal branch, but this is because the branch information is hidden in the variables σ and τ . The derivation of the expansion is for an asymptotic series, as deﬁned in Sect. 1.4. Such series are not necessarily convergent4 , but in [19], the series (6) together with (9) was studied for x ∈ R and the series was shown to converge for x > e. The question naturally arises of where the series for principal and non-principal branches converge for z ∈ C. Since we are dealing with the accuracy and convergence of series on multiple domains of z and for multiple branches of W , we wish to avoid analyzing each branch separately and being tempted to present multiple repetitious plots of results. We thus use the plot shown in Fig. 3 to summarize our ﬁndings. The plot accumulates maps of the large circle shown above in Fig. 1 under successive branches Wk ; these plots are compared with maps made by the corresponding series approximation (9) using 2 terms of the summation. The contours corre4  
   
  Indeed, some authors deﬁne an asymptotic series as one that does not converge [18].  
   
  Non-principal Branches of Lambert W. A Tale of 2 Circles  
   
  205  
   
  spond to circles of radii r = 50, 10, 5, 3, 1, e−1 . In each case the dashed curve is W and the solid curve is the series approximation. In Fig. 3, we focus ﬁrst on the approximation for the principal branch, indicated by the red curves. We see that for r > 3, the accuracy is acceptable, and improves for larger r, as expected. Since we are considering an asymptotic approximation, we ﬁx the number of terms in the summation to 2, and consider changes with r. We note in particular that the exact and approximate curves for r = 50 are practically indistinguishable to the human eye. We can also investigate the convergence of the series. For r > 10 we can take more terms of the summation and observe improved accuracy (data not shown), indicating the series is convergent for larger r values (as well as asymptotic). For smaller values of r, the series loses accuracy, and in parallel fails to converge, the extraneous curves swamping the ﬁgure. Therefore, for r < 3 we plot only the values of W0 and remove the distraction of the failed approximations. Both the W curves and the approximations are smooth across the branch boundaries. This reﬂects the properties that Wk (−x) = lim Wk+1 (−x + iy) ,  
   
  for x < −1/e , and  
   
  (11)  
   
  lnk (−x) = lim lnk+1 (−x + iy) ,  
   
  for x < 0 .  
   
  (12)  
   
  y↑0 y↑0  
   
  This does not ensure that the boundaries between the branches of W and of the approximations agree, although they approach each other with improved accuracy. For branches k = 0, we observe something that is unexpected, namely, that the approximations show evidence of remaining accurate for all values of r down to r = e−1 . Indeed, the series appear convergent. This is diﬃcult to justify graphically, but can be checked by extended summation for values where graphical evidence is weakest. In Table 1 we calculate approximations to W−1 (−1/e) = −1 and W−1 (−0.4) using increasing numbers of terms in the sum. Adding up large numbers of terms in a sum can require additional intermediate precision for accuracy. For the table, Maple’s default 10-digit accuracy had to be increased to 30 decimal digits for sums of more than 50 terms. The numerical results indicate convergence, but do not constitute a proof.  
   
  3  
   
  de Bruijn Series for Small z  
   
  A new feature associated with the analysis around the origin is the disappearance from the asymptotic analysis of the principal branch. Figure 4 shows a plot of 1 and centred at the origin. values of Wk computed on a circle of radius r = 20 The principal branch, shown in red, is the small closed curve around the origin, while all other branches form the continuous curve on the far left. It is important to note a diﬀerence between W0 and W−1 . The real values of W0 occur in the middle of its range, or to put it another way, the real values of W0 do not coincide with the branch boundaries. In contrast, the real values of W−1 occur on one  
   
  206  
   
  J. Imre and D. J. Jeﬀrey  
   
  Fig. 3. A systematic test of expansion (9), using two terms of the summation. Each continuous curve is a concatenation of mappings of the same large circle using successively the various branches of W and of its approximations. The dashed curves are the exact values of Wk while the solid curves are the approximations. The contours correspond to circles of radii, from right to left, r = 50, 10, 5, 3, 1, e−1 . The approximations to the principal branch for r < 3 are so bad that they distract from the plots and have been omitted. For non-principal branches, all approximations are plotted.  
   
  of its branch boundaries. We want this diﬀerence to be reﬂected, if possible, in the asymptotic forms we use. As in the previous section, the leading asymptotic term is logarithm, and the problem is to match the branches of the logarithm term to W−1 , and more generally to all Wk for k = 0. Two possible asymptotic approximations are shown in Fig. 4 as the vertical lines to the right of the curve showing the values of W . The right-most line is the approximation lnk z which was already used for the previous section. Since W−1 (−0.01) = −6.473, i.e. purely real, but ln(−0.01) = −4.605 + πi and ln−1 (−0.01) = −4.605 − πi, it is clear that the approximations that worked well in the previous section, do not work here. For this reason, we introduce what we call a ‘shifted log’ by the deﬁnition (13) Lk (z) = lnk z − sgn(k)iπ , for k = 0 . We see that for this function L−1 (−0.01) = −4.605, and so is purely real where W−1 is real. This function is plotted in Fig. 4 as the straight line in between the other two contours. Notice that W−1 (−e−1 ) = −1, and L−1 (−e−1 ) = −1 also. Of course, W−1 (z) is not diﬀerentiable at z = −e−1 , but L−1 (z) is diﬀerentiable, showing that more terms in the series will be needed for numerical accuracy.  
   
  Non-principal Branches of Lambert W. A Tale of 2 Circles  
   
  207  
   
  Table 1. Numerical tests of convergence for the expansion (9). The row N = ∞ refers to the value of W that the series is trying to reach. The series appears convergent, although painfully slowly. N  
   
  value for x = −e−1 value for x = −0.4  
   
  ∞ 40 70 100 160  
   
  −1 −1.1568 − 0.1565 i −1.1190 − 0.1188 i −1.0997 − 0.0996 i −1.0789 − 0.0788 i  
   
  −0.9441 − 0.4073 i −0.9665 − 0.3495 i −0.9259 − 0.3800 i −0.9232 − 0.4055 i −0.9448 − 0.4183 i  
   
  Having matched the leading-order behaviour of Wk using the shifted logarithm, we repeat the approach used above of substituting into W eW = z. (Lk (z) + v(z)) exp(Lk (z) + v(z)) = (Lk (z) + v(z)) (−z) exp(v(z)) = z v(z) = − ln(−Lk (z)) + u(z) . It might seem that u will follow a pattern like ln(ln(−Lk )), but this is not so. (Lk (z) − ln(−Lk (z)) + u)) exp(Lk (z) − ln(−Lk (z)) + u)) −z = (Lk (z) − ln(−Lk (z)) + u) exp(u) = z . −Lk (z) Rearranging gives 1−  
   
  u ln(−Lk (z)) + − e−u = 0 . Lk (z) Lk (z)  
   
  (14)  
   
  Thus, if we redeﬁne σ, τ by σ=  
   
  1 Lk (z)  
   
  and  
   
  τ=  
   
  ln(−Lk (z)) , Lk (z)  
   
  (15)  
   
  we can return to (8) and (9). It is remarkable that the fundamental relation (8), originally derived for the principal branch, has now reappeared twice: once for any branch (|z|  1) and now for |z| e−1 . Since (13) was chosen so that it is purely real where W−1 is real, we ﬁrst compare plots for −e−1 ≤ x < 0. Figure 5 compares W−1 (x) with two approximations, sum 9 for N = 0 and for N = 3. They are most accurate near x = 0 as expected. Figure 6 shows a comparison in the complex plane for branches from k = −2 to k = 2. The contours are maps of small circles of radii r = 0.25, 0.15, 0.05. The series approximation was limited to N = 1 in order to obtain a visible separation of the exact and approximate contours. Recall that smaller values of r correspond to contours further to the left.  
   
  208  
   
  J. Imre and D. J. Jeﬀrey  
   
  Fig. 4. A comparison of possible asymptotic approximations to Wk for small circles around the origin. The dashed curve shows Wk (z) for k = 0. The two vertical lines show the two candidates: lnk z is the right-most line and was used for large circles; the new shifted logarithm is the left line. The lines are sectioned into thick and thin segments. These show the branches of the approximations. The branches of lnk z are seen to be not aligned with the boundaries of W , shown by the horizontal dashed lines. In contrast, the branches of the shifted logarithm are closer to the boundaries of the branches of W . Note that W−1 (x) and the shifted logarithm are both purely real (although not equal, alas) for the same range of arguments, namely real and in the interval [−e−1 , 0). For completeness, the map of the principal branch is also shown (around the origin), to emphasize that it does not participate in the asymptotic behaviour.  
   
  Fig. 5. Plots of W−1 (x) and approximations based on (9) together with (15). The solid line shows W−1 ; the dashed line shows (9) for N = 0; the dotted line shows N = 3.  
   
  Non-principal Branches of Lambert W. A Tale of 2 Circles  
   
  209  
   
  Fig. 6. Comparison of Wk , k = 0 and (9) using (15). The series uses N = 1 in order to separate the function and the approximation. The boundary between k = −1 and k = 1 is the negative real axis both for the function and for the approximation.  
   
  4  
   
  A Surprising Convergence  
   
  The approximation (7) used for |z|  1 was discarded for |z| −e−1 because the branch boundaries were not aligned with the function near negative inﬁnity. One could expect therefore that its accuracy would be bad, or wrong, or it would possibly return values for branches not requested. It is therefore surprising that in spite of starting from dismal estimates, the approximation manages to achieve results of reasonable accuracy. In Table 2, a comparison is made between series (9) based on (15) with the rejected series based on (7). Out of curiosity, we have tabulated the competing approximations when summed to one-term, two-terms and four-terms. The preferred series always performs better, but the other series also achieves good accuracy. As stated several times, (15) has the advantage of returning real values when W−1 is real, so we stick to our preferred series and do not pursue further discussion of this point.  
   
  5  
   
  A Further Variation  
   
  We brieﬂy comment on a variation on the above series which can lead to more accurate estimates. We introduce a parameter during the derivation of the fundamental relation. During the derivation of (6), we considered the equation lnk z + v = e−v , and argued that v is of smaller asymptotic order than lnk z. We thus neglected it on the left side of the equation and solved lnk z = e−v for v. We can note, however, that a constant is also of lower asymptotic order than  
   
  210  
   
  J. Imre and D. J. Jeﬀrey  
   
  Table 2. Comparison of series (9) combined with (7) and then with (15). The various approximations are printed in adjacent columns for easy comparison. The errors reported in the last two columns report the errors in the 4-term summations. x  
   
  k  
   
  Wk  
   
  lnk x  
   
  Lk (x)  
   
  Eq. (7) N = 0 Eq. (15) N = 0  
   
  −0.1 −1 −3.58  
   
  −2.30 − πi  
   
  −2.30  
   
  −3.66 − 0.94i  
   
  −3.15  
   
  −0.01 −1 −6.47  
   
  −4.61 − πi  
   
  −4.61  
   
  −6.32 − 0.60i  
   
  −6.13  
   
  −2 −4.45 − 7.31i −2.30 − 3πi −2.30 − 2πi −4.58 − 7.61i  
   
  −4.20 − 7.50i  
   
  −0.01 −2 −6.90 − 7.08i −4.61 − 3πi −4.61 − 2πi −6.96 − 7.40i  
   
  −6.66 − 7.22i  
   
  −0.1  
   
  x  
   
  k  
   
  Wk  
   
  Eq. (7) N = 2  
   
  Eq. (15) N = 2  
   
  Error (7) Error (15)  
   
  −0.1 −1 −3.577  
   
  −3.405 − 0.127i −3.591  
   
  0.213  
   
  0.013  
   
  −0.01 −1 −6.473  
   
  −6.416 + 0.035i −6.481  
   
  0.066  
   
  0.008  
   
  −0.1  
   
  −2 −4.449 − 7.307i −4.448 − 7.314i −4.442 − 7.305i 0.0074  
   
  0.0071  
   
  −0.01 −2 −6.896 − 7.081i −6.891 − 7.086i −6.894 − 7.079i 0.0069  
   
  0.0039  
   
  lnk z, and instead of neglecting v, estimate the v on the left by a constant p: thus lnk z + p = e−v . We now have the approximation Wk,dB (z, p) = lnk (z) − ln(p + lnk (z)) + u . Substituting in W eW = z leads now to the equation (lnk z − ln(p + lnk z) + u)  
   
  1 = e−u . p + lnk z  
   
  (16)  
   
  A simple manipulation allows us to convert this equation into yet another manifestation of the fundamental relation (8). (lnk z + p − p − ln(p + lnk z) + u)  
   
  p + ln(p + lnk z) u 1 = 1− + . p + lnk z lnk z + p p + lnk z  
   
  Thus, remarkably, we have 1 − τ + σu − e−u = 0 , and σ =  
   
  p + ln(p + lnk z) 1 ,τ = . p + lnk z lnk z + p  
   
  (17)  
   
  The contours in Fig. 3 would correspond to p = 0. The eﬀect of p is greatest in the principal branch, where the approximation for the circle of radius r = 3 improves between the two ﬁgures, and for r ≤ 1, the approximations for p = 1 are good enough to be plotted (but still not good). The approximations for non-principal branches are little changed by the parameter.  
   
  6  
   
  Concluding Remarks  
   
  It was pointed out in Fig. 1 that the singular point zc = −e−1 is the place where diﬀerent branch cuts meet. The point’s singular nature is reﬂected in the drop  
   
  Non-principal Branches of Lambert W. A Tale of 2 Circles  
   
  211  
   
  in the accuracy of the various series seen above. It is interesting to extend the summation of the series to large numbers of terms so as to reach zc , but it is not practical. The three branches k = 0 and k = ±1 share an expansion in the variable 2(ez + 1) [1], and for obtaining numerical values when z is in the neighbourhood of zc , that expansion is much more convenient. By concentrating the discussion on plots of the ranges of Wk , we have been able to condense the information more eﬃciently that by presenting results in the domains of the functions. We think this is a fruitful way to discuss multivalued functions. Contrast Fig. 1 with the usual treatment in reference books of functions such as logarithm or arctangent. The books always present plots of the branch cuts in the domain, but never the ranges. The need to understand ranges is heightened by the fact that the ranges of Wk are not trivially related to each other, in contrast to the way in which ln1 z is only 2πi diﬀerent from ln0 z. This paper has not attempted to supply formal proofs of the convergence properties of the series studied here. The aim has been to establish the correct forms of the expansions, and to demonstrate numerically their properties. Some of the surprising observations made here remain open problems, and invite both more detailed numerical investigation and formal analytical work.  
   
  References 1. Corless, R.M., Gonnet, G.H., Hare, D.E.G., Jeﬀrey, D.J., Knuth, D.E.: On the Lambert W function. Adv. Comp. Math. 5(4), 329–359 (1996) 2. Jeﬀrey, D.J., Hare, D.E.G., Corless, R.M.: Unwinding the branches of the Lambert W function. Math. Scientist 21, 1–7 (1996) 3. Olver, F.W.J., et al. (eds.): NIST Digital Library of Mathematical Functions (2023). https://dlmf.nist.gov/. Accessed 15 June 2023 4. Flajolet, P., Knuth, D.E., Pittel, B.: The ﬁrst cycles in an evolving graph. Disc. Math. 75, 167–215 (1989) 5. Borwein, J.M., Lindstrom, S.B.: Meetings with Lambert W and other special functions in optimization and analysis. Pure Appl. Funct. Anal. 1(3), 361–396 (2016) 6. Kalugin, G.A., Jeﬀrey, D.J., Corless, R.M., Borwein, P.B.: Stieltjes and other integral representations for functions of Lambert W. Integral Transf. Spec. Funct. 23(8), 581–593 (2012) 7. Iacono, R., Boyd, J.P.: New approximations to the principal real-valued branch of the Lambert W-function. Adv. Comput. Math. 43, 1403–1436 (2017) 8. Mahroo, O.A.R., Lamb, T.D.: Recovery of the human photopic electroretinogram after bleaching exposures: estimation of pigment regeneration kinetics. J. Physiol. 554(2), 417–437 (2004) 9. Marsaglia, G., Marsaglia, J.C.W.: A new derivation of Stirling’s approximation to n!. Am. Math. Monthly 97(9), 826–829 (1990) 10. Vinogradov, V.: On Kendall-Ressel and related distributions. Stat. Prob. Lett. 81, 1493–1501 (2011) 11. Vinogradov, V.: Some utilizations of Lambert W function in distribution theory. Commun. Stat. Theory Methods 42, 2025–2043 (2013) 12. de Bruijn, N.G.: Asymptotic Methods in Analysis. North-Holland (1961)  
   
  212  
   
  J. Imre and D. J. Jeﬀrey  
   
  13. Corless, R.M., Jeﬀrey, D.J., Knuth, D.E.: A sequence of series for the Lambert W function. In: K¨ uchlin, W.W. (ed.) ISSAC 1997: Proceedings of the 1997 International Symposium on Symbolic and Algebraic Computation, pp. 197–204. Association of Computing Machinery (1997) 14. Jeﬀrey, D.J., Watt, S.M.: Working with families of inverse functions. In: Buzzard, K., Kutsia, T. (eds.) Intelligent Computer Mathematics, vol. 13467 of Lecture Notes in Computer Science, pp. 1–16. Springer, Heidelberg (2022). https://doi. org/10.1007/978-3-031-16681-5 16 15. Olver, F.W.J.: Asymptotics and Special Functions. Academic Press, Cambridge (1974) 16. Comtet, L.: Inversion de y α ey et y logα y au moyen des nombres de Stirling. C. R. Acad. Sc. Paris 270, 1085–1088 (1970) 17. Graham, R.L., Knuth, D.E., Patashnik, O.: Concrete Mathematics, 2nd edn. Addison-Wesley, Boston (1994) 18. Dingle, R.B.: Asymptotic Expansions: Their Derivation and Interpretation. Academic Press, Cambridge (1973) 19. Jeﬀrey, D.J., Corless, R.M., Hare, D.E.G., Knuth, D.E.: Sur l’inversion de y a ey au moyen des nombres de Stirling associ´es. Comptes Rendus Acad. Sci. Paris Serie I-Mathematique 320(12), 1449–1452 (1995)  
   
  On the Qualitative Analysis of the Equations of Motion of a Nonholonomic Mechanical System Valentin Irtegov(B) and Tatiana Titorenko Matrosov Institute for System Dynamics and Control Theory SB RAS, 134, Lermontov street, Irkutsk 664033, Russia [email protected]   
   
  Abstract. The problem on the rotation of a dynamically asymmetric rigid body around a fixed point is considered. The body is fixed inside a spherical shell, which a ball and a disk adjoin to. The equations of motion of the mechanical system in the case of absence of external forces admit two additional first integrals and these are completely integrable. The nonintegrable case, when potential forces act upon the system, is also considered. The qualitative analysis of the equations of motion is done in the both cases: stationary sets are found and their Lyapunov stability is studied. A mechanical interpretation for the obtained solutions is given.  
   
  Keywords: Nonholonomic mechanical system Computer algebra  
   
  1  
   
  · Qualitative analysis ·  
   
  Introduction  
   
  The problem considered in this paper goes back to the Chaplygin work [1] of rolling a dynamically asymmetric balanced ball along a horizontal plane without slipping. The integrability of the system was revealed by Chaplygin with the help of its explicit reduction to quadratures. A suﬃcient number of works are devoted to the Chaplygin problem and its integrable generalizations (see, e.g., [2]). One of them is investigated in the paper. In [3] the generalization of system [2] is given. The motion of a dynamically asymmetric rigid body around ﬁxed point O is considered (see Fig. 1). The body is rigidly enclosed in a spherical shell, the geometrical center of which coincides with the ﬁxed point of the body. One ball and one disk adjoin to the spherical shell. It is supposed that slipping at a contact point of the ball with the shell is absent. The disk – nonholonomic hinge – concerns the external surface of the spherical shell. The centers of the balls and the axis of the disk are ﬁxed in space. The study of dynamics of such systems is of interest, e.g., for robotics in the problems of the design and control of mobile spherical robots (see., e.g., [4]). The motion of the mechanical system is described by the diﬀerential equations [3] c The Author(s), under exclusive license to Springer Nature Switzerland AG 2023  F. Boulier et al. (Eds.): CASC 2023, LNCS 14139, pp. 213–232, 2023. https://doi.org/10.1007/978-3-031-41724-5_12  
   
  214  
   
  V. Irtegov and T. Titorenko  
   
  Fig. 1. The rigid body enclosed in a spherical shell, which a ball and a disk adjoin to.  
   
  Iω ˙ = Iω × ω + Rγ × N + μE + MQ , D1 ω ˙ 1 = D1 ω1 × ω + R1 γ × N, ˙ γ˙ = γ × ω, E = E × ω, (1) and the equations of constraints Rω × γ + R1 ω1 × γ = 0, (ω, E) = 0.  
   
  (2)  
   
  Here ω = (ω1 , ω2 , ω3 ), R is the angular velocity of the body and the radius of the spherical shell, ω1 = (ω11 , ω12 , ω13 ), R1 is the angular velocity and the radius of the adjoint ball, γ = (γ1 , γ2 , γ3 ) is the unit vector of the axis connecting the ﬁxed point with the center of the adjoint ball, E = (e1 , e2 , e3 ) is the vector of the normal to the plane containing the ﬁxed point and the axis of the disk, I = diag(A, B, C) is the inertia tensor of the body, D1 is the inertia tensor of the adjoint ball, N= (N1 , N2 , N3 ), μ are indeﬁnite factors related to the reactions of constraints (2), MQ is the moment of external forces. One supposes that the position of the vectors E and γ with respect to each other is arbitrary. By means of the equations of constraints (2) the diﬀerential Eqs. (1) are reduced to the form [3]: ˙ = E × ω, (3) Iω ˙ + Dγ × (ω ˙ × γ) = Iω × ω + μE + MQ , γ˙ = γ × ω, E 2  
   
  where D = R D . R12 1 The indeﬁnite factor μ is found from the condition that the derivative of the 2nd relation (2) in virtue of diﬀerential Eqs. (3) is equal to zero. If the body is subject to external forces, e.g., potential ones MQ = γ ×  
   
  ∂U ∂U +E× , ∂γ ∂E  
   
  On the Qualitative Analysis of the Equations of Motion  
   
  215  
   
  where U = U (γ, E) is the potential energy of external forces, Eqs. (3) admit the following ﬁrst integrals 2H = (IQ ω, ω) + 2U (γ, E) = 2 h, V1 = (γ, γ) = 1, V2 = (E, E) = 1, V3 = (γ, E) = c1 , V4 = (ω, E) = 0  
   
  (4)  
   
  and are nonintegrable in the general case. Here IQ = I + D − Dγ ⊗ γ, γ ⊗ γ = [cij ], c11 = γ12 , c12 = γ1 γ2 , . . . In the case of the absence of external forces (U = 0) and (E × γ) = 0, Eqs. (3) have two additional ﬁrst integrals F1 = (K, E × γ), F2 = (K, E × (E × γ)), where K = IQ ω − (IQ ω, E)E, and then system (3) is completely integrable.  
   
  2  
   
  Problem Statement  
   
  The qualitative analysis of the problem under consideration was not conducted so far. In the present work, the qualitative analysis of the equations of motion (3) on the invariant set deﬁned by the relation V4 = 0 (4) is done. We ﬁnd invariant sets of various dimension from the necessary conditions of extremum of the ﬁrst integrals of the problem (or their combinations) and study their Lyapunov stability. The sets found in this way are called stationary ones. The stationary sets of zero dimension are known as stationary solutions, while the positive dimension sets are called stationary invariant manifolds (IMs). We use the Routh–Lyapunov method [5] and some its generalizations [6] for the study of the problem. The computer analysis of the problem is mainly done symbolically. Computer algebra system (CAS) Mathematica and the software package [7] written in the language of this system are applied to solve computational problems. With the help of the package, the stability of the found solutions is investigated. The paper is organized as follows. In Sect. 2 and 3, we describe ﬁnding stationary sets both in the case of absence of external forces and when potential forces act upon the mechanical system. Solutions obtained in these sections correspond to equilibria of the mechanical system. In Sect. 4, solutions corresponding to pendulum-type motions are presented. In Sect. 5, the stability of the found solutions is analyzed. In Sect. 6, we give some conclusions.  
   
  3  
   
  On Stationary Sets in the Case of Absence of External Forces  
   
  The equations of motion (3) in an explicit form on the invariant set V4 = 0 when U = 0 are written as  
   
  216  
   
  V. Irtegov and T. Titorenko  
   
  1 D((A − B)(B + D)γ3 ω ¯ 2 − (A − C)(C + D)γ2 ω3 ) γ1 ω1 σ1 +(B − C)((C + D)(B + D − Dγ22 ) − D(B + D)γ32 ) ω ¯ 2 ω3 + μ [(C + D)  ×((B + D)e1 + Dγ2 (e2 γ1 − e1 γ2 )) + D(B + D)γ3 (e3 γ1 − e1 γ3 )] , 1 (A − B)((B + D)(A + D − Dγ12 ) − D(A + D) γ22 ) ω1 ω ¯2 ω˙ 3 = − σ1 −D((A − C)(A + D)γ2 ω1 − (B − C)(B + D)γ1 ω ¯ 2 ) γ3 ω3 + μ [D(A + D)  2 ×γ2 (e2 γ3 − e3 γ2 ) + (B + D)(e3 (A + D − Dγ1 ) + De1 γ1 γ3 )] ,  
   
  ω˙ 1 = −  
   
  γ˙ 1 = −γ3 ω ¯ 2 + γ2 ω3 , γ˙ 2 = γ3 ω1 − γ1 ω3 , γ˙ 3 = −γ2 ω1 + γ1 ω ¯2, e˙ 1 = −e3 ω ¯ 2 + e2 ω3 , e˙ 2 = e3 ω1 − e1 ω3 , e˙ 3 = −e2 ω1 + e1 ω ¯2,  
   
  (5)  
   
  3 ω3 , where ω ¯ 2 = − e1 ω1e+e 2  
   
  1 (A−B)((B + D)(A + D) e3 + D(B + D)γ1 (γ3 e1 −e3 γ1 ) σ2 +D(A + D)γ2 (γ3 e2 − e3 γ2 )) ω1 ω ¯2 −(A − C)(e2 (A + D)(C + D) + D(C + D)γ1 (e1 γ2 − e2 γ1 )  
   
  μ=−  
   
  +D(A + D)γ3 (e3 γ2 − e2 γ3 )) ω1 ω3 + (B − C)((B + D)(C + D)e1  +D(C + D)γ2 (e2 γ1 − e1 γ2 ) + D(B + D)γ3 (e3 γ1 − e1 γ3 )) ω ¯ 2 ω3 , σ1 = D((B +D)(C +D) γ12 + (A+D)(C + D) γ22 + (A+D)(B +D) γ32 ) −(A + D)(B + D)(C + D), σ2 = (B + D)(C + D) e21 + (A + D)(C + D) e22 + (A + D)(B + D) e23 −D[(C + D)(e2 γ1 − e1 γ2 )2 + (B + D)(e3 γ1 − e1 γ3 )2 +(A + D)(e3 γ2 − e2 γ3 )2 ], Equations (5) admit the following ﬁrst integrals: ¯ 22 + (C + D − Dγ32 ) ω32 2 H = (A + D − Dγ12 ) ω12 + (B + D − Dγ22 ) ω −2D(γ1 γ2 ω1 ω ¯ 2 + γ1 γ3 ω1 ω3 + γ2 γ3 ω ¯ 2 ω3 ) = 2 h, 2 2 2 2 2 V1 = γ1 + γ2 + γ3 = 1, V2 = e1 + e2 + e23 = 1, V3 = e1 γ1 + e2 γ2 + e3 γ3 = c1 , ¯2 F1 = −(A + D)(e3 γ2 − e2 γ3 ) ω1 + (B + D)(e3 γ1 − e1 γ3 ) ω −(C + D)(e2 γ1 − e1 γ2 ) ω3 = c2 , F2 = [e1 (A + D − 2Dγ12 )(e2 γ2 + e3 γ3 ) − γ1 (A (e22 + e23 ) −D((e22 + e23 )(γ12 − 1) + (e3 γ2 − e2 γ3 )2 + e21 (γ22 + γ32 )))] ω1 +[e2 (B + D − 2Dγ22 )(e1 γ1 + e3 γ3 ) − γ2 (B (e21 + e23 ) −D((e21 + e23 )(γ22 − 1) + (e3 γ1 − e1 γ3 )2 + e22 (γ12 + γ32 )))] ω ¯2 +[e3 (e1 γ1 + e2 γ2 )(C + D − 2Dγ32 ) − γ3 (C (e21 + e22 ) −D((e2 γ1 − e1 γ2 )2 + e23 (γ12 + γ22 ) + (e21 + e22 )(γ32 − 1)))] ω3 = c3 .  
   
  (6)  
   
  On the Qualitative Analysis of the Equations of Motion  
   
  217  
   
  Here F1 , F2 are the additional integrals of the 3rd and 5th degrees, respectively. As was remarked above, the stationary conditions for the ﬁrst integrals of the problem (or their combinations) are used to obtain solutions of interest for us. In the problem under consideration, because of rather high degrees of the ﬁrst integrals, another approach [8] turned out to be more eﬀective for seeking the desired solutions: ﬁrst, obtain the desired solutions from the equations of motion, and, then, ﬁnd the conditions on the parameters of the problem under which these solutions satisfy the stationary equations for the ﬁrst integrals. Obviously, Eqs. (5) have the solution ω1 = ω3 = 0. These relations together with the integrals V1 = 1, V2 = 1 deﬁne the invariant manifold (IM) of codimension 4 for the equations of motion (5). It is easy to verify by direct calculation according to the IM deﬁnition. The equations of the IM are written as: ω1 = ω3 = 0, e21 + e22 + e23 = 1, γ12 + γ22 + γ32 = 1. With the help of maps on IM (7)   ω1 = ω3 = 0, γ1 = ± 1 − γ22 − γ32 , e1 = ± 1 − e22 − e23 ,  
   
  (7)  
   
  (8)  
   
  we ﬁnd that the integral V3 takes the form   e2 γ2 + e3 γ3 ± 1 − γ22 − γ32 1 − e22 − e23 = c1 on this IM. Thus, IM (7) exists for any angles between the vectors E and γ, i.e., it is the family of IMs. The diﬀerential equations γ˙ 2 = 0, γ˙ 3 = 0, e˙ 2 = 0, e˙ 3 = 0 on IM (7) have the family of solutions: γ2 = γ20 = const, γ3 = γ30 = const, e2 = e02 = const, e3 = e03 = const.  
   
  (9)  
   
  The latter relations together with the IM equations determine four families of solutions for the equations of motion (5)   2 2 2 2 ω1 = ω3 = 0, e1 = ± 1 − e02 − e02 , e2 = e02 , e3 = e03 , γ1 = 1 − γ 02 − γ 02 , γ2 = γ 02 , γ3 = γ 03 ;  
   
    2 2 2 2 ω1 = ω3 = 0, e1 = ± 1 − e02 − e02 , e2 = e02 , e3 = e03 , γ1 = − 1 − γ 02 − γ 02 , γ2 = γ 02 , γ3 = γ 03  
   
  (10)  
   
  that can be veriﬁed by substituting the solutions into these equations. Here e02 , e03 , γ 02 , γ 03 are the parameters of the families. Evidently, the solutions belong to IM (7). From a mechanical point of view, the elements of the families of solutions (10) correspond to equilibria of the mechanical system under study. Using the stationary equations ∂K1 /∂ω1 = 0, ∂K1 /∂ω3 = 0, ∂K1 /∂γj = 0, ∂K1 /∂ej = 0 (j = 1, 2, 3)  
   
  218  
   
  V. Irtegov and T. Titorenko  
   
  for the integral 2K1 = 2λ0 H − λ1 (V1 − V2 )2 − λ2 F1 F2 (λi = const), it is not diﬃcult to show that this integral takes a stationary value both on IM (7) and solutions (10). For this purpose, it is suﬃcient to substitute expressions (8) (or (10)) into the above equations. These become identity. Directly, from diﬀerential Eqs. (5), it is also easy to obtain the following their solutions: ω1 = ω3 = 0, e1 = ±γ1 , e2 = ±γ2 , e3 = ±γ3 .  
   
  (11)  
   
  Relations (11) together with the integral V1 = 0 deﬁne two IMs of codimension 6 of diﬀerential Eqs. (5) that is veriﬁed by direct computation according to the IM deﬁnition. The equations of these IMs have the form: ω1 = ω3 = 0, e1 ∓ γ1 = 0, e2 ∓ γ2 = 0, e3 ∓ γ3 = 0, γ12 + γ22 + γ32 = 1. (12) On substituting expressions (12) into the stationary conditions for the integral 2K2 = 2λ0 H − λ1 V1 − λ2 V2 − 2λ3 V3 − 2λ4 F1 − 2λ5 F2 (λi = const) we ﬁnd the values λ2 = λ1 , λ3 = ∓λ1 under which the integral K2 assumes a stationary value on IMs (12). The integrals K1 and K2 (under the corresponding values of λ2 , λ3 ) are used for obtaining the suﬃcient conditions of stability of the above solutions. The diﬀerential equations γ˙ 2 = 0, γ˙ 3 = 0 on each IMs (12) have the following family of solutions: γ2 = γ20 = const, γ3 = γ30 = const. Thus, geometrically, in space R8 , two-dimensional surface corresponds to each of IMs (12), each point of which is a ﬁxed point of the phase space. The integral V3 takes the values ±1 on IMs (12). Thus, IMs (12) correspond to the cases when the vectors E and γ are parallel or opposite in direction.  
   
  4  
   
  On Stationary Sets in the Case of the Presence of External Forces  
   
  Let the mechanical system under study be under the inﬂuence of external potential forces with the potential energy U = (a, γ) + (b, E), where a = (a1 , a2 , a2 ), b = (b1 , b2 , b2 ) are the indeﬁnite factors. In this case, the equations of motion (3) on the invariant set V4 = 0 are written as:  
   
  On the Qualitative Analysis of the Equations of Motion  
   
  219  
   
  1 ¯ 2 − (A − C)(C + D)γ2 ω3 ) γ1 ω1 D((A − B)(B + D)γ3 ω σ1 +(B − C)((C + D)(B + D − Dγ22 ) − D(B + D)γ32 ) ω ¯ 2 ω3 + μ [(C + D) ×((B + D)e1 + Dγ2 (e2 γ1 − e1 γ2 )) + D(B + D)γ3 (e3 γ1 − e1 γ3 )] +((C + D)(B + D − Dγ22 ) − D(B + D)γ32 )MQ1 + D(C + D)γ1 γ2 MQ2  +D(B + D)γ1 γ3 MQ3 , 1 (A − B)((B + D)(A + D − Dγ12 ) − D(A + D) γ22 ) ω1 ω ω˙ 3 = − ¯2 σ1 −D((A − C)(A + D)γ2 ω1 − (B − C)(B + D)γ1 ω ¯ 2 ) γ3 ω3 + μ [D(A + D) 2 ×γ2 (e2 γ3 − e3 γ2 ) + (B + D)(e3 (A + D − Dγ1 ) + De1 γ1 γ3 )]  
   
  ω˙ 1 = −  
   
  +Dγ3 ((B + D)γ1 MQ1 + (A + D)γ2 MQ2 ) + ((B + D)(A+D−Dγ12 )  −D(A + D)γ22 )MQ3 , γ˙ 1 = −γ3 ω ¯ 2 + γ2 ω3 , γ˙ 2 = γ3 ω1 − γ1 ω3 , γ˙ 3 = −γ2 ω1 + γ1 ω ¯2, e˙ 1 = −e3 ω ¯ 2 + e2 ω3 , e˙ 2 = e3 ω1 − e1 ω3 , e˙ 3 = −e2 ω1 + e1 ω ¯2,  
   
  (13)  
   
  1 (A−B)((B + D)(A + D) e3 + D(B + D) γ1 σ2 ×(γ3 e1 − e3 γ1 ) + D(A + D)γ2 (γ3 e2 − e3 γ2 )) ω1 ω ¯2  
   
  where μ = −  
   
  −(A − C)(e2 (A + D)(C + D) + D(C + D)γ1 (e1 γ2 − e2 γ1 ) +D(A + D)γ3 (e3 γ2 − e2 γ3 )) ω1 ω3 + (B − C)((B +D)(C +D) e1 +D(C + D)γ2 (e2 γ1 − e1 γ2 ) + D(B + D)γ3 (e3 γ1 − e1 γ3 )) ω ¯ 2 ω3 −((C + D)((B + D)e1 + Dγ2 (e2 γ1 − e1 γ2 )) +D(B + D)γ3 (e3 γ1 − e1 γ3 ))MQ1 − ((C + D)((A + D)e2 +Dγ1 (e1 γ2 − e2 γ1 )) + D(A + D)γ3 (e3 γ2 − e2 γ3 ))MQ2 −(D(A + D)γ2 (e2 γ3 − e3 γ2 ) + (B + D)((A + D)e3  +Dγ1 (e1 γ3 − e3 γ1 )))MQ3 . MQ1 = b3 e2 −b2 e3 + a3 γ2 −a2 γ3 , MQ2 = −b3 e1 + b1 e3 −a3 γ1 +a1 γ3 , MQ3 = b2 e1 − b1 e2 + a2 γ1 − a1 γ2 . Here ω ¯ 2 , σ1 , σ2 have the same values as in Sect. 2. The ﬁrst integrals of Eqs. (13): 2 H = (A + D − Dγ12 ) ω12 + (B + D − Dγ22 ) ω ¯ 22 + (C + D − Dγ32 ) ω32 −2D(γ1 γ2 ω1 ω ¯ 2 + γ1 γ3 ω1 ω3 + γ2 γ3 ω ¯ 2 ω3 ) + a1 γ1 + a2 γ2 + a3 γ3 +b1 e1 + b2 e2 + b3 e3 = 2 h, V1 = γ12 + γ22 + γ32 = 1, V2 = e21 + e22 + e23 = 1, V3 = e1 γ1 + e2 γ2 + e3 γ3 = c1 .  
   
  (14)  
   
  220  
   
  V. Irtegov and T. Titorenko  
   
  We shall seek solutions of diﬀerential Eqs. (13) of the following type: ω1 = ω3 = 0, e1 = e01 , e2 = e02 , e3 = e03 , γ1 = γ10 , γ2 = γ20 , γ3 = γ30 ,  2 2 where e02 , e03 , γ20 , γ30 are some constants, and e01 = ± 1 − e02 − e03 ,  2 2 γ10 = ± 1 − γ20 − γ30 . On substituting (15) into Eqs. (13) these take the form:  
   
  (15)  
   
  μ ¯ [(C + D)((B + D) e01 + Dγ20 (e02 γ10 − e01 γ20 )) + D(B + D)γ30 (e03 γ10 − e01 γ30 )] 2 2 ¯Q ¯ Q + D(C + D)γ 0 γ 0 M +((C + D)(B + D − Dγ 0 ) − D(B + D)γ 0 )M 2  
   
  3  
   
  1 2  
   
  1  
   
  2  
   
  ¯ Q = 0, +D(B + D)γ10 γ30 M 3 2  
   
  μ ¯ [D(A + D)γ20 (e02 γ30 − e03 γ20 ) + (B + D)(e03 (A + D − Dγ10 ) + De01 γ10 γ30 )] ¯ Q + (A + D)γ 0 M ¯ Q ) + ((B + D)(A + D − Dγ 02 ) +Dγ 0 ((B + D)γ 0 M 3  
   
  −D(A +  
   
  1  
   
  2  
   
  1  
   
  2 ¯Q D)γ20 )M 3  
   
  1  
   
  2  
   
  = 0.  
   
  (16)  
   
  1 [(C + D)((B + D) e01 + Dγ20 (e02 γ10 − e01 γ20 )) + D(B + D) σ ¯2 ¯ Q + [(C +D)((A + D) e0 + Dγ 0 (e0 γ 0 −e0 γ 0 )) ×γ30 (e03 γ10 − e01 γ30 )] M 2 1 1 2 2 1 1 0 0 0 ¯ Q + [D(A + D)γ20 (e02 γ30 − e03 γ20 ) +D(A + D)γ3 (e3 γ2 − e02 γ30 )] M 2  0 0 0 0 ¯Q , +(B + D)((A + D)e3 + Dγ1 (e1 γ3 − e03 γ10 ))] M 3  
   
  Here μ ¯=  
   
  2  
   
  2  
   
  σ ¯2 = (B + D)(C + D) e01 + (A + D)(C + D) e02 + (A + D)(B + D) e03  
   
  2  
   
  −D[(C + D)(e02 γ10 − e01 γ20 )2 + (B + D)(e03 γ10 − e01 γ30 )2 ¯ Q = b3 e0 − b2 e0 + a3 γ 0 − a2 γ 0 , +(A + D)(e03 γ20 − e02 γ30 )2 ], M 2 3 2 3 1 0 0 0 ¯ Q = −b3 e1 + b1 e3 − a3 γ1 + a1 γ30 , M ¯ Q = b2 e01 − b1 e02 + a2 γ10 − a1 γ20 . M 2  
   
  3  
   
  Equations (16) are linear with respect to ai , bi (i = 1, 2, 3). Considering them as unknowns, we ﬁnd, e.g., b2 , b3 , as the expressions of a1 , a2 , a3 , b1 , e0i , γi0 : b2 =  
   
  2 2 2 1 (b1 e02 (e01 + e02 + e03 ) + a3 (e01 e03 γ20 − e02 e03 γ10 ) 2 2 2 e01 (e01 + e02 + e03 ) 2  
   
  2  
   
  2  
   
  2  
   
  −a2 ((e01 + e02 )γ10 + e01 e03 γ30 ) + a1 ((e01 + e02 )γ20 + e02 e03 γ30 )), 2 2 2 2 2 1 (b1 e03 (e01 + e02 + e03 ) − a3 ((e01 + e03 )γ10 + e01 e02 γ20 ) b3 = 0 0 2 2 2 0 0 e1 (e1 + e2 + e3 ) 2  
   
  2  
   
  +a2 e02 (e01 γ30 − e03 γ10 ) + a1 (e02 e03 γ20 + (e01 + e03 )γ30 )).  
   
  (17)  
   
  0 0 0 0 0 0 Assuming e3 = e2 , γ3 = γ2 and a2 = a3 = 0, we obtain γ2 = −(b1 e2 ± 2 b2 1 − 2e02 )/a1 from the 1st relation (17). The 2nd relation (17) under the above value of γ20 takes the form b3 = b2 . So, when a2 = a3 = 0, b3 = b2 , we  
   
  On the Qualitative Analysis of the Equations of Motion  
   
  221  
   
  have 4 families of solutions of diﬀerential Eqs. (13):   a21 − 2z12 2 0 0 ω1 = ω3 = 0, e1 = − 1 − 2e2 , e2 = e3 = e2 , γ1 = ∓ , a1 z1 z1 γ2 = − , γ3 = − ; a1 a1   a21 − 2z22 2 0 0 ω1 = ω3 = 0, e1 = 1 − 2e2 , e2 = e3 = e2 , γ1 = ± , a1 z2 z2 (18) γ2 = − , γ3 = − . a1 a1   2 2 Here z1 = b1 e02 + b2 1 − 2e02 , z2 = b1 e02 − b2 1 − 2e02 , and e02 is the parameter of the families.   2 The integral V3 takes the form −(2e02 z1 ± 1 − 2e02 a21 − 2z12 )/a1 = c1 on the ﬁrsttwo families of solutions (18), and on the last two families, it is  2 −(2e02 z2 ∓ 1 − 2e02 a21 − 2z22 )/a1 = c1 . Thus, solutions (18) exist under any angles between vectors E and γ. From a mechanical point of view, the elements of the families of solutions (18) correspond to the equilibria of the mechanical system under study. From the stationary conditions ∂Φ/∂ω1 = 0, ∂Φ/∂ω3 = 0, ∂Φ/∂γj = 0, ∂Φ/∂ej = 0 (j = 1, 2, 3) of the integral 2Φ = 2λ0 H − λ1 V1 − λ2 V2 − 2λ3 V3 we ﬁnd the constraints on λi , under which the ﬁrst two families of solutions (18) satisfy these conditions:    2 e02 a21 − 2z12 ± 1 − 2e02 z1 b1 z1 ∓ b2 a21 − 2z12 z1 , λ2 = , λ3 = . λ0 = − 2 0 2 0 a1 e2 a1 e2 a1 e02 Having substituted the latter expressions into the integral Φ, we have:    2 2(e02 a21 − 2z12 ± 1 − 2e02 z1 ) b1 z1 ∓ b2 a21 − 2z12 H − V1 − V2 2Φ1,2 = ∓ a21 e02 a21 e02 2z1 − V3 . (19) a1 e02 By the same way, we ﬁnd the integrals taking a stationary value on the elements of the last two families of solutions (18):    2 2(e02 a21 − 2z22 ± 1 − 2e02 z2 ) b1 z2 ± b2 a21 − 2z22 H − V1 − V2 2Φ3,4 = ± a21 e02 a21 e02 2z2 − V3 . a1 e02  
   
  222  
   
  5  
   
  V. Irtegov and T. Titorenko  
   
  On Pendulum-Like Motions  
   
  In the problem under consideration, we could not obtain solutions corresponding to permanent rotations of the mechanical system. These motions are typical of rigid body dynamics. Basing on the analysis of the equations of motion (5) and (13), one can suppose that there are no such solutions. However, under the action of external potential forces the mechanical system can perform pendulum-like oscillations. When a2 = a3 = b1 = 0, the relations ω3 = 0, γ1 = ±1, γ2 = γ3 = e1 = 0  
   
  (20)  
   
  deﬁne two IMs of codimension 5 of the equations of motion (13). The diﬀerential equations on these IMs are written as ω˙ 1 =  
   
  b3 e2 − b2 e3 , e˙ 2 = e3 ω1 , e˙ 3 = −e2 ω1 A  
   
  and describe the pendulum-like oscillations of the body with a ﬁxed point relative to the axis Ox in the frame rigidly attached to the body. The integral V3 on IMs (20) is equal to zero identically that corresponds to the case of orthogonal vectors γ, E. The integral Ψ = (V1 − 1)V3 assumes a stationary value on IMs (20). Let us consider another similar solution for equations (13). It is the IM of codimension 3: ω1 = γ3 = e3 = 0.  
   
  (21)  
   
  This solution exists for a3 = b3 = 0. The diﬀerential equations on IM (21) b2 e1 − b1 e2 + a2 γ1 − a1 γ2 , C +D γ˙ 1 = γ2 ω3 , γ˙ 2 = −γ1 ω3 , e˙ 1 = e2 ω3 , e˙ 2 = −e1 ω3 ω˙ 3 =  
   
  describe the pendulum-like oscillations of the body relative to the axis Oz. The motions exist under any angle between the vectors γ, E, because the integral V3 on IM (21) takes the form: e1 γ1 + e2 γ2 = c1 . So, it is the family of IMs.  
   
  6  
   
  On the Stability of Stationary Sets  
   
  In this Section, we investigate the stability of the above found solutions on the base of the Lyapunov theorems on the stability of motion. To solve the problems, which often arise in the process of the analysis, the software package [7] written in Mathematica language is applied. In particular, the package gives a possibility to obtain the equations of the ﬁrst approximation and their characteristic polynomial, using the equations of motion and the solution under study  
   
  On the Qualitative Analysis of the Equations of Motion  
   
  223  
   
  as input data, and then, to conduct the analysis of the polynomial roots, basing on the criteria of asymptotic stability of linear systems. When the problem of stability is solved by the Routh–Lyapunov method, the package, using the solution under study and the ﬁrst integrals of the problem as input data, constructs a quadratic form and the conditions of its sign-deﬁniteness in the form of the Sylvester inequalities. Their analysis is performed by means of Mathematica built-in functions, e.g., Reduce, RegionPlot3D. 6.1  
   
  The Case of Absence of External Forces  
   
  Let us investigate the stability of one of IMs (12), e.g., ω1 = ω3 = 0, e1 − γ1 = 0, e2 − γ2 = 0, e3 − γ3 = 0, γ12 + γ22 + γ32 = 1, using the integral 2K21 = 2λ0 H −λ1 (V1 +V2 −2V3 )−2λ4 F1 −2λ5 F2 for obtaining its suﬃcient conditions. We use the maps ω1 = 0, ω3 = 0, e1 = ±z, e2 = γ2 , e3 = γ3 , γ1 = ±z  on this IM. From now on, z = 1 − γ22 − γ32 . Introduce the deviations: y1 = ω1 , y2 = ω3 , y3 = e1 − z, y4 = e2 − γ2 , y5 = e3 − γ3 , y6 = γ1 − z. The 2nd variation of the integral K21 on the set deﬁned by the ﬁrst variations of the conditional integrals δV1 = ±2z y6 = 0, δV2 = 2(γ2 y4 + γ3 y5 ± z y3 ) = 0, δV3 = γ2 y4 + γ3 y5 ± z (y3 + y6 ) = 0, is written as: 2δ 2 K21 = α11 y12 + α12 y1 y2 + α22 y22 + α33 y32 + α34 y3 y4 + α24 y2 y4 + α13 y1 y3 +α23 y2 y3 + α14 y1 y4 + α44 y42 , where ((A − B) γ22 + (B + D)(1 − γ32 )) λ0 (B + D) γ3 zλ0 , α12 = ± , 2γ22 γ22 ((C + D) γ22 + (B + D) γ32 ) λ0 (γ 2 − 1) λ1 γ2 λ1 z = , α33 = 2 2 , α34 = ∓ , 2 2γ2 2γ3 γ32  (C + D) γ (B + D) γ3  (γ 2 + γ32 ) λ1 2 λ6 ∓ (B − C) zλ5 , α44 = − 2 = + , γ3 γ2 2γ32 ((A − B) γ22 + B + D) zλ5 =∓ − (A + D)λ6 , γ2 γ3 1 =− ((B + D) γ3 λ5 ∓ (C + D) γ2 zλ6 ) + (B − C) γ2 λ5 , γ2 γ3 1 =− (((B + D) + (A − B) γ22 ∓ (B + D) γ3 zλ6 ) γ2 λ5 ) − (A − B) γ3 λ5 . γ2 γ3  
   
  α11 = α22 α24 α13 α23 α14  
   
  224  
   
  V. Irtegov and T. Titorenko  
   
  The conditions of sign-deﬁniteness of the quadratic form δ 2 K21 (γ22 − 1) λ1 λ2 > 0, Δ2 = 21 > 0, 2 γ3 γ3 λ1 Δ3 = 2 2 [((C + D) γ22 + (B + D) γ32 ) λ0 λ1 + ((C + D)2 γ22 + ((B + D)2 γ2 γ3  
   
  Δ1 =  
   
  −(B − C)2 γ22 ) γ32 )(λ25 + λ26 )] > 0, 1 Δ4 = 2 2 ((C + D)(B + D + (A − B)γ22 ) + (A − C)(B + D)γ32 ) γ2 γ3 ×[λ20 λ21 + (B + C + 2D + (A − B) γ22 + (A − C) γ32 ) λ0 λ1 (λ25 + λ26 ) +((C +D)(B +D +(A−B) γ22 )+(A−C)(B +D) γ32 )(λ25 +λ26 )2 ] > 0. (22) are suﬃcient for the stability of the IM under study. The diﬀerential equations γ˙ 2 = 0, γ˙ 3 = 0 on IMs (12) have the family of solutions: γ2 = γ20 = const, γ3 = γ30 = const.  
   
  (23)  
   
  Thus, each of IMs (12) can be considered as a family of IMs, where γ20 , γ30 are the parameters of the family. Let γ30 = γ20 and λ5 = λ6 = λ1 . Taking into consideration (23) and the above constraints, inequalities (22) take the form: 2  
   
  (γ20 − 1) λ1 λ21 > 0, 2 2 > 0, γ20 γ20 λ21 2 2 2 02 2 ((B + C + 2D)λ0 + 2((B + D) + (C +D) −(B −C) γ2 ) λ1 ) > 0, 0 γ2 λ21 02 4 ((B + D)(C + D) + ((A − D)(B + C) + 2(AD − BC)) γ2 ) γ20 2  
   
  ×(λ20 + 2(B + C + 2D − (B + C − 2 A) γ20 )λ0 λ1 + 4((B + D)(C + D) 2  
   
  +((A − D)(B + C) + 2(AD − BC)) γ20 )λ21 ) > 0. With the help of the built-in function Reduce, we ﬁnd the conditions of compatibility of the latter inequalities: A > B > C > 0 and A < B + C, D > 0 and    σ3 σ3 λ0 > 0 and σ1 < λ1 < σ2 − or σ2 + < λ1 < 0 and 4 4   1 1 0 0 − 1 < γ2 < − √ or √ < γ2 < 1 or 2 2   σ3 1 1  < λ1 < 0 and − √ ≤ γ20 < 0 or 0 < γ20 ≤ √ . λ0 > 0 and σ2 + 4 2 2  
   
  On the Qualitative Analysis of the Equations of Motion  
   
  225  
   
  Here σ1 =  
   
  2((B −  
   
  2 C)2 γ20  
   
  (B + C + 2D)λ0 , − (B 2 + C 2 + 2BD + 2D(C + D))) 2  
   
  ((B + C + 2D − (B + C − 2 A)γ20 )λ0 , 2 4((2BC + (B + C)D − A(B + C + 2D))γ20 − (B + D)(C + D))  2 4 (B − C)2 − 2(B − C)2 γ20 + (B + C − 2 A)2 γ20 λ0 σ3 = 2 . (B + D)(C + D) + (A(B + C + 2D) − 2BC − (B + C)D)γ20 σ2 =  
   
  The constraints on the parameter γ20 give the suﬃcient conditions of stability for the elements of the family of IMs. The constraints imposed on the parameters λ0 , λ1 isolate a subfamily of the family of the integrals K21 , which allows one to obtain these suﬃcient conditions. The analysis of stability of the 2nd IM of IMs (12) is done analogously. Let us investigate the stability of IM (7), using the integral 2K1 = 2λ0 H − λ1 (V1 − V2 )2 − λ2 F1 F2 for obtaining suﬃcient conditions. The analysis is done in themap ω1 = 0, ω3 = 0, γ1 = −z1 , e1 = −z2 on this IM. From now on, z1 = 1 − γ22 − γ32 , z2 = 1 − e22 − e23 . In order to reduce the amount of computations we restrict our consideration by the case when the following restrictions are imposed on the geometry of mass of the mechanical system: A = 3 C/2, B = 2 C, D = C/2. Introduce the deviations from the unperturbed solution: y1 = ω1 , y2 = ω2 , y3 = γ1 + z1 , y4 = e1 + z2 . The 2nd variation of the integral K1 in the deviations on the set δV1 = −2z1 y3 = 0, δV2 = −2z2 y4 = 0 has the form: 2δ 2 K1 = β11 y12 + β12 y1 y2 + β22 y22 , where β11 , β12 , β22 are the expressions of C, γ2 , γ3 , e2 , e3 . These are bulky enough and presented entirely in Appendix. Taking into consideration that γ2 = γ20 = const, γ3 = γ30 = const, e2 = e02 = const, e3 = e03 = const (9) on IM (7), and introducing the restrictions on the parameters γ30 = γ20 , e03 = e02 , we write the conditions of positive deﬁniteness of the quadratic form 2δ 2 K1 (the Sylvester inequalities) as follows:  
   
  226  
   
  V. Irtegov and T. Titorenko  
   
   2 2 2 2 Δ1 = 2[ 1 − 2e02 (γ20 + e02 (1 − 4γ20 ))  2 2 −2e02 γ20 (1 − 2e02 ) 1 − 2γ20 ] z + 1 > 0,   2 2 1  2 2 2 Δ2 = − 02 8γ20 + e02 (6 − 32γ20 ) − 15 − 16e02 1 − 2e02 γ20 1 − 2γ20 e2    2 2 2 2 2 2 +2 2e02 γ20 (1 − 2e02 )(15 − 14e02 − 16γ20 (1 − 4e02 )) 1 − 2γ20 + 1 − 2e02 2  
   
  2  
   
  4  
   
  2  
   
  2  
   
  2  
   
  2  
   
  4  
   
  2  
   
  2  
   
  ×(3e02 (2e02 − 5) − (120e02 − 106e02 + 15) γ20   4 4 2 4 2 +8(32e02 − 16e02 + 1) γ20 ) z + γ20 (15 − 8γ20 )2   2 2 2 2 2 +4e02 1 − 2e02 γ20 1 − 2γ20 (15−14e02 −16(1 − 4e02 ) γ20 ) 4  
   
  2  
   
  4  
   
  ×(3e02 (2e02 − 5) − (120e02 − 106e02 + 15) γ20 + 8(32e02 − 16e02 + 1) γ20 ) 2  
   
  2  
   
  2  
   
  6  
   
  4  
   
  2  
   
  +e02 (9e02 (5 − 2e02 )2 − 2(1504e02 − 4508e02 + 3420e02 − 675) γ20 6  
   
  4  
   
  2  
   
  4  
   
  6  
   
  2  
   
  +4(8736e02 − 17264e02 + 9761e02 − 1785)γ20 − 32(3840e02 − 5312e02   2 6 2 2 8 +2300e02 − 325) γ20 − 4096(1 − 4e02 )2 (1 − 2e02 ) γ20 ) z 2 > 0.  
   
  4  
   
  (24)  
   
  Here z = Cλ2 , λ0 = 1. The system of inequalities (24) has been solved graphically. The built-in function RegionPlot3D is used. The region, in which the inequalities have common values, is shown in Fig. 2 (dark region). Thus, when the values of the parameters z, e02 , γ20 lie in this region, the IM under study is stable. 6.2  
   
  The Case of the Presence of External Forces  
   
  In this Subsection, we analyze the stability of the elements of the families of solutions (18). Let us investigate one of the ﬁrst two families, e.g.,   a21 − 2z 2 2 0 0 ω1 = ω3 = 0, e1 = − 1 − 2e2 , e2 = e3 = e2 , γ1 = − , a1 z z (25) γ2 = − , γ3 = − , a1 a1  2 where z = b1 e02 + b2 1 − 2e02 . The integral    2 2(e02 a21 −2z 2 + 1 − 2e02 z) b1 z − b2 a21 − 2z 2 2z H −V1 − V2 − V3 2Φ1 = − a21 e02 a21 e02 a1 e02 is used for obtaining the suﬃcient conditions.  
   
  On the Qualitative Analysis of the Equations of Motion  
   
  Fig. 2. The region of stability of the IM for γ20 ∈ [− √12 ,  
   
  1 √ ],e02 2  
   
  ∈ (0,  
   
  1 √ ], 2  
   
  227  
   
  z ∈ (0, 3]  
   
  In the deviations   a21 − 2z 2 2 y1 = e1 + 1 − 2e02 , y2 = e2 − e02 , y3 = e3 − e02 , y4 = γ1 + , a1 z z y5 = γ2 + , y6 = γ3 + , y7 = ω1 , y8 = ω2 a1 a1 on the linear manifold  
   
    2 z(y5 + y6 )+ a21 −2z 2 y4 = 0, δH = b1 y1 + b2 (y2 + y3 ) + a1 y4 = 0, δV1 = − a1  2 0 δV2 = 2(e2 (y2 + y3 ) − 1 − 2e02 y1 ) = 0,    1 2 z(y2 + y3 ) + a21 − 2z 2 y1 = 0 δV3 = e02 (y5 + y6 ) − 1 − 2e02 y4 − a1  
   
  the 2nd variation of the integral Φ1 has the form: δ 2 Φ1 = Q1 + Q2 , where   2 2 1  2 Q1 = 2 03 (3b2 e02 1−2e02 −b1 (1 − 4e02 )) z + b2 (1 − e02 ) a21 − 2z 2 2a1 e2      1  2 2 0 2 0 2 2 −a1 e2 y1 + 2 02 1 − 2e2 (b1 z−b2 a1 −2z )− a21 −2z 2 z y1 y2 a1 e2       1 1  0 2 2 −2z 2 − a + 2 0 b2 a21 −2z 2 −b1 z y22 + 1−2e02 z y1 y6 e 2 2 1 0 a1 e2 a1 e2  
   
  228  
   
  V. Irtegov and T. Titorenko  
   
  2z y2 y6 − y62 , a1 e02    B + C + 2D  02 z + e0 2 − 2z 2 y 2 Q2 = − 1 − 2e a 2 8 2 1 2a21 e02  2   (B + D) 1 − 2e02  02 z + e0 2 − 2z 2 y y + 1 − 2e a 7 8 2 2 1 2 a21 e02   2 2 1  2 − 4 03 a21 [(Ae02 + B(1 − 2e02 ))( 1 − 2e02 z + e02 a21 − 2z 2 ) 2a1 e2    2 2 2 +D 1 − 2e02 ((1 − 4e02 ) z + e02 1 − 2e02 a21 − 2z 2 )]  2 3 2 2 2 −D [(1 − 8e02 )(b31 e02 1 − 2e02 + b32 (1 − 2e02 )2 + 3b1 b2 e02 (1 − 2e02 ) z)   2 +e02 (3 − 8e02 ) a21 − 2z 2 z 2 ] y72 . +  
   
  The analysis of sign-deﬁniteness of the quadratic forms Q1 and Q2 was done for the case when b1 = 0 and A = 3 C/2, B = 2 C, D = C/2. Under these restrictions on the parameters, the conditions of negative deﬁniteness of the quadratic forms Q1 and Q2 are respectively written as:   2 1  2 Δ1 = −1 < 0, Δ2 = − 2 02 b2 (b2 (1 − 2e02 ) + e02 a21 − 2b22 (1 − 2e02 )) > 0, a1 e2 2 4 2 b2  Δ3 = 4 05 2b2 e02 (a21 (1 − 3e02 ) − b22 (16e02 − 14e02 + 3)) a e 1 2  2 4 2 2 + a21 − 2b22 (1 − 2e02 ) (a21 e02 + b22 (16e02 − 10e02 + 1)) < 0 (26) and   2C  02 0 2 − 2b2 (1 − 2e02 ) < 0, b a (1 − 2e ) + e 2 2 2 2 1 2 a21 e02 2 2 2 4 2 C2  Δ2 = 6 04 3a41 e02 (5 − 2e02 ) − 8b42 (1 − 2e02 )2 (32e02 − 16e02 + 1) a1 e2  
   
  Δ1 = −  
   
  2  
   
  4  
   
  2  
   
  2  
   
  +a21 b22 (15 − 4e02 (60e02 − 83e02 + 34)) − 2b2 e02 (1 − 2e02 )   2 4 2 2 ×(a21 (14e02 −15) + 16b22 (8e02 −6e02 +1)) a21 −2b22 (1−2e02 ) > 0. (27) Taking into consideration the conditions for solutions (25) to be real    1 1 1 (28) a1 = 0 and e02 = ± √ or − √ < e02 < √ and − σ1 ≤ b2 ≤ σ1 2 2 2 under the above restrictions on the parameters b1 , A, B, D, inequalities (26) and (27) are compatible when the following conditions  
   
  On the Qualitative Analysis of the Equations of Motion  
   
    
   
  1  b2 < 0, σ2 < e02 ≤ √ or 2   1 b2 > 0, − √ ≤ e02 < −σ2 2  
   
  a1 = 0, C > 0 and  
   
  hold.  Here σ1 =  
   
  a21 2 , σ2 = 2(1 − 2e02 )  
   
  229  
   
   a21  
   
  (29)  
   
  b22 . + 2b22  
   
  The latter conditions are suﬃcient for the stability of the elements of the family of solutions under study. Let us compare them with necessary ones which we shall obtain, using the Lyapunov theorem on stability in linear approximation [9]. The equations of the 1st approximation in the case considered are written as:  √ √ √ 1 y˙ 1 = 2e02 y8 − z1 y7 , y˙ 2 = e02 y7 + z1 y8 , y˙ 3 = e02 − 0 y7 + z1 y8 , e2    √ b2  z 1 1 2 − 2b2 z y − b √z y , , y ˙ y − 2 z y = a y˙ 4 = 7 1 8 5 2 1 7 1 2 1 8 a1 e02 a1  √  √ 1  a21 − 2b22 z1 (e02 y8 − z1 y7 ) y˙ 6 = , + b z y 2 1 7 a1 e02  2 √ 1 y˙ 7 = 16a21 b2 e02 (y3 − y2 ) + 2a21 e02 z1 (5a1 y5 − 2b2 y1 − 3a1 y6 ) , z2 2 2 1  2 2a1 [b2 (4e02 − 5) y1 + 5a1 y5 + a1 e02 (3y6 − 7y5 )] y˙ 8 = z2 2 √ +10a21 b2 e02 z1 (y3 − y2 ) + 2b22 z1 (4e02 − 1)(a1 (y5 + y6 ) − 2b2 y1 )   −4b2 e02 z1 a21 − 2b22 z1 (a1 (y5 + y6 ) − 2b2 y1 ) . (30) 2  
   
  2  
   
  2  
   
  Here z1 = 1−2e02 , z2 = C(3a21 (2e02 −5)−8b2 z1 (b2 (4e02 −1)−2e02 The characteristic equation of system (30) has the form: λ4 (λ4 + α1 λ2 + α2 ) = 0,  
   
    
   
  a12 − 2b22 z1 )). (31)  
   
  where 2 4 4 2 4C  α1 = 2 a41 e02 [2b2 (251e02 − 122e02 − 137) + 3(10e02 − 33e02 + 20) z   2 4 2 4 2 04 02 2 2 a1 − 2b2 z1 ] + 8b2 z1 [(64e2 −24e2 + 1) a21 − 2b22 z1 −2b2 e02 (64e02 −40e02  4 2 4 2 +5)] − a21 b22 z1 [(432e02 − 518e02 + 47) a21 − 2b22 z1 − 2b2 e02 (560e02 − 706e02  +173)] ,  
   
  230  
   
  V. Irtegov and T. Titorenko 6 4 2 2 2 1  4 2 (8a1 b2 (240e02 − 408e02 + 206e02 − 19) + 12a61 (4e02 (e02 − 3) 2 z2  6 4 2 +5) − 64a21 b42 (64e02 − 80e02 + 24e02 − 1) z1 ) − 8a21 b2 e02 a21 − 2b22 z1  4 2 4 2 ×(a21 (56e02 − 110e02 + 53) − 8b22 (32e02 − 32e02 + 5) z1 ) .  
   
  α2 =  
   
  The roots of the bipolynomial in the round brackets are purely imaginary when the conditions α1 > 0, α2 > 0, α12 − 4α2 > 0 hold. Taking into consideration (28), the latter inequalities are hold under the following constraints imposed on the parameters C, a1 , b2 , e02 :   3a1 3a1 a1  C > 0 and a1 < 0 and and b2 < √ or √ < b2 < √ 2 2 2  ρ1 ρ1 1  3a1 1  a1 ≤ e02 ≤ √ ≤ e02 < √ or b2 = √ and or b2 = √ and 2 2 2 2 2 2  a  ρ1 1 1 1 − < e02 ≤ √ or √ < b2 < 0 and ρ2 < e02 ≤ √ or 2 2 2 2    1 a1 0 < b2 < √ and − √ ≤ e02 < −ρ2 or C > 0 and a1 > 0 and 2 2  a  1 3a 3a ρ  √1 < b2 < √ 1 or b2 > √ 1 and − √ ≤ e02 ≤ − 1 or 2 2 2 2 2   1 a1 ρ1  3a1 0 b2 = √ and − √ ≤ e2 < − or b2 = √ and 2 2 2 2  1 ρ 1 . (32) − √ < e02 ≤ − 2 2  Here ρ1 =  
   
  2b22 − a21 , ρ2 = b22  
   
    
   
   a21 + b22 − b22 (2a21 + 5b22 ) . 2a21 + 4b22  
   
  The analysis of zero roots of characteristic Eq. (31) was done by the technique applied in [10]. The analysis shown that the characteristic equation has zero roots with simple elementary divisors. Whence it follows, the elements of the family of solutions under study are stable in linear approximation when conditions (32) hold. Comparing them with (29), we conclude that the suﬃcient conditions are close to necessary ones. The analogous result has been obtained for the 2nd family of solutions. Instability was proved for the rest of the families of solutions.  
   
  7  
   
  Conclusion  
   
  The qualitative analysis of the diﬀerential equations describing the motion of the nonholonomic mechanical system has been done. The solutions of these  
   
  On the Qualitative Analysis of the Equations of Motion  
   
  231  
   
  equations, which correspond to the equilibria and pendulum-like motions of the mechanical system, have been found. The Lyapunov stability of the solutions has been investigated. In some cases, the obtained suﬃcient conditions were compared with necessary ones. The analysis was done nearly entirely in symbolic form. Computational diﬃculties were in the main caused by the problem of bulky expressions: the diﬀerential equations are rather bulky, and the ﬁrst integrals of these equations are the polynomials of the 2nd–5th degrees. Computer algebra system Mathematica was applied to solve computational problems. The results presented in this work show the eﬃciency of the approach used for the analysis of the problem as well as computational tools.  
   
  Appendix  β11 = (4e22 )−1 C ((e23 − 1)(γ22 − 5) − e22 (1 − γ22 + z12 ) + 2e2 γ2 z1 z2 ) λ0 +C [(5e53 γ2 (3γ32 − z12 ) + e2 e43 γ3 (43γ22 + 20γ32 − 25) + e2 γ3 (e22 − 5) ×(5 − 3γ22 − γ32 + e22 (4γ22 + γ32 − 2)) + e2 e23 γ3 (50 − 58γ22 − 25γ32 +e22 (59γ22 + 17γ32 − 27)) + e3 γ2 (e22 (65 − 37γ22 − 46γ32 ) + 5(γ22 + 3γ32 − 5) +e42 (36γ22 + 23γ32 − 28)) + e33 γ2 (e22 (37γ22 + 55γ32 − 33) − 5(2γ22 + 7γ32 − 6))) z1 +(e42 γ2 γ3 (4(1 − γ22 ) − 3γ32 ) + e22 γ2 γ3 (21γ22 + 16γ32 − 25 + e23 (53 − 57γ22 −45γ32 )) − 5γ2 γ3 (e23 − 1)(5 − γ22 − γ32 + e23 (3γ22 + 4γ32 − 3)) − e32 e3 (10 + 36γ24 −18γ32 + 7γ34 + γ22 (41γ32 − 46)) + e2 e3 (25 − 60γ22 + 19γ24 + (44γ22 − 45)γ32  
   
  +15γ34 − e23 (10 − 29γ22 + 19γ24 + (53γ22 − 35)γ32 + 20γ34 ))) z2 ] λ2 ,  β22 = (4e22 )−1 C (3e22 + 5e23 − (e3 γ2 − e2 γ3 )2 ) λ0 + C [(3e52 γ3 (4γ22 + γ32 − 1)  
   
  +e42 e3 γ2 (15 − 12γ22 + 19γ32 ) − 5e33 γ2 (5 − γ22 − 3γ32 + e23 (γ22 + 4γ32 − 1)) +e22 e3 γ2 (9γ22 − 13γ32 − 21 + e23 (24 − 19γ22 + 5γ32 )) + e2 e23 γ3 (5 + 11γ22 − 15γ32 +e23 (15 − 21γ22 + 20γ32 )) + e32 γ3 (3(3 − 3γ22 − γ32 ) + e23 (8 − 3γ22 + 21γ32 ))) z1 +(3e42 γ2 γ3 (3 − 4γ22 − 3γ32 ) + e22 γ2 γ3 (e23 (9γ22 − 15γ32 − 14) + 3 (γ22 + γ32 − 3)) +5e23 γ2 γ3 (5 − γ22 − γ32 + e23 (3γ22 + 4γ32 − 3)) + e32 e3 (6 + 12γ24 + 5γ32 − 11γ34 2 4 2 4 −γ22 (21 + 13γ32 )) + e2 e3 (5γ32 (γ32 − 3) + γ22 (15  + 2γ3 ) − 3γ2 + e3 (13γ2  
   
  +γ22 (11γ32 − 23) − 5 (γ32 + 4γ34 − 2)))) z2 ] λ2 ,  β12 = (4e22 )−1 C 2 (e2 (e2 γ3 − e3 γ2 ) z1 + (e3 (γ22 − 5) − e2 γ2 γ3 ) z2 ) λ0  
   
  +C [2e42 e3 γ2 γ3 (14γ22 + 9γ32 − 15) + 10e3 γ2 γ3 (e23 − 1)(5 − γ22 − γ32 +e23 (3γ22 + 4γ32 − 3)) + 2e52 (3 + 12γ24 + γ32 (γ32 − 4) + γ22 (11γ32 − 15)) +2e22 e3 γ2 γ3 (29 − 20γ22 − 7γ32 + e23 (39γ22 + 23γ32 − 40)) + e32 (γ32 (10 + 3γ32 ) −24γ24 − 15 + γ22 (51 − 13γ32 ) + e23 (62γ24 + 2γ32 (2γ32 − 19) + 2γ22 (31γ32 − 46) +26)) + e2 (3γ22 (γ22 − 5) + (15 − 2γ22 )γ32 − 5γ34 + 4e43 (8γ22 − 5)(γ22 + 2γ32 − 1) +e23 (γ22 (98 − 53γ32 ) + 5(γ32 (2γ32 + 7) − 7) − 35γ24 )) + 2(2e32 e3 γ3 (7γ22 + γ32 − 4) +e42 γ2 (12γ22 + 5γ32 − 9) + e2 e3 γ3 (10 − 13γ22 + 4e23 (8γ22 − 5) + 5γ32 ) +5e23 γ2 (5 − γ22 − 3γ32 + e23 (γ22 + 4γ32 − 1)) + e22 γ2 (15 − 6γ22 + 2γ32  +e23 (25γ22 + 13γ32 − 26))) z1 z2 ] λ2 .  
   
  232  
   
  V. Irtegov and T. Titorenko  
   
  References 1. Chaplygin, S.A.: On rolling a ball on a horizontal plane. Matematicheskii Sbornik 1(24), 139–168 (1903) 2. Veselov, A.P., Veselova, L.E.: Integrable nonholonomic systems on Lie groups. Math. Notes 5(44), 810–819 (1988) 3. Borisov, A.V., Mamaev, I.S.: A new integrable system of nonholonomic mechanics. Dokl. Phys. 60, 269–271 (2015) 4. Alves, J., Dias, J.: Design and control of a spherical mobile robot. J. Syst. Control Eng. 217, 457–467 (2003) 5. Lyapunov, A.M.: On permanent helical motions of a rigid body in fluid. Collected Works USSR Acad. Sci. 1, 276–319 (1954) 6. Irtegov, V.D., Titorenko, T.N.: On an approach to qualitative analysis of nonlinear dynamic systems. Numer. Analys. Appl. 1(15), 48–62 (2022) 7. Banshchikov, A.V., Burlakova, L.A., Irtegov, V.D., Titorenko, T.N.: Software Package for Finding and Stability Analysis of Stationary Sets. Certificate of State Registration of Software Programs. FGU-FIPS, No. 2011615235 (2011) 8. Irtegov, V., Titorenko, T.: On stationary motions of the generalized Kowalewski gyrostat and thier stability. In: Gerdt, V.P., et al. (eds.) CASC 2017. LNCS, vol. 10490, pp. 210–224. Springer, Heidelberg (2017). https://doi.org/10.1007/978-3319-66320-3 16 9. Lyapunov, A.M.: The general problem of the stability of motion. Int. J. Control 55(3), 531–534 (1992) 10. Irtegov, V., Titorenko, T.: On equilibrium positions in the problem of the motion of a system of two bodies in a uniform gravity field. In: Boulier, F., et al. (eds.) CASC 2022. LNCS, vol. 13366, pp. 165–184. Springer Nature AG, Cham, Switzerland (2022). https://doi.org/10.1007/978-3-031-14788-3 10  
   
  Solving Parametric Linear Systems Using Sparse Rational Function Interpolation Ayoola Jinadu(B) and Michael Monagan Department of Mathematics, Simon Fraser University, Burnaby, BC V5A 1S6, Canada {ajinadu,mmonagan}@sfu.ca Abstract. Let Ax = b be a parametric linear system where the entries of the matrix A and vector b are polynomials in m parameters with integer coeﬃcients and A be of full rank n. The solutions xi will be rational functions in the parameters. We present a new algorithm for computing x that uses our sparse rational function interpolation which was presented at CASC 2022. It modiﬁes Cuyt and Lee’s sparse rational function interpolation algorithm to use a Kronecker substitution on the parameters. A failure probability analysis and complexity analysis for our new algorithm is presented. We have implemented our algorithm in Maple and C. We present timing results comparing our implementation with a Maple implementation of Bareiss/Edmonds/Lipson fraction free Gaussian elimination and three other algorithms in Maple for solving Ax = b. Keywords: Parametric linear systems · Sparse rational function interpolation · Kronecker substitution · Failure probability · Black box  
   
  1  
   
  Introduction  
   
  Consider the parametric linear system Ax = b where the coeﬃcient matrix A ∈ Z[y1 , y2 , . . . , ym ]n×n is of full rank n and b ∈ Z[y1 , y2 , . . . , ym ]n is the right hand side column vector such that the number of terms in the entries of A and b denoted by #Aij , #bi ≤ t and deg(Aij ), deg(bi ) ≤ d. It is well know that the solution x is unique since rank(A) = n. In this paper we aim to compute the solution vector of rational functions  T T  f1 f2 fn ··· x = x1 x2 · · · xn = (1) g1 g2 gn such that fk , gk ∈ Z[y1 , y2 , . . . , ym ], gk = 0, gk |det(A) and gcd(fk , gk ) = 1 for 1 ≤ k ≤ n. Using Cramer’s rule, the solutions of Ax = b are given by xi =  
   
  det(Ai ) ∈ Z(y1 , . . . , ym ) det(A)  
   
  (2)  
   
  where Ai is the matrix obtained by replacing the i-th column of A with the right hand side column vector b and det(A) is a polynomial in Z[y1 , y2 , . . . , ym ]. Let x ˜i = xi det(A) be a polynomial in Z[y1 , y2 , . . . , ym ]. c The Author(s), under exclusive license to Springer Nature Switzerland AG 2023  F. Boulier et al. (Eds.): CASC 2023, LNCS 14139, pp. 233–254, 2023. https://doi.org/10.1007/978-3-031-41724-5_13  
   
  234  
   
  A. Jinadu and M. Monagan  
   
  Maple and other computer algebra systems such as Magma have an implementation of the Bareiss/Edmonds one step fraction free Gaussian elimination algorithm [2,5] which triangularizes an augmented matrix B = [A|b] to obtain det(A) as a polynomial in Z[y1 , y2 , . . . , ym ] and then solves for the polynomials x ˜i via back substitution using Lipson’s fraction free back formula [8]. Ignoring pivoting, the following pseudo-code of the Bareiss/Edmonds algorithm and Lipson’s fraction free back substitution formula solves Ax = b: Algorithm 1: BareissPseudocode Input: Coeﬃcient matrix A, column vector b with n ≥ 1 and m ≥ 1. Output: Vector x ∈ Z(y1 , y2 , . . . , ym )n 1 B := [A|b ] ; B0,0 := 1; 2 // fraction free triangularization begins 3 for k = 1, 2, . . . , n − 1 do 4 for i = k + 1, k + 2, . . . , n do 5 for j = k + 1, k + 2, . . . , n + 1 do 6  
   
  Bi,j := 7 8 9 10 11 12 13 14 15  
   
  Bk,k Bi,j − Bi,k Bk,j ; Bk−1,k−1  
   
  (3)  
   
  end do Bi,k := 0; end do end do // fraction free back substitution begins x ˜n := Bn,n+1 ; for i = n − 1, n − 2, . . . , 2, 1 do Ni := Bi,n+1 Bn,n − n ˜j ; j=i+1 Bi,j x Di := Bi,i ;  
   
  16  
   
  x ˜i := 17 18 19 20 21 22 23  
   
  Ni ; Di  
   
  (4)  
   
  end do // simpliﬁcation begins for i = 1, 2, . . . , n do hi = gcd(˜ xi , Bn,n ); x ˜i Bn,n fi := ; gi := ; hi hi xi := fi /gi ; end do  
   
  Note that the divisions by Bk,k and Di are exact in Z[y1 , y2 , . . . , ym ] and Bk,k is the determinant of the principle k by k submatrix of A. However there is an expression swell because at the last major step of triangularizing B when k = n − 1 where it computes Bn,n =  
   
  Bn−1,n−1 Bn,n − Bn,n−1 Bn−1,n = det(A), Bn−2,n−2  
   
  (5)  
   
  Solving Parametric Linear Systems  
   
  235  
   
  the numerator polynomial in (5) is the product of determinants Bn,n Bn−2,n−2 ∈ Z[y1 , y2 , . . . , ym ].  
   
  (6)  
   
  If the original entries Bi,j from the augmented matrix B = [A|b] are sparse polynomials in many parameters then the numerator polynomial in (5) may be 100 times or more larger than det(A). The same situation also holds for the polynomials x ˜i . One approach to avoid this expression swell tried by Monagan and Vrbik [15] computes the quotients of (3) and (4) directly using lazy polynomial arithmetic. Another approach is to interpolate the polynomials x ˜i and det(A) directly from points using sparse polynomial interpolation algorithms [3,17] and Chinese remaindering when needed. This approach is described brieﬂy as follows. Pick ˜(α) using an evaluation point α ∈ Zm p and solve A(α)x(α) = b(α) mod p for x Gaussian elimination over Zp and also compute det(A(α)) at the same time. Provided det(A(α)) = 0, then x ˜i (α) = xi (α) × det(A(α)). Thus we have images of x ˜i and det(A) so we can interpolate them. xi , det(A)) for 1 ≤ To compute x in simplest terms, we compute hi = gcd(˜ x ˜i to simplify the solutions. However, in practice i ≤ n and cancel them from det(A) x ˜i there may be a large cancellation in det(A) . Our new algorithm will interpolate xi directly thus avoiding any gcd computations which may be expensive.  
   
  Example 1. Consider the following linear system of 21 equations in variables x1 , x2 , . . . , x21 and parameters y1 , y2 , . . . , y5 : x7 + x12 = 1, x8 + x13 = 1, x21 + x6 + x11 = 1, x1 y1 + x1 − x2 = 0 x3 y2 + x3 − x4 = 0, x11 y3 + x11 − x12 = 0, x16 y5 − x17 y5 − x17 = 0 y3 (−x20 + x21 ) + x21 = 0, y3 (−x5 + x6 ) + x6 − x7 = 0, −x8 y4 + x9 y3 + x9 = 0 y2 (−x10 + x18 ) + x18 − x19 = 0, y4 (x14 − x13 ) + x14 − x15 = 0 2x3 (y22 − 1) + 4x4 − 2x5 = 0, 2y12 (x1 − 1) − 2x10 + 4x2 = 0 2y32 (x19 − 2x20 + x21 ) − 2x21 = 0, 2y42 (x7 − 2x8 + x9 ) − 2x9 = 0 2x11 (y32 − 1) + 4x12 − 2x13 = 0, 2y42 (x12 − 2x13 + x14 ) − 2x14 + 4x15 − 2x16 = 0 2y32 (x4 − 2x5 + x6 ) − 2x6 + 4x7 − 2x8 = 0, 2y52 (x15 − 2x16 + x17 ) − 2x17 = 0 2y22 (−2x10 − x18 − x2 ) − 2x18 + 4x19 − 2x20 = 0 where the solution of the above system deﬁnes a general cubic Beta-Splines in the study of modelling curves in Computer Graphics. Using the Bareiss/Edmonds/Lipson algorithm on page 232, we ﬁnd that #Bn,n = # det(A) = 1033, #Bn−2,n−2 = 672 and #Bn,n Bn−2,n−2 = 14348, so an expression swell factor of 14348/1033 = 14. Furthermore, we obtain #˜ xi , #xi and the expression swell factor labelled swell for computing x ˜i in Table 1. The Gentleman & Johnson minor expansion algorithm [7] can also be used to compute the solutions xi by computing n + 1 determinants, namely, the numerators det(Ai ) for 1 ≤ i ≤ n (Ai is as deﬁned in (2)) and the denominator  
   
  236  
   
  A. Jinadu and M. Monagan  
   
  Table 1. Number of polynomial terms in x ˜i = Ni /Di and xi = fi /gi and expression swell factor for computing x ˜i 1  
   
  2  
   
  8  
   
  9  
   
  10  
   
  #Ni  
   
  586  
   
  1,172 1,197 1,827 2,142 1,666 2,072  
   
  3  
   
  4  
   
  5  
   
  6  
   
  7  
   
  1,320  
   
  1,320  
   
  2,650 2,543  
   
  #Di  
   
  2  
   
  3  
   
  6  
   
  9  
   
  9  
   
  9  
   
  9  
   
  9  
   
  18  
   
  18  
   
  #˜ xi  
   
  293  
   
  586  
   
  504  
   
  693  
   
  882  
   
  686  
   
  840  
   
  536  
   
  424  
   
  879  
   
  638  
   
  swell 2  
   
  2  
   
  3  
   
  3  
   
  3  
   
  3  
   
  3  
   
  3  
   
  3  
   
  3  
   
  4  
   
  # fi  
   
  1  
   
  2  
   
  4  
   
  4  
   
  4  
   
  19  
   
  16  
   
  8  
   
  8  
   
  8  
   
  2  
   
  # gi  
   
  5  
   
  3  
   
  10  
   
  7  
   
  4  
   
  22  
   
  16  
   
  16  
   
  26  
   
  12  
   
  3  
   
  12  
   
  13  
   
  14  
   
  15  
   
  16  
   
  17  
   
  18  
   
  19  
   
  20  
   
  21  
   
  #Ni  
   
  3,490 3,971 5,675 7,410 4,940 7,072 11,793 12,802 11,211 9,620  
   
  #Di  
   
  36  
   
  36  
   
  #˜ xi  
   
  834  
   
  1,033 871  
   
  117  
   
  153  
   
  153  
   
  432  
   
  672  
   
  672  
   
  672  
   
  672  
   
  1044  
   
  696  
   
  348  
   
  690  
   
  836  
   
  693  
   
  528  
   
  swell 4  
   
  4  
   
  7  
   
  7  
   
  7  
   
  20  
   
  17  
   
  15  
   
  16  
   
  18  
   
  # fi  
   
  1  
   
  1  
   
  1  
   
  1  
   
  1  
   
  2  
   
  14  
   
  4  
   
  1  
   
  1  
   
  # gi  
   
  3  
   
  3  
   
  5  
   
  5  
   
  3  
   
  3  
   
  23  
   
  7  
   
  4  
   
  7  
   
  11 27  
   
  det(A) only once. But then we still have to compute gi = gcd(det(Ai ), det(A)) to simplify the solutions xi which is not cheap. In this work, we interpolate the simpliﬁed solutions xi = fi /gi directly using sparse rational function interpolation. We use a black box representation to denote any given parametric linear system. That is, a black box BB representing n Ax = b denoted by BB : Zm p → Zp is a computer program that takes a prime p m and an evaluation point α ∈ Zp as inputs and outputs x(α) = A−1 (α)b(α) ∈ Znp . The implication of the black box representation of Ax = b is that important properties of x such as #fk , #gk and their variable degrees are unknown so we have to ﬁnd them by interpolation. Our ﬁrst contribution is a new algorithm that probes a given black box BB and uses sparse multivariate rational function interpolation to interpolate the rational function entries in x modulo primes and then uses Chinese remaindering and rational number reconstruction to recover its integer coeﬃcients. Our algorithm for solving Ax = b follows the work of Jinadu and Monagan in [11] where they modiﬁed Cuyt and Lee’s sparse rational function interpolation algorithm to use the Ben-Or/Tiwari interpolation algorithm and Kronecker substitution on the parameters in order to solve parametric polynomial systems by computing its Dixon resultant. Our second contribution is a hybrid Maple + C implementation of our new algorithm for solving Ax = b and it can be downloaded freely from the web at: http://www.cecm.sfu.ca/personal/monaganm/code/ParamLinSolve/. Our third contribution is the failure probability analysis and the complexity analysis of our algorithm in terms of the number of black box probes required. This paper is organized as follows. In Sect. 2, we review the sparse multivariate rational function algorithm of Cuyt and Lee and we describe how it should be modiﬁed with the use of a Kronecker substitution on the parameters.  
   
  Solving Parametric Linear Systems  
   
  237  
   
  Our algorithms are presented in Sect. 3. Section 4 contains the failure probability analysis and complexity analysis of our algorithm. In Sect. 5, we present timing results comparing a hybrid Maple+C implementation of our algorithm with a Maple implementation of the Bareiss/Edmonds/Lipson fraction free Gaussian elimination algorithm with three other algorithms for solving Ax = b.  
   
  2  
   
  Sparse Multivariate Rational Function Interpolation  
   
  2.1  
   
  Cuyt and Lee’s Algorithm  
   
  Let K be a ﬁeld and let f /g ∈ K(y1 , . . . , ym ) be a rational function such that gcd(f, g) = 1. Cuyt and Lee’s algorithm [4] to interpolate f /g must be combined with a sparse polynomial interpolation to interpolate f and g. The ﬁrst step in their algorithm is to introduce a homogenizing variable z to form the auxiliary (y1 z,...,ym z) which can be written as rational function fg(y 1 z,...,ym z) f0 + f1 (y1 , . . . , ym )z + · · · + fdeg(f ) (y1 , . . . , ym )z deg(f ) f (y1 z, . . . , ym z) = g(y1 z, . . . , ym z) g0 + g1 (y1 , . . . , ym )z + · · · + gdeg(g) (y1 , . . . , ym )z deg(g) and then normalize it using either constant terms f0 = 0 or g0 = 0. However it is not uncommon to have f0 = g0 = 0. Thus in the case when both constant terms g0 and f0 are zero, one has to pick a basis shift β ∈ (K \ {0})m such that g(β) = 0 and form a new auxiliary rational function as deg(f ) ˆ fj (y1 , . . . , ym )z j f (y1 z + β1 , . . . , ym z + βm ) fˆ(y1 z, . . . , ym z) j=0 := = deg(g) . gˆ(y1 z, . . . , ym z) g(y1 z + β1 , . . . , ym z + βm ) gˆj (y1 , . . . , ym )z j j=0  
   
  The introduction of the basis shift β forces the production of a constant term in fˆ/ˆ g so that we can normalize it using either fˆ0 or gˆ0 . Thus we can write deg(f ) fˆj (y1 ,...,ym )zj fˆ(y1 z, . . . , ym z) j=0 g ˆ0 = deg(g) gˆj (y1 ,...,ym )zj . gˆ(y1 z, . . . , ym z) 1 + j=1 g ˆ0 Note that gˆ0 = c˜ × g(β1 , β2 , . . . , βm ) = 0 for some c˜ ∈ K. If a rational function f /g is represented by a a black box, we can recover it by densely interpolating univariate auxiliary rational functions  
   
  ˆ , z) = A(α j  
   
  fˆ0 g ˆ0  
   
  fˆdeg(f ) (α) deg(f ) fˆ1 (αj ) z g ˆ0 z + · · · + g ˆ0 j) j g ˆ (α g ˆ1 (α ) deg(g) z deg(g) g ˆ0 z + · · · + g ˆ0  
   
  +  
   
  1+  
   
  ∈ Zp (z) for j = 0, 1, 2, · · ·  
   
  ˆ j for α ∈ Zm p from the black box and then use the coeﬃcients of A(α , z) via sparse ˆ j , z), we use the interpolation to recover f /g. In order to densely interpolate A(α Maximal Quotient Rational Function Reconstruction algorithm (MQRFR) [14] which requires deg(f ) + deg(g) + 2 black box probes on z. Note that the use  
   
  238  
   
  A. Jinadu and M. Monagan  
   
  of a basis shift in the formation of the auxiliary rational function destroys the sparsity of f /g, so its eﬀect has to be removed before f /g can be recovered. This is done by adjusting the coeﬃcients of the lower degree terms in the numerator ˆ j , z) by the contributions from the higher degree terms and denominator of A(α before the sparse interpolation step is performed (See [11, Subroutine 2]). 2.2  
   
  Using a Kronecker Substitution on the Parameters  
   
  In this work, the Ben-Or/Tiwari algorithm is the preferred sparse polynomial interpolation algorithm for the Cuyt and Lee’s algorithm because it requires the fewest number of black box probes. However, in order to interpolate a polynomial f = 0 using the Ben-Or/Tiwari interpolation algorithm over Zp , the working prime p is required to be at least pdm where pm is the m-th prime and d = deg(f ). Unfortunately, such a prime p may be too large for machine arithmetic if the total degree d is large. This is the main drawback of using the BenOr/Tiwari algorithm. Here we review the idea of Jinadu and Monagan from [11] where they formulated how to use a Kronecker substitution to combat the large prime problem posed by using the Ben-Or/Tiwari algorithm in Cuyt and Lee’s method. Definition 2. Let K be an integral domain and let f /g ∈ K(y1 , . . . , ym ). Let r = (r1 , r2 , . . . , rm−1 ) ∈ Zm−1 with ri > 0. Let Kr : K(y1 , . . . , ym ) → K(y) be the Kronecker substitution f (y, y r1 , y r1 r2 , . . . , y r1 r2 ···rm−1 ) ∈ K(y). Kr (f /g) = g(y, y r1 , y r1 r2 , . . . , y r1 r2 ···rm−1 ) Let di = max{(deg f, yi ), deg(g, yi )} for 1 ≤ i ≤ m. Provided we choose ri > di for 1 ≤ i ≤ m − 1 then Kr is invertible, g = 0 and Kr (f /g) = 0 ⇐⇒ f = 0. Unfortunately, we cannot use the original deﬁnition of auxiliary rational function given by Cuyt and Lee that we reviewed in Subsect. 2.1 to interpolate the univariate mapped function Kr (f /g). Thus we need a new deﬁnition for how to compute the corresponding auxiliary rational function relative to the mapped univariate function Kr (f /g), and not the original function f /g itself. Thus using a homogenizing variable z we deﬁne auxiliary rational function F (y, z) =  
   
  f (zy, zy r1 , . . . , zy r1 r2 ···rm−1 ) ∈ K[y](z). g(zy, zy r1 , . . . , zy r1 r2 ···rm−1 )  
   
  (7)  
   
  As before, the existence of a constant term in the denominator of F (y, z) must be guaranteed, so we use a basis shift β ∈ (K \ {0})m with g(β) = 0 and formally deﬁne an auxiliary rational function with Kronecker substitution as follows. Definition 3. Let K be a ﬁeld and let f /g ∈ K(y1 , . . . , ym ) such that gcd(f, g) = 1. Let z be the homogenizing variable and let r = (r1 , . . . , rm−1 ) with ri > di = max{(deg f, yi ), deg(g, yi )}. Let Kr be the Kronecker substitution and let β ∈ Km be a basis shift. We deﬁne F (y, z, β) :=  
   
  f (zy + β1 , zy r1 + β2 , . . . , zy r1 r2 ···rm−1 + βm ) f β (y, z) = ∈ K[y](z) β g (y, z) g(zy + β1 , zy r1 + β2 , . . . , zy r1 r2 ···rm−1 + βm )  
   
  as an auxiliary rational function with Kronecker substitution Kr .  
   
  Solving Parametric Linear Systems  
   
  239  
   
  Notice in the above deﬁnition that for β = 0, F (y, 1, 0) =  
   
  f 0 (y, 1) = Kr (f /g). g 0 (y, 1)  
   
  Thus Kr (f /g) can be recovered using the coeﬃcients of z i in F (αi , z, β) for some evaluation point α ∈ Zm p and i ≥ 0. If g has a constant term, then one can use β = (0, . . . , 0). Also, observe that the degree of Kr (f /g) in y is exponential in m but deg(F (y, z, β), z) through which Kr (f /g) is interpolated remains the same and the number of terms and the number of probes needed to interpolate f /g are m the same. To recover the exponents in y we require our input prime p > i=1 ri .  
   
  3  
   
  The Algorithm  
   
  Let the polynomials fk and gk of the entries xk =   
   
  deg(f )  
   
  fk =  
   
  fk gk  
   
    
   
  of x be viewed as  
   
  deg(g)  
   
  fi,k (y1 , y2 , . . . , ym ) and gk =  
   
  i=0  
   
  gj,k (y1 , y2 , . . . , ym )  
   
  (8)  
   
  j=0  
   
  such that i and j are the total degrees of all the polynomial terms in fi,k and gi,k respectively. For convenience, we write deg(fi,k ) = i and deg(gj,k ) = j. Given a black box BB representing Ax = b, we divide the steps to recover x by our new algorithm (Algorithm 4) into seven main steps. The ﬁrst step in our algorithm is to obtain the degrees needed to interpolate x. These include the total degrees deg(fk ), deg(gk ) for 1 ≤ k ≤ n, which are needed to densely interpolate the univariate auxiliary rational functions, the maximum partial degrees max (maxnk=1 (deg(fk , yi ), deg(gk , yi ))) for 1 ≤ i ≤ m, which are needed to apply Kronecker substitution and the total degrees of the polynomials fi,k and gi,k which helps avoid doing unnecessary work when the eﬀect of the basis shift β is removed in [11, Subroutine 2] (See Lines 1–5 of Algorithm 4). With high probability, we describe how to discover these degrees as follows. Let p be a large prime. First, pick α, β ∈ (Zp \ {0})m at random, and use enough distinct points for z selected at random from Zp to interpolate the univariate rational function hk (z) =  
   
  fk (α1 z + β1 , . . . , αm z + βm ) Nk (z) = ∈ Zp (z), Dk (z) gk (α1 z + β1 , . . . , αm z + βm )  
   
  via probes to the black box such that deg(Nk ) = deg(fk ) and deg(Dk ) = deg(gk ) for 1 ≤ k ≤ n with high probability. Next, pick γ ∈ (Zp \{0})m−1 and θ ∈ Zp \{0} at random and probe the black box to interpolate the univariate rational function Hi (z) :=  
   
  Hf i fk (γ1 , . . . , γi−1 , θz, γi+1 , · · · , γm ) ∈ Zp (z) = Hg i gk (γ1 , . . . , γi−1 , θz, γi+1 , · · · , γm )  
   
  using enough distinct random points for z from Zp . With high probability deg(Hfi , z) = deg(fk , yi ) and deg(Hgi , z) = deg(gk , yi ) for 1 ≤ i ≤ m.  
   
  240  
   
  A. Jinadu and M. Monagan  
   
  Finally, suppose we have obtained deg(fk ), deg(gk ) correctly for 1 ≤ k ≤ n. Then pick α ∈ (Zp \ {0})m at random and use enough random distinct points for z selected from Zp to interpolate the univariate rational function dfk ¯ Nk fk (α1 z, . . . , αm z) j=0 Ni,k (z) Wk (z) = ∈ Zp (z) = dg = k gk (α1 z, . . . , αm z) ¯ Dk Di,k (z) i=0  
   
  where dfk = deg(N k ) and dgk = deg(Dk ). Now if deg(fk ) = dfk and deg(gk ) = ¯i,k ) and deg(gi,k ) = deg(D ¯ i,k ) with high probability. dgk then deg(fi,k ) = deg(N But, if there is no constant term in fk or gk then deg(fk ) = dfk and deg(gk ) = dgk because ek = deg(gcd(N k , Dk )) > 0. Since we do not know what ek is, then it follows that if ek = deg(fk ) − dfk = deg(gk ) − dgk with high probability then ¯i,k ) + ek and deg(gi,k ) = deg(D ¯ i,k ) + ek with high probability. deg(fi,k ) = deg(N Example 4. Let f1 y 3 + y1 y2 = 12 g1 y2 + y3 where f3,1 = y13 , f2,1 = y1 y2 , g2,1 = y22 and g1,1 = y3 . Then W1 (z) =  
   
  α3 z 3 + α1 α2 z 2 z(α13 z 2 + α1 α2 z) f1 (α1 z, α2 z, α3 z) = 12 2 = g1 (α1 z, α2 z, α3 z) α2 z + α3 z z(α22 z + α3 ) =  
   
  α13 z 2 + α1 α2 z . α22 z + α3  
   
  Thus deg(f1 ) = 3 = df1 = 2 and deg(g1 ) = 2 = dg1 = 1. Since e1 = deg(f1 ) − df1 = deg(g1 ) − dg1 = 1, we have that deg(f3,1 ) = 2 + e1 = 3, deg(f2,1 ) = 1 + e1 = 2, deg(g2,1 ) = 1 + e1 = 2 and deg(g1,1 ) = 0 + e1 = 1. After obtaining all the degree bounds, the second step in our algorithm is to probe the black box BB with input evaluation points α ∈ Zm p to obtain images x(α) = A−1 (α)b(α) ∈ Znp (See Lines 17–19). The third step is to perform dense interpolation of auxiliary univariate rational functions labelled as Aj (z) using the images x(α) = A−1 (α)b(α) ∈ Znp (See Lines 23–27). By design, the fourth step is to determine the number of terms in the leading term polynomials fdeg(fk ),k and gdeg(fk ),k and interpolate them via calls to Subroutine BMStep in Lines 29–30. Next, #fi,k and #gi,k as deﬁned in (8) are determined by calls to Subroutine RemoveShift in Lines 34–35 where the eﬀect of the basis shift β = 0 is removed and the coeﬃcients of the auxiliary univariate rational functions Aj (z) are adjusted in order to interpolate fi,k and gi,k . Note that for each i, the size of the supports #fi,k (or #gi,k ) are #f unknown and they will be discovered when deg(λ, z) < 2i,k for some feedback polynomial λ ∈ Zp [z] which is generated by the Berlekamp-Massey algorithm [1] in Line 1 of Subroutine BMStep. That is, we compute λ(z) ∈ Zp [z] using  
   
  Solving Parametric Linear Systems  
   
  241  
   
  l = 2, 4, 6, . . . points, the sequence of coeﬃcients in z i from Aj (z) and we wait until deg(λ(z)) = 1, 2, 3, . . . , t, t, t, . . . , with high probability (See Line 21). This idea was given by Kaltofen in [13]. With high probability, the t roots of the feedback polynomial λ over Zp will be used to determine the support of the polynomials fi,k (or gi,k ) and the t sequence of coeﬃcients of z i from the auxiliary univariate rational functions Aj (z) will be used to determine the t unknown coeﬃcients of the polynomial fi,k . Once fi,k , gi,k modulo a prime have been interpolated, the sixth step in our algorithm is to apply rational number reconstruction (RNR) on the assembled vector X = [ fgkk mod p, 1 ≤ k ≤ n] to get x in Line 42. If RNR process fails then more primes and images of x are needed to interpolate x using Chinese remaindering and RNR. Thus, the ﬁnal step is to call Algorithm 5, an algorithm similar to Algorithm 4, except that the size of the supports and the variable degrees of the polynomials fi,k and gi,k are now known, and Algorithm 5 uses more primes, RNR and Chinese remaindering to get the solution x.  
   
  Subroutine 2: BMStep  
   
  1 2 3 4 5 6 7 8 9  
   
  Input: P = [Pj ∈ Zp : 1 ≤ j ≤ i, i is even] , α ∈ Zp , shift sˆ ∈ [0, p − 1] and r which deﬁnes the Kronecker substitution Kr . Output: A non-zero multivariate polynomial F¯ ∈ Zp [y1 , y2 , . . . , ym ] or FAIL. Run the Berlekamp-Massey algorithm[1] on P to obtain λ(z) ∈ Zp [z]; . . . . O(i2 ) if deg(λ, z) = 2i then return FAIL end // More images are needed Compute the roots of λ in Zp [z] to obtain the monomial evaluations m ˆ i . Let ˆ i and let t = |m|; ˆ . . . . . O(t2 log p) m ˆ ⊂ Zp be the set of monomial evaluations m if t = deg(λ, z) then return FAIL end // λ(z) is wrong. Solve αei = m ˆ i for ei with ei ∈ [0, p − 2] // The exponents are found here. ˆ = [ y ei : i = 1, 2 · · · , t ] // These are the monomials Let M ˆ ) // F ∈ Zp [y]; . . . . . . . . . . . . . . O(t2 ) F ←VandermondeSolver (m, ˆ [P1 , · · · Pt ], sˆ, M −1 ¯ F ← Kr (F ) ∈ Zp [y1 , . . . , ym ].// Invert the Kronecker map Kr . return F¯  
   
  Subroutine 3: VandermondeSolver Input: Vectors m, ˆ v ∈ Ztp , shift sˆ ∈ [0, p − 2] and monomials [M1 , · · · , Mt ] Output: A non-zero polynomial F ∈ Zp [y1 , · · · , ym ] 1 Let Vij = m ˆ siˆ+j−1 for 1 ≤ i, j ≤ t. // A shifted transposed Vandermonde matrix 2 2 Solve the shifted transposed Vandermonde system V a = v using Zippel’s O(t ) algorithm. ai 3 Compute ai = for 1 ≤ i ≤ t. m ˆ siˆ t 4 return F = i=1 ai Mi  
   
  242  
   
  A. Jinadu and M. Monagan  
   
  Algorithm 4: ParamLinSolve  
   
  1 2 3 4  
   
  5 6 7  
   
  8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  
   
  n Input: A black box BB : Zm p → Zp with m ≥ 1. Output: Vector x ∈ Z(y1 , . . . , ym )n or FAIL. Compute total degrees (deg(fk ), deg(gk )) for 1 ≤ k ≤ n ek ← deg(fk ) + deg(gk ) + 2 for 1 ≤ k ≤ n. emax ← maxn k=1 {ek } Compute (Efk , Egk ) where Efk and Egk denote the lists of the total degrees of the polynomials as deﬁned in (8)  fik and gik in fk and gk respectively  Dyi ← max maxn k=1 (deg(fk , yi ), deg(gk , yi )) for 1 ≤ i ≤ m. Initialize ri = Dyi + 1 for 1 ≤ i ≤ m and let r = (r1 , r2 , . . . , rm−1 ).  m Pick a prime p such that p > m j=1 ri and a basis shift β = 0 ∈ Zp at random. // p is the prime to be used by the black box. Let Kr : Zp (y1 , y2 , . . . , ym ) → Zp (y) be the Kronecker substitution Kr (fk /gk ) Pick a random shift sˆ ∈ [0, p − 1] and any generator α for Z∗p . Let z be the homogenizing variable Pick θ ∈ Zepmax at random with θi = θj for i = j.  max M ← ei=1 (z − θi ) ∈ Zp [z]; . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . O(e2max ) k←1 for i = 1, 2, · · · while k ≤ n do Yˆi ← (αsˆ+i−1 , α(ˆs+i−1)r1 , . . . , α(ˆs+i−1)(r1 r2 ···rm−1 ) ). for j = 1, 2, . . . , emax do Zj ← Yˆi θj + β ∈ Zm p vj ← BB(Zj ) // Here vj = A−1 (Zj )b(Zj ) ∈ Zn p if vj = FAIL then return FAIL end // rank(A(Zj )) < n. end if i ∈ / {2, 4, 8, 16, 32, · · ·} then next end for j = 1, 2, . . . , i do Interpolate U ∈ Zp [z] using points (θi , vkj : 1 ≤ j ≤ ek ); . . . . . . . . . . . . . . . O(e2k ) Aj (z) ← MQRFR(M, U, p);[14] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . O(e2k )  
   
  Let Aj (z) =  
   
  25  
   
  Nj (z) ˆj (z) N  
   
  ∈ Zp (z) // These are the auxiliary functions in z.  
   
  ˆj ) = deg(gk ) then return FAIL end if deg(Nj ) = deg(fk ) or deg(N deg(Nˆ ) ˆ Normalize Aj (z) such that Nj (z) = 1 + ai z i .  
   
  26 27  
   
  i=1  
   
  end Fk ← BMStep([coeﬀ(Nj , z deg(fk ) ) : 1 ≤ j ≤ i], α, sˆ, r); O(i2 + #Fk2 log p) ˆj , z deg(gk ) ) : 1 ≤ j ≤ i], α, sˆ, r); O(i2 + #G2 log p) Gk ← BMStep([coeﬀ(N k // Here Fk = fdeg(fk ),k mod p and Gk = gdeg(gk ),k mod p if Fk = FAIL and Gk = FAIL then // Subroutine RemoveShift is Subroutine 2 on page 196 in [11]. fk ← RemoveShift(Fk , [Yˆ1 , . . . , Yˆi ], [N1 , . . . , Ni ], α, sˆ, β, r, Efk ) ˆ1 , . . . , N ˆi ], α, sˆ, β, r, Eg ) gk ← RemoveShift(Gk , [Yˆ1 , . . . , Yˆi ], [N k if fk = FAIL and gk = FAIL then k ← k + 1 // we have interpolated xk mod p end end  
   
  28 29 30 31 32 33 34 35 36 37 38 39 40  
   
  end  
   
  41  
   
  X ← [ gfk , 1 ≤ k ≤ n] // Here X = x mod p  
   
  42 43 44  
   
  k  
   
  Apply rational number reconstruction on the coeﬃcients of X mod p to get x if x = FAIL then return x end return MorePrimes(BB, ((deg(fk ), deg(gk )) : 1 ≤ k ≤ n), X, p)  
   
  Solving Parametric Linear Systems  
   
  243  
   
  Algorithm 5: MorePrimes  
   
  1 2  
   
  n Input: Black box BB : Zm q → Zq with m ≥ 1. Input: Degrees {(deg(fk ), deg(gk )) : 1 ≤ k ≤ n} and X = x mod p where p is the ﬁrst prime used by Algorithm ParamLinSolve. Output: Vector x ∈ Z(y1 , . . . , ym )n or FAIL. Let ek = deg(fk ) + deg(gk ) + 2 for 1 ≤ k ≤ n and let emax = max ek . Let B1 = [fdeg(fk )−1,k , . . . , f0,k ] and B2 = [gdeg(gk )−1,k , . . . , g0,k ] where fi,k , gi,k are as in (8) and set P = p.  deg(fk )  
   
  3  
   
  Let Nmax = maxn k=1 maxi=0  
   
  4  
   
  do  
   
  5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  
   
  deg(gk )  
   
  {#fi,k }, maxi=0  
   
  {#gi,k }} .  
   
  Get a new prime q = p. // The black box BB uses a new prime q. Pick α, β ∈ (Zq \ {0})m , θ ∈ Zeqmax and shift sˆ ∈ [1, q − 2] at random. for i = 1, 2, . . . , Nmax do s ˆ+i−1 Yˆi ← (α1sˆ+i−1 , α2sˆ+i−1 , . . . , αm ). for j = 1, 2, . . . , emax do Zj ← Yˆi θj + β ∈ Zm p vj ← BB(Zj ) // Here vj = A−1 (Zj )b(Zj ) ∈ Zn p if vj = FAIL then return FAIL end // rank(A(Zj )) < n. end end for k = 1, 2, . . . , n do ˆ ) ← (#fdeg(f ),k , supp(fdeg(f ),k )) // supp means support. (ˆ n, M k k ¯ ) ← (#gdeg(g ),k , supp(gdeg(g ),k )) (¯ n, M k k ˆ i (α) : 1 ≤ i ≤ n ¯ i (α) : 1 ≤ i ≤ n (m, ˆ m) ¯ ← ([M ˆ ], [M ¯ ]); . . . . . . . O(m(ˆ n+n ¯ )) if the  evaluations m ˆi = m ˆ j or m ¯i = m ¯ j then return FAIL end. k M ← ei=1 (z − θi ) ∈ Zq [z]; . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . O(e2k ) for j = 1, 2, . . . , Nmax do Interpolate U ∈ Zp [z] using points (θi , vkj : 1 ≤ j ≤ ek ); . . . . . . O(e2k ) ˆj (z) ∈ Zq (z). . . . . . . . . O(e2k ) Bj ← MQRFR(M, U, p)//Bj = Nj (z)/N  ˆj (z) = 1 + deg(Nˆ ) bi z i . Normalize Bj (z) s.t. N i=1 ˆj ) = deg(gk ) then return FAIL end if deg(Nj ) = deg(fk ) or deg(N end ˆj , z) for 1 ≤ i ≤ Nmax . Let ai = LC(Nj , z) and let bi = LC(N ˆ ); . . . . . . . . . . . . . . . . . . O(ˆ Fk ←VandermondeSolver(m, ˆ [a1 , . . . , anˆ ], sˆ, M n2 ) ¯ Gk ←VandermondeSolver(m, ¯ [b1 , . . . , bn¯ ], sˆ, M ); . . . . . . . . . . . . . . . . . . O(¯ n2 ) Fk ←GetTerms(Fk , [Yˆ1 , . . . , YˆNmax ], [N1 , . . . , NNmax ], sˆ, α, β, B1 ) ˆ1 , . . . , N ˆNmax ], sˆ, α, β, B2 ) Gk ←GetTerms(Gk , [Yˆ1 , . . . , YˆNmax ], [N if Fk = FAIL or Gk = FAIL then return FAIL end end ˆ ← [ Fk , 1 ≤ k ≤ n] // Here X ˆ = x mod q X Gk ˆ ˆ ˆ mod q using Chinese remaindering Solve F ≡ X mod P and F ≡ X P ← P × q. Apply rational number reconstruction on coeﬃcients of Fˆ mod P to get x if x = FAIL then return F else (X, p) ← (Fˆ , q) end end  
   
  244  
   
  A. Jinadu and M. Monagan  
   
  Subroutine 6: GetTerms Input: A multivariate polynomial Fk ∈ Zq [y1 , . . . , ym ], Points α ∈ (Zq \ {0})m , ˆ ∈ [1, q − 2], a list of lower total degree β ∈ Zm q ,a random shift s polynomials B1 = [fdeg(fk )−1,k , . . . , f0,k ], list of points [Yˆj ∈ Zm q : 1 ≤ j ≤ Nmax ] and list [Nj ∈ Zq [z] : 1 ≤ j ≤ Nmax ]. Output: A non-zero polynomial f k ∈ Zq [y1 , . . . , ym ] max ˆ ← (Fk , Fk , deg(Fk )) and set Γ = (0, 0, , . . . , 0) ∈ ZN 1 (A, f k , d) . q ˆ ← [supp(e) : e ∈ B1 ] // supp means support. 2 D ← [deg(e) : e ∈ B1 ], M 3 for h = 1, 2, . . . , |D| do 4 d ← Dh 5 if β = 0 then ˆ 6 Pick θ ∈ Zd+1 at random. q 7 for j = 1, 2, · · · , Nmax do 8 Zj,t ← A(y1 = Yˆj,1 θt + β1 , . . . , ym = Yˆj,m θt + βm ) for ˆ 1 ≤ t ≤ dˆ + 1; . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . O(m#A + md) 2 ˆ ˆ 9 Interpolate W j ∈ Zq [z] using (θt , Zj,t : 1 ≤ t ≤ d + 1); . . . . . . . . O(d ) ˆ 10 Γj ← Γj + W j ; . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . O(d) 11 end 12 end 13 if d = 0 then   14 P ← coeﬀ(Nj , z d ) : 1 ≤ j ≤ Nmax 15 if β = 0 then Pj ← Pj − coeﬀ(Γj , z d ) for 1 ≤ j ≤ Nmax end ˆ i (α) : 1 ≤ i ≤ n ˆ h ; . . . . . . . . . . . . . . . . . . . . . . O(mˆ 16 m ˆ ← [M ˆ ] where n ˆ = #M n) 17 if any monomial evaluations m ˆi = m ˆ j then return FAIL end. ˆ h ); . . . . . . . . . . . . . . . . . . . . . . . . . . . O(ˆ 18 A ← VandermondeSolver(m, ˆ P, sˆ, M n2 ) 19 else 20 A ← coeﬀ(N1 , z 0 ) // We use only one point to get the constant term 21 if β = 0 then A ← A − coeﬀ(Γ1 , z 0 ) end ˆ ← (f + A, deg(A) + 1). 22 (f k , d) k 23 end 24 end 25 return f k .  
   
  4 4.1  
   
  Analysis Failure Probability Analysis  
   
  Here we identify all the problems that can occur in our algorithm for solving parametric linear systems. The proofs in this paper require the Schwartz-Zippel Lemma [16,17]. We state the lemma and some useful results now. Lemma 5 (Schwartz-Zippel Lemma). Let K be a ﬁeld and let f be a nonzero polynomial in K[y1 , y2 , . . . , ym ]. If α is chosen at random from F m with ) F ⊂ K then Prob[f (α) = 0] ≤ deg(f |F | .  
   
  Solving Parametric Linear Systems  
   
  245  
   
  t Definition 6. Let f = i=1 ai Ni ∈ Z[y1 , y2 , . . . , ym ] where ai ∈ Z \ {0}, t = #f ≥ 1 and Ni is a monomial in variables y1 , y2 , . . . , ym . The height of f denoted by f ∞ is deﬁned as f ∞ = maxti=1 |ai |. We also deﬁne H ∞ = 1 ,...,ym ) max ( fk ∞ , gk ∞ ) where H = fgkk (y (y1 ,...,ym ) such that gcd(fk , gk ) = 1. Theorem 7 [9, Proposition 2]. Let A be a n×n matrix with Aij ∈ Z[y1 , . . . , ym ], n #Aij ≤ t and Aij ∞ ≤ h. Then det(A) ∞ < n 2 tn hn . Lemma  8 m[6, Lemma 2, page 135]. Let f, g ∈ Z[y1 , y2 , . . . , ym ]. If g|f then  
   
  g ∞ ≤ e i=1 deg(f,yi ) f ∞ where e is the Euluer number and e ≈ 2.718. Remark 9. For the rest of this paper, let deg(bj ), deg(Aij ), deg(fi ), deg(gi ) ≤ d. Let #Aij , #bj , #fi , #gi ≤ t and let Aij ∞ , bj ∞ ≤ h. Let P = {p1 , p2 , . . . , pN } be the list of machine primes to be used in our algorithm such that pmin = minN i=1 {pi } and N is a large positive integer. We now estimate the height of the entries xk of the solution vector x. Theorem 10. We have n  
   
  xk ∞ ≤ enmd n 2 tn hn where e is the Euler number and e ≈ 2.718. Rk where Rk Proof. By Cramer’s rule, the solutions of Ax = b are given by R denotes the matrix obtained by replacing the k-th column of the coeﬃcient matrix A by vector b and R = det(A). Let hk = gcd(Rk , R). Observe that Rk /hk fk = = xk R/hk gk where gcd(fk , gk ) = 1. Therefore fk |Rk and gk |R. By Lemma 8, it follows that  
   
  gk ∞ ≤ e  
   
  m  
   
  i=1  
   
  deg(R,yi )  
   
  R ∞ ≤ e  
   
  m  
   
  i=1  
   
  nd  
   
  R ∞ ≤ enmd R ∞  
   
  (9)  
   
  and similarly,  
   
  fk ∞ ≤ enmd Rk ∞  
   
  (10)  
   
  because deg(R, yi ) ≤ deg(R) ≤ n × maxni=1 {deg(Aij )} ≤ nd. Therefore n  
   
  xk ∞ ≤ max ( fk ∞ , gk ∞ ) ≤ enmd max ( Rk ∞ , R ∞ ) ≤ enmd n 2 tn hn by Theorem 7.  

  We remark that the above bound for the height of xk is the worst case bound.  
   
  246  
   
  A. Jinadu and M. Monagan  
   
  4.1.1  
   
  Unlucky Primes and Evaluation Points  
   
  Definition 11. Let p be a prime. A prime p is said to be unlucky if p|det(A). Definition 12. Suppose p is not an unlucky prime. Let α ∈ Zm p be an evaluation point. We say that α is unlucky if det(A)(α) = 0. Lemma 13. Let p be a prime chosen at random from list of primes P . Then n  
   
  logpmin n 2 tn hn Pr[ p is unlucky ] ≤ . N Proof. Let R = det(A) and let c be an integer coeﬃcient of R. The number of primes p from P that can divide c is at most logpmin c. So Pr[ p | c ] ≤  
   
  logpmin c . N  
   
  By deﬁnition, prime p is unlucky ⇐⇒ p|R =⇒ p divides one term in R. So logpmin R ∞ . N n  
   
  logpmin n 2 tn hn Using Theorem 7, it follows that Pr[ p is unlucky ] ≤ .  
   
  N Pr[ p is unlucky ] = Pr[ p |R ] ≤ Pr[ p divides one term in R ] ≤  
   
  Lemma 14. Let p be a prime chosen at random from the list of primes P . Let α ∈ Zm p be an evaluation point. If p is not an unlucky prime then Pr[ α is unlucky ] ≤  
   
  nd . p  
   
  Proof. Using Lemma 5, we have Pr[ α is unlucky ] = Pr[ det(A)(α) = 0 ] ≤  
   
  nd deg(det(A)) ≤ . p p  

  4.1.2  
   
  Bad Evaluation Points, Primes and Basis Shift  
   
  Definition 15. We say that α ∈ Zp \ {0} is a bad evaluation point if deg(fkβ (α, z)) < deg(fk , z) or deg(gkβ (α, z)) < deg(gk , z) for any k. Definition 16. We say that β ∈ (Zp \ {0})m is a bad basis shift if gcd(fk , gk ) = 1 but deg(gcd(fkβ (α, z), gkβ (α, z))) > 0 for any k. Definition 17. We say a prime p is bad if p|LC(fkβ (y, z)) in z or p|LC(gkβ (y, z)) in z for any k.  
   
  Solving Parametric Linear Systems  
   
  247  
   
  To avoid the occurrence of bad evaluation points with high probability in Algorithm 4, we had to interpolate Fk (αsˆ+i , z, β) for some random point sˆ ∈ [0, p − 1] instead of Fk (αi , z, β). This is labelled as Aj in Line 25. Line 26 detects the occurrence of bad evaluation points, a bad basis shift or a bad prime. Example 18. Let p be a prime and let f1 y1 = ∈ Zp (y1 , y2 , y3 ). g1 (y1 + y3 )y2 Observe that the partial degrees ei = max{deg(f1 , yi ), deg(g1 , yi )} = 1 for 1 ≤ i ≤ 3. For the Kronecker map Kr to be invertible we need ri > ei , so let r = (2, 2). Thus the mapped function Kr (f1 /g1 ) =  
   
  y f (y, y 2 , y 4 ) y = = 3 . 2 4 4 2 g(y, y , y ) (y + y )y y + y6  
   
  Since g1 has no constant term, we need a basis shift β ∈ (Zp \{0})3 . To interpolate Kr (f1 /g1 ), we need to densely interpolate F1 (αj , z, β) for 1 ≤ j ≤ 4 = 2 × #g1 . Computing F1 (α, z, β) directly yields the univariate rational function F1 (α, z, β) =  
   
  f1β (α, z) g1β (α, z)  
   
  =  
   
  (zα4  
   
  αz + β1 . + zα + β1 + β3 )(zα2 + β2 )  
   
  The Sylvester resultant R = Res(f1β (α, z), g1β (α, z), z) = α2 (α3 β1 − β3 )(αβ1 − β2 ) = 0 since α = 0 and β = (β1 , β2 , β3 ) = (0, 0, 0). But, if β2 = αβ1 = 0 or β3 = α3 β1 = 0 then R(β) = 0 which implies that β is a bad basis shift. 4.1.3  
   
  Main Results  
   
  Theorem 19. Let Na be greater than the required number of auxiliary rational function needed to interpolate x and suppose all the degree bounds obtained in Lines 1–5 of Algorithm 4 are correct. Let e be the Euler number where e ≈ 2.718. Suppose Algorithm 4 only needs one prime to interpolate x. If prime p is chosen at random from P then the probability that Algorithm 4 returns FAIL is at most √  
   
  6Na n2 d logpmin (th n) + 2Na n2 md logpmin (e) + N  
   
  2n(1 + d)m Na + t2 + t2 d + 5n2 Na d2 . p−1 Proof. Recall that emax = maxnk=1 {deg(fk ) + deg(gk ) + 2} ≤ 4d. Notice that Pr[vj = FAIL in Line 19] = Pr[prime p or evaluation point Zj in Line 17 is unlucky]. By Lemma 13 and 14, we have that Pr[Algorithm 4 returns FAIL in Line 19] ≤ n  
   
  √   
   
  d logpmin (th n) nd logpmin n 2 tn hn 2 + ≤ 4n dNa + emax nNa (11) p N p N  
   
  248  
   
  A. Jinadu and M. Monagan  
   
  There are three causes of FAIL in Line 26 of Algorithm 4. All three failure causes (bad evaluation point, bad basis shift and bad prime) are direct consequence of our attempt to interpolate auxiliary rational functions Aj in Line 25. We will handle the bad evaluation point case ﬁrst. Let Δ(y) =  
   
  n   
   
  LC(fkβ (y, z))LC(gkβ (y, z)) ∈ Zp [y].  
   
  k=1  
   
  Notice that the evaluation point αsˆ+j−1 in Line 15 is random since sˆ ∈ [0, p − 1] is random and α is randomly selected in Line 9. Since a basis shift β does not aﬀect the degree and the leading coeﬃcients of auxiliary rational functions, we have that if αsˆ+j−1 is a bad then Δ(αsˆ+j−1 ) = 0. Thus Prob[αsˆ+j−1 is a bad for 0 ≤ j ≤ Na − 1] ≤  
   
  2Na n(1 + d)m Na deg(Δ) ≤ . p−1 p−1  
   
  Now suppose θj := αsˆ+j−1 is not bad for 1 ≤ j ≤ Na . Let w1 , w2 , · · · wm be new variables and let  
   
  Gkj  
   
  (r r ···r ) fk (θj z + w1 , . . . , zθj 1 2 m−1 + wm ) fˆkj = = ∈ Zp (w1 , w2 , . . . , wm )(z). (r r ···r ) gˆkj gk (θj z + w1 , . . . , zθj 1 2 m−1 + wm )  
   
  gkj )(β) = 0. Let Rkj = Res(fˆkj , gˆkj , z) ∈ Recall that LC(fˆkj )(β) = 0 and LC(ˆ Zp [w1 , w2 , . . . , wm ] be the Sylvester resultant and Na  n  let Δ(w1 , w2 , . . . , wm ) = Rkj . Clearly, β picked at random in Line 7 j=1 k=1  
   
  is a bad basis shift ⇐⇒ Δ(β) = 0 ⇐⇒ deg(gcd(fˆkj (z, β), gˆkj (z, β)) > 0 for any k and j. Using Bezout’s bound [9, Lemma 4], we have deg(Rkj ) ≤ deg(fk ) deg(gk ) ≤ d2 . Thus Prob[β is a bad basis shift] = Prob[Δ(β) = 0] ≤  
   
  nd2 Na deg(Δ) ≤ . p−1 p−1  
   
  Finally, we deal with the bad prime case. Observe that Prob[ prime p is bad ] ≤ Prob[p divides 1 term of LC(fk ) or LC(gk ) n logpmin ( fk ∞ gk ∞ ) . N Using Eqs. (9) and (10), we have Prob[ prime p is bad for 1 ≤ j ≤ Na ] for 1 ≤ k ≤ n] ≤  

  √ n 2Na n2 logpmin (th n) + md logpmin (e) Na n logpmin (enmd n 2 tn hn )2 ≤ . ≤ N N  
   
  Solving Parametric Linear Systems  
   
  249  
   
  Thus Pr[Algorithm 4 returns FAIL in Line 26] is at most  
   
  √ 2Na n2 logpmin (th n) + md logpmin e 2Na n(1 + d)m nd2 Na + + . N p−1 p−1  
   
  (12)  
   
  Since Na is greater than the required number of auxiliary rational function needed by Algorithm 4 to interpolate x, then Line 2 of Subroutine 2 will never return FAIL. However the feedback polynomial λ ∈ Zp [z] generated to ﬁnd the number of terms in fi,k or gi,k in Line 4 of Subroutine 2 might be wrong so it will return FAIL which causes Algorithm 4 to return FAIL in either Lines 29 or 30 or34 or 35. By [10, Theorem 2.6], Pr[ getting the wrong #fi,k or #gi,k ] ≤ n  
   
  k=1  
   
  deg(fk ) i=0  
   
  #fi,k (#fi,k +1) deg(Kr (fi,k ))+  
   
  deg(gk ) i=0  
   
  #gi,k (#gi,k +1) deg(Kr (gi,k )  
   
  . Since #fi,k , #gi,k ≤ t and deg(Kr (fi,k )), deg(Kr (gi,k )) ≤ (1 + d)m , we have 2(p−1)  
   
  Pr[Algorithm 4 returns FAIL in Lines 29 or 30 or 34 or 35] ≤  
   
  2nt2 (1 + d)m+1 . (13) p−1  
   
  Our result follows by adding (11), (12) and (13).  

  Theorem 20. Let Na be greater than the required number of auxiliary rational functions needed to interpolate x. Let q be a new prime selected at random from the list of primes P to reconstruct the coeﬃcients of x using rational number reconstruction. Let e ≈ 2.718 be the Euler number. Then Pr[Algorithm 5 returns FAIL] √  
   
  6Na n2 d logpmin (th n) + 2Na n2 md logpmin (e) 7n2 d2 Na + 4nd2 t2 + . ≤ N q−1 Proof. Using (11), the probability that Algorithm 5 returns FAIL in Line 12 is at most √   
   
  d logpmin (th n) 2 4n dNa + (14) q N If the monomial evaluations obtained in Line 19 of Algorithm 5 or the monomial evaluations obtained in Line 17 of Subroutine 6 are not distinct then Pr[Algorithm 5 returns FAIL in Line 19 or 30 or 31]  

  deg(f ) deg(g ) n  ( i=0 k #f2i,k deg(fi,k ) + i=0 k #g2i,k deg(gi,k )) 4nd2 t2 ≤ . (15) ≤ q−1 q−1 k=1  
   
  Notice that the rational functions Bj obtained in Line 23 are of the form fkβ (y1 , y2 , . . . , ym , z) gkβ (y1 , y2 , . . . , ym , z)  
   
  =  
   
  fk (y1 z + β1 , . . . , ym z + βm ) , gk (y1 z + β1 , . . . , ym z + βm )  
   
  250  
   
  A. Jinadu and M. Monagan  
   
  and are diﬀerent from the Aj obtained in Algorithm 4 because a Kronecker map n is not used. Let Δ = k=1 LC(fkβ )LC(gkβ ) ∈ Zp [y1 , y2 , . . . , ym ]. Since deg(Δ) ≤ ˆmax , then Prob[Yˆj picked in Line 8 of Algorithm 5 is bad : 0 ≤ 2nd and Na ≥ N ˆmax − 1] ≤ 2ndNa . Hence Pr[Algorithm 5 returns FAIL in Line 25] ≤ j≤N q−1  
   
  √ 2 2Na n logpmin (th n) + md logpmin (e) 2ndNa nd2 Na + + . (16) N q−1 q−1  

  Our result follows by adding (14), (15) and (16). 4.2  
   
  Complexity Analysis  
   
  Theorem 21. Let B = [A|b] be a n × (n + 1) augmented matrix such that #Bij ≤ t and deg(Bij ) ≤ d. Suppose that the integer coeﬃcients of the entries Bij of B are l base C digits long. That is, Bij ∞ ≤ C l . Let prime p chosen at random from the list of primes P and C < p < 2C. A black box probe costs O(n2 tl + n2 mdt + n3 ) arithmetic operations in Zp . t Proof. Let Bij = k=1 ak Bij,k (y1 , . . . , ym ). The total cost of computing B mod p is O(n2 tl) since the modular reduction Bij mod p costs O(tl). All monomial evaluations Bij k (α) can be computed using O(mdt) multiplications and t multiplications for the product ak Bij k (α) ∈ Zp . So, the cost of evaluating B is O(n2 mdt). The cost of solving B(α) over Zp using Gaussian elimination is  
   
  O(n3 ). Thus a black box probe costs O(n2 tl + n2 mdt + n3 ). deg(g )  
   
  deg(f )  
   
  k ˆmax = maxn (max {#fi,k }, maxj=0 k {#gi,k }) Theorem 22. Let N i=0 k=1 where fi,k , gi,k , fk , gk is as deﬁned in (8) and let emax = 2 + maxnk=1 {deg(fk ) + deg(gk )}. Let H be maximum of all the integer coeﬃcients of all the polynomials fk and gk . Then the number of black box probes required by our algorithm to ˆmax log H). interpolate the solution vector x is O(emax N  
   
  5  
   
  Implementation and Benchmarks  
   
  We have implemented our new algorithm in Maple with some parts coded in C to improve its overall eﬃciency. The parts coded in C include evaluating an augmented matrix at integer points modulo prime p, solving the evaluated augmented matrix with integer entries over Zp using Gaussian elimination, ﬁnding and factoring the feedback polynomial produced by the Berlekamp-Massey algorithm, solving a t×t shifted Vandermonde system and performing dense rational function interpolation using the MQRFR algorithm modulo a prime. Each probe to the black box is computed using C code and its supports primes up to 63 bits in length. We have benchmarked our code on a 24 core Intel Gold 6342 processor with 256 gigabytes of RAM using only 1 core.  
   
  Solving Parametric Linear Systems  
   
  251  
   
  To test the performance of our algorithm, we create the following artiﬁcial problem. Let D ∈ Z[y1 , y2 , . . . , ym ]n×n with rank(D) = n. Let the coeﬃcient matrix A be a diagonal matrix such that its diagonal entries are non zero polyT  nomials g1 , . . . , gn and let the vector b = f1 f2 · · · fn . Clearly the vector  x=  
   
  f1 f2 g1 g2  
   
  ···  
   
  fn gn  
   
  T  
   
  solves Ax = b. But suppose we create a new linear system W x∗ = c by premultiplying Ax = b by D so that W x∗ = (DA)x∗ = Db = c. Then both parametric systems Ax = b and W x∗ = c are equivalent. That is, x∗ = W −1 c =  
   
  Adj(A)Adj(D)Db Adj(A)b Adj(DA)c = = = A−1 b = x det(DA) det(D) det(A) det(A)  
   
  where Adj denotes the adjoint matrix. In Table 2 we compare our new algorithm (row ParamLinSolve) with a Maple implementation of the Bareiss/Edmonds fraction free one step Gaussian elimination method with Lipson’s fraction formula for back substitution (row Bareiss), a Maple implementation of the Gentleman & Johnson minor expansion method (row Gentleman) and using Maple’s commands ReducedRowEchelonForm (row ReducedRow) and LinearSolve (row LinearSolve) for solving the systems W x∗ = c that were created artiﬁcially. The artiﬁcial systems W x∗ = c were created using the following Maple code: CreateSystem := proc(n,m,T,dT,t,d) local A, D,W,c,b,Y,i; Y := [ seq(y||i,i=1..m) ]; D := Matrix(n,n, () -> randpoly( Y,terms=T, degree=dT)); b := Vector[column](n, () -> randpoly(Y, terms =t, degree=d)); i := [ seq( randpoly( Y, terms =t, degree=d),i=1..n) ]; A := DiagonalMatrix(i); W,c := D.A, D.b; return W,c,A,D; end: The three input systems solved in Table 3 are real systems (Example 1 and two other systems) which were the motivation for this work. Note that the timings reported for the real systems in Table 3 are in the columns and not in rows as in Table 2. The notation ! indicates that Maple was unable to allocate enough memory to ﬁnish the computation and − means unknown in both Tables 2 and 3. The breakdown of the timings for all individual algorithms involved for computing the system named bigsys are reported in Table 4. Column max in Table 3  
   
  252  
   
  A. Jinadu and M. Monagan  
   
  contains the number of terms in the largest polynomial to be interpolated in the rational functions of the unique solution of a system. Column max in Table 3 contains the number of terms in the largest polynomial to be interpolated in the rational functions of the unique solution x of a parametric linear system. The artiﬁcial input systems W x∗ = c were created by generating matrices D, A and column vector b randomly, with all of their entries in Z[y1 , . . . , ym ] where m = 10, deg(Dij ) ≤ dT = 5, #Di,j = T ≤ 2 and deg(Aij ), deg(bj ) ≤ d = 10, #Ai,j , #bj = t ≤ 5 and rank(A) = rank(D) = n for 3 ≤ n ≤ 10. Using the Gentleman & Johnson algorithm, we obtain # det(A), # det(D), # det(W ) (rows 2–4 in Table 2) and the total CPU time used to compute each of them are reported in rows 10–13. We remark that we did not compute the gcd(det(Ak ), det(A)) when the Gentleman & Johnson algorithm was used. As the reader can see from Table 2, our algorithm performed better than other algorithms for n ≥ 5. As the reader can see in Table 4, computing the roots of the feedback polynomial for the bigsys system is the dominating cost. This is because the number of terms in many of the polynomials fi , gi to be interpolated is large. In particular, it has four polynomials where max(#fi , #gi ) > 50, 000 and our root ﬁnding algorithm for computing the roots of λ(z) costs O(t2 log p) where t = deg(λ) is the number of terms of the fi and gi being interpolated. Table 2. CPU Timings for solving W x∗ = c with #fi , #gi ≤ 5 for 3 ≤ n ≤ 10. n  
   
  3  
   
  4  
   
  5  
   
  6  
   
  7  
   
  8  
   
  9  
   
  10  
   
  # det(A)  
   
  125  
   
  625  
   
  3,125  
   
  15,500  
   
  59,851  
   
  310,796  
   
  1,923,985  
   
  9,381,213  
   
  # det(D)  
   
  40  
   
  336  
   
  3,120  
   
  38,784  
   
  518,009 8,477,343 156,424,985 –  
   
  # det(W )  
   
  5,000  
   
  209,960 9,741,747 –  
   
  –  
   
  –  
   
  –  
   
  0.220 s  
   
  0.239 s  
   
  0.259 s  
   
  0.317 s  
   
  !  
   
  !  
   
  !  
   
  ParamLinSolve 0.079 s 0.176 s  
   
  0.154 s  
   
  0.211 s  
   
  LinearSolve  
   
  304.20 s  
   
  124200 s !  
   
  0.129 s 1.26 s  
   
  –  
   
  ReducedRow  
   
  0.01 s  
   
  0.083  
   
  11.05 s  
   
  3403.2 s !  
   
  !  
   
  !  
   
  !  
   
  Bareiss  
   
  2.02 s  
   
  !  
   
  !  
   
  !  
   
  !  
   
  !  
   
  !  
   
  !  
   
  Gentleman  
   
  0.040 s 3.19 s  
   
  239.40 s  
   
  !  
   
  !  
   
  !  
   
  !  
   
  !  
   
  time-det(A)  
   
  0s  
   
  0s  
   
  0.003 s  
   
  0.08 s  
   
  0.898 s  
   
  0.703 s  
   
  17.03 s  
   
  25.32 s  
   
  time -det(D)  
   
  0s  
   
  0s  
   
  0.007 s  
   
  1.21 s  
   
  1.39 s  
   
  601.8 s  
   
  2893.8 s  
   
  !  
   
  time-det(W )  
   
  0s  
   
  0.310 s  
   
  20.44 s  
   
  !  
   
  !  
   
  !  
   
  !  
   
  !  
   
  Table 3. CPU Timings for solving three real parametric linear systems system names n  
   
  m max  
   
  21 5  
   
  2623.8 s  
   
  0.021 s  
   
  0.026 s  
   
  0.500 s 1033  
   
  Bigsys  
   
  44 48 58240 7776 s  
   
  !  
   
  17.85 s  
   
  1.66 s  
   
  !  
   
  6037416  
   
  Caglar  
   
  12 56 23072 1685.57 s  
   
  NA  
   
  1232.40 s  
   
  15480.35 s  
   
  NA  
   
  15744  
   
  NA=Not Attempted  
   
  26  
   
  ParamLinSolve Gentleman LinearSolve ReducedRow Bareiss # det(A)  
   
  Bspline  
   
  0.220 s  
   
  Solving Parametric Linear Systems  
   
  253  
   
  Table 4. Breakdown of CPU timings for all individual algorithms involved for solving bigsys Time(ms) Percentage Matrix Evaluation  
   
  151.48 s  
   
  1.9 %  
   
  Gaussian Elimination  
   
  110.71 s  
   
  1.4 %  
   
  Univariate Rational Function Interpolation  
   
  706.07 s  
   
  9%  
   
  Finding λ ∈ Zp [z] using the Berlekamp-Massey Algorithm 208.25 s  
   
  2.6 %  
   
  Roots of λ over Zp  
   
  4856.96 s  
   
  62 %  
   
  Solving Vandermonde systems  
   
  434.46 s  
   
  5.6 %  
   
  Multiplication and Addition of Evaluation points  
   
  257.40 s  
   
  3.3 %  
   
  Computing Discrete logarithms  
   
  586.64 s  
   
  7.6 %  
   
  Miscellaneous  
   
  464.67 s  
   
  9.4 %  
   
  Overall Time  
   
  7776 s  
   
  100 %  
   
  References 1. Atti, N.B., Lombardi, H., Diaz-Toca, G.M.: The Berlekamp-Massey algorithm revisited. AAECC 17(4), 75–82 (2006) 2. Bareiss, E.: Sylvester’s identity and multistep integer-preserving Gaussian elimination. Math. Comput. 22(103), 565–578 (1968) 3. Ben-Or, M., Tiwari, P.: A deterministic algorithm for sparse multivariate polynomial interpolation. In: Proceedings of STOC 2020, pp. 301–309. ACM (1988) 4. Cuyt, A., Lee, W.-S.: Sparse interpolation of multivariate rational functions. J. Theor. Comput. Sci. 412, 1445–1456 (2011) 5. Edmonds, J.: Systems of distinct representatives and linear algebra. J. Res. Natl. Bureau Stand. 718(4), 241–245 (1967) 6. Gelfond, A.: Transcendental and Algebraic Numbers. GITTL, Moscow (1952). English translation by Leo, F., Boron, Dover, New York (1960) 7. Gentleman, W.M., Johnson, S.C.: The evaluation of determinants by expansion by minors and the general problem of substitution. Math. Comput. 28(126), 543–548 (1974) 8. Lipson, J.: Symbolic methods for the computer solution of linear equations with applications to ﬂow graphs. In: Proceedings of SISMC 1968, pp. 233–303. IBM (1969) 9. Hu, J., Monagan, M.: A fast parallel sparse polynomial GCD algorithm. In: Proceedings of ISSAC 2016, pp. 271–278. ACM (2016) 10. Hu, J.: Computing polynomial greatest common divisors using sparse interpolation. Ph.D. thesis, Simon Fraser University (2018) 11. Jinadu, A., Monagan, M.: An interpolation algorithm for computing Dixon resultants. In: Boulier, F., England, M., Sadykov, T.M., Vorozhtsov, E.V. (eds.) CASC 2022. LNCS, vol. 13366, pp. 185–205. Springer, Cham (2022). https://doi.org/10. 1007/978-3-031-14788-3_11 12. Jinadu, A., Monagan, M.: A new interpolation algorithm for computing Dixon Resultants. ACM 56(2), 88–91 (2022) 13. Kaltofen, E., Lee, W., Lobo, A.: Early termination in Ben-Or/Tiwari sparse interpolation and a hybrid of Zippel’s algorithm. In: Proceedings of ISSAC 2000, pp. 192–201. ACM (2000)  
   
  254  
   
  A. Jinadu and M. Monagan  
   
  14. Monagan, M.: Maximal quotient rational reconstruction: an almost optimal algorithm for rational reconstruction. In: Proceedings of ISSAC 2004, pp. 243–249. ACM (2004) 15. Monagan, M., Vrbik, P.: Lazy and forgetful polynomial arithmetic and applications. In: Gerdt, V.P., Mayr, E.W., Vorozhtsov, E.V. (eds.) CASC 2009. LNCS, vol. 5743, pp. 226–239. Springer, Heidelberg (2009). https://doi.org/10.1007/9783-642-04103-7_20 16. Schwartz, J.: Fast probabilistic algorithms for veriﬁcation of polynomial identities. J. ACM 27, 701–717 (1980) 17. Zippel, R.: Probabilistic algorithms for sparse polynomials. In: Ng, E.W. (ed.) Symbolic and Algebraic Computation. LNCS, vol. 72, pp. 216–226. Springer, Heidelberg (1979). https://doi.org/10.1007/3-540-09519-5_73  
   
  On the Distance to the Nearest Defective Matrix Elizaveta Kalinina(B) , Alexei Uteshev , Marina Goncharova , and Elena Lezhnina Faculty of Applied Mathematics, St. Petersburg State University, 7–9 Universitetskaya nab., St. Petersburg 199034, Russia {e.kalinina,a.uteshev,m.goncharova,e.lezhnina}@spbu.ru http://www.apmath.spbu.ru  
   
  Abstract. The problem of finding the Frobenius distance in the Cn×n matrix space from a given matrix to the set of matrices with multiple eigenvalues is considered. The problem is reduced to the univariate algebraic equation construction via computing the discriminant of an appropriate bivariate polynomial. Several examples are presented including the cases of complex and real matrices.  
   
  Keywords: Wilkinson’s problem norm · Discriminant  
   
  1  
   
  · Complex perturbations · Frobenius  
   
  Introduction  
   
  The problem of distance evaluation from a given square matrix A to a certain subset of matrices in the matrix space is a known metric problem of Computational Algebra. For instance, one might refer to the distance to the nearest degenerate matrix, or to the nearest orthogonal matrix (Procrustes problem), or, in the case of Routh–Hurwitz stable matrix A, to the nearest unstable matrix (stability radius), etc. The present article is devoted to a problem from this ﬁeld. Namely we are looking for the distance from A ∈ Cn×n to the set D of complex matrices with multiple eigenvalues (these matrices are further referred to as the defective matrices). This classical problem is known as Wilkinson’s problem, and the required distance, further denoted as dC (A, D), is called the Wilkinson distance of A [2,15]. For the spectral and the Frobenius norm, Wilkinson’s problem has been studied by many researchers (see, for example, [2,6,7,13,14,18,20–22] and references therein). The most important result for the spectral norm was obtained by Malyshev [14]. Theorem 1. Let A ∈ Cn×n . Let the singular values of the matrix   A − λIn γIn On×n A − λIn c The Author(s), under exclusive license to Springer Nature Switzerland AG 2023  F. Boulier et al. (Eds.): CASC 2023, LNCS 14139, pp. 255–271, 2023. https://doi.org/10.1007/978-3-031-41724-5_14  
   
  (1)  
   
  256  
   
  E. Kalinina et al.  
   
  be ordered like σ1 (λ, γ) ≥ σ2 (λ, γ) ≥ . . . ≥ σ2n (λ, γ) ≥ 0. Then the 2-norm distance dC (A, D) can be evaluated as dC (A, D) = min max σ2n−1 (λ, γ) . λ∈C γ≥0  
   
  However, the min-max representation does not provide the constructive solution of Wilkinson’s problem. For this reason, in some works [1–3,13], the pseudospectra approach was used to ﬁnd the Wilkinson distance. For both the 2-norm and the Frobenius norm, the ε-pseudospectrum of a matrix A is deﬁned as Λε (A) = {σmin < ε} where ε > 0, and σmin stands for the smallest singular value of the matrix A−zI. Equivalently, Λε (A) = {z ∈ C| det(A + E − zI) = 0, for some E ∈ Cn×n with E < ε}. The examination of the pseudospectrum of a matrix A gives the critical points of the minimal singular value σmin (x, y) of the matrix A−(x+iy)I. These critical points allow one to ﬁnd the nearest defective matrix. A geometric solution using such approach is given in [13]. In [2], the smallest perturbation E∗ is found using the fact that the components of the pseudospectrum of A + E∗ must coalesce. The computational approaches to approximate the nearest defective matrix by algorithms based on Newton’s method are suggested in [1,3]. All the approaches developed in the above cited papers could be characterized as related to the Numerical Linear Algebra. Also there are several works concerning the problems related to the perturbation sensitivity of multiple eigenvalues (for example, see [4,15,17] and others). In the present paper, to ﬁnd the Wilkinson distance in the Frobenius norm we use the Symbolic Computation approach that has been initiated in [12]. Main goal is the construction of the univariate algebraic equation with the set of real zeros coinciding with the critical values of the squared distance function to the set D. The paper is organized as follows. In Sect. 2, we start with algebraic background for the stated problem. The cornerstone notion here is the multivariate resultant of a system of algebraic equations that helps to ﬁnd the solution of this system. A particular case of the resultant, namely the bivariate discriminant of a polynomial in two variables, is a univariate polynomial whose zero set contains all the critical values of the squared distance to the set of matrices with multiple eigenvalues. Its construction is theoretically feasible via application of symbolic methods for elimination of variables. In Sect. 3, we consider the case of a complex matrix. With the help of the fact that the minimal perturbation is a rank-one matrix and the theorems connecting singular values and eigenvalues of matrices under consideration, we obtain the  
   
  Distance to Defective Matrix  
   
  257  
   
  system of algebraic equations whose zero set contains the multiple eigenvalue of the nearest defective matrix and the squared distance to this matrix. The case of a real matrix has some simpliﬁcations and features that we treat in Sect. 4. For both complex and real cases, the examples showing applicability of the developed algorithm are presented. Notation. For a matrix A ∈ Cn×n , fA (λ) denotes its characteristic polynomial, dC (A, D) denotes the distance in Cn×n from A to the set D of matrices possessing a multiple eigenvalue; E∗ and B∗ = A + E∗ stand for, correspondingly, the (minimal) perturbation matrix and the nearest to A matrix in D (i.e., dC (A, D) = A − B∗ ); we then term by λ∗ = a∗ + ib∗ the multiple eigenvalue of B∗ ; I (or In ) denotes the identity matrix (of the corresponding order); D (or Dx,y ) denotes the discriminant of a polynomial (with subscript indicating the variables); the superscript H stands for the Hermitian transpose while  stands for the transpose. Remark. All the computations were performed in CAS Maple 15.0, LinearAlgebra package. Although all the approximate computations have been performed within the accuracy 10−40 , the ﬁnal results are rounded to 10−6 .  
   
  2  
   
  Algebraic Preliminaries  
   
  We assume that the concept of resultant and discriminant of the univariate polynomials is known to the reader. A sketch of theoretical results related to the problems discussed further can be found in the corresponding section of [11]. A concept of the multivariate resultant is used to establish a necessary and suﬃcient condition for the existence of a common zero of a multivariate algebraic system. Its constructive computation can be implemented in several ways, and we will exemplify below the procedure based of the B´ezout construction of the resultant [5] for the bivariate case. Consider the polynomials {f1 (x, y), f2 (x, y), g(x, y)} ⊂ R[x, y], n1 := deg f1 ≥ 1, n2 := deg f2 ≥ 1, m := deg g ≥ 1. We need to ﬁnd the condition for the existence of a solution of a system of algebraic equations f1 (x, y) = 0, f2 (x, y) = 0, g(x, y) = 0 .  
   
  (2)  
   
  We expand f1 and f2 in decreasing powers of variables: fj (x, y) ≡ fj,nj (x, y) + fj,nj −1 (x, y) + . . . + fj,0 (x, y), j ∈ {1, 2} where fj,k (x, y) stands for the form of degree k. Suppose the resultant of the leading forms A0 := Rx (f1,n1 (x, 1), f2,n2 (x, 1)) = 0; then the system f1 (x, y) = 0, f2 (x, y) = 0  
   
  (3)  
   
  258  
   
  E. Kalinina et al.  
   
  has precisely N = n1 n2 (the B´ezout bound) solutions (αj , βj ) ∈ C2 , and the bivariate resultant is formally deﬁned as g g Rx,y (f1 , f2 , g) := Am 0 Rx,y (f1 , f2 ), where Rx,y (f1 , f2 ) :=  
   
  N   
   
  g(αj , βj ) .  
   
  j=1  
   
  We utilize the process of ﬁnding the normal form (or the reduction) modulo the ideal I(f1 , f2 ). As a basis for the vector space R[x, y]/I(f1 , f2 ), generically the B´ezout’s set p q M = {μk (x, y)}N k=1 = {x y |0 ≤ p ≤ n1 , 0 ≤ q ≤ n2 }  
   
  (4)  
   
  can be chosen. The monomials of this set might be numbered arbitrarily but, in view of subsequent needs, we specify μ1 = 1, μ2 = x, μ3 = y. Then we ﬁnd the normal form for μk (x, y)g(x, y): μk (x, y)g(x, y) + I(f1 , f2 ) = bk1 μ1 (x, y) + . . . + bkN μN (x, y), {bkj }N k,j=1 ⊂ R. The matrix  
   
  N  
   
  B = [bkj ]k,j=1  
   
  (5)  
   
  is called the B´ezout matrix. One has Rgx,y (f1 , f2 ) = det B . The determinant in the right-hand side is a rational function of the coeﬃcients of the polynomials f1 , f2 and g, and generically, the condition det B = 0 is the necessary and suﬃcient for the existence of a solution of system (2). Under the condition rank(B) = N −1, this solution is unique. Denote by BN j the cofactor to the entries of the last row of det B and assume that BN 1 = 0. Then the components of the solution (x0 , y0 ) of system (2) can be found by the formulas (6) x0 = BN 2 /BN 1 , y0 = BN 3 /BN 1 , i.e., they can be expressed as rational functions of the coeﬃcients of the polynomials f1 , f2 , and g. In further considerations, we are mainly in need of a particular case of the resultant, namely the discriminant of a bivariate polynomial F (x, y) ∈ R[x, y]. It can be formally deﬁned as Dx,y (F (x, y)) := RF x,y (∂F/∂x, ∂F/∂y) , and it can be represented as a rational function of the coeﬃcients of the polynomial F . For the case of polynomials in three variables x, y, and z, the above traced procedures permit one to implement the algorithm of elimination of the variables x and y from the corresponding algebraic system. This algorithm results in a univariate algebraic equation providing z-components of solutions while the x and y-components are represented as rational functions of the z-component.  
   
  Distance to Defective Matrix  
   
  3  
   
  259  
   
  Complex Matrix  
   
  We will utilize further the two known results [8–10]. The ﬁrst one is related to the matrix eigenvalues. Theorem 2. Let {λ1 , λ2 , . . . , λn } ⊂ C be the spectrum of a matrix B ∈ Cn×n and let Vλ1 ∈ Cn be a unit eigenvector corresponding to λ1 . Then there exists a unitary matrix V = [Vλ1 , V2 , . . . , Vn ] that furnishes the upper triangular Schur decomposition B = V TV H where T = [tij ]ni,j=1 is upper triangular with diagonal entries {tjj = λj }nj=1 . The second result concerns the singular values of a matrix. For a nonsingular matrix A ∈ Cn×n , denote by σ1 ≥ σ2 ≥ . . . ≥ σn > 0 its singular values while by Uσj and Vσj its left and right unit singular vectors corresponding to σj . Thus, the singular value decomposition of A is A = U Dn V H , with unitary matrices U = [Uσ1 , . . . , Uσn ] and V = [Vσ1 , . . . , Vσn ], and diagonal matrix Dn = diag {σ1 , σ2 , . . . , σn }. Theorem 3. For both the 2-norm and the Frobenius norm, one has min ||A − B|| = ||A − B∗ || = σn .  
   
  det B=0  
   
  The nearest to A singular matrix is B∗ = U Dn−1 V H where Dn−1 = diag {σ1 , σ2 , . . . , σn−1 , 0} . The minimal perturbation E∗ such that B∗ = A + E∗ , E∗  = σn is given by the rank-one matrix E∗ = −σn Uσn VσHn = −Uσn UσHn A . Corollary 1. The distance from A ∈ Cn×n to the nearest matrix B0 with the prescribed eigenvalue λ0 ∈ C such as det(A − λ0 I) = 0, equals the least singular value σ0 of the matrix A − λ0 I. If Uσ0 is the unit left singular vector of A − λ0 I corresponding to σ0 , then E0 = Uσ0 UσH0 (λ0 I − A), E0  = σ0 is the minimal perturbation such that A + E0 = B0 . Further, for a given matrix A, we want to ﬁnd an appropriate value λ0 such that the corresponding nearest matrix B0 has λ0 as a multiple eigenvalue.  
   
  260  
   
  E. Kalinina et al.  
   
  Lemma 1. A value λ0 ∈ C is a multiple eigenvalue of a given matrix B iﬀ there exist unit vectors {X0 , Y0 } ⊂ Cn such that BX0 = λ0 X0 , Y0H B = λ0 Y0H , Y0H X0 = 0 .  
   
  (7)  
   
  This assertion was presented in the work [13] with reference to [19]. Its proof is trivial under additional assumption of the uniqueness of the multiple eigenvalue. For the general case, no proof is listed anywhere. Proof. Consider the Schur decomposition of the matrix B from Theorem 2. Let λ0 ∈ C be a multiple eigenvalue of the matrix B and let Vλ0 be a corresponding unit eigenvector. A unitary matrix V = [Vλ0 , V2 , . . . , Vn ] can be chosen providing the decomposition B = V T V H where T is the upper triangular matrix such that t11 = λ0 , tnn = λ0 . Then the vectors X0 = Vλ0 and Y0 = Vn satisfy conditions (7). Now assume that λ0 is a simple eigenvalue of the matrix B but the conditions (7) are fulﬁlled for some unit vectors X0 , Y0 . A unitary matrix V can be chosen providing the decomposition B = V T V H where T is the upper triangular 0 = V H X0 and matrix such that t11 = λ0 , t22 = λ0 , . . . tnn = λ0 . The vectors X H  Y0 = V Y0 are unit vectors that satisfy the conditions 0 , Y0H T = λ0 Y0H , Y0H X 0 = 0 .  0 = λ0 X TX  
   
  (8)  
   
  0 := [ x1 , . . . , x n−1 , x n ] , then the ﬁrst of the conditions (8) yields tnn x n = If X n that leads to x n = 0. Then, successively using the triangular structure of T , λn x 0 := [1, 0, . . . , 0] . Simi2 = 0. Therefore, X one can deduce that x n−1 = 0, . . . , x  lar structure can be established for Y0 . This contradicts the last condition (8). The following statement is a counterpart of the result proved in [14]. Lemma 2. Denote by σ(a, b) a singular value of the matrix A − (a + bi)I ({a, b} ⊂ R), and by U (a, b) and V (a, b) its corresponding left and right unit singular vectors. The system of equations ∂σ/∂a = 0, ∂σ/∂b = 0 possesses a solution (a0 , b0 ) ∈ R2 iﬀ U H (a0 , b0 )V (a0 , b0 ) = 0 . Proof. Since σ(a, b) ≡ U H (a, b)(A − (a + bi)I)V (a, b) , U H (a, b)U (a, b) ≡ 1, V H (a, b)V (a, b) ≡ 1 , diﬀerentiation of these identities with respect to a results in  H  ∂U ∂σ ∂V = (A − (a + bi)I)V + U H (A − (a + bi)I) − U HV ∂a ∂a ∂a  H  ∂U ∂V = U +VH − U H V = −U H V . ∂a ∂a  
   
  (9)  
   
  Distance to Defective Matrix  
   
  Similarly,  
   
  261  
   
  ∂σ/∂b = −iU H V ,  
   
  and this completes the proof. Now consider the matrix E(a, b) = −σ(a, b)U (a, b)V H (a, b) . According to Corollary 1, the matrix B = A + E has the eigenvalue λ = a + bi and this is the nearest to A matrix with such an eigenvalue. Corollary 2. System (9) possesses a solution (a0 , b0 ) ∈ R2 iﬀ λ0 = a0 + b0 i is a multiple eigenvalue of the matrix A + E(a0 , b0 ). Proof. Being the singular vectors of the matrix A + E(a0 , b0 ), the vectors U (a0 , b0 ) and V (a0 , b0 ) satisfy the conditions (A + E(a0 , b0 ))V (a0 , b0 ) = (a0 + b0 i)V (a0 , b0 ), U H (a0 , b0 )(A + E(a0 , b0 )) = (a0 + b0 i)U H (a0 , b0 ) . By Lemma 2, system (9) possesses a solution (a0 , b0 ) ∈ R2 iﬀ U H (a0 , b0 )V (a0 , b0 ) = 0 . The conditions of Lemma 1 are fulﬁlled. Due to the last result, the values of the parameters a and b corresponding to the potential multiple eigenvalue of the matrix in D nearest to A are contained in the set of stationary points of the function σ(a, b). The latter is deﬁned implicitly via the equation    det ((a + bi)I − A) (a − bi)I − AH − σ 2 I = 0 . Due to the implicit function theorem [16], the partial derivatives ∂σ/∂a and ∂σ/∂b can be expressed via those of the function    (10) Θ(a, b, z) := det ((a + bi)I − A) (a − bi)I − AH − zI . Indeed, one has: ∂Θ ∂Θ ∂σ ∂Θ ∂Θ ∂σ + 2σ ≡ 0, + 2σ ≡0 ∂a ∂z ∂a ∂b ∂z ∂b and, therefore, the stationary points of the function σ(a, b) are deﬁned by the system of equations Θ(a, b, z) = 0, ∂Θ(a, b, z)/∂a = 0, ∂Θ(a, b, z)/∂b = 0.  
   
  (11)  
   
  We are looking for the real solutions of system (11). We ﬁrst clarify the essence of the z-component of these solutions.  
   
  262  
   
  E. Kalinina et al.  
   
  Theorem 4. Let system (11) possess a real solution (a0 , b0 , z0 ) such that z0 > 0 and ∂Θ/∂z = 0. By U0 ∈ Cn , U0  = 1 denote the left singular vector of the √ matrix (a0 +ib0 )I −A corresponding to the singular value z0 . Then the rank-one perturbation (12) E0 = U0 U0H ((a0 + ib0 )I − A) √ is such that E0  = z0 and the matrix B0 = A + E0 ∈ Cn×n possesses the multiple eigenvalue a0 + ib0 . √ Proof. The equality E0  = z0 is veriﬁed directly. Any solution (a0 , b0 , z0 ) of the system (11) with z0 > 0, is such that ∂σ/∂a = 0, ∂σ/∂b = 0. Hence, by Lemma 2, the vectors √ U0 and z0 V0 = ((a0 + ib0 )I − A)H U0 are orthogonal. By Corollary 2, this yields that the matrix B0 possesses the multiple eigenvalue a0 + ib0 . Remark. In some exceptional cases, system (11) has a continuum of solutions (for example, this relates to the cases of skew-symmetric and orthogonal matrices [12]). Evidently, in these cases, we obtain a continuum of nearest matrices in D. Theorem 4 and Corollary 1 claim that the value dC (A, D) for A ∈ D equals the square root of one of the positive values of the z-components of the real solutions of system (11). Our next aim is to eliminate the variables a and b from this system. According to the results of Sect. 2, we need to ﬁnd the bivariate discriminant Da,b (Θ(a, b, z)). This is a polynomial in z. 2  
   
  Theorem 5. Generically polynomial Da,b (Θ(a, b, z)) possesses a factor z n . Proof. Polynomial Θ(a, b, 0) can be represented as the sum of squares of two polynomials from R[a, b]: Θ(a, b, 0) ≡ F12 (a, b) + F22 (a, b) where F1 (a, b) := Re (det [(a + bi)I − A]) , F2 (a, b) := Im (det [(a + bi)I − A]) and deg F1 = deg F2 = n. Therefore, for z = 0, system (11) transforms into F12 + F22 = 0, F1 ∂F1 /∂a + F2 ∂F2 /∂a = 0, F1 ∂F1 /∂b + F2 ∂F2 /∂b = 0 that in turn is equivalent to F1 (a, b) = 0, F2 (a, b) = 0 . The latter possesses n2 solutions in C2 including n real ones coinciding with {(Re(μj ), Im(μj ))}nj=1 where {μ1 , . . . , μn } is the spectrum of the matrix A.  
   
  Distance to Defective Matrix  
   
  Denote  
   
  2  
   
  FC (z) := Da,b (Θ(a, b, z))/z n .  
   
  263  
   
  (13)  
   
  Generically, d2C (A, D) equals the minimal positive zero of the equation FC (z) = 0; the latter will be further referred to as the distance equation.   Remark. Since the matrix ((a + bi)I − A) (a − bi)I − AH is a Hermitian positive semi-deﬁnite one, (its characteristic) polynomial Θ(a, b, z) has real coeﬃcients, and all the real zeros of the distance equation are non-negative. Hence, the following algorithm for ﬁnding the distance to the nearest defective matrix and the minimal complex perturbation can be suggested. 1. Compute Θ(a, b, z) by formula (10). 2. Compute (for instance, via the B´ezout matrix approach exempliﬁed in Example 1) the bivariate discriminant Da,b (Θ(a, b, z)). √ 3. Evaluate the minimal positive zero z∗ of polynomial (13). Thus, dC = z∗ . 4. Evaluate (via the B´ezout matrix approach exempliﬁed in Example 1) the corresponding values a∗ and b∗ such that (a∗ , b∗ , z∗ ) is the solution of system (11). 5. Compute the unit left singular vector U∗ of the matrix A − (a∗ + ib∗ )I corre√ sponding to z∗ . 6. Compute the minimal perturbation E∗ by (12). Example 1. Find dC (A, D) for the matrix ⎡ ⎤ 1 + i 1 − 2i 2 − 2i A = ⎣ 1 + 2i 2 + i 1 − 3i ⎦ . 2 1 + 2i 2 + i Solution. One has Θ(a, b, z) = −z 3 + (3a2 + 3b2 − 10a − 6b + 49)z 2 +(−3a4 − 6a2 b2 − 3b4 + 20a3 + 12a2 b + 20ab2 + 12b3 −61a2 − 60ab − 105b2 + 144a + 210b − 539)z +(−a3 + 3ab2 + 5a2 − 6ab − 5b2 + 11a + 15b − 39)2 +(−3a2 b + b3 + 3a2 + 10ab − 3b2 − 15a + 11b + 4)2 , and polynomial (13) is computed via the determinant of the B´ezout matrix (5). The B´ezout set of monomials diﬀers from (4): M = {1, a, b, a2 , a3 , b2 , b3 , b4 , ab, ab2 , ab3 , a2 b, a2 b2 } . The B´ezout matrix has the order 13 with its entries being polynomials in z: b11 = −51764778 z 3 + 32048312739 z 2 + 146567003492 z − 2397651748842, . . .  
   
  264  
   
  E. Kalinina et al.  
   
  Up to an integer factor, one has FC (z) = 108399666917514309184000000z 12 + 3762725041344245481644288000z 11 +7970534284699355155910379345664z 10 +594852772422819225099947772015616z 9 +58966505410792048579506939783280880z 8 −1934010322986529287515147546541977912z 7 −3339817707641603248547229214144474391z 6 −668550529522759437104028660964878679783z 5 +34400831204203249689441872938140635868897z 4 −456665104689590746438681155159484447480610z 3 +2541391271350022866101000210682775147554550z 2 −6005735582941157597386422955673240674516500z +4417849441492361445160051187261557418095000 .  
   
  The distance equation possesses the following real zeros z1 ≈ 1.298448, 4.362357, 6.371340, 6.882992, 13.995031, 23.393345 . √ Hence, dC (A, D) = z1 ≈ 1.139494. Corresponding values for the a and bcomponents of solutions of system (11) are evaluated via the cofactors to the last row of det B(z). Formulas (6) take the form a = B13,2 (z)/B13,1 (z), b = B13,3 (z)/B13,1 (z) , and we restrict ourselves here to demonstration of the denominator (skipping an integer factor): B13,1 (z) = z 8 (1636287272729082827584195302400000 z 10 +516189189984338149941804758347801600 z 9 +13308879336238950915643689611262176000 z 8 +12798163449938933324094163049611587456 z 7 −41558519493626568482835297835309335402880 z 6 −85832655417511950681993552102152413260748 z 5 +91417365889462739280827447351551203496537387 z 4 −1852347585745752531328887611730151802746655737 z 3 +15546611877005879880021480393809409194725568820 z 2 −57318861605312466147953930049815178122740094650 z +65077268487484068397392884364062721686477728500). Substitution z = z1 yields a1 ≈ 3.809241, b1 ≈ 0.668805 .  
   
  Distance to Defective Matrix  
   
  265  
   
  Now the unit left singular vector of A − (a1 + b1 i)I corresponding to  
   
  √ z1 is  
   
  U1 ≈ [−0.126403 + 0.234075i, 0.482021 − 0.080184i, 0.040115 + 0.829968i] , and the minimal perturbation is evaluated via (12) ⎡  
   
  ⎤ 0.105485 − 0.195337i −0.141553 − 0.138978i 0.010251 − 0.056115i E∗ ≈ ⎣ −0.402250 + 0.066914i −0.042258 + 0.361922i −0.092974 + 0.048320i ⎦ . −0.033476 − 0.692614i −0.602916 − 0.142937i −0.063226 − 0.166585i  
   
  The spectrum of the matrix A + E∗ is {≈ −2.618482 + 1.662389i, a1 + ib1 , a1 + ib1 } .  
   
  4  
   
  Real Matrix  
   
  We now turn to the case of a real matrix A though the potential perturbations are still treated in Cn×n . System (11) splits naturally into two subsystems. Theorem 6. Let A ∈ Rn×n . If system (11) possesses a solution (a0 , b0 , z0 ) with b0 = 0, then it has the solution (a0 , −b0 , z0 ). Proof. Polynomial Θ(a, b, z) is even in b:  Θ(a, −b, z) = det ((a + ib)I − A )((a − ib)I − A) − zI    = det ((a + ib)I − A )((a − ib)I − A) − zI  = det ((a − ib)I − A )((a + ib)I − A) − zI = Θ(a, b, z). Consequently, Θa is even in b while Θb is odd in b. The latter becomes even on dividing by b. Further analysis depends on whether or not the condition b = 0 is fulﬁlled. If b = 0, then system (11) transforms into Θ(a, 0, z) = 0, ∂Θ(a, 0, z)/∂a = 0 .  
   
  (14)  
   
  The bivariate discriminant (13) degrades to the univariate one Da (Θ(a, 0, z)). This polynomial happens to possess a factor z n . We denote FR (z) := Da (Θ(a, 0, z))/z n .  
   
  (15)  
   
  Equation FR (z) = 0 provides the distance dR (A, D) to the nearest matrix in D with double real eigenvalue. The corresponding perturbation E is also real. As for the case b = 0, system (11) can be reduced to Θ = 0, Θa = 0, Θb /b = 0 where all the polynomials are even in b. Substitute b := b2 into these polynomials and denote Ξ(a, b, z) := Θ(a, b, z), Ξa (a, b, z) := Θa (a, b, z), Ξb (a, b, z) := Θb (a, b, z)/b .  
   
  266  
   
  E. Kalinina et al.  
   
  Theorem 7. The result of elimination of variables a and b from the system Ξ = 0, Ξa = 0, Ξb = 0 is the equation  
   
  (16)  
   
  z n(n−1)/2 FI (z) = 0 .  
   
  Here FI (z) ∈ R[z] and generically deg FI (z) = n(n − 1)(n − 2)/2. (Thus, for n = 2, polynomial FI (z) is just a constant). If z0 is a positive zero of FI (z), the corresponding real solution of system (16) might have the b-component either positive or negative. We are interested only in the positive variant. Equation FI (z) = 0 provides the distance dI (A, D) to the nearest matrix in D with double imaginary eigenvalues. Its real zero z0 corresponds to a pair of multiple zeros of the polynomial Θ(a, b, z0 ), and these zeros are either in the form (a0 , ±β0 ) or in the form (a0 , ±iβ0 ) with real β0 . We are deﬁnitely interested only in the real solutions of system (11). > 0, b0 = 0 of system (11), the rankFor any real solution (a0 , b0 , z0 ) with z0 √ one perturbation (12) is such that E0  = z0 and the matrix B0 = A + E0 ∈ Cn×n possesses the double eigenvalue a0 + ib0 (v. Theorem 4). Evidently, the matrix E0 provides the double eigenvalue a0 − ib0 for the matrix B0 = A + E0 . In view of Theorem 4, the distance dC (A, D) results from the competition between dR (A, D) and dI (A, D), i.e., between the minimal positive zero of FR (z) and the minimal positive zero of FI (z) that corresponds to the real solution of the system (11). Formal relationship of the polynomials FR (z) and FI (z) with the general case of the distance equation treated in Sect. 3 is given by the following result. Theorem 8. For a real matrix A, one has the following identity Da,b (Θ(a, b, z)) ≡ z n(n+1)/2 FR (z)FI (z) .  
   
  (17)  
   
  Proof. We restrict ourselves here with the establishing of the factor z n(n+1)/2 in the right-hand side of (17). This can be done with the aid of arguments similar to those from the proof of Theorem 5. Indeed, Θ(a, b, 0) ≡ det((a + bi)I − A) det((a − bi)I − A ) and Θ(a, b, 0) = 0 iﬀ either a + bi or a − bi coincides with some of eigenvalues {νj }nj=1 of the matrix A. Since the latter is real, for any (a0 , b0 ) ∈ R2 such that Θ(a0 , b0 , 0) = 0, the relations a0 + ib0 = νj , a0 − ib0 = νk should be valid for some pair of indices j and k from {1, . . . , n}. Then (a0 , b0 ) is also a solution of the system ∂Θ(a, b, 0)/∂a = 0, ∂Θ(a, b, 0)/∂b = 0  
   
  Distance to Defective Matrix  
   
  267  
   
  due to the equality ∂fA (a + bi) ∂Θ(a, b, 0) ∂fA (a − bi) ≡ fA (a − bi) + fA (a + bi) ∂a ∂a ∂a and similarly for ∂Θ(a, b, 0)/∂b. Here fA (ν) := det(νI − A). The total number of possible pairs (j, k) chosen from the set {1, . . . , n} such that j ≤ k (NB: equal values are allowed!) is exactly n(n + 1)/2. For a real matrix, the following modiﬁcation of the algorithm from Sect. 3 can be implemented. 1. 2. 3. 4. 5.  
   
  Compute Θ(a, b, z) by formula (10). Compute the univariate discriminant Da (Θ(a, 0, z)). Evaluate the minimal positive zero z1 of the polynomial (15). Compute the bivariate discriminant Da,b (Ξ(a, b, z)). Evaluate the minimal positive zero z1 of the polynomial FI (z) deﬁned in Theorem 7. 6. Find the corresponding value b1 such that (a1 , b1 , z1 ) is a solution of the system (16). If b1 > 0, then go to point 7. Otherwise, evaluate the next to z1 positive zero of √ FI (z), denote it z1 and return to the point 6. 7. Set dC (A, D) = z∗ where z∗ = min{z1 , z1 }. 8. Compute the minimal perturbation E∗ via (12). Example 2. Find dC (A, D) for  
   
  ⎡  
   
  ⎤ 0 1 0 0 1⎦ . A=⎣ 0 −91 −55 −13  
   
  Solution. First compute Eq. (15): FR (z) := 33076090700402342058246544 z 6 −377039198861306289080145178864 z 5 +937864902703881321034450183916 z 4 −771868276098720970149792503999 z 3 +211070978787821517684022650624 z 2 −510584100140452518540394496 z +319295875259784560640000 . Its real zeros are as follows z1 ≈ 0.739336, 0.765571, 0.980468, 11396.658548 . Next compute the polynomial Ξ(a, b, z): Ξ(a, b, z) = −z 3 + (3a2 + 3b + 26a + 11477)z 2 −(3 a4 + 6 a2 b + 3 b2 + 52a3 + 52ab + 11756a2 + 11536b + 11466 a + 19757)z    + a2 + b + 14 a + 49 (a2 + b + 6 a + 13)2 − 16 b .  
   
  268  
   
  E. Kalinina et al.  
   
  Now we trace brieﬂy the procedure of elimination of a and b from system (16). The B´ezout set of monomials M = {1, a, b, b2 } , and the B´ezout matrix is of the order 4. Then det B(z) ≡ z 3 FI (z) where FI (z) = 412324266119803814719539025 z 3 + 33923334498676415590177600 z 2 +691077589890510378371072 z − 899669298077697638400 . For any zero z0 of this polynomial, the corresponding a and b components of the solution to system (16) can be obtained via the cofactors to the last row of det B(z) (18) a = B42 (z)/B41 (z), b = B43 (z)/B41 (z) where B41 = 16(624300876564482975z 2 − 226254560538037856z −3469512291865600), B42 = 8(43719663040898080379z 2 + 2929017747573439808z +29336262189312000), B43 = 3083432482762007609519z 3 + 1101690698089389073600z 2 +67186386329988787456z − 129087561954918400 . Polynomial FI (z) possesses a single real zero, namely z1 ≈ 0.001227 , and substitution of this value into formulas (18) yields a = a1 ≈ −4.403922, b = b1 ≈ 0.750705 . Since b1 > 0, one may claim that dC (A, D) =  
   
    
   
  z1 ≈ 0.035026 .  
   
  The two perturbations in C3×3 providing this distance correspond to the solutions of system (11)  (a1 , b1 , z1 ) and (a1 , −b1 , z1 ) where b1 = b1 ≈ 0.866432 . Let us compute via (12) the one corresponding to (a1 , −b1 , z1 ). The √unit left singular vector of (a1 − ib1 )I − A corresponding to the singular value z1 is as follows U1 ≈ [0.930609, 0.360923 + 0.039918 i, 0.045052 + 0.008866 i]  
   
    
   
  Distance to Defective Matrix  
   
  269  
   
  and the minimal perturbation ⎡ ⎤ 0.001289 − 0.000442i −0.007120 + 0.000832i 0.031666 + 0.002551i E∗ ≈ ⎣ 0.000519 − 0.000116i −0.002797 + 0.000017i 0.012172 + 0.002348i ⎦ . 0.000067 − 0.000009i −0.000353 − 0.000028i 0.001509 + 0.000425i The spectrum of the matrix A + E∗ is {a1 − ib1 , a1 − ib1 , −13 − 2(a1 − ib1 ) ≈ −4.192156 − 1.732865i} . To test the performability of the algorithm sketched in the present section, we chose the next matrix from the Matlab gallery( grcar ,6). Example 3. Find dC (A, D) for ⎤ 1 1 1 1 00 ⎢ −1 1 1 1 1 0 ⎥ ⎥ ⎢ ⎢ 0 −1 1 1 1 1 ⎥ ⎥ A=⎢ ⎢ 0 0 −1 1 1 1 ⎥ . ⎥ ⎢ ⎣ 0 0 0 −1 1 1 ⎦ 0 0 0 0 −1 1 ⎡  
   
  Solution. Here polynomial FR (z) of degree 30 has the minimal zero z1 ≈ 0.116565. Polynomial FI (z) of degree 58 has integer coeﬃcients of orders up to 1089 and possesses 22 positive zeros with the minimal one1 z1 ≈ 0.04630491415327188209539627157 . The latter corresponds to the real solution of system (11): (a1 , ±b1 , z1 ) where a1 ≈ 0.753316, b1 ≈ −1.591155 . Thus, one obtains dC (A, D) =  
   
    
   
  z1 ≈ 0.2151857666140395125353 .  
   
  This conﬁrms estimation dC (A, D) ≈ 0.21519 from [1,2]. For the solution (a1 , b1 , z1 ), the spectrum of the nearest to A defective matrix is as follows {0.361392 − 1.944783i, 1.139422 − 1.239762i, 1.502453 − 0.616966i, 1.490100 + 0.619201i, a1 + ib1 , a1 + ib1 } .  
   
  1  
   
  All the decimals in the following approximation are error-free.  
   
  270  
   
  5  
   
  E. Kalinina et al.  
   
  Conclusions  
   
  We have investigated the Wilkinson’s problem for the distance evaluation from a given matrix to the set of matrices possessing multiple eigenvalues. The problem is reduced to that of a univariate algebraic equations system solving. In the framework of the developed approach, the algorithm for ﬁnding the nearest defective matrix is also proposed. The last opportunity might be essential for the problem of sensitivity estimation of a particular matrix entry perturbation on the distance value. The authors believe that the counterparts of the approach that might be applicable to the other metric problems in matrix space including those mentioned in the ﬁrst paragraph of the present paper can be constructed. Acknowledgment. This research was supported by the St. Petersburg State University (project ID 96291288). The authors are grateful to the anonymous referees and to Prof. Evgenii V. Vorozhtsov for valuable suggestions that helped to improve the quality of the paper.  
   
  References 1. Akinola, R.O., Freitag, M.A., Spence, A.: The calculation of the distance to a nearby defective matrix. Numer. Linear Algebra Appl. 21(3), 403–414 (2014) 2. Alam, R., Bora, S.: On sensitivity of eigenvalues and eigendecompositions of matrices. Linear Algebra Appl. 396, 273–301 (2005) 3. Alam, R., Bora, S., Byers, R., Overton, M.L.: Characterization and construction of the nearest defective matrix via coalescence of pseudospectral components. Linear Algebra Appl. 435, 494–513 (2011) 4. Armentia, G., Gracia, J.-M., Velasco, F.-E.: Nearest matrix with a prescribed eigenvalue of bounded multiplicities. Linear Algebra Appl. 592, 188–209 (2020) 5. Bikker, P., Uteshev, A.Y.: On the Bezout construction of the resultant. J. Symb. Comput. 28(1), 45–88 (1999) 6. Demmel, J.W.: Computing stable eigendecompositions of matrices. Linear Algebra Appl. 79, 163–193 (1986) 7. Demmel, J.W.: On condition numbers and the distance to the nearest ill-posed problem. Numer. Math. 51, 251–289 (1987) 8. Eckart, C., Young, G.: The approximation of one matrix by another of lower rank. Psychometrika 1, 211–218 (1936) 9. Higham, N.G.: Matrix nearness problems and applications. In: Applications of matrix theory, pp. 1–27. Oxford Univ. Press, New York (1989) 10. Horn, R.A., Johnson, Ch.: Matrix Analysis, 2nd edn. Cambridge University Press, New York (2013) 11. Kalinina, E.A., Smol’kin, Y.A., Uteshev, A.Y.: Stability and distance to instability for polynomial matrix families. Complex perturbations. Linear Multilinear Algebra 70, 1291–1314 (2022) 12. Kalinina, E., Uteshev, A.: Distance evaluation to the set of matrices with multiple eigenvalues. In: Boulier, F., England, M., Sadykov, T.M., Vorozhtsov, E.V. (eds.) CASC 2022. Lecture Notes in Computer Science, vol. 13366, pp. 206–224. Springer, Cham (2022). https://doi.org/10.1007/978-3-031-14788-3 12  
   
  Distance to Defective Matrix  
   
  271  
   
  13. Lippert, R.A., Edelman, A.: The computation and sensitivity of double eigenvalues. In: Chen, Z., Li, Y., Micchelli, C.A., Xu, Y. (eds.) Proceedings of the Advances in Computational Mathematics, pp. 353–393. Gaungzhou International Symposium, Dekker, New York (1999) 14. Malyshev, A.: A formula for the 2-norm distance from a matrix to the set of matrices with multiple eigenvalues. Numer. Math. 83, 443–454 (1999) 15. Mengi, E.: Locating a nearest matrix with an eigenvalue of prespecified algebraic multiplicity. Numer. Math. 118, 109–135 (2011) 16. de Oliveira, O.: The implicit and inverse function theorems: easy proofs. Real Anal. Exchange 39(1), 207–218 (2013/2014) 17. Petkov, P.H., Konstantinov, M.M.: The numerical Jordan form. Linear Algebra Appl. 638, 1–45 (2022) 18. Ruhe, A.: Properties of a matrix with a very ill-conditioned eigenproblem. Numer. Math. 15, 57–60 (1970) 19. Wilkinson, J.H.: The Algebraic Eigenvalue Problem. Oxford University Press, New York (1965) 20. Wilkinson, J.H.: Note on matrices with a very ill-conditioned eigenproblem. Numer. Math. 19, 176–178 (1972) 21. Wilkinson, J.H.: On neighbouring matrices with quadratic elementary divisors. Numer. Math. 44, 1–21 (1984) 22. Wilkinson, J.H.: Sensitivity of eigenvalues. Util. Math. 25, 5–76 (1984)  
   
  Eﬀective Algorithm for Computing Noetherian Operators of Positive Dimensional Ideals Katsusuke Nabeshima1(B) and Shinichi Tajima2 1  
   
  Department of Applied Mathematics, Tokyo University of Science, 1-3, Kagurazaka, Tokyo, Japan [email protected]  2 Graduate School of Science and Technology, Niigata University, 8050, Ikarashi 2-no-cho, Nishi-ku, Niigata, Japan [email protected]   
   
  Abstract. An eﬀective algorithm for computing Noetherian operators of positive dimensional ideals is introduced. It is shown that an algorithm for computing Noetherian operators of zero dimensional ideals, that was previously published by the authors [https://doi.org/10.1007/ s00200-022-00570-7], can be generalized to that of positive dimensional ideals. The key ingredients of the generalization are the prime decomposition of a radical ideal and a maximal independent set. The results of comparison between the resulting algorithm with another existing one are also given. Keywords: Noetherian operator · Partial diﬀerential operator Primary ideal · Positive dimensional ideal  
   
  1  
   
  ·  
   
  Introduction  
   
  This is the continuation of the authors’ paper [16] that introduces an algorithm for computing Noetherian operators of zero dimensional ideals. In the 1930s, W. Gr¨ obner addressed the problem of characterizing ideal membership with diﬀerential conditions [11]. Later in the 1960s, L. Ehrenspreis and V. P. Palamodov obtained a complete description of primary ideals and modules in terms of diﬀerential operators [7,8,21]. At the core of the results, one has the notion of Noetherian operators to describe a primary module (and ideal). Recently several authors, including the authors of the present paper, have studied the Noetherian operators in the context of symbolic computation. In [3– 6], Y. Cid-Riz, J. Chen et al. give algorithms for computing Noetherian operators and the Macaulay2 implementation. They use the Hilbert schemes and Macaulay dual spaces for studying and computing them. In [16], the authors propose a different algorithm for computing Noetherian operators of zero dimensional ideals. The theory of holonomic D-modules and local cohomology play key roles in this c The Author(s), under exclusive license to Springer Nature Switzerland AG 2023  F. Boulier et al. (Eds.): CASC 2023, LNCS 14139, pp. 272–291, 2023. https://doi.org/10.1007/978-3-031-41724-5_15  
   
  Noetherian Operators of Positive Dimensional Ideals  
   
  273  
   
  approach. Notably, as the authors’ algorithm [16] is constructed by mainly linear algebra techniques, the algorithm is much faster than the algorithms presented by Y. Cid-Riz, J. Chen et al. in computational speed. In this paper, by adopting the framework proposed in [16], we consider a method for computing Noetherian diﬀerential operators of a positive dimensional primary ideal. We show that the use of the maximally independent set allows us to reduce the computation of Noetherian operators of positive dimensional primary ideals to that of zero dimensional cases. Accordingly, as the resulting algorithm of computing Noetherian operators of positive dimensional primary ideals consists mainly of linear algebra computation, it is also eﬀective. This paper is organized as follows. In Sect. 2, following [16], we recall results of Noetherian operators of zero dimensional primary ideals. In Sect. 3, we review some mathematical basics that are utilized in our main results. Section 4 consists of three subsections. In Sect. 4.1, we describe an algorithm for computing Noetherian operators of positive dimensional ideals. In Sect. 4.2 we give results of benchmark tests. In Sect. 4.3, we introduce a concept of Noetherian representations and we present an algorithm for computing Noetherian representations as an application of our approach.  
   
  2  
   
  Noetherian Operators of Zero Dimensional Ideals  
   
  Here we recall the algorithm for computing Noetherian operators of zero dimensional ideals that is published in [16]. Through this paper, we use the notation X as the abbreviation of n variables x1 , x2 , . . . , xn , K as a subﬁeld of the ﬁeld C of complex numbers and Q as the ﬁeld of rational numbers. The set of natural numbers N includes zero. For f1 , . . . , fr ∈ . . . , xn ], let f1 , . . . , fr  denote the ideal in K[X] generated by K[X] = K[x1 ,  the radical of the ideal f1 , . . . , fr . If an f1 , . . . , fr and f1 , . . . , fr  denote √ ideal I ⊂ K[X] is primary and I = p, then we say that I is p-primary. Let D = K[X][∂] denote the ring of partial diﬀerential operators with ∂ with relations coeﬃcients in K[X] where ∂ = {∂x1 , ∂x2 , . . . , ∂xn }, ∂xi = ∂x i xi xj = xj xi , ∂xi ∂xj = ∂ ∂ , ∂ x = x ∂ (i =  j), ∂ x xj xi xj i i xj xi i = xi ∂xi + 1 (1 ≤ i, j ≤ n), i.e. D = { β∈Nn cβ ∂ β |cβ ∈ K[X]} where ∂ β = ∂xβ11 ∂xβ22 · · · ∂xβnn n and β = (β1 , β2 , . . . , βn ) ∈ Nn . For β = (β1 , β2 , . . . , βn ) ∈ Nn , |β| := i=1 βi . The set of all terms of ∂ is denoted by Term(∂) and that of X is denoted by Term(X). Let us ﬁx a term order on Term(∂). For a given partial diﬀerential operator of the form  cβ ∂ β (cα , cβ ∈ K[X]), ψ = cα ∂ α + ∂ α ∂ β  
   
  we call ∂ α the head term, cα the head coeﬃcient and ∂ β the lower terms. We denote the head term by ht(ψ), the head by  coeﬃcient  hc(ψ) and the set of lower  ∂ λ = ht(ψ) . For a ﬁnite subset Ψ ⊂ D, terms of ψ as LL(ψ) = ∂ λ ∈ Term(ψ)  ht(Ψ ) = {ht(ψ) | ψ ∈ Ψ }, LL(Ψ ) = ψ∈Ψ LL(ψ).  
   
  274  
   
  K. Nabeshima and S. Tajima  
   
  For instance, let ψ = x31 x22 ∂x31 ∂x22 ∂x3 + x23 ∂x21 ∂x3 + x1 x3 ∂x2 ∂x3 + x21 x2 x3 be a partial diﬀerential operator in Q[x1 , x2 , x3 ][∂x1 , ∂x2 , ∂x3 ] and the graded lexicographic term order on Term({∂x1 , ∂x2 , ∂x3 }) with ∂x1 ∂x2 ∂x3 . Then, ht(ψ) = ∂x31 ∂x22 ∂x3 , hc(ψ) = x31 x22 and LL(ψ) = {∂x21 ∂x3 , ∂x2 ∂x3 , 1}. For each 1 ≤ i ≤ n, we write the standard unit vector as ith  
   
  ei = (0, . . . , 0, 1 , 0, . . . , 0). The deﬁnition of Noetherian operators is the following. Theorem 1 (Ehrenspreis-Palamodov [7,8,21]). Let q be a p-primary ideal in K[X] and proper. There exist partial diﬀerential operators ψ1 , ψ2 , . . . , ψ ∈ D with the following property. A polynomial g ∈ K[X] lies in the ideal q if and only if ψ1 (g), ψ2 (g), . . . , ψ (g) ∈ p. Definition 1. The partial diﬀerential operators ψ1 , ψ2 , . . . , ψ that satisfy Theorem 1 are called Noetherian operators of the primary ideal q. The core of the algorithm for computing Noetherian operators of zero dimensional ideals, that is introduced in [16], is the following theorem. Actually, this is the generalization of the result of L. H¨ ormander [14, Theorem 7.76 and pp. 235]. Theorem 2 ([16, Theorem 5]). Let I be a zero-dimensional ideal generated by f1 , . . . , fr in K[X] and q a primary component of a minimal primary decompo√ sition of I with q = p. Let Ns (I) be the set of all partial diﬀerential operators ϕ = β∈Nn ,|β|10 m  
   
  1.172  
   
  7  
   
  >10 m  
   
  2.922  
   
  8  
   
  >10 m  
   
  4.875  
   
  As is evident from Table 1, our new implementation is much faster in comparison with Macaulay2 implementation because Algorithm 1 mainly consists of linear algebra techniques. This is one of the big advantages of the new algorithm. 4.3  
   
  Computing Noetherian Representations  
   
  Here we introduce an algorithm for computing a Noetherian representation that can be regarded as an alternative primary ideal decomposition of a polynomial ideal. As we described in Sect. 3 and Sect. 4.1, Noetherian operators encode primary components of a polynomial ideal. Thus, they can be utilized to characterize an ideal. Definition 7. Let I be an ideal in K[X], I = q1 ∩ q2 ∩ · · · ∩ qt a primary decomposition of I where qi is a primary ideal for 1 ≤ i ≤ t. Let NBi ⊂ K(Ui )[Yi ][{∂y |y ∈ Yi }] be a basis of the vector space NTqi e where Ui is a MIS modulo qi and Yi = X\Ui . Then, √ √ √ {( q1 , NB1 , U1 ), ( q2 , NB2 , U2 ), . . . , ( qt , NBt , Ut )} is called a Noetherian representation of I and written as Noether(I). 1  
   
  A function noro pd.prime dec [15], that computes a prime decomposition of a radical ideal, is available in a program ﬁle noro pd.rr that is contained in the OpenXM package [20].  
   
  288  
   
  K. Nabeshima and S. Tajima  
   
  √ By combining an algorithm for computing a prime decomposition of I [1,15, 22], Lemma 3, 4, 5 and Algorithm 1, we can construct an algorithm for computing Noether(I) without computing a primary decomposition of I. The following algorithm is based on Gianni-Trager-Zacharias algorithm [10] of computing a primary ideal decomposition. Algorithm 2 (noetherian-rep) Specification: noetherian-rep(F ) Computing Noetherian representation of F . Input: F ⊂ K[X]. Output: NR = {(p1 , NB1 , U1 ), . . . , (pt , NBt , Ut )}: Noetherian representation of F . BEGIN F lag ← 1; NR ← ∅; while F lag = 1 do  k {p1 , . . . , pk } ← i=1 pi is the minimal prime decomposition of F ; (∗) pmax ← Select a maximal dimensional prime ideal pmax from {p1 , . . . , pk }; U ← Compute a MIS modulo pmax ; Y ← X\U ; b ← Set a block term order with U Y ; M ← {p ∈ {p1 , . . . , pk }| dim(p) = dim(pmax ), U is a MIS modulo p}; ← Set a term order on Term({∂y |y ∈ Y }); while M = ∅ do pm ← Select p form M ; M ← M \{pm }; NB ← Noether(F, pm , U, Y, ); NR ← NR ∪ {(pm , NB, U )}; end-while if Y = ∅ then G ← Compute a Gr¨ obner basis of F  w.r.t. b in K[U, Y ] = K[X]; h ← LCM{hc(g)|g ∈ G} where G is regarded as a subset of K[U ][Y ]; if h is a constant then F lag ← 0; else s ← Compute a natural number with H : h∞ = H : hs ; F ← {F ∪ {hs }}; end-if else F lag ← 0; end-if end-while return NR; END As we mentioned in Remark √ 2, in general, an algorithm for computing a prime decomposition of the radical I, at (∗), is much faster that that for computing primary decomposition of a polynomial ideal I in K[X].  
   
  Noetherian Operators of Positive Dimensional Ideals  
   
  289  
   
  Theorem 4. Algorithm 2 terminates and outputs correctly. Proof. By utilizing Lemma 5, we have F  = F ∪ {hs11 } ∩ (F  : hs11 ) where obner basis of F  w.r.t. a h1 = LCM{hc(g)|g ∈ G ⊂ K[U1 ][Y1 ]}, G is a Gr¨ block term order with U1 Y1 on Term(X) in K[X], U1 is a MIS modulo F , s1 Y1 = X\U1 and s1 is a natural number that satisfying F  : h∞ 1 = F  : h1 . s1 In the second while-loop, a Noetherian representation of F  : h1 is obtained because of Lemma 3 and 4. Renew F2 := F ∪{hs11 }. Again, by utilizing Lemma 6, we have F2  = F2 ∪ {hs22 } ∩ (F2  : hs22 ) where h2 = LCM{hc(g)|g ∈ G2 ⊂ obner basis of F2  w.r.t. a block term order with U2 Y2 K[U2 ][Y2 ]}, G2 is a Gr¨ on Term(X) in K[X], U2 is a MIS modulo F2 , Y2 = X\U2 and s2 is a natural s2 number satisﬁes F2  : h∞ 2 = F2  : h2 . In the second while-loop, a Noetherian s2 representation of F2  : h2 is obtained by the same reason above. We repeat the same procedure until hi becomes a constant (i ∈ N). Then, the union NR of all triples is a Noetherian representation of the input ideal F  because of F  = (∩ti=2 (Fi  : hsi i )) ∩ (F  : hs11 ). As K[X] is a Noetherian ring, the number t is ﬁnite. Thus, Algorithm 2 terminates and outputs correctly.   We illustrate the algorithm with the following example. Example 3. Let us consider √ the ideal I of Example 2, again. As we described in √ Example 2, we have I = x2 + 3y, z ∩ x, z as the prime decomposition of I. Since {y} is the MIS modulo x2 + 3y, z and x, z, thus M = {x2 + 3y, z, x, z}. We have NR = {(x2 + 3y, z, NB, {y}), (x, z, {1, ∂z }, {y})} in Example 2. The reduced Gr¨ obner basis G of I w.r.t. a block term order with {x, z} {y} is G = {z 3 , (3y + 1)x4 z + (18y 2 + 6y)x2 z + 27y 3 z + 9y 2 z, x6 + 6yx4 + 9y 2 x2 + z 2 } in Q[x, y, z]. Then, h = LCM{hc(g)|g ∈ G ⊂ Q[y][x, z]} = 3y + 1 in Q[y] and F  : h∞ = F  : h. We set F  = {3y + 1} ∪ {f1 , f2 , f3 }. In this case, F   is zero dimensional, namely, the MIS modulo F   is the empty set.   The prime decomposition of F  is  F   = x, 3y + 1, z ∩ x − 1, 3y + 1, z ∩ x + 1, 3y + 1, z. Thus, for each prime ideal, Algorithm 1 outputs the reduced basis of the vector space as follows: NZ = {(x, 3y + 1, z, {1, ∂x , ∂z , ∂x ∂z , ∂z2 − ∂z2 , ∂x3 − 3∂x ∂z2 }, ∅), (x − 1, 3y + 1, z, {1, ∂x , ∂z , ∂x ∂z , ∂x2 − 4∂z2 , ∂x3 − 12∂x ∂z2 − 36∂z2 }, ∅), (x + 1, 3y + 1, z, {1, ∂x , ∂z , ∂x ∂z , ∂x2 − 4∂z2 , ∂x3 − 12∂x ∂z2 + 36∂z2 }, ∅)}. Therefore, Noether(I) = NR ∪ NZ. We remark that bases of the primary ideals that are associated to (x2 +3y, z, NB ∅), (x − 1, 3y + 1, z, {1, ∂x , ∂z , ∂x ∂z , ∂x2 − 4∂z2 , ∂x3 − 12∂x ∂z2 − 36∂z2 } ∅) and (x+1, 3y+1, z, {1, ∂x , ∂z , ∂x ∂z , ∂x2 −4∂z2 , ∂x3 −12∂x ∂z2 +36∂z2 } ∅) are the following q1 , q2 , q3 . respectively.  
   
  290  
   
  K. Nabeshima and S. Tajima  
   
  q1 = {z 3 , x4 z + 6x2 yz + 9y 2 z, 9x4 y 2 + 54x2 y 3 − x2 z 2 + 81y 4 − 6yz 2 , x6 + 6x4 y + 9x2 y 2 + z 2 }, q2 = {3y+1, z 3 , 4x2 −3xz 2 −8x+4z 2 +4, x2 z−2xz+z, 12x3 −32x2 +28x+z 2 −8}, q3 = {3y+1, z 3 , 4x2 +3xz 2 +8x+4z 2 +4, x2 z+2xz+z, 12x3 +32x2 +28x−z 2 +8}. Since we can check q1  ⊂ q2  and q1  ⊂ q3 , thus q2 and q3 are redundant, namely, the following is also a Noetherian representation of F : Noether(I) = NR ∪ {(x, 3y + 1, z, {1, ∂x , ∂z , ∂x ∂z , ∂z2 − ∂z2 , ∂x3 − 3∂x ∂z2 }, ∅)}. The Noetherian representation above corresponds to the minimal primary decomposition of I. Since we adapt the Gianni-Trager-Zacharias algorithm [10] of computing a primary decomposition, there is a possibility that the output of Algorithm 2 contains redundant components, like the above. After obtaining the decomposition, it is possible to delete the redundant components by checking the inclusions. In Sect. 6 of [16], an algorithm for computing generators of a zero dimensional primary ideal q from a triple (p, NB, ∅) is introduced where q is p-primary and NB is a basis of the vector space NTq in K[X][∂]. Even if q is not zero dimensional, we can utilize the algorithm for computing generators of qe in K(U )[Y ] where U is a MIS of q and Y = X\U . As qec = q, generators of q can be obtained by the algorithm that is published in [16]. Actually, in Example 3, q1 , q2 , q3 were computed by the algorithm. Therefore, by combining Algorithm 3 and the algorithm for computing generators (and techniques of [15]), one can construct an algorithm for computing a minimal primary decomposition of a polynomial ideal I ⊂ K[X] and the Noetherian representation Noether(I), simultaneously. Acknowledgments. This work has been partly supported by JSPS Grant-in-Aid for Scientiﬁc Research(C) (Nos. 22K03334, 23K03076).  
   
  References 1. Aoyama, T., Noro, M.: Modular algorithms for computing minimal associated primes and radicals of polynomial ideals. In: Proceedings of the ISSAC 2018, pp. 31–38. ACM (2018) 2. Becker, T., Weispfenning, V.: Gr¨ obner Bases, A Computational Approach to Commutative Algebra (GTM 141). Springer, Heidelberg (1993). https://doi.org/10. 1007/978-1-4612-0913-3 3. Chen, J., H¨ ark¨ onen, M., Krone, R., Leykin, A.: Noetherian operators and primary decomposition. J. Symb. Comp. 110, 1–23 (2022) 4. Chen, J., Cid-Ruiz, Y., H¨ ark¨ onen, M., Krone, R., Leykin, A.: Noetherian operators in Macaulay2. J. Softw. Algebra Geom. 12, 33–41 (2022) 5. Cid-Ruiz, Y., Stumfels, B.: Primary decomposition with diﬀerential operators. Int. Math. Res. Not. rnac178 (2022) 6. Cid-Ruiz, Y., Homs, R., Stumfels, B.: Primary ideals and their diﬀerential equations. Found. Comput. Math. 21, 1363–1399 (2021)  
   
  Noetherian Operators of Positive Dimensional Ideals  
   
  291  
   
  7. Ehrenspreis, L.: A fundamental principle for system of linear diﬀerential equations with constant coeﬃcients and some of its applications. In: Proceedings of the International Symposium on Linear Spaces, pp. 161–174. Jerusalem Academic Press (1961) 8. Ehrenspreis, L.: Fourier Analysis in Several Complex Variables. Wiley Interscience Publishers, Hoboken (1970) 9. Grayson, D.R., Stillman, M.E.: Macaulay2: a software system for research in algebraic geometry (2002). https://www.math.uiuc.edu/Macaulay2 10. Gianni, P., Trager, B., Zacharias, G.: Gr¨ obner bases and primary decomposition of polynomial ideals. J. Symb. Comp. 6, 149–167 (1988) 11. Gr¨ obner, W.: Uber eine neue idealtheoretische Grundlegung der algebraischen Geometrie. Math. Ann. 115, 333–358 (1938) 12. Hoﬀmann, J., Levandovskyy, V.: Constructive arithmetics in Ore localizations of domains. J. Symb. Comp. 98, 23–46 (2020) 13. Hoﬀmann, J., Levandovskyy, V.: Constructive arithmetics in Ore localizations enjoying enough commutativity. J. Symb. Comp. 102, 209–230 (2021) 14. H¨ ormander, L.: An Introduction to Complex Analysis in Several Variables. The third revised edition. North-Holland (1990) 15. Kawazoe, T., Noro, M.: Algorithms for computing a primary ideal decomposition without producing intermediate redundant components. J. Symb. Comp. 46, 1158– 1172 (2011) 16. Nabeshima, K., Tajima, S.: Eﬀective Algorithm for computing Noetherian operators of zero-dimensional ideals. Appl. Algebra Eng. Commun. Comput. 33, 867–899 (2022) 17. Noro, M., Takeshima, T.: Risa/Asir - a computer algebra system. In: Proceedings of the ISSAC 1992, pp. 387–396. ACM (1992) 18. Ohara, K., Tajima, S.: An algorithm for computing Grothendieck local residues I, – shape basis case –. Math. Comput. Sci. 13, 205–216 (2019) 19. Ohara, K., Tajima, S.: An algorithm for computing Grothendieck local residues II – general case –. Math. Comput. Sci. 14, 483–496 (2020) 20. OpenXM committers: OpenXM, a project to integrate mathematical software systems. (1998–2022). https://www.openxm.org 21. Palamodov, V.P.: Linear Diﬀerential Operators with Constant Coeﬃcients. Die Gundlehren der mathematischen Wissenschaften, vol. 168. Springer, New York (1970). Translated from the Russian by A. Brown 22. Shimoyama, T., Yokoyama, K.: Localization and primary decomposition of polynomial ideals. J. Symb. Comp. 22, 247–277 (1996) 23. Tajima, S.: An algorithm for computing the Noetherian operator representations and its applications to constant coeﬃcients holonomic PDE’s. Tools for Mathematical Modellings, St. Petersbourg, pp. 154–160 (2001) 24. Tajima, S.: On Noether diﬀerential operators attached to a zero-dimensional primary ideal – shape basis case –. In: Proceedings of the 12th International Conference on Finite or Inﬁnite Dimensional Complex Analysis and Applications, pp. 357–366. Kyushu University Press (2005)  
   
  On the Structure and Generators of Diﬀerential Invariant Algebras Peter J. Olver(B) School of Mathematics, University of Minnesota, Minneapolis, MN 55455, USA [email protected]  http://www.math.umn.edu/~olver  
   
  Abstract. The structure of algebras of diﬀerential invariants, particularly their generators, is investigated using the symbolic invariant calculus provided by the method of equivariant moving frames. We develop a computational algorithm that will, in many cases, determine whether a given set of diﬀerential invariants is generating. As an example, we establish a new result that the Gaussian curvature generates all the diﬀerential invariants for Euclidean surfaces in three-dimensional space.  
   
  Keywords: Moving frame formula · Generating set  
   
  1  
   
  · Diﬀerential invariant · Recurrence  
   
  Introduction  
   
  The equivariant moving frame method, originally developed by Mark Fels and the author, [1,17]—see also Mansﬁeld, [10]—provides a powerful algorithmic method for computing and studying diﬀerential invariants and, more generally, invariant diﬀerential forms, [8], of general Lie group actions. This paper focusses on the algebraic structures that are induced by the moving frame calculus, with particular attention paid to generators and relations. In the standard approach, one works in a diﬀerential geometric setting, and so the underlying category is smooth or analytic diﬀerential functions, classiﬁed up to functional independence. However, here we will take a more algebraic tack, and work in the category of polynomial functions, or, occasionally, rational functions. See also [4,5] for further development of the algebraic approach to moving frames. Remark: In this paper, the word “symbolic” is used in three diﬀerent ways. The ﬁrst is in the general computer algebra term “symbolic manipulation”. Second is the “symbolic invariant calculus”, a term inspired by [10], which is established by the method of moving frames, and eﬀectively and completely determines the structure of the algebra of diﬀerential invariants and, more generally, invariant diﬀerential forms, purely symbolically, without any need for the explicit formulas for the moving frame, the diﬀerential invariants, the invariant diﬀerential forms, or the operators of invariant diﬀerentiation. Third is the “extended symbolic c The Author(s), under exclusive license to Springer Nature Switzerland AG 2023  F. Boulier et al. (Eds.): CASC 2023, LNCS 14139, pp. 292–311, 2023. https://doi.org/10.1007/978-3-031-41724-5_16  
   
  On the Structure and Generators of Diﬀerential Invariant Algebras  
   
  293  
   
  invariant calculus”, which is an adaptation of the second usage, that is developed in Sect. 7, and forms the basis of our computational algorithm. The starting point is a smooth or analytic action of a real1 r-dimensional Lie group G on a real m-dimensional manifold M . The action may be only local, and to avoid further complications with discrete symmetries, we will assume it to be connected, as in [11]. In the algebraic framework, we take M to be an open subset of R m , with ﬁxed coordinates z = (z 1 , . . . , z m ). We choose a basis for the inﬁnitesimal generators vκ =  
   
  m  i=1  
   
  ζκi (z)  
   
  ∂ , ∂z i  
   
  κ = 1, . . . , r,  
   
  (1)  
   
  which are vector ﬁelds on M that span a Lie algebra isomorphic to the abstract Lie algebra g of the Lie group G. For simplicity, we will assume that G acts locally eﬀectively on subsets, [13], which is equivalent to requiring that its basis inﬁnitesimal generators (1) be linearly independent vector ﬁelds when restricted to any open subset of M . To ensure that the symbolic invariant calculus is fully algebraic, we will further assume that the group action is inﬁnitesimally algebraic, meaning that either: • G acts locally transitively on M , or, equivalently its inﬁnitesimal generators v1 , . . . , vr span the tangent space to M at all points; or, • if intransitive, the coeﬃcient functions ζκi (z) of the inﬁnitesimal generators are polynomial functions of the coordinates on M . In the latter case, we will also assume, in order to simplify the exposition, that G acts “locally transitively on the independent variables”, in a sense deﬁned at the beginning of Sect. 4. The preceding blanket assumptions hold in almost all examples of interest arising in applications. Sections 3–5 review known facts and computational techniques from the method of moving frames. The new constructions and results appear in Sects. 6– 9, while Sect. 10 summarizes the resulting algorithm. Remark: The methods to be presented can be extended to inﬁnite-dimensional Lie pseudo-group actions. Although the constructions and underlying theory are signiﬁcantly more complicated in the latter context, the resulting structure theory is of a very similar ﬂavor; see [19–21] for details.  
   
  2  
   
  Multi-indices  
   
  Let p ≥ 1 be a ﬁxed integer. A p multi-index is an ordered n-tuple K = (k1 , . . . , kn ) with 1 ≤ kν ≤ p, where n = #K is the order of K. We consider the empty 0-tuple O = () to be the unique multi-index of order 0. Let M(n) denote 1  
   
  The constructions work in an identical fashion for complex Lie groups acting analytically on complex manifolds.  
   
  294  
   
  P. J. Olver  
   
  the set of all multi-indices of order 0 ≤ k ≤ n. Note that M(n) has  cardinality | M(n) | = 1 + p + · · · + pn = (pn+1 − 1)/(p − 1). We further let M = n≥0 M(n) denote the set of all p multi-indices. A symmetric p multi-index J of order n = #J ≥ 1 is an unordered n-tuple J = (j1 , . . . , jn ) with 1 ≤ jν ≤ p, where we identify any two n-tuples that are obtained by permuting their indices. Thus any symmetric multi-index can be rearranged to be nondecreasing, meaning ji ≤ ji+1 for 1 ≤ i < #J. The empty order 0 multi-index O is considered to be symmetric. We let S(n) denote theset of  all symmetric multi-indices of order 0 ≤ k ≤ n. Its cardinality is | S(n) | = n+p p .  Let S = n≥0 S(n) denote the set of all symmetric p multi-indices.  
   
  3  
   
  The Jet Calculus  
   
  Given the action of a Lie group on an m-dimensional manifold M , we are interested in the induced action on p-dimensional submanifolds N ⊂ M for some ﬁxed 1 ≤ p < m. We split the coordinates on M ⊂ R m into independent and dependent variables z = (x, u) = { x1 , . . . , xp , u1 , . . . , uq }, where p+q = m. We will restrict our attention to submanifolds that can be identiﬁed with graphs of smooth functions u = f (x). For details, including extensions to general p-dimensional submanifolds, see [11]. The corresponding jet space of order 0 ≤ n ≤ ∞, denoted by Jn = Jn (M, p), is deﬁned as the space of equivalence classes of p-dimensional submanifolds under the equivalence relation of n-th order contact. It has induced local coordinates (x, u(n) ) = (. . . xi . . . uα J . . .),  
   
  i = 1, . . . , p,  
   
  α = 1, . . . , q,  
   
  J ∈ S(n) ,  
   
  α where we identify uα J = uj1 ...jk , where k = #J, with the partial derivative ∂ k uα /∂xJ , so the equality of mixed partials is reﬂected in the fact that J is a symmetric multi-index. The dependent variables uα = uα O are identiﬁed as those jet coordinates with empty multi-index O = (), so that J0  M . By a diﬀerential function (respectively, diﬀerential polynomial ) we mean a smooth (respectively, polynomial) function F (x, u(n) ) of the jet coordinates. In the jet space calculus, the total derivative operators D1 , . . . , Dp are derivations that act on diﬀerential functions (polynomials) by diﬀerentiating with respect to the independent variables x1 , . . . , xp , treating the jet variables uα J as functions thereof; they are thus characterized by their action on the individual jet coordinates:  
   
  Di xj = δji ,  
   
  α Di uα J = uJ,i ,  
   
  i, j = 1, . . . , p,  
   
  α = 1, . . . , q,  
   
  J ∈ S,  
   
  where δji is the Kronecker delta, and, given J = (j1 , . . . , jk ) ∈ S, we deﬁne the symmetric multi-index (J, i) = (j1 , . . . , jk , i) ∈ S of order k + 1. Thus, we can write q   ∂ ∂ Di = + uα i = 1, . . . , p. (2) J,i α, ∂xi ∂u J α=1 J∈S  
   
  On the Structure and Generators of Diﬀerential Invariant Algebras  
   
  295  
   
  The total derivative operators mutually commute: [ Di , Dj ] = Di Dj − Dj Di = 0. Higher order total derivatives are obtained by composition DJ = Dj1 · · · Djk ,  
   
  J = (j1 , . . . , jk ) ∈ S,  
   
  (3)  
   
  where commutativity is reﬂected in the fact that J is taken to be a symmetric multi-index. In particular, DO = 11 is the identity operator. The induced action of the Lie group G on p-dimensional submanifolds induces an action on the jet spaces Jn , called the prolonged action. Its inﬁnitesimal generators have the form vκ =  
   
  p  i=1  
   
  ξκi (x, u)  
   
  q   ∂ ∂ (#J) + ϕα ) α, J,κ (x, u ∂xi α = 1 ∂uJ  
   
  κ = 1, . . . , r,  
   
  (4)  
   
  J∈S  
   
  where, by the well-known prolongation formula, [11],   p p   α α α i α ϕJ,κ = vκ (uJ ) = DJ ϕκ − ξκ ui + ξκi uα J,i . i=1  
   
  (5)  
   
  i=1  
   
  Note: In view of the formula (2) for the total derivatives, the coeﬃcients ϕα J,κ depend polynomially on the jet coordinates uβK of orders #K ≥ 1. Hence, under our assumption that the action of G is inﬁnitesimally algebraic, each prolonged inﬁnitesimal generator (4) is a derivation of the space of diﬀerential polynomials. A diﬀerential invariant is, by deﬁnition, an invariant diﬀerential function I(x, u(n) ). The inﬁnitesimal invariance condition requires vκ (I) = 0,  
   
  κ = 1, . . . , r,  
   
  which, by connectivity of the (prolonged) group action, is necessary and suﬃcient for invariance of the function I. One method for determining the invariants is to solve this system of homogeneous linear partial diﬀerential equations, [11]. However, the moving frame method is more direct and also has the advantage of being purely algebraic, and hence can be readily implemented in standard computer algebra systems.  
   
  4  
   
  Invariantization  
   
  In addition to assuming that G acts inﬁnitesimally algebraically on M , we will also, merely for the purpose of simplifying the notation and presentation, assume that it acts “locally transitively on the independent variables”, meaning that the projected inﬁnitesimal generators κ = v  
   
  p  i=1  
   
  ξκi (x, u)  
   
  ∂ , ∂xi  
   
  κ = 1, . . . , r,  
   
  (6)  
   
  296  
   
  P. J. Olver  
   
  span a subspace of dimension p at each point (x, u) ∈ M . If G itself acts locally transitively on M , this condition is automatically satisﬁed. By a general result, [12], local eﬀectiveness implies that the prolonged group action is locally free2 on a dense open subset of a jet space of suﬃciently high order, say s. By a local cross-section, we mean a submanifold K ⊂ Js of complementary dimension that intersects the prolonged group orbits transversally in at most one point. Such a cross-section is deﬁned by the equations Z σ (x, u(s) ) = cσ ,  
   
  σ = 1, . . . , r,  
   
  (7)  
   
  prescribed by r independent diﬀerential functions Z 1 , . . . , Z r of order ≤ s and r constants c1 , . . . , cr ∈ R. To remain in the algebraic category, we assume that the Z σ are polynomial functions of the jet coordinates. The simplest, and by far the most common, choice is when the Z σ ’s are individual jet coordinates, in which case (7) is said to deﬁne a coordinate cross-section. Our blanket assumption that G acts locally transitively on the independent variables implies that we can, and will, always select the ﬁrst p cross-section functions to be the independent variables: Z i = xi for i = 1, . . . , p. If G acts transitively on M , then we will select the next q = m − p of them to be the dependent variables: Z α+p = uα for α = 1, . . . , q. The construction of the moving frame map from the crosssection Eqs. (7) follows as in [1,17]; since we do not require these formulas in the symbolic calculus employed here, we will not dwell on the details. Speciﬁcation of the cross-section and consequent moving frame induces a process of invariantization, denoted by ι, that associates to each diﬀerential function F the unique diﬀerential invariant I = ι(F ) that agrees with F on the cross-section. In particular, if I is a diﬀerential invariant, then ι(I) = I. Thus, the invariantization process deﬁnes a projection from the algebra of diﬀerential functions to the algebra of diﬀerential invariants: ι(ι(F )) = ι(F ). Moreover, it clearly respects all algebraic operations, and hence deﬁnes an algebra morphism. On the other hand, the resulting diﬀerential invariants are not necessarily polynomial in the jet coordinates, being prescribed by the moving frame solution to the polynomial cross-section equations, (7). If the group acts algebraically (which is not guaranteed by our assumptions on its inﬁnitesimal generators), then the resulting diﬀerential invariants are algebraic functions of the jet coordinates, [4,5]. See [9] for a (non-constructive) version based on rational diﬀerential invariants. In the symbolic moving frame calculus, the explicit formulas for the diﬀerential invariants are not required, although they can, at least modulo algebraic complications, be explicitly constructed through an application of the invariantization process. In particular, the invariantization of each diﬀerential function used to deﬁne the cross-section (7) is the corresponding normalization constant: ι(Z σ ) = cσ ,  
   
  σ = 1, . . . , r.  
   
  (8)  
   
  These are commonly referred to as the phantom diﬀerential invariants. Thus, in view of our speciﬁed choice of cross-section as predicated on the assumption 2  
   
  A group action is locally free if the isotropy subgroup at each point is discrete.  
   
  On the Structure and Generators of Diﬀerential Invariant Algebras  
   
  297  
   
  that the group acts locally transitively on the independent variables, all the independent variables invariantize to constants: ι(xi ) = ci ,  
   
  i = 1, . . . , p,  
   
  (9)  
   
  being the ﬁrst p of the phantom diﬀerential invariants (8). The basic diﬀerential invariants are obtained by invariantization of the remaining jet coordinates: IJα = ι(uα J ),  
   
  α = 1, . . . , q,  
   
  J ∈ S.  
   
  (10)  
   
  If G acts transitively, then, again by our assumption on the form of the crosssection, all the I α = ι(uα ) are also constant phantom invariants. Since the invariantization process respects all algebraic operations, if F (x, u(n) ) = F ( . . . xi . . . uα J ... ) is any diﬀerential function, then i α ι(F ) = F ( . . . ι(xi ) . . . ι(uα J ) . . . ) = F ( . . . c . . . IJ . . . ).  
   
  (11)  
   
  In particular, if J(x, u(n) ) is any diﬀerential invariant, then i α J( . . . xi . . . uα J . . . ) = J( . . . c . . . IJ . . . ).  
   
  (12)  
   
  Equation (12) is known as the Replacement Rule, and allows one to immediately and uniquely “rewrite” any diﬀerential invariant in terms of the basic diﬀerential invariants (10), merely by replacing each jet coordinate by its corresponding basic diﬀerential invariant. Thus, the basic diﬀerential invariants form a complete system of diﬀerential invariants in the sense that any other diﬀerential invariant is a function thereof. Interestingly, even though the basic diﬀerential invariants need not be polynomial or even algebraic functions, every polynomial (algebraic) diﬀerential invariant can be written as a polynomial (algebraic) function thereof. On the other hand, the basic diﬀerential invariants are not functionally independent, but are subject to the r polynomial equations provided by the invariantized cross-section relations (8): ι(Z i ) = ι(xi ) = ci ,  
   
  i = 1, . . . , p,  
   
  Z σ ( . . . ci . . . IJα . . . ) = cσ ,  
   
  σ = p + 1, . . . , r,  
   
  (13)  
   
  which form a complete system of functional (polynomial) relations. In particular, if we are using a coordinate cross-section, then the non-phantom basic diﬀerential invariants provide a complete system of functionally independent diﬀerential invariants, in the sense that any other diﬀerential invariant can be locally uniquely written as a function (not necessarily polynomial) thereof. In the sequel, we let  

  (n) α = 1, . . . , q, J ∈ S I (n) = ι(u(n) ) = IJα = ι(uα ) (14)  
   
  J  
   
  298  
   
  P. J. Olver  
   
  denote the basic diﬀerential invariants obtained by invariantizing the dependent variable jet coordinates of order ≤ n, including all such constant phantom invariants. Observe that, since the moving frame has order s, the order of each IJα is ≤ max{s, #J}. The invariant diﬀerential operators are obtained by invariantizing the total derivative operators (2): Di = ι(Di ),  
   
  i = 1, . . . , p.  
   
  (15)  
   
  As before, in the symbolic moving frame calculus, there is no need for their explicit formulas, although these can (modulo computational complications) be found through an explicit implementation of the invariantization process, [1]. Invariance means that if I is any diﬀerential invariant, so is Di I. The invariant diﬀerential operators produced by the moving frame construction do not, in general, commute; see Eq. (22) below for details. Higher order invariant diﬀerential operators are obtained by iteration: DK = Dk1 Dk2 · · · Dkl ,  
   
  K = (k1 , . . . , kl ) ∈ M,  
   
  (16)  
   
  where the non-commutativity of the Di ’s is reﬂected in the fact that K is an ordered multi-index. As before, DO = 11 is the identity map. The diﬀerential invariant algebra will mean the algebra generated by the basic diﬀerential invariants, which could be polynomial, rational, or smooth functions thereof, depending on the context, along with the invariant diﬀerential operators. In the algorithm described below, we will restrict attention to the polynomial category. The fundamental Lie–Tresse Theorem, [1,9,12,21], states that the diﬀerential invariant algebra is generated by a ﬁnite number of generating diﬀerential invariants through the operations of invariant diﬀerentiation. Theorem 1. Given a Lie group action on submanifolds of dimension p as above, there exist a ﬁnite number of generating diﬀerential invariants I 1 , . . . , I l such that every diﬀerential invariant can be locally expressed as a function of them and their invariant derivatives, namely DK I σ for K ∈ M and σ = 1, . . . , l. The Lie–Tresse Theorem can be viewed, in a certain sense, as the analogue of the Hilbert Basis Theorem for diﬀerential invariant algebras. The moving frame recurrence formulas can be used to prove Theorem 1 constructively, in that they identify a set of generating diﬀerential invariants; see below. A signiﬁcant problem, and the main focus of the latter part of this paper, is to ﬁnd minimal generating sets of diﬀerential invariants since those identiﬁed via the moving frame calculus are typically far from minimal, and contain many redundancies. There is also an analogue of the Hilbert Syzygy Theorem for diﬀerential invariant algebras; see [21] for details.  
   
  5  
   
  The Recurrence Formulae  
   
  Besides the systematic and algorithmic methods underlying its construction, the most important new contribution of the equivariant moving frame method,  
   
  On the Structure and Generators of Diﬀerential Invariant Algebras  
   
  299  
   
  [1,17], is the general recurrence formula, which we now state for diﬀerential functions. See [8] for the extension to invariant diﬀerential forms. While, as we noted above, the invariantization process respects all algebraic operations, it does not respect diﬀerentiation. The recurrence formula tells us how the operations of invariantization and diﬀerentiation are related. Theorem 2. Given 1 ≤ i ≤ p, let Di = ι(Di ) be the invariant diﬀerential operator (15) produced by the moving frame invariantization process. Let v1 , . . . , vr be the prolonged inﬁnitesimal generators (4) of the group action. Let F be a diﬀerential function and ι(F ) its moving frame invariantization. Then r  

    
   
  Riκ ι vκ (F ) , Di ι(F ) = ι Di (F ) +  
   
  i = 1, . . . , p,  
   
  (17)  
   
  κ=1  
   
  for certain diﬀerential invariants R = { Riκ | κ = 1, . . . , r, i = 1, . . . , p } .  
   
  (18)  
   
  In particular, setting F = uα J in (17) leads to the recurrence formulae for the basic diﬀerential invariants: Di IJα  
   
  =  
   
  α IJ,i  
   
  +  
   
  r   
   
  Riκ ι(ϕα J,κ ),  
   
  (19)  
   
  κ=1  
   
  where ϕα J,κ are the prolonged inﬁnitesimal generator coeﬃcients (5). The diﬀerential invariants Riκ are known as the Maurer–Cartan invariants since they appear as the coeﬃcients of the pull-backs of the Maurer–Cartan forms on the Lie group G under the equivariant moving frame map, [1]. Fortunately, we do not need to know or understand this fact since the Maurer–Cartan invariants can be eﬀectively computed by solving the phantom recurrence formulae. Namely, setting F = Z σ to be the cross-section diﬀerential functions in (17), and noting that ι(Z σ ) = cσ is constant, we deduce r  
   
    
   
  Riκ ι vκ (Z σ ) , 0 = ι Di (Z σ ) +  
   
  i = 1, . . . , p.  
   
  (20)  
   
  κ=1  
   
  For each ﬁxed i = 1, . . . , p, the corresponding phantom recurrence formulae (20) are a system of r linear algebraic equations for the r Maurer–Cartan invariants Riκ , κ = 1, . . . , r. The condition that (7) deﬁne a valid cross-section implies that these p linear systems all have a unique solution. Thus, under our assumptions on the group action, the coeﬃcients of the phantom recurrence formulae (20) are polynomial functions of the basic diﬀerential invariants, which implies that the Maurer–Cartan invariants R are rational functions of the basic diﬀerential invariants I (s) . As noted above, the invariant diﬀerential operators produced by the moving frame construction do not, in general, commute. Their commutators can be written in the following form:  
   
  300  
   
  P. J. Olver  
   
  [ D j , D k ] = D j D k − Dk D j =  
   
  p   
   
  i Yjk Di ,  
   
  j, k = 1, . . . , p,  
   
  (21)  
   
  i, j, k = 1, . . . , p,  
   
  (22)  
   
  i=1  
   
  where the coeﬃcients i i Yjk = − Ykj =  
   
  r   
   
  Rkκ ι(Dj ξκi ) − Rjκ ι(Dk ξκi ) ,  
   
  κ=1  
   
  are certain diﬀerential invariants known as the commutator invariants. See [1,8] for details on the derivation of this formula.  
   
  6  
   
  The Symbolic Invariant Calculus  
   
  The upshot of the preceding developments is that, remarkably, we do not need to know the actual formulas for the moving frame, nor the diﬀerential invariants, nor the invariant diﬀerential operators, in order to determine the structure of the resulting diﬀerential invariant algebra! In other words, we can work entirely symbolically when analyzing the diﬀerential invariant algebra, whose structure is entirely determined by the recurrence formulae (19, 20) and the commutator formulae (21, 22). Let us now formalize this procedure. To this end, and under our blanket assumptions on the Lie group action and choice of moving frame cross-section, we introduce new “symbolic” variables v = ( . . . vJα . . . ),  
   
  α = 1, . . . , q,  
   
  J ∈ S,  
   
  which will serve to represent the basic diﬀerential invariants: vJα ←→ IJα . We will also set α = 1, . . . , q, J ∈ S(n) , v (n) = ( . . . vJα . . . ), for 0 ≤ n ≤ ∞, so that v = v (∞) . Let us deﬁne the symbolic invariantization process  ι , acting on diﬀerential functions F (x, u(n) ), by the following rule based on (11):  
   
  i α ι (xi ) . . .  ι (uα  ι F (x, u(n) ) = F ( . . .  J ) . . . ) = F ( . . . c . . . vJ . . . ) = F (v). (23) As such the symbolic variables will be subject to the polynomial cross-section relations σ = p + 1, . . . , r, (24) Z σ (v) = cσ , which are based on (7), keeping (9) in mind. The algebraic variety deﬁned by the polynomial Eqs. (24) will be called the cross-section variety. All symbolic calculations take place on this variety. As noted before, the simplest case is when we choose a coordinate cross-section, in which case the variables vJα that correspond to the jet coordinates uα J used to specify the cross-section are constant. Thus, in this case, the cross-section variety is simply an aﬃne subspace. As we saw above, the diﬀerential invariant algebra structure is completely encoded by the recurrence relations, speciﬁcally (19), which determine how the  
   
  On the Structure and Generators of Diﬀerential Invariant Algebras  
   
  301  
   
  invariant diﬀerential operators act on the basic diﬀerential invariants. Rather than use the invariant diﬀerential operators directly, it will help to replace them i be the derivation deﬁned by symbolic derivations. Namely, for i = 1, . . . , p, let D by its action on the symbolic variables: r   
   
  α i vJα = vJ,i D +  
   
  κi  R ι (ϕα J,κ ),  
   
  (25)  
   
  κ=1  
   
  κ where ϕα J,κ are the prolonged inﬁnitesimal generator coeﬃcients (5), while Ri = κ  ι (Ri ) are the symbolic Maurer–Cartan invariants, which can be obtained by replacing the basic diﬀerential invariants in the formulae for the Maurer–Cartan invariants Riκ by their symbolic counterparts, IJα −→ vJα , or, equivalently, by solving the linear system of equations r  
   
    
   
  κi  R ι vκ (Z σ ) , 0= ι Di Z σ +  
   
  σ = 1, . . . , r,  
   
  i = 1, . . . , p, (26)  
   
  κ=1  
   
  associated with the (symbolic) phantom invariants, cf. (20). Since, under our assumptions on the group action, the coeﬃcients of the linear system are polynomials in the symbolic variables v, the Maurer–Cartan invariants will be rational functions of v. As above, the calculations are performed on the cross-section variety (24). As before, the symbolic invariant derivations so constructed will not, in general, commute. Their commutators follow from (21, 22): k − D j = k ] = D j D k D j , D [D  
   
  p   
   
  i , Y ijk D  
   
  (27)  
   
  i=1  
   
  where i Y ijk =  ι (Yjk )=  
   
  r   
   
  i κ  κ ι (Dk ξ i ) . R k ι (Dj ξκ ) − Rj  κ  
   
  (28)  
   
  κ=1  
   
  are the symbolic commutator invariants. We recursively construct their higher order counterparts K = D k · · · D k , D 1 l  
   
  K ∈ M(n) ,  
   
  0 ≤ l = #K ≤ n,  
   
  (29)  
   
  keeping in mind that, owing to their non-commutativity, the multi-index K is O = 11 is the identity operator.) On the other unordered. (For completeness, D hand, by invoking the commutator relations (27), one can adapt a Poincaré– Birkhoﬀ–Witt type argument, [7], to restrict to only nondecreasing multi-indices, although this appears unnecessary, modulo possibly exploiting it in order to speed up the computational algorithm.  
   
  7  
   
  The Extended Symbolic Invariant Calculus  
   
  The fact that the symbolic Maurer–Cartan invariants are, in general, rational functions of the symbolic variables v takes us outside our polynomial “comfort  
   
  302  
   
  P. J. Olver  
   
  zone”. Moreover, the algorithm to be developed below will ask that we not explicitly compute them via solving the phantom recurrence formulas (26) in advance. Instead, to maintain polynomiality, we will introduce a further set of symbolic variables wiκ to represent each Maurer–Cartan invariant Riκ , and rewrite (19) in the form r  α i vJα = vJ,i D + wiκ  ι (ϕα (30) J,κ ). κ=1  
   
  These new symbolic variables will be subject to the linear algebraic constraints r  
   
    
   
  ι Di Z σ + wiκ  ι vκ (Z σ ) , 0 = Ciσ (v, w) ≡  κ=1  
   
  σ = 1, . . . , r, i = 1, . . . , p,  
   
  (31)  
   
  corresponding to (26), whose coeﬃcients depend polynomially on v. Solving this κ , as conlinear system will recover the symbolic Maurer–Cartan invariants R i structed in the preceding section, but here we will not do this, and instead work on the polynomial subvariety it deﬁnes. We will also need to symbolically diﬀerentiate the variables representing the Maurer–Cartan invariants, and hence include further symbolic variables κ . . . ), w = ( . . . wi;K  
   
  κ = 1, . . . , r,  
   
  i = 1, . . . , p,  
   
  K ∈ M,  
   
  (32)  
   
  where K is an ordered multi-index owing to the non-commutativity of the symbolic invariant derivations. We also set κ w(n) = ( . . . wi;K . . . ),  
   
  κ = 1, . . . , r,  
   
  i = 1, . . . , p,  
   
  K ∈ M(n) , (33)  
   
  for 0 ≤ n ≤ ∞, so that, for instance, w(0) = ( . . . wiκ . . . ) represents the undiﬀerentiated Maurer–Cartan invariants R, while w = w(∞) . We extend the symbolic invariant derivations (25) to the polynomial algebra generated by (v, w) by setting j w κ = w κ . D i;K i;j,K  
   
  (34)  
   
  Their commutators are as in (27) above, but now we express the symbolic commutator invariants in terms of the symbolic Maurer–Cartan variables: i Y ijk =  ι (Yjk )=  
   
  r   
   
  wkκ  ι (Dj ξκi ) − wjκ  ι (Dk ξκi ) .  
   
  (35)  
   
  κ=1  
   
  The symbolic diﬀerentiated Maurer–Cartan invariants (34) are subject to a system of linear constraints, with polynomially v dependent coeﬃcients, which are obtained by symbolically diﬀerentiating (31): σ K C σ (v, w) (v, w) ≡ D 0 = Ci;K i   
   
  r  
   
   σ  ι Di (Z ) + κ = 1 wiκ  ι vκ (Z σ ) , = DK   
   
  σ = 1, . . . , r, i = 1, . . . , p,  
   
  (36)  
   
  K ∈ M.  
   
  We will call the subvariety determined by (23, 31, 36) the extended cross-section variety. As above, one can appeal to the commutation formulae (27) to restrict to non-decreasing multi-indices K, but we will not use this option in what follows.  
   
  On the Structure and Generators of Diﬀerential Invariant Algebras  
   
  8  
   
  303  
   
  Independence  
   
  Let us review a basic result on functional dependence that will be used in the sequel. Given a smooth function f : R m → R k depending on x = (x1 , . . . , xm ) ∈ R m , we denote its k × m Jacobian matrix by   ∂f i . (37) ∇f = ∂xj Theorem 3. The components of f = (f 1 (x), . . . , f k (x)) are functionally independent if and only if their Jacobian matrix has rank ∇f = k. See [11] for details, including a precise deﬁnition of functional independence. For our purposes, the following corollary will be of crucial importance. Proposition 4. Let M be an m-dimensional manifold. Suppose that f : M → R k and g : M → R l are smooth functions. Assume that the rank of their Jacobian matrices ∇f and ∇g are constant. Then we can locally write f = h ◦ g where h : R l → R k is smooth if and only if   ∇f rank = rank ∇g. (38) ∇g More generally, suppose M = { x ∈ R n | c(x) = 0 } is a submanifold deﬁned by the vanishing of a function c : R n → R j . We assume that ∇c is also of constant rank in an open neighborhood of M . Suppose f : R n → R k and g : R n → R l . Then Lemma 4 becomes the statement that, locally, ⎛ ⎞   ∇f ∇g ⎝ ⎠ f | M = h ◦ g | M if and only if rank ∇g = rank on M. (39) ∇c ∇c In other words, given y i = f i (x1 , . . . , xn ) for i = 1, . . . , k, and z j = g j (x1 , . . . , xn ) for j = 1, . . . , l, and assuming the Jacobian matrices have constant rank, then, locally, we can write y i = hi (z 1 , . . . , z l ) for i = 1, . . . , k on the submanifold M deﬁned by c(x) = 0 if and only if condition (39) holds on M .  
   
  9  
   
  Generating Diﬀerential Invariants  
   
  We now turn to the problem of ﬁnding generating sets of diﬀerential invariants, in accordance with the Lie–Tresse Theorem 1. There are two a priori known generating sets of diﬀerential invariants. First: Theorem 5. If the moving frame has order s, then I (s+1) is a generating set.  
   
  304  
   
  P. J. Olver  
   
  The proof relies on the structure of the basic recurrence formulae (19), the key observation being that if k = #J ≥ s, then the only term on the right hand α —all the summation terms, including side of order k + 1 is the leading term IJ,i the Maurer–Cartan invariants, are of order ≤ k. See also [14] for further details. The next result is due to Hubert, [3], and is again based on an analysis of the recurrence relations. Theorem 6. The invariants I (0) ∪ R form a generating set. In particular, if G acts transitively, then the invariants I (0) = ι(u) are all phantom and hence constant and therefore in this case the Maurer–Cartan invariants R form a generating set. In both cases, the generating sets are, typically, far from minimal and there are many redundancies. Hence, the quest is to ﬁnd minimal generating sets. Unfortunately, apart from the case of curves, where p = 1, there is as yet no general construction of minimal generating sets or computational test that will ensure whether or not a given generating set is minimal—except in the obvious situation where one can ﬁnd a single generator. In low dimensional examples, e.g., surfaces in R 3 , this happens surprisingly often, cf. [6,15,16,22]. To this end, we will now describe an algorithm for determining if a given set of diﬀerential invariants J = (J 1 , . . . , J l ) forms a generating set. We will work in the extended symbolic invariant calculus, as presented in Sect. 7. The proposed generating diﬀerential invariants are represented symbolically by functions   (40) J(v) = J 1 (v), . . . , J l (v) depending on a ﬁnite number of the symbolic variables vJα . To remain in the polynomial category, we assume that these are polynomials. In most cases, they are, in fact, individual vJα ’s or perhaps simple combinations thereof. We could also allow them to depend on the symbolic Maurer–Cartan variables w; this will not change the ensuing argument. Let ν K J ν , (v, w) = D JK  
   
  ν = 1, . . . , l,  
   
  K ∈ M,  
   
  (41)  
   
  be the symbolic derivatives of the proposed generating invariants. We will call #K the level of the diﬀerentiated symbolic invariant (41). Now suppose that   (42) I(v, w) = I 1 (v, w), . . . , I k (v, w) is a known generating set, represented symbolically. A simple choice based on Theorem 5, and the one preferred here, is to set I = v (s+1) where s is the order of the moving frame. Alternatively, one could invoke Theorem 6 and take I = w(0) to be the (symbolic) Maurer–Cartan invariants. Typically, there are obvious redundancies among these generating invariants, including those prescribed by  
   
  On the Structure and Generators of Diﬀerential Invariant Algebras  
   
  305  
   
  the extended cross-section variety (31, 36), and one can use these to reduce their initial number in order to streamline the ensuing computations. Clearly the J’s ν ’s, as always when are generating if we can write each I σ as a function of the JK σ restricted to the extended cross-section variety. If any I already appears among the J ν ’s, this requirement is automatic and so these can also be set aside when implementing the ensuing algorithm. We now invoke Proposition 4, in the reformulation given at the very end of Sect. 8. The variables x represent the symbolic variables v, w. Of course, there are inﬁnitely many of the latter; however, each function depends on only ﬁnitely many of them, and so, in any ﬁnite calculation, one can ignore all symbolic variables of a suﬃciently higher order. The functions y = f (x) will represent the generating invariants in (42), so y = I(v, w), which can be reduced by discarding redundancies as discussed above, and we let I denote the remaining diﬀerential invariants. The functions z = g(x) will represent the proposed generating differential invariants (40) and their derivatives (41) up to a speciﬁed level n ≥ 0, so ν (v, w) . . . ), z = J (n) (v, w) = ( . . . JK  
   
  ν = 1, . . . , l,  
   
  K ∈ M(n) .  
   
  (43)  
   
  The polynomial constraints c(x) = 0 represent the extended cross-section variety (36) up to level n, so σ 0 = C (n) (v, w) = ( . . . Ci;K (v, w) . . . ),  
   
  σ = 1, . . . , r,  
   
  i = 1, . . . , p,  
   
  K ∈ M(n) .  
   
  (44)  
   
  Thus, according to (39), we need to compute the gradients (Jacobian matrices) of the right hand sides of (42, 43, 44) with respect to the v’s and w’s, whereby ∇ = (∇v , ∇w ), and we set J(n) =  
   
    
   
   ∇J (n) , ∇C (n)  
   
  ⎞ ∇I = ⎝ ∇J (n) ⎠. ∇C (n) ⎛  
   
  I(n)  
   
  (45)  
   
  As a direct corollary of (39), we have established our desired criterion. Theorem 7. The diﬀerential invariants {J 1 , . . . , J l } form a generating set if and only if (46) rank I(n) = rank J(n) for some level n ≥ 0. Indeed, if (46) holds, then Corollary 4 implies that, on the extended cross-section variety, we can express all the components of the known generating set I(v, w) ν K J ν , which implies that J in terms of the diﬀerentiated invariants JK (v, w) = D is also a generating set of diﬀerential invariants.  
   
  306  
   
  P. J. Olver  
   
  Remark: Ideally, the rank criterion (46) should be checked symbolically. In practice, this is beyond the current capabilities of Mathematica, and so instead it is checked by making several substitutions of random integers for the variables in the matrices. While not 100% foolproof, this method works well in all calculations performed to date. Here is the one example that has been computed so far. Although not so complicated, it’s starting to reach the limits of what Mathematica is capable of—although a more clever programming scheme might push it a bit further. It would also be good to reprogram this in a more powerful computer algebra system. Example 8. Consider the action of the Euclidean group SE(3) = SO(3)  R 3 , consisting of all rigid motions, on surfaces S ⊂ R 3 . For simplicity, we assume the surface is given by the graph of a function u = f (x, y). The corresponding local coordinates on the surface jet bundle are x, y, u, ux , uy , uxx , uxy , uyy , . . . , and, in general, ujk = Dxj Dyk u. The total derivative operators are Dx = ∂x + ux ∂u + uxx ∂ux + uxy ∂uy + uxxx ∂uxx + uxxy ∂uxy + uxyy ∂uyy + · · · , Dy = ∂y + uy ∂u + uxy ∂ux + uyy ∂uy + uxxy ∂uxx + uxyy ∂uxy + uyyy ∂uyy + · ·(47) · . The classical moving frame construction, [2,15], relies on the cross-section x = y = u = ux = uy = uxy = 0,  
   
  (48)  
   
  of order s = 2, which is a valid cross-section provided uxx = uyy . The resulting fundamental diﬀerential invariants are denoted as Ijk = ι(ujk ). In particular, κ1 = I20 = ι(uxx ),  
   
  κ2 = I02 = ι(uyy ),  
   
  are the principal curvatures; the moving frame is valid provided κ1 = κ2 , meaning that we are at a non-umbilic point. The mean and Gaussian curvature invariants K = κ1 κ2 , H = 12 (κ1 + κ2 ), are often used as convenient alternatives. Higher order diﬀerential invariants are obtained by invariant diﬀerentiation3 using D1 = ι(Dx ), D2 = ι(Dy ). We caution the reader that the action of SE(3) is only locally free on the second order jet space, and this implies some residual discrete ambiguities remaining in the resulting normalized diﬀerential invariants; for example, rotating the surface 90◦ around its normal interchanges the principal curvatures, while rotating it 180◦ through its tangent plane changes their signs. This ambiguity, however, does not aﬀect the ensuing calculations. Since we are working entirely symbolically, we do not require the explicit formulas for the moving frame, nor the principal curvature invariants, nor the invariant diﬀerential operators. A complete derivation of all the non-symbolic formulas for the equivariant moving frame, diﬀerential invariants, invariant diﬀerential operators, etc., can be found in [18]. 3  
   
  These are related to, but not the same as, the operators of covariant diﬀerentiation, since the latter do not take diﬀerential invariants to (scalar) diﬀerential invariants.  
   
  On the Structure and Generators of Diﬀerential Invariant Algebras  
   
  307  
   
  A basis for the prolonged inﬁnitesimal generators is provided by the following six vector ﬁelds4 : v5 = ∂y , v6 = ∂u , (49) v4 = ∂ x , representing inﬁnitesimal translations, and v1 = − y∂x + x∂y − uy ∂ux + ux ∂uy − 2 uxy ∂uxx + (uxx − uyy )∂uxy + 2 uxy ∂uyy + · · · , v2 = − u∂x + x∂u + (1 + u2x )∂ux + ux uy ∂uy + 3 ux uxx ∂uxx + (uy uxx + 2 ux uxy )∂uxy + (2 uy uxy + ux uyy )∂uyy + · · · ,  
   
  (50)  
   
  v3 = − u∂y + y∂u + ux uy ∂ux + (1 + u2y )∂uy + (uy uxx + 2 ux uxy )∂uxx + (2 uy uxy + ux uyy )∂uxy + 3 uy uyy ∂uyy + · · · , representing inﬁnitesimal rotations, where we just display the terms up to second order, although it is straightforward to prolong further, to any desired order, using (5). The phantom recurrence formulae5 are 0 = D1 I10 = I20 + R12 ,  
   
  0 = D2 I10 = R22 ,  
   
  0 = D1 I01 = R13 ,  
   
  0 = D2 I01 = I02 + R23 ,  
   
  0 = D1 I11 = I21 + (I20 −  
   
  I02 )R11 ,  
   
  0 = D2 I11 = I12 + (I20 −  
   
  (51) I02 )R21 ,  
   
  and can easily be solved for the (rotational) Maurer–Cartan invariants Riκ . However, since we are working in the extended symbolic calculus, these are not needed here. The generating diﬀerential invariants I (s+1) = I (3) guaranteed by Theorem 5 are I20 , I02 and the 4 third order invariants I30 , I21 , I12 , I03 . However, the order two basic recurrence formulae have the very simple form D1 I20 = I30 ,  
   
  D2 I20 = I21 ,  
   
  D1 I02 = I12 ,  
   
  D2 I02 = I03 ,  
   
  (52)  
   
  because the third order coeﬃcients of the prolonged inﬁnitesimal generators v1 , v2 , v3 all vanish on the chosen cross-section. Thus it is obvious that we can generate all of the third order diﬀerential invariants from I = { I20 , I02 }, meaning that the principal curvatures (or, equivalently, the Gauss and mean curvature) form a generating set. In [15], it was proved, by cleverly manipulating the higher order recurrence formulae and the commutator relations, that, in fact, a minimal generating set is provided by merely the mean curvature H alone. (We know that this is minimal 4 5  
   
  The system for numbering the vκ is for later convenience. For completeness, we should also include those of order 0, i.e. for K1 = ι(x) = 0, K2 = ι(y) = 0, I00 = ι(u) = 0; however, these are only used to determine the translational Maurer–Cartan invariants, namely, Riκ for κ = 4, 5, 6 and i = 1, 2, which do not appear anywhere else, and hence play no role in the ensuing calculations. This always happens when the transformation group includes translations.  
   
  308  
   
  P. J. Olver  
   
  because it consists of a single diﬀerential invariant.) Indeed, for suitably generic surfaces, there is a universal formula expressing the Gauss curvature as a rational function of H and its invariant derivatives. Let us instead apply the computational algorithm based on Theorem 7. By this means, we not only reconﬁrm the preceding result that the mean curvature generates, but also prove that either principal curvature—κ1 or κ2 – is also a minimal generating set, as is the Gauss curvature K. The latter result comes as a surprise, since it implies that the mean curvature, which is an extrinsic invariant that depends upon the embedding of the surface in Euclidean space, can be expressed in terms of the Gauss curvature, which is an intrinsic invariant as a consequence of Gauss’ Theorema Egregium, [2], and its invariant derivatives. Of course, the explanation is that the invariant diﬀerential operators do not preserve intrinsicness. Thus, it would be of interest to further develop a classiﬁcation scheme for distinguishing intrinsic and extrinsic higher order diﬀerential invariants. Note: Technically, we should work symbolically by replacing the I’s by v’s and the R’s by w’s. But, while this makes the symbolic algorithm easier to explain, in practice whether we call the symbolic variables v, w or I, R makes no diﬀerence. In detail, using my Mathematica code6 to compute the symbolic Jacobian matrices and then computing their ranks by substituting random integers (a few times just to make sure), we ﬁnd the following. For J = { 2 H = κ1 + κ2 = I20 + I02 } and I = { κ2 = I02 }: level  
   
  size J(k)  
   
  rank J(k)  
   
  size I(k)  
   
  rank I(k)  
   
  0 1 2  
   
  13 × 18 39 × 47 91 × 101  
   
  13 39 91  
   
  14 × 18 40 × 47 92 × 101  
   
  14 40 92  
   
  3 4  
   
  195 × 204 403 × 404  
   
  195 394  
   
  196 × 204 404 × 404  
   
  195 394  
   
  Since the ranks are equal at level 3 (and so the level 4 computation is unnecessary, but was performed as a check on the algorithm), by Theorem 7, we can write κ2 in terms of the third order invariant derivatives of H, which is thus generating, in accordance with the result found in [15]. Interestingly, the explicit formula that was found there by manipulation of the recurrence formula involves the fourth order derivatives of H, and hence there is an as yet unknown formula for K involving at most third order derivatives of H. (This is not a contradiction, owing to the many syzygies among the diﬀerentiated invariants.)  
   
  6  
   
  The software packages and details of the computations are available on the author’s website: https://www-users.cse.umn.edu/~olver/omath.html.  
   
  On the Structure and Generators of Diﬀerential Invariant Algebras  
   
  309  
   
  For J = { κ1 = I20 } and I = { κ2 = I02 }: level 0  
   
  size J(k) 13 × 18  
   
  rank J(k) 13  
   
  size I(k) 14 × 18  
   
  rank I(k) 14  
   
  1 2  
   
  39 × 47 91 × 101  
   
  39 91  
   
  40 × 47 92 × 101  
   
  40 92  
   
  3 4  
   
  195 × 204 403 × 404  
   
  194 393  
   
  196 × 204 404 × 404  
   
  194 393  
   
  It is interesting that the level 3 and 4 rows have a (slightly) diﬀerent rank than the previous case. As before, the ranks are equal at level 3, and thus, we can write κ2 in terms of the third order derivatives of κ1 , which is thus generating. Switching the principal curvatures implies that κ2 is also generating. This is a new result. Finally, when J = { K = κ1 κ2 = I20 I02 } and I = { κ2 = I02 }, the table is the same as in the ﬁrst case, which implies that we can write κ2 in terms of the third order derivatives of the Gauss curvature K, which is thus generating, and hence there is a previously unknown formula for H in terms of derivatives of K, valid for suitably generic surfaces. As noted above, this is a surprising new result, and it would be instructive to construct the explicit formula, which has yet to be done.  
   
  10  
   
  The Algorithm  
   
  We close by summarizing the above constructions in the form of an algorithm for determining whether a prescribed collection of diﬀerential invariants forms a generating set. 1. Input the inﬁnitesimal generators of the action of the Lie group. Their coefﬁcients form the entries of the associated Lie matrix. 2. Input the level n of the computation and the order k of the cross-section. 3. Compute the prolonged inﬁnitesimal generators up to order n + k + 1 using (5). 4. Input the cross-section, as in (7). Ensure that this is a valid cross-section by checking that the Lie matrix has rank r = dim G when restricted to the cross-section. If not, terminate the calculation. 5. Compute the recurrence formulas up to order n + k + 1 in the form (30), including the linear algebraic constraints (31) following from the crosssection speciﬁcation. 6. Compute the commutators in the symbolic form (35). 7. Compute the higher order constraints (36) up to level n. 8. Choose a known generating set of diﬀerential invariants represented symbolically as in (42). In the implementation used in the example, these are the ones given in Theorem 5, eliminating obvious redundancies to streamline the computation.  
   
  310  
   
  P. J. Olver  
   
  9. Input the proposed generating diﬀerential invariants represented symbolically as in (40), and compute their invariant derivatives (43) to level n. 10. Compute the Jacobian matrices (45). If the rank condition (46) is satisﬁed, then the chosen diﬀerential invariants form a generating set. If not, then either they are not generating, or one needs to choose a higher level n. In practice, since computing the ranks of the symbolic matrices (45) is too computationally intensive, one substitutes random integers for the variables they depend on, and compares the ranks of the corresponding integer matrices, repeating this computation several times to be sure. Of course, with poor choices of random integers, this ﬁnal numerical step may be misleading, but in the implementation this is not observed, and the ranks are almost always independent of the random choice. If unsuccessful, one can try a higher level. Unfortunately, I do not know a bound on the level required to be sure whether or not the selected diﬀerential invariants are generating; establishing this is a signiﬁcant and apparently diﬃcult open problem. Acknowledgments. I would like to thank Marc Härkönen and Anton Leykin for suggestions and for checking the computations. I also thank Francis Valiquette for several corrections. I further thank the referees for their careful reading of the original version and useful suggestions.  
   
  References 1. Fels, M., Olver, P.J.: Moving coframes: II. Regularization and theoretical foundations. Acta Appl. Math. 55, 127–208 (1999) 2. Guggenheimer, H.W.: Diﬀerential Geometry. McGraw-Hill, New York (1963) 3. Hubert, E.: Generation properties of Maurer-Cartan invariants, INRIA (2007) 4. Hubert, E., Kogan, I.A.: Rational invariants of a group action. Construction and rewriting. J. Symb. Comp. 42, 203–217 (2007) 5. Hubert, E., Kogan, I.A.: Smooth and algebraic invariants of a group action: local and global constructions. Found. Comput. Math. 7, 455–493 (2007) 6. Hubert, E., Olver, P.J.: Diﬀerential invariants of conformal and projective surfaces. SIGMA: Symmetry Integrability Geom. Methods Appl. 3, 097 (2007) 7. Knapp, A.W.: Lie Groups: Beyond an Introduction, 2nd edn. Birkhäuser, Boston (2002) 8. Kogan, I.A., Olver, P.J.: Invariant Euler-Lagrange equations and the invariant variational bicomplex. Acta Appl. Math. 76, 137–193 (2003) 9. Kruglikov, B., Lychagin, V.: Global Lie-Tresse theorem. Selecta Math. 22, 1357– 1411 (2016) 10. Mansﬁeld, E.L.: A Practical Guide to the Invariant Calculus. Cambridge University Press, Cambridge (2010) 11. Olver, P.J.: Applications of Lie Groups to Diﬀerential Equations. Graduate Texts in Mathematics, vol. 107, 2nd edn. Springer-Verlag, New York (1993) 12. Olver, P.J.: Equivalence, Invariants, and Symmetry. Cambridge University Press, Cambridge (1995)  
   
  On the Structure and Generators of Diﬀerential Invariant Algebras  
   
  311  
   
  13. Olver, P.J.: Moving frames and singularities of prolonged group actions. Selecta Math. 6, 41–77 (2000) 14. Olver, P.J.: Generating diﬀerential invariants. J. Math. Anal. Appl. 333, 450–471 (2007) 15. Olver, P.J.: Diﬀerential invariants of surfaces. Diﬀ. Geom. Appl. 27, 230–239 (2009) 16. Olver, P.J.: Moving frames and diﬀerential invariants in centro-aﬃne geometry. Lobachevskii J. Math. 31, 77–89 (2010) 17. Olver, P.J.: Modern developments in the theory and applications of moving frames. London Math. Soc. Impact150 Stories 1, 14–50 (2015) 18. Olver, P.J.: Equivariant moving frames for Euclidean surfaces (2016). https:// math.umn.edu/~olver/mf_/eus.pdf 19. Olver, P.J., Pohjanpelto, J.: Maurer-Cartan forms and the structure of Lie pseudogroups. Selecta Math. 11, 99–126 (2005) 20. Olver, P.J., Pohjanpelto, J.: Moving frames for Lie pseudo-groups. Canadian J. Math. 60, 1336–1386 (2008) 21. Olver, P.J., Pohjanpelto, J.: Diﬀerential invariant algebras of Lie pseudo-groups. Adv. Math. 222, 1746–1792 (2009) 22. Olver, P.J., Polat, G.G.: Joint diﬀerential invariants of binary and ternary forms. Portugaliae Math. 76, 169–204 (2019)  
   
  An Algorithm for the Intersection Problem of Planar Parametric Curves Ling Tan1,2 , Bo Li1,2 , Bingwei Zhang1,2 , and Jin-San Cheng1,2(B) 1  
   
  KLMM, Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing 100190, China [email protected]  2 University of Chinese Academy of Sciences, Beijing 100049, China  
   
  Abstract. This study presents a novel approach for handling the intersection of planar parametric curves. By leveraging the inherent properties of parametric curves, our technique simpliﬁes the process by reducing and comparing the ranges of x and y coordinates. The essential advantage of this technique lies in its simplicity, achieved through the reduction and comparison of the x and y coordinates ranges of the two curves. The monotonicity of curves is used during the reduction strategy. We utilize the opposite monotone system within a box to determine the uniqueness and existence of a simple intersection point. Moreover, we comprehensively analyzed singular cases like cusps, self-intersections, and tangents. Examples and comparisons with other methods showcase the algorithm’s robustness and eﬃciency, particularly for high-degree systems. Keywords: Reduction method Uniqueness and existence  
   
  1  
   
  · Opposite monotone system ·  
   
  Introduction  
   
  Finding intersections between planar parametric curves is a fundamental task in computer-aided geometric design and solid modeling, especially when considering B´ezier curves and NURBS (Non-Uniform Rational Basis Spline) curves. To address this intersection problem, we denote the equations of the two parametric curves as follows:   x1 (s) y1 (s) , r1 (s) = (X1 (s), Y1 (s)) = , w1 (s) w1 (s)   x2 (t) y2 (t) , , (1) r2 (t) = (X2 (s), Y2 (s)) = w2 (t) w2 (t) where x1 (s), y1 (s), w1 (s), x2 (t), y2 (t) and w2 (t) are univariate polynomials and (s, t) ∈ R2 . This work was partially supported by the National Key Research and Development Program of China grant 2022YFC3802102. c The Author(s), under exclusive license to Springer Nature Switzerland AG 2023  F. Boulier et al. (Eds.): CASC 2023, LNCS 14139, pp. 312–329, 2023. https://doi.org/10.1007/978-3-031-41724-5_17  
   
  An Algorithm for the Intersection Problem of Planar Parametric Curves  
   
  313  
   
  Three primary algorithms exist for computing intersections of plane curves deﬁned by rational parametrizations. These algorithms utilize elimination theory [24,33], B´ezier subdivision [3,21,23,27,31] and methods that solve bivariate polynomial systems [4,8–11,28,29]. The elimination theory relies on the ability to convert any rational parametric curve into an algebraic plane curve represented as F (x, y) = 0, with F (x, y) being a bivariate polynomial. This method involves converting one of the parametric curves into its implicit form and substituting the other curve’s representation into it. This reduction transforms the intersection problem into solving the real roots of a univariate polynomial [32– 35]. The algorithm exhibits relatively fast performance for low-degree curves (up to degree three or four). However, as the degrees of the curves increase, the algorithm’s eﬃciency diminishes. This is due to the use of resultants and the computational burden of expanding a symbolic determinant. Additionally, ﬁnding the roots of higher-degree polynomials lead to numerical instability [39]. The B´ezier’s subdivision technique leverages the convex hull property of B´ezier curves and utilizes de Casteljau’s algorithm. The intersection algorithm involves computing the convex hulls of the two curves. If the hulls do not overlap, there is no intersection. Otherwise, the curves are subdivided, and the resulting hulls are checked for intersection. In each iteration, the algorithm discards curve regions without intersection points. Subdivision divides a curve segment into two curve segments, with simple algorithms demonstrating linear convergence. By employing the B´ezier clipping method [36], convergence can be accelerated. B´ezier clipping determines parameter ranges that guarantee the absence of intersection points and eﬀectively exploits the convex hull property. Methods based on solving bivariate polynomial system set r1 (s) = r2 (t) to yield two polynomial equations  x1 (s)w2 (t) − x2 (t)w1 (s) = 0, (2) y1 (s)w2 (t) − y2 (t)w1 (s) = 0. with two unknown variables s and t. The subdivision method can yield boxes that may not contain any roots. Various methods are employed to determine the uniqueness and existence of a root within a given domain and obtain isolated intervals. Miranda’s theorem [16,25] is utilized to verify the existence of real zeros. The Jacobian test [1,16,22] is employed to determine if a system has at most one real zero. For testing the uniqueness of complex zeros, the interval Newton method [20,26,30] and α-theory [37] can be utilized. Additionally, there is noteworthy research exploring the topology of parametric curves [19]. The primary emphasis of this paper lies in the intersection analysis of two plane curves described by rational parametrizations. While it is possible to convert parametric curve/curve intersections into algebraic curve/curve intersections using (2), such a conversion results in the loss of the distinctive properties exhibited by parametric curves. Let f1 (s, t) = 0, f2 (s, t) = 0  
   
  (3)  
   
  be two algebraic curves, where f1 and f2 are polynomial in the variables s and t. Solving the polynomial system gives the intersection of two parametric curves  
   
  314  
   
  L. Tan et al.  
   
  [4,8–10,28,29]. We will use the system (3) to discuss the roots of the original intersection problem of singular conditional. This paper focuses on the analysis of geometric properties associated with parametric curves. By comparing the ranges of x-coordinates and y-coordinates between two parametric curves, we are able to narrow down the candidate boxes that potentially contain their intersections. A major advantage of this technique is its reliance only on solving univariate polynomials, which surpasses the complexity of solving systems of bivariate equations. Leveraging the monotonicity of the curves during the computation of coordinate ranges enables us to ascertain the presence and uniqueness of a simple intersection point within the designated box [10]. We utilize a specialized equation system for determination in situations involving singular cases. Our algorithm has been successfully implemented in Matlab, and our experimental results showcase its eﬀectiveness and eﬃciency, particularly for high-degree systems. The remainder of this paper is structured as follows: The reduction strategy is presented in Sect. 2. We introduce the uniqueness and existence theorem in Sect. 3. In Sect. 4, we delve into singular cases, where we employ a specialized system of equations for decision-making. The summary of the algorithm is provided in Sect. 5. Moving on to Sect. 6, we present several numerical examples to showcase the eﬃciency of our algorithm, along with a comparison to some related algorithms. Finally, we oﬀer our ﬁnal remarks.  
   
  2  
   
  Reduction Strategy  
   
  In this section, we will describe our algorithm to rigorously compute all intersection points of two parametric curves F (s, t) = (rr1 (s), r2 (t)) in R2 . To facilitate the analysis, we divide the real line into three intervals, namely R = (−∞, ai ] ∪ [ai , bi ] ∪ [bi , +∞), where ai < 0 < bi , i = 1, 2. By doing so, we can categorize all intersection points of F into nine regions (e.g., (s, t) ∈ (−∞, a1 ] × (−∞, a2 ], (−∞, a1 ] × [a2 , b2 ], (−∞, a1 ] × [b2 , +∞), · · · ) for further examination. Additionally, if s ∈ (−∞, a1 ], we can substitute s = 1s ∈ [ a11 , 0), and the task of ﬁnding all intersection points of F (s, t) in (s, t) ∈ (−∞, a1 ] × [a2 , b2 ] becomes equivalent to ﬁnding all intersection points of F (s , t) in (s , t) ∈ [ a11 , 0) × [a2 , b2 ]. This approach allows us to reduce the problem to locating intersection points within a bounded box. Note that the number of the intersections of two rational curves is ﬁnite. If we use the method for general parametric curves, there may exist inﬁnite intersections if we consider the whole space. But we can set a stopping tolerance. Let us go over the basic notations of parametric curves. Let f1 (s, t), f2 (s, t) be as deﬁned in (2). We assume that w1 (s) has no real root in I and w2 (t) has no root in J in the rest of the paper. We say F has intersections in B if the equations f1 (s, t) = 0, f2 (s, t) = 0 have solutions in B. Let x1 (I) = {x1 (p) | p ∈ I} and we say x1 (I) > 0 (< 0) if x1 (p) > 0 (< 0) for any p ∈ I. 2.1  
   
  Reduction Strategy  
   
  Let two plane curves deﬁned by rational parametrizations F = (rr1 (s), r2 (t)) and B = I × J ⊂ R2 . Using the geometric properties of parametric curves, we design  
   
  An Algorithm for the Intersection Problem of Planar Parametric Curves  
   
  315  
   
  a reduction strategy by comparing and decreasing the ranges of X1 (s) and X2 (t), Y1 (s) and Y2 (t). A smooth mapping f : I → R of a closed interval I = [a, b] can be thought of as a monotonic mapping on Ii where I is the disjoint union I = ∪Ii such that f is monotone on each Ii . It is a monotonic composition of I on f . It can be easily achieved by decomposing I at the points p such that f  (p) = 0, where f  is the derivative of f . It is clear that the range of f on a monotonic interval is decided by the values of its two endpoints. The reduction method has two main steps as follows. Calculate extreme values and solve univariate polynomials. (1) Compute the extreme points of X1 (s), s ∈ I and X2 (t), t ∈ J and decompose I, J into monotonic intervals related to X1 (s) and X2 (t) respectively. We have I = ∪ni=1 Ii and J = ∪m j=1 Jj . (2) Let M1 = max{X1 (s )|s is the endpoints of Ii , ∀i} and N1 = min{X1 (s )| s is the endpoints of Ii , ∀i}, we deﬁne M2 and N2 for X2 (t) over J in the same way. We usually have [N1 , M1 ] ∩ [N2 , M2 ] = ∅. Otherwise, the two curves have no intersection. Let M be the minimum of M1 and M2 and N be the maximum of N1 and N2 . A necessary condition that a point (s0 , t0 ) is the solution of equation X1 (s) = X2 (t) in B is X1 (s0 ) ∈ [N, M ] and X2 (t0 ) ∈ [N, M ]. Therefore, the solutions of inequality N ≤ X1 (s) ≤ M and N ≤ X2 (t) ≤ M can be seen as the boundary of reduced boxes. To ensure the identiﬁcation of the intersection between the two parametric curves, it is necessary to continue the reduction process for Y1 (s) and Y2 (t) as that have done for X1 (s) and X2 (t). Eventually, we obtain the reduced solution candidate boxes for the intersection of the parametric curves. Consequently, Algorithm 1, which compares the ranges of the x-coordinates (or y-coordinates), can be summarized as follows. The correctness and termination of the algorithm are evident based on the preceding analysis. Algorithm 1 C = Reduction (X1 (s), X2 (t), B): Input: Two rational polynomials X1 (s) and X2 (t), and a box B = [a, b] × [c, d] ⊂ R2 . Output: A box list C . 1: Decompose [a, b], [c, d] related to X1 (s) and X2 (t), compute Ni , Mi , N, M (i = 1, 2). 2: C = {}. 3: if [N1 , M1 ] ∩ [N2 , M2 ] = ∅ then 4: Solve (X1 (s) − N )(X1 (s) − M )(s − a)(s − b) = 0 and denote its roots in [a, b] as s1 , . . . , sm . Solve (X2 (t) − N )(X2 (t) − M )(t − c)(t − d) = 0 and denote its roots in [c, d] as t1 , . . . , tn . 5: for each pair (i, j)(1 ≤ i ≤ m − 1, 1 ≤ j ≤ n − 1), do 6: if X1 ([si , si+1 ]) ∩ X2 ([tj , tj+1 ]) = ∅ then 7: Append Bij = [si , si+1 ] × [tj , tj+1 ] to C . 8: end if 9: end for 10: end if 11: Output C .  
   
  316  
   
  L. Tan et al.  
   
  For each box, denoted as B, of the output of Algorithm 1, we compute Reduction(Y1 (s), Y2 (t), B), whose output is the candidate boxes of the intersection of the two parametric curves, as outlined in Algorithm 2. Algorithm 2 L = Candidatebox(rr1 (s), r2 (t), B): Input: Two parametric curves F = (rr1 (s), r2 (t)), a domain B = I × J and an error tolerance . Output: A candidate box list L . 1: Initialize B = {B} and L = {}. 2: repeat 3: Pop an element B  from B. 4: C1 = Reduction (X1 (s), X2 (t), B  ). 5: Let C3 = {}. 6: for each element B  in C1 do 7: C2 = Reduction (Y1 (s), Y2 (t), B  ). 8: Add all elements in C2 to C3 . 9: end for 10: repeat 11: Pop an element B0 from C3 . 12: if the size of one element B0 in C3 is less than  then 13: Append B0 to L . 14: else 15: Split B0 into B1 and B2 along the longer side of B0 and add them into B. 16: end if 17: until C3 = ∅ 18: until B = ∅ 19: Output L .  
   
  In Algorithm 2, as the iteration and the subdivision continue, the boxes shrink, and the procedure ultimately stops. The correctness and termination of the algorithm are obvious. 2.2  
   
  Preconditioner  
   
  In Algorithm 1, when M1 is close to M2 and N1 is close to N2 , the iteration and subdivision may be slow. We can do a coordinate transformation to change the situation. We present the following lemma to solve the problem. Lemma 1. Let F = (rr1 (s), r2 (t)) and B = I × J be a rectangle in the plane. For any nonzero constant ω, we have a new system F1 = (rr11 (s), r21 (t)) where r11 (s) = (X1 (s) + ωY1 (s), Y1 (s)) and r21 (t) = (X2 (t) + ωY2 (t), Y2 (t)). Then F and F1 have the same intersections in B. Proof. The system {X1 (s) = X2 (t), Y1 (s) = Y2 (t)} are equivalent to {X1 (s) + ωY1 (s) = X2 (t) + ωY2 (t), Y1 (s) = Y2 (t)}. So F and F1 have the same intersections in B.  
   
  An Algorithm for the Intersection Problem of Planar Parametric Curves  
   
  317  
   
  During each iteration, it is possible to select an appropriate constant ω to improve the performance of Algorithms 1 and 2. A comprehensive analysis of the constant ω will be provided in Sect. 3.2.  
   
  3  
   
  Uniqueness and Existence  
   
  This section focuses on determining the presence of a solution within a candidate box. Leveraging the monotonicity of the curves during the computation of coordinate ranges enables us to ascertain the existence and uniqueness of a simple intersection point within a given box [10]. 3.1  
   
  An Opposite Monotone System in a Box  
   
  In this subsection, we provide a criterion to ascertain the existence of at most one intersection within the candidate box B = [s1 , s2 ] × [t1 , t2 ] for F = (rr1 (s), r2 (t)). Our method leverages the geometric properties of planar curves. The following deﬁnitions introduce an opposite monotone system for parametric curves. Definition 1. Let r1 (s) = (X1 (s), Y1 (s)) be a plane curves deﬁned by rational parametrization and s ∈ I. We say r1 (s) is monotonically increasing in I if Sign(X1 (I) Y1 (I)) > 0. Similarly, we say r1 (s) is monotonically decreasing in I if Sign(X1 (I) Y1 (I)) < 0. Definition 2. Let F = (rr1 (s), r2 (t)) be two plane curves deﬁned by rational parametrization and s ∈ I, t ∈ J, B = I × J. We say F is an opposite monotone system in B if one of r1 (s) and r2 (t) is monotonically increasing in B, the other one is monotonically decreasing in B. Lemma 2. If F = (rr1 (s), r2 (t)) is an opposite monotone system in B, then the system F has at most one intersection in B. Proof. Suppose that an opposite monotone system F has at least two intersection points in B. Without losing the generality, we suppose that r1 (s) is monotonically increasing. Let (s1 , t1 ), (s2 , t2 ) be two intersection points such that r1 (s1 ) = r2 (t1 ) and r1 (s2 ) = r2 (t2 ), s1 < s2 , X1 (s1 ) < X1 (s2 ) and Y1 (s1 ) < Y1 (s2 ). Therefore, X2 (t1 ) < X2 (t2 ) and Y2 (t1 ) < Y2 (t2 ). We have now reached a contradiction with the fact that r2 (t) is monotonically decreasing. The lemma is proved.  
   
  3.2  
   
  How to Transform a System to an Opposite Monotone System in a Box  
   
  Sometimes F = (rr1 (s), r2 (t)) is not an opposite monotone system in a box even when it contains only one intersection. In order to make the system F to be an opposite monotone system in a box B, we need to choose a proper  
   
  318  
   
  L. Tan et al.  
   
  constant ω by Lemma 1 to transform the system F into an equivalent system F1 such that F1 is an opposite system inside B, as shown in the following theorem. Without losing the generality, we assume that Y1 (s) = 0 and Y2 (t) = 0 for any (s, t) ∈ B. Otherwise, we use r11 (s) = (X1 (s), ωX1 (s) + Y1 (s)) and r21 (t) = (X2 (t), ωX2 (t) + Y2 (t)). Theorem 1. Suppose that F = (rr1 (s), r2 (t)) is not an opposite monotone system in the box B = I × J, [a1 , b1 ] =  
   
      X  (s) X  (t) − 1 | s ∈ I , [a2 , b2 ] = − 2 |t ∈ J . Y1 (s) Y2 (t)  
   
  If [a1 , b1 ] ∩ [a2 , b2 ] = ∅, then we can get a proper constant ω such that the new system F1 = (rr11 (s), r21 (t)) where r11 (s) = (X1 (s) + ωY1 (s), Y1 (s)) and r21 (t) = (X2 (t) + ωY2 (t), Y2 (t)) is an opposite monotone system. More specifically: a2 − b1 , 2 a1 − b2 . (2) If b2 < a1 , then we choose ω = 2 a2 − b1 , let r1 (s) and r2 (t) be both monotonically increasProof. For ω = 2 ing in B = I × J and b1 < a2 . We have Sign(X1 (I) Y1 (I)) > 0 and Sign(X2 (J) Y2 (J)) > 0. If Y1 (I) > 0 and Y2 (J) > 0, then X1 (I) + ωY1 (I) > 0 and X2 (J) +  ωY2 (J) < 0. By Deﬁnition 2, the new system F1 = (rr11 (s), r21 (t)) where r11 (s) = (X1 (s) + ω Y1 (s), Y1 (s)) and r21 (t) = (X2 (t) + ωY2 (t)), Y2 (t)) is an opposite system (Fig .1). If Y1 (I) > 0 and Y2 (J) < 0, then X1 (I)+ωY1 (I) > 0 and X2 (J)+ωY2 (J) > 0. So the new system F1 = (rr11 (s), r21 (t)) is an opposite system; If Y1 (I) < 0 and Y2 (J) > 0, then X1 (I)+ωY1 (I) < 0 and X2 (J)+ωY2 (J) < 0. So the new system F1 = (rr11 (s), r21 (t)) is an opposite system; If Y1 (I) < 0 and Y2 (J) < 0, then X1 (I)+ωY1 (I) < 0 and X2 (J)+ωY2 (J) > 0. So the new system F1 = (rr11 (s), r21 (t)) is an opposite system. Suppose that r1 (s) and r2 (t) are both monotonically increasing in B and b2 < a2 . The same conclusion can be obtained. This is the same as r1 (s) and  
   
  r2 (t) which are both monotonically decreasing in B. (1) If b1 < a2 , then we choose ω =  
   
  However, when the two curves intersect at or near tangency, it is not possible to transform the curves r1 (s) and r2 (t) into an opposite monotone system. The analysis of this particular case will be presented in Sect. 4.3.  
   
  Fig. 1. Perform an aﬃne transformation.  
   
  An Algorithm for the Intersection Problem of Planar Parametric Curves  
   
  319  
   
  For a point p ∈ R2 and a positive number δ, we deﬁne a set of boxes as B(p, δ) = {B|B is a box and p ∈ B, w(B) < δ} where w(B) = max{the length of B,the width of B }. Then, we have the following lemma: Lemma 3. Let F = (rr1 (s), r2 (t)) and p∗ a simple zero of F . Then, there exists δ > 0 such that for any B ∈ B(p∗ , δ), there is a constant ω such that the new system F1 = (rr11 (s), r21 (t)) where r11 (s) = (X1 (s) + ωY1 (s), Y1 (s)) and r21 (t) = (X2 (t) + ωY2 (t)), Y2 (t)) is an opposite monotone system. Proof. Note that JF (p) is continuous function and JF (p∗ ) = 0. There exists δ > 0 such that JF (p) = 0 for any p ∈ B = I × J and B ∈ B(p∗ , δ). Thus, we have [a1 , b1 ] ∩ [a2 , b2 ] = ∅. By Theorem 1, there is a constant ω such that the  
   
  new system F1 = (rr11 (s), r21 (t)) is an opposite monotone system. Remark: If p∗ is a tangent intersection of two curves, then for any box B containing p∗ , we can not transform the system F into an opposite monotone system in B since 0 = det(JF (p∗ )) ∈ det(JF (B)). But for each simple root p∗ of F , we can always ﬁnd a small box B containing p∗ and a constant ω s.t. F1 is an opposite monotone system in B. 3.3  
   
  How to Check the Existence  
   
  We will demonstrate the method for verifying the existence of an intersection within a box for an opposite system. To achieve this, we employ the ﬁndings presented in [10,11]. Consequently, it becomes necessary to convert the parametric system into an implicit system. Initially, we introduce two deﬁnitions for the conversion of an opposite (parametric) system into an opposite (implicit) system. The subsequent deﬁnitions are adaptations derived from the relevant deﬁnitions in [10,11]. s ∈ I, t ∈ J, B = Definition 3. Let f1 = X1 (s) − X2 (t) and   I × J. We say f1 ∂f1 1 is monotonically increasing in B if Sign ∂f (B) (B) < 0. Similarly, f1 ∂t  ∂s  ∂f1 1 is monotonically decreasing in B if Sign ∂f ∂s (B) ∂t (B) > 0. Definition 4. Let G = (f1 , f2 ), where f1 = X1 (s) − X2 (t), f2 = Y1 (s) − Y2 (t) and B = I × J. We say G is an opposite monotone system in B if one of f1 and f2 is monotonically increasing in B, and the other one is monotonically decreasing in B. The subsequent lemma demonstrates that if a parametric opposite system forms an opposite system within B, then the corresponding implicit system also constitutes an opposite system within B. Lemma 4. If F = (rr1 (s), r2 (t)) forms an opposite monotone system within B = I × J, then G = (f1 , f2 ) also constitutes an opposite monotone system within B.  
   
  320  
   
  L. Tan et al.  
   
  ∂f1 ∂f2 ∂f2    1 Proof. We can see that ∂f ∂s = X1 (s), ∂t = −X2 (t), ∂s = Y1 (s) and ∂t =  −Y2 (t). The system F = (rr1 (s), r2 (t)) is an opposite monotone system in B. There are eight cases: Case (1) if X1 (I) > 0, Y1 (I) > 0 and X2 (J) < 0, Y2 (J) < 0, we have f1 is monotonically decreasing in B and f2 is monotonically increasing in B; Case (2) if X1 (I) > 0, Y1 (I) > 0 and X2 (J) > 0, Y2 (J) < 0, we have f1 is monotonically increasing in B and f2 is monotonically decreasing in B. Other cases are symmetrical.  
   
  Therefore, G = (f1 , f2 ) is an opposite monotone system in B. See Fig. 2.  
   
  Fig. 2. If F is an opposite monotone system, so is G .eps  
   
  A method exists to verify the existence of a root for an opposite monotone system G = (f1 , f2 ) within the interval B = [s1 , s2 ] × [t1 , t2 ]. Further details can be found in Sects. 3.3 and 3.4 of [10]. Here, we provide a concise overview. Let G = (f1 , f2 ) be an opposite monotone system in B and V (B) = { (s1 , t1 ), (s1 , t2 ), (s2 , t1 ), (s2 , t2 ) }. We assume that S1 ∩ ∂B = {k1 , k2 } and S2 ∩ ∂B = {k1 , k2 } where Si is the set deﬁned by fi = 0 in B for i = 1, 2 and ∂B = {(x, y)|x = s1 or x = s2 or y = t1 or y = t2 }. Lemma 5 ([10] Lemma 3.12). Let G = (f1 , f2 ) be an opposite monotone system in B, where f1 , f2 are rational functions. Assume that S1 ∩ ∂B = {k1 , k2 }, we have: (1) If f2 (k1 )f2 (k2 ) ≤ 0, G = 0 has a unique root in B. (2) If f2 (k1 )f2 (k2 ) > 0, G = 0 has no root in B. We can compute Sign(f2 (k1 )f2 (k2 )) to decide whether they have an intersection. Suppose that f intersects with the top and bottom of the box. If the equations X1 (s)−X2 (t1 ) = 0 and X1 (s)−X2 (t2 ) = 0 have solutions in [s1 , s2 ], then we denote them as α and β. Notice that there are at most one solution for the equations in [s1 , s2 ]. We can get k1 = (α, t1 ) and k2 = (β, t2 ). Note that the solutions may be on other sides and we can deal with them similarly. If we can exactly compute the points k1 , k2 , we can easily know that G has a unique root or no root in B by Lemma 5. However, it is unnecessary. Notice that one of f1 and f2 is monotonically increasing and the other is monotonical decreasing in B, we need only to determine the position of vertex of B. By computing the Sign(f1 , V (B)) and Sign(f2 , V (B)) where Sign(f, V (B))={Sign(f (p))|any p ∈ V (B)}, we immediately know which sides of I these points k1 , k2 , k1 and k2 lie on. We can arbitrarily  
   
  An Algorithm for the Intersection Problem of Planar Parametric Curves  
   
  321  
   
  take a point h on the side which k is on, we know that Sign(f (h)) = Sign(f (k)). By this method, we can easily know Sign(f2 (k1 ), f2 (k2 )). The bad case is that k2 , k2 are on the same side and we can not separate them. This case happens when k1 = k2 or ||k2 − k2 || is less than the given bisection precision. As we have done in [10], we may need to combine two boxes into one box and recheck the new box again.  
   
  4  
   
  Some Singular Cases  
   
  As mentioned previously, the aforementioned method is applicable only to regular intersections and may not work for certain singular cases. In this section, we will address these singular cases, which include cusp points, self-intersection points formed by a single parametric curve, and the tangent case formed by two parametric curves. Detailed deﬁnitions and relevant information regarding cusps can be found in [5,6,14]. We will also revisit the concepts of real cusps and real multiple points, where self-intersections are considered as multiple points. Lemma 6 ([19] Lemma 4.1). The set of parameters corresponding to real cusps is TC = {t ∈ R\TpC : (t, t) ∈ S}, the set of parameters corresponding to real multiple points is TM = {t ∈ R\TpC : ∃s = t, s ∈ R such that (s, t) ∈ S},  where TpC = {t ∈ C : i qi (t) = 0} and S = {(s, t) ∈ C2 : hi = 0 for all i}. The system of bivariate polynomial are   p1 (t) p2 (t) pi (s)qi (t) − qi (s)pi (t) for a curve φ(t) = , hi = and i = 1, 2. s−t q1 (t) q2 (t) Let F = (rr1 (s), r2 (t)), p = (s0 , t0 ) ∈ B a zero  of F , that is, r1 (s0 ) = r2 (t0 ). X1 (s) Y1 (s) If det(JF (p)) = 0 where JF = , we say p is either a cusp or a X2 (t) Y2 (t) tangent point of F . Using Lemma 6 to determine cusps and self-intersections, and using the Jacobian matrix to determine cusps and tangent points. There are certain singular conditional cases. In cases 1(a) and 1(b) of Fig. 3, the intersection of two curves is on or near a cusp point of one curve. In cases 2(a) and 2(b) of Fig. 3, they are self-intersection case or near self-intersection case. In cases 3(a) and 3(b) of Fig. 3, they are tangent case or near tangent case. There are some mixed situations for these cases. We will discuss and show how to determine them. If t0 ∈ V(I1 ), then there exits a s0 such that f1 (s0 , t0 ) = f2 (s0 , t0 ) = 0. We say that the partial solution t0 ∈ V(I1 ) can be extended to a solution (s0 , t0 ) ∈ V(I).  
   
  322  
   
  L. Tan et al.  
   
  Fig. 3. cusp case 1(a), nearly cusp case 1(b), self-intersection case 2(a) and nearly self-intersection case 2(b), tangential case 3(a) and nearly tangential case 3(b).  
   
  4.1  
   
  Cusp Cases  
   
  In the following discussion, we will assume that r1 (s) = (X1 (s), Y1 (s)) exhibits a (near) cusp point, as depicted in Fig. 1(a) and 1(b) of Fig. 3. A ccthe condition where both derivatives X1 (s) and Y1 (s) are zero, and there is a change in the sign of the directional derivative along the tangent direction. It should be noted that in certain situations, the requirement for the directional derivative to change sign may be omitted. We will now investigate the following system.  r1 (s) = r2 (t), (4) TC (rr1 ) = 0. If the system has a real root within the speciﬁed box, it indicates that the two curves intersect at a single point, as depicted in Fig. 1(a) of Fig. 3. However, if the system does not possess a real root in the box, we can employ the method outlined in Sect. 3 to certify the existence of roots, if any. It is worth noting that solving the system (4) is relatively straightforward, as it only requires solving univariate polynomials. 4.2  
   
  Self-intersection Cases  
   
  Let us consider the scenario where r1 (s) exhibits a (near) self-intersection point, as depicted in Fig. 2(a) or 2(b) of Fig. 3. In this scenario, we will obtain two boxes, namely B1 = [s1 , s2 ] × [t1 , t2 ] and B2 = [s1 , s2 ] × [t1 , t2 ], such that the point (rr1 (p1 ), r2 (q1 )) is close to (rr1 (p2 ), r2 (q2 )). Here, p1 , p2 , q1 , and q2 represent the midpoints of the intervals I1 , I2 , J1 , and J2 respectively, and we have the condition [t1 , t2 ] ∩ [t1 , t2 ] = ∅. It is assumed that s1 < s2 < s1 < s2 .  
   
  An Algorithm for the Intersection Problem of Planar Parametric Curves  
   
  Based on the above analysis, We determine whether the system ⎧ ⎪ ⎨ r1 (s) = r1 (h), r1 (s) = r2 (t), ⎪ ⎩ S1 < s − h < S 2 .  
   
  323  
   
  (5)  
   
  has a real solution, where S1 = s1 − s2 , S2 = s2 − s1 . Here we can use Newton’s method for over-determined systems to compute its solution [12]. Suppose that (5) have a real solution (s0 , t0 , h0 ). We know that (X1 (s0 ), Y1 (s0 )) = (X1 (h0 ), Y1 (h0 )) is a self-intersection point of r1 (s) and r1 (s0 ) = r1 (h0 ) = r2 (t0 ), which is exactly the self-intersection point of r1 (s) as shown in 1(a) of Fig. 3. Otherwise, the two curves have two diﬀerent intersection points in B1 and B2 as illustrated in 2(b) of Fig. 3. We also can solve the system  r1 (s) = r2 (t), (6) TM (rr1 ) = 0. One can also compute the real roots of (5) and (6) by symbolic methods such as the Gr¨ obner bases method [7], the Ritt-Wu characteristic set method [15] and so on. Example 1. In the region B = [0, 1]×[0, 1], let us consider the intersection points of two parametric curves  43 − 604s + 3104s2 − 5056s3 + 2560s4 r1 (s) := , 9 − 128s + 640s2 − 1024s3 + 512s4  151 − 2076s + 10268s2 − 16384s3 + 8194s4 , 63 − 896s + 4480s2 − 7168s3 + 3584s4   17500 + 43123t − 28115t2 348 + 35t , r2 (t) := . 5000 140 The two parametric curves have √ a special intersection point at√(X0 , Y0 ) = (5, 71/28) where (s1 , t1 ) = ((2 + 3)/4, 1/5) and (s2 , t2 ) = ((2 − 3)/4, 1/5). It is the self-intersection case of r1 (s), as illustrated in Fig. 4. We can apply Algorithm 2 and choose  = 10−10 to get four boxes: B1 = [0.0669872981077, 0.0669872981078] × [0.1999999999994, 0.2000000000013], B2 = [0.9330127018921, 0.9330127018923] × [0.1999999999987, 0.2000000000006], B3 = [0.1803473387387, 0.1803473387389] × [0.4906576541991, 0.4906576542049], B4 = [0.7976830053688, 0.7976830053688] × [0.0450535239848, 0.0450535239857].  
   
  For this example, the solutions show that B1 = I1 × J1 and B2 = I2 × J2 are close to the self-intersection of r1 (s) as shown in the middle points of Fig. 4. Since J1 ∩ J2 = ∅. We use MAPLE to solve the Eq. (5). Let S1 =0.8660254037 and S2 =0.8660254038. The solution is as follows [s = 0.9330127019, t = 0.2000000000, h = 0.06698729811]. This illustrates that B1 and B2 represent the same point.  
   
  324  
   
  L. Tan et al.  
   
  Fig. 4. Intersection in self-intersection case.  
   
  4.3  
   
  Tangential Cases  
   
  In this case, the method proposed in Sect. 3 fails to determine whether the box contains one intersection point even if the the size of the region is smaller than the given error tolerance. If the proper ω in Theorem 1 cannot be found, it implies that r1 (s) and r2 (t) may possess (near) tangent intersection points within the box B, as depicted in 3(a) or 3(b) of Fig. 3. If two curves are tangent, then the tangent direction is the same at the tangent point. Let us consider the following system.  r1 (s) = r2 (t), (7) X1 (s) : Y1 (s) = X2 (t) : Y2 (t). If the system (7) possesses a real root within the box, it indicates that the two curves have only one intersection point, as depicted in 3(a) of Fig. 3. In such cases, Newton’s method for over-determined systems [12] can be utilized to compute the solution. Alternatively, if the system does not yield a real root, we can certify the solutions using the method outlined in Sect. 3. There are other ways to deal with it. Outputting the result when the box is smaller than the speciﬁed error tolerance is one technique to deal with it. In other words there is no distinction between the two cases. But if we want to do this perfectly, we can utilize symbolic methods such as the Gr¨ obner basis method [7], the Ritt-Wu characteristic set method [15] and the method in [11]. 4.4  
   
  Mixed Cases  
   
  In fact, the singular cases may be mixed one, that is, several singular cases mix at one point. For example, a cusp point of r1 (s) meets a self-intersection point of r2 (t). And there may exist more complicated cases. For mixed cases, we can deal with them case by case, that is, we check them separately using the methods discussed above. We will not discuss them in more details.  
   
  5  
   
  Algorithm  
   
  This section summarizes our algorithm to rigorously compute all the intersection points of two parametric curves in a box.  
   
  An Algorithm for the Intersection Problem of Planar Parametric Curves  
   
  325  
   
  Consider two rational parametric curves r1 (s) and r2 (t), and let B = I ×J be a rectangular region in the plane. Our objective is to compute all the intersection points of r1 (s) and r2 (t) within B, while ensuring a speciﬁed tolerance level. The algorithm aims to provide a set of bounding boxes, each with a size smaller than a given error tolerance  > 0, containing exactly one intersection point. However, it is important to note that in cases where the coeﬃcients of the two curves are not exact, the solutions of singular cases may not be precise. The algorithm encompasses three main steps: Reduction: Initially, Algorithm 2 is employed to obtain candidate boxes within the speciﬁed error tolerance. This iterative and subdividing procedure progressively reduces the size of the boxes until termination. Existence and uniqueness checking: This step addresses the uniqueness and existence of the system within each box using an opposite monotone approach. If necessary, an aﬃne transformation is performed. The correctness of this step is ensured by Theorem 1, Lemma 3, and Lemma 5. Singular case handling: If the opposite monotone method fails to conclusively determine the existence of a solution within a box, and the box size is smaller than the speciﬁed error tolerance, methods speciﬁcally designed for singular cases are employed. These methods compute the boxes and output related solutions.  
   
  6  
   
  Experiments  
   
  The aforementioned algorithm has been implemented in MATLAB on a computer running Windows 11, equipped with a 12th Gen Intel i7-12700 CPU and 16 GB RAM. Currently, our implementation does not incorporate parallel computing; however, we plan to explore this aspect as part of our future work. Let F = (rr1 (s), r2 (t)) be two plane curves deﬁned by rational parametrization and deg(rr i ), coeﬀi denote the maximal degree, the maximal absolute value of coeﬃcients among xi (s), yi (s) and wi (s) for i = 1, 2. We ﬁnd the intersections of the two curves in B = [0, 1] × [0, 1]. The termination precision  = 10−6 . We test some examples which are generated as below. The system 1, 2, 3, 6, 7, 8 are randomly generated and the system 4 is two rational B´ezier curves with degree 10. The system 5 is two rational B´ezier curves where one of them is with degree 30 and another one is with degree 15. The results are in Table 1. We compare the calculation times of our approach with those of Birootisolation (BRI) [10] and IRIT [18]. They are based on solving general bivariate polynomial systems with numerical methods. BRI is an algorithm for isolating real roots of a bivariate polynomial system implemented in Maple. This algorithm employs the orthogonal monotone system to check the uniqueness and the existence of solutions. IRIT is a matlab interface to the multivariate polynomial solver. This solver is for real roots of sets of non-linear polynomial equations. We build various systems at random and the number of xi (s), yi (s) and wi (s) terms equal to deg(rri ) + 1 for i = 1, 2, and therefore the equations are dense. We determine the average time, and isolate all of the termination precision  = 10−6 . Table 2 shows the outcomes. All the methods can ﬁnd out the solutions.  
   
  326  
   
  L. Tan et al. Table 1. Comparison for systems with diﬀerent sizes. Example deg(rr 1 ) deg(rr 2 ) coeﬀ1  
   
  coeﬀ2  
   
  Times  
   
  system1  
   
  2  
   
  2  
   
  5  
   
  5  
   
  0.0030 s  
   
  system2  
   
  3  
   
  4  
   
  19  
   
  23  
   
  0.0013 s  
   
  system3  
   
  8  
   
  9  
   
  320  
   
  160  
   
  0.0014 s  
   
  system4  
   
  10  
   
  10  
   
  26026  
   
  336  
   
  0.0156 s  
   
  system5  
   
  30  
   
  15  
   
  2.2×1014 5.2×104 0.3006 s  
   
  system6  
   
  200  
   
  200  
   
  100  
   
  100  
   
  0.9285 s  
   
  system7  
   
  500  
   
  500  
   
  5000  
   
  5000  
   
  159.5788 s  
   
  system8  
   
  1000  
   
  1000  
   
  5000  
   
  5000  
   
  224.5351 s  
   
  In Table 2, “\” means it is unable to give solutions within 5 h. One can ﬁnd that our method faster than BRI and IRIT, and especially for the systems with high degrees. The main beneﬁt of our method is that it simply requires solving univariate polynomials. As metioned in their paper, the BRI method is good at system with sparse terms and high degrees for implicit equations. But our example are with dense terms, the BRI method is unable to handle degrees higher than 50 in a ﬁxed time since there are so many terms. IRIT is based on B´ezier clipping with some improvements [2,13,17,38] and it is diﬃcult to handle high degrees. The examples of Table 1 and Table 2 can be found on the website https://github.com/tanling2021/example-of-plane-curvesdeﬁned-by-rational-parametrization. Table 2. Comparison with other methods (i = 1, 2). deg(rr i ) coeﬀi BRI  
   
  IRIT  
   
  our method  
   
  2  
   
  5  
   
  0.9070 s 0.0005 s  
   
  0.0030 s  
   
  20  
   
  100  
   
  3.2500 s 0.0033 s  
   
  0.0095 s  
   
  50  
   
  100  
   
  \  
   
  0.2161 s  
   
  0.2448 s  
   
  100  
   
  500  
   
  \  
   
  8.3483 s  
   
  1.1517 s  
   
  200  
   
  500  
   
  \  
   
  61.2055 s 1.3490 s  
   
  300  
   
  500  
   
  \  
   
  \  
   
  500  
   
  5000  
   
  \  
   
  \  
   
  159.5788 s  
   
  1000  
   
  5000  
   
  \  
   
  \  
   
  224.5351 s  
   
  23.1671 s  
   
  We constructed the following example (see Fig. 5) to demonstrate the stability of our algorithm. This example includes complex cases where the intersection points involve nearly self-intersections and tangent points. We took 0.0278s to ﬁnd out all 18 intersections in the box [−2, 2] × [−2, 2].  
   
  An Algorithm for the Intersection Problem of Planar Parametric Curves  
   
  327  
   
  Fig.5. The intersection of the two curves (s8 − 8s6 + 20s4 − 16s2 , s7 − 7s5 + 14s3 −  7s) t6 + 704477 t4 − 174750 t2 + 302500 , t7 − 2677 t5 + 512469 t3 − 210681 t . and t8 − 2364805 298116 99372 8281 74529 400 40000 40000  
   
  7  
   
  Conclusion  
   
  In this paper, based on the work of [10], we propose a novel numerical approach for computing the intersections of two plane curves deﬁned by rational parametrization. The simple intersection of our method is certiﬁed. We also discuss how to deal with singular intersections. The experiments shows that our method is eﬃcient and stable.  
   
  References 1. Aberth, O.: Introduction to Precise Numerical Methods. Elsevier, Amsterdam (2007) 2. Bartoˇ n, M., Elber, G., Hanniel, I.: Topologically guaranteed univariate solutions of underconstrained polynomial systems via no-loop and single-component tests. In: Proceedings of the 14th ACM Symposium on Solid and Physical Modeling, pp. 207–212 (2010) 3. Bartoˇ n, M., J¨ uttler, B.: Computing roots of polynomials by quadratic clipping. Comput. Aided Geom. Des. 24(3), 125–141 (2007) 4. Berberich, E., Emeliyanenko, P., Sagraloﬀ, M.: An elimination method for solving bivariate polynomial systems: eliminating the usual drawbacks. In: 2011 proceedings of the Thirteenth Workshop on Algorithm Engineering and Experiments (ALENEX), pp. 35–47. SIAM (2011) 5. Brieskorn, E., Kn¨ orrer, H.: Plane Algebraic Curves: Translated by John Stillwell. Springer, Heidelberg (2012). https://doi.org/10.1007/978-3-0348-0493-6 6. Bruce, J.W., Bruce, J.W., Giblin, P.: Curves and Singularities: A Geometrical Introduction to Singularity Theory. Cambridge University Press, Cambridge (1992) 7. Buchberger, B.: Ein algorithmus zum auﬃnden der basiselemente des restklassenrings nach einem nulldimensionalen polynomideal. Universitat Innsbruck, Austria, Ph.D. thesis (1965) 8. Cheng, J.S., Gao, X.S., Guo, L.: Root isolation of zero-dimensional polynomial systems with linear univariate representation. J. Symb. Comput. 47(7), 843–858 (2012)  
   
  328  
   
  L. Tan et al.  
   
  9. Cheng, J.S., Gao, X.S., Li, J.: Root isolation for bivariate polynomial systems with local generic position method. In: Proceedings of the 2009 International Symposium on Symbolic and Algebraic Computation, pp. 103–110 (2009) 10. Cheng, J.S., Wen, J.: Certiﬁed numerical real root isolation for bivariate polynomial systems. In: Proceedings of the 2019 on International Symposium on Symbolic and Algebraic Computation, pp. 90–97 (2019) 11. Cheng, J.S., Wen, J., Zhang, B.: Certiﬁed numerical real root isolation for bivariate nonlinear systems. J. Symb. Comput. 114, 149–171 (2023) 12. Dedieu, J., Shub, M.: Newton’s method for overdetermined systems of equations. Math. Comput. 69(231), 1099–1115 (2000) 13. Elber, G., Kim, M.S.: Geometric constraint solver using multivariate rational spline functions. In: Proceedings of the Sixth ACM Symposium on Solid Modeling and Applications, pp. 1–10 (2001) 14. Fischer, G.: Plane Algebraic Curves, vol. 15. American Mathematical Society (2001) 15. Gallo, G., Mishra, B.: Eﬃcient algorithms and bounds for Wu-Ritt characteristic sets. In: Mora, T., Traverso, C. (eds.) Eﬀective Methods in Algebraic Geometry. Progress in Mathematics, vol. 94, pp. 119–142. Springer, Boston (1990). https:// doi.org/10.1007/978-1-4612-0441-1 8 16. Garloﬀ, J., Smith, A.P.: Solution of systems of polynomial equations by using Bernstein expansion. In: Alefeld, G., Rohn, J., Rump, S., Yamamoto, T. (eds.) Symbolic Algebraic Methods and Veriﬁcation Methods, pp. 87–97. Springer, Vienna (2001). https://doi.org/10.1007/978-3-7091-6280-4 9 17. Hanniel, I., Elber, G.: Subdivision termination criteria in subdivision multivariate solvers. In: Kim, M.-S., Shimada, K. (eds.) GMP 2006. LNCS, vol. 4077, pp. 115– 128. Springer, Heidelberg (2006). https://doi.org/10.1007/11802914 9 18. Jonathan, M., Ron, Z.: The IRIT multivariate solver-matlab interface (2014). http://www.cs.technion.ac.il/∼irit/matlab/ 19. Katsamaki, C., Rouillier, F., Tsigaridas, E., Zafeirakopoulos, Z.: On the geometry and the topology of parametric curves. In: Proceedings of the 45th International Symposium on Symbolic and Algebraic Computation, ISSAC 2020, pp. 281–288. Association for Computing Machinery, New York (2020) 20. Krawczyk, R.: Newton-algorithmen zur bestimmung von nullstellen mit fehlerschranken. Computing 4(3), 187–201 (1969) 21. Lane, J.M., Riesenfeld, R.F.: A theoretical development for the computer generation and display of piecewise polynomial surfaces. IEEE Trans. Pattern Anal. Mach. Intell. 1, 35–46 (1980) 22. Lien, J.-M., Sharma, V., Vegter, G., Yap, C.: Isotopic arrangement of simple curves: an exact numerical approach based on subdivision. In: Hong, H., Yap, C. (eds.) ICMS 2014. LNCS, vol. 8592, pp. 277–282. Springer, Heidelberg (2014). https:// doi.org/10.1007/978-3-662-44199-2 43 23. Ma, Y.L., Hewitt, W.T.: Point inversion and projection for NURBS curve and surface: control polygon approach. Comput. Aided Geom. Des. 20(2), 79–99 (2003) 24. Manocha, D., Demmel, J.: Algorithms for intersecting parametric and algebraic curves I: simple intersections. ACM Trans. Graph. (TOG) 13(1), 73–100 (1994) 25. Miranda, C.: Un’osservazione su un teorema di Brouwer. Consiglio Nazionale delle Ricerche (1940) 26. Moore, R.E.: A test for existence of solutions to nonlinear systems. SIAM J. Numer. Anal. 14(4), 611–615 (1977) 27. Mørken, K., Reimers, M., Schulz, C.: Computing intersections of planar spline curves using knot insertion. Comput. Aided Geom. Des. 26(3), 351–366 (2009)  
   
  An Algorithm for the Intersection Problem of Planar Parametric Curves  
   
  329  
   
  28. Rouillier, F.: Solving zero-dimensional systems through the rational univariate representation. Appl. Algebra Eng. Commun. Comput. 9(5), 433–461 (1999) 29. Rouillier, F., Zimmermann, P.: Eﬃcient isolation of polynomial’s real roots. J. Comput. Appl. Math. 162(1), 33–50 (2004) 30. Rump, S.M.: Solving algebraic problems with high accuracy. In: A New Approach to Scientiﬁc Computation, pp. 51–120. Elsevier (1983) 31. Schulz, C.: B´ezier clipping is quadratically convergent. Comput. Aided Geom. Des. 26(1), 61–74 (2009) 32. Sederberg, T.W.: Planar piecewise algebraic curves. Comput. Aided Geom. Des. 1(3), 241–255 (1984) 33. Sederberg, T.W., Anderson, D.C., Goldman, R.N.: Implicit representation of parametric curves and surfaces. Comput. Vision Graph. Image Process. 28(1), 72–84 (1984) 34. Sederberg, T.W., Chen, F.: Implicitization using moving curves and surfaces. In: Proceedings of the 22nd Annual Conference on Computer Graphics and Interactive Techniques, pp. 301–308 (1995) 35. Sederberg, T.W., Goldman, R.N.: Algebraic geometry for computer-aided geometric design. IEEE Comput. Graphics Appl. 6(6), 52–59 (1986) 36. Sederberg, T.W., White, S.C., Zundel, A.K.: Fat arcs: a bounding region with cubic convergence. Comput. Aided Geom. Des. 6(3), 205–218 (1989) 37. Smale, S.: Newton’s method estimates from data at one point. In: Ewing, R.E., Gross, K.I., Martin, C.F. (eds.) The Merging of Disciplines: New Directions in Pure, Applied, and Computational Mathematics, pp. 185–196. Springer, New York (1986). https://doi.org/10.1007/978-1-4612-4984-9 13 38. van Sosin, B., Elber, G.: Solving piecewise polynomial constraint systems with decomposition and a subdivision-based solver. Comput. Aided Des. 90, 37–47 (2017) 39. Wilkinson, J.H.: The evaluation of the zeros of ill-conditioned polynomials. Part I. Numer. Math. 1(1), 150–166 (1959)  
   
  A Symbolic-Numeric Method for Solving the Poisson Equation in Polar Coordinates Evgenii V. Vorozhtsov(B) Khristianovich Institute of Theoretical and Applied Mechanics of the Siberian Branch of the Russian Academy of Sciences, Novosibirsk 630090, Russia [email protected]   
   
  Abstract. A new version of the method of collocations and least squares (CLS) is proposed for the numerical solution of the Poisson equation in polar coordinates on uniform and non-uniform grids. To increase the accuracy of the numerical solution the degree of the local approximating polynomial has been increased by one in comparison with the earlier second-degree version of the CLS method for solving the Poisson equation. By introducing the general curvilinear coordinates the original Poisson equation has been reduced to the Beltrami equation. The method has been veriﬁed on three test problems having the exact analytic solutions. The examples of numerical computations show that if the singularity – the radial coordinate origin lies outside the computational region then the proposed method produces the solution errors which are two orders of magnitude less than in the case of the earlier CLS method. If the computational region contains the singularity then the solution errors are generally two and three orders of magnitude less than in the case of a second-degree approximating polynomial at the same number of grid nodes.  
   
  Keywords: Poisson equation collocations and least squares  
   
  1  
   
  · Polar coordinates · The method of  
   
  Introduction  
   
  Mathematical modeling of a number of physical processes is based on solving the Poisson equation. In particular, this equation describes the behavior of the electrostatic potential [11] and the stationary temperature ﬁeld in the presence of heat sources [20]. For numerical simulation of viscous incompressible ﬂuid ﬂows in a circular pipe or in an annular gap between two concentric pipes, the Navier– Stokes equations are often used in cylindrical coordinates θ, r, z, where θ is the azimuthal coordinate, r is the polar radius, and z is the coordinate measured The research was carried out within the state assignment of Ministry of Science and Higher Education of the Russian Federation. c The Author(s), under exclusive license to Springer Nature Switzerland AG 2023  F. Boulier et al. (Eds.): CASC 2023, LNCS 14139, pp. 330–349, 2023. https://doi.org/10.1007/978-3-031-41724-5_18  
   
  A Symbolic-Numeric Method for Solving the Poisson Equation  
   
  331  
   
  along the normal to the plane (θ, r). However, when numerically solving these equations, a diﬃculty arises due to the fact that in these equations, there are singularities in the form of factors 1r both in the continuity equation and in the momentum equations [13]. In addition, in all momentum equations, there is also a singularity having the form of the factor r12 . A singularity of the form 1r is present in all equations of the Prandtl–Reuss model of the ﬂow of elastic-plastic materials in cylindrical coordinates [12]. In [15], radiation plasma dynamics equations were solved in the variables r, t, where r is the radial coordinate and t is the time. The right-hand sides of these equations contain a singularity of the form 1r . The existing numerical methods for solving the Poisson equation in areas with circular boundaries (in the two-dimensional case) and in areas with cylindrical boundaries (in the three-dimensional case) can be divided into two groups. The ﬁrst group includes methods that allow solving the Poisson equations in disc-shaped or annular regions directly in Cartesian rectangular coordinates. In [4], a diﬀerence scheme was presented for solving the Poisson equation in irregular regions on an adaptive rectangular grid reﬁning near the region boundary. The reﬁnement criterion was based on estimating the proximity to an irregular boundary, so that the cells of the smallest size are located at the boundary. In order to store spatial discretization data, a data structure in the octree was used in [21], and the authors of [4] used data structures in the quadtree and octree form. In [4], the disadvantage of using data structures in the quadtree and octree form was indicated: some CPU time expenses are needed to traverse the tree from its root to the desired node of the graph. Paper [28] presents a collocation and least squares method for solving a twodimensional Poisson equation with discontinuous coeﬃcients on a square computational grid. In this method, the grid cells are divided into independent and non-independent cells. An independent cell is a cell that is crossed by a curved boundary, but the cell center remains inside the computational region. It is proposed to attach a non-independent cell to neighboring independent cells. Thus, unlike [4], the method [28] does not reﬁne the grid near the region boundary. The second group of the works devoted to the development of the numerical techniques for solving the Poisson equation in the discs or annuli is constituted by the works in which the Poisson equation in polar and cylindrical coordinates is solved in the two- and three-dimensional cases, respectively. The convenience of using the above curvilinear coordinates consists of the fact that the spatial computational region becomes a rectangle in the two-dimensional case and a parallelepiped in the three-dimensional case. The two-dimensional Poisson equation in polar coordinates was approximated in the work [34] by a ﬁnite diﬀerence scheme having a centered three-point stencil along each of the both polar coordinates. It was proved theoretically in [25] that the approximation order of this scheme along the polar radius r is h2 O( rr ), where r is the polar radius and hr is the size of a cell of the rectangular grid in the (θ, r) plane, where θ is the circumferential coordinate. Let us take a cell one of faces of which coincides with the line r = 0. If we now take in this  
   
  332  
   
  E. V. Vorozhtsov  
   
  cell a point with r = Chr , where 0 < C < 1, then it is clear that in such a cell, the approximation order of the diﬀerence scheme drops to the ﬁrst order. The eﬃcient spectral-diﬀerence methods were developed later for solving the Poisson equations in polar and cylindrical coordinates by using the discrete fast Fourier transform. In the two-dimensional case, one obtains for the coeﬃcients of the Fourier expansion a system of linear algebraic equations (SLAE), which is solved eﬃciently by the Thomas method, and in the three-dimensional case, the arising SLAE is solved by the matrix factorization technique. A second-order diﬀerence scheme was constructed in [17] for the Fourier coeﬃcients. A compact fourth-order diﬀerence scheme was proposed in [16] for the Fourier coeﬃcients in the case of solving the Poisson equation in polar coordinates. The results of numerical computations presented therein show that the approximation order of the proposed scheme drops to the third order when the computational region includes the line r = 0. One should note a shortcoming of spectraldiﬀerence methods for solving the Poisson equations in polar and cylindrical coordinates: the grid along the circumferential coordinate must be uniform. The highest eﬃciency of the discrete fast Fourier transform is reached only in the case when the number of nodes Nθ along the circumferential coordinate has the form Nθ = 2N + 1, where N is a positive integer, N > 1. As is known, at an adequate generation and use of non-uniform grids one can increase signiﬁcantly the numerical solution accuracy in comparison with the use of a uniform grid with the same number of nodes [1,14,35]. In this connection, a number of numerical techniques were developed for solving the Poisson equation in polar coordinates on non-uniform grid [2,23]. In the work [39], the incompressible Navier–Stokes equations were solved in polar coordinates in the streamfunction-vorticity (ψ − ω) formulation. The lefthand sides of the equations for ω and ψ coincide with the Laplace operator in polar coordinates. The elimination of ω gives rise to a fourth order partial differential equation (PDE) in streamfunction. This equation contains the singular factors of the forms r1k , k = 1, 2, 3, 4. To avoid these singularities the authors of [39] multiplied the both sides of the above PDE by r4 . The collocation methods for the numerical solution of boundary-value problems both for the ordinary diﬀerential equations (ODEs) and PDEs date back to the early 1970es [3,24]. The collocation method was used in [24] for the numerical solution of ODEs. Cavendish [3] dealt with the collocation methods for elliptic and parabolic boundary value problems. A shortcoming of pure collocation methods is as follows: the matrix AX = b of the system of linear algebraic equations, which is to be solved, is ill-conditioned [18,19]. A widespread technique for reducing the condition number of the matrix A is the use of the preconditioners and postconditioners; the overview of the relevant literature may be found in [19]. There are in the literature the theoretical results on convergence of the collocation methods both for the ODEs and PDEs. In particular, collocation with piecewise polynomial functions was developed in [24] as a method for solving two-point boundary value problems for ODEs and convergence was proved for a  
   
  A Symbolic-Numeric Method for Solving the Poisson Equation  
   
  333  
   
  general class of linear problems and a rather broad class of nonlinear problems. Faleichik [5] proved convergence of collocation methods for stiﬀ ODE systems with complex spectrum. As regards the convergence of pure collocation methods for elliptic PDEs, the convergence theorem was proved in [22] for the case when the PDE is solved on the unit square. In our case, the Poisson equation is solved in a rectangular region in which 0 ≤ θ ≤ 2π and 0 ≤ r ≤ rmax , where rmax > 0. It is easy to transform this region to the unit square with the aid of the passage to new variables θ¯ = θ/(2π) and r¯ = r/rmax . The collocation and least squares (CLS) method of numerical solution of boundary value problems for diﬀerential equations reduces the condition number of a system of linear algebraic equations that must be solved in the collocation method. This is achieved in the CLS method in the following way: the rows corresponding to the conditions for matching local solutions at the boundaries between neighboring cells are added to the matrix rows that correspond to collocation equations. This constitutes the diﬀerence of the CLS method from pure collocation methods. To the author’s knowledge, there are at present unfortunately no convergence theorems for the CLS method. It was shown in [36] that the inclusion of matching conditions in the matrix of the system leads to a decrease in the condition number by 3–5 orders of magnitude, depending on the number of grid cells, collocation points, and matching points. It is this signiﬁcant reduction in the condition number of the matrix that ensures the eﬃciency of the CLS method in solving boundary value problems for partial diﬀerential equations. In [30], a CLS method was proposed for the numerical solution of the Poisson equation in polar coordinates. The local solution in each grid cell was represented therein as a second-degree polynomial in θ, r. In the cases when the computational region is an annulus with min(r) = O(1) the method of [30] has the approximation order, which is very close to two. However, in the cases where the line r = 0 lies in the computational region the order of accuracy of the proposed CLS method drops from the second order to an order O(hpr ), where 0 < p < 1. The above overview of the methods developed for the numerical solution of the Poisson equation in polar or cylindrical coordinates shows that there is the problem of the convergence order reduction in these methods in cases where the line r = 0 is part of the computational region. We can formulate the following general question: is it possible to develop a numerical method, which would have the same order of accuracy independently of the fact whether the line r = 0 belongs or does not belong to the computational region? One of the ways to give a positive answer to this question may be located in the area of the CLS methods. As a matter of fact, it was shown in [9] that the accuracy of the CLS method increases with increasing degree of approximating polynomials when this method is applied for the numerical solution of the incompressible Navier–Stokes equations in Cartesian coordinates. Therefore, one may hope that an increase in the degree of the local approximating polynomial can help in the matter of achieving the uniform accuracy of the numerical solution of the Poisson equation in cases where the polar axis r = 0 is included in  
   
  334  
   
  E. V. Vorozhtsov  
   
  the spatial computational domain. In the present work, we use the third-degree polynomials as approximating polynomials in the context of the CLS method. A suﬃciently universal applicability of the CLS method for solving various initial- and boundary-value problems for partial diﬀerential equations of diﬀerent types was demonstrated previously in the works [9,10,27,29,31–33,36–38]. As the degree of the approximating local polynomial increases, the complexity of the expressions for collocation equations increases. In order to avoid errors in the derivation of these expressions “by hand” it is very advisable to carry out all the necessary analytical calculations in a computer algebra system (CAS). The CAS Mathematica has a very useful built-in function FortranForm, which allows the user to translate Mathematica expressions into the Fortran operators, which can then easily be included in Fortran programs. This speeds up considerably the process of the development of new Fortran programs. We used the CAS Mathematica in the above way to generate a Fortran program for calculating in each grid cell the expressions for the entries of the local matrix and the righthand sides of the algebraic system.  
   
  2  
   
  The CLS Method for the Numerical Solution of the Poisson Equation in Polar Coordinates  
   
  As a result of the passage from the Cartesian coordinates x, y to polar coordinates r, θ by formulas x = r cos θ, y = r sin θ the Poisson equation uxx + uyy = f (x, y) takes the form ∂ 2 u 1 ∂u 1 ∂2u + + = f (θ, r), (1) ∂r2 r ∂r r2 ∂θ2 where f (θ, r) = f (r cos θ, r sin θ). We will omit the bar over f in the following for the sake of brevity. Equation (1) is solved in the rectangular region Ω = {(θ, r), 0 ≤ θ < 2π, R1 ≤ r ≤ R2 }  
   
  (2)  
   
  under the Dirichlet boundary conditions u = g1 (θ), r = R1 ;  
   
  u = g2 (θ), r = R2 ;  
   
  0 ≤ θ < 2π.  
   
  (3)  
   
  In (2) and (3), R1 and R2 are the given quantities, 0 ≤ R1 < R2 . The periodicity condition is speciﬁed at the boundaries θ = 0 and θ = 2π u(0, r) = u(2π, r),  
   
  R1 ≤ r ≤ R 2 .  
   
  (4)  
   
  We formulate a “discrete” problem approximating the original diﬀerential boundary value problem. In the CLS method, a grid is constructed in the computational domain (2). It can be non-uniform along both coordinates θ and r. Let rj be the r coordinate of the jth grid node on the r axis, and let Nr be the number of nodes of a non-uniform grid in the interval [R1 , R2 ]. The set of grid nodes r1 , . . . , rNr must satisfy the relations R1 = r1 < r2 < · · · < rNr = R2 . Similarly, in the range [0, 2π), the set of grid nodes θ1 , . . . , θNθ is generated so  
   
  A Symbolic-Numeric Method for Solving the Poisson Equation  
   
  335  
   
  that the relations 0 = θ1 < θ2 < · · · < θNθ = 2π are fulﬁlled, where Nθ is the number of grid nodes in the interval [0, 2π). Denote by Ωi,j the subdomain of the area (2) occupied by the cell with the indices i, j that is Ωi,j = {(θ, r), θi ≤ θ ≤ θi+1 , rj ≤ r ≤ rj+1 }, i = 1, . . . , Nθ −1, j = 1, . . . , Nr −1. (5) One often encounters in ﬂuid dynamics problems the spatial subregions with large solution gradients. In the case of a uniform grid, such subregions may have a size of less than one grid step; in these cases, the numerical algorithm can simply “not identify” such narrow transitional regions, and this may lead to considerable errors and incorrect results of the numerical simulation. In such situations, the application of non-uniform grids clustering in the subregions of large solution gradients makes it possible to increase the accuracy of simulation. One of the simplest techniques of controlling the grid stretching in the case of the Poisson equation uxx + uyy = f (x, y) consists of the use of the mapping [35] x = f2 (η) cos f1 (ξ),  
   
  y = f2 (η) sin f1 (ξ),  
   
  (6)  
   
  where the monitoring functions f1 (ξ) and f2 (η) enter the relations θ = f1 (ξ), r = f2 (η) and are speciﬁed by the user with regard for the speciﬁcs of the problem to be solved. The computational region in the plane of curvilinear coordinates (ξ, η) still remains rectangular as in the case when f1 (ξ) = ξ and f2 (η) = η. Let us assume following [14,35] that the computational grid in the (ξ, η) plane is square with steps Δξ = Δη = 1. If f1 (ξ) = ξ or f2 (η) = η, then the computational grid in the original plane (θ, r) will be non-uniform. The Poisson equation takes the following form at the passage from the variables x, y to curvilinear coordinates ξ, η [14]: ΔB u(ξ, η) = f (ξ, η),  
   
  (7)  
   
  where ΔB u is the Beltrami operator, f (ξ, η) = f (f2 (η) cos f1 (ξ), f2 (η) sin f1 (ξ)),      ∂ g22 uξ − g12 uη 1 ∂ g11 uη − g12 uξ ΔB u = √ + , (8) √ √ g ∂ξ g ∂η g gij (i, j = 1, 2) are the scalar products of covariant tangent vectors, gij = xξi ·xξj , i, j = 1, 2, where ξ1 ≡ ξ, ξ2 ≡ η, xξ = ∂x(ξ, η)/∂ξ, yξ = ∂y(ξ, η)/∂ξ, etc., xξ = (xξ , yξ ), xη = (xη , yη ) that is g11 = x2ξ + yξ2 , g22 = x2η + yη2 , g12 = g21 = xξ xη + yξ yη ,  
   
  √  
   
  g = xξ yη − xη yξ . (9)  
   
  The computation of quantities gij according to (9) in the speciﬁc case of the mapping (6) leads to the following expression for the Beltrami operator:       ∂ f2 (η)uξ 1 ∂ f1 (ξ)f2 (η)uη ΔB u = + . (10) f2 (η)f1 (ξ)f2 (η) ∂ξ f2 (η)f1 (ξ) ∂η f2 (η)  
   
  336  
   
  E. V. Vorozhtsov  
   
  This diﬀerential operator was input in our Mathematica program as follows: ClearAll[u];     f2 [η] ∗ D[u[ξ, η], ξ] 1 lapu = ∗ D , ξ f2[η] f1 [ξ]f2 [η] f2[η] f1 [ξ]   1  +D ∗ f1 [ξ] ∗ f2[η] ∗ D[u[ξ, η], η], η . f2 [η]  
   
  (11)  
   
  For the purpose of the veriﬁcation of this expression we have used the fact that in the particular case of f1 (ξ) = ξ = θ and f2 (η) = η = r, the above expression must coincide with the left-hand side of Eq. (1). This check-up was implemented with Mathematica as follows: lapu1 = lapu/.{f2 [η] → 0, f1 [ξ] → 0, f1 [ξ] → 1, f2 [η] → 1, f2[η] → r} This resulted in the expression, which obviously coincides with the left-hand side of (1): u(0,1) [ξ, η] u(2,0) [ξ, η] + u(0,2) [ξ, η] + . r r2 In each cell Ωi,j , the local coordinates y1 and y2 are used in the CLS method along with the global coordinates ξ and η. The local coordinates are introduced as follows: θ − θi+1/2 r − rj+1/2 , y2 = , y1 = 0.5(θi+1 − θi ) 0.5(rj+1 − rj ) where (θi+1/2 , rj+1/2 ) are the coordinates of the geometric center of the Ωi,j cell, they are computed by the following formulas: θi+1/2 = (θi + θi+1 )/2, rj+1/2 = (rj + rj+1 )/2. Thus, the local coordinates y1 , y2 vary from −1 to +1 within the cell. This is convenient for the implementation of the CLS method. To ensure the grid steps Δξ = Δη = 1 in the plane of curvilinear coordinates ξ, η we specify the connection between the coordinates ξ, η and the local coordinates y1 , y2 by the following formulas: y1 =  
   
  ξ − ξi+1/2 , 0.5  
   
  y2 =  
   
  η − ηj+1/2 , 0.5  
   
  (12)  
   
  where (ξi+1/2 , ηj+1/2 ) are the coordinates of the geometric center of the Ωi,j cell in the (ξ, η) plane that is ξi+1/2 = ξi + 0.5, ηj+1/2 = ηj + 0.5. The formulas ∂ dy1 ∂ 1 ∂ ∂ = · = =2 , ∂ξ dξ ∂y1 0.5 ∂y1 ∂y1  
   
  ∂ ∂ =2 ∂η ∂y2  
   
  (13)  
   
  enable one to replace the diﬀerentiation with respect to ξ and η in (10) with the diﬀerentiation with respect to y1 and y2 . Besides, it is necessary to replace ξ and η in f2 (η), f1 (ξ), f2 (η) by the formulas ξ = 0.5y1 + ξi+1/2 , η = 0.5y2 + ηj+1/2 . The passage in the expression (11) to the local variables y1 and y2 was implemented in the language of the CAS Mathematica as follows: lapu2 = lapu/.{u(0,1) [ξ, η] → 2u(0,1) [y1, y2], u (2,0)  
   
  u(1,0) [ξ, η] → 2u(1,0) [y1, y2], u  
   
  (0,2)  
   
  [ξ, η] → 4u(0,2) [y1, y2],  
   
  [ξ, η] → 4u(2,0) [y1, y2]}  
   
  A Symbolic-Numeric Method for Solving the Poisson Equation  
   
  337  
   
  In the obtained expression for lapu2, there are the Greek letters and the primed variables, which are unacceptable in the available Fortran compiler. Therefore, one must prepare the operator lapu2 for its further use in a Fortran program. To this end, the following denotations were used in our Mathematica program: lapu3 = lapu2/./{f2[η] → y, f2 [η] → r1s, f2 [η] → r2s, f1 [ξ] → th1s, f1 [ξ] → th2s} The variable y coincides with r: r ≡ y. The derivatives f1 (ξ), f2 (η), f1 (ξ), f2 (η) enter formula (10). These derivatives were approximated at the center of the cell Ωi,j with the second order of accuracy. Let us illustrate the procedure for calculating these derivatives by the example of the derivatives f2 (η), f2 (η). The central diﬀerences were used for their approximation in internal cells [14,35]: f2 (ηj+1/2 ) = rj+1 − rj ,  
   
  f2 (ηj+1/2 ) = rj+3/2 − 2rj+1/2 + rj−1/2 .  
   
  (14)  
   
  In the left boundary cell Ωi,1 , we apply the right one-sided diﬀerences:  f2 (η3/2 ) = (1/2) 4r5/2 − 3r3/2 − r7/2 , f2 (η3/2 ) = r7/2 − 2r5/2 + r3/2 . (15) In the right boundary cell Ωi,Nr −1 , we apply the left one-sided diﬀerences:  f2 (ηNr −1/2 ) = 12 rNr −1/2 − 4rNr −3/2 + rNr −5/2 , (16) f2 (ηNr −1/2 ) = rNr −1/2 − 2rNr −3/2 + rNr −5/2 . To avoid the singularities in the form of the factors 1r and r12 in Eq. (1) we have multiplied the both sides of this equation by r2 following [39]. It is to be noted that at the application of the CLS method for solving any problems, it is important that the equations of the overdetermined system, which play equal role in the approximate solution, have approximately equal weight coeﬃcients. Denote by ΔB,y1 ,y2 the Beltrami operator in local variables y1 and y2 . Note that the factor 1/[f2 (η)]2 enters the Beltrami operator (7). This factor has the order of smallness 1/O(h2r ) in the uniform grid case, where hr is the grid step in the interval [R1 , R2 ]. And the coeﬃcients of the equations obtained from the boundary condition have the order of smallness O(1). To ensure the same orders of smallness for the coeﬃcients of all equations of the algebraic system for b1 , . . . , b10 it is enough to multiply the both sides of the Beltrami equation by a quantity of the order O(h2r ). One can ensure this by multiplying the equation by the quantity [f2 (η)]2 . Thus, the ﬁnal form of the collocation equation is as follows: 2 2 (17) ζ [f2 (η)f2 (η)] ΔB,y1 ,y2 u = ζ [f2 (η)f2 (η)] F (y1 , y2 ), where F (y1 , y2 ) = f (0.5y1 + ξi+1/2 , 0.5y2 + ηj+1/2 ) and ζ is a user-speciﬁed parameter. This results in some improvement of the numerical solution accuracy. To perform the passage to Eq. (17) the left- and right-hand sides were calculated as follows:  
   
  338  
   
  E. V. Vorozhtsov  
   
  Fig. 1. Versions of the speciﬁcation of collocation and matching points: (a) Nc = 10, Nm = 2, M = 4; (b) Nc = 11, Nm = 2, M = 12; (c) Nc = 12, Nm = 4, M = 4; (d) Nc = 16, Nm = 5, M = 4.  
   
  equ1= Expand[zeta*(y*r1s)^2*lapu3]; rhs= zeta*(r1s*y)^2*frhs[x,y]; Here frhs is a double precision function in the Fortran code, which computes the right-hand side of the Poisson equation; x = θ, y = r. The number of collocation points Nc in each cell Ωi,j and their location inside the cell are speciﬁed by the user, and this can be done in diﬀerent ways. The collocation points were set at the same angular distance from one another on the Lam´e curve (hyperellipse)  
   
  y M y M  
   
  2  
   
  1  
   
  + = 1, ω ω  
   
  (18)  
   
  where M is a user-speciﬁed real number. Figure 1 shows the examples of specifying diﬀerent numbers of collocation points by the given technique; the dashed line shows curve (18) at the diﬀerent values of M . It is to be noted that the collocation points are located in the cell Ωi,j asymmetrically with respect to the straight lines y1 = 0, y2 = 0 at odd values of Nc (see Fig. 1, (b)), which may deteriorate to some extent the accuracy of the solution obtained by the CLS method. It is, therefore, desirable to use the even values of the parameter Nc . In the present work, the polynomial representation of the solution of the Poisson equation in each cell Ωi,j is employed in the form of the following thirddegree polynomial: u(y1 , y2 ) = b1 +b2 y1 +b3 y2 +b4 y12 +2b5 y1 y2 +b6 y22 +b7 y13 +b8 y12 y2 +b9 y1 y22 +b10 y23 . (19) In this equation, b1 , . . . , b10 are the unknown coeﬃcients that are to be found. The substitution of expression (19) in (17) leads to an algebraic equation, which is linear in the coeﬃcients b1 , . . . , b10 . The coordinates of Nc collocation points (y1,i,m , y2,j,m ), m = 1, . . . , Nc are then substituted in this linear equation. As a result, one obtains Nc collocation equations. Generally, we used the following rule when setting the value of Nc : the number of collocation points must be no less than the number of unknown coeﬃcients bj , j = 1, . . . , 10 in the local approximating polynomial (19) because it is the collocation equation, which approximates the Beltrami equation (17).  
   
  A Symbolic-Numeric Method for Solving the Poisson Equation  
   
  339  
   
  Similarly to [30–32], we speciﬁed on the sides of each cell the conditions for matching the solution therein with the solutions in neighboring cells. As the vast experience of the application of the CLS method to the solution of various PDEs shows, the incorporation of the matching conditions in the matrix of a system of linear algebraic equations (SLAE) for determining the bi enables a considerable reduction of the condition number of the resulting SLAE. In addition, the matching conditions ensure the unique piecewise polynomial solution. The requirements of the continuity of a linear combination of the values of the approximate solution and its derivative along a normal to the wall have been taken here as matching conditions: σ1 h∂u/∂n + σ2 u = σ1 h∂(U − )/∂n + σ2 (U − ).  
   
  (20)  
   
  One takes in the left-hand sides of these relations the solution u in the current cell, which is to be found, and in the right-hand side, one takes the solution in the neighboring cell; this is typically the known solution from the foregoing iteration of the CLS method, which is denoted as follows: U (y1 , y2 ) = a1 +a2 y1 +a3 y2 +a4 y12 +2a5 y1 y2 +a6 y22 +a7 y13 +a8 y12 y2 +a9 y1 y22 +a10 y23 . The points at which Eqs. (20) are written are called the matching points. Here n = (n1 , n2 ) is the external normal to the cell side, and U − are the limits of the function U as its arguments tend to the cell side from outside the cell; σ1 and σ2 are the non-negative user-speciﬁed weight parameters, which aﬀect to some extent the condition number of the obtained system of linear algebraic equations and the solution convergence rate [8]. The quantity h in (20) is speciﬁed as follows: on the side r = rj+1 of the cell ∂U − 2 Ωi,j we assume h = 12 according to (12). Then h∂(U − )/∂n = h · dy dη · ∂y2 = ∂U − ∂y2 . −  
   
  We have similarly on the side θ = θi+1 : hθ ∂(U − )/∂n = hθ ∂(U − )/∂θ = ∂U /∂y1 , hθ = 12 . Denote by Nm the number of matching points on each cell side. Since the number of cell sides is equal to four, we obtain 4Nm matching conditions in each cell (the matching points are shown by small squares in Fig. 1). If the cell side on which r = const belongs to the boundary of the Ω region, then one writes the boundary conditions u(y1 , y2 ) = g1 or u(y1 , y2 ) = g2  
   
  (21)  
   
  according to (3) instead of the matching conditions on this side at the points, to which on the cell sides lying inside the region the points of assigning the matching conditions correspond. In the matching conditions (20), the periodicity conditions (4) were taken into account along the θ coordinate in the boundary cells Ω1,j and ΩNθ −1,j , j = 1, . . . , Nr − 1. Consider at ﬁrst the cell Ω1,j . The side θ1 = 0 of this cell is simultaneously the side θ1 = 2π of the cell ΩNθ −1,j . Therefore, equality (20) was implemented in the cell Ω1,j as follows:  
   
  340  
   
  E. V. Vorozhtsov  
   
      ∂u(y1 , y2 ) ∂U (y1 , y2 ) + σ2 u(y1 , y2 ) = σ1 + σ2 U (y1 , y2 ) . σ1 i=1, i=Nθ −1, ∂y1 ∂y1 y1 =−1  
   
  y1 =1  
   
  (22) In a similar way, the equation     ∂u(y1 , y2 ) ∂U (y1 , y2 ) σ1 + σ2 u(y1 , y2 ) = σ1 + σ2 U (y1 , y2 ) . i=1, i=Nθ −1, ∂y1 ∂y1 y1 =1  
   
  y1 =−1  
   
  (23) was included in the SLAE when assembling it for the cell ΩNθ −1,j . At the practical implementation of the CLS method, the solution is found in the cells Ωi,j in the direction of the increasing indices i, j. Therefore, at the SLAE assembly in the cell Ω1,j , the solution in the cell ΩNθ −1,j is not known yet. In this connection, we have implemented the computation with the use of the alternating Schwarz method [26]. According to this method, the values known at the moment of the solution in the given cell were taken as U − in (20) and (22). Let n be the iteration number, n = 0, 1, 2, . . . Condition (22) was then implemented as follows:   ∂un+1 (y1 , y2 ) n+1 + σ2 u (y1 , y2 ) σ1 ∂y1 i=1,y1 =−1   n ∂U (y1 , y2 ) = σ1 + σ2 U n (y1 , y2 ) . ∂y1 i=Nθ −1,y1 =1 And on the right-hand side of Eq. (23), one can take the values of U (y1 , y2 ) and ∂U (y1 , y2 )/∂y1 at the (n + 1)th iteration because at the computation in the direction of the increasing index i, the values of the coeﬃcients b1 , . . . , b10 in (19) are already known by the moment when the computational process reaches the boundary cell ΩNθ −1,j . Thus, the following SLAE was solved in each cell Ωij : n , Aij X n+1 = fij  
   
  (24)  
   
    n , . . . , bn+1 stands for the transpose; fij is the vector of where X = (bn+1 1 10 ) and the right-hand sides, it includes both the right-hand sides of collocation equations and the right-hand sides of the matching conditions. The collocation part of the matrix Aij was computed by us in the language of the CAS Mathematica as follows.  
   
  X={b1, b2, b3, b4, b5, b6, b7, b8, b9, b10}; mb = Length[X]; rowm = Table[0,{mb}]; SetDirectory["D:\\Papers\\CASC2023"]; "Coefficients of the Poisson collocation equation" >> colloc.txt; Do[eq = " AR(m,"; eq = eqToString[m]") = "; eqm = FullSimplify[rowm[[m]] ]; e1f = FortranForm[eqm]; eq ToString[e1f] >>> colloc.txt,{m,mb}]; rh1 = zeta*(r1s*y)^2*frhs[x,y]; eq = " BR(m) = "; e1f = FortranForm[rh1]; eq ToString[e1f] >>> colloc.txt;  
   
  A Symbolic-Numeric Method for Solving the Poisson Equation  
   
  341  
   
  In the above program fragment, one row of the matrix AR = Aij is computed. The number of these rows is equal to the number of collocation points Nc ; n . The programming of the matching conditions is carried out similarly BR = fij to the case of the collocation equation. One must only replace the collocation equation with the equation expressing the matching condition. The initial guess u0 (θ, r) was set with regard for the boundary conditions (3) by a linear interpolation of the values g1 (θ) and g2 (θ): u0 (θ, r) =  
   
  [g1 (θ) − g2 (θ)]r + g2 (θ)R1 − g1 (θ)R2 . R1 − R2  
   
  As a result, one obtains in each cell a system involving Nc + 4Nm equations, where Nc ≥ 10, Nm ≥ 1, by including in the SLAE the collocation equations and the matching conditions. By virtue of the fact that Nc + 4Nm ≥ 14, the SLAE for ﬁnding ten unknown coeﬃcients a1 , . . . , a10 in (19) is overdetermined. The method of reﬂections [7] was applied for the numerical solution of this SLAE. The Givens method of rotations [6] is less eﬃcient than the method [7] because it requires a CPU time, which is by the factor of 1.27 larger than in the case of the Householder method. In the version of the method implemented here, the numerical solution of the global problem is found iteratively in the so-called Gauss–Seidel process. In this process, all cells of the region are scanned sequentially at each global iteration after the initial guess has been assigned to the solution in each cell. One solves in each cell a SLAE, which determines a “local” piece of the global solution. If the current cell belongs to the region boundary, the boundary conditions of the problem are then realized therein because their approximation has been included in the SLAE determining the solution in this cell. The Poisson equation (1) contains a singularity at point r = 0. The solution itself is regular if the right-hand side of the Poisson equation and the boundary conditions are suﬃciently smooth. In the spectral-diﬀerence methods [16,17], the singularity problem was solved by using a uniform grid on the r axis, which was shifted by a half-step from the point r = 0, as well as the symmetry conditions of the coeﬃcients of the expansion into the Fourier series. There is no singularity problem in the proposed CLS method at ﬁnite grid step values. The collocation points are set inside the cell, therefore, always r = rj,m > 0 (j = 1, . . ., Nr − 1; m = 1, . . . , Nc ). There is no division by r in the matching conditions (20), that is, they have no singularity.  
   
  3  
   
  Computational Results  
   
  To investigate the accuracy of the above-proposed version of the CLS method we have used the same test solutions of the Poisson equation as in [30]: u(x, y) = 3ex+y (x − x2 )(y − y 2 ) + 5, ex + ey u(x, y) = . 1 + xy u(x, y) = ((x + 1)5/2 − (x + 1))((y + 1)5/2 − (y + 1)).  
   
  (25) (26) (27)  
   
  342  
   
  E. V. Vorozhtsov  
   
  The above exact solutions were taken in [30] from the works [2,17]. The corresponding right-hand sides f (x, y) are easily obtained by substituting solutions (25)–(27) into the left-hand side of equation uxx + uyy = f (x, y). Then one ﬁnds the expression for the function f¯√(θ, r) in (1). Note that at the √ use of test (26), it is necessary to specify R2 < 2 in (2) because at R2 = 2 and θ = 3π/4, the denominator in (26) vanishes, that is, it gives rise to a singularity. In the example (27), the derivatives ∂u/∂rk and ∂u/∂θk also contain the singularities at k > 2 in the form of the following factors: √  
   
  1 1 , √ , 1 + r sin θ 1 + r cos θ  
   
  1 (1 +  
   
  5 r sin θ)k− 2  
   
  ,  
   
  1 5  
   
  (1 + r cos θ)k− 2  
   
  .  
   
  For example, 1 + r sin θ = 0 at r = 1 and sin θ = −1; at r = 2 and cos θ = −1/2, etc. One can also note that solutions (25)–(27) possess the symmetry property: u(x, y) = u(y, x). The computations by the CLS method were done on both uniform and nonuniform grids along the θ and r axes. The non-uniform grids were generated along each axis by the same algorithm described in [35, p. 106–107]. Let us brieﬂy describe the algorithm for obtaining the non-uniform grid in the interval R1 ≤ r ≤ R2 . In this algorithm, one must at ﬁrst specify the grid steps r2 − r1 and rNr −rNr −1 by the formulas: r2 −r1 = λr,L ·hr , rNr −rNr −1 = λr,R ·hr , where hr is the uniform grid step in the interval R1 ≤ r ≤ R2 ; this uniform grid has Nr nodes that is hr = (R2 − R1 )/(Nr − 1); λr,L and λr,R are the user-speciﬁed coeﬃcients, 0 < λr,L , λr,R ≤ 1. If λr,L < 1 and λr,R = 1, then one obtains along the r axis a grid that clusters near the boundary r = R1 ; if λr,L < 1 and λr,R < 1, the grid clusters near the both boundaries r = R1 and r = R2 ; if λr,L = 1 and λr,R < 1, then the grid clusters near the boundary r = R2 ; and, ﬁnally, at λr,L = λr,R = 1, a uniform grid is obtained. The function sinh(ζ) is involved in the computations of the coordinates of grid node coordinates in this algorithm. To determine the error of the method on a speciﬁc spatial computational grid the grid analogs of the error norms were computed with the use of the norms of the Lp spaces (p ≥ 1) by the formulas ⎤ p1 ⎡ N θ −1 N r −1   
   
  p 1 uk 1 1 − uex rj+ 12 δrj+ 12 δθi+ 12 ⎦ , δuk p = ⎣ i+ 12 ,j+ 12 π(R22 − R12 ) i=1 j=1 i+ 2 ,j+ 2  

  (28) δuk ∞ = max uki+ 1 ,j+ 1 − uex 1 1 , i+ ,j+ i,j  
   
  2  
   
  2  
   
  2  
   
  2  
   
  k where uex i+1/2,j+1/2 and ui+ 12 ,j+ 12 are, respectively, the exact solution and the approximate solution by the CLS method, which have been computed at the center of the Ωi,j cell, δθi+ 12 = θi+1 − θi , δrj+ 12 = rj+1 − rj . The convergence rate νp of the CLS method on a sequence of grids at the grid reﬁnement was computed by the formula known in numerical analysis:  log δuk (hm−1 ) p / δuk (hm ) p , (29) νp = log(hm−1 /hm )  
   
  A Symbolic-Numeric Method for Solving the Poisson Equation  
   
  343  
   
  where hm , m = 2, 3, . . . are some values of steps hr and hθ such that |hr,m−1 − hr,m | + |hθ,m−1 − hθ,m | > 0. Let bki,j,l (k = 0, 1, . . .; l = 1, . . . , 10) be the value of the coeﬃcient bl in (19) in the cell Ωi,j at the kth iteration. The following condition was used for the termination of iterations by the Schwarz’s alternating method: δbk+1 < ε,   
   
  where δbk+1 = max i,j  

    
   
  k  
   
  − b max bk+1 i,j,l , i,j,l  
   
  1≤l≤10  
   
  (30)  
   
  (31)  
   
  ε is a user-speciﬁed small positive number,  2 ε degree v = k and suitable starting value w(0) , the sequence of iterates   w(i+1) = w(i) + shift−h w(i) (shifth 1 − vw(i) ) converges to shinvh v in log2 (h − k) steps. A suitable starting value for w(0) is given by Shinv0 in Sect. 4.  
   
  3  
   
  Division in Non-Commutative R[x]  
   
  We now lay out how to use shift and shinv to compute quotients for polynomials with non-commutative coeﬃcients. First we show classical algorithms to compute left and right quotients in R[x]. We then prove two theorems, one showing that xn lquov = xn rquov in this setting, making the whole shifted inverse well deﬁned, and another showing that it may be used to compute left and right quotients.  
   
  Eﬃcient Quotients of Non-commutative Polynomials  
   
  3.1  
   
  375  
   
  Deﬁnitions and Classical Algorithms  
   
  Let u and v be two polynomials in R[x] with Euclidean norm being the polynomial degree. The left and right quotients and remainders are deﬁned as in (2). Left and right quotients will exist provided that vk is invertible in R and they may be computed by Algorithm 1. In the presentation of the algorithm, π denotes a permutation on two elements so is either the identity or a transposition. The notation ×π is a shorthand for × ◦ π so a ×π b = a × b when π is the identity and a ×π b = b × a when π is a transposition. There are some circumstances where quotients or related quantities may be computed even if vk is not invertible. When R is an integral domain, quotients may be computed as usual in K[x] with K being the quotient ﬁeld of R. Alternatively, when R is non-commutative but vk commutes with v, it is possible to compute pseudoquotients and pseudoremainders satisfying m u = v ql + rl , u m = qr v + rr ,  
   
  degree rl < degree v degree rr < degree v  
   
  m = vkh−k+1 , as shown in Algorithm 2. In this case, we write ql = u lpquo v qr = u rpquo v  
   
  rl = lprem v rl = rprem v.  
   
  Requiring vk to commute with v is quite restrictive, however, so we focus our attention to situations where the inverse of vk exists.  
   
  376  
   
  3.2  
   
  S. M. Watt  
   
  Whole Shift and Whole Shifted Inverse in R[x]  
   
  We now examine the notions of the whole shift and whole shifted inverse for R[x] with non-commutative R. First consider the whole shift. Since x commutes h with all values in R[x], we may without ambiguity take, for u = i=0 ui xi and n ∈ Z,   shiftn u = xn (ui xi ) = (ui xi )xn . (7) i+n≥0  
   
  i+n≥0  
   
  That is, the fact that R[x] is non-commutative does not lead to left and right variants of the whole shift. We state two simple theorems with obvious proofs: Theorem 3. Let w ∈ R[x]. Then, for all n ∈ Z≥0 , shift−n shiftn w = w. Theorem 4. Let u, v ∈ R[x] with degree u = h and degree v = k. Then, for m ∈ Z, shift−k−m (u × v) = shift−k (shift−m (u) × v) shift−h−m (u × v) = shift−h (u × shift−m (v)).  
   
  We now come to the main point of this section and show shinv is well-deﬁned when R is non-commutative. Theorem 5 (Whole shifted inverse for non-commutative R[x]). k Let v = i=0 vi xi ∈ R[x], with R a non-commutative ring and vk invertible in R. Then, for h ∈ Z≥0 , xh lquo v = xh rquo v. Proof. Let ql = xh lquov and qr = xh rquov. If h < k, then ql = qr = 0. Otherwise, both ql and qr have degree h − k ≥ 0 so vk ql h−k = 1 k   
   
  vj ql i+k−j = 0  
   
  j=M  
   
  qr h−k vk = 1 k   
   
  qr i+k−j vj = 0,  
   
  (8) 0 ≤ i < h − k,  
   
  (9)  
   
  j=M  
   
  where M = max(0, i − h + 2k). We show by induction on i that ql i = qr i for 0 ≤ i ≤ h − k. Since vk is invertible, (8) and (9) give ql h−k = qr h−k = vk−1  
   
  (10)  
   
  and ql i = −  
   
  k−1  j=M  
   
  vk−1 vj ql i+k−j  
   
  qr i = −  
   
  k−1  j=M  
   
  qr i+k−j vj vk−1 ,  
   
  0 ≤ i < h − k. (11)  
   
  Eﬃcient Quotients of Non-commutative Polynomials  
   
  377  
   
  Equation (10) gives the base of the induction. Now suppose ql i = qr i for N < i ≤ h − k. Then for i = N ≥ 0 equation (11) gives ql N = −  
   
  k−1   
   
  vk−1 vj ql N +k−j = −  
   
  j=M  
   
  =−  
   
  k−1  j=M  
   
  =−  
   
  k−1  =M  
   
  =−  
   
  k−1   
   
  vj  
   
  vk−1 vj qr N +k−j  
   
  j=M  
   
   vk−1  
   
  k−1   
   
  −  
   
  k−1  =M  
   
  ⎛ ⎝−  
   
  k−1   
   
    
   
  qr N +k−j+k− v vk−1 ⎞  
   
  vk−1 vj qr N +k−j+k− ⎠ v vk−1  
   
  j=M  
   
  qr N +k−j v vk−1 = qr N .  
   
  =M  
   
   Thus we may write shinvh v without ambiguity in the non-commutative case, i.e shinvh v = xh lquo v = xh rquo v. 3.3  
   
  (12)  
   
  Quotients from the Whole Shifted Inverse in R[x]  
   
  We consider computing the left and right quotients in R[x] from the whole shifted inverse. We have the following theorem. Theorem 6 (Left and right quotients from the whole shifted inverse in R[x]). Let u, v ∈ R[x], R a ring, with degree v = k and vk invertible in R. Then for h ≥ degree u, u lquo v = shift−h (shinvh (v) × u) and u rquo v = shift−h (u × shinvh (v)).  
   
  Proof. Consider ﬁrst the right quotient. It is suﬃcient to show u = shift−h (u × shinvh v) × v + rr for some rr with degree rr < k. It suﬃces to show   shift−k u = shift−k shift−h (u × shinvh v) × v .  
   
  (13)  
   
  We have (u × shinvh v) × v = u × ((xh rquo v) × v)  
   
  (14)  
   
  h  
   
  = u × (x − ρ), ρ = 0 or degree ρ < k = shifth u − u × ρ. shifth u = (u × shinvh v) × v + u × ρ.  
   
  (15)  
   
  378  
   
  S. M. Watt  
   
  Since h ≥ 0, Theorem 3 applies and equation (15) gives   u = shift−h (u × shinvh v) × v + shift−h (u × ρ) with the degree of shift−h (u × ρ) less than k. Therefore   shift−k u = shift−k−h (u × shinvh v) × v   = shift−k shift−h (u × shinvh v) × v) , by Theorem 4, and we have shown equation (13) as required. The proof for lquo replaces equation (14) with v × (shinvh v × u) = (v × (xh lquo v)) × u and follows the same lines, mutatis mutandis.  
   
    
   
  As in the commutative case, it may be more eﬃcient to compute only the top part of the product instead of computing the whole thing then shifting away part. Now that we have shown that shift and shinv are well-deﬁned for non-commutative R[x], we next see that shinv may be computed by our generic algorithm.  
   
  4  
   
  Generic Algorithm for the Whole Shifted Inverse  
   
  Earlier work has shown how to compute shinv eﬃciently for Z, both for Euclidean domains F [x], and generically [10]. The generic version shown here in Algorithm 3. We justify below that it applies equally well to polynomials with noncommutative coeﬃcients. The algorithm operates on a ring D that is required to have a suitable shift and certain other operations and properties must be deﬁned. For example, on F [x], F a ﬁeld, these are u · xn if n ≥ 0 shiftn u = −n if n < 0 u quo x coeﬀ(u, i) = ui Shinv0(v) = (1/vk x − 1/vk · vk−1 · 1/vk , 2) hasCarries = false Mult(a, b) = ab MultMod(a, b, n) = ab rem xn . The iterative step of Algorithm 3 is given on line 32. Since D.PowDiff computes shifth 1 − v · w, this line computes   shiftm w + shift2m−h w · (shifth 1 − v · w) . (16)  
   
  Eﬃcient Quotients of Non-commutative Polynomials  
   
  379  
   
  380  
   
  S. M. Watt  
   
  The shift operations are multiplications by powers of x, with shifth p = pxh . The expressions involving k, h,  and m for shift amounts arise from multiplication by various powers of x at diﬀerent points in order to compute shorter polynomials when possible. Since x commutes with all values, it is possible to accumulate these into single pre- and post- shifts. With this in mind, the R[x] operations + and · ultimately compute the polynomial coeﬃcients using the operations of R and the order of the multiplicands in (16) is exactly that of the Newton-Schulz iteration (3). The form of Shinv0 above is chosen so that it gives a suitable initial value for non-commutative polynomials. The computational complexity of the Refine methods of Algorithm 4 may be summarized as follows: The function D.Refine1 computes full-length values at each iteration so has time complexity O(log(h−k)M (h)) where M (N ) is the time complexity of multiplication. The function D.Refine2 reduces the size of the values, computing only the necessary preﬁxes. The function D.Refine3 reduces the   log(h−k) M (2i ) , size of some values further and achieves time complexity O i=1 which gives time complexity O(M (N )), N = h − k for the purely theoretical M (N ) ∈ O(N log N ), for Sch¨ onhage-Strassen M (N ) ∈ O(N log N log log N ) and for M (N ) ∈ O(N p ), p > 0.  
   
  5  
   
  Non-commutative Polynomial Example  
   
  We give an example of computing left and right quotients via the whole shifted inverse with R[x] = F7 2×2 [x] using the algorithms of Sects. 3 and 4. Note that R[x] is not a domain—there may be zero divisors, but it is easy enough to check for them. This example, and the one in Sect. 7, were produced using the Domains package in Maple [5]. The setup to use the Domains package for this example is with(Domains); F := GaloisField(7); F2x2 := SquareMatrix(2, F); PF2x2 := DenseUnivariatePolynomial(F2x2, x); We start with  

       
   
    
   
   22 4 21 3 20 2 33 45 46 5 x + x + x + x+ , u= x + 01 13 41 54 12 61  
   
    
   
    
   
   53 12 43 2 x+ . v= x + 04 61 45 The whole 5-shifted inverse of v is then  
   
      
   
   54 3 60 2 10 51 x + x + x+ . shinv5 v = 34 41 22 63 From this, the left and right quotients and remainders are computed to be  

      
   
    
   
    26 3 61 2 20 16 31 14 x + x + x+ x+ , rl = , ql = 11 00 33 41 00 43  

      
   
    
   
    35 3 11 2 05 20 40 04 x + x + x+ x+ , rr = . qr = 50 15 55 21 26 56  
   
  Eﬃcient Quotients of Non-commutative Polynomials  
   
  381  
   
  Taking a larger example where u has degree 100 and v degree 10, D.Refine1 computes shinv100 v with one guard digit in 6 steps with intermediate values of w all of prec 92. Methods D.Refine2 and D.Refine3 compute the same result also in 6 steps but with values of w having prec 4, 8, 16, 32, 64, 92 successively. Method D.Refine3 uses a shorter preﬁx of v on the ﬁrst iteration (s = 3). The Maple code used for this example is given in Fig. 1.  
   
  6  
   
  Division in R[x; σ, δ]  
   
  We now examine the more general case where the polynomial variable does not commute with coeﬃcients. For quotients and remainders to be deﬁned, a notion of degree is required and we note that this leads immediately to Ore extensions, or skew polynomials. After touching upon classical algorithms, we introduce the notions of left and right whole shifted inverse. We note that the modiﬁed Newton-Schulz iteration may be used to compute whole shifted inverses, though in this case there is no beneﬁt over classical division. Finally, we show how left and right whole shifted inverses may be used to compute right and left quotients, each with only one multiplication. 6.1  
   
  Deﬁnitions and Classical Algorithms  
   
  Consider a ring of objects with elements from a ring R extended by x, with x not necessarily commuting with elements of R. By distributivity, any ﬁnite expression in this extended ring is equal to a sum of monomials, the monomials composed of products of elements of R and x. To have a well-deﬁned degree compatible with that of usual polynomials, it is required that ∀ r ∈ R ∃ a, b, c, d ∈ R s.t. xr − rx = ax + b = xc + d.  
   
  (17)  
   
  We call the elements of such a ring skew polynomials. Condition (17) implies that for all r ∈ R there exist σ(r), δ(r) ∈ R such that x r = σ(r) x + δ(r).  
   
  (18)  
   
  Therefore, to have well-deﬁned notion of degree, the ring must be an Ore extension, R[x; σ, δ]. Ore studied these non-commutative polynomials almost a century ago [6] and overviews of Ore extensions in computer algebra are given in [1,2]. The subject is viewed from a linear algebra perspective in [3] and the complexity of skew arithmetic is studied in [9]. The ring axioms of R[x; σ, δ] imply that σ be an endomorphism on R and δ be a σ-derivation, i.e. for all r, s ∈ R δ(r + s) = δ(r) + δ(s)  
   
  δ(r · s) = σ(r) · δ(s) + δ(r) · s.  
   
  Diﬀerent choices of σ and δ allow skew polynomials to represent linear diﬀerential operators, linear diﬀerence operators, q-generalizations of these and other algebraic systems.  
   
  382  
   
  S. M. Watt  
   
  Condition (18) implies that it is possible to write any skew polynomial as a sum of monomials with all the powers of x on the right or all on the left. We will use the notation ui for coeﬃcients of skew polynomials with all powers of the variable on the right and i u for coeﬃcients with all powers of the variable on the left, e.g. u=  
   
  h   
   
  ui xi =  
   
  i=0  
   
  h   
   
  xi i u.  
   
  i=0  
   
  Algorithm 4 gives left and right classical division in R[x; σ, δ]. As in Sect. 3, ×π is multiplication with arguments permuted by π. When σ(r) = r, R[x; σ, δ] is a diﬀerential ring, usually denoted R[x, δ], and Algorithm 4 specializes to Algorithm 1. The left division algorithm applies only when σ is bijective. If left division is of primary interest, start from rx = xσ ∗ (r) + δ ∗ (r) instead of (18) and work in the adjoint ring R[x; σ ∗ , δ ∗ ]. Some care is needed in Algorithm 4 to avoid duplicating computation. Notice that for rskewdiv the application of qcoeff on line 6 requires n-fold application of σ to invvk and that the computation of t×π v on line 7 is coeﬀ(t) xi+k ×v. The latter requires commuting h − k powers of x across v over the course of the division. Depending on the cost to compute σ, it may be useful to create an array of the values σ i (invvk ) for i from 0 to h − k. It is also possible to precompute and store the products xi × v, with xi+1 × v obtained from xi × v by one application of (18). Then the xi × v may be used in descending order in the for loop without re-computation. Both of these pre-computations are performed in the Maple program for P[RDiv] shown in Fig. 2. 6.2  
   
  Whole Shift and Inverse in R[x; σ, δ]  
   
  It is possible to deﬁne left and right analogs of the whole shift and whole shifted inverse for skew polynomials. In general, the left and right operations give different values. Deﬁnition 3 (Left and right whole n-shift in R[x; σ, δ]). Given u ∈ R[x; σ, δ] and n ∈ Z, the left whole n-shift of u is  xi+n i u, lshiftn,x u = i+n≥0  
   
  the right whole n-shift of u is rshiftn,x u =  
   
    
   
  ui xi+n  
   
  i+n≥0  
   
  When x is clear by context, we write lshiftn u and rshiftn u.  
   
  Eﬃcient Quotients of Non-commutative Polynomials  
   
  383  
   
  Deﬁnition 4 (Left and right whole n-shifted inverse in R[x; σ, δ]). Given n ∈ Z≥0 and v ∈ R[x; σ, δ], the left whole n-shifted inverse of v with respect to x is lshinvn,x v = xn lquo v the right whole n-shifted inverse of v with respect to x is rshinvn,x v = xn rquo v When x is clear by context, we write lshinvn v and rshinvn v. Modiﬁed Newton-Schulz Iteration. For monic v ∈ R[x; σ, δ], the whole shifted inverses may be computed using modiﬁed Newton-Schulz iterations with g = 1 guard places as follows: wl(0) = wr(0) = xh−k+g − vk−1 xh−k−1+g   wl(i+1) = wl(i) + rshift−h wl(i) × (rshifth 1 − v × wl(i) ) ,   wr(i+1) = wr(i) + lshift−h (lshifth 1 − wr(i) × v) × wr(i) ,  
   
  (19)  
   
  rshift−g wl (i) → lshinvh v lshift−g wr(i) → rshinvh v. These generalize D.Refine1 in Algorithm 3. For D.Refine2 and D.Refine3, the shifts that reduce the size of intermediate expressions are combined into one pre- and one post-shift in R[x]. But on R[x; σ, δ] we do not expect these simpliﬁcations of shift expressions to be legitimate. Even though (19) can be used to compute whole shifted inverses, it does not give any beneﬁt over classical division. In the special case of R[x, δ], the multiplication by v and then by w make it so each iteration creates only one correct term, so h − k iterations are required rather than log2 (h − k). In other skew polynomial rings, e.g. linear diﬀerence operators, the iteration (19) can still converge, but with multiple iterations required for each degree of the quotient. It is therefore simpler to compute lshinv and rshinv by classical division.  
   
  384  
   
  6.3  
   
  S. M. Watt  
   
  Quotients from Whole Shifted Inverses in R[x; σ, δ]  
   
  It is possible to compute left and right quotients from the right and left whole shifted inverses in R[x; σ, δ]. Although computing whole shifted inverses is not asymptotically fast as it is in R[x], once a whole shifted inverse is obtained it can be used to compute multiple quotients and hence remainders, each requiring only one multiplication. This is useful, e.g., when working with diﬀerential ideals. In some cases this multiplication of skew polynomials is asymptotically fast [8]. Theorem 7 (Quotients from whole shifted inverses in R[x; σ, δ]). Let u, v ∈ R[x; σ, δ], with R a ring, k = degree v, h = degree u, and vk invertible in R. Then u rquo v = rshift−h (u × lshinvh v) u lquo v = lshift−h (rshinvh v × u).  
   
  (20) (21)  
   
  Proof. We ﬁrst prove (20). For h ≥ k, we proceed by induction on h − k. Suppose h − k = 0. Since u − (uh × 1/vk ) × v has no term of degree h, we have u rquo v = uh × 1/vk . On the other hand, when h = k, lshinvh v = 1/vk so rshift−h (u × lshinvh v) = uh × 1/vk and (20) holds. For the inductive step, we assume that (20) holds for h − k < N . ˆ be given by For h − k = N , let u = q × v + o(xk ) and let Q, qˆ and u u = (Qxh−k + qˆ) × v + r,  
   
  Q ∈ R, qˆ ∈ o(xh−k ), r ∈ o(xk ),  
   
  u ˆ = u − Qxh−k × v. With this, u ˆ has degree at most h − 1. The inductive hypothesis gives u ˆ rquo v = u × lshinvh v). Therefore, rshift−h (ˆ u ˆ = u − Qxh−k × v = (ˆ u rquo v) × v + rˆ, rˆ ∈ o(xk ) = rshift−h (ˆ u × lshinvh v) × v + rˆ   u × lshinvh v) + Qxh−k × v + rˆ ⇒ u = rshift−h (ˆ = rshift−h (ˆ u × lshinvh v + Qx2h−k ) × v + rˆ. From this, we have u rquo v = rshift−h (ˆ u × lshinvh v + Qx2h−k )   = rshift−h (u − Qxh−k × v) × lshinvh v + Qx2h−k   = rshift−h u × lshinvh v − Qxh−k × v × lshinvh v + Qx2h−k   = rshift−h u × lshinvh v − Qxh−k × v × (xh lquo v) + Qx2h−k   = rshift−h u × lshinvh v − Qxh−k × (xh + o(xk )) + Qx2h−k   = rshift−h u × lshinvh v + Q × o(xh ) = rshift−h (u × lshinvh v).  
   
  Eﬃcient Quotients of Non-commutative Polynomials  
   
  385  
   
  This completes the inductive step and the proof of (20). Equation (21) is proven as above, mutatis mutandis.  As in the commutative case, it may be more eﬃcient to compute only the required top part of the product in (20) and (21) rather than to compute the whole product and then shift by −h.  
   
  7 7.1  
   
  Skew Polynomial Examples Diﬀerential Operators  
   
  We take F7 [y, ∂y ] as a ﬁrst example of using whole shifted inverses to compute quotients of skew polynomials. We use Algorithm 4 to compute the left and right whole shifted inverses, and then Theorem 7 to obtain the quotients. We start with u and v u = (3y + 6)∂y5 + (3y + 1)∂y4 + 6y∂y3 + 4y∂y2 + (2y + 1)∂y + (2y + 5) v = 4∂y2 + (2y + 5)∂y + (4y + 6). The whole shifted inverses lshinv5 v = ∂y5 lquo v and rshinv5 = ∂y5 rquo v are computed by Algorithm 4. lshinv5 = 2∂y3 + (6y + 1)∂y2 + (4y 2 + 4y + 3)∂y + (5y 3 + y 2 + 3y + 2) rshinv5 = 2∂y3 + (6y + 1)∂y2 + (4y 2 + 4y + 5)∂y + (5y 3 + y 2 + y + 1). Then ql = lshift−5 (rshinv5 v × u) and qr = rshift−5 (u × lshinv5 v) so ql = (6y + 5)∂y3 + (4y 2 + 3y + 3)∂y2 + (5y 3 + 5y 2 + 5)∂y + (y 4 + 3y 3 + 5y 2 + 5y + 2) rl = (5y 5 + 4y 4 + 3y 3 + 6y 2 + 4y)∂y + (3y 5 + 2y 4 + y 3 + 5y 2 + 5) qr = (6y + 5)∂y3 + (4y 2 + 3y + 1)∂y2 + (5y 3 + 5y 2 + 4y + 3)∂y + (y 4 + 3y 3 + 5y 2 + 3y + 5) rr = (5y 5 + 4y 4 + 6y 3 )∂y + (3y 5 + 3y 4 + 5y 3 + y 2 + 4y + 5). A proof-of-concept Maple implementation for generic skew polynomials is given in Fig. 2. The program is to clarify any ambiguities without any serious attention to eﬃciency. The setup for the above example is with(Domains): LinearOrdinaryDifferentialOperator := (R, x) -> SkewPolynomial(R, x, r->r, R[Diff], r->r): F := GaloisField(7): R := DenseUnivariatePolynomial(F, ’y’): Lodo := LinearOrdinaryDifferentialOperator(R, ’D[y]’):  
   
  386  
   
  S. M. Watt  
   
  7.2  
   
  Diﬀerence Operators  
   
  We use linear ordinary diﬀerence operators as a second example, this time with σ not being the identity. We construct F7 [y, Δy ] as F7 [y][Δy ; E, E −1]. As before, we use Algorithm 4 to compute the left and right whole shifted inverses, and then Theorem 7 to obtain the quotients. We take u and v to be u = yΔ5y + (3y + 6)Δ4y + (6y + 5)Δ3y + 3yΔ2y + (2y + 1)Δy + 5y v = 4Δ2y + (6y + 1)Δy + (6y + 6). The whole shifted inverses lshinv5 v = Δ5y lquo v and rshinv5 = Δ5y rquo v are computed by Algorithm 4. lshinv5 = 2Δ3y + (4y + 2)Δ2y + (y 2 + 4y)Δy + (2y 3 + 6y 2 + y) rshinv5 = 2Δ3y + (4y + 1)Δ2y + (y 2 + 2)Δy + (2y 3 + y 2 + 4y + 1). Then ql = lshift−5 (rshinv5 v × u) and qr = rshift−5 (u × lshinv5 v) so ql = (2y + 3)Δ3y + (4y 2 + 3y + 4)Δ2y + (y 3 + 5y 2 + 6y + 4)Δy + (2y 4 + 6y 3 + 4y 2 + 4y + 4) rl = (2y 5 + 6y 4 + 6y 2 + 5y + 3)Δy + (2y 5 + 2y 4 + 4y 3 + 2y + 1) qr = 2yΔ3y + (4y 2 + 5)Δ2y + (y 3 + 5y 2 + y + 6)Δy + (2y 4 + 4y 3 + 5y + 1) rr = (2y 5 + 3y 4 + 4y 3 + y 2 )Δy + (2y 5 + 6y 4 + 5y 3 + 3y 2 + 5y). The Maple setup for this example is # Delta(f) acts as subs(y=y+1, f) - f for f in R LinearOrdinaryDifferenceOperator := proc(R, x, C) local E := R[ShiftOperator]; SkewPolynomial(R, x, r->E(r,C[1]), r->R[‘-‘](E(r,C[1]),r), r->E(r,C[‘-‘](C[1]))); end: F := GaloisField(7); R := DenseUnivariatePolynomial(F, ’y’); Lodo := LinearOrdinaryDifferenceOperator(R, ’Delta[y]’, F) 7.3  
   
  Diﬀerence Operators with Matrix Coeﬃcients  
   
  As a ﬁnal example, we take quotients in F72×2 [y, Δy ] to underscore the genericity of this method.    
   
       
   
    
   
    60 30 44 43 32 11 5 4 u= y+ Δy + y+ y+ Δy + Δ3y 11 20 65 03 44 41      
   
    
   
    
   
     01 06 53 32 00 52 2 + y+ y+ y+ Δy + Δy + 45 43 62 54 06 12  
   
  v=  
   
      
   
    
   
     15 26 46 03 15 y+ y+ Δy + Δ2y + 00 04 34 12 26  
   
  Eﬃcient Quotients of Non-commutative Polynomials  
   
  387  
   
      
   
   23 50 04 3 lshinv5 = Δy + y+ Δ2y 45 30 12   
   
     
   
   20 2 31 02 + y + y+ Δy 40 01 44   
   
      
   
   50 3 42 2 26 12 + y + y + y+ 30 04 66 66  
   
      
   
   23 50 44 rshinv5 = Δ3y + y+ Δ2y 45 30 22   
   
     
   
   20 2 21 60 + y + y+ Δy 40 51 02   
   
      
   
   50 3 22 2 35 13 + y + y + y+ 30 34 54 31   
   
    
   
    
   
     
   
    13 20 2 46 31 21 3 ql = y+ y ++ y+ Δy + Δ2y 15 40 21 64 50   
   
      
   
   50 3 40 2 24 05 + y + y + y+ Δy 30 66 54 61   
   
       
   
   20 4 43 3 10 2 43 56 + y + y + y + y+ 40 26 50 15 16   

        
   
   60 5 62 4 66 3 22 2 24 65 rl = y + y + y + y + y+ Δy 00 10 46 36 60 20   

        
   
   00 5 60 4 32 3 51 2 36 24 + y + y + y + y + y+ 50 34 36 30 46 26   
   
    
   
    
   
     
   
    54 20 2 00 62 53 y+ y + y+ Δ3y + Δ2y 61 10 60 46 45   
   
      
   
   50 3 16 2 55 53 + y + y + y+ Δy 60 02 14 26   
   
       
   
   20 4 25 3 52 2 22 25 + y + y + y + y+ 10 56 43 11 23   

        
   
   54 5 14 4 44 3 13 2 32 26 rr = y + y + y + y + y+ Δy 62 03 32 14 25 45   

        
   
   32 5 34 4 30 3 61 2 32 40 + y + y + y + y + y+ 51 46 26 26 60 13 qr =  
   
  The Maple setup for this example is the same as for the previous example but with F := SquareMatrix(2, GaloisField(7)).  
   
  388  
   
  S. M. Watt  
   
  Fig. 1. Maple code for fast generic polynomial shinv and left and right division  
   
  Eﬃcient Quotients of Non-commutative Polynomials  
   
  Fig. 2. Maple code for generic skew polynomials  
   
  389  
   
  390  
   
  S. M. Watt  
   
  Fig. 2. (continued)  
   
  Eﬃcient Quotients of Non-commutative Polynomials  
   
  391  
   
  Fig. 2. (continued)  
   
  8  
   
  Conclusions  
   
  We have extended earlier work on eﬃcient computation of quotients in a generic setting to the case of non-commutative univariate polynomial rings. We have shown that when the polynomial variable commutes with the coeﬃcients, the whole shift and whole shifted inverse are well-deﬁned and they may be used to compute left and right quotients. The whole shifted inverse may be computed by a modiﬁed Newton method in exactly the same way as when the coeﬃcients are commutative and the number of iterations is logarithmic in the degree of the result. When the polynomial variable does not commute with the coeﬃcients, left and right whole shifted inverses exist and may be computed by classical division. Once a left or right whole shifted inverse is obtained, several right or left quotients with that divisor may be computed, each with a single multiplication.  
   
  References 1. Abramov, S.A., Le, H.Q., Li, Z.: Univariate Ore polynomial rings in computer algebra. J. Math. Sci. 131(5), 5885–5903 (2005) 2. Bronstein, M., Petkovˇsek, M.: An introduction to pseudo-linear algebra. Theoret. Comput. Sci. 157(1), 3–33 (1996)  
   
  392  
   
  S. M. Watt  
   
  3. Jacobson, N.: Pseudo-linear transformations. Ann. Math. Second Ser. 38(2), 484– 507 (1937) 4. Moenck, R.T., Borodin, A.B.: Fast modular transforms via division. In: Proceedings of the 13th Annual Symposium on Switching and Automata Theory (SWAT 1972), pp. 90–96. IEEE, New York (1972) 5. Monagan, M.B.: Gauss: a parameterized domain of computation system with support for signature functions. In: Miola, A. (ed.) DISCO 1993. LNCS, vol. 722, pp. 81–94. Springer, Heidelberg (1993). https://doi.org/10.1007/BFb0013170 6. Ore, Ø.: Theory of non-commutative polynomials. Ann. Math. Second Ser. 34(3), 480–508 (1933) 7. Schulz, G.: Iterative Berechnung der reziproken Matrix. Z. Angew. Math. Mech. 13(1), 57–59 (1933) 8. van der Hoeven, J.: FFT-like multiplication of linear diﬀerential operators. J. Symb. Comput. 33(1), 123–127 (2002) 9. van der Hoeven, J.: On the complexity of skew arithmetic. Appl. Algebra Eng. Commun. Comput. 27, 105–122 (2016) 10. Watt, S.M.: Eﬃcient generic quotients using exact arithmetic. In: Proceedings of the International Symposium on Symbolic and Algebraic Computation (ISSAC 2023). ACM, New York (2023)  
   
  Inverse Kinematics and Path Planning of Manipulator Using Real Quantifier Elimination Based on Comprehensive Gr¨ obner Systems Mizuki Yoshizawa, Akira Terui(B) , and Masahiko Mikawa University of Tsukuba, Tsukuba, Japan [email protected]  , [email protected]  https://researchmap.jp/aterui  
   
  Abstract. Methods for inverse kinematics computation and path planning of a three degree-of-freedom (DOF) manipulator using the algorithm for quantiﬁer elimination based on Comprehensive Gr¨ obner Systems (CGS), called CGS-QE method, are proposed. The ﬁrst method for solving the inverse kinematics problem employs counting the real roots of a system of polynomial equations to verify the solution’s existence. In the second method for trajectory planning of the manipulator, the use of CGS guarantees the existence of an inverse kinematics solution. Moreover, it makes the algorithm more eﬃcient by preventing repeated computation of Gr¨ obner basis. In the third method for path planning of the manipulator, for a path of the motion given as a function of a parameter, the CGS-QE method veriﬁes the whole path’s feasibility. Computational examples and an experiment are provided to illustrate the eﬀectiveness of the proposed methods.  
   
  Keywords: Comprehensive Gr¨ obner systems Robotics · Inverse kinemetics · Path planning  
   
  1  
   
  · Quantiﬁer elimination ·  
   
  Introduction  
   
  We discuss inverse kinematics computation of a 3-degree-of-freedom (DOF) manipulator using computer algebra. Manipulator is a robot with links and joints that are connected alternatively. The end part is called the end-eﬀector. The inverse kinematics problem is fundamental in motion planning. In the motion planning of manipulators, a mapping from a joint space and the operational space of the end-eﬀector is considered for solving the forward and inverse kinematics problems. The forward kinematics problem is solved to ﬁnd the endeﬀector’s position from the given conﬁguration of the joints. On the other hand, the inverse kinematic problem is solved to ﬁnd the conﬁguration of the joints if the solution exists. c The Author(s), under exclusive license to Springer Nature Switzerland AG 2023  F. Boulier et al. (Eds.): CASC 2023, LNCS 14139, pp. 393–419, 2023. https://doi.org/10.1007/978-3-031-41724-5_21  
   
  394  
   
  M. Yoshizawa et al.  
   
  For solving inverse kinematics problems, computer algebra methods have been proposed [5,8,17,20,21]. Some of these methods are especially for modern manipulators with large degrees of freedom [17], which indicates an interest in applying global methods to a real-world problem. The inverse kinematics problem is expressed as a system of polynomial equations in which trigonometric functions are replaced with variables, and constraints on the trigonometric functions are added as new equations. Then, the system of equations gets “triangularized” by computing a Gr¨ obner basis and approximate solutions are calculated using appropriate solvers. We have proposed an implementation for inverse kinematics computation of a 3-DOF manipulator [7]. The implementation uses SymPy, a library of computer algebra, on top of Python, and also uses a computer algebra system Risa/Asir [13] for Gr¨ obner basis computation, connected with OpenXM infrastructure [11]. An advantage of using Gr¨ obner basis computation for solving inverse kinematics problems is that the global solution can be obtained. The global solution helps to characterize the robot’s motion, such as kinematic singularities. On the other hand, Gr¨ obner basis computation is relatively costly. Thus, repeating Gr¨ obner basis computation every time the position of the end-eﬀector changes leads to an increase in computational cost. Furthermore, in inverse kinematics computation with a global method, it is necessary to determine if moving the end-eﬀector to a given destination is feasible. Usually, numerical methods are used to compute an approximate solution of the system of polynomial equations, but this is only an approximation and another computation is required to verify the existence of the solution to the inverse kinematics problem. In fact, our previous implementation above has the problem of calculating approximate solutions without verifying the existence of the real solution to the inverse kinematics problem. We have focused on Comprehensive Gr¨obner Systems (CGS). CGS is a theory and method for computing Gr¨ obner bases for ideals of the polynomial ring, where generators of the ideal have parameters in their coeﬃcients. Gr¨ obner basis is computed in diﬀerent forms depending on constraints of parameters. In the system of polynomial equations given as an inverse kinematics problem, by expressing the coordinates of the end-eﬀector as parameters, then, by computing CGS from the polynomial system, we obtain the Gr¨ obner basis where the coordinates of the end-eﬀector are expressed in terms of parameters. When moving the robot, the coordinates of the end-eﬀector are substituted into the Gr¨ obner basis corresponding to the segment in which the coordinates satisfy constraints on the parameters, then solved the conﬁguration of the joints. This allows us to solve the system of polynomial equations immediately without computing Gr¨ obner basis when the robot is actually in motion. Furthermore, we have focused on quantiﬁer elimination with CGS (CGSQE) [6]. CGS-QE is a QE method based on CGS, and it is said to be eﬀective when the constraints have mainly equality constraints. When we use CGS to solve inverse kinematics problems for the above purposes, the CGS-QE method also allows us to verify the existence of a solution to the inverse kinematics prob-  
   
  Inverse Kinematics and Path Planning of Manipulator Using CGS-QE  
   
  395  
   
  lem. Then, if the given inverse kinematic problem is determined to be feasible, it is possible to immediately obtain a solution to the inverse kinematic problem without Gr¨ obner basis computation. With these motivations, we have proposed an inverse kinematics solver that veriﬁes the existence of a solution to the inverse kinematics problem by the CGSQE method, and eﬃciently ﬁnds a feasible solution using CGS [14]. Our solver uses “preprocessing steps [14, Algorithm 1]” to conﬁgure the solver before the startup of the manipulator, that is, we eliminate segments without real points and, if the input system is a non-zero dimensional ideal, we ﬁnd a trivial root that makes the input system zero-dimensional. Then, when the manipulator is running, the solver uses “main steps [14, Algorithm 2]” to determine the existence of feasible solutions and compute them. However, in the proposed algorithm, the preprocessing steps were performed manually. The main contribution of this paper is the extension of our previous solver [14] in two ways. The ﬁrst is that the computation of the preprocessing steps is completely automated. The procedures in the previous work were reﬁned into an algorithm that can be executed automatically. The second is the extension of the solver to path planning (trajectory planning) in two ways. Trajectory planning is a computation in which the path along which the manipulator (the end-eﬀector) is to be moved is given in advance, and the conﬁguration of the joints is determined at each time so that the position of the end-eﬀector changes as a function of time along that path. Trajectory planning also considers the manipulator’s kinematic constraints to determine the conﬁguration of the joints at each time. Our extension of the solver to trajectory planning is as follows. The ﬁrst method iteratively solves the inverse kinematics problem along a path using the proposed method described above. In the second method, the path is represented by a function of a parameter. Feasibility of the inverse kinematics problem is determined using the CGS-QE method within a given time range. It determines whether the entire trajectory falls within the manipulator’s feasible region before the manipulator moves. If the trajectory planning is feasible, we solve the inverse kinematics problem sequentially along the path. This paper is organized as follows. In Sect. 2, the inverse kinematics problem for the 3-DOF manipulator is formulated for the use of Gr¨ obner basis computation. In Sect. 3, CGS, CGS-QE method, and a method of real root counting are reviewed. In Sect. 4, an extension of a solver for inverse kinematics problem based on the CGS-QE method is proposed. In Sect. 5, trajectory planning methods based on the CGS-QE method are presented. In Sect. 6, conclusions and future research topics are discussed.  
   
  2  
   
  Inverse Kinematics of a 3-DOF Robot Manipulator  
   
  R In this paper, as an example of a 3-DOF manipulator, one built with LEGO R  1 MINDSTORMS EV3 Education (henceforth abbreviated to EV3) is used  
   
  1  
   
  LEGO and MINDSTORMS are trademarks of the LEGO Group.  
   
  396  
   
  M. Yoshizawa et al.  
   
  Fig. 1. A 3-DOF manipulator built with EV3.  
   
  Fig. 2. Components and the coordinate systems of the manipulator.  
   
  in (Fig. 1). The EV3 kit is equipped with large and small motors, optical, touch, gyro sensors, and a computer called “EV3 Intelligent Brick.” A GUI-based development environment is provided, and development environment with Python, Ruby, C, and Java are also available. The components of the manipulator is shown in Fig. 2. The manipulator has eight links (segments) and eight joints connected alternatively. A link ﬁxed to the bottom is called Link 0, and the other links are numbered as Link 1, . . . , 7 towards the end-eﬀector. For j = 1, . . . , 7, the joint connecting Links j − 1 and j is called Joint j. The foot of Link 0 on the ground is called Joint 0, and the end-  
   
  Inverse Kinematics and Path Planning of Manipulator Using CGS-QE  
   
  397  
   
  eﬀector is called Joint 8. Due to the circumstances of the appropriate coordinate transformation described below, Joints 1 and 2 overlap, and Link 1 does not exist either. (Note that by setting joint parameters appropriately, the consistency of coordinate transformation is maintained even for such a combination of links and segments.) Joints 1(= 2), 4, 7 are revolute joints, while the other joints are ﬁxed. At Joint i, according to a modiﬁed Denavit-Hartenberg convention [16], the coordinate system Σi is deﬁned as follows (Fig. 2). The origin is located at Joint i, and the xi , yi and zi axes are deﬁned as follows (in Fig. 2, the positive axis pointing upwards and downwards is denoted by “” and “⊗”, respectively): – The zj axis is chosen along with the axis of rotation of Joint j. – The xj−1 axis is selected along with the common normal to axes zj−1 to zj . – The yj axis is chosen so that the present coordinate system is right-handed. Note that the above deﬁnition of axes may have ambiguity. For the current manipulator, if the axes zi and zi−1 are parallel, there are inﬁnite ways to take the xi axis. Thus, in this case, the xi axis is deﬁned as follows. – In the coordinate system Σ0 , deﬁne the axes x0 , y0 , z0 like those in Σ1 as depicted in Fig. 2. Also, in the coordinate system Σ8 , deﬁne the axes x8 , y8 , z8 like those in Σ7 , respectively. – In the coordinate system Σi (i = 2, . . . , 7), since the origin is located on Joint i, deﬁne the xi axis to overlap Link i. For analyzing the motion of the manipulator, we deﬁne a map between the joint space and the configuration space or operational space. For a joint space, since we have revolute joints 1, 4, 7, their angles θ1 , θ4 , θ7 , respectively, are located in a circle S 1 , we deﬁne the joint space as J = S 1 × S 1 × S 1 . For a conﬁguration space, let (x, y, z) be the end-eﬀector position located in R3 and then deﬁne the conﬁguration space as C = R3 . Thus, we consider a map f : J −→ C. The forward kinematic problem is to ﬁnd the position of the end-eﬀector in C for the given conﬁguration of the joints in J , while the inverse kinematic problem is to ﬁnd the conﬁguration of the joints in J which enables the given position of the end-eﬀector in C. We ﬁrst solve the forward kinematic problem for formulating the inverse kinematic problem. Let ai be the distance between axes zi−1 and zi , αi the angle between axes zi−1 and zi with respect to the xi axis, di the distance between the axes xi−1 and xi , and θi be the angle between the axes xi−1 and xi with respect to the zi axis. Then, the coordinate transformation matrix i−1 Ti from the coordinate system Σi to Σi−1 is expressed as in Fig. 3. where the joint parameters ai , αi , di and θi are shown in Table 1 (note that the unit of ai and di is [mm]). The transformation matrix T from the coordinate system Σ8 to Σ0 is calculated as T = 0 T1 1 T2 2 T3 3 T4 4 T5 5 T6 6 T7 7 T8 , where i−1 Ti is expressed as in Fig. 4.  
   
  398  
   
  M. Yoshizawa et al.  
   
  Fig. 3. The transformation matrix  
   
  i−1  
   
  Ti .  
   
  Table 1. Joint parameters for EV3. i ai (mm) αi  
   
  di (mm) θi  
   
  1  
   
  80  
   
  0  
   
  0  
   
  θ1  
   
  2  
   
  0  
   
  π/2  
   
  0  
   
  π/4  
   
  3  
   
  88  
   
  0  
   
  0  
   
  π/4  
   
  4  
   
  24  
   
  0  
   
  0  
   
  θ4  
   
  5  
   
  96  
   
  0  
   
  0  
   
  −π/2  
   
  6  
   
  16  
   
  0  
   
  0  
   
  π/2  
   
  7  
   
  40  
   
  0  
   
  0  
   
  θ7  
   
  8 120  
   
  0  
   
  0  
   
  0  
   
  Then, the position (x, y, z) of the end-eﬀector with respect to the coordinate system Σ0 is expressed as x = −120 cos θ1 cos θ4 sin θ7 + 16 cos θ1 cos θ4 − 120 cos θ1 sin θ4 cos θ7 √ − 136cosθ1 sinθ4 + 44 2 cos θ1 , y = −120 sin θ1 cos θ4 sin θ7 + 16 sin θ1 cos θ4 − 120 sin θ1 sin θ4 cos θ7 √ − 136 sin θ1 sin θ4 + 44 2 sin θ1 ,  
   
  (1)  
   
  √ z = 120 cos θ4 cos θ7 + 136cosθ4 − 120 sin θ4 sin θ7 + 16sinθ4 + 104 + 44 2.  
   
  The inverse kinematics problem comes down to solving (1) for θ1 , θ4 , θ7 . By substituting trigonometric functions cos θi and sin θi with variables as ci = cos θi , si = sin θi , subject to c2i + s2i = 1, (1) is transferred to a system of polynomial equations: √ f1 = 120c1 c4 s7 − 16c1 c4 + 120c1 s4 c7 + 136c1 s4 − 44 2c1 + x = 0, √ f2 = 120s1 c4 s7 − 16s1 c4 + 120s1 s4 c7 + 136s1 s4 − 44 2s1 + y = 0, (2) √ f3 = −120c4 c7 − 136c4 + 120s4 s7 − 16s4 − 104 − 44 2 + z = 0, f4 = s21 + c21 − 1 = 0,  
   
  f5 = s24 + c24 − 1 = 0,  
   
  f6 = s27 + c27 − 1 = 0.  
   
  Inverse Kinematics and Path Planning of Manipulator Using CGS-QE  
   
  Fig. 4. The transformation matrix  
   
  3  
   
  i−1  
   
  399  
   
  Ti (i = 1, . . . , 8).  
   
  Real Quantifier Elimination Based on CGS  
   
  Equations (1) and (2) show that solving the inverse kinematic problem for the given system can be regarded as a real quantiﬁer elimination of a quantiﬁed formula ∃c1 ∃s1 ∃c4 ∃s4 ∃c7 ∃s7 (f1 = 0 ∧ f2 = 0 ∧ f3 = 0 ∧ f4 = 0 ∧ f5 = 0 ∧ f6 = 0),  
   
  (3)  
   
  with x, y, z as parameters. In this section, we brieﬂy review an algorithm of real quantiﬁer elimination based on CGS, the CGS-QE algorithm, by Fukasaku et al. [6]. Two main tools play a crucial role in the algorithm: one is CGS, and another is real root counting, or counting the number of real roots of a system of polynomial equations. Note that, in this paper, we only consider equations in the quantiﬁed formula. Hereafter, let R be a real closed ﬁeld, C be the algebraic closure of R, and K be a computable subﬁeld of R. This paper considers R as the ﬁeld of real numbers R, C as the ﬁeld of complex numbers C, and K as the ﬁeld of rational ¯ and A¯ denote variables X1 , . . . , Xn and A1 , . . . , Am , respecnumbers Q. Let X ¯ ¯ tively, and T (X) be the set of the monomials which consist of variables in X. ¯ For an ideal I ⊂ K[X], let VR (I) and VC (I) be the aﬃne varieties of I in R ¯ ∈ I: f (¯ c ∈ Rn | ∀f (X) c) = 0} and or C, respectively, satisfying that VR (I) = {¯ n ¯ c ∈ C | ∀f (X) ∈ I: f (¯ c) = 0}. VC (I) = {¯ 3.1  
   
  CGS  
   
  For the detail and algorithms on CGS, see Fukasaku et al. [6] or references therein. In this paper, the following notation is used. Let be an admissible ¯ X] ¯ with a term order on T (X), ¯ we term order. For a polynomial f ∈ K[A, ¯ ¯ ¯ regard f as a polynomial in (K[A])[X], which is the ring of polynomials with X ¯ ¯ as variables and coeﬃcients in (K[A]) such that A is regarded as parameters.  
   
  400  
   
  M. Yoshizawa et al.  
   
  ¯ < (f ), LC(f ) and LM(f ) denotes the leading Given a term order on T (X), term, the leading coeﬃcient, and the leading monomial, respectively, satisfying ¯ and LM ∈ T (X) ¯ (we follow the that < (f ) = LC(f )LM(f ) with LC(f ) ∈ K[A] notation by Cox et al. [4]). Definition 1 (Algebraic Partition and Segment). Let S ⊂ C m for m ∈ N. A finite set {S1 , . . . , St } of nonempty subsets of S is called an algebraic partition of S if it satisfies the following properties: t 1. S = k=1 Sk . 2. For k = j ∈ {1, . . . , t}, Sk ∩ Sj = ∅. 3. For k ∈ {1, . . . , t}, Sk is expressed as Sk = VC (I1 ) \ VC (I2 ) for some ideals ¯ I1 , I2 ⊂ K[A]. Furthermore, each Sk is called a segment. Definition 2 (Comprehensive Gr¨ obner System (CGS)). Let S ⊂ C m ¯ ¯ X], ¯ a finite set and be a term order on T (X). For a finite subset F ⊂ K[A, obner System (CGS) G = {(S1 , G1 ), . . . , (St , Gt )} is called a Comprehensive Gr¨ of F over S with parameters A¯ with respect to if it satisfies the following: ¯ X]. ¯ 1. For k ∈ {1, . . . , t}, Gk is a finite subset of K[A, 2. The set {S1 , . . . , St } is an algebraic partition of S. ¯ = {g(¯ ¯ | g(A, ¯ X) ¯ ∈ Gk } is a Gr¨ c, X) c, X) obner basis 3. For each c¯ ∈ Sk , Gk (¯ ¯ ¯ ¯ = {f (¯ ¯ | of the ideal F (¯ c, X) ⊂ C[X] with respect to , where F (¯ c, X) c, X) ¯ ¯ f (A, X) ∈ F }.   c) = 0. 4. For each c¯ ∈ Sk , any g ∈ Gk satisfies that LC(g) (¯ ¯ is a minimal or the reduced Gr¨ c, X) obner basis, G is Furthermore, if each Gk (¯ called a minimal or the reduced CGS, respectively. In the case S = C m , the words “over S” may be omitted. 3.2  
   
  Real Root Counting  
   
  ¯ be a zero-dimensional ideal. Then, the quotient ring K[X]/I ¯ Let I ⊂ K[X] is regarded as a ﬁnite-dimensional vector space over K [3]; let {v1 , . . . , vd } be its ¯ basis. For h ∈ K[X]/I and i, j satisfying 1 ≤ i, j ≤ d, let θh,i,j be a linear transformation deﬁned as  
   
  f  
   
  ∈  
   
  ∈  
   
  ¯ ¯ θh,i,j : K[X]/I −→ K[X]/I → hvi vj f.  
   
  Let qh,i,j be the trace of θh,i,j and MhI be a symmetric matrix such that its (i, j)th element is given by qh,i,j . Let χIh (X) be the characteristic polynomial of MhI , and σ(MhI ), called the signature of MhI , be the number of positive eigenvalues of MhI minus the number of negative eigenvalues of MhI . Then, we have the following theorem on the real root counting [1,15].  
   
  Inverse Kinematics and Path Planning of Manipulator Using CGS-QE  
   
  401  
   
  Theorem 1 (The Real Root Counting Theorem). We have σ(MhI ) = #({¯ c ∈ VR (I) | h(¯ c) > 0}) − #({¯ c ∈ VR (I) | h(¯ c) < 0}). Corollary 1. σ(M1I ) = #(VR (I)). Since we only consider a quantiﬁed formula with equations, as in (3), we omit properties of the real root counting related to quantiﬁer elimination of quantiﬁed formula with inequalities or inequations (for detail, see Fukasaku et al. [6]). 3.3  
   
  CGS-QE Algorithm  
   
  The CGS-QE algorithm accepts the following quantiﬁed formula given as ¯ 1 (A, ¯ X) ¯ = 0 ∧ · · · ∧ fμ (A, ¯ X) ¯ = 0 ∧ p1 (A, ¯ X) ¯ > 0 ∧ · · · ∧ pν (A, ¯ X) ¯ > 0∧ ∃X(f ¯ ¯ ¯ ¯ q1 (A, X) = 0 ∧ · · · ∧ qξ (A, X) = 0), ¯ X] ¯ \ Q[A], ¯ f1 , . . . , fμ , p1 , . . . , pν , q1 , . . . , qξ ∈ Q[A, then outputs an equivalent quantiﬁer-free formula. Note that, in this paper, we give a quantiﬁed formula only with equations as shown in (3). The algorithm is divided into several algorithms. The main algorithm is called MainQE, and sub-algorithms are called ZeroDimQE and NonZeroDimQE for the case that the ideal generated by the component of the CGS is zero-dimensional or positive dimensional, respectively. (For a complete algorithm description, see Fukasaku et al. [6]). In the real root counting, we need to calculate σ(MhI ) as in Sect. 3.2. This calculation is executed using the following property [22] derived from Descartes’ rule of signs. Let M be a real symmetric matrix of dimension d and χ(X) be the characteristic polynomial of M of degree d, expressed as χ(λ) = λd + ad−1 λd−1 + . . . + a0 , χ(−λ) = (−1)d λd + bd−1 λd−1 + . . . + b0 .  
   
  (4)  
   
  Note that b = a if  is even, and b = −a if  is odd. Let Lχ+ and Lχ− be the sequence of the coeﬃcients in χ(λ) and χ(−λ), deﬁned as Lχ+ = (1, ad−1 , . . . , a0 ),  
   
  Lχ− = ((−1)d , bd−1 , . . . , b0 ),  
   
  (5)  
   
  ¯ χ− be the sequences deﬁned by remov¯ χ+ and L respectively. Furthermore, let L ing zero coeﬃcients in Lχ+ and Lχ− , respectively, and let ¯ χ+ ), Sχ+ = (the number of sign changes in L ¯ χ− ). Sχ− = (the number of sign changes in L  
   
  (6)  
   
  Then, we have the following. Lemma 1. Let Sχ+ and Sχ− be defined as in (6). Then, we have Sχ+ = #({c ∈ R | c > 0 ∧ χ(c) = 0}), Sχ− = #({c ∈ R | c < 0 ∧ χ(c) = 0}).  
   
  402  
   
  M. Yoshizawa et al.  
   
  Corollary 2. Let Sχ+ and Sχ− be defined as in (6), and I be a zero-dimensional ideal and M1I be a matrix defined as in Sect. 3.2. Then, we have #(VR (I)) = σ(M1I ) ⇔ Sχ+ = Sχ− .  
   
  (7)  
   
  Remark 1. As shown below, most of our inverse kinematic computation uses up to the real root counting part of the CGS-QE algorithm. The part of the algorithm that eliminates quantiﬁed variables and obtains conditions on the parameters is used only to verify the feasibility of the inverse kinematic solution for the given path (see Sect. 5.2).  
   
  4  
   
  Solving the Inverse Kinematic Problem  
   
  This section shows a method for solving the inverse kinematic problem in (2). Speciﬁcally, for the coordinates of the end-eﬀector that are given as (x, y, z) = (x0 , y0 , z0 ) ∈ R3 , determine the feasibility of the conﬁguration of the end-eﬀector with the CGS-QE method. If the conﬁguration of the end-eﬀector is feasible, then compute c1 , s1 , c4 , s4 , c7 , s7 by solving (2), and compute the angle θ1 , θ4 , θ7 of Joint 1, 4, 7, respectively, as θ1 = arctan(s1 /c1 ), θ4 = arctan(s4 /c4 ), θ7 = arctan(s7 /c7 ).  
   
  (8)  
   
  The computation is executed as follows, summarized as Algorithm 1. For ¯ = (c1 , s1 , c4 , s4 , c7 , s7 ) parameters Algorithm 1, f1 , . . . , f6 in (2), variables X A¯ = (x, y, z), and a position of the end-eﬀector p = (x0 , y0 , z0 ) are given. (For optional arguments, see Remark 3). ¯ X] ¯ with an appropriate monomial order. 1. Compute CGS of f1 , . . . , f6  ⊂ R[A, Let (9) F = {(S1 , G1 ), . . . , (St , Gt )} be the computed CGS. Assume that the segment Sk is represented as Sk = VC (Ik,1 ) \ VC (Ik,2 ),  
   
  Ik,1 = Fk,1 ,  
   
  Ik,2 = Fk,2 ,  
   
  (10)  
   
  ¯ where Fk,1 , Fk,2 ⊂ R[A]. 2. From F, eliminate (S, G) ∈ F satisfying that S ∩ R3 = ∅ and that are easily detected. Re-arrange indices as F  = {(S1 , G1 ), . . . , (St , Gτ )}. See Sect. 4.1 for detail. 3. For (x0 , y0 , z0 ), choose (Sk , Gk ) ∈ F  satisfying that (x0 , y0 , z0 ) ∈ Sk . Let G = {g1 , . . . , gρ },  
   
  (11)  
   
  be Gk with substituting (x0 , y0 , z0 ) for (x, y, z). 4. For G in (11), determine if G is zero-dimensional. For the case G is not zero-dimensional, see Sect. 4.3.  
   
  Inverse Kinematics and Path Planning of Manipulator Using CGS-QE  
   
  403  
   
  Algorithm 1. Solving the inverse kinematic problem Input: F = {f1 , . . . , f6 }: (2) for the inverse kinematic problem, V = {c1 , s1 , c4 , s4 , c7 , s7 }: variables, P = {x, y, z}: parameters, p = (x0 , y0 , z0 ): a position of the end-eﬀector to be placed, F (optional): a CGS of F  or the output of Generate-Real-CGS(F ,P) (Algorithm 2) where F is a CGS of F , RealCGS = {TRUE | FALSE} (optional): whether one wish to call Generate-Real-CGS (Algorithm 2) or not; Output: Θ = {θ1 , θ4 , θ7 }: joint angles of a solution of the inverse kinematic problem, or Θ = ∅ if there are no solution or an inﬁnite number of solutions; 1: function Solve-IKP-Point(F , V, P, p, F , RealCGS) 2: if F = ∅ then 3: Compute a CGS of F  as F = {(S1 , G1 ), . . . , (St , Gt )}; 4: end if 5: if RealCGS = TRUE then  See Sect. 4.1 (Algorithm 2) 6: F  ← Generate-Real-CGS(F , V); 7: else F  ← F; 8: end if 9: Choose (Sk , Gk ) from the CGS F  satisfying p ∈ Sk ; 10: G ← {g ∈ G | x ← x0 , y ← y0 , z ← z0 in g}  See Sect. 4.2 (Algorithm 4) 11: σ ← Count-Real-Roots(G ); 12: if σ = “FAIL” then  See Sect. 4.3 (Algorithm 5) 13: Θ ← Solve-IKP-NonZeroDim(G ); 14: else if σ = 0 then Θ ← ∅; 15: else 16: S ← (real solutions of g1 = · · · = gρ = 0 in (12)); 17: Θ ← (joint angles obtained by (8)); 18: end if 19: return Θ; 20: end function  
   
  5. If G is zero-dimensional, calculate the number of real roots of g1 = · · · = gρ = 0.  
   
  (12)  
   
  See Sect. 4.2 for detail. 6. If the system of polynomial equations (12) has real roots, calculate approximate roots with a numerical method. If the system has more than one set of real roots, we accept the ﬁrst set of roots that the solver returns. 7. By (8), calculate joint angles θ1 , θ4 , θ7 . Remark 2. We see that Algorithm 1 outputs Θ = {θ1 , θ4 , θ7 } or Θ = ∅ correctly, as follows. After computing the CGS F, some segments without real points are eliminated optionally, resulting in F  . Then, a pair of a segment and the accompanying Gr¨ obner basis (Sk , Gk ) is chosen, satisfying that p ∈ Sk . After deﬁning G by substituting parameters (x, y, z) in g ∈ G with p, The number of real roots of polynomial equations {g  = 0 | g  ∈ G } is counted by Algorithm 4, and it returns σ. In the case σ = 0, this means that there are no real roots in  
   
  404  
   
  M. Yoshizawa et al.  
   
  {g  = 0 | g  ∈ G }, thus ∅ is output. In the case σ = “FAIL”, G is investigated by Algorithm 5 and a value of ∅ or Θ is returned, which becomes the output of this algorithm. Finally, in the case σ > 0, real solutions of {g  = 0 | g  ∈ G } are calculated as Θ, which becomes the output of this algorithm. This ﬁnishes the computation. Remark 3. In Algorithm 1, it is also possible to calculate the GCS F or F  (in which some segments without real points are eliminated) ﬁrst and then given to the algorithm. The arguments F and RealCGS in the function Solve-IKPPoint are optional. Furthermore, if F  is given to Solve-IKP-Point, the variable RealCGS is set TRUE. Pre-computing the CGS before executing Algorithm 1 would make the algorithm more eﬃcient, especially when repeatedly solving the same problem (see Example 2). 4.1  
   
  Removing a Segment Not Existing in R3  
   
  In the inverse kinematic problem, since the parameters consist of x, y, z in (2), the segments in the algebraic partition corresponding to the CGS F in (9) exist in C3 . However, since only real values of x, y, z are used in solving the inverse kinematic problem, if a segment Sk in (10) do not exist in R3 , then it can be ignored. Thus, by investigating generators in Fk,1 and Fk,2 in (10), we remove some Sk that satisﬁes Sk ∩ R3 = ∅ and that is easily detected, as follows, summarized as Algorithm 2. 1. Let f ∈ Fk,1 . If f is a univariate polynomial and deg f = 2, calculate the discriminant disc(f ) of f . If disc(f ) < 0, then remove (Sk , Gk ). 2. If f is a univariate polynomial and deg f ≥ 3, calculate the number of real roots of f by the Sturm’s method. If the number of real roots of f is equal to 0, then remove (Sk , Gk ). 3. Let (x0 , y0 , z0 ) be a root of f ∈ Fk,1 as many coordinates as possible are 0. Assume that there exists f0 ∈ Fk,1 with only the real root (x0 , y0 , z0 ) (for detecting f0 satisfying this property, see below). 4. If there exists g ∈ Fk,1 satisfying that g(x0 , y0 , z0 ) is a nonzero constant, then we see that (x0 , y0 , z0 ) ∈ Sk ∩ R3 , thus remove (Sk , Gk ). 5. If all h ∈ Fk,2 satisﬁes h(x0 , y0 , z0 ) = 0, then we see that (x0 , y0 , z0 ) ∈ Sk ∩ R3 , thus remove (Sk , Gk ). In Step 3 above, we ﬁnd (x0 , y0 , z0 ), a root of f ∈ Fk,1 as many coordinates as possible are 0, along with f0 which has (x0 , y0 , z0 ) only the real root, as follows. For the purpose, we ﬁnd f with the terms of the degree with respect to each parameter x, y, z is even, expressed as  ap,q,r x2p y 2q z 2r , a ∈ R, ap,q,r = 0. (13) f =a+ (p,q,r)∈Z3≥0 \{(0,0,0)}  
   
  We see that f of the form as in (13) may have the following property.  
   
  Inverse Kinematics and Path Planning of Manipulator Using CGS-QE  
   
  405  
   
  Algorithm 2. Removing a segment which does not exist in R3 Input: F = {(S1 , G1 ), . . . , (St , Gt )}: a CGS, P: parameters Output: F  = {(S1 , G1 ), . . . , (Sτ , Gτ )}: a CGS with organized numbering in which segments those do not exist in R3 are removed; 1: function Generate-Real-CGS(F , P) 2: Undecided ← True; 3: for each (S, G) ∈ F do 4: (x0 , y0 , z0 ) ← (x, y, z); 5: for each f ∈ F1 where S = VC (I1 ) \ VC (I2 ), I1 = F1  and I2 = F2  do 6: if f is a univariate polynomial then 7: if deg f ≥ 3 then 8: #RealRoots ← (the number of reall roots of f computed with the Sturm’s method); 9: if #RealRoots = 0 then Undecided ← False; break; 10: end if 11: else if deg f = 2 then 12: if disc(f ) = 0 then Undecided ← False; break; 13: end if 14: end if 15: else (x0 , y0 , z0 ) ← Find-Trivial-Roots(f, (x0 , y0 , z0 ));  Algorithm 3 16: if (x0 , y0 , z0 ) = ∅ then Undecided ← False; break; 17: end if 18: end if 19: end for 20: if (x0 , y0 , z0 ) = ∅ then Undecided ← False; 21: else 22: for each g ∈ F1 do 23: if g(x0 , y0 , z0 ) is a nonzero constant then Undecided ← False; break; 24: end if 25: end for 26: if for all g ∈ F2 g(x0 , y0 , z0 ) = 0 then Undecided ← False; 27: end if 28: end if 29: if Undecided = True then F  ← F  ∪ {(S, G)}; 30: end if 31: end for 32: Renumber indices of (S, G) in F  as F  = {(S1 , G1 ), . . . , (Sτ , Gτ )}; 33: return F  34: end function  
   
  1. If a = 0 and the signs of a and ap,q,r (ap,q,r = 0) are the same, then f does not have a real root. 2. If a = 0 and the signs of a and ap,q,r (ap,q,r = 0) are the same, then f has a root that the parameters appearing in f equals 0. Let (x0 , y0 , z0 ) be (x, y, z) with the variable appearing in f set to 0. Example 1. Examples of polynomials of the form as in (13) satisfying properties in above.  
   
  406  
   
  M. Yoshizawa et al.  
   
  Algorithm 3. Find a roots as many coordinates as possible are 0 ¯ (x0 , y0 , z0 ): x0 ∈ {x, 0}, y0 ∈ {y, 0}, z0 ∈ {z, 0}; Input: f ∈ R[A], Output: (x0 , y0 , z0 ): x0 ∈ {x, 0}, y0 ∈ {y, 0}, z0 ∈ {z, 0} or ∅; 1: function Find-Trivial-Roots(f , (x0 , y0 , z0 )) 2: if f is expressed as in (13) then 3: if a = 0 then 4: if the signs of a and ap,q,r are the same then (x0 , y0 , z0 ) ← ∅; 5: end if 6: else if the signs of a and ap,q,r are the same then 7: if x appears in f then x0 ← 0 8: else if y appears in f then y0 ← 0 9: else if z appears in f then z0 ← 0 10: end if 11: end if 12: end if 13: return (x0 , y0 , z0 ); 14: end function  
   
  1. A polynomial with a = 0 and the signs of a and ap,q,r (ap,q,r = 0) are the same: f1 (x, y, z) = 2x2 y 4 + z 2 + 3 = 0 does not have a real root. 2. A polynomial with a = 0 and the signs of a and ap,q,r (ap,q,r = 0) are the same: f2 (x, y, z) = −2x2 y 4 − z 2 = 0 has a trivial real root x = y = z = 0. By Algorithm 3, we ﬁnd a polynomial that has no real roots or f0 that has only the real root (x0 , y0 , z0 ) with as many coordinates as possible are 0. Remark 4. We see that Algorithm 3 ﬁnds a polynomial of the form of (13) that has no real roots or f0 that has only the real root (x0 , y0 , z0 ) with as many coordinates as possible are 0, as follows. If f is the form of (13) with a = 0, investigate if signs of a and the other non-zero coeﬃcients are the same. If the signs are the same, f does not have a real root, and the algorithm returns ∅. On the other hand, if f is the form of (13) with a = 0 and signs of the other non-zero coeﬃcients are the same, f has a unique root with x = 0, y = 0 or z = 0. Then, x0 , y0 or z0 are replaced with 0 if corresponding variables appears in f . Remark 5. We see that Algorithm 2 outputs a CGS F with some segments without real points eliminated, as follows. Let Sk , Ik,1 , Ik,2 , Fk,1 and Fk,2 be as in (10). If f ∈ Fk,1 is a univariate polynomial, real roots are counted using the discriminant (if deg f = 2) or Sturm’s method (if deg f ≥ 3). Thus, if f is a univariate polynomial with no real toot, then Sk has no real point. Next, for f ∈ Fk,1 expressed as in (13), Algorithm 3 reports that there exists f ∈ Fk,1 that does not have a real root or ﬁnds a root (x0 , y0 , z0 ) with as many coordinates as possible are 0. 1. If f ∈ Fk,1 has no real root, then Sk has no real point.  
   
  Inverse Kinematics and Path Planning of Manipulator Using CGS-QE  
   
  407  
   
  Algorithm 4. Calculating the number of real roots [6] Input: G: a Gr¨ obner basis as in (11) Output: σ: the number of real roots of {g = 0 | g ∈ G}; In the case G is not zero-dimensional, return σ = “FAIL”; 1: function Count-Real-Roots(G) 2: if G is zero-dimensional then G  Calculated by Corollary 1 3: σ ← σ(M1 ); 4: else σ ← “FAIL”;  See Sect. 4.3 5: end if 6: return σ; 7: end function  
   
  2. If there exists a root (x0 , y0 , z0 ) with as many coordinates as possible are 0, since the form of the input polynomial in Algorithm 3 is as in (13), we see that (x0 , y0 , z0 ) is a root of f0 ∈ Fk,1 that has no other real roots. We examine if (x0 , y0 , z0 ) ∈ Sk = VC (Ik,1 ) \ VC (Ik,2 ). If there exists g ∈ Fk,1 satisfying that g(x0 , y0 , z0 ) is a nonzero constant, then (x0 , y0 , z0 ) ∈ VC (Ik,1 ), thus (x0 , y0 , z0 ) ∈ Sk . Futhermore, if all h ∈ Fk,2 satisﬁes h(x0 , y0 , z0 ) = 0, (x0 , y0 , z0 ) ∈ VC (Ik,2 ), thus (x0 , y0 , z0 ) ∈ Sk . Remark 6. Even without Algorithm 2, it is possible to eventually remove segments that do not have a real point in Algorithm 1. However, it may be possible to improve the eﬃciency of solving the inverse kinematic problem while iterating Algorithm 1 by providing a CGS that has previously removed segments that do not have real number points using Algorithm 2 (see Example 2). 4.2  
   
  Calculating the Number of Real Roots  
   
  Calculating the number of real roots in (2) is based on Algorithm MainQE in the CGS-QE method [6]. While the original algorithm computes constraints on parameters such that the equations have a real root, the parameters are substituted with the coordinates of the end-eﬀector, thus the number of real roots is calculated as follows, summarized as Algorithm 4. 1. Let G be the Gr¨ obner basis G in (11). Determine if G is zero-dimensional. If G is not zero-dimensional, apply computation in Sect. 4.3. G 2. Calculate a real symmetric matrix M1 (for its deﬁnition, see Sect. 3.2). 3. By Corollary 1, calculate the number of real roots of {g = 0 | g ∈ G} by G calculating σ(M1 ). Remark 7. For a Gr¨ obner basis G, we see that Algorithm 4 counts the number of real roots of {g = 0 | g ∈ G} if G is zero-dimensional. If G is zerodimensional, then the number of real roots is calculated by Corollary 1. On the other hand, G is not zero-dimensional, it returns “FAIL”.  
   
  408  
   
  4.3  
   
  M. Yoshizawa et al.  
   
  Calculation for Non-Zero Dimensional Ideals  
   
  Our previous studies [14] have shown that, for G in (11), there exists a case that G is not zero-dimensional. In the case x0 = y0 = 0, c21 + s21 − 1 ∈ G and the corresponding segment S satisﬁes S = VC (I1 ) \ VC (I2 ), I1 = x, y. (Note that, in this case, the segment S is diﬀerent from the one in which the most feasible endeﬀector positions exist.) This means that the points in VR (I1 ) satisfy x = y = 0, and the end-eﬀector is located on the z-axis in the coordinate system Σ0 . In this case, θ1 , the angle of Joint 1 is not uniquely determined. Then, by putting θ1 = 0 (i.e., c1 = 1, s1 = 0) in g ∈ G, we obtain a new system of polynomial equations G which satisﬁes that G  is zero-dimensional, and, by solving a new system of polynomial equations {g  = 0 | g  ∈ G }, a solution to the inverse kinematic problem is obtained. Based on the above observations, for G in (11), in the case, G is not zerodimensional, we perform the following calculation, summarized as Algorithm 5. 1. It is possible that G has a polynomial g0 = s21 + c21 − 1. If such g0 exists, deﬁne G = {g ∈ G \ {g0 } | substitute s1 ← 1 and c1 ← 0 in g}. 2. For newly deﬁned G , apply Algorithm 4 for testing if G is zero-dimensional. If G is zero-dimensional, calculate the number of real roots of the system of equations (14) g1 = · · · = gρ = 0, where g1 , . . . , gρ ∈ G. 3. If the number of real roots of (14) is positive, then compute approximate real roots and put then into Θ. Remark 8. For a Gr¨ obner basis G of non-zero dimensional ideal, we see that Algorithm 5 outputs Θ = {θ1 , θ4 , θ7 } or Θ = ∅ correctly, as follows. G is calculated as G = {g ∈ G | g = s21 + c21 − 1}. Then, for g  ∈ G , s1 ← 0 and c1 ← 1. The number of real roots of polynomial equations {g  = 0 | g  ∈ G } is counted by Algorithm 4, and it returns σ. In the case σ = 0, this means that there are no real roots in {g  = 0 | g  ∈ G }, thus ∅ is output. In the case σ = “FAIL”, further computation is cancelled and ∅ is output. Finally, in the case σ > 0, real solutions of {g  = 0 | g  ∈ G } are calculated as Θ, which becomes the output of this algorithm. Remark 9. Note that Algorithms 2, 3 and 5 correspond to “preprocessing steps (Algorithm 1)” in our previous solver [14]. In our previous solver, except for the computation of the CGS, “the rest of computation was executed by hand”[14, Sect. 4].  
   
  Inverse Kinematics and Path Planning of Manipulator Using CGS-QE  
   
  409  
   
  Algorithm 5. Computing real roots for non-zero dimensional ideal Input: G: a Gr¨ obner basis of non-zero dimensional ideal Output: Θ = {θ1 , θ4 , θ7 }: joint angles of a solution of the inverse kinematic problem, or Θ = ∅ if there are no solution or an inﬁnite number of solutions; 1: function Solve-IKP-NonZeroDim(G) 2: G ← ∅; 3: for each g ∈ G do 4: if g = s21 + c21 − 1 then G ← G ∪ {g}; 5: end if 6: end for 7: for each g  ∈ G do s1 ← 1; c1 ← 0; 8: end for  See Sect. 4.2 (Algorithm 4) 9: σ ← Count-Real-Roots(G ); 10: if σ = 0 or “FAIL” then Θ ← ∅; 11: else 12: S ← (real solutions of {g  = 0 | g ∈ G }); 13: Θ ← (joint angles obtained by (8)); 14: end if 15: return Θ; 16: end function  
   
  4.4  
   
  Experiments  
   
  We have implemented and tested the above inverse kinematics solver [18]. An implementation was made on the computer algebra system Risa/Asir [13]. Computation of CGS was executed with the implementation by Nabeshima [12]. The computing environment is as follows: Intel Xeon Silver 4210 3.2 GHz, RAM 256 GB, Linux Kernel 5.4.0, Risa/Asir Version 20230315. Test sets for the end-eﬀector’s position were the same as those used in the tests of our previous research [7,14]. The test sets consist of 10 sets of 100 random end-eﬀector positions within the feasible region; thus, 1000 random points were given. The coordinates of the position were given as rational numbers with the magnitude of the denominator less than 100. For solving a system of polynomial equations numerically, computer algebra system PARI-GP 2.3.11 [19] was used in the form of a call from Risa/Asir. In the test, we have used pre-calculated CGS of (2) (originally, to be calculated in Line 3 of Algorithm 1). The computing time of CGS was approximately 62.3 s. Table 2 shows the result of experiments. In each test, ‘Time’ is the average computing time (CPU time), rounded at the 5th decimal place. ‘Error’ is the average of the absolute error, or the 2-norm distance of the end-eﬀector from the randomly given position to the calculated position with the conﬁguration of the computed joint angles θ1 , θ4 , θ7 . The bottom row, ‘Average’ shows the average values in each column of the 10 test sets. The average error of the solution was approximately 1.63 × 10−12 [mm]. Since the actual size of the manipulator is approximately 100 [mm], computed solutions with the present method seem suﬃciently accurate. Comparison with  
   
  410  
   
  M. Yoshizawa et al. Table 2. A result of inverse kinematics computation. Test  
   
  Time (sec.) Error (mm)  
   
  1 2 3 4 5 6 7 8 9 10  
   
  0.1386 0.1331 0.1278 0.1214 0.1147 0.1004 0.0873 0.0792 0.0854 0.0797  
   
  1.2428 × 10−12 2.3786 × 10−12 1.0845 × 10−12 1.6150 × 10−12 1.5721 × 10−12 1.6229 × 10−12 2.2518 × 10−12 1.3923 × 10−12 1.2919 × 10−12 1.8674 × 10−12  
   
  Average 0.1068  
   
  1.6319 × 10−12  
   
  data in our previous research shows that the current result is more accurate than our previous result (1.982×10−9 [mm] [14] and 4.826×10−11 [mm] [7]). Note that the software used for solving equations in the current experiment diﬀers from the one used in our previous experiments; this could have aﬀected the results. The average computing time for solving the inverse kinematic problem was approximately 100 [ms]. Comparison with data in our previous research shows that the current result is more eﬃcient than our previous result (540 [ms] [14] and 697 [ms] [7], measured in the environment of Otaki et al. [14]). However, systems designed for real-time control using Gr¨ obner basis computation have achieved computation times of 10 [ms] order [20,21]. Therefore, our method may have room for improvement (see Sect. 6).  
   
  5  
   
  Path and Trajectory Planning  
   
  In this section, we propose methods for path and trajectory planning of the manipulator based on the CGS-QE method. In path planning, we calculate the conﬁguration of the joints for moving the position of the end-eﬀector along with the given path. In trajectory planning, we calculate the position (and possibly its velocity and acceleration) of the endeﬀector as a function of time series depending on constraints on the velocity and acceleration of the end-eﬀector and other constraints. In Sect. 5.1, we make a trajectory of the end-eﬀector to move it along a line segment connecting two diﬀerent points in R3 with considering constraints on the velocity and acceleration of the end-eﬀector. Then, by the repeated use of inverse kinematics solver proposed in Sect. 4, we calculate a series of conﬁguration of the joints. In Sect. 5.2, for the path of a line segment expressed with a parameter, we verify that by using the CGS-QE method, moving the end-eﬀector along  
   
  Inverse Kinematics and Path Planning of Manipulator Using CGS-QE  
   
  411  
   
  the path is feasible for a given range of the parameter, then perform trajectory planning as explained in the previous subsection. 5.1  
   
  Path and Trajectory Planning for a Path Expressed as a Function of Time  
   
  Assume that the end-eﬀector of the manipulator moves along a line segment from the given initial to the ﬁnal position as follows. – pd = t (x, y, z): current position of the end-eﬀector, – p0 = t (x0 , y0 , z0 ): the initial position of the end-eﬀector, – pf = t (xf , yf , zf ): the ﬁnal position of the end-eﬀector, where pd , p0 , pf ∈ R3 and x0 , y0 , z0 , xf , yf , zf are constants satisfying x0 = xf , y0 = yf , z0 = zf . Then, with a parameter s ∈ [0, 1], pd is expressed as pd = p0 (1 − s) + pf s.  
   
  (15)  
   
  Note that the initial position p0 and the ﬁnal position pf corresponds to the case of s = 0 and 1 in (15), respectively. Then, we change the value of s with a series of time t. Let T be a positive integer. For t ∈ [0, T ], set s as a function of t as s = s(t) satisfying that s ∈ [0, 1]. Let s˙ and s¨ be the ﬁrst and the second derivatives of s, respectively. (Note that s˙ and s¨ corresponds to the speed and the acceleration of the end-eﬀector, respectively). Let us express s(t) as a polynomial in t. At t = 0, the end-eﬀector is stopped at p0 . Then, accelerate and move the end-eﬀector along with a line segment for a short while. After that, slow down the end-eﬀector and, at t = T , stop it at pf . We require the acceleration at t = 0 and T equals 0 for smooth starting and stopping. Then, s(t) becomes a polynomial of degree 5 in t [10], as follows. Let s(t) =  
   
  a4 T 5  
   
   5  4  3  2 t a3 T t a2 T t a1 T t + + + + a0 t, T 4 T 3 T 2 T  
   
  (16)  
   
  where a4 , a3 , a2 , a1 , a0 ∈ R. (Note that, for s(0) = 0, s(t) does not have a constant term.) Then, we have  4  3  2   t t t t s(t) ˙ = a4 + a3 + a2 + a1 + a0 , T T T T  3  2   4a4 t 3a3 t 2a2 t a1 s¨(t) = + + + . T T T T T T T  
   
  (17)  
   
  By the constraints s(0) = s(0) ˙ = s¨(0) = 0, s(T ) = 1, s(T ˙ ) = s¨(T ) = 0, we see that a0 = a1 = 0 and a3 , a4 , a5 satisfy the following system of linear equations. 20a2 + 15a3 + 12a4 −  
   
  60 = 0, T  
   
  a2 + a3 + a4 = 0,  
   
  2a2 + 3a3 + 4a4 = 0. (18)  
   
  412  
   
  M. Yoshizawa et al.  
   
  Algorithm 6. A path and trajectory planning of the manipulator Input: F = {f1 , . . . , f6 }: a system of equations for the inverse kinematic problem (2), V = {c1 , s1 , c4 , s4 , c7 , s7 }: variables, P = {x, y, z}: parameters, p0 = t (x0 , y0 , z0 ): the initial position of the end-eﬀector in the path, pf = t (xf , yf , zf ): the ﬁnal position of the end-eﬀector in the path, T : a step length of the time series; F (optional): a CGS of F  or the output of Generate-Real-CGS(F ,P) (Algorithm 2) where F is a CGS of F , RealCGS = {TRUE | FALSE} (optional): whether one wish to call Generate-Real-CGS (Algorithm 2) or not; Output: L = {Θt = (θ1,t , θ4,t , θ7,t ) | t = 1, . . . , T }: a series of solution of the inverse kinematic problem (2); 1: function Compute-IKP-Trajectory(F , V, P, p0 , pf , T , F , RealCGS) 2: if F = ∅ then 3: Compute a CGS of F  as F = {(S1 , G1 ), . . . , (St , Gt )}; 4: end if 5: if RealCGS = TRUE then  See Sect. 4.1 (Algorithm 2) 6: F  ← Generate-Real-CGS(F , V); 7: else F  ← F; 8: end if 9: L ← ∅; 10: for t = 1, . . . , T do  from (19) and (15), 11: s ← T65 t5 − T154 t4 + T103 t3 ; pd ← p0 (1 − s) + pf respectively; 12: Θ ← Solve-IKP-Point(F, V, P, pd , F  , FALSE);  See Sect. 4 (Algorithm 1) 13: if Θ = ∅ then 14: L ← L ∪ {Θ}; 15: else return L; 16: end if 17: end for 18: return L; 19: end function  
   
  By solving (18), we obtain a2 = become as  
   
  30 T , a3  
   
  = − 60 T , a4 =  
   
  30 T .  
   
  Thus, s(t), s(t), ˙ s¨(t)  
   
  30 60 30 6 5 15 4 10 3 t − 4 t + 3 t , s(t) ˙ = 5 t4 − 4 t3 + 3 t2 , T5 T T T T T 120 180 60 s¨(t) = 5 t3 − 4 t2 + 3 t, T T T s(t) =  
   
  (19)  
   
  respectively. We perform trajectory planning as follows. For given p0 = t (x0 , y0 , z0 ), pf = t (xf , yf , zf ), t ∈ [0, T ], calculate s(t) by (19). For each value of t changing as t = 0, 1, . . . , T , calculate pd = t (xd , yd , zd ) by (15), then apply Algorithm 1 with xd , yd , zd and calculate the conﬁguration of joints θ1 , θ4 , θ7 . This procedure is summarized as Algorithm 6. Remark 10. We see that Algorithm 6 outputs a trajectory for the given path of the end-eﬀector, as follows. After computing the CGS F, some segments without  
   
  Inverse Kinematics and Path Planning of Manipulator Using CGS-QE  
   
  413  
   
  real points are eliminated optionally, resulting in F  . Next, a trajectory of points on the given path is calculated as s(t) with t = 0, . . . , T . Then, for t = 0, . . . , T , an inverse kinematic problem is solved with Algorithm 1, and while the solution Θ of the inverse kinematic problem exists, a sequence of solutions L is obtained. Remark 11. In Algorithm 6, it is also possible to calculate the GCS F or F  (in which some segments without real points are eliminated by Algorithm 2) ﬁrst and then give them to the algorithm as in the case of Algorithm 1. (The speciﬁcation is the same as Algorithm 1; see Remark 3.) Example 2. Let p0 = t (x0 , y0 , z0 ) = t (10, 40, 80), pf = t (xf , yf , zf ) = (40, 100, 20), and T = 50. As the CGS corresponding to (2), F that has already been computed in Sect. 4.4 is given. By Algorithm 6, a sequence L of the conﬁguration of the joints θ1 , θ4 , θ7 corresponding to each point in the trajectory of the end-eﬀector from p0 to pf has been obtained. The total amount of computing time (CPU time) for path and trajectory planning was approximately 3.377 s. Next, we show another example by using CGS F  = Generate-Real-CGS(F, V), where F is the same as the one used in the previous example. Then, the computing time (CPU time) was approximately 2.246 sec. Note that computing time has been reduced by using the CGS with some segments not containing real points eliminated using Algorithm 2.  
   
  t  
   
  Remark 12. Algorithm 6 may cause a discontinuity in the sequence of the conﬁguration of the joints when a point on the trajectory gives a non-zero dimensional ideal as handled by Algorithm 5. For example, assume that the trajectory has a point p = (0, 0, z0 ) at t = t0 (0 < t0 < T ). Then, at t = t0 , according to Algorithm 5, θ1 is set to 0 regardless of the value of θ1 at t = t0 − 1. This could cause θ1 to jump between t0 − 1 and t0 , resulting a discontinuity in the sequence of conﬁguration of Joint 1. Preventing such discontinuity in trajectory planning is one of our future challenges. 5.2  
   
  Trajectory Planning with Verification of the Feasibility of the Inverse Kinematic Solution  
   
  Assume that the path of the motion of the end-eﬀector is given as (15) with the initial position p0 and the ﬁnal position pf . We propose a method of trajectory planning by verifying the existence of the solution of the inverse kinematic problem with the CGS-QE method. In the equation of the inverse kinematic problem (2), by substituting parameters x, y, z with the coordinates of pd in (15), respectively, we have the following system of polynomial equations.  
   
  414  
   
  M. Yoshizawa et al.  
   
  Algorithm 7. Trajectory planning with CGS-QE method Input: F = {f1 , . . . , f6 }: a system of equations for the inverse kinematic problem (2), V = {c1 , s1 , c4 , s4 , c7 , s7 }: variables, P = {x, y, z}: parameters, p0 = t (x0 , y0 , z0 ): the initial position of the end-eﬀector in the path, pf = t (xf , yf , zf ): the ﬁnal position of the end-eﬀector in the path, T : the step length of a time series; F (optional): a CGS of F  or the output of Generate-Real-CGS(F ,P) (Algorithm 2) where F is a CGS of F , RealCGS = {TRUE | FALSE} (optional): whether one wish to call Generate-Real-CGS (Algorithm 2) or not; Output: L = {Θt = (θ1,t , θ4,t , θ7,t ) | t = 1, . . . , T }: a series of solution of the inverse kinematic problem (2); 1: function Solve-IKP-Trajectory-CGS-QE(F , V, P, p0 , pf , T , F , RealCGS) 2: if F = ∅ then 3: Compute a CGS of F  as F = {(S1 , G1 ), . . . , (St , Gt )}; 4: end if 5: if RealCGS = TRUE then  See Sect. 4.1 (Algorithm 2) 6: F  ← Generate-Real-CGS(F , V); 7: else F  ← F; 8: end if 9: M ← MainQE(F  ); 10: if [0, 1] ⊂ M then  See 11: L ← Compute-IKP-Trajectory(F, V, P, p0 , pf , T, F  , FALSE); Sect. 5.1 (Algorithm 6) 12: else L ← ∅; 13: end if 14: return L; 15: end function  
   
  √ f1 = 120c1 c4 s7 − 16c1 c4 + 120c1 s4 c7 + 136c1 s4 − 44 2c1 + x0 (1 − s) + xf s = 0, √ f2 = 120s1 c4 s7 − 16s1 c4 + 120s1 s4 c7 + 136s1 s4 − 44 2s1 + y0 (1 − s) + yf s = 0, √ f3 = −120c4 s7 − 136c4 + 120s4 s7 − 16s4 − 104 − 44 2 + z0 (1 − s) + zf s = 0, f4 = s21 + c21 − 1 = 0,  
   
  f5 = s24 + c24 − 1 = 0,  
   
  (20)  
   
  f6 = s27 + c27 − 1 = 0.  
   
  Note that x0 , y0 , z0 , xf , yf , zf are the constants. Equation (20) has a parameter s. Using the CGS-QE method, we verify (20) has real roots for s ∈ [0, 1]. The whole procedure for trajectory planning is shown in Algorithm 7. Remark 13. In Algorithm 7, it is also possible to calculate the GCS F or F  (in which some segments without real points are eliminated by Algorithm 2) ﬁrst and then give them to the algorithm as in the case of Algorithms 1 and 6. (The speciﬁcation is the same is Algorithms 1 and 6; see Remark 3).  
   
  Inverse Kinematics and Path Planning of Manipulator Using CGS-QE  
   
  415  
   
  In Algorithm 7, Line 9 corresponds to Algorithm MainQE in the CGS-QE method. Its detailed procedure for a zero-dimensional ideal is as follows. Let F  be the input CGS, (S, G) a segment, M ⊂ R3 the output. Assume that the ideal G is zero-dimensional. G  
   
  1. In the case G = {1}, calculate the matrix M1 . G 2. Calculate the characteristic polynomial χ1 (X). 3. Calculate the range M of parameter s that makes (20) has a real root as follows. (a) By (4) and (5), generate the sequences of coeﬃcients LχG + and LχG − G  
   
  G  
   
  1  
   
  1  
   
  of χ1 (X) and χ1 (−X), respectively. Note that LχG + and LχG − 1 1 consist of polynomials in s. (b) Using LχG + , LχG − , make sequences of equations and/or inequality in 1 1 s, such as (1, ad−1 > 0, ad−2 < 0, . . . , a0 > 0). For the sequences, calculate the number of sign changes SχG + and SχG − as in (6). 1 1 (c) By Corollary 2, collect the sequences of equations/inequalities that satisfy SχG + = SχG − . From the sequences satisfying the above condition, 1 1 extract conjunction of the constraints on s as M ⊂ R. Remark 14. We see that Algorithm 7 outputs a trajectory for the given path of the end-eﬀector after verifying feasibility of the whole given path, as follows. For a system of polynomial equations F with parameter s in (20), a CGS F of F  is calculated. After calculating F, some segments without real points are eliminated optionally, resulting in F  . Next, for F  , the range M of parameter s that makes (20) has a real root with the MainQE algorithm in the CGS-QE method. Then, if [0, 1] ⊂ M , a series of solution of the inverse kinematic problem L is calculated by calling Algorithm 6. We have implemented Algorithm 7 using Risa/Asir, together with using Wolfram Mathematica 13.1 [23] for calculating the characteristic polynomial in Step 2 and simpliﬁcation of formula in Step 3 above. For connecting Risa/Asir and Mathematica, OpenXM infrastructure [11] was used. Example 3. Let p0 = t (x0 , y0 , z0 ) = t (10, 40, 80) and pf = t (xf , yf , zf ) = (40, 100, 20) (the same as those in Example 2). For (20), substitute x0 , y0 , z0 , xf , yf , zf with the above values and deﬁne a system of polynomial equations with parameter s as  
   
  t  
   
  √ f1 = 120c1 c4 s7 − 16c1 c4 + 120c1 s4 c7 + 136c1 s4 − 44 2c1 + 30 s + 10 = 0, √ f2 = 120s1 c4 s7 − 16s1 c4 + 120s1 s4 c7 + 136s1 s4 − 44 2s1 + 60 s + 40 = 0, √ f3 = −120c4 s7 − 136c4 + 120s4 s7 − 16s4 − 60 s − 44 2 − 24 = 0, f4 = s21 + c21 − 1 = 0,  
   
  f5 = s24 + c24 − 1 = 0,  
   
  (21)  
   
  f6 = s27 + c27 − 1 = 0,  
   
  and verify that (21) has a real root for s ∈ [0, 1]. In Algorithm 7, computing a CGS F (Line 3) was performed in approximately 485.8 sec., in which F  
   
  416  
   
  M. Yoshizawa et al.  
   
  has 6 segments. The step of Generate-Real-CGS (Line 6) was performed in approximately 0.009344 s with obtaining one segment existing in R. The step of MainQE (Line 9) was performed in approximately 1.107 s, and we see that [0, 1] ⊂ M , thus the whole trajectory is included in the feasible region of the manipulator. The rest of the computation is the same as the one in Example 2.  
   
  6  
   
  Concluding Remarks  
   
  In this paper, we have proposed methods for inverse kinematic computation and path and trajectory planning of a 3-DOF manipulator using the CGS-QE method. For the inverse kinematic computation (Algorithm 1), in addition to our previous method [14], we have automated methods for eliminating segments that do not contain real points (Algorithm 2) and for handling non-zero dimensional ideals (Sect. 4.3). Note that our solver veriﬁes feasibility for the given position of the end-eﬀector before performing the inverse kinematic computation. For path and trajectory planning, we have proposed two methods. The ﬁrst method (Algorithm 6) is the repeated use of inverse kinematics solver (Algorithm 1). The second method (Algorithm 7) is based on veriﬁcation that the given path (represented as a line segment) is included in the feasible region of the endeﬀector with the CGS-QE method. Examples have shown that the ﬁrst method seems eﬃcient and suitable for real-time solving of inverse kinematics problems. Although the second method is slower than the ﬁrst one, it provides rigorous answers on the feasibility of path planning. This feature would be helpful for the initial investigation of path planning that needs rigorous decisions on the feasibility before performing real-time solving of inverse kinematics problems. Further improvements of the proposed methods and future research directions include the following. 1. If more than one solution of the inverse kinematic problem exist, currently we choose the ﬁrst one that the solver returns. However, currently, there is no guarantee that a series of solutions of the inverse kinematic problem in the trajectory planning (in Sect. 5.1) is continuous, although it just so happened that the calculation in Example 2 was well executed. The problem of guaranteeing continuity of solutions to inverse kinematics problems needs to be considered in addition to the problem of guaranteeing feasibility of solutions; for this purpose, tools for solving parametric semi-algebraic systems by decomposing the parametric space into connected cells above which solutions are continuous might be useful [2,9,24]. Furthermore, another criterion can be added for choosing an appropriate solution, based on another criteria such as the manipulability measure [16] that indicates how the current conﬁguration of the joints is away from a singular conﬁguration. 2. Our algorithm for trajectory planning (Algorithm 6) may cause a discontinuity in the sequence of the conﬁguration of the joints when a point on the  
   
  Inverse Kinematics and Path Planning of Manipulator Using CGS-QE  
   
  417  
   
  trajectory gives a non-zero dimensional ideal. The algorithm needs to be modiﬁed to output a sequence of continuous joint conﬁgurations, even if the given trajectory contains points that give non-zero dimensional ideals (see Remark 12). 3. Considering real-time control, the eﬃciency of the solver may need to be improved. It would be necessary to actually run our solver on the EV3 to verify the accuracy and eﬃciency of the proposed algorithm to conﬁrm this issue (see Sect. 4.4). 4. In this paper, we have used a line segment as a path of the end-eﬀector. Path planning using more general curves represented by polynomials would be useful for giving the robot more freedom of movement. However, if path planning becomes more complex, more eﬃcient methods would be needed. 5. While the proposed method in this paper is for a manipulator of 3-DOF, many industrial manipulators have more degrees of freedom. Developing the method with our approach for manipulators of higher DOF will broaden the range of applications. Acknowledgements. The authors would like to thank Dr. Katsuyoshi Ohara for support for the OpenXM library to call Mathematica from Risa/Asir, and the anonymous reviewers for their helpful comments. This research was partially supported by JSPS KAKENHI Grant Number JP20K11845.  
   
  References 1. Becker, E., W¨ oermann, T.: On the trace formula for quadratic forms. In: Recent Advances in Real Algebraic Geometry and Quadratic Forms (Berkeley, CA, 1990/1991; San Francisco, CA, 1991), Contemporary Mathematics, vol. 155, pp. 271–291. AMS, Providence (1994). https://doi.org/10.1090/conm/155/01385 2. Chen, C., Maza, M.M.: Semi-algebraic description of the equilibria of dynamical systems. In: Gerdt, V.P., Koepf, W., Mayr, E.W., Vorozhtsov, E.V. (eds.) CASC 2011. LNCS, vol. 6885, pp. 101–125. Springer, Heidelberg (2011). https://doi.org/ 10.1007/978-3-642-23568-9 9 3. Cox, D.A., Little, J., O’Shea, D.: Using Algebraic Geometry, 2nd edn. Springer, Heidelberg (2005). https://doi.org/10.1007/b138611 4. Cox, D.A., Little, J., O’Shea, D.: Ideals, Varieties, and Algorithms: An Introduction to Computational Algebraic Geometry and Commutative Algebra, 4th edn. Springer, Heidelberg (2015). https://doi.org/10.1007/978-3-319-16721-3 5. Faug`ere, J.C., Merlet, J.P., Rouillier, F.: On solving the direct kinematics problem for parallel robots. Research Report RR-5923, INRIA (2006). https://hal.inria.fr/ inria-00072366 6. Fukasaku, R., Iwane, H., Sato, Y.: Real quantiﬁer elimination by computation of comprehensive Gr¨ obner systems. In: Proceedings of the 2015 ACM on International Symposium on Symbolic and Algebraic Computation, ISSAC 2015, pp. 173–180. ACM, New York (2015). https://doi.org/10.1145/2755996.2756646  
   
  418  
   
  M. Yoshizawa et al.  
   
  7. Horigome, N., Terui, A., Mikawa, M.: A design and an implementation of an inverse kinematics computation in robotics using Gr¨ obner bases. In: Bigatti, A.M., Carette, J., Davenport, J.H., Joswig, M., de Wolﬀ, T. (eds.) ICMS 2020. LNCS, vol. 12097, pp. 3–13. Springer, Cham (2020). https://doi.org/10.1007/978-3-03052200-1 1 8. Kalker-Kalkman, C.M.: An implementation of Buchbergers’ algorithm with applications to robotics. Mech. Mach. Theory 28(4), 523–537 (1993). https://doi.org/ 10.1016/0094-114X(93)90033-R 9. Lazard, D., Rouillier, F.: Solving parametric polynomial systems. J. Symb. Comput. 42(6), 636–667 (2007). https://doi.org/10.1016/j.jsc.2007.01.007 10. Lynch, K.M., Park, F.C.: Modern Robotics: Mechanics, Planning, and Control. Cambridge University Press, Cambridge (2017) 11. Maekawa, M., Noro, M., Ohara, K., Takayama, N., Tamura, K.: The design and implementation of OpenXM-RFC 100 and 101. In: Shirayanagi, K., Yokoyama, K. (eds.) Computer Mathematics: Proceedings of the Fifth Asian Symposium on Computer Mathematics (ASCM 2001), pp. 102–111. World Scientiﬁc (2001). https:// doi.org/10.1142/9789812799661 0011 12. Nabeshima, K.: CGS: a program for computing comprehensive Gr¨ obner systems in a polynomial ring [computer software] (2018). https://www.rs.tus.ac.jp/ nabeshima/softwares.html. Accessed 30 June 2023 13. Noro, M.: A computer algebra system: Risa/Asir. In: Joswig, M., Takayama, N. (eds.) Algebra, Geometry and Software Systems, pp. 147–162. Springer, Heidelberg (2003). https://doi.org/10.1007/978-3-662-05148-1 8 14. Otaki, S., Terui, A., Mikawa, M.: A design and an implementation of an inverse kinematics computation in robotics using real quantiﬁer elimination based on comprehensive Gr¨ obner systems. Preprint (2021). https://doi.org/10.48550/arXiv. 2111.00384, arXiv:2111.00384 15. Pedersen, P., Roy, M.F., Szpirglas, A.: Counting real zeros in the multivariate case. In: Computational Algebraic Geometry (Nice, 1992). Progress in Mathematics, vol. 109, pp. 203–224. Birkh¨ auser Boston, Boston (1993). https://doi.org/10.1007/9781-4612-2752-6 15 16. Siciliano, B., Sciavicco, L., Villani, L., Oriolo, G.: Robotics: Modelling, Planning and Control. Springer, Heidelberg (2008). https://doi.org/10.1007/978-1-84628642-1 17. da Silva, S.R.X., Schnitman, L., Cesca Filho, V.: A solution of the inverse kinematics problem for a 7-degrees-of-freedom serial redundant manipulator using Gr¨ obner bases theory. Math. Probl. Eng. 2021, 6680687 (2021). https://doi.org/10.1155/ 2021/6680687 18. Terui, A., Yoshizawa, M., Mikawa, M.: ev3-cgs-qe-ik-2: an inverse kinematics solver based on the CGS-QE algorithm for an EV3 manipulator [computer software] (2023). https://github.com/teamsnactsukuba/ev3-cgs-qe-ik-2 19. The PARI Group, Univ. Bordeaux: PARI/GP version 2.13.1 (2021). https://pari. math.u-bordeaux.fr/ 20. Uchida, T., McPhee, J.: Triangularizing kinematic constraint equations using Gr¨ obner bases for real-time dynamic simulation. Multibody Syst. Dyn. 25, 335–356 (2011). https://doi.org/10.1007/s11044-010-9241-8 21. Uchida, T., McPhee, J.: Using Gr¨ obner bases to generate eﬃcient kinematic solutions for the dynamic simulation of multi-loop mechanisms. Mech. Mach. Theory 52, 144–157 (2012). https://doi.org/10.1016/j.mechmachtheory.2012.01.015  
   
  Inverse Kinematics and Path Planning of Manipulator Using CGS-QE  
   
  419  
   
  22. Weispfenning, V.: A new approach to quantiﬁer elimination for real algebra. In: Caviness, B.F., Johnson, J.R. (eds.) Quantiﬁer Elimination and Cylindrical Algebraic Decomposition. Texts and Monographs in Symbolic Computation, pp. 376– 392. Springer, Vienna (1998). https://doi.org/10.1007/978-3-7091-9459-1 20 23. Wolfram Research Inc: Mathematica, Version 13.1 [computer software] (2022). https://www.wolfram.com/mathematica. Accessed 14 May 2023 24. Yang, L., Hou, X., Xia, B.: A complete algorithm for automated discovering of a class of inequality-type theorems. Sci. China Ser. F Inf. Sci. 44(1), 33–49 (2001). https://doi.org/10.1007/BF02713938  
   
  Author Index  
   
  A Ansari, Mahsa 1  
   
  J Jeffrey, David J. 199 Jia, H. M. 128 Jinadu, Ayoola 233  
   
  B Barket, Rashid 21 Bernauer, Klara 39 Brandt, Alexander 69  
   
  K Kalinina, Elizaveta  
   
  C Cheng, Jin-San 312 Chuluunbaatar, O. 128 Clamond, Didier 90 D Derbov, V.L.  
   
  255  
   
  L Lezhnina, Elena 255 Li, Bo 312 Li, Xiaoliang 183 Lichtblau, Daniel 141 Lin, C.J. 128  
   
  128  
   
  E England, Matthew  
   
  M Mikawa, Masahiko 393 Monagan, Michael 1, 233 Moreno Maza, Marc 69  
   
  21  
   
  G Galligo, André 90 Gerhard, Jürgen 21 Go, Soo 107 Goncharova, Marina 255 González Trochez, Juan Pablo Gusev, A. A. 128 H Hai, L. L. 128 Hashemi, Amir 141 Hofstadler, Clemens 39 Hormann, Kai 162 Huang, Bo 183 I Imre, Jacob 199 Irtegov, Valentin 213  
   
  69  
   
  N Nabeshima, Katsusuke 272 Nazmitdinov, R.G. 128 Niu, Wei 183 O Olver, Peter J. 292 P Pan, Victor Y.  
   
  107  
   
  R Regensburger, Georg S Soto, Pedro  
   
  107  
   
  © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2023 F. Boulier et al. (Eds.): CASC 2023, LNCS 14139, pp. 421–422, 2023. https://doi.org/10.1007/978-3-031-41724-5  
   
  39  
   
  422  
   
  Author Index  
   
  T Tajima, Shinichi 272 Tan, Ling 312 Terui, Akira 393 Titorenko, Tatiana 213  
   
  W Wang, Weidong 350 Watt, Stephen M. 370 Wen, P.W. 128 X Xie, Shaofen  
   
  U Uteshev, Alexei  
   
  Y Yang, Jing 350 Yap, Chee 162 Yoshizawa, Mizuki Yuan, Haoze 69  
   
  255  
   
  V Vinitsky, S.I. 128 Vorozhtsov, Evgenii V.  
   
  183  
   
  330  
   
  393  
   
  Z Zhang, Bingwei 312 Zhang, Ya Shi 162  

 Report "Computer Algebra in Scientific Computing. 25th International Workshop, CASC 2023 Havana, Cuba, August 28 – September 1, 2023 Proceedings 9783031417238, 9783031417245"  
 ×    

 --- Select Reason ---  Pornographic  Defamatory  Illegal/Unlawful  Spam  Other Terms Of Service Violation  File a copyright complaint     

 Close  Submit    

    Contact information  
 Michael Browner   
   [email protected]    
   
   Address:   
 1918 St.Regis, Dorval, Quebec, H9P 1H6, Canada.   
   
 Support & Legal  
  O nas 
  Skontaktuj się z nami 
  Prawo autorskie 
  Polityka prywatności 
  Warunki 
  FAQs 
  Cookie Policy 
    
 Subscribe to our newsletter  
  Be the first to receive exclusive offers and the latest news on our products and services directly in your inbox.  
   Subscribe     

 Copyright © 2024 DOKUMEN.PUB. All rights reserved.        

 Unsere Partner sammeln Daten und verwenden Cookies zur Personalisierung und Messung von Anzeigen. Erfahren Sie, wie wir und unser Anzeigenpartner Google Daten sammeln und verwenden  .   Cookies zulassen

35. CAivDE_1 conference:
Skip to content    
 ResearchGate   LinkedIn   Bluesky   X   Instagram   Facebook   YouTube   Rss     

 English | English 
  Deutsch 

 Search for:      

 Home 
  Research | Projects 
  Research Areas | Visual Analytics 
  Human-Computer Interaction 
  Application Areas 
  Services | Teaching 
  Development 
  Consulting 
  Publications 
  Team 
  Partners 
  Contact 
    
 Search for:      

 Home 
  Research | Projects 
  Research Areas | Visual Analytics 
  Human-Computer Interaction 
  Application Areas 
  Services | Teaching 
  Development 
  Consulting 
  Publications 
  Team 
  Partners 
  Contact 
    
 Home 
  Research | Projects 
  Research Areas | Visual Analytics 
  Human-Computer Interaction 
  Application Areas 
  Services | Teaching 
  Development 
  Consulting 
  Publications 
  Team 
  Partners 
  Contact 

 Search for:      

     << All Events    
      
 International Conference Information Visualisation (IV2023)  
 25  July  2023  (8:00 AM)  -  28  July  2023  (5:00 PM)    

 IV2023 – 27th International Conference Information Visualisation    
 25 – 28 July 2023  
 Tampere University ● Tampere ● Finland ●  
 https://www.graphicslink.co.uk/IV2023/index.htm   
  
 Call for Papers, Poster, Videos, and Participation  
  
 Theme and scope are planned as a series of symposia with details, and further information is available at IV2023: https://iv.csites.fct.unl.pt/fi/symposia/    
 Submission Porta: https://www.conftool.org/IV-cgiv-2023/   
 Publication: https://iv.csites.fct.unl.pt/fi/call-for-papers/publication/   
  
 IV2023 – Information visualization:   
 Information Visualisation Theory & Practice 
  Applications of Information Visualization 
  Information Visualization Evaluation 
  Human-Computer Interaction for Information Visualization 
  Graph Theory & Network Visualization 
   
 IV2023 – Knowledge Visualization   
 Knowledge Visualization and Visual Thinking 
  Learning Analytics 
  Music Visualization 
  Digital Humanities Knowledge Visualisation 
  IV2023 – AI/ML, Visual Analytics, and Visual Knowledge Discovery    
 13 International Symposium Visual Analytics and Data Science 
  AI and Visual Knowledge Discovery 
  Visualization in Data Science and Machine Learning 
  Advances in Interactive and Visual Data Clustering 
    
 IV2023 – Visual Methods in Big Data, social, and business analytics   
 Big data Visualization and Visual Analytics 
  Visualisation in Business Intelligence and Open Data 
  Social Issues Analysis and Visualisation 
   
 vis2023  – Visualization   
 2nd Symposium on AI-Empowered Visual Computing 
  Augmented Reality Visualization and Art 
  D-ART – Symposium of Digital Art and Gallery 
  Scientific Visualization 
  Visualization, Art, & Design 
  CAivDE – Computer Animation, Information Visualisation, and Digital Effects 
  Digital Entertainment 
  Computer Games and their applications 
   
 MediVis2023   
 Visualization and Artificial Intelligence for Medicine, Healthcare, and Social Good 
   
 BuiltViz2023   
 Visualisation in Built and Rural Environment 
  ResearcherLink in Sustaining Built Heritage 
  Visualisation for the Heritage of Asia-Pacific Architecture and Urbanism 
   
 GMAI2023   
 Geometric Modelling and Imaging 
   
 Preconference course:   Doctoral Research Workshop  
 Researcher Link Forum:  Research Project Collaboration  
 Focus Group Publication:  Post-conference publication  
  
 ——————————————————————————-  
 Important Dates – https://iv.csites.fct.unl.pt/fi/call-for-papers/important-dates/   
 Submission Portal: https://www.conftool.org/IV-cgiv-2023/   
 ========= ===================================  
 General Co-Chairs:   
  Harri Siirtola (Dr.), Tampere University, Finland  
  Ebad Banissi (Em Prof.), LSBU, UK  
 Symposium General Co-Chairs:   
  Kawa Nazemi  (Prof.), Darmstadt University of Applied Sciences, Germany – Visual Analytics and Data Science  
  Boris Kovalerchuk (Prof.), University of Central Washington, USA – AI and Visual Knowledge Discovery  
  Urska Cvek (Prof.), Louisiana State University , USA – Visualization and Artificial Intelligence for Medicine, Healthcare  
  Anna Ursyn (Prof.), University of Northern Colorado, USA – Digital Art and Gallery  

 Share This Event  

   This event has passed.     
 ×    

 Details  
 Start:  25/07/2023 @ 8:00  CEST   End:  28/07/2023 @ 17:00  CEST   Event Categories:  Conference  , Event  , Research   Website:  https://iv.csites.fct.unl.pt/fi/      
   
 Venue  
  Tampere University   Kalevantie 4   
  Tampere  ,  33100  Finland   + Google Map       
   
 Organizer  
  GraphicsLink   View Organizer Website      
   
 + Google Calendar  + iCal Export    

 «  Call for Papers – MDPI Electronics – Special Issue “Visual Analytics, Simulation, Decision Making Technologies” 
  Call for Papers: 1st International Workshop on Disinformation and Toxic Content Analysis (DiTox 2023) » 

 Details  
 Start:  25/07/2023 @ 8:00  CEST   End:  28/07/2023 @ 17:00  CEST   Event Categories:  Conference  , Event  , Research   Website:  https://iv.csites.fct.unl.pt/fi/      
 Organizer  
  GraphicsLink   View Organizer Website      
   
 Venue  
  Tampere University   Kalevantie 4   
  Tampere  ,  33100  Finland   + Google Map       

 Imprint  Data Privacy    

 © 2024 Research Department on Human-Computer Interaction & Visual Analytics (vis) – Darmstadt University of Applied Sciences (h_da)    

 Page load link    
 Manage Cookie Consent   

 To provide the best experiences, we use technologies like cookies to store and/or access device information. Consenting to these technologies will allow us to process data such as browsing behavior or unique IDs on this site. Not consenting or withdrawing consent, may adversely affect certain features and functions.  
   
 Functional   Functional    Always active       The technical storage or access is strictly necessary for the legitimate purpose of enabling the use of a specific service explicitly requested by the subscriber or user, or for the sole purpose of carrying out the transmission of a communication over an electronic communications network.    
  Preferences   Preferences         The technical storage or access is necessary for the legitimate purpose of storing preferences that are not requested by the subscriber or user.    
  Statistics   Statistics         The technical storage or access that is used exclusively for statistical purposes.  The technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.    
  Marketing   Marketing         The technical storage or access is required to create user profiles to send advertising, or to track the user on a website or across several websites for similar marketing purposes.    

 Manage options  Manage services  Manage {vendor_count} vendors  Read more about these purposes    
   
 Accept  Deny  View preferences  Save preferences  View preferences    
 {title}  {title}  {title}    

 Manage consent    
  WordPress Double Opt-in by Forge12    
 Go to Top

36. CGI_0 conference:
Skip to content      

 Menu   Home 
  About 
  Important Dates 
  Call For Papers 
  For Authors 
  REGISTRATION 
  Committees 
  Preliminary Conference Program 
  opening ceremony virtual entrance 
  Photo Gallery 
  Keynote Speakers 
  Presentation Guidelines 
  CGI WORKSHOP/Special Sessions 
  ENGAGE WORKSHOP 
  CGI CHALLENGE | CGI-PSG2023 
  CGI-NFR2023 
  CGI-CCC2023 
  CGI-HRDC2023 
  CGI-CLSLR2023 
  CGI-AIAA2023 
  CGI AWARDS 
  Contact 

 Computer Graphics International 2023    
 Shanghai, China  
 August 28 to September 1, 2023  
 CALL FOR PAPERS   FLYER     
 Registration is now open! We accept Wechat Payment, International and local bank transfer.  Due to some technical issues of our payment system, we have extended the registration deadline for the first round call for papers to the July 15th. We apologize for the inconvenience. Please email vrar@cs.sjtu.edu.cn if you have any concerns.    
 Address: Shanghai Marriott Hotel Pudong East, 15 Xinjinqiao Road, Pudong New  
  District, Shanghai, China, 201206  
  地址：上海金桥红枫万豪酒店，浦东新区新金桥路 15 号, 上海, 201206   
 Conference Venues are located on the Fifth Floor for the Aug 28th – Aug 31st, the Third Floor for the Sep 1st and Lunch Venues are located on Level 2.    

 About Us  

 COMPUTER GRAPHICS INTERNATIONAL, Shanghai 2023  
 CGI is one of the oldest annual international conferences on Computer Graphics in the world. Researchers are invited to share their experiences and novel achievements in various fields of Computer Graphics and Virtual Reality. Previous recent CGI conferences have been held in Sydney, Australia (2014), Strasbourg, France (2015), Heraklion, Greece (2016), Yokohama, Japan (2017), Bintan, Indonesia (2018), and Calgary in Canada (2019). CGI has been virtual between 2020 and 2022 due to the COVID pandemic.  
 This year, CGI 2023 is organized by Shanghai Jiao Tong University and University of Sydney, and supported by the Computer Graphics Society (CGS), with the assistance of Wuhan Textile University and the STATE KEY LABORATORY OF COMPUTER SCIENCE (SKLCS), CGI 2023 will (hopefully) be held as a hybrid event-allowing both onsite and online participation – in Shanghai. The Visual Computer is the official journal of the Computer Graphics Society.  
 The main topics of the CGI 2023 conference are the following:   
 Rendering Techniques 
  Metaverse (VR/MR/XR) 
  Physically Based Modeling 
  Machine Learning for Computer Graphics 
  Data Compression for Graphics 
  Image Based Rendering and ModelingGeometric Computing 
  Computer Animation 
  Shape Analysis and Image Retrieval 
  Digital Cultural Heritage 
  Image Processing and Analysis 
  Global Illumination 
  Digital Humans 
  Stylized Rendering 

 Geometry Processing and Analysis 
  Shape and Surface Modeling 
  Computer Vision for Computer Graphics 
  Scientific Visualization 
  Computational Geometry 
  Computational Photography 
  Visual Analytics 
  Volume Rendering 
  Computational Fabrication 
  3D Reconstruction 
  Graphical Human-Computer Interaction 
  Sketch-based Modelling 
  Textures 

 CGI2023 papers can be submitted either on March 17  for possible publication in the journal Visual Computer  or June 12   (extented to June 19 )  for possible publication in a LNSC Proceedings book  published by Springer, or the CAVW  journal (Computer Animation and Virtual Worlds) published by Wiley, or the VRIH  journal (Virtual Reality and Intelligent hardware) publish by Science press.  

 Important Dates  
 Conference, Special sessions, and Workshops, August 28 to September 1, 2023   
 All deadlines are 23:59 GMT time on the date stated  

 IMPORTANT DATES  
  
 Submission Deadline | Preliminary Notification to Authors | Deadline to Receive Revised Papers From Authors | Final Notification of Revised Papers 
 Visual Computer | March 10  (extented to March 17), 2023 | April 22, 2023 | May 18, 2023 | June 15, 2023 

 Submission Deadline | Notification of Acceptance | Camera-Ready 
 CGI Proceedings book papers   
  CAVW journal   
  VRIH journal | June 12  (extented to June 19 ) , 2023 | July 13, 2023 | August 5, 2023 

 GENERAL GUIDELINES FOR PAPERS SUBMISSIONS      
  
 The scientific program of the conference will include accepted papers from the first call for papers and these accepted papers will be published by Springer in the Visual Computer Journal  (impact factor 2.835) by Springer-Verlag.   
 The accepted papers from the second call for papers will be included either in the CGI conference Proceedings published by LNCS, Springer  , or   in the VRIH journal   (Virtual Reality and Intelligent Hardware journal published by Science Press), or  in the CAVW journal   (Computer Animation and Virtual Worlds) published by Wiley.   
 Note that for ALL submissions, the review process is double blind  , which requires the paper and all supplemental materials to be anonymous. Ensure that self-referencing is anonymous (refer to your full name rather than “I” or “we”). Avoid providing information that may identify the authors in the acknowledgements (e.g. co-workers and grant IDs) and in the supplemental material (e.g. titles in the movies, or attached papers). Avoid providing links to websites that identify the authors. Violation of any of these guidelines will lead to rejection without review.   

 Our Team  
  Honorary Conference Chairs  
 Leadership by Shanghai Jiao Tong University  
  Enhua Wu, Chinese Academy of Sciences / University of Macau, China  
  Dagan Feng, The University of Sydney, Australia  
    
 Conference Chairs  
 Nadia Magnenat Thalmann, University of Geneva, Switzerland  
  Bin Sheng, Shanghai Jiao Tong University, China  
  Jinman Kim, The University of Sydney, Australia  
   
 Program Chairs  
 Daniel Thalmann, École Polytechnique Fédérale de Lausanne (EPFL), Switzerland  
  Stephen Lin, Microsoft Research Asia  
  Lizhuang Ma, Shanghai Jiao Tong University, China  
  Ping Li, Hong Kong Polytechnic University, Hong Kong, China  
   
 Organization Chairs  
 Lei Bi, University of Sydney, Australia  
  Xinrong Hu, Wuhan Textile University, China  
  Lei Zhu, The Hong Kong University of Science and Technology, Hong Kong, China  
   
 Paper Awards Chairs  
 Nadia Magnenat Thalman, MIRALab-University of Geneva, Switzerland  
  Yiyu Cai, Nanyang Technological University, Singapore  
  Xiaogang Jin, Zhejiang University, China  
   
 Workshops/Special Session Chairs  
 George Papagiannakis, University of Crete, Greece  
  Sheng Li, Peking University, China  
  Xiaohong Liu, Shanghai Jiao Tong University, China  
  Jing Qin, Hong Kong Polytechnic University, Hong Kong, China  
   
 Tutorial Chairs  
 Selim Balcisoy, Sabanci University,Turkey  
  Liang Wan,Tianjin University, China  
  Weiliang Meng, Institute of Automation, Chinese Academy of Sciences, China  
   
 Communication Chairs  
 Hyewon Seo, ICube – University of Strasbourg, France  
  Guangzheng Fei, Communication University of China, China  
  Youquan Liu, Changan University, China  
   
 Social Media Chairs  
 Luciana Nedel, UFRGS, Brazil  
  Ran Yi, Shanghai Jiao Tong University, China  
  Xiao Lin, Shanghai Normal University, China  
   
 Demo Chairs  
 Bing Shao, Jilin University of The Arts, China  
  Zhifeng Xie, Shanghai University, China  
  Yang Wen, Shenzhen Univeristy, China  
   
 Challenge Chairs  
 Di Lin, Tianjin University, China  
  Jin Huang, Wuhan Textile University, China  
  Gang Yang, Beijing University of Forest, China  
   
 Plenary Talk Chairs  
 Jian Zhang, Bournemouth University, United Kingdom  
  Xiaoyang Mao, University of yamanashi, Japan  
  Yanci Zhang, Sichuan University, China  
   
 Panel Chairs  
 Constantine Stephanidis, ICS – FORTH, Greece  
  Xiaojuan Qi, University of Hong Kong, Hong Kong, China  
  Xiaoguang Han, The Chinese University of Hong Kong (Shenzhen), Hong Kong, China  
   
 Poster Chairs  
 Younhyun Jung, Gachon University, Korea  
  Mingqiang Wei, Nanjing University of Aeronautics and Astronautics, China  
  Ye Pan, Shanghai Jiao Tong University, China  
   
 Publicity Chairs  
 Jian Chang, University of Bournemouth, United Kingdom  
  Marina Gavrilova, University of Calgary, Canada  
  Nanxuan (Cherry) Zhao, Adobe, USA  
  Huisi Wu, Shenzhen University, China  
  Zhihua Chen, East China University of Science and Technology, China  
   
 Chairs for Young Investigators and Early Career Development  
 Saleha Masood, COMSATS Institute of Information Technology, Pakistan  
  Tamam Alsarhan, Applied Science Private University, Jordan  
  Jian Zhu, Guangdong University of Technology, China  
   
 Publication Chairs  
 Xuequan Lu, Deakin University, Australia  
  Liansheng Wang, Xiamen University, China  
  Zhiwen Shao, China University of Mining and Technology, China  
  Shaoping Lu, Nankai University, China  
   
 Program Committee  
  
  Antonio Agudo, Institut de Robòtica i Informàtica industrial, CSIC-UPC 
  Andreas Aristidou, University of Cyprus 
  Selim Balcisoy, Sabanci University 
  Jan Bender, RWTH Aachen University 
  Bedrich Benes, Purdue University 
  Yiyu Cai, Nanyang Technological University 
  Tolga Capin, TED University, Turkey 
  Jian Chang, Bournemouth University 
  Jie ChenHong, Kong Baptist University 
  Naser Damer, Fraunhofer IGD, Germany 
  Amal Dev P, Institut Polytechnique de Paris 
  Jan Egger, Institute for AI in Medicine (IKIM), University Hospital Essen (UKE), Essen, Germany 
  Bin Fan, University of Science and Technology Beijing 
  Jieqing Feng, Zhejiang University 
  Feng Lu, Huazhong University of Science and Technology 
  Ioannis Fudos, University of Ioannina 
  Issei Fujishiro, Keio University 
  Marina Gavrilova, University of Calgary 
  Enrico Gobbetti, CRS4 Visual Computing 
  Laurent Grisoni, University of Lille 
  Xinrong Hu, Wuhan Textile University 
  Yunqing Guan, Singapore Institute of Technology 
  Ruizhen Hu, Shenzhen University 
  Jin Huang, Wuhan Textile University 
  Kei Iwasaki, Wakayama University 
  Xiaogang Jin, Zhejiang University 
  Younhyun Jung, Gachon University 
  Takashi Kanai, The University of Tokyo 
  Arjan Kuijper, Fraunhofer IGD, Darmstadt 
  Di Lin, Tianjin University 
  Jie Li, Tianjin University 
  Manfred Lau, City University of Hong Kong 
    
 Tsz Ho Kwok, Concordia University 
  Yu-Kun Lai, Cardiff University 
  Shiguang Liu, Tianjin University 
  Xuequan Lu, Deakin University 
  Anum Masood, Norwegian University of Science and Technology 
  Weiliang Meng, Institute of Automation, Chinese Academy of Sciences 
  Bochang Moon, Gwangju Institute of Science and Technology 
  Soraia Musse, Pontificia Universidade Catolica do Roi Grande do Sul, PUCRS, Brazil 
  Anam Nazir, COMSATS University Islamabad, Wah Campus 
  Junyong Noh, Korea Advanced Institute of Science and Technology 
  Nicolas Pronost, Université Claude Bernard Lyon 1 
  Filip Sadlo, Heidelberg University 
  Yun Sheng, Liverpool John Moores University 
  Alexei Sourin, Nanyang Technological University 
  Zhigang Tu, Wuhan University 
  Petr Vasik, Brno University of Technology 
  Wencheng Wang, Institute of Software, Chinese Academy of Sciences 
  Tien-Tsin Wong, The Chinese University of Hong Kong, Hong Kong, China 
  Chunxia Xiao, Wuhan University 
  Kai Xu, National University of Defense Technology 
  Kun Xu, Tsinghua University 
  Meng Yang, Beijing Forestry University 
  Xiaosong Yang, Bournemouth University 
  Junfeng Yao, Xiamen University 
  Jian Zhang, Bournemouth University 
  Jianmin Zheng, Nanyang Technological University 
  Lei Zhu, The Hong Kong University of Science and Technology (Guangzhou) 
  Nadine Aburumman, Brunel University 
  Euijoon Ahn, James Cook University 
  Hui Cui, La Trobe University 
  Sheng Li, Peking University 

 contact  
   
 For any questions regarding  
 the conference programme 
  publications 
  invitations for accepted papers 
  Please contact the local organizing committee by email at:  

    vrar@cs.sjtu.edu.cn    

 Follow us on youtube  

 Copyright © 2024 CGI'23 Shanghai –  OnePress  theme by FameThemes

37. CAivDE_2 conference:


38. CSCL_0 conference:
Enable JavaScript and cookies to continue

39. CSCL_1 conference:
Enable JavaScript and cookies to continue

40. CSCL_2 conference:
Science Direct                  Journals & Books 
   
 ScienceDirect help 

 !  There was a problem providing the content you requested  
 Please contact us via our support center  for more information and provide the details below.  
 Reference Number: 8ea886b81bc004e5  
 IP Address: 1.54.87.107  
 User Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0  
 Timestamp: 2024-11-30 05:44:07 UTC  
   
 ::CLOUDFLARE_ERROR_1000S_BOX::   

 Elsevier             About ScienceDirect    Shopping cart    Contact and support    Terms and conditions    Privacy policy    
 We use cookies to help provide and enhance our service and tailor content and ads. By continuing you agree to the use of cookies   .  
 Copyright © 2020 Elsevier B.V. or its licensors or contributors. ScienceDirect ® is a registered trademark of Elsevier B.V.  
   
 RELX Group

41. CSCL_3 conference:
Enable JavaScript and cookies to continue

42. CAivDE_3 conference:


43. ISAGA_0 conference:
Skip to content     ISAGA   International Simulation and Gaming Association  

 Welcome to ISAGA 
  Our Activities | Menu Toggle | ISAGA Conferences 
  ISAGA Summer Schools (ISS) 
  SIGs (Special Interest Groups) 
  ISAGA Webinars hosted by SVVV 
  ISAGA Simulation and Gaming Competition (ISGC) 
  ISAGA Calendar 
  ISAGA Newsletter 
  ISAGA Newsletter Archive 
  About ISAGA | Menu Toggle | Executive Board 
  Advisory Council / Honorary Members 
  Member network 
  Member meeting 
  Global Member Network 
  Networking and Resources | Menu Toggle | Formal documents 
  Resources 
  Other SAGAs 

    ISAGA   International Simulation and Gaming Association  

 Main Menu            

 Welcome to ISAGA 
  Our Activities | Menu Toggle | ISAGA Conferences 
  ISAGA Summer Schools (ISS) 
  SIGs (Special Interest Groups) 
  ISAGA Webinars hosted by SVVV 
  ISAGA Simulation and Gaming Competition (ISGC) 
  ISAGA Calendar 
  ISAGA Newsletter 
  ISAGA Newsletter Archive 
  About ISAGA | Menu Toggle | Executive Board 
  Advisory Council / Honorary Members 
  Member network 
  Member meeting 
  Global Member Network 
  Networking and Resources | Menu Toggle | Formal documents 
  Resources 
  Other SAGAs 

 ISAGA Conferences  
  
 The ISAGA conference is open to all people interested in the domain of simulation and gaming. It is organized as annual meeting of the simulation and gaming communities from all across the globe. In its over 50 years of history  , the conference traveled to almost every continent and visited more than 30 countries.  
  ISAGA 2025 at Stuttgart, Germany, from July 15 th  to 18 th  2025   
   The 56th international conference on Simulation and Gaming will be in Stuttgart. Here  is the official website.  

  Call for Contributions for ISAGA 2025 has started   
 We are pleased to announce the start of the Call for Contributions for the ISAGA25 Conference! The conference will take place from 15 to 18 July 2025 at the DHBW Stuttgart (Germany) and offers a unique platform for the exchange of innovative ideas and research in the field of simulation and gaming methods.  
  Further information and submission:  Contributing – ISAGA2025   
 Selection of topics:  
  – Artificial intelligence, big data and automation  
  – Virtual reality  
  – Sustainability and climate change  
  – Urban, spatial and transport planning  
  – Dealing with crisis and disaster management  
  – Society in transition  
  – Lifelong learning and future skills  
   
  Important dates:  
  – Submission deadline for full papers: 15 January 2025  
  – Submission deadline for posters, workshops, etc: 15 February 2025  
  – Notification of acceptance: 15 March 2025  
  We invite researchers, teachers and users to submit their contributions. Use this opportunity to present your work to an international audience and make valuable contacts!  
  ISAGA 2024 at Christchurch, New Zealand, from July 8th to 12th 2024   
 We are very happy about the ISAGA Conference 2024  at the University of Canterbury, in Ōtautahi Christchurch  , New Zealand. The conference was on “Simulation Gaming Across Borders”  . The Conference website is here: ISAGA 2024 | International Simulation and Gaming Association | ISAGA is connected with different saga’s around the world   
 Here  you can find a wonderful report on the conference and get an insight into what was on offer there.  

   Past conferences  
  
 Year,  # | Location | Theme | Organizers | Publications 
 2024, 55th | Christchurch, New Zealand | Simulation Gaming Across Borders | Heide Lukosch, Maria Freese, University of Canterbury | Forthcoming 
 2023, 54th | La Rochelle, France | Simulation and Gaming for social and environmental transitions | Nicolas Becu, La Rochelle University – LIENSs laboratory | https://shs.hal.science/halshs-04209935 
 2022, 53rd | Boston, MA, USA | Gaming and Simulation for Social Impact | Casper Harteveld | Simulation and Gaming for Social Impact: 53rd International Simulation and Gaming Association Conference, ISAGA 2022, Boston, MA, USA, July 11–14, 2022, Revised Selected Papers | SpringerLink 
 2021, 52nd | Indore, India (online) | Gaming, Simulation and Innovations: Challenges and Opportunities | Shri Vaishnav Vidyapeeth Vishwavidyalaya university | Dhar, U., Dubey, J., Dumblekar, V., Meijer, S., Lukosch, H. (2022). Gaming, Simulation and Innovations: Challenges and Opportunities. 
 2020, 51th | Stoke-on-Trent, UK (online) | Serious Games | Special ISAGA track at the 6th Joint International Conference on Serious Games, JCSG 2020 | Ma, M., Fletcher, Bobbie, S., Göbel, S., Hauge, J.B., Marsh, T. (2020). Serious Games. Joint International Conference, JCSG 2020 
 2019, 50th | Warsaw, Poland | Simulation & Gaming through Times and Across Disciplines. Past and Future, Heritage and Progress | Marcin Wardaszko, Błażej Podgórski, Małgorzata Ćwil, Anna Winniczuk, Michał Jakubowski, Wanda Widziszewska, Anna Świątkowska | Wardaszko, M. (Ed.) (2019). Simulation & Gaming Through Times and Across Disciplines. Past and Future, Heritage and Progress. – Kozminski University, Warsaw.  
  ISBN 978-83-66502-01-7.  
   
  Wardaszko, M., Meijer, S., Lukosch, H., Kanegae, H., Kriz, W.C., Grzybowska-Brzezińska, M. (Eds.) (2021). Simulation Gaming Through Times and Disciplines – 50th International Simulation and Gaming Association Conference, ISAGA 2019, Warsaw, Poland. 
 2018, 49th | Bangkok, Thailand | Active Learning and Neo-Simulation & Gaming: Sharing Wisdom | Urairat Yamchuti, Songsri Soranastaporn, Ryoju Hamada | Proceedings of the 49 th  ISAGA Conference “Active Learning and Neo-Simulation and Gaming: Sharing Wisdom”. – Mahidol University Salaya Campus, Nakorn Pathom, Thailand, 2018.  
   
  Hamada, R., Soranastaporn, S., Kanegae, H., Dumrongrojwatthana, P., Chaisanit, S., Rizzi, P., Dumblekar, V. (Eds.) (2019). Neo-Simulation and Gaming Toward Active Learning. 
 2017, 48th | Delft, the Netherlands | Simulation Games for Sustainable Cities and Smart Infrastructures | Heide Lukosch, Geertje Bekebrede, Rens Kortmann | Lukosch, H.K., Bekebrede, G., Kortmann, R. (Eds.) (2018). Simulation Gaming. Applications for Sustainable Cities and Smart Infrastructures – 48th International Simulation and Gaming Association Conference, ISAGA 2017, Delft, The Netherlands 
 2016, 47th | Melbourne, Australia | Leadership in Simulation and Gaming | Todd Mason and Elyssebeth Leigh | Monaghan, M. (ed.) (2016). Australasian Simulation Congress. Proceedings. Melbourne, Simulation Australasia.  
  ISBN 978-0-9925960-2-6.  
   
  Naweed, A., Wardaszko, M., Leigh, E., Meijer, S. (Eds.) (2018). Intersections in Simulation and Gaming – 21st Annual Simulation Technology and Training Conference, SimTecT 2016, and 47th International Simulation and Gaming Association Conference, ISAGA 2016, Held as Part of the First Australasian Simulation Congress, ASC 2016, Melbourne, VIC, Australia 
 2015, 46th | Kyoto, Japan | Hybrid Simulation and Gaming in the Networked Society | Hidehiko Kanegae | Kaneda, T., Kanegae, H., Rizzi, P., & Toyoda, Y. (Eds.) (2015). Proceedings of the 46th ISAGA Conference Hybrid Simulation & Gaming in the Networked Society. ISBN 978-4-902590-44-9.  
   
  Kaneda, T., Kanegae, H., Rizzi, P. & Toyoda, Y. (Eds.) (2016). Hybrid Simulation and Gaming in the Network Society. TSS, volume 9. Springer, Singapore. 
 2014, 45th | Dornbirn, Austria | The Shift from Teaching to Learning: Individual, Collective and Organizational Learning Through Gaming & Simulation | Willy Kriz | Kriz, W.C. (Ed.) (2014). The Shift from Teaching to Learning: Individual, Collective and Organizational Learning Through Gaming & Simulation. Proceedings of the 45th Conference of the International Simulation and Gaming Association, Dornbirn, 2014. Bielefeld: W. Bertelsmann Verlag. (and CD-ROM: ISBN 978-3-7639-5422-3).  
   
  Duke, R.D. & Kriz, W.C. (Eds.) (2014). Back to the Future of Gaming. Bielefeld: W. Bertelsmann Verlag 
 2013, 44th | Stockholm, Sweden | Gaming in an Interconnected Industry | Sebastiaan Meijer | Meijer S.A., Smeds R. (Eds.) (2013). Electronic Proceedings of ISAGA 2013. KTH Transport Science Publication Series, Stockholm.  
   
  Meijer S.A., Smeds R. (Eds.) (2014). Frontiers in Gaming Simulation :  44th International Simulation and Gaming Association Conference, ISAGA 2013 and 17th IFIP WG 5.7 Workshop on Experimental Interactive Learning in Industrial Management, Stockholm, Sweden  . 
 2012, 43rd | Cluj-Napoca, Romania | The Journey of Change: Mapping the Process | Cătălina Oţoiu | Otoiu, C. & Otoiu, G. (Eds.) (2013) The Journey of Change: Mapping the Process. ISAGA 2012 Conference Proceedings. Cluj-Napoca, RO: Editura ASCR 
 2011, 42nd | Warsaw, Poland | Bonds & Bridges. Facing the Challenges of the Globalizing World with the Use of Simulation and Gaming | Marcin Wardaszko and Jagoda Gandziarowska-Ziołecka | Bielecki, W.T., Gandziarowska-Ziolecka, J., Pikos, A.M. & Wardaszko, M. (Eds.) (2011). Bonds & Bridges. Facing the Challenges of the Globalizing World with the Use of Simulation and Gaming. Warsaw: Poltext.  
  ISBN 978-83-7561-212-7 
 2010, 41st | Spokane WA, USA | Changing the World Through Meaningful Play | Elizabeth Murff | Beran, M. (Ed.) (2011) Changing the World Through Meaningful Play. Abstracts and Papers. ISAGA-Conference 2010. Spokane, WA: Eastern Washington University Press.  
  ISBN 978-1-4507-6269-4 
 2009, 40th  ****** | Singapore | Learn to Game, Game to Learn (http://ssagsg.org/ssagsg/isaga2009/index.html) | Geo Kin Yeo and Yiyu Cai | Yeo, G. and Cai, Y. (Eds.) (2009) Learn to Game, Game to Learn. Proceedings of the 40th annual Conference of the International Simulation and Gaming Association (ISAGA), Singapore: National University Singapore, July 2009. Society of Simulation and Gaming of Singapore. ISBN 978-981-08-3769-3 (CD-ROM).  
   
  Hill, J. and Rodrigo, M.M. (Eds.) (2012). Symposium: ISAGA 2009 Conference Proceedings. – Simulation and Gaming.  
  Volume 43. Issue 1. February 2012. https://journals.sagepub.com/toc/sagb/43/1 
 2008, 39th | Kaunas, Lithuania | Games: Virtual Worlds and Reality | Eugenijus Bagdonas and Irena Patasiene | Bagdonas, E., Patasiene, I., Jovarauskiene, D. (Eds.) (2008). Games: Virtual Worlds and Reality. ISAGA 2008 Conference book. – Technologija, Kaunas.  
   
  Bagdonas, E. & Patasiene, I. (Eds.) (2009). Games: Virtual Worlds and Reality. Selected Papers of ISAGA-2008. – Technologija, Kaunas 
 2007, 38th | Nijmegen, the Netherlands | Organizing and Learning Through Gaming and  
  Simulation | Vincent Peters and Marleen van de Westelaken | V. Peters, M. van de Westelaken, A. van Gils, & A. van Loveren (Eds.) (2007). Proceedings of the 38th Conference of the International Simulation and Gaming Association (CD-ROM). Nijmegen, The Netherlands: Stichting ISAGA Conferentie 2007.  
   
  Mayer, I. & Mastik, H. (Eds.) (2007). Organizing and Learning through Gaming and Simulation. Proceedings of ISAGA 2007. Eburon, Delft.  
  ISBN 978-90-5972-2316 
 2006, 37th | St. Petersburg, Russia | Global Interdependence of the Uniform Education Space | Yuli Porkhovnik | Porkhovnik, Y. (Ed.) (2006). Reality and Game & Game and Reality: Abstracts and Papers of the 37th Annual Conference of the International Simulation and Gaming Association (ISAGA) – St. Petersburg State University of Engineering and Economics (Engecon), St. Petersburg, Russian Federation 
 2005, 36th | Atlanta GA, USA | Serious Play: Form, Function, and Fun | Richard Teach | Narasimhan, S., & Teach, R. (Ed.) (2006). Form, Function, and Fun. ISAGA-Conference 2005. Atlanta GA, USA. The Proceedings of the 36th International Simulation and Gaming Association; 28 June – 2 July 2005 
 2004, 35th  ***** | Munich, Germany | BRIDGING THE GAP:  
  Transforming Knowledge into Action through Gaming and Simulation | Willy Kriz | Eberle, T., Kriz, W.C., Puschert, M., & Glötzner, F. (Eds.) (2004). Bridging the Gap: Transforming Knowledge Into Action Through Gaming and Simulation. Proceedings of the 35th Conference of  
  the International Simulation and Gaming Association (ISAGA). SAGSAGA, Germany 
 2003, 34th  **** | Kisarazu, Japan | Social Contributions and Responsibilities of Simulation and Gaming | Rei Shiratori | Shiratori R., Arai K., Kato F. (eds.) (2005). Gaming, Simulations, and Society: Research Scope and Perspective. Springer-Verlag, Tokyo.  
  DOI: 10.1007/b138103 
 2002, 33rd  *** | Edinburgh, Scotland, UK | Interactive Learning Through Gaming and Simulation | Fred Percival and Helen Godfrey | Fred Percival, Helen Godfrey, Phyllis Laybourn, & Sarah Murray (Eds.) (2003). Interactive Learning Through Gaming and Simulation. The International Simulation and Gaming Yearbook; Volume 11 
 2001, 32nd | Bari, Italy | On the Edge of the Millennium: A New Foundation for Gaming Simulation | Paola Rizzi, Antonio  
  Brusa and Ivan Blecic | Elena Musci (Ed.) (2001). On the Edge of the Millennium: A New Foundation for Gaming Simulation. Edizioni B.A.  
  Graphis, Bari, Italy 
 2000, 31st | Tartu, Estonia | Simulation and Gaming in the Building of the Information Society | Anne Willems | Leen Rahnu (Ed.) (2001). Bridging the Information and Knowledge Societies. Tartu, Estonia 
 1999, 30th | Sydney, Australia | Anticipating the Unexpected | Elyssebeth Leigh | Leigh, E., & McLaughlan, R. (2000). Anticipating the  
  Unexpected – ISAGA ’99: Conference Proceedings of the 30th Annual  
  Conference of the International Simulations and Gaming Association (ISAGA). UTS, Sydney 
 1998, 29th | St. Petersburg, Russia | Simulation and Gaming in Professional Education | Yuli Porkhovnik and A.  
  Fedotov | Porkhovnik, Y.M., & Novik, M.M. (eds.) (1999). Simulation and Gaming in Professional Education and Management. St. Petersburg: Evropeyskiy Dom 
 1997, 28th | Tilburg, the Netherlands | Gaming/Simulation for Policy Development and Organizational Change: beyond Looking Glass and Learning Language | Jac Geurts & Cisca Joldersma | Geurts, J., Joldersma, C., & Roelofs, E. (1998). Gaming/Simulation for Policy Development and Organizational Change. Tilburg: Tilburg University Press 
 1996, 27th | Jurmala (Riga Bay), Latvia | Simulation and Gaming for Sustainable Development | Valdis Bisters | Bisters, V. (1997). Simulation and Gaming for Sustainable Development. Riga, Latvia: Environmental Publishers  
  “Vide.” 
 1995, 26th | Valencia, Spain | Learning through Experience: Challenge and Change | Francis Watts and  
  Amparo Garca Carbonell | Garcia-Carbonell, G., & Watts, F. (1996). Simulación¡ ya! El Aprendizaje a través de la Experiencia: El Reto del Cambio [Simulation now!  
  Learning Through Experience: The challenge of Change].  
  València, Spain: Diputació de València 
 1994, 25th | Ann Arbor, MI, USA | ISAGA – The Next Generation | Richard Duke | Crookall, D., & Arai, K. (1995). Simulation and Gaming across Disciplines and Cultures: ISAGA at a Watershed; Thousand Oaks, CA: SAGE 
 1993, 24th | Bucharest, Romania | Active Teaching Methods, Simulation, and Gaming to Help the Reform | Eduard Rădăceanu | Rãdãceanu, E. (Ed.) (1994). Reform and Progress helped by Simulation and Gaming. Bucharest, Romania: IROMA 
 1992, 23rd  *** | Edinburgh, Scotland, UK | Developing Transferable Skills through Simulation and Gaming in Education and Training | Fred Percival | Percival, F., Lodge, S., and Saunders, D. (Eds.) (1993). The Simulation and Gaming Yearbook 1993, Developing Transferable Skills in Education and Training. Kogan Page, London 
 1991, 22nd | Kyoto, Japan | Global Modeling for Solving Global Problems | Hiroharu Seki | Crookall, D., Arai, K. (eds.) (1992). Global Interdependence: Simulation and Gaming Perspectives. Proceedings of the 22nd International Conference of the International Simulation and Gaming Association (ISAGA) Kyoto, Japan: 15–19 July 1991. Springer, Tokyo.  
  DOI: 10.1007/978-4-431-68189-2 
 1990, 21st  ** | Durham, NH, USA | Simulation Gaming for the Twenty-First Century | Dennis Meadows | * 
 1989, 20th | Weimar, German Democratic Republic | Transfer von Planspielen [Transfer of Gaming Simulations]] | Hans Gernert | Wissenschaftliche Zeitschrift der Hochschule für Architektur und Bauwesen. Weimar, 36 Jahrgang [1990]. Reihe B: Heft 4 
 1988, 19th | Utrecht, the Netherlands | On the Improvement of Competence | Jan Klabbers | Klabbers, J.H.G., Scheper, W.J., Takkenberg, C.A.Th., & Crookall, D. (1989). Simulation-Gaming: On the Improvement of Competence in Dealing with Complexity, Uncertainty and Value Conflicts. Oxford: Pergamon [now an imprint of Elsevier.] 
 1987, 18th | Venice, Italy | Simulation-Gaming in Education and Training | Arnaldo Ceccini and Giorgio Panizzi | Crookall, D., Klabbers, J. H.G., Coote, A., Saunders, D., Cecchini, A., & Delle Piane, A. (1988). Simulation-Gaming  
  in Education and Training. Oxford: Pergamon 
 1986, 17th | Toulon, France | Simulation & Communication | David Crookall | Crookall, D., Greenblat, C. S., Coote, A., Klabbers, J. H. G., & Watson, D. R. (1987). Simulation-Gaming in the Late 1980s. Oxford: Pergamon 
 1985, 16th | Alma-Ata, USSR | Business Games and Simulation Modelling | Vladimir Burkov | Delovye Igry i Imitacionnoe Modelirovanie: Tezisy Dokladov. 16-j seminar IFAK/ISAGA.[Business Games and Simulation Modelling: 16th IFAC/ISAGA Workshop. Abstracts of papers.] M., Institut Problem Upravleniya [Institute of Control Sciences], 1985 
 1984, 15th | Elsinore, Denmark | Eric Petterson | None published 
 1983, 14th | Sophia, Bulgaria | Simulation and Gaming in Problem-Solving and Training | Ognyan Panov and Isak Assa |  
 1982, 13th | Stirling, Scotland, UK | Problems and Prospects of Game Design | Drew Mackie | None published 
 1981, 12th | Haifa, Israel | Who Plays, Why, How and the Time Dimensions | Hubert Law-Yone | * 
 1980, 11th | Geneva, Switzerland | Simulation/Games in Education, Research and Decision-Making | Maurice Graber | Goldberg, D., & M. Graber, M. (1980). Simulation/Games in Education, Research and Decision-Making. Geneva,  
  Switzerland 
 1979, 10th | Leeuwarden, the Netherlands | How to Build a Simulation/Game | Klaas Bruin | Bruin, K., de Haan, J., Teijken, C., & Veeman, W. (1979). How to Build a Simulation/Game. Leeuwarden: Univeristy Groningen 
 1978, 9th | Lund, Sweden | Gaming Simulation on Energy | Mats Lörstad | Gaming/Simulation on Energy: Proceedings of ISAGA IX Conference (1978). Lund, Sweden: Decision Data * 
 1977, 8th | Birmingham, UK | Margaret Hobson and Robert Armstrong | None published 
 1976, 7th | Caracas, Venezuela | Simulation and Decision-Making | Estelio Breto-Flores | Breto-Flores, Emilio. (1976). Proceso de construcción de modelos y analisis de sistemas sociales. Caracas, Venezuela * 
 1975, 6th | Milan, Italy | Theory and Practice of Gaming-Simulation | Gianluigi Sartorio | None published 
 1974, 5th | Berlin, Germany | Declan Kennedy | None published 
 1973, 4th | Gaithersburg MD, USA | Cathy Greenblat and Peter House | Simulation and Gaming: Proceedings of the 12th Annual Symposium, National Gaming Council, and the 4th Annual Conference, International Simulation and Gaming Association, held at the National Bureau of Standards, Gaithersburg, Md., September 17-19, 1973. National Bureau of Standards, 1974 
 1972, 3rd | Birmingham, UK | John Taylor | None published 
 1971, 2nd | Utrecht, the Netherlands | Henk Becker | Becker, H.A. & Goudappel, H.M. (1972). Developments in Simulation and Gaming. The Netherlands: Boom Meppel 
 1970, 1st | Bad Godesberg, Germany | Richard Duke, Allan Feldt, Hans Hansen | None published 
  
  * some collected papers and abstracts are published in an extended program brochure  
 ** joint meeting of ISAGA and NASAGA  
 *** joint meeting of ISAGA and SAGSET  
 **** joint meeting of ISAGA and JASAG  
 ***** joint meeting of ISAGA and SAGSAGA  
 ****** joint meeting of ISAGA and SSAGSg  

 Search for:   Search           

 Copyright © 2024 ISAGA | Powered by Astra WordPress Theme

44. UAI_0 conference:
UAI 2023    

 Conference   Local Information  Tutorials  Workshops  Accepted Papers  Award-winning Papers  Keynote Speakers  Important Dates  Code of Conduct  Registration  Scholarships  Top Reviewers  Schedule  Hotel & Local Accommodation    
 For Authors   Call for Papers  Call for Tutorials   Call for Workshops   Submission Instructions   Conflicts of Interest  Subject Areas  Camera-ready Instructions  Presentation Instructions    
 Organization   Organizing Committee  Area Chairs  Program Committee  Reviewing Instructions  AUAI    

 UAI 2023 - Call for Papers  

  The Conference on Uncertainty in Artificial Intelligence ( UAI  ) is one of the premier international conferences on research related to learning and reasoning in the presence of uncertainty. The conference has been held every year since 1985. The upcoming 39th edition ( UAI 2023  ) will be an in-person conference with virtual elements taking place in Pittsburgh, Pennsylvania, USA from 31 July to 4 August 2023.  
 We invite papers that describe novel theory, methodology and applications related to artificial intelligence, machine learning and statistics. Papers will be assessed in a rigorous double-blind peer-review process, based on the criteria of technical correctness, novelty, clarity of writing, and potential impact. Authors are strongly encouraged to make code and data available.  
 All accepted papers will be presented in poster sessions and spotlight presentations (physically or remotely). Selected papers will have longer presentations and an assigned discussant to foster debate. All accepted papers will be published in a volume of Proceedings of Machine Learning Research (PMLR)  .  
 Deadlines and other relevant dates can be found under important dates  .  
 Important dates for authors:  
   
 17 February 2023 (23:59 Anywhere on Earth, AoE): Paper submission deadline 
  11-20 April 2023: Author response and discussion period 
  8 May 2023: Author notification 
  Papers should be submitted on OpenReview at https://openreview.net/group?id=auai.org/UAI/2023/Conference  . Please see Submission Instructions  for more details on how your manuscript should be formatted.  
 We are looking forward to building an exciting program and we aim to make the most of the advantages that a hybrid conference can create. If you have any particular positive or negative experiences that you would like to share with us, please do not hesitate to email us.  
 If you are interested in giving a tutorial or organising a workshop at UAI 2023, please contact the tutorial chairs ( uai2023chairs+tutorials@gmail.com  ) or workshop chairs ( uai2023chairs+workshop@gmail.com  ) by 10 March 2023.  
 Relevant dates:  
   
 31 July: Tutorials 
  1-3 August: Main conference 
  4 August: Workshops 
   
  Robin Evans and Ilya Shpitser  
  UAI 2023 Program Chairs  
  uai2023programchairs@gmail.com   

  Sponsors

45. ISAGA_1 conference:
People 
  RESEARCH ACTIVITIES | Socio-economic and environmental assessment 
  Participatory simulations and serious games 
  Modeling and Simulation 
  PROJECTS | GAMA Platform 
  SIMPLE 
  RAC – Serious game on waste management in Bac Hung Hai Irrigation System 
  PREMISS 
  COMOKIT 
  SUCCESS 
  Completed Projects 
  OPPORTUNITIES 
  News 

 People 
  RESEARCH ACTIVITIES | Socio-economic and environmental assessment 
  Participatory simulations and serious games 
  Modeling and Simulation 
  PROJECTS | GAMA Platform 
  SIMPLE 
  RAC – Serious game on waste management in Bac Hung Hai Irrigation System 
  PREMISS 
  COMOKIT 
  SUCCESS 
  Completed Projects 
  OPPORTUNITIES 
  News 

  News  

    News   
  ACROSS LAB at the ISAGA 2023 – 54th edition   

 ACROSS LAB at the ISAGA 2023 – 54th edition  
 07.07.2023 - acrosslab    

 Between the 4th and 7th of July 2023, the city of La Rochelle (Nouvelle Aquitaine, France), hosted the 54th edition of ISAGA (International Simulation and Gaming Association) conference. This year, the cycles of conference focused on “ Simulation and Gaming for Social and Environmental Transitions   ”. The ACROSS lab was accepted to communicate on the first results provided by the use of RÁC, a serious game built to foster social dialogue in the Bắc Hưng Hải irrigation system on the matter of waste management.  
 The research was presented on Thursday morning (06/07/23) during session 10, entitled “ Play for social and environmental changes: focus on farmers as players   ”. It was the occasion to present the game, to justify its use, present the first results, and have inspiring talks with the other panelists, also working with farmers with participatory simulations and serious games. The presentation was then followed by a discussion between the six panelists from session 10, answering questions from the public.  
 Finally, participating in ISAGA 2023 allowed us to follow up or discover inspiring research considering the way to approach gaming in research in developing countries, from design and conception to ethics and actual use.  
 Lab’s attendee: Léo Biré ( leo.bire@ird  .fr)  
 The conference proceedings: “Simulation and Gaming for Social and Environmental Transitions. Proceedings of ISAGA 2023 Conference  . Becu, N (Ed.). La Rochelle University, September 2023. ISBN: 979-10-415-2760-1.” https://shs.hal.science/halshs-04209935   
 Films of the whole conference: https://videos.univ-lr.fr/sciences-humaines-et-sociales/isaga-2023-the-54th-edition-of-the-international-simulation-and-gaming-conference-will-take-place/   
 Film of session 10: https://videos.univ-lr.fr/video/2858-paper-session-10-part-2-play-for-social-and-environmental-changes-focus-on-farmers-as-players/   

 All  
 Meetings/ Visits 
  Conference/Workshop 
  Press Release 
  Coding Camp 
  Seminars/ Exhibition 
    
 Hot News  
 Course and Conference on Artificial Intelligence for Climate Change   
 acrosslab  27/11/2024 
  ACROSS at the Science and Technology Exhibition of the Ministry of Agriculture and Rural Development   
 acrosslab  15/11/2024 
  ACROSS Representatives Join the 2nd LMI Days to Discuss Water as a Common Good   
 acrosslab  08/07/2024 
  ACROSS Intern Meeting – May 2024   
 acrosslab  31/05/2024 

  Related news  
   
 Course and Conference on Artificial Intelligence for Climate Change  
 acrosslab  27/11/2024   
 The Vietnam Institute for Advanced Study in Mathematics (VIASM), in collaboration with the Institute of Meteorology, Hydrology, and Climate Change (IMHEN); VinUniversity (VinUni); and the French Nationale Research Institute for... 
  ACROSS Representatives Join the 2nd LMI Days to Discuss Water as a Common Good  
 acrosslab  08/07/2024   
 Marseille, France – Mr. Nguyen Ngoc Doanh, Co-director of ACROSS, and Mrs. Phung Diep Anh, participated in the second edition of LMI Days, held in Marseille on June 25th and... 
  EU Funds Smart Agro-Ecological Transformation Project in Vietnam’s Mekong Delta  
 acrosslab  14/12/2023   
 (Photo credit: The STAR-FARM kick-off meeting was organized against the backdrop of the International Rice Festival in Hau Giang province © L. Vo, CIRAD) The European Union (EU) has provided... 
  GAMA Training co-organised by VinUni and UMMISCO  
 acrosslab  08/12/2023   
 During 3 days, from December 5th to 7th, 2023, UMMISCO Vietnam in collaboration with Vin University organised a training on modelling and simulation tools based on GAMA platform aiming at... 
  ACROSS at the Annual Scientific Conference of Thuyloi University  
 acrosslab  17/11/2023   
 On Friday, 17th of November 2023, ACROSS has participated in the Annual Scientific Conference organized by Thuyloi University. ACROSS team has introduced the serious game RAC which was developed for... 
  Workshop on Mathematical Models in Nature Sciences: Existence and Stability  
 acrosslab  19/07/2023   
 On the 1st August 2023, a workshop on Mathematical Models in Nature Sciences: Existence and Stability will be organised at Thuyloi University. The workshop will gather speakers/experts from different universities... 

 ACROSS – Advanced Computational Research On Sustainability Science  
  International Joint Laboratory ACROSS  
  5th Floor, A1 Building, Thuy Loi University, 175 Tay Son, Hanoi  
   
  0983 362 787    
  across@tlu.edu.vn    

 Research Activities  
 Socio-economic and environmental assessment 
  Participatory simulations and serious games 
  Modeling and Simulation 

 Projects  
 RÁC – Serious game on waste management in Bac Hung Hai Irrigation System 
  PREMISS 
  COMOKIT 
  SUCCESS 
  Completed Projects 

 COPYRIGHT © 2022 ACROSS. Powered by Letweb  .

46. UAI_1 conference:
UAI 2023    

 Conference   Local Information  Tutorials  Workshops  Accepted Papers  Award-winning Papers  Keynote Speakers  Important Dates  Code of Conduct  Registration  Scholarships  Top Reviewers  Schedule  Hotel & Local Accommodation    
 For Authors   Call for Papers  Call for Tutorials   Call for Workshops   Submission Instructions   Conflicts of Interest  Subject Areas  Camera-ready Instructions  Presentation Instructions    
 Organization   Organizing Committee  Area Chairs  Program Committee  Reviewing Instructions  AUAI    

 The Conference on Uncertainty in Artificial Intelligence (UAI) is one of the premier international conferences on research related to knowledge representation, learning, and reasoning in the presence of uncertainty. UAI is supported by the Association for Uncertainty in Artificial Intelligence (AUAI)  .  
 The conference has been held every year since 1985. The 39th edition will be held at the University Center  at Carnegie Mellon University  , Pittsburgh, PA, USA, on these dates:  
 Tutorials: July 31st, 2023 
  Main conference: August 1st - August 3rd, 2023 
  Workshops: August 4th, 2023 
   
 The Conference banquet will be held at Phipps Conservatory, close to the conference venue. See also the video here  .  

  Sponsors

47. UAI_2 conference:
UAI 2023    

 Conference   Local Information  Tutorials  Workshops  Accepted Papers  Award-winning Papers  Keynote Speakers  Important Dates  Code of Conduct  Registration  Scholarships  Top Reviewers  Schedule  Hotel & Local Accommodation    
 For Authors   Call for Papers  Call for Tutorials   Call for Workshops   Submission Instructions   Conflicts of Interest  Subject Areas  Camera-ready Instructions  Presentation Instructions    
 Organization   Organizing Committee  Area Chairs  Program Committee  Reviewing Instructions  AUAI    

 UAI 2023 - Call for Papers  

  The Conference on Uncertainty in Artificial Intelligence ( UAI  ) is one of the premier international conferences on research related to learning and reasoning in the presence of uncertainty. The conference has been held every year since 1985. The upcoming 39th edition ( UAI 2023  ) will be an in-person conference with virtual elements taking place in Pittsburgh, Pennsylvania, USA from 31 July to 4 August 2023.  
 We invite papers that describe novel theory, methodology and applications related to artificial intelligence, machine learning and statistics. Papers will be assessed in a rigorous double-blind peer-review process, based on the criteria of technical correctness, novelty, clarity of writing, and potential impact. Authors are strongly encouraged to make code and data available.  
 All accepted papers will be presented in poster sessions and spotlight presentations (physically or remotely). Selected papers will have longer presentations and an assigned discussant to foster debate. All accepted papers will be published in a volume of Proceedings of Machine Learning Research (PMLR)  .  
 Deadlines and other relevant dates can be found under important dates  .  
 Important dates for authors:  
   
 17 February 2023 (23:59 Anywhere on Earth, AoE): Paper submission deadline 
  11-20 April 2023: Author response and discussion period 
  8 May 2023: Author notification 
  Papers should be submitted on OpenReview at https://openreview.net/group?id=auai.org/UAI/2023/Conference  . Please see Submission Instructions  for more details on how your manuscript should be formatted.  
 We are looking forward to building an exciting program and we aim to make the most of the advantages that a hybrid conference can create. If you have any particular positive or negative experiences that you would like to share with us, please do not hesitate to email us.  
 If you are interested in giving a tutorial or organising a workshop at UAI 2023, please contact the tutorial chairs ( uai2023chairs+tutorials@gmail.com  ) or workshop chairs ( uai2023chairs+workshop@gmail.com  ) by 10 March 2023.  
 Relevant dates:  
   
 31 July: Tutorials 
  1-3 August: Main conference 
  4 August: Workshops 
   
  Robin Evans and Ilya Shpitser  
  UAI 2023 Program Chairs  
  uai2023programchairs@gmail.com   

  Sponsors

48. ISAGA_2 conference:
Skip to content     ISAGA   International Simulation and Gaming Association  

 Welcome to ISAGA 
  Our Activities | Menu Toggle | ISAGA Conferences 
  ISAGA Summer Schools (ISS) 
  SIGs (Special Interest Groups) 
  ISAGA Webinars hosted by SVVV 
  ISAGA Simulation and Gaming Competition (ISGC) 
  ISAGA Calendar 
  ISAGA Newsletter 
  ISAGA Newsletter Archive 
  About ISAGA | Menu Toggle | Executive Board 
  Advisory Council / Honorary Members 
  Member network 
  Member meeting 
  Global Member Network 
  Networking and Resources | Menu Toggle | Formal documents 
  Resources 
  Other SAGAs 

    ISAGA   International Simulation and Gaming Association  

 Main Menu            

 Welcome to ISAGA 
  Our Activities | Menu Toggle | ISAGA Conferences 
  ISAGA Summer Schools (ISS) 
  SIGs (Special Interest Groups) 
  ISAGA Webinars hosted by SVVV 
  ISAGA Simulation and Gaming Competition (ISGC) 
  ISAGA Calendar 
  ISAGA Newsletter 
  ISAGA Newsletter Archive 
  About ISAGA | Menu Toggle | Executive Board 
  Advisory Council / Honorary Members 
  Member network 
  Member meeting 
  Global Member Network 
  Networking and Resources | Menu Toggle | Formal documents 
  Resources 
  Other SAGAs 

 Member meeting  
  
 Meeting 2024  
 The 2024 member meeting was held online. The date and time: 17 September 2024, 11amCET/9pm NZT, on Zoom.  
 You find the documents for the meeting below!  
  ISAGA Member meeting 2024 HL NW  Download    
  Annual-report-ISAGA-20240626  Download    
  Financial-Report-ISAGA-20240626  Download    
  ISAGA Annual Member Meeting 2024 Protocol  Download    
 Meeting 2023  
 The 2023 member meeting was held in conjunction to the ISAGA conference in La Rochelle, France, and was a physical meeting on Tuesday July 4th, 2023 at 16.45. You can find three documents submitted: The Member meeting notes, the Annual Report (with integrated policy plan) and the Financial report.  
 Agenda of the meeting:  
  1. Opening and Welcome  
  2. Annual Report  
  3. Financial Report  
  4. Conferences 2024 – 2025  
  5. Election to the EB (1 member)  
  6. AoB  
  7. Closure  
  ISAGA Member Meeting 230704_La Rochelle  Download    
  Annual-report-ISAGA-EB-2023-HL-230615  Download    
  Financial-Report-ISAGA-2022-23-concept-V1  Download    
 Meeting 2022  
 The 2022 member meeting was held on 2022/10/21 at 13.00 – 14.30 CET. It was an online meeting on Zoom.  
  There are two documents submitted before the meeting: The Annual Report (with integrated policy plan) and the Financial report.  
  Annual-report-ISAGA-EB-2021-221017  Download    
  Financial-Report-ISAGA-2021-22-final-version  Download    
 Meeting notes of the meeting, and the slides including presentation of the candidates can be found below.  
  Isaga-members-meeting-notes-21102022_final  Download    
 Membership-meeting-presentation  Download    
 Meeting 2021  
  2021-Meeting-Notes-Part-B-final  Download    
  2021-Meeting-Notes-Part-A-final  Download    
  
 The 2021 meeting was held online:  
 The documents for the meeting can be found here:  
  Midterm-Financial-Report-ISAGA-2020-21-V2  Download    
  FInal-Policy-Plan-210906  Download    
 Meeting 2020  
 The Member Meeting 2020 was for the first time organized in a digital format.  
  Screenshot of members happy to meet online!   Documents of the meeting can be found here:  
 Financial-Report-ISAGA-2019-20  Download    
 Policy_Plan_2020-2021-final  Download    
 Approval-financial-report-2020-by-Rens-Kortman-Tu-Delft-the-Netherlands  Download    
 Minutes-of-ISAGA2019-GA1  Download    
 Minutes-of-ISAGA2019-GA2  Download    

 Search for:   Search           

 Copyright © 2024 ISAGA | Powered by Astra WordPress Theme

49. ISAGA_3 conference:
Anglais 
    
 Connection    
   
 Create an account  Password lost    
   
 Menu  Home 
  Theme 
  Program 
  - Keynotes 
  - Paper sessions (in-person) 
  - Workshops 
  - Posters 
  - Public event and exhibition stands 
  - Des jeux sérieux pour les transitions sociales et environnementales 
  - Social events 
  - Online session 
  Registration info 
  Prepare your venue 
  Organizers 
  Important dates 
  Submission info 
  Related events 
  Contact 
      
 Registrations  Registration 

 To help you prepare your venue to ISAGA conference in La Rochelle, these are the important dates to take into account.  

 Call For Papers is open since 23 rd  November 2022 – you can submit anytime until the deadline | (submissions are closed) 
   
  Registrations are open since 1 | st | February 2023 
   
  13 | th | February 2023 | – Submission deadline for Papers, Extended abstracts, and Thematic sessions 
  Extended deadline: 27  th   February | (submissions are closed) 
  6  th   March | (submissions are closed) – Submission deadline for Posters, Game demonstration workshops, Thematic activity workshops, and Game exhibition stands 
    
 14 | th | March 2023 | – Notification of acceptance 
  Shifted to 21  st   March | (submissions are closed) 
   
  2 nd  May 2023 | – Delivery of the final versions for Papers, Extended abstract, and Thematic sessions 
  22 nd  May 2023 | – Delivery of the final version of the abstract for Posters, Game demonstration workshops, Thematic activity workshops, and Game exhibition stands (abstracts will be included in the Conference booklet) 
   
  1 | st | June 2023 - Register before this date to benefit from the early bid registration fee 

 28 | th | June 2023 – Online-only session of ISAGA 2023 conference 
    
 4 | th | to 7 | th | July 2023 – ISAGA 2023 conference in La Rochelle, France (in-person only) 

 For those who cannot travel, an additionnal day for online-only paper presentations will be organized on the 28 th  June 2023. The dates for the submission deadline, notification of acceptance and delivery of the final version  , are the same as for the in-person conference.   

 More information will be communicated as the organisation of the conference progresses.   

 Application Colloque - L'application de gestion des colloques est un projet soutenu historiquement par l'Union Européenne dans le cadre du programme Innova-TIC.   
 Legal Notice

50. UAI_3 conference:
UAI 2023    

 Conference   Local Information  Tutorials  Workshops  Accepted Papers  Award-winning Papers  Keynote Speakers  Important Dates  Code of Conduct  Registration  Scholarships  Top Reviewers  Schedule  Hotel & Local Accommodation    
 For Authors   Call for Papers  Call for Tutorials   Call for Workshops   Submission Instructions   Conflicts of Interest  Subject Areas  Camera-ready Instructions  Presentation Instructions    
 Organization   Organizing Committee  Area Chairs  Program Committee  Reviewing Instructions  AUAI    

 UAI 2023 - Accepted Papers  

  There will be 243 papers presented at the conference. The list of papers with links to the PMLR page is below.  
  
 ID: 8 | Exploration for Free: How Does Reward Heterogeneity Improve Regret in Cooperative Multi-agent Bandits?   
  
 Xuchuang Wang, Lin Yang, Yu-Zhen Janice Chen, Xutong Liu, Mohammad Hajiesmaili, Don Towsley, John C.S. Lui  

  TL;DR:  We study the free exploration mechanism in the multi-agent multi-armed bandits with heterogeneous reward model.   Abstract:   
 This paper studies a cooperative multi-agent bandit scenario in which the rewards observed by agents are heterogeneous---one agent's meat can be another agent's poison. Specifically, the total reward observed by each agent is the sum of two values: an arm-specific reward, capturing the intrinsic value of the arm, and a privately-known agent-specific reward, which captures the personal preference/limitations of the agent. This heterogeneity in total reward leads to different local optimal arms for agents but creates an opportunity for *free exploration* in a cooperative setting---an agent can freely explore its local optimal arm with no regret and share this free observation with some other agents who would suffer regrets if they pull this arm since the arm is not optimal for them. We first characterize a regret lower bound that captures free exploration, i.e., arms that can be freely explored have no contribution to the regret lower bound. Then, we present a cooperative bandit algorithm that takes advantage of free exploration and achieves a near-optimal regret upper bound which tightly matches the regret lower bound up to a constant factor. Lastly, we run numerical simulations to compare our algorithm with various baselines without free exploration. 
 ID: 11 | ViBid: Linear Vision Transformer with Bidirectional Normalization   
  
 Jeonggeun Song, Heung-Chang Lee  

  TL;DR:  We empirically demonstrated the shortcomings of softmax-free and the significance of softmax in attention through BiNorm experiments. Binorm is the simplest adaptation of the current matrix multiplication order-changing algorithms.   Abstract:   
 The vision transformer has achieved state-of-the-art performance in various vision tasks; however, the memory consumption is larger than those of previous convolutional neural network based models because of O(N^2) time and memory complexity of the general self-attention models. Many approaches aim to change the complexity to O(N) to solve this problem; however, they stack deep convolutional layers to retain locality or complicate the architecture as seen in window attention, to compensate for the performance degradation. To solve these problems, we propose ViBid algorithm, which resolves the complexity problem of O(N^2) by replacing Softmax with bidirectional normalization (BiNorm). In addition, it has a much simpler architecture than the existing transformer model with O(N) complexity. Owing to our simple architecture, we were able to use larger resolutions for training, and we obtained a lighter and superior GPU throughput model with competitive performance. ViBid can be used with any transformer method that uses queries, keys, and values (QKV) because of BiNorm, and it is quite universal due to its simple architectural structure. 
 ID: 24 | Pessimistic Model Selection for Deep Reinforcement Learning   
  
 Chao-Han Huck Yang, Zhengling Qi, Yifan Cui, Pin-Yu Chen  

  TL;DR:  A pessimistic model selection approach for offline deep reinforcement with a theoretical guarantee is presented.   Abstract:   
 Deep Reinforcement Learning (DRL) has demonstrated great potentials in solving sequential decision making problems in many applications. Despite its promising performance, practical gaps exist when deploying DRL in real-world scenarios. One main barrier is the over-fitting issue that leads to poor generalizability of the policy learned by DRL. In particular, for offline DRL with observational data, model selection is a challenging task as there is no ground truth available for performance demonstration, in contrast with the online setting with simulated environments. In this work, we propose a pessimistic model selection (PMS) approach for offline DRL with a theoretical guarantee, which features a tuning-free framework for finding the best policy among a set of candidate models. Two refined approaches are also proposed to address the potential bias of DRL model in identifying the optimal policy. Numerical studies demonstrated the superior performance of our approach over existing methods. 
 ID: 31 | RDM-DC: Poisoning Resilient Dataset Condensation with Robust Distribution Matching   
  
 Tianhang Zheng, Baochun Li  

    Abstract:   
 Dataset condensation aims to condense the original training dataset into a small synthetic dataset for data-efficient learning. The recently proposed dataset condensation techniques allow the model trainers with limited resources to learn acceptable deep learning models on a small amount of synthetic data. However, in an adversarial environment, given the original dataset as a poisoned dataset, dataset condensation may encode the poisoning information into the condensed synthetic dataset. To explore the vulnerability of dataset condensation to data poisoning, we revisit the state-of-the-art targeted data poisoning method and customize a targeted data poisoning algorithm for dataset condensation. By executing the two poisoning methods, we demonstrate that, when the synthetic dataset is condensed from a poisoned dataset, the models trained on the synthetic dataset may predict the targeted sample as the attack-targeted label. To defend against data poisoning, we introduce the concept of poisoned deviation to quantify the poisoning effect. We further propose a poisoning-resilient dataset condensation algorithm with a calibration method to reduce poisoned deviation. Extensive evaluations demonstrate that our proposed algorithm can protect the synthetic dataset from data poisoning with minor performance drop. 
 ID: 34 | Online Estimation of Similarity Matrices with Incomplete Data   
  
 Fangchen Yu, Yicheng Zeng, Jianfeng Mao, Wenye Li  
   
    [link to video]   
   
  TL;DR:  The paper proposes a series of matrix correction algorithms that estimate similarity matrices with incomplete data streams in different online scenarios.   Abstract:   
 The similarity matrix measures the pairwise similarities between a set of data points. It is an essential concept in data processing and is routinely used in practical applications. Obtaining the similarity matrix is usually trivial when the data points are completely observed. However, getting a high-quality similarity matrix often turns hard when there are incomplete observations, which becomes even more complex on sequential data streams. To address the challenge, we propose matrix correction algorithms that leverage the positive semi-definiteness of the similarity matrix to provide improved similarity estimation in both offline and online scenarios. Our approaches have a solid theoretical guarantee of performance and excellent potential for parallel execution on large-scale data. They also exhibit high effectiveness and efficiency in empirical evaluations with significantly improved results over the classical imputation-based methods, benefiting downstream applications with superior performance. 
 ID: 35 | Consistent Emphatic Temporal-Difference Learning   
  
 Jiamin He, Fengdi Che, Yi Wan, A. Rupam Mahmood  
   
    [link to video]   
   
  TL;DR:  We proposed the first practical consistent off-policy TD algorithm and showed its competitive performance.   Abstract:   
 Off-policy policy evaluation has been a critical and challenging problem in reinforcement learning, and Temporal-Difference (TD) learning is one of the most important approaches for addressing it. Notably, Full Importance-Sampling TD is the only existing off-policy TD method that is guaranteed to find the on-policy TD fixed point in the linear function approximation setting but, unfortunately, has a high variance and is scarcely practical. This notorious high variance issue motivates the introduction of Emphatic TD, which tames down the variance but has a biased fixed point. Inspired by these two methods, we propose a new consistent algorithm with a transient bias, which strikes a balance between bias and variance. Further, we unify the new algorithm with several existing algorithms and obtain a new family of consistent algorithms called \emph{Consistent Emphatic TD} (CETD($\lambda$, $\beta$, $\nu$)), which can control a smooth bias-variance trade-off by varying the speed at which the transient bias fades. Through theoretical analysis and experiments on a didactic example, we validate the consistency of CETD($\lambda$, $\beta$, $\nu$). Moreover, we show that CETD($\lambda$, $\beta$, $\nu$) converges faster to the lowest error in a complex task with a high variance. 
 ID: 39 | Learning Choice Functions with Gaussian Processes   
  
 Alessio Benavoli, Dario Azzimonti, Dario Piga  
   
    [link to video]   
   
  TL;DR:  We develop a Gaussian Process based-method to learn choice functions from choice data via Pareto rationalisation.   Abstract:   
 In consumer theory, ranking available objects by means of preference relations yields the most common description of individual choices. However, preference-based models assume that individuals: (1) give their preferences only between pairs of objects; (2) are always able to pick the best preferred object. In many situations, they may be instead choosing out of a set with more than two elements and, because of lack of information and/or incomparability (objects with contradictory characteristics), they may not able to select a single most preferred object. To address these situations, we need a choice-model which allows an individual to express a set-valued choice. Choice functions provide such a mathematical framework. We propose a Gaussian Process model to learn choice functions from choice-data. The proposed model assumes a multiple utility representation of a choice function based on the concept of Pareto rationalisation, and derives a strategy to learn both the number and the values of these latent multiple utilities. Simulation experiments demonstrate that the proposed model outperforms the state-of-the-art methods. 
 ID: 40 | Exploiting Inferential Structure in Neural Processes   
  
 Dharmesh Tailor, Mohammad Emtiyaz Khan, Eric Nalisnick  

    Abstract:   
 Neural Processes (NPs) are appealing due to their ability to perform fast adaptation based on a context set. This set is encoded by a latent variable, which is often assumed to follow a simple distribution. However, in real-word settings, the context set may be drawn from richer distributions having multiple modes, heavy tails, etc. In this work, we provide a framework that allows NPs’ latent variable to be given a rich prior defined by a graphical model. These distributional assumptions directly translate into an appropriate aggregation strategy for the context set. Moreover, we describe a message-passing procedure that still allows for end-to-end optimization with stochastic gradients. We demonstrate the generality of our framework by using mixture and Student-t assumptions that yield improvements in function modelling and test-time robustness. 
 ID: 41 | Inference and Sampling of Point Processes from Diffusion Excursions   
 [spotlight]  
 Ali Hasan, Yu Chen, Yuting Ng, Mohamed Abdelghani, Anderson Schneider, Vahid Tarokh  

  TL;DR:  We develop methods to represent point processes in terms of excursions of a diffusion.   Abstract:   
 Point processes often have a natural interpretation with respect to a continuous process. We propose a point process construction that describes arrival time observations in terms of the state of a latent diffusion process. In this framework, we relate the return time of diffusion in a continuous path space to new arrivals of the point process. These models arise in many disciplines, such as financial settings where actions in a market are determined by a hidden continuous price or in neuroscience where a latent stimulus generates spike trains. Based on the developments in It\^o's excursion theory, we describe computational methods for inferring and sampling from the point process derived from the diffusion process. We provide numerical examples for the proposed method using both simulated and real data to illustrate the approach. The proposed methods and framework provide a basis for interpreting point processes through the lens of a diffusion. 
 ID: 42 | Learning Robust Representation for Reinforcement Learning with Distractions by Reward Sequence Prediction   
  
 Qi Zhou, Jie Wang, Qiyuan Liu, Yufei Kuang, Wengang Zhou, Houqiang Li  

  TL;DR:  Our method learns robust representations by predicting reward sequences via a novel TD-style algorithm, achieving state-of-the-art sample efficiency and generalization in environments with distractions.   Abstract:   
 Reinforcement learning algorithms have achieved impressive success in learning behaviors from pixels. However, their application to real-world tasks remains challenging because of their sensitivity to visual distractions (e.g., changes in viewpoint and light). A major reason is that the learned representations often suffer from overfitting task-irrelevant information. By comparing several representation learning methods, we find that the key to robust representation learning is the choice of prediction targets. Therefore, we propose a novel representation learning approach---namely, Reward Sequence Prediction (RSP)---that uses reward sequences or their transforms (e.g., discrete time Fourier transform) as prediction targets. RSP can learn robust representations efficiently because reward sequences rarely contain task-irrelevant information while providing sufficient supervised signals to accelerate representation learning. An appealing feature is that RSP makes no assumption about the type of distractions and thus can improve performance even when multiple types of distractions exist. We evaluate our approach in Distracting Control Suite. Experiments show that our method achieves state-of-the-art sample efficiency and generalization ability in tasks with distractions. 
 ID: 45 | Information Theoretic Clustering via Divergence Maximization among Cluster Distributions   
  
 Sahil Garg, Mina Dalirrooyfard, Anderson Schneider, Yeshaya Adler, Yuriy Nevmyvaka, Yu Chen, Fengpei Li, Guillermo Cecchi  

    Abstract:   
 Information-theoretic clustering is one of the most promising and principled approaches to finding clusters with minimal apriori assumptions. The key criterion therein is to maximize the mutual information between the data points and their cluster labels. We instead propose to maximize the Kullback‚ÄìLeibler divergence between the underlying distributions associated to clusters (referred to as cluster distributions). We show it to be equivalent to optimizing over the mutual information criterion while simultaneously maximizing cross entropy between the cluster distributions. For practical efficiency, we propose to empirically estimate the objective of KL-D between clusters in its dual form leveraging deep neural nets as a dual function approximator. Remarkably, our theoretical analysis establishes that estimating the divergence measure in its dual form simplifies the problem of clustering to one of optimally finding k ‚àí 1 cut points for k clusters in the 1-D dual functional space. Overall, our approach enables linear-time clustering algorithms with theoretical guarantees of near-optimality, owing to the submodularity of the objective. We show the empirical superiority of our approach w.r.t. current state-of-the-art methods on the challenging task of clustering noisy timeseries as observed in domains such as neuroscience, healthcare, financial markets, spatio-temporal environmental dynamics, etc. 
 ID: 46 | In- or Out-of-Distribution Detection via Dual Divergence Estimation   
  
 Sahil Garg, Sanghamitra Dutta, Mina Dalirrooyfard, Anderson Schneider, Yuriy Nevmyvaka  

    Abstract:   
 Detecting out-of-distribution (OOD) samples is a problem of practical importance for a reliable use of deep neural networks (DNNs) in production settings. The corollary to this problem is the detection in-distribution (ID) samples, which is applicable to domain adaptation scenarios for augmenting a train set with ID samples from other data sets, or to continual learning for replay from the past. For both ID or OOD detection, we propose a principled yet simple approach of (empirically) estimating KL-Divergence, in its dual form, for a given test set w.r.t. a known set of ID samples in order to quantify the contribution of each test sample individually towards the divergence measure and accordingly detect it as OOD or ID. Our approach is compute-efficient and enjoys strong theoretical guarantees. For WideResnet101 and ViT-L-16, by considering ImageNet-1k dataset as the ID benchmark, we evaluate the proposed OOD detector on 51 test (OOD) datasets, and observe drastically and consistently lower false positive rates w.r.t. all the competitive methods. Moreover, the proposed ID detector is evaluated, using ECG and stock price datasets, for the task of data augmentation in domain adaptation and continual learning settings, and we observe higher efficacy compared to relevant baselines. 
 ID: 47 | On Identifiability of Conditional Causal Effects   
  
 Yaroslav Kivva, Jalal Etesami, Negar Kiyavash  

    Abstract:   
 We address the problem of identifiability of an arbitrary conditional causal effect given both the causal graph and a set of any observational and/or interventional distributions of the form $Q[S]:=P(S|do(V\setminus S))$, where $V$ denotes the set of all observed variables and $S\subseteq V$. We call this problem conditional generalized identifiability (c-gID in short) and prove the completeness of Pearl's $do$-calculus for the c-gID problem by providing sound and complete algorithm for the c-gID problem. This work revisited the c-gID problem in Lee et al. [2020], Correa et al. [2021] by adding explicitly the positivity assumption which is crucial for identifiability. It extends the results of [Lee et al., 2019, Kivva et al., 2022] on general identifiability (gID) which studied the problem for unconditional causal effects and Shpitser and Pearl [2006b] on identifiability of conditional causal effects given merely the observational distribution $P(\mathbf{V})$ as our algorithm generalizes the algorithms proposed in [Kivva et al., 2022] and [Shpitser and Pearl, 2006b]. 
 ID: 56 | Stochastic Generative Flow Networks   
 [spotlight]  
 Ling Pan, Dinghuai Zhang, Moksh Jain, Longbo Huang, Yoshua Bengio  

  TL;DR:  We propose a novel Stochastic GFlowNet method for extending GFlowNets to the more general stochastic environments.   Abstract:   
 Generative Flow Networks (or GFlowNets for short) are a family of probabilistic agents that learn to sample complex combinatorial structures through the lens of ``inference as control''. They have shown great potential in generating high-quality and diverse candidates from a given energy landscape. However, existing GFlowNets can be applied only to deterministic environments, and fail in more general tasks with stochastic dynamics, which can limit their applicability. To overcome this challenge, this paper introduces Stochastic GFlowNets, a new algorithm that extends GFlowNets to stochastic environments. By decomposing state transitions into two steps, Stochastic GFlowNets isolate environmental stochasticity and learn a dynamics model to capture it. Extensive experimental results demonstrate that Stochastic GFlowNets offer significant advantages over standard GFlowNets as well as MCMC- and RL-based approaches, on a variety of standard benchmarks with stochastic dynamics. 
 ID: 67 | Personalized Federated Domain Adaptation for Item-to-Item Recommendation   
  
 Ziwei Fan, Trong Nghia Hoang, HAO DING, Anoop Deoras  

  TL;DR:  We propose and investigate a personalized federated modeling framework based on GNNs to summarize, assemble and adapt recommendation patterns across markets with heterogeneous customer behaviors into effective local models   Abstract:   
 Item-to-Item (I2I) recommendation is an important function in most recommendation systems, which generates replacement or complement suggestions for a particular item based on its semantic similarities to other cataloged items. Given that subsets of items in a recommendation system might be co-interacted with by the same set of customers, graph-based models, such as graph neural networks (GNNs), provide a natural framework to combine, ingest and extract valuable insights from such high-order relational interactions between cataloged items, as well as their metadata features, as has been shown in many recent studies. However, learning GNNs effectively for I2I requires ingesting a large amount of relational data, which might not always be available, especially in new, emerging market segments. To mitigate this data bottleneck, we postulate that recommendation patterns learned from existing mature market segments (with private data) could be adapted to build effective warm-start models for emerging ones. To achieve this, we propose and investigate a personalized federated modeling framework based on GNNs to summarize, assemble and adapt recommendation patterns across market segments with heterogeneous customer behaviors into effective local models. Our key contribution is a personalized graph adaptation model that bridges the gap between recent literature on federated GNNs and (non-graph) personalized federated learning, which either does not optimize for the adaptability of the federated model or is restricted to local models with homogeneous parameterization, excluding GNNs with heterogeneous local graphs. The effectiveness of our framework is demonstrated on a real-world dataset on multiple item categories spanning multiple market segments. 
 ID: 79 | BISCUIT: Causal Representation Learning from Binary Interactions   
 [spotlight]  
 Phillip Lippe, Sara Magliacane, Sindy Löwe, Yuki M Asano, Taco Cohen, Efstratios Gavves  
   
    [link to video]   
   
  TL;DR:  BISCUIT identifies causal variables from high-dimensional observations using binary interactions between an external system (e.g. robot) and the causal variables.   Abstract:   
 Identifying the causal variables of an environment and how to intervene on them is of core value in applications such as robotics and embodied AI. While an agent can commonly interact with the environment and may implicitly perturb the behavior of some of these causal variables, often the targets it affects remain unknown. In this paper, we show that causal variables can still be identified for many common setups, e.g., additive Gaussian noise models, if the agent's interactions with a causal variable can be described by an unknown binary variable. This happens when each causal variable has two different mechanisms, e.g., an observational and an interventional one. Using this identifiability result, we propose BISCUIT, a method for simultaneously learning causal variables and their corresponding binary interaction variables. On three robotic-inspired datasets, BISCUIT accurately identifies causal variables and can even be scaled to complex, realistic environments for embodied AI. 
 ID: 80 | Memory Mechanism for Unsupervised Anomaly Detection   
  
 Jiahao Li, Yiqiang Chen, Yunbing Xing  

  TL;DR:  This paper proposed a memory mechanism to enable the model learning to know unknowns.   Abstract:   
 Unsupervised anomaly detection is a binary classification that detects anomalies in unseen samples given only unlabeled normal data. Reconstruction-based approaches are widely used, which perform reconstruction error minimization on training data to learn normal patterns and quantify the degree of anomalies by reconstruction errors on testing data. However, this approach tends to miss anomalies when the normal data has multi-pattern. Because the model generalizes unrestrictedly beyond normal patterns even to include anomaly patterns. In this paper, we proposed a memory mechanism that memorizes typical normal patterns through a capacity-controlled external differentiable matrix so that the generalization of the model to anomalies is limited by the retrieval of the matrix. We achieved state-of-the-art performance on several public benchmarks. 
 ID: 82 | Split, Count, and Share: A Differentially Private Set Intersection Cardinality Estimation Protocol   
  
 Michael Purcell, Yang Li, Kee Siong Ng  

  TL;DR:  We present a simple privacy-preserving protocol for estimating the cardinality of the intersection of two sets.   Abstract:   
 We describe a simple two-party protocol in which each party contributes a set as input. The output of the protocol is an estimate of the cardinality of the intersection of the two input sets. We show that our protocol is efficient and secure. In particular, we show that the space complexity and communication complexity are constant, the time complexity for each party is proportional to the size of their input set, and that our protocol is differentially private. We also analyze the distribution of the output of the protocol, deriving both its asymptotic distribution and finite-sample bounds on its tail probabilities. These analyses show that, when the input sets are large, our protocol produces accurate set intersection cardinality estimates. As such, we claim that our protocol is an attractive alternative to traditional private set intersection cardinality (PSI-CA) protocols when the input sets are large, exact precision is not required, and differential privacy on its own can provide sufficient protection to the underlying sensitive data. 
 ID: 84 | How to Use Dropout Correctly on Residual Networks with Batch Normalization   
  
 Bum Jun Kim, Hyeyeon Choi, Hyeonah Jang, Donggeon Lee, Sang Woo Kim  

  TL;DR:  In this study, we investigate the correct position to apply Dropout.   Abstract:   
 For the stable optimization of deep neural networks, regularization methods such as dropout and batch normalization have been used in various tasks. Nevertheless, the correct position to apply dropout has rarely been discussed, and different positions have been employed depending on the practitioners. In this study, we investigate the correct position to apply dropout. We demonstrate that for a residual network with batch normalization, applying dropout at certain positions increases the performance, whereas applying dropout at other positions decreases the performance. Based on theoretical analysis, we provide the following guideline for the correct position to apply dropout: apply one dropout after the last batch normalization but before the last weight layer in the residual branch. We provide detailed theoretical explanations to support this claim and demonstrate them through module tests. In addition, we investigate the correct position of dropout in the head that produces the final prediction. Although the current consensus is to apply dropout after global average pooling, we prove that applying dropout before global average pooling leads to a more stable output. The proposed guidelines are validated through experiments using different datasets and models. 
 ID: 85 | DeepGD3: Unknown-Aware Deep Generative/Discriminative Hybrid Defect Detector for PCB Soldering Inspection   
  
 Ching-Wen Ma, Yanwei Liu  
   
    [link to video]   
   
  TL;DR:  A generative/discriminative hybrid model effectively address the issue of performance degradation when the test samples come from new components for which no defective sample is available.   Abstract:   
 This paper presents a novel approach for detecting soldering defects in Printed Circuit Boards (PCBs) composed mainly of Surface Mount Technology (SMT) components, using advanced computer vision and deep learning techniques. The main challenge addressed is the detection of soldering defects in new components for which only examples of good soldering are available at the model training phase. To meet industrial quality standards, we must keep the leakage rate (i.e., miss detection rate) low. To address this, we design the system to be "unknown-aware" with a low unknown rate and utilize the knowledge gained from the soldering examples of old components to detect the soldering defects of new components. We evaluated the method on a real-world dataset from an electronics company. It significantly reduces the leakage rate from 1.827\% $\pm$ 3.063\% to 0.063\% $\pm$ 0.075\% with an unknown rate of 3.706\% $\pm$ 2.270\%, compared to the baseline approach. 
 ID: 88 | Low-Rank Matrix Recovery with Unknown Correspondence   
  
 Zhiwei Tang, Tsung-Hui Chang, Xiaojing Ye, Hongyuan Zha  

  TL;DR:  We formulate a new matrix recovery problem for addressing a common obstacle in utilizing heterogeneous data, and develop an efficient algorithm to solve it.   Abstract:   
 We study a matrix recovery problem with unknown correspondence: given the observation matrix $M_o=[A,\tilde P B]$, where $\tilde P$ is an unknown permutation matrix, we aim to recover the underlying matrix $M=[A,B]$. Such problem commonly arises in many applications where heterogeneous data are utilized and the correspondence among them are unknown, e.g., due to data mishandling or privacy concern. We show that, in some applications, it is possible to recover $M$ via solving a nuclear norm minimization problem. Moreover, under a proper low-rank condition on $M$, we derive a non-asymptotic error bound for the recovery of $M$. We propose an algorithm, $\text{M}^3\text{O}$ (Matrix recovery via Min-Max Optimization) which recasts this combinatorial problem as a continuous minimax optimization problem and solves it by proximal gradient with a Max-Oracle. $\text{M}^3\text{O}$ can also be applied to a more general scenario where we have missing entries in $M_o$ and multiple groups of data with distinct unknown correspondence. Experiments on simulated data, the MovieLens 100K dataset and Yale B database show that $\text{M}^3\text{O}$ achieves state-of-the-art performance over several baselines and can recover the ground-truth correspondence with high accuracy. 
 ID: 91 | Quasi-Bayesian Nonparametric Density Estimation via Autoregressive Predictive Updates   
 [spotlight]  
 Sahra Ghalebikesabi, Christopher C. Holmes, Edwin Fong, Brieuc Lehmann  

    Abstract:   
 Bayesian methods are a popular choice for statistical inference in small-data regimes due to the regularization effect induced by the prior. In the context of density estimation, the standard nonparametric Bayesian approach is to target the posterior predictive of the Dirichlet process mixture model. In general, direct estimation of the posterior predictive is intractable and so methods typically resort to approximating the posterior distribution as an intermediate step. The recent development of quasi-Bayesian predictive copula updates, however, has made it possible to perform tractable predictive density estimation without the need for posterior approximation. Although these estimators are computationally appealing, they tend to struggle on non-smooth data distributions. This is due to the comparatively restrictive form of the likelihood models from which the proposed copula updates were derived. To address this shortcoming, we consider a Bayesian nonparametric model with an autoregressive likelihood decomposition and a Gaussian process prior. While the predictive update of such a model is typically intractable, we derive a quasi-Bayesian predictive update that achieves state-of-the-art results on moderate-sized examples. 
 ID: 95 | Towards Physically Reliable Molecular Representation Learning   
 [oral]  
 Seunghoon Yi, Youngwoo Cho, Jinhwan Sul, Seung Woo Ko, Soo Kyung Kim, Jaegul Choo, Hongkee Yoon, Joonseok Lee  
   
    [slides]   
   
  TL;DR:  We propose a physics-driven molecular representation learning method powered by self-supervised masked atomic modeling, and novel evaluation schemes to ensure reliability of the model in various ways.   Abstract:   
 Estimating the energetic properties of molecular systems is a critical task in material design. Machine learning has shown remarkable promise on this task over classical force-fields, but a fully data-driven approach suffers from limited labeled data; not just the amount of available data lacks, but the distribution of labeled examples is highly skewed to stable states. In this work, we propose a molecular representation learning method that extrapolates well beyond the training distribution, powered by physics-driven parameter estimation from classical energy equations and self-supervised learning inspired from masked language modeling. To ensure reliability of the proposed model, we introduce a series of novel evaluation schemes in multifaceted ways, beyond the energy or force accuracy that has been dominantly used. From extensive experiments, we demonstrate that the proposed method is effective in discovering molecular structures, outperforming other baselines. Furthermore, we extrapolate it to the chemical reaction pathways beyond stable states, taking a step towards physically reliable molecular representation learning. 
 ID: 100 | Nonconvex Stochastic Scaled-Gradient Descent and Generalized Eigenvector Problems   
  
 Chris Junchi Li, Michael Jordan  

    Abstract:   
 Motivated by the problem of online canonical correlation analysis, we propose the \emph{Stochastic Scaled-Gradient Descent} (SSGD) algorithm for minimizing the expectation of a stochastic function over a generic Riemannian manifold. SSGD generalizes the idea of projected stochastic gradient descent and allows the use of scaled stochastic gradients instead of stochastic gradients. In the special case of a spherical constraint, which arises in generalized eigenvector problems, we establish a nonasymptotic finite-sample bound of $\sqrt{1/T}$, and show that this rate is minimax optimal, up to a polylogarithmic factor of relevant parameters. On the asymptotic side, a novel trajectory-averaging argument allows us to achieve local asymptotic normality with a rate that matches that of Ruppert-Polyak-Juditsky averaging. We bring these ideas together in an application to online canonical correlation analysis, deriving, for the first time in the literature, an optimal one-time-scale algorithm with an explicit rate of local asymptotic convergence to normality. Numerical studies of canonical correlation analysis are also provided for synthetic data. 
 ID: 105 | MDPose: Real-Time Multi-Person Pose Estimation via Mixture Density Model   
  
 Seunghyeon Seo, Jaeyoung Yoo, Jihye Hwang, Nojun Kwak  

  TL;DR:  We reformulate multi-person pose estimation task as a density estimation, enabling real-time instance-aware keypoint estimation without any additional instance identification process.   Abstract:   
 One of the major challenges in multi-person pose estimation is instance-aware keypoint estimation. Previous methods address this problem by leveraging an off-the-shelf detector, heuristic post-grouping process or explicit instance identification process, hindering further improvements in the inference speed which is an important factor for practical applications. From the statistical point of view, those additional processes for identifying instances are necessary to bypass learning the high-dimensional joint distribution of human keypoints, which is a critical factor for another major challenge, the occlusion scenario. In this work, we propose a novel framework of single-stage instance-aware pose estimation by modeling the joint distribution of human keypoints with a mixture density model, termed as MDPose. Our MDPose estimates the distribution of human keypoints' coordinates using a mixture density model with an instance-aware keypoint head consisting simply of 8 convolutional layers. It is trained by minimizing the negative log-likelihood of the ground truth keypoints. Also, we propose a simple yet effective training strategy, Random Keypoint Grouping (RKG), which significantly alleviates the underflow problem leading to successful learning of relations between keypoints. On OCHuman dataset, which consists of images with highly occluded people, our MDPose achieves state-of-the-art performance by successfully learning the high-dimensional joint distribution of human keypoints. Furthermore, our MDPose shows significant improvement in inference speed with a competitive accuracy on MS COCO, a widely-used human keypoint dataset, thanks to the proposed much simpler single-stage pipeline. 
 ID: 114 | Bayesian Numerical Integration with Neural Networks   
  
 Katharina Ott, Michael Tiemann, Philipp Hennig, Francois-Xavier Briol  

  TL;DR:  We propose a novel architecture for neural networks for numerical integration based on the Stein operator with an approximation of the Bayesian posterior based on the Laplace approximation.   Abstract:   
 Bayesian probabilistic numerical methods for numerical integration offer significant advantages over their non-Bayesian counterparts: they can encode prior information about the integrand, and can quantify uncertainty over estimates of an integral. However, the most popular algorithm in this class, Bayesian quadrature, is based on Gaussian process models and is therefore associated with a high computational cost. To improve scalability, we propose an alternative approach based on Bayesian neural networks which we call Bayesian Stein networks. The key ingredients are a neural network architecture based on Stein operators, and an approximation of the Bayesian posterior based on the Laplace approximation. We show that this leads to orders of magnitude speed-ups on the popular Genz functions benchmark, and on challenging problems arising in the Bayesian analysis of dynamical systems, and the prediction of energy production for a large-scale wind farm. 
 ID: 116 | Fast Heterogeneous Federated Learning with Hybrid Client Selection   
  
 Duanxiao Song, Guangyuan Shen, Dehong Gao, libin yang, Xukai Zhou, Shirui Pan, Wei Lou, Fang Zhou  

    Abstract:   
 Client selection schemes are widely adopted to handle the communication-efficient problems in recent studies of Federated Learning (FL). However, the large variance of the model updates aggregated from the randomly-selected unrepresentative subsets directly slows the FL convergence. We present a novel clustering-based client selection scheme to accelerate the FL convergence by variance reduction. Simple yet effective schemes are designed to improve the clustering effect and control the effect fluctuation, therefore, generating the client subset with certain representativeness of sampling. Theoretically, we demonstrate the improvement of the proposed scheme in variance reduction. We also present the tighter convergence guarantee of the proposed method thanks to the variance reduction. Experimental results confirm the exceed efficiency of our scheme compared to alternatives. 
 ID: 118 | Probabilistic Circuits That Know What They Don't Know   
 [oral]  
 Fabrizio Ventola, Steven Braun, Zhongjie Yu, Martin Mundt, Kristian Kersting  
   
    [slides]   
   
  TL;DR:  We show that probabilistic circuits can be overconfident and not robust to out-of-distribution data, and we overcome this challenge by introducing a tractable sampling-free inference procedure to estimate model uncertainty.   Abstract:   
 Probabilistic circuits (PCs) are models that allow exact and tractable probabilistic inference. In contrast to neural networks, they are often assumed to be well-calibrated and robust to out-of-distribution (OOD) data. In this paper, we show that PCs are in fact not robust to OOD data, i.e., they don't know what they don't know. We then show how this challenge can be overcome by model uncertainty quantification. To this end, we propose tractable dropout inference (TDI), an inference procedure to estimate uncertainty by deriving an analytical solution to Monte Carlo dropout (MCD) through variance propagation. Unlike MCD in neural networks, which comes at the cost of multiple network evaluations, TDI provides tractable sampling-free uncertainty estimates in a single forward pass. TDI improves the robustness of PCs to distribution shift and OOD data, demonstrated through a series of experiments evaluating the classification confidence and uncertainty estimates on real-world data. 
 ID: 127 | Implicit Training of Energy Models for Structured Prediction   
  
 Shiv Shankar  
   
    [link to video]   
   
    Abstract:   
 Much research in deep learning is devoted to developing new model and training procedures. On the other hand, training objectives received much less attention and are often restricted to combinations of standard losses. When the objective aligns well with the evaluation metric, this is not a major issue. However when dealing with complex structured outputs, the ideal objective can be hard to optimize and the efficacy of usual objectives as a proxy for the true objective can be questionable. In this work, we argue that the existing inference network based structured prediction methods~\citep{tu-18, tu2020improving} are indirectly learning to optimize a dynamic loss objective parameterized by the energy model. We then explore using implicit-gradient based technique to learn the corresponding dynamic objectives. Our experiments show that implicitly learning a dynamic loss landscape is an effective method for improving model performance in structured prediction. 
 ID: 129 | MixupE: Understanding and Improving Mixup from Directional Derivative Perspective   
 [oral]  
 Yingtian Zou, Vikas Verma, Sarthak Mittal, Wai Hoh Tang, Hieu Pham, Juho Kannala, Yoshua Bengio, Arno Solin, Kenji Kawaguchi  
   
    [slides]   
   
  TL;DR:  We propose a theory-driven improvement of Mixup, which is theoretically and empirically validated to be effective.   Abstract:   
 Mixup is a popular data augmentation technique for training deep neural networks where additional samples are generated by linearly interpolating pairs of inputs and their labels. This technique is known to improve the generalization performance in many learning paradigms and applications. In this work, we first analyze Mixup and show that it implicitly regularizes infinitely many directional derivatives of all orders. Based on this new insight, we propose an improved version of Mixup, theoretically justified to deliver better generalization performance than the vanilla Mixup. To demonstrate the effectiveness of the proposed method, we conduct experiments across various domains such as images, tabular data, speech, and graphs. Our results show that the proposed method improves Mixup across various datasets using a variety of architectures, for instance, exhibiting an improvement over Mixup by 0.8% in ImageNet top-1 accuracy. 
 ID: 130 | Two-Stage Holistic and Contrastive Explanation of Image Classification   
  
 Weiyan Xie, Xiao-Hui Li, Zhi LIN, Leonard Poon, Caleb Chen Cao, Nevin L. Zhang  
   
    [link to video]   
   
  TL;DR:  We propose a contrastive whole-output explanation method for image classification.   Abstract:   
 Explanations for the outputs of deep neural network classifiers are essential in promoting trust and comprehension among users. Conventional methods often offer explanations only for one single class in the output and neglect other classes with high probabilities, resulting in a limited view of the model's behaviors. In this paper, we propose a holistic explanation method for image classification. It not only facilitates an overall understanding of model behavior, but also provides a framework where one can examine the evidence for discriminating competing classes, and thereby yield contrastive explanations. We demonstrate the advantages of the new method over baselines in terms of both faithfulness to the model and interpretability to users. The source code will be made available to the public upon publication of the paper. 
 ID: 136 | Approximate Thompson Sampling via Epistemic Neural Networks   
  
 Ian Osband, Zheng Wen, Seyed Mohammad Asghari, Vikranth Dwaracherla, Morteza Ibrahimi, Xiuyuan Lu, Benjamin Van Roy  

  TL;DR:  Better joint predictions lead to better decisions in deep RL.   Abstract:   
 Thompson sampling (TS) is a popular heuristic for action selection, but it requires sampling from a posterior distribution. Unfortunately, this can become computationally intractable in complex environments, such as those modeled using neural networks. Approximate posterior samples can produce effective actions, but only if they reasonably approximate joint predictive distributions of outputs across inputs. Notably, accuracy of marginal predictive distributions does not suffice. Epistemic neural networks (ENNs) are designed to produce accurate joint predictive distributions. We compare a range of ENNs through computational experiments that assess their performance in approximating TS across bandit and reinforcement learning environments. The results indicate that ENNs serve this purpose well and illustrate how the quality of joint predictive distributions drives performance. Further, we demonstrate that the \textit{epinet} --- a small additive network that estimates uncertainty --- matches the performance of large ensembles at orders of magnitude lower computational cost. This enables effective application of TS with computation that scales gracefully to complex environments. 
 ID: 138 | Lifelong Bandit Optimization: No Prior and No Regret   
  
 Felix Schur, Parnian Kassraie, Jonas Rothfuss, Andreas Krause  

  TL;DR:  We meta-learn sparse kernels for lifelong optimization of linear bandits with oracle-optimal regret guarantee.   Abstract:   
 Machine learning algorithms are often repeatedly applied to problems with similar structure over and over again. We focus on solving a sequence of bandit optimization tasks and develop LIBO, an algorithm which adapts to the environment by learning from past experience and becomes more sample-efficient in the process. We assume a kernelized structure where the kernel is unknown but shared across all tasks. LIBO sequentially meta-learns a kernel that approximates the true kernel and solves the incoming tasks with the latest kernel estimate. Our algorithm can be paired with any kernelized or linear bandit algorithm and guarantees oracle optimal performance, meaning that as more tasks are solved, the regret of LIBO on each task converges to the regret of the bandit algorithm with oracle knowledge of the true kernel. Naturally, if paired with a sublinear bandit algorithm, LIBO yields a sublinear lifelong regret. We also show that direct access to the data from each task is not necessary for attaining sublinear regret. We propose F-LIBO, which solves the lifelong problem in a federated manner. 
 ID: 139 | Learning Nonlinear Causal Effect via Kernel Anchor Regression   
  
 Wenqi Shi, Wenkai Xu  

    Abstract:   
 Learning causal effects is a fundamental problem in science. Anchor regression has been developed to address this problem for a large class of causal graphical models, though the relationships between the variables are assumed to be linear. In this work, we tackle the nonlinear setting by proposing kernel anchor regression (KAR). Beyond a classic two-stage least square (2SLS) estimator, we also study an improved variant that involves nonparametric kernel regression in three separate stages. We provide convergence results for the proposed KAR estimators and the identifiability conditions for KAR to learn the nonlinear structural equation models (SEM). Experimental results demonstrate the superior performances of the proposed KAR estimators over existing baselines. 
 ID: 142 | Amortized Inference for Gaussian Process Hyperparameters of Structured Kernels   
  
 Matthias Bitzer, Mona Meister, Christoph Zimmer  
   
    [link to video]   
   
  TL;DR:  We propose amortizing hyperparameter inference for GP's over the combined space of kernel structures and datasets.   Abstract:   
 Learning the kernel parameters for Gaussian processes is often the computational bottleneck in applications such as online learning, Bayesian optimization, or active learning. Amortizing parameter inference over different datasets is a promising approach to dramatically speed up training time. However, existing methods restrict the amortized inference procedure to a fixed kernel structure. The amortization network must be redesigned manually and trained again in case a different kernel is employed, which leads to a large overhead in design time and training time. We propose amortizing kernel parameter inference over a complete kernel-structure-family rather than a fixed kernel structure. We do that via defining an amortization network over pairs of datasets and kernel structures. This enables fast kernel inference for each element in the kernel family without retraining the amortization network. As a by-product, our amortization network is able to do fast ensembling over kernel structures. In our experiments, we show drastically reduced inference time combined with competitive test performance for a large set of kernels and datasets. 
 ID: 143 | Semi-supervised Learning of Partial Differential Operators and Dynamical Flows   
  
 Michael Rotman, Amit Dekel, Ran Ilan Ber, Lior Wolf, Yaron Oz  

    Abstract:   
 The evolution of many dynamical systems is generically governed by nonlinear partial differential equations (PDEs), whose solution, in a simulation framework, requires vast amounts of computational resources. In this work, we present a novel method that combines a hyper-network solver with a Fourier Neural Operator architecture. Our method treats time and space separately and as a result, it successfully propagates initial conditions in continuous time steps by employing the general composition properties of the partial differential operators. Following previous works, supervision is provided at a specific time point. We test our method on various time evolution PDEs, including nonlinear fluid flows in one, two, or three spatial dimensions. The results show that the new method improves the learning accuracy at the time of the supervision point, and can interpolate the solutions to any intermediate time. 
 ID: 144 | Modified Retrace for Off-Policy Temporal Difference Learning   
  
 Xingguo Chen, Xingzhou Ma, Yang Li, Guang Yang, Shangdong Yang, Yang Gao  

  TL;DR:  We proposed modified retrace to measure the off-policyness between the target policy and the behavior policy, and obtained a convergence guarantee.   Abstract:   
 Off-policy learning is a key to extend reinforcement learning as it allows to learn a target policy from a different behavior policy that generates the data. However, it is well known as ``the deadly triad'' when combined with bootstrapping and function approximation. Retrace is an efficient and convergent off-policy algorithm with tabular value functions which employs truncated importance sampling ratios. Unfortunately, Retrace is known to be unstable with linear function approximation. In this paper, we propose modified Retrace to correct the off-policy return, derive a new off-policy temporal difference learning algorithm (TD-MRetrace) with linear function approximation, and obtain a convergence guarantee under standard assumptions in both prediction and control cases. Experimental results on counterexamples and control tasks validate the effectiveness of the proposed algorithm compared with traditional algorithms. 
 ID: 147 | Learning in Online MDPs: Is there a Price for Handling the Communicating Case?   
  
 Gautam Chandrasekaran, Ambuj Tewari  

  TL;DR:  We design a low regret online learning algorithm for communicating MDPs   Abstract:   
 It is a remarkable fact that the same $O(\sqrt{T})$ regret rate can be achieved in both the Experts Problem and the Adversarial Multi-Armed Bandit problem albeit with a worse dependence on number of actions in the latter case. In contrast, it has been shown that handling online MDPs with communicating structure and bandit information incurs $\Omega(T^{2/3})$ regret even in the case of deterministic transitions. Is this the price we pay for handling communicating structure or is it because we also have bandit feedback? In this paper we show that with full information, online MDPs can still be learned at an $O(\sqrt{T})$ rate even in the presence of communicating structure. We first show this by proposing an efficient follow the perturbed leader (FPL) algorithm for the deterministic transition case. We then extend our scope to consider stochastic transitions where we first give an inefficient $O(\sqrt{T})$-regret algorithm (with a mild additional condition on the dynamics). Then we show how to achieve $O\left(\sqrt{\frac{T}{\alpha}}\right)$ regret rate using an oracle-efficient algorithm but with the additional restriction that the starting state distribution has mass at least $\alpha$ on each state. 
 ID: 149 | The Shrinkage-Delinkage Trade-off: An Analysis of Factorized Gaussian Approximations for Variational Inference   
 [oral]  
 Charles Margossian, Lawrence K. Saul  
   
    [link to video]  [slides]   
   
  TL;DR:  We examine the uncertainty deficit of Variational Inference when using a factorized Gaussian approximation.   Abstract:   
 When factorized approximations are used for variational inference (VI), they tend to understimate the uncertainty---as measured in various ways---of the distributions they are meant to approximate. We consider two popular ways to measure the uncertainty deficit of VI: (i) the degree to which it underestimates the componentwise variance, and (ii) the degree to which it underestimates the entropy. To better understand these effects, and the relationship between them, we examine an informative setting where they can be explicitly (and elegantly) analyzed: the approximation of a Gaussian,~$p$, with a dense covariance matrix, by a Gaussian,~$q$, with a diagonal covariance matrix. We prove that $q$ always underestimates both the componentwise variance and the entropy of $p$, \textit{though not necessarily to the same degree}. Moreover we demonstrate that the entropy of $q$ is determined by the trade-off of two competing forces: it is decreased by the shrinkage of its componentwise variances (our first measure of uncertainty) but it is increased by the factorized approximation which delinks the nodes in the graphical model of $p$. We study various manifestations of this trade-off, notably one where, as the dimension of the problem grows, the per-component entropy gap between $p$ and $q$ becomes vanishingly small even though $q$ underestimates every componentwise variance by a constant multiplicative factor. We also use the shrinkage-delinkage trade-off to bound the entropy gap in terms of the problem dimension and the condition number of the correlation matrix of $p$. Finally we present empirical results on both Gaussian and non-Gaussian targets, the former to validate our analysis and the latter to explore its limitations. 
 ID: 150 | Mixture of Normalizing Flows for European Option Pricing   
  
 Yongxin Yang, Timothy Hospedales  

    Abstract:   
 We present a mixture of normalizing flows (MoNF) approach to European option pricing with guarantees that its estimations are free from static arbitrage. In contrast to many existing methods that meet economic rationality constraints (e.g., non-arbitrage) by introducing auxiliary losses, our solution meets those constraints exactly by design. To achieve this, we propose to build a model for risk neutral density using normalizing flows, which results in a pricing model, instead of modelling the option pricing function directly. First, we convert the constraints for the direct pricing models to the constraints for models backed by risk neutral density estimation, then we design a specific NF architecture that meets these constraints. Furthermore, we find that employing a mixture of such normalizing flows improves the performance significantly, compared to using a deeper single NF. Finally, we present a mechanism to regularise the proposed model, and this regularisation can serve as a bridge between our method and any sample-based mathematical finance method. The evaluations on five option datasets show superiority of our method compared to mathematical finance solutions and some other neural networks based methods. 
 ID: 153 | Copula for Instance-wise Feature Selection and Rank   
  
 Hanyu Peng, Guanhua Fang, Ping Li  

  TL;DR:  Towards an end-to-end feature selection with copula to explore feature correlation   Abstract:   
 Instance-wise feature selection and ranking methods can achieve a good selection of task-friendly features for each sample in the context of neural networks. However, existing approaches that assume feature subsets to be independent are imperfect when considering the dependency between features. To address this limitation, we propose to incorporate the Gaussian copula, a powerful mathematical technique for capturing correlations between variables, into the current feature selection framework with no additional changes needed. Experimental results on both synthetic and real datasets, in terms of performance comparison and interpretability, demonstrate that our method is capable of capturing meaningful correlations. 
 ID: 155 | AUC Maximization in Imbalanced Lifelong Learning   
  
 Xiangyu Zhu, Jie Hao, Yunhui Guo, Mingrui Liu  
   
    [link to video]   
   
    Abstract:   
 Imbalanced data is ubiquitous in machine learning, such as medical or fine-grained image datasets. The existing continual learning methods employ various techniques such as balanced sampling to improve classification accuracy in this setting. However, classification accuracy is not a suitable metric for imbalanced data, and hence these methods may not obtain a good classifier as measured by other metrics (e.g., Area under the ROC Curve). In this paper, we propose a solution to enable efficient imbalanced continual learning by designing an algorithm to effectively maximize one widely used metric in an imbalanced data setting: Area Under the ROC Curve (AUC). We find that simply replacing accuracy with AUC will cause \textit{gradient interference problem} due to the imbalanced data distribution. To address this issue, we propose a new algorithm, namely DIANA, which performs a novel synthesis of model \underline{D}ecoupl\underline{I}ng \underline{AN}d \underline{A}lignment. In particular, the algorithm updates two models simultaneously: one focuses on learning the current knowledge while the other concentrates on reviewing previously-learned knowledge, and the two models gradually align during training.The results show that DIANA achieves state-of-the-art performance on the imbalanced datasets. 
 ID: 159 | Fast Teammate Adaptation in the Presence of Sudden Policy Change   
  
 Ziqian Zhang, Lei Yuan, Lihe Li, Ke Xue, Chengxing Jia, Cong Guan, Chao Qian, Yang Yu  
   
    [link to video]   
   
  TL;DR:  A new framework Fastap to handle the situation where the teammates policy suffer from sudden change within one episode in cooperative MARL.   Abstract:   
 In cooperative multi-agent reinforcement learning (MARL), where an agent coordinates with teammate(s) for a shared goal, it may sustain non-stationary caused by the policy change of teammates. Prior works mainly concentrate on the policy change during the training phase or teammates altering cross episodes, ignoring the fact that teammates may suffer from policy change suddenly within an episode, which might lead to miscoordination and poor performance as a result. We formulate the problem as an open Dec-POMDP, where we control some agents to coordinate with uncontrolled teammates, whose policies could be changed within one episode. Then we develop a new framework Fast teammates adaptation (Fastap) to address the problem. Concretely, we first train versatile teammates' policies and assign them to different clusters via the Chinese Restaurant Process (CRP). Then, we train the controlled agent(s) to coordinate with the sampled uncontrolled teammates by capturing their identifications as context for fast adaptation. Finally, each agent applies its local information to anticipate the teammates' context for decision-making accordingly. This process proceeds alternately, leading to a robust policy that can adapt to any teammates during the decentralized execution phase. We show in multiple multi-agent benchmarks that Fastap can achieve superior performance than multiple baselines in stationary and non-stationary scenarios. 
 ID: 184 | Noisy Adversarial Representation Learning for Effective and Efficient Image Obfuscation   
  
 Jonghu Jeong, Minyong Cho, Philipp Benz, Tae-hoon Kim  

  TL;DR:  To protect users privacy in machine learning as a service, we introduce an effective and efficient adversarial representation learning method with simple noisy features.   Abstract:   
 Recent real-world applications of deep learning have led to the development of machine learning as a service (MLaaS). However, the scenario of client-server inference presents privacy concerns, where the server processes raw data sent from the user's client device. One solution to this issue is to provide an obfuscator function to the client device using Adversarial Representation Learning (ARL). Prior works have primarily focused on the privacy-utility trade-off while overlooking the computational cost and memory burden on the client side. In this paper, we propose an effective and efficient ARL method that incorporates feature noise into the ARL pipeline. We evaluated our approach on various datasets, comparing it with state-of-the-art ARL techniques. Our experimental results indicate that our method achieves better accuracy, lower computation and memory overheads, and improved resistance to information leakage and reconstruction attacks. The code is available in the supplementary and will be made public after publication. 
 ID: 186 | Inference for Mark-Censored Temporal Point Processes   
 [spotlight]  
 Alex James Boyd, Yuxin Chang, Stephan Mandt, Padhraic Smyth  

  TL;DR:  Through a proper proposal distribution, one can efficiently and tractably marginalize out missing information in marked temporal point processes, thus allowing for accommodating partially observed sequences.   Abstract:   
 Marked temporal point processes (MTPPs) are a general class of stochastic models for modeling the evolution of events of different types (``marks'') in continuous time. These models have broad applications in areas such as medical data monitoring, financial prediction, user modeling, and communication networks. Of significant practical interest in such problems is the issue of missing or censored data over time. In this paper, we focus on the specific problem of inference for a trained MTPP model when events of certain types are not observed over a period of time during prediction. We introduce the concept of mark-censored sub-processes and use this framework to develop a novel marginalization technique for inference in the presence of censored marks. The approach is model-agnostic and applicable to any MTPP model with a well-defined intensity function. We illustrate the flexibility and utility of the method in the context of both parametric and neural MTPP models, with results across a range of datasets including data from simulated Hawkes processes, self-correcting processes, and multiple real-world event datasets. 
 ID: 189 | Transfer Learning for Individual Treatment Effect Estimation   
  
 Ahmed Aloui, Juncheng Dong, Cat Phuoc Le, Vahid Tarokh  

  TL;DR:  This work presents theoretical and empirical studies about estimating individual treatment effect using knowledge transfer from the previous experience.   Abstract:   
 This work considers the problem of transferring causal knowledge between tasks for Individual Treatment Effect (ITE) estimation. To this end, we theoretically assess the feasibility of transferring ITE knowledge and present a practical framework for efficient transfer. A lower bound is introduced on the ITE error of the target task to demonstrate that ITE knowledge transfer is challenging due to the absence of counterfactual information. Nevertheless, we establish generalization upper bounds on the counterfactual loss and ITE error of the target task, demonstrating the feasibility of ITE knowledge transfer. Subsequently, we introduce a framework with a new Causal Inference Task Affinity (CITA) measure for ITE knowledge transfer. Specifically, we use CITA to find the closest source task to the target task and utilize it for ITE knowledge transfer. Empirical studies are provided, demonstrating the efficacy of the proposed method. We observe that ITE knowledge transfer can significantly (up to 95%) reduce the amount of data required for ITE estimation. 
 ID: 190 | Conditional Counterfactual Causal Effect for Individual Attribution   
 [spotlight]  
 Ruiqi Zhao, lei zhang, Shengyu Zhu, Zitong Lu, Zhenhua Dong, Chaoliang Zhang, Jun Xu, Zhi Geng, Yangbo He  

    Abstract:   
 Identifying the causes of an event, also termed as causal attribution, is a commonly encountered task in many application problems. Available methods, mostly in Bayesian or causal inference literature, suffer from two main drawbacks: 1) cannot attributing for individuals, (2) attributing one single cause at a time and cannot deal with the interaction effect among multiple causes. In this paper, based on our proposed new measurement, called conditional counterfactual causality effect (CCCE), we introduce an individual causal attribution method, which is able to utilize the individual observation as the evidence and consider common influence and interaction effect of multiple causes simultaneously. We discuss the identifiability of CCCE and also give the identification formulas under proper assumptions. Finally, we conduct experiments on simulated and real data to illustrate the effectiveness of CCCE and the results show that our proposed method outperforms significantly over state-of-the-art methods. 
 ID: 196 | Random Reshuffling with Variance Reduction: New Analysis and Better Rates   
 [spotlight]  
 Grigory Malinovsky, Alibek Sailanbayev, Peter Richtárik  
   
    [link to video]   
   
  TL;DR:  We provide the better rates for variance reduced random reshuffling methods.   Abstract:   
 Virtually all state-of-the-art methods for training supervised machine learning models are variants of SGD, enhanced with a number of additional tricks, such as minibatching, momentum, and adaptive stepsizes. However, one of the most basic questions in the design of successful SGD methods, one that is orthogonal to the aforementioned tricks, is the choice of the next training data point to be learning from. Standard variants of SGD employ a sampling with replacement strategy, which means that the next training data point is sampled from the entire data set, often independently of all previous samples. While standard SGD is well understood theoretically, virtually all widely used machine learning software is based on sampling without replacement as this is often empirically superior. That is, the training data is randomly shuffled/permuted, either only once at the beginning, strategy known as random shuffling (RS), or before every epoch, strategy known as random reshuffling (RR), and training proceeds in the data order dictated by the shuffling. RS and RR strategies have for a long time remained beyond the reach of theoretical analysis that would satisfactorily explain their success. However, very recently, Mishchenko et al. [2020] provided tight sublinear convergence rates through a novel analysis, and showed that these strategies can improve upon standard SGD in certain regimes. Inspired by these results, we seek to further improve the rates of shuffling-based methods. In particular, we show that it is possible to enhance them with a variance reduction mechanism, obtaining linear convergence rates. To the best of our knowledge, our linear convergence rates are the best for any method based on sampling without replacement. 
 ID: 205 | A Bayesian Approach for Bandit Online Optimization with Switching Cost   
  
 Zai Shi, Jian Tan, Feifei Li  

    Abstract:   
 As a classical problem, online optimization with switching cost has been studied for a long time due to its wide applications in various areas. However, few works have investigated the bandit setting where both the forms of the main cost function $f(x)$ evaluated at state $x$ and the switching cost function $c(x, y)$ of transitioning from state $x$ to $y$ are unknown. In this paper, we consider the situation when $\left(f(x_t)+\varepsilon_t,\, c(x_t, x_{t-1})\right)$ can be observed with noise $\varepsilon_t$ after making a decision $x_t$ at time $t$, aiming to minimize the expected total cost within a time horizon. To solve this problem, we propose two algorithms from a Bayesian approach, named Greedy Search and Alternating Search, respectively. They have different theoretical guarantees of competitive ratios under mild regularity conditions, and the latter algorithm achieves a faster running speed. Using simulations of two classical black-box optimization problems, we demonstrate the superior performance of our algorithms compared with the classical method. 
 ID: 211 | Assessing the Impact of Context Inference Error and Partial Observability on RL Methods for Just-In-Time Adaptive Interventions   
  
 Karine Karine, Predrag Klasnja, Susan Murphy, Benjamin Marlin  

  TL;DR:  We study the impact of context inference error and partial observability on policy learning for adaptive health interventions.   Abstract:   
 Just-in-Time Adaptive Interventions (JITAIs) are a class of personalized health interventions developed within the behavioral science community. JITAIs aim to provide the right type and amount of support by iteratively selecting a sequence of intervention options from a pre-defined set of components in response to each individual's time varying state. In this work, we explore the application of reinforcement learning methods to the problem of learning intervention option selection policies. We study the effect of context inference error and partial observability on the ability to learn effective policies. Our results show that the propagation of uncertainty from context inferences is critical to improving intervention efficacy as context uncertainty increases, while policy gradient algorithms can provide remarkable robustness to partially observed behavioral state information. 
 ID: 212 | Monte-Carlo Search for an Equilibrium in Dec-POMDPs   
  
 YANG YOU, Vincent Thomas, Francis Colas, Olivier Buffet  

    Abstract:   
 Decentralized partially observable Markov decision processes (Dec-POMDPs) formalize the problem of designing individual controllers for a group of collaborative agents under stochastic dynamics and partial observability. Seeking a global optimum is difficult (NEXP complete), but seeking a Nash equilibrium ‚Äî each agent policy being a best response to the other agents ‚Äî is more accessible, and allowed addressing infinite-horizon problems with solutions in the form of finite state controllers. In this paper, we show that this approach can be adapted to cases where only a generative model (a simulator) of the Dec-POMDP is available. This requires relying on a simulation-based POMDP solver to construct an agent‚Äôs FSC node by node. A related process is used to heuristically derive initial FSCs. Experiment with benchmarks shows that MC-JESP is competitive with existing Dec-POMDP solvers, even better than many offline methods using explicit models. 
 ID: 213 | Benign Overfitting in Adversarially Robust Linear Classification   
  
 Jinghui Chen, Yuan Cao, Quanquan Gu  

    Abstract:   
 ``Benign overfitting'', where classifiers memorize noisy training data yet still achieve a good generalization performance, has drawn great attention in the machine learning community. To explain this surprising phenomenon, a series of works have provided theoretical justification for over-parameterized linear regression, classification, and kernel methods. However, it is not clear if benign overfitting can occur in the presence of adversarial examples, i.e., examples with tiny and intentional perturbations to fool the classifiers. In this paper, we show that benign overfitting indeed occurs in adversarial training, a principled approach to defend against adversarial examples, on subGaussian mixture data. In detail, we prove the risk bounds of the adversarially trained linear classifier on the mixture of sub-Gaussian data under $\ell_p$ adversarial perturbations. Our result suggests that under moderate perturbations, adversarially trained linear classifiers can achieve the near-optimal standard and adversarial risks, despite overfitting the noisy training data. Numerical experiments validate our theoretical findings. 
 ID: 214 | Solving Multi-Model MDPs by Policy Gradient and Dynamic Programming   
  
 Xihong Su, Marek Petrik  

    Abstract:   
 Multi-model Markov decision process(MMDP) is a promising framework for computing policies that are robust to parameter uncertainty in MDPs. MMDPs aim to find a policy that maximizes the expected return over a distribution of MDP models. Because MMDPs are NP-hard to solve, most methods resort to approximations. In this paper, we derive the policy gradient of MMDPs and propose CADP, which combines a coordinate ascent method and a dynamic programming algorithm for solving MMDPs. The main innovation of CADP compared with earlier algorithms is to take the policy gradient perspective to adjust model weights iteratively to guarantee monotone policy improvements to a local maximum. A theoretical analysis of CADP proves that it never performs worse than previous dynamic programming algorithms like WSU. Our numerical results indicate that CADP substantially outperforms existing methods on several benchmark problems. 
 ID: 216 | Massively Parallel Reweighted Wake-Sleep   
  
 Thomas Heap, Gavin Leech, Laurence Aitchison  
   
    [link to video]   
   
  TL;DR:  We develop a method for drawing exponentially many samples of latent variables for use in Reweighted wake-sleep.   Abstract:   
 Reweighted wake-sleep (RWS) is a machine learning method for performing Bayesian inference in a very general class of models. RWS draws $K$ samples from an underlying approximate posterior, then uses importance weighting to provide a better estimates of the true posterior. RWS then updates its approximate posterior towards the importance-weighted estimate of the true posterior. However, recent work (Chatterjee and Diaconis, 2018) indicates that the number of samples required for effective importance weighting is $\mathcal{O}(e^n)$, where $n$ is the number of latent variables. Attaining such a large number of importance samples is intractable in all but the smallest models. Here, we develop massively parallel RWS, which circumvents this issue by drawing $K$ samples of all $n$ latent variables, and individually reasoning about all $K^n$ possible combinations of samples. While reasoning about $K^n$ combinations might seem intractable, the required computations can be performed in polynomial time by exploiting conditional independencies in the generative model. We show considerable improvements over standard "global" RWS, which draws $K$ samples from the full joint. 
 ID: 217 | An Effective Negotiating Agent Framework based on Deep Offline Reinforcement Learning   
  
 Siqi Chen, Jianing Zhao, Gerhard Weiss, Ran Su, Kaiyou Lei  
   
    [link to video]   
   
  TL;DR:  A novel Deep Offline Reinforcement learning Negotiating Agent (DOREA) framework can learn a strategy from offline dataset and adapt it to opponent changes.   Abstract:   
 Learning is crucial for automated negotiation, and recent years have witnessed a remarkable achievement in application of reinforcement learning (RL) for various negotiation tasks. Conventional RL methods focus generally on learning from active interactions with opposing negotiators. However, collecting online data is expensive in many realistic negotiation scenarios. While previous studies partially mitigate this problem through the use of opponent simulators (i.e., agents following known strategies), in reality it is usually hard to fully capture an opponent‚Äôs negotiation strategy. Moreover, a further challenge lies in an agent's capability of adapting to dynamic variations of an opponent‚Äôs preferences or strategy, which may happen from time to time for different reasons in subsequent negotiations. In response to these challenges, this article proposes a novel Deep Offline Reinforcement learning Negotiating Agent (DOREA) framework that allows to learn an effective strategy using previously collected negotiation datasets without requiring interaction with an opponent. This is in contrast to existing RL-based negotiation approaches that all rely on active interaction with opponents. Furthermore, the strategy fine-tuning mechanism is included to adjust the learned strategy in response to the preferences or strategy changes of the opponent. The performance of the DOREA framework is evaluated based on a diverse set of state-of-the-art baselines under different settings. Experimental results show that the proposed framework allows to learn effective strategies exclusively with offline datasets, and is also capable of effectively adapting to changes of an opponent's negotiation preferences or strategy. 
 ID: 219 | Guided Deep Kernel Learning   
  
 Idan Achituve, Gal Chechik, Ethan Fetaya  

  TL;DR:  To remedy the overfitting issues in deep kernels, we propose utilizing infinite-width neural networks to guide their optimization process and retain their Bayesian merits.   Abstract:   
 Combining Gaussian processes with the expressive power of deep neural networks is commonly done nowadays through deep kernel learning (DKL). Unfortunately, due to the kernel optimization process, this often results in losing their Bayesian benefits. In this study, we present a novel approach for learning deep kernels by utilizing infinite-width neural networks. We propose to use the Neural Network Gaussian Process (NNGP) model as a guide to the DKL model in the optimization process. Our approach harnesses the reliable uncertainty estimation of the NNGPs to adapt the DKL target confidence when it encounters novel data points. As a result, we get the best of both worlds, we leverage the Bayesian behavior of the NNGP, namely its robustness to overfitting, and accurate uncertainty estimation, while maintaining the generalization abilities, scalability, and flexibility of deep kernels. Empirically, we show on multiple benchmark datasets of varying sizes and dimensionality, that our method is robust to overfitting, has good predictive performance, and provides reliable uncertainty estimations. 
 ID: 220 | Heteroskedastic Geospatial Tracking with Distributed Camera Networks   
  
 Colin Samplawski, Shiwei Fang, Ziqi Wang, Deepak Ganesan, Mani Srivastava, Benjamin Marlin  

  TL;DR:  We introduce a new single-object geospatial tracking dataset from a distributed camera network and present a modeling framework that considers uncertainties for this task.   Abstract:   
 Visual object tracking has seen significant progress in recent years. However, the vast majority of this work focuses on tracking objects within the image plane of a single camera and ignores the uncertainty associated with predicted object locations. In this work, we focus on the geospatial object tracking problem using data from a distributed camera network. The goal is to predict an object's track in geospatial coordinates along with uncertainty over the object's location while respecting communication constraints that prohibit centralizing raw image data. We present a novel single-object geospatial tracking data set that includes high-accuracy ground truth object locations and video data from a network of four cameras. We present a modeling framework for addressing this task including a novel backbone model and explore how uncertainty calibration and fine-tuning through a differentiable tracker affect performance. 
 ID: 227 | Multi-View Graph Contrastive Learning for Solving Vehicle Routing Problems   
 [spotlight]  
 Yuan Jiang, Zhiguang Cao, Yaoxin Wu, Jie Zhang  
   
    [link to video]   
   
  TL;DR:  A multi-view graph contrasting learning (MVGCL) approach to tackle out-of-distribution (o.o.d.) issue in routing problem, which couples a graph pattern learner in a self-supervised fashion with deep reinforcement learning.   Abstract:   
 Recently, neural heuristics based on deep learning have reported encouraging results for solving vehicle routing problems (VRPs), especially on independent and identically distributed (i.i.d.) instances, e.g. uniform. However, in the presence of a distribution shift for the testing instances, their performance becomes considerably inferior. In this paper, we propose a multi-view graph Contrastive learning (MVGCL) approach to enhance the generalization across different distributions, which exploits two graph pattern learners in a self-supervised fashion to facilitate a neural heuristic equipped with an active search scheme. Specifically, we first propose two augmentation methods that are specially designed for routing problems, and our MVGCL leverages graph contrastive learning to extract transferable patterns from VRP graphs to attain the generalizable multi-view (i.e. node and graph) representation. Then it adopts the learnt node embedding and graph embedding to assist the neural heuristic and the active search (during inference) for route construction, respectively. Extensive experiments on randomly generated VRP instances from various distributions, and the ones from TSPLib and CVRPLib show that our MVGCL is superior to the baselines in boosting the cross-distribution generalization performance. 
 ID: 233 | Neural Probabilistic Logic Programming in Discrete-Continuous Domains   
 [oral]  
 Lennert De Smet, Pedro Zuidberg Dos Martires, Robin Manhaeve, Giuseppe Marra, Angelika Kimmig, Luc De Raedt  
   
    [slides]   
   
  TL;DR:  DeepSeaProbLog: a neural probabilistic logic programming language with discrete and continuous random variables.   Abstract:   
 Neural-symbolic AI (NeSy) allows neural networks to exploit symbolic background knowledge in the form of logic. It has been shown to aid learning in the limited data regime and to facilitate inference on out-of-distribution data. Probabilistic NeSy focuses on integrating neural networks with both logic and probability theory, which additionally allows learning under uncertainty. A major limitation of current probabilistic NeSy systems, such as DeepProbLog, is their restriction to finite probability distributions, i.e., discrete random vari- ables. In contrast, deep probabilistic programming (DPP) excels in modelling and optimising continuous probability distributions. Hence, we introduce DeepSeaProbLog, a neural probabilistic logic programming language that incorporates DPP techniques into NeSy. Doing so results in the support of inference and learning of both discrete and continuous probability distributions under logical constraints. Our main contributions are 1) the semantics of DeepSeaProbLog and its corresponding inference algorithm, 2) a proven asymptotically unbiased learning algorithm, and 3) a series of experiments that illustrate the versatility of our approach. 
 ID: 234 | Robust Statistical Comparison of Random Variables with Locally Varying Scale of Measurement   
  
 Christoph Jansen, Georg Schollmeyer, Hannah Blocher, Julian Martin Rodemann, Thomas Augustin  
   
    [link to video]   
   
  TL;DR:  We consider a generalization of stochastic dominance to handle data with non-standard scale of measurement and introduce corresponding (regularized and/or robustified) statistical tests.   Abstract:   
 Spaces with locally varying scale of measurement, like multidimensional structures with differently scaled dimensions, are pretty common in statistics and machine learning. Nevertheless, it is still understood as an open question how to exploit the entire information encoded in them properly. We address this problem by considering an order based on (sets of) expectations of random variables mapping into such non-standard spaces. This order contains stochastic dominance and expectation order as extreme cases when no, or respectively perfect, cardinal structure is given. We derive a (regularized) statistical test for such generalized stochastic dominance, operationalize it by linear optimization, and robustify it by imprecise probability models. Our findings are illustrated with data from multidimensional poverty measurement, finance, and medicine. 
 ID: 235 | On the Limitations of Markovian Rewards to Express Multi-Objective, Risk-Sensitive, and Modal Tasks   
  
 Joar Max Viktor Skalse, Alessandro Abate  

  TL;DR:  We study three classes of tasks (multi-objective tasks, risk-sensitive tasks, and modal tasks), and provide necessary and sufficient conditions for when these tasks can be expressed using scalar, Markovian reward functions.   Abstract:   
 In this paper, we study the expressivity of scalar, Markovian reward functions in Reinforcement Learning (RL), and identify several limitations to what they can express. Specifically, we look at three classes of RL tasks (multi-objective RL, risk-sensitive RL, and modal RL), and show that most of the instances in each of these three classes cannot be expressed using scalar, Markovian rewards. Among these three classes, we provide necessary and sufficient conditions for when a problem can be reduced to ordinary, scalar reward reinforcement learning. Modal problems have so far not been given any systematic treatment in the RL literature; we thus call attention to them as a new class of problems. Finally, we also show that many of these problems can be solved by means of bespoke RL approaches: this rules out the possibility that those problems that cannot be expressed using Markovian reward functions also are impossible to learn effectively. 
 ID: 236 | Generating Synthetic Datasets by Interpolating along Generalized Geodesics   
  
 Jiaojiao Fan, David Alvarez-Melis  

  TL;DR:  We generate synthetic datasets by interpolating along generalized geodesics, so as to improve the transfer learning performance.   Abstract:   
 Data for pretraining machine learning models often consists of collections of heterogeneous datasets. Although training on their union is reasonable in agnostic settings, it might be suboptimal when the target domain ---where the model will ultimately be used--- is known in advance. In that case, one would ideally pretrain only on the dataset(s) most similar to the target one. Instead of limiting this choice to those datasets already present in the pretraining collection, here we explore extending this search to all datasets that can be synthesized as `combinations' of them. We define such combinations as multi-dataset interpolations, formalized through the notion of generalized geodesics from optimal transport (OT) theory. We compute these geodesics using a recent notion of distance between labeled datasets, and derive alternative interpolation schemes based on it: using either barycentric projections or optimal transport maps, the latter computed using recent neural OT methods. These methods are scalable, efficient, and ---notably--- can be used to interpolate even between datasets with distinct and unrelated label sets. Through various experiments in transfer learning in computer vision, we demonstrate this is a promising new approach for targeted on-demand dataset synthesis. 
 ID: 240 | Multi-modal Differentiable Unsupervised Feature Selection   
  
 Junchen Yang, Ofir Lindenbaum, Yuval Kluger, Ariel Jaffe  

    Abstract:   
 Multi-modal high throughput biological data presents a great scientific opportunity and a significant computational challenge. In multi-modal measurements, every sample is observed simultaneously by two or more sets of sensors. In such settings, many observed variables in both modalities are often nuisance and do not carry information about the phenomenon of interest. Here, we propose a multi-modal unsupervised feature selection framework: identifying informative variables based on coupled high-dimensional measurements. Our method is designed to identify features associated with two types of latent low-dimensional structures: (i) shared structures that govern the observations in both modalities, and (ii) differential structures that appear in only one modality. To that end, we propose two Laplacian-based scoring operators. We incorporate the scores with differentiable gates that mask nuisance features and enhance the accuracy of the structure captured by the graph Laplacian. The performance of the new scheme is illustrated using synthetic and real datasets, including an extended biological application to single-cell multi-omics. 
 ID: 243 | Efficient Privacy-Preserving Stochastic Nonconvex Optimization   
  
 Lingxiao Wang, Bargav Jayaraman, David Evans, Quanquan Gu  

  TL;DR:  Efficient private stochastic nonconvex optimization algorithm with improved utility guarantees   Abstract:   
 While many solutions for privacy-preserving convex empirical risk minimization (ERM) have been developed, privacy-preserving nonconvex ERM remains a challenge. We study nonconvex ERM, which takes the form of minimizing a finite-sum of nonconvex loss functions over a training set. We propose a new differentially private stochastic gradient descent algorithm for nonconvex ERM that achieves strong privacy guarantees efficiently, and provide a tight analysis of its privacy and utility guarantees, as well as its gradient complexity. Our algorithm reduces gradient complexity while matching the best-known utility guarantee. Our experiments on benchmark nonconvex ERM problems demonstrate superior performance in terms of both training cost and utility gains compared with previous differentially private methods using the same privacy budgets. 
 ID: 246 | Two-stage Kernel Bayesian Optimization in High Dimensions   
  
 Jian Tan, Niv Nayman  

    Abstract:   
 Bayesian optimization is a popular method for optimizing expensive black-box functions. Yet it oftentimes struggles in high dimensions, where the computation could be prohibitively heavy. While a complex kernel with many length scales is prone to overfitting and expensive to train, a simple coarse kernel with too few length scales cannot effectively capture the variations of the high dimensional function in different directions. To alleviate this problem, we introduce CobBO: a Bayesian optimization algorithm with two-stage kernels and a coordinate backoff stopping rule. It adaptively selects a promising low dimensional subspace and projects past measurements into it using a computational efficient coarse kernel. Within the subspace, the computational cost of conducting Bayesian optimization with a more flexible and accurate kernel becomes affordable and thus a sequence of consecutive observations in the same subspace are collected until a stopping rule is met. Extensive evaluations show that CobBO finds solutions comparable to or better than other state-of-the-art methods for dimensions ranging from tens to hundreds, while reducing both the trial complexity and computational costs. 
 ID: 247 | Simple Transferability Estimation for Regression Tasks   
  
 Cuong N. Nguyen, Phong Tran, Lam Si Tung Ho, Vu C. Dinh, Anh Tuan Tran, Tal Hassner, Cuong V Nguyen  

    Abstract:   
 We consider transferability estimation, the problem of estimating how well deep learning models transfer from a source to a target task. We focus on regression tasks, which received little previous attention, and propose two simple and computationally efficient approaches that estimate transferability based on the negative regularized mean squared error of a linear regression model. We prove novel theoretical results connecting our approaches to the actual transferability of the optimal target models obtained from the transfer learning process. Despite their simplicity, our approaches significantly outperform existing state-of-the-art regression transferability estimators in both accuracy and efficiency. On two large-scale keypoint regression benchmarks, our approaches yield 9% to 26% better results on average while being at least 27% faster than previous state-of-the-art methods. 
 ID: 249 | Partial Identification of Dose Responses with Hidden Confounders   
 [oral]  
 Myrl G Marmarelis, Greg Ver Steeg, Andrew Jesson, Elizabeth Haddad, Neda Jahanshad, Aram Galstyan  
   
    [slides]   
   
  TL;DR:  We bound the estimated causal effects of continuous-valued treatments when they might be biased by hidden confounders.   Abstract:   
 Inferring causal effects of continuous-valued treatments from observational data is a crucial task promising to better inform policy- and decision-makers. A critical assumption needed to identify these effects is that all confounding variables---causal parents of both the treatment and the outcome---are included as covariates. Unfortunately, given observational data alone, we cannot know with certainty that this criterion is satisfied. Sensitivity analyses provide principled ways to give bounds on causal estimates when confounding variables are hidden. While much attention is focused on sensitivity analyses for discrete-valued treatments, much less is paid to continuous-valued treatments. We present novel methodology to bound both average and conditional average continuous-valued treatment-effect estimates when they cannot be point identified due to hidden confounding. A semi-synthetic benchmark on multiple datasets shows our method giving tighter coverage of the true dose-response curve than a recently proposed continuous sensitivity model and baselines. Finally, we apply our method to a real-world observational case study to demonstrate the value of identifying dose-dependent causal effects. 
 ID: 250 | Accelerating Voting by Quantum Computation   
  
 Ao Liu, Qishen Han, Lirong Xia, Nengkun Yu  

  TL;DR:  We accelerate voting by leveraging quantum computing.   Abstract:   
 Studying the computational complexity of determining winners under voting rules and designing fast algorithms are classical and fundamental questions in computational social choice. In this paper, we accelerate voting by leveraging quantum computing. We propose a quantum voting algorithm that can be applied to any anonymous voting rule. We further show that our algorithm can be quadratically faster than any classical sampling algorithm under a wide range of common voting rules, including plurality, Borda, Copeland, and STV. Precisely, our quantum voting algorithm achieves an accuracy of at least $1 - \varepsilon$ with runtime $\Theta\left(\frac{n\cdot\log(1/\varepsilon)}{\text{MOV}}\right)$, where $n$ is the number of votes and $\text{MOV}$ is margin of victory, the smallest number of voters to change the winner. On the other hand, any classical voting algorithm based on sampling a subset of voting achieves the same accuracy with runtime $\Theta\left(\frac{n^2\cdot\log(1/\varepsilon)}{\text{MOV}^2}\right)$ [Bhattacharyya and Dey, 2021]. Our theoretical results are supported by experiments under the plurality and Borda rule. 
 ID: 251 | Merging Models Pre-Trained on Different Features with Consensus Graph   
  
 Tengfei Ma, Trong Nghia Hoang, Jie Chen  

  TL;DR:  We develop a new representation consensus technique that helps combining pre-trained models with different feature spaces.   Abstract:   
 Learning an effective global model on private and decentralized datasets has become an increasingly important challenge of machine learning when applied in practice. Existing distributed learning paradigms, such as Federated Learning, enable this via model aggregation which enforces a strong form of modeling homogeneity and synchronicity across clients. This is however not suitable to many practical scenarios. For example, in distributed sensing, heterogeneous sensors reading data from different views of the same phenomenon would need to use different models for different data modalities. Local learning therefore happens in isolation but inference requires merging the local models to achieve consensus. To enable consensus among local models, we propose a feature fusion approach that extracts local representations from local models and incorporates them into a global representation that improves the prediction performance. Achieving this requires addressing two non-trivial problems. First, we need to learn an alignment between similar feature components which are arbitrarily arranged across clients to enable representation aggregation. Second, we need to learn a consensus graph that captures the high-order interactions between local feature spaces and how to combine them to achieve a better prediction. This paper presents solutions to these problems and demonstrates them in real-world applications such as power grids and traffic networks. 
 ID: 255 | Posterior Sampling-based Online Learning for the Stochastic Shortest Path Model   
  
 Mehdi Jafarnia-Jahromi, Liyu Chen, Rahul Jain, Haipeng Luo  

  TL;DR:  The first posterior sampling algorithm for online learning in stochastic shortest path models with near-optimal regret and excellent empirical performance   Abstract:   
 We consider the problem of online reinforcement learning for the Stochastic Shortest Path (SSP) problem modeled as an unknown MDP with an absorbing state. We propose \ssp, a simple posterior sampling-based reinforcement learning algorithm for the SSP problem. The algorithm operates in epochs. At the beginning of each epoch, a sample is drawn from the posterior distribution on the unknown model dynamics, and the optimal policy with respect to the drawn sample is followed during that epoch. An epoch completes if either the number of visits to the goal state in the current epoch exceeds that of the previous epoch, or the number of visits to any of the state-action pairs is doubled. We establish a Bayesian regret bound of $\tilde{O}(B S\sqrt{AK})$, where $B$ is an upper bound on the expected cost of the optimal policy, $S$ is the size of the state space, $A$ is the size of the action space, and $K$ is the number of episodes. The algorithm only requires the knowledge of the prior distribution, and has no hyper-parameters to tune. It is the first such posterior sampling algorithm and outperforms numerically previously proposed optimism-based algorithms. 
 ID: 256 | Human-in-the-Loop Mixup   
 [oral]  
 Katherine M. Collins, Umang Bhatt, Weiyang Liu, Vihari Piratla, Ilia Sucholutsky, Bradley C. Love, Adrian Weller  
   
    [slides]   
   
  TL;DR:  Synthetic labels used in mixup are not consistently aligned with human perceptual judgments; relabeling examples, with humans-in-the-loop and leveraging human uncertainty information, holds promise to increase downstream model reliability.   Abstract:   
 Aligning model representations to humans has been found to improve robustness and generalization. However, such methods often focus on standard observational data. Synthetic data is proliferating and powering many advances in machine learning; yet, it is not always clear whether synthetic labels are perceptually aligned to humans -- rendering it likely model representations are not human aligned. We focus on the synthetic data used in mixup: a powerful regularizer shown to improve model robustness, generalization, and calibration. We design a comprehensive series of elicitation interfaces, which we release as HILL MixE Suite, and recruit 159 participants to provide perceptual judgments along with their uncertainties, over mixup examples. We find that human perceptions do not consistently align with the labels traditionally used for synthetic points, and begin to demonstrate the applicability of these findings to potentially increase the reliability of downstream models, particularly when incorporating human uncertainty. We release all elicited judgments in a new data hub we call H-Mix. 
 ID: 257 | Composing Efficient, Robust Tests for Policy Selection   
 [spotlight]  
 Dustin Morrill, Thomas Walsh, Daniel Hernandez, Peter R. Wurman, Peter Stone  
   
    [link to video]   
   
  TL;DR:  This paper introduces RPOSST, an algorithm for composing efficient, robust, reusable tests of candidate deployment RL policies by selecting a small number of the most useful test cases.   Abstract:   
 Modern reinforcement learning systems produce many high-quality policies throughout the learning process. However, to choose which policy to actually deploy in the real world, they must be tested under an intractable number of environmental conditions. We introduce RPOSST, an algorithm to select a small set of test cases from a larger pool based on a relatively small number of sample evaluations. RPOSST treats the test case selection problem as a 2-player game and optimizes a solution with provable $k$-of-$N$ robustness, bounding the error relative to a test that used all the test cases in the pool. Empirical results demonstrate that RPOSST finds a small set of test cases that identify high quality policies in a toy one-shot game, poker datasets, and a high-fidelity racing simulator. 
 ID: 261 | Studying the Effect of GNN Spatial Convolutions On The Embedding Space's Geometry   
 [spotlight]  
 Claire Donnat, So Won Jeong  

  TL;DR:  In this paper, we analyse the effect of the convolution operator on the embedding geometry.   Abstract:   
 By recursively summing node features over entire neighborhoods, spatial graph convolution operators have been heralded as key to the success of Graph Neural Networks (GNNs). Yet, despite the multiplication of GNN methods across tasks and applications, the effect of this aggregation operation has yet to be analyzed. In fact, while most recent efforts in the GNN community have focused on optimizing the architecture of the neural network, fewer works have attempted to characterize (a) the different classes of spatial convolution operators, (b) their impact on the geometry of the embedding space, and (c) how the choice of a particular convolution should relate to properties of the data. In this paper, we propose to answer all three questions by dividing existing operators into two main classes (symmetrized vs. row-normalized spatial convolutions), and show how these correspond to different implicit biases on the data. Finally, we show that this convolution operator is in fact tunable, and explicit regimes in which certain choices of convolutions --- and therefore, embedding geometries --- might be more appropriate. 
 ID: 268 | Conformal Risk Control for Ordinal Classification   
  
 Yunpeng Xu, Wenge Guo, Zhi Wei  

  TL;DR:  We formulated the ordinal classification task in the conformal risk control framework, provided theoretic risk bounds, proposed two types of loss functions, developed corresponding algorithms, and evaluated the method on 3 datasets.   Abstract:   
 As a natural extension to the standard conformal prediction method, several conformal risk control methods have been recently developed and applied to various learning problems. In this work, we seek to control the conformal risk in expectation for ordinal classification tasks, which have broad applications to many real problems. For this purpose, we firstly formulated the ordinal classification task in the conformal risk control framework, and provided theoretic risk bounds of the risk control method. Then we proposed two types of loss functions specially designed for ordinal classification tasks, and developed corresponding algorithms to determine the prediction set for each case to control their risks at a desired level. We demonstrated the effectiveness of our proposed methods, and analyzed the difference between the two types of risks on three different datasets, including a simulated dataset, the UTKFace dataset and the diabetic retinopathy detection dataset. 
 ID: 272 | Blackbox optimization of unimodal functions   
  
 Ashok Cutkosky, Abhimanyu Das, Weihao Kong, Chansoo Lee, Rajat Sen  

  TL;DR:  Simple but optimal method for black-box optimization of unimodal functions with practical application to hyper-parameter tuning   Abstract:   
 We provide an intuitive new algorithm for blackbox stochastic optimization of unimodal functions, a function class that we observe empirically can capture hyperparameter-tuning loss surfaces. Our method's convergence guarantee automatically adapts to Lipschitz constants and other problem difficulty parameters, recovering and extending prior results. We complement our theoretical development with experimental validation on hyperparameter tuning tasks. 
 ID: 273 | Adaptive Conditional Quantile Neural Processes   
  
 Peiman Mohseni, Nick Duffield, Bani Mallick, Arman Hasanzadeh  

    Abstract:   
 Neural processes are a family of probabilistic models that inherit the flexibility of neural networks to parameterize stochastic processes. Despite providing well-calibrated predictions, especially in regression problems, and quick adaptation to new tasks, the Gaussian assumption that is commonly used to represent the predictive likelihood fails to capture more complicated distributions such as multimodal ones. To overcome this limitation, we propose Conditional Quantile Neural Processes (CQNPs), a new member of the neural processes family, which exploits the attractive properties of quantile regression in modeling the distributions irrespective of their form. By introducing an extension of quantile regression where the model learns to focus on estimating informative quantiles, we show that the sampling efficiency and prediction accuracy can be further enhanced. Our experiments with real and synthetic datasets demonstrate substantial improvements in predictive performance compared to the baselines, and better modeling of heterogeneous distributions' characteristics such as multimodality. 
 ID: 277 | Piecewise Deterministic Markov Processes for Bayesian Neural Networks   
  
 Ethan Goan, Dimitri Perrin, Kerrie Mengersen, Clinton Fookes  

  TL;DR:  Development of event sampling algorithm allowing implementation of PDMP samplers for Bayesian neural networks.   Abstract:   
 Inference on modern Bayesian Neural Networks (BNNs) often relies on a variational inference treatment, imposing violated assumptions of independence and the form of the posterior. Traditional MCMC approaches avoid these assumptions at the cost of increased computation due to its incompatibility to subsampling of the likelihood. New Piecewise Deterministic Markov Process (PDMP) samplers permit subsampling, though introduce a model specific inhomogenous Poisson Process (IPPs) which is difficult to sample from. This work introduces a new generic and adaptive thinning scheme for sampling from these IPPs, and demonstrates how this approach can accelerate the application of PDMPs for inference in BNNs. Experimentation illustrates how inference with these methods is computationally feasible, can improve predictive accuracy, MCMC mixing performance, and provide informative uncertainty measurements when compared against other approximate inference schemes. 
 ID: 281 | Learning to Reason about Contextual Knowledge for Planning under Uncertainty   
  
 Cheng Cui, Saeid Amiri, Yan Ding, Xingyue Zhan, Shiqi Zhang  
   
    [link to video]   
   
  TL;DR:  In this paper, we develop a novel algorithm (PERIL) for knowledge-based SDM that learns from interaction experience to reason about contextual knowledge.   Abstract:   
 Sequential decision-making (SDM) methods enable AI agents to compute an action policy toward achieving long-term goals under uncertainty. Existing research has shown that contextual knowledge in declarative forms can be used for improving the performance of SDM methods. However, the contextual knowledge from people tends to be incomplete and sometimes inaccurate, which greatly limits the applicability of knowledge-based SDM methods. In this paper, we develop a novel algorithm for knowledge-based SDM, called PERIL, that learns from interaction experience to reason about contextual knowledge, as applied to urban driving scenarios. Experiments have been conducted using CARLA, a widely used autonomous driving simulator. Results demonstrate PERIL's superiority in comparison to existing knowledge-based SDM baselines. 
 ID: 288 | Fixed-Budget Best-Arm Identification with Heterogeneous Reward Variances   
  
 Anusha Lalitha, Kousha Kalantari, Yifei Ma, Anoop Deoras, Branislav Kveton  

  TL;DR:  We design and analyze best-arm identification algorithms for the setting where reward variances are not equal.   Abstract:   
 We study the problem of best-arm identification (BAI) in the fixed-budget setting with heterogeneous reward variances. We propose two variance-adaptive BAI algorithms for this setting: SHVar for known reward variances and SHAdaVar for unknown reward variances. Our algorithms rely on non-uniform budget allocations among the arms where the arms with higher reward variances are pulled more often than those with lower variances. The main algorithmic novelty is in the design of SHAdaVar, which allocates budget greedily based on overestimating the unknown reward variances. We bound probabilities of misidentifying the best arms in both SHVar and SHAdaVar. Our analyses rely on novel lower bounds on the number of pulls of an arm that do not require closed-form solutions to the budget allocation problem. Since one of our budget allocation problems is analogous to the optimal experiment design with unknown variances, we believe that our results are of a broad interest. Our experiments validate our theory, and show that SHVar and SHAdaVar outperform algorithms from prior works with analytical guarantees. 
 ID: 290 | Convergence Rates for Localized Actor-Critic in Networked Markov Potential Games   
  
 Zhaoyi Zhou, Zaiwei Chen, Yiheng Lin, Adam Wierman  

  TL;DR:  We design a localized actor-critic algorithm for networked Markov potential games with provable finite-time convergence guarantees.   Abstract:   
 We introduce a class of networked Markov potential games where agents are associated with nodes in a network, each agent has its own local potential function, and the rewards of each agent depend only on the states and actions of agents within a $\kappa$-hop neighborhood. In this context, we propose a localized actor-critic policy. The policy is scalable since each agent uses only local information and does not need access to the global state. Further, the policy avoids the curse of dimensionality through the use of function approximation. Our main results provide finite-sample guarantees. We prove an $\mathcal{O}(1/M^{1/4})$ rate of convergence of the averaged Nash regret up to a critic error and a localization error, where $M$ is the total iteration number. This is the first finite-sample bound for multi-agent competitive games that does not depend on the number of agents. 
 ID: 294 | Nyström $M$-Hilbert-Schmidt Independence Criterion   
  
 Florian Kalinke, Zoltán Szabó  
   
    [link to video]   
   
  TL;DR:  We propose a Nyström approximation of the Hilbert-Schmidt independence criterion for more than two components with theoretical guarantees.   Abstract:   
 Kernel techniques are among the most popular and powerful approaches of data science. Among the key features that make kernels ubiquitous are (i) the number of domains they have been designed for, (ii) the Hilbert structure of the function class associated to kernels facilitating their statistical analysis, and (iii) their ability to represent probability distributions without loss of information. These properties give rise to the immense success of Hilbert-Schmidt independence criterion (HSIC) which is able to capture joint independence of random variables under mild conditions, and permits closed-form estimators with quadratic computational complexity (w.r.t.\ the sample size). In order to alleviate the quadratic computational bottleneck in large-scale applications, multiple HSIC approximations have been proposed, however these estimators are restricted to $M=2$ random variables, do not extend naturally to the $M\ge 2$ case, and lack theoretical guarantees. In this work, we propose an alternative Nyström-based HSIC estimator which handles the $M\ge 2$ case, prove its consistency, and demonstrate its applicability in multiple contexts, including synthetic examples, dependency testing of media annotations, and causal discovery. 
 ID: 297 | Validation of Composite Systems by Discrepancy Propagation   
 [spotlight]  
 David Reeb, Kanil Patel, Karim Said Barsim, Martin Schiegg, Sebastian Gerwinn  

  TL;DR:  By convex relaxations of distributional discrepancy optimizations, our method quantifies how close a chain of models approximates a real-world system.   Abstract:   
 Assessing the validity of a real-world system with respect to given quality criteria is a common yet costly task in industrial applications due to the vast number of required real-world tests. Validating such systems by means of simulation offers a promising and less expensive alternative, but requires an assessment of the simulation accuracy and therefore end-to-end measurements. Additionally, covariate shifts between simulations and actual usage can cause difficulties for estimating the reliability of such systems. In this work, we present a validation method that propagates bounds on distributional discrepancy measures through a composite system, thereby allowing us to derive an upper bound on the failure probability of the real system from potentially inaccurate simulations. Each propagation step entails an optimization problem, where -- for measures such as maximum mean discrepancy (MMD) -- we develop tight convex relaxations based on semidefinite programs. We demonstrate that our propagation method yields valid and useful bounds for composite systems exhibiting a variety of realistic effects. In particular, we show that the proposed method can successfully account for data shifts within the experimental design as well as model inaccuracies within the simulation. 
 ID: 298 | Group Equivariant Vision Transformer   
  
 Renjun Xu, Kaifan Yang, Ke Liu, Fengxiang He  

  TL;DR:  We prove that previous attempts on designing group-equivariant ViT not effective in some cases, which is then addressed by a novel, effective equivariant positional encoding.   Abstract:   
 Vision Transformer (ViT) has achieved remarkable performance in computer vision. However, positional encoding in ViT makes it substantially difficult to realize the equivariance, compared to models based on convolutional operations which are translation-equivariant. Initial attempts have been made on designing equivariant ViT but proved not effective in some cases in this paper. To address this issue, we propose a Group Equivariant Vision Transformer (GE-ViT) via a novel, effective positional encoding operation. We prove that GE-ViT meets all the theoretical requirements of an equivariant neural network. Comprehensive experiments are conducted on standard benchmark datasets. The empirical results demonstrate that GE-ViT has made significant improvement over non-equivariant self-attention networks. The code will be released publicly. 
 ID: 303 | MFA: Multi-scale Feature-aware Attack for Object Detection   
 [spotlight]  
 Wen Chen, Yushan Zhang, Zhiheng Li, Yuehuan Wang  
   
    [link to video]   
   
    Abstract:   
 Physically adversarial attacks can mislead detectors in the real world and have attracted increasing attention. However, most existing works directly manipulate the model‚Äôs final outputs as attack objects while ignoring the inherent characteristics of objects such as multi-scale features, which are easily trapped into model-specific local optimum and degrade the transferability. To address this issue, we propose the Multi-scale Feature-aware Attack (MFA) to generate adversarial camouflages with strong attacking ability and transferability by disrupting multi-scale object-aware critical features. Specifically, we adopt the location and category information of the detector outputs to assign attribution scores to different scale feature layers. Then, we weight each feature according to their attribution results and design a pixel-level loss function in the opposite optimized direction of object detection to generate adversarial camouflages. We conduct extensive experiments in both the digital and physical world on ten detection models (e.g., the up-to-date yolov7) and significantly demonstrate the superior performance of the proposed MFA. Our Code will be available at: https://github.com/ChenWen1997/MFA. 
 ID: 306 | Causal Effect Estimation from Observational and Interventional Data Through Matrix Weighted Linear Estimators   
  
 Klaus-Rudolf William Kladny, Julius von Kügelgen, Bernhard Schölkopf, Michael Muehlebach  
   
    [link to video]   
   
    Abstract:   
 We study causal effect estimation from a mixture of observational and interventional data in a confounded linear regression model with multivariate treatments. We show that the statistical efficiency in terms of expected squared error can be improved by combining estimators arising from both the observational and interventional setting. To this end, we derive methods based on matrix weighted linear estimators and prove that our methods are asymptotically unbiased in the infinite sample limit. This is an important improvement compared to the pooled estimator using the union of interventional and observational data, for which the bias only vanishes if the ratio of observational to interventional data tends to zero. Studies on synthetic data confirm our theoretical findings. In settings where confounding is substantial and the ratio of observational to interventional data is large, our estimators outperform a Stein-type estimator and various other baselines. 
 ID: 307 | Diversity-enhanced Probabilistic Ensemble For Uncertainty Estimation   
  
 Hanjing Wang, Qiang Ji  

    Abstract:   
 Ensemble methods combine multiple individual models for prediction, which have demonstrated their effectiveness in accurate uncertainty quantification (UQ) and strong robustness. Obtaining a diverse ensemble set of model parameters results in better Bayesian model averaging performance and better approximation of the true posterior distribution of model parameters. In this paper, we propose the diversity-enhanced probabilistic ensemble method with the adaptive uncertainty-guided ensemble learning strategy for better quantifying uncertainty and further improving the model robustness. Specifically, we construct the probabilistic ensemble model by building a Gaussian distribution of the model parameters for each ensemble component using Laplacian approximation in a post-processing manner. Then a mixture of Gaussian model is established with learnable and refinable parameters in an EM-like algorithm. During ensemble training, we leverage the uncertainty estimated from previous models as guidance when training the next one such that the new model will focus more on the less explored regions by previous models. Various experiments including out-of-distribution detection and image classification under distributional shifts have demonstrated better uncertainty estimation and improved model generalization ability for our proposed method. 
 ID: 309 | Differentiable User Models   
  
 Alex Hämäläinen, Mustafa Mert Çelikok, Samuel Kaski  
   
    [link to video]   
   
  TL;DR:  We introduce a method for efficient online inference with advanced and computationally costly cognitive models, enabling use of modern machine learning pipelines also in the ubiquitous cases with humans in the loop.   Abstract:   
 Probabilistic user modeling is essential for building collaborative AI systems within probabilistic frameworks. However, modern advanced user models, often designed as cognitive behavior simulators, are computationally prohibitive for interactive use in cooperative AI assistants. We address this problem by introducing widely-applicable differentiable surrogates for bypassing this computational bottleneck; the surrogates enable using modern behavioral models with online computational cost which is independent of their original computational cost. We show experimentally that modeling capabilities comparable to the only available solution, existing likelihood-free inference methods, are achievable with a computational cost suitable for online applications. Finally, we demonstrate how AI-assistants can now use cognitive models for online interaction in a menu-search task, which has so far required hours of computation during interaction. 
 ID: 310 | MMEL: A Joint Learning Framework for Multi-Mention Entity Linking   
  
 Chengmei YANG, Bowei He, Yimeng Wu, Chao Xing, Lianghua He, Chen Ma  

  TL;DR:  To tackle the multi-mention entity link problem, we propose a novel method, consisting of a context-entity joint feature extraction module, a multimodal learning framework, and a multi-mention collaborative ranking method with the pairwise training.   Abstract:   
 Entity linking, bridging mentions in the contexts with their corresponding entities in the knowledge bases, has attracted wide attention due to many potential applications. Previous methods mainly focus on the single-mention scenarios and neglect the scenarios where multiple mentions exist simultaneously in the same context, which limits their performance. In fact, such multi-mention scenarios are pretty common in public datasets and real-world applications. To solve this challenge, we first propose a joint feature extraction module to learn the representations of context and entity candidates, which can take the multimodal information into consideration. Then, we design a pairwise training scheme (for training) and a multi-mention collaborative ranking method (for testing) to model the potential connections between different mentions. We evaluate our method on a public dataset and a self-constructed dataset, NYTimes-MEL, under both the text-only and multimodal settings. The experimental results demonstrate that our method can largely outperform the state-of-the-art methods, especially in multi-mention scenarios. 
 ID: 320 | Layer-wise and Dimension-wise Locally Adaptive Federated Learning   
  
 Belhal Karimi, Xiaoyun Li, Ping Li  

    Abstract:   
 In the emerging paradigm of Federated Learning (FL), large amount of clients such as mobile devices are used to train possibly high-dimensional models on their respective data. Combing (\textit{dimension-wise}) adaptive gradient methods (e.g., Adam, AMSGrad) with FL has been an active direction, which is shown to outperform traditional SGD based FL in many cases. In this paper, we focus on the problem of training federated deep neural networks, and propose a novel FL framework which further introduces \emph{layer-wise} adaptivity to the local model updates to accelerate the convergence of adaptive FL methods. Our framework includes two variants based on two recent locally adaptive federated learning algorithms. Theoretically, we provide a convergence analysis of our layer-wise FL methods, coined Fed-LAMB and Mime-LAMB, which match the convergence rate of state-of-the-art results in adaptive FL and exhibits linear speedup in terms of the number of workers. Experimental results on various datasets and models, under both IID and non-IID local data settings, show that both Fed-LAMB and Mime-LAMB achieve faster convergence speed and better generalization performance, compared to various recent adaptive FL methods. 
 ID: 322 | Energy-based Predictive Representations for Partially Observed Reinforcement Learning   
  
 Tianjun Zhang, Tongzheng Ren, Chenjun Xiao, Wenli Xiao, Joseph E. Gonzalez, Dale Schuurmans, Bo Dai  

  TL;DR:  We propose a novel predictive state representation with energy-based models, that shows superior performance on POMDPs.   Abstract:   
 In real world applications, it is usually necessary for a reinforcement learning algorithm to handle the partial observability beyond Markov decision processes (MDPs). Although the partially observable Markov decision process (POMDP) has been precisely motivated for this requirement, such a formulation raises significant computational and statistical hardness challenges in learning and planning. In this work, we introduce the Energy-based Predictive Representation (EPR), which leads to a unified framework for practical reinforcement learning algorithm design in both MDPs and POMDPs settings, to handle the learning, exploration, and planning in a coherent way. The proposed approach relies on the powerful neural energy-based model to extract sufficient representation, from which Q-functions can be efficiently approximated. With such a representation, we develop an efficient approach for computing confidence, which allows optimism/pessimism in the face of uncertainty to be efficiently implemented in planning, hence managing the exploration versus exploitation tradeoff. An experimental investigation shows that the proposed algorithm can surpass state-of-the-art performance in both MDP and POMDP settings in comparison to existing baselines. 
 ID: 325 | Incentivising Diffusion while Preserving Differential Privacy   
 [spotlight]  
 Fengjuan Jia, Mengxiao Zhang, Jiamou Liu, Bakh Khoussainov  

    Abstract:   
 Diffusion auction refers to an emerging paradigm of online marketplace where an auctioneer utilises a social network to attract potential buyers. Diffusion auction poses significant privacy risks. From the auction outcome, it is possible to infer hidden, and potentially sensitive, preferences of buyers. To mitigate such risks, we initiate the study of differential privacy (DP) in diffusion auction mechanisms. DP is a well-established notion of privacy that protects a system against inference attacks. Achieving DP in diffusion auctions is non-trivial as the well-designed auction rules are required to incentivise the buyers to truthfully report their neighbourhood. We study the single-unit case and design two differentially private diffusion mechanisms (DPDMs): recursive DPDM and layered DPDM. We prove that these mechanisms guarantee differential privacy, incentive compatibility and individual rationality for both valuations and neighbourhood. We then empirically compare their performance on real and synthetic datasets. 
 ID: 328 | Learning To Invert: Simple Adaptive Attacks for Gradient Inversion in Federated Learning   
  
 Ruihan Wu, Xiangyu Chen, Chuan Guo, Kilian Q Weinberger  

    Abstract:   
 Gradient inversion attack enables recovery of training samples from model gradients in federated learning (FL), and constitutes a serious threat to data privacy. To mitigate this vulnerability, prior work proposed both principled defenses based on differential privacy, as well as heuristic defenses based on gradient compression as countermeasures. These defenses have so far been very effective, in particular those based on gradient compression that allow the model to maintain high accuracy while greatly reducing the effectiveness of attacks. In this work, we argue that such findings underestimate the privacy risk in FL. As a counterexample, we show that existing defenses can be broken by a simple adaptive attack, where a model trained on auxiliary data is able to invert gradients on both vision and language tasks. 
 ID: 332 | Approximating Probabilistic Explanations via Supermodular Minimization   
  
 Louenas Bounia, Frederic M Koriche  

  TL;DR:  In the setting of probabilistic explanations, we propose two greedy approximation algorithms for minimizing explanation errors subject to a cardinality constraint.   Abstract:   
 Explaining in accurate and intelligible terms the predictions made by classifiers is a key challenge of eXplainable Artificial Intelligence (XAI). To this end, an abductive explanation for the output $h(x)$ of some data instance $x$, given a classifier $h$, is a subset-minimal collection of features $I$ such that the restriction of $x$ to $I$ is sufficient to determine $h(x)$. Yet, due to cognitive limitations, abductive explanations are often too large to be interpretable, and in those cases, we need to identify a subset $S$ of $I$ of size at most $k$ that determines $h(x)$ with high probability. In this paper, we show that finding such probabilistic explanations is NP-hard, even for decision trees. In order to circumvent this issue, we investigate the approximability of probabilistic explanations through the lens of supermodularity. We examine both greedy descent and greedy ascent methods for supermodular minimization, whose approximation guarantees depend on the curvature of the ``unnormalized'' error function that evaluates the precision of $S$. Based on various experiments for explaining decision tree predictions, we show that our greedy algorithms provide an efficient alternative to the state-of-the-art constraint optimization method. 
 ID: 341 | Stochastic Graphical Bandits with Heavy-Tailed Rewards   
  
 Yutian Gou, Jinfeng Yi, Lijun Zhang  

    Abstract:   
 We consider stochastic graphical bandits, where after pulling an arm, the decision maker observes rewards of not only the chosen arm but also its neighbors in a feedback graph. Most of existing work assumes that the rewards are drawn from bounded or at least sub-Gaussian distributions, which however may be violated in many practical scenarios such as social advertising and financial markets. To settle this issue, we investigate stochastic graphical bandits with heavy-tailed rewards, where the distributions have finite moments of order $1+\epsilon$, for some $\epsilon\in(0, 1]$. Firstly, we develop one UCB-type algorithm, whose expected regret is upper bounded by a sum of gap-based quantities over the \textit{clique covering} of the feedback graph. The key idea is to estimate the reward means of the selected arm's neighbors by more refined robust estimators, and to construct a graph-based upper confidence bound for selecting candidates. Secondly, we design another elimination-based strategy and improve the regret bound to a gap-based sum with size controlled by the \textit{independence number} of the feedback graph. For benign graphs, the \textit{independence number} could be smaller than the size of the \textit{clique covering}, resulting in tighter regret bounds. Finally, we conduct experiments on synthetic data to demonstrate the effectiveness of our methods. 
 ID: 342 | Revisiting Bayesian Network Learning with Small Vertex Cover   
 [oral]  
 Juha Harviainen, Mikko Koivisto  
   
    [slides]   
   
  TL;DR:  We present new algorithms for learning, sampling and counting Bayesian networks parameterized by the vertex cover number.   Abstract:   
 The problem of structure learning in Bayesian networks asks for a directed acyclic graph (DAG) that maximizes a given scoring function. Since the problem is NP-hard, research effort has been put into discovering restricted classes of DAGs for which the search problem can be solved in polynomial time. Here, we initiate investigation of questions that have received less attention thus far: Are the known polynomial algorithms close to the best possible, or is there room for significant improvements? If the interest is in Bayesian learning, that is, in sampling or weighted counting of DAGs, can we obtain similar complexity results? Focusing on DAGs with bounded vertex cover number‚Äìa class studied in Korhonen and Parviainen's seminal work (NIPS 2015)‚Äìwe answer the questions in the affirmative. We also give, apparently the first, proof that the counting problem is #P-hard in general. In addition, we show that under the vertex-cover constraint counting is #W[1]-hard. 
 ID: 351 | Multi-View Independent Component Analysis with Shared and Individual Sources   
  
 Teodora Pandeva, Patrick Forré  

    Abstract:   
 Independent component analysis (ICA) is a blind source separation method for linear disentanglement of independent latent sources from observed data. We investigate the special setting of noisy linear ICA where the observations are split among different views, each receiving a mixture of shared and individual sources. We prove that the corresponding linear structure is identifiable, and the sources distribution can be recovered. To computationally estimate the sources, we optimize a constrained form of the joint log-likelihood of the observed data among all views. We show empirically that our objective recovers the sources also in the case when the measurements are corrupted by noise. Furthermore, we propose a model selection procedure for recovering the number of shared sources which we verify empirically. Finally, we apply the proposed model in a challenging real-life application, where the estimated shared sources from two large transcriptome datasets (observed data) provided by two different labs (two different views) lead to recovering biologically meaningful (shared) sources utilized for finding a plausible representation of the underlying graph structure. 
 ID: 353 | On Inference and Learning With Probabilistic Generating Circuits   
 [oral]  
 Juha Harviainen, Vaidyanathan Peruvemba Ramaswamy, Mikko Koivisto  
   
    [slides]   
   
  TL;DR:  We present faster inference algorithms for probabilistic generating circuits and study the hardness of parameter learning.   Abstract:   
 Probabilistic generating circuits (PGCs) are economical representations of multivariate probability generating polynomials (PGPs). They unify and extend decomposable probabilistic circuits and determinantal point processes, admitting tractable computation of marginal probabilities. However, the need for addition and multiplication of high-degree polynomials incurs a significant additional factor in the complexity of inference. Here, we give a new inference algorithm that eliminates this extra factor. Specifically, we show that it suffices to keep track of the highest degree coefficients of the computed polynomials, rendering the algorithm linear in the circuit size. In addition, we show that determinant-based circuits need not be expanded to division-free circuits, but can be handled by division-based fast algorithms. While these advances enhance the appeal of PGCs, we also discover an obstacle to learning them from data: it is NP-hard to recognize whether a given PGC encodes a PGP. We discuss the implications of our ambivalent findings and sketch a method, in which learning is restricted to PGCs that are composed of moderate-size subcircuits. 
 ID: 354 | JANA: Jointly Amortized Neural Approximation of Complex Bayesian Models   
 [spotlight]  
 Stefan T. Radev, Marvin Schmitt, Valentin Pratz, Umberto Picchini, Ullrich Koethe, Paul Buerkner  

  TL;DR:  This work proposes a deep learning method for simulatenously approximating intractable likelihood functions and posterior densities arising in surrogate modeling and simulation-based inference.   Abstract:   
 This work proposes "jointly amortized neural approximation" (JANA) of intractable likelihood functions and posterior densities arising in Bayesian surrogate modeling and simulation-based inference. We train three complementary networks in an end-to-end fashion: 1) a summary network to compress individual data points, sets, or time series into informative embedding vectors; 2) a posterior network to learn an amortized approximate posterior; and 3) a likelihood network to learn an amortized approximate likelihood. Their interaction opens a new route to amortized marginal likelihood and posterior predictive estimation - two important ingredients of Bayesian workflows that are often too expensive for standard methods. We benchmark the fidelity of JANA on a variety of simulation models against state-of-the-art Bayesian methods and propose a powerful and interpretable diagnostic for joint calibration. In addition, we investigate the ability of recurrent likelihood networks to emulate complex time series models without resorting to hand-crafted summary statistics. 
 ID: 356 | Bayesian PLS! Approximate Bayes Optimal Pseudo-Label Selection (PLS)   
  
 Julian Martin Rodemann, Jann Goschenhofer, Emilio Dorigatti, Thomas Nagler, Thomas Augustin  
   
    [link to video]   
   
  TL;DR:  We propose approximate Bayes optimal selection of pseudo-samples in self-training to address the confirmation bias.   Abstract:   
 Semi-supervised learning by self-training heavily relies on pseudo-label selection (PLS). The selection often depends on the initial model fit on labeled data. Early overfitting might thus be propagated to the final model by selecting instances with overconfident but erroneous predictions, often referred to as confirmation bias. This paper introduces BPLS, a Bayesian framework for PLS that aims to mitigate this issue. At its core lies a criterion for selecting instances to label: an analytical approximation of the posterior predictive of pseudo-samples. We derive this selection criterion by proving Bayes optimality of the posterior predictive of pseudo-samples. We further overcome computational hurdles by approximating the criterion analytically. Its relation to the marginal likelihood allows us to come up with an approximation based on Laplace's method and the Gaussian integral. We empirically assess BPLS for parametric generalized linear and non-parametric generalized additive models on simulated and real-world data. When faced with high-dimensional data prone to overfitting, BPLS outperforms traditional PLS methods. 
 ID: 358 | Probabilistic Multi-Dimensional Classification   
  
 Vu-Linh Nguyen, Yang Yang, Cassio de Campos  

  TL;DR:  In this paper, we present a first attempt to learn probabilistic multi-dimensional classifiers which are interpretable, accurate, scalable and capable of handling mixed data.   Abstract:   
 Multi-dimensional classification (MDC) can be employed in a range of applications where one needs to predict multiple class variables for each given instance. Arguably, probabilistic MDC has been studied seldom when compared to its single class variable counterpart. Existing MDC methods often suffer from at least one of inaccuracy, scalability, limited use to certain types of data, hardness of interpretation or lack of probabilistic (uncertainty) estimations. To our best knowledge, this paper is a first attempt to address all these disadvantages simultaneously. We propose a formal framework for probabilistic MDC in which learning an optimal multi-dimensional classifier can be decomposed, without loss of generality, into learning a set of (smaller) single-variable multi-class probabilistic classifiers and a directed acyclic graph. Current and future developments of both probabilistic classification and graphical model learning can directly enhance our framework, which is flexible and provably optimal. A collection of experiments is conducted to highlight the usefulness of this MDC framework. 
 ID: 368 | A scalable Walsh-Hadamard regularizer to overcome the low-degree spectral bias of neural networks   
  
 Ali Gorji, Andisheh Amrollahi, Andreas Krause  

  TL;DR:  We empirically investigate the spectral bias of neural networks in learning only low-degree interactions and introduce a regularizer to remedy this.   Abstract:   
 Despite the capacity of neural nets to learn arbitrary functions, models trained through gradient descent often exhibit a bias towards "simpler" functions. Various notions of simplicity have been introduced to characterize this behavior. Here, we focus on the case of neural networks with discrete (zero-one) inputs through the lens of their Fourier (Walsh-Hadamard) transforms, where the notion of simplicity can be captured through the degree of the Fourier coefficients. We empirically show that neural networks have a tendency to learn lower-degree frequencies. We show how this spectral bias towards simpler features can in fact hurt the neural network's generalization on real-world datasets. To remedy this we propose a new and scalable functional regularization scheme that aids the neural network to learn higher degree frequencies. Our regularizer also helps avoid erroneous identification of low-degree frequencies, which further improves generalization. We extensively evaluate our regularizer on synthetic datasets to gain insights into its behavior. Finally, we show significantly improved generalization on four different datasets compared to standard neural networks and other relevant baselines. 
 ID: 370 | On the Role of Model Uncertainties in Bayesian Optimisation   
  
 Jonathan Foldager, Mikkel Jordahn, Lars Kai Hansen, Michael Riis Andersen  

    Abstract:   
 Bayesian Optimization (BO) is a popular method for black-box optimization, which relies on uncertainty as part of its decision-making process when deciding which experiment to perform next. However, not much work has addressed the effect of uncertainty on the performance of the BO algorithm and to what extent calibrated uncertainties improve the ability to find the global optimum. In this work, we provide an extensive study of the relationship between the BO performance (regret) and uncertainty calibration for popular surrogate models and acquisition functions, and compare them across both synthetic and real-world experiments. Our results show that Gaussian Processes, and more surprisingly, Deep Ensembles are strong surrogate models. Our results further show a positive association between calibration error and regret, but interestingly, this association disappears when we control for the type of surrogate model in the analysis. We also study the effect of recalibration and demonstrate that it generally does not lead to improved regret. Finally, we provide theoretical justification for why uncertainty calibration might be difficult to combine with BO due to the small sample sizes commonly used. 
 ID: 374 | Quantifying Aleatoric and Epistemic Uncertainty in Machine Learning: Are Conditional Entropy and Mutual Information Appropriate Measures?   
 [oral]  
 Lisa Wimmer, Yusuf Sale, Paul Hofman, Bernd Bischl, Eyke Hüllermeier  
   
    [slides]   
   
    Abstract:   
 The quantification of aleatoric and epistemic uncertainty in terms of conditional entropy and mutual information, respectively, has recently become quite common in machine learning. While the properties of these measures, which are rooted in information theory, seem appealing at first glance, we identify various incoherencies that call their appropriateness into question. In addition to the measures themselves, we critically discuss the idea of an additive decomposition of total uncertainty into its aleatoric and epistemic constituents. Experiments across different computer vision tasks support our theoretical findings and raise concerns about current practice in uncertainty quantification. 
 ID: 375 | Differential Privacy in Cooperative Multiagent Planning   
  
 Bo Chen, Calvin Hawkins, Mustafa O. Karabag, Cyrus Neary, Matthew Hale, ufuk topcu  

  TL;DR:  We develop a framework to provide inter-agent privacy in multiagent systems and to synthesize policies that remain performant under private communications.   Abstract:   
 Privacy-aware multiagent systems must protect agents' sensitive data while simultaneously ensuring that agents accomplish their shared objectives. Towards this goal, we propose a framework to privatize inter-agent communications in cooperative multiagent decision-making problems. We study sequential decision-making problems formulated as cooperative Markov games with reach-avoid objectives. We apply a differential privacy mechanism to privatize agents' communicated symbolic state trajectories, and analyze tradeoffs between the strength of privacy and the team's performance. For a given level of privacy, this tradeoff is shown to depend critically upon the total correlation among agents' state-action processes. We synthesize policies that are robust to privacy by reducing the value of the total correlation. Numerical experiments demonstrate that the team's performance under these policies decreases by only 6 percent when comparing private versus non-private implementations of communication. By contrast, the team's performance decreases by 88 percent when using baseline policies that ignore total correlation and only optimize team performance. 
 ID: 380 | Provably Efficient Adversarial Imitation Learning with Unknown Transitions   
 [oral]  
 Tian Xu, Ziniu Li, Yang Yu, Zhi-Quan Luo  
   
    [link to video]  [slides]   
   
  TL;DR:  We theoretically explore adversarial imitation learning with unknown transitions.   Abstract:   
 The process of learning good policies from expert demonstrations, known as imitation learning (IL), has been proven effective in many applications. Adversarial imitation learning (AIL), a subset of IL methods, is particularly promising, but its theoretical foundation in the presence of unknown transitions has yet to be fully developed. This paper explores the theoretical underpinnings of AIL in this context, where the primary challenge is the stochastic and uncertain nature of environment transitions. We examine the expert sample complexity and interaction complexity required to recover good policies, which are of great practical interest. To this end, we establish a framework connecting reward-free exploration and AIL, and propose an algorithm, MB-TAIL, that achieves the minimax optimal expert sample complexity of $\widetilde{\mathcal{O}} (H^{3/2} |\mathcal{S}|/\varepsilon)$ and interaction complexity of $\widetilde{\mathcal{O}} (H^{3} |\mathcal{S}|^2 |\mathcal{A}|/\varepsilon^2)$. Here, $H$ represents the planning horizon, $|\mathcal{S}|$ is the state space size, $|\mathcal{A}|$ is the action space size, and $\varepsilon$ is the desired imitation gap. MB-TAIL is the first algorithm to achieve this level of expert sample complexity in the unknown transition setting and improves upon the interaction complexity of the best-known algorithm, OAL, by $\mathcal{O} (H)$. Additionally, we demonstrate the generalization ability of MB-TAIL by extending it to the function approximation setting and proving that it can achieve expert sample and interaction complexity independent of $|\mathcal{S}|$. 
 ID: 387 | Combinatorial Categorized Bandits with Expert Rankings   
  
 Sayak Ray Chowdhury, Gaurav Sinha, Nagarajan Natarajan, Amit Sharma  

    Abstract:   
 Many real-world systems such as e-commerce websites and content-serving platforms employ two-stage recommendation --- in the first stage, multiple nominators (experts) provide ranked lists of items (one nominator per category, e.g., sports and political news articles), and in the second stage, an aggregator filters across the lists and outputs a single (short) list of $K$ items to the users. The aggregation stage can be posed as a combinatorial multi-armed bandit problem, with the additional structure that the arms are grouped into categories (disjoint sets of items) and the ranking of arms within each category is known. We propose algorithms for selecting top $K$ items in this setting under two learning objectives, namely minimizing regret over rounds and identifying the top $K$ items within a fixed number of rounds. For each of the objectives, we provide sharp regret/error analysis using carefully defined notion of ``gap'' that exploits our problem structure. The resulting regret/error bounds strictly improve over prior work in combinatorial bandits literature. We also provide supporting evidence from simulations on synthetic and semi-synthetic problems. 
 ID: 390 | Causal Discovery for time series from multiple datasets with latent contexts   
  
 Wiebke Günther, Urmi Ninad, Jakob Runge  

    Abstract:   
 Causal discovery from time series data is a typical problem setting across the sciences. Often, multiple datasets of the same system variables are available, for instance, time series of river runoff from different catchments. The local catchment systems then share certain causal drivers, such as time-dependent large-scale weather over all catchments, but differ in other catchment-specific drivers, such as the altitude of the catchment. These drivers can be called temporal and spatial contexts, respectively, and are often partially unobserved. Pooling the datasets and considering the joint causal graph among system, context, and certain auxiliary variables enables us to overcome such latent confounding of system variables. In this work, we present a non-parametric time series causal discovery method, J(oint)-PCMCI+, that efficiently learns such joint causal time series graphs when both observed and latent contexts are present, including time lags. We present asymptotic consistency results and numerical experiments demonstrating the utility and limitations of the method. 
 ID: 392 | Increasing Effect Sizes of Pairwise Conditional Independence Tests between Random Vectors   
  
 Tom Hochsprung, Jonas Wahl, Andreas Gerhardus, Urmi Ninad, Jakob Runge  

  TL;DR:  Our paper introduces a new pairwise conditional independence testing algorithm.   Abstract:   
 A simple approach to test for conditional independence of two random vectors given a third random vector is to simultaneously test for conditional independence of every pair of components of the two random vectors given the third random vector. In this work, we show that conditioning on additional components of the two random vectors that are independent given the third one increases the tests' effect sizes while leaving the validity of the overall approach unchanged. Up to the effective reduction of the sample size due to enlarging the conditioning sets, these larger effect sizes lead to higher statistical power. We leverage this result to derive a practical pairwise testing algorithm that first chooses tests with a relatively large effect size and then does the actual testing. In simulations, our algorithm outperforms standard pairwise independence testing and other existing methods if the dependence within the two random vectors is sufficiently high. 
 ID: 394 | Causal Discovery with Hidden Confounders   
  
 David Kaltenpoth, Jilles Vreeken  

  TL;DR:  We propose a general framework for discovering latent confounders from purely observational data. We show that in the sparse linear Gaussian case, our proposed model is identifiable and permits a consistent algorithm.   Abstract:   
 Causal sufficiency is a cornerstone assumption in causal discovery. It is, however, both unlikely to hold in practice as well as unverifiable. When it does not hold, existing methods struggle to return meaningful results. In this paper, we show how to discover the causal network over both observed and unobserved variables. Moreover, we show that the causal model is identifiable in the sparse linear Gaussian case. More generally, we extend the algorithmic Markov condition to include latent confounders. We propose a consistent score based on the Minimum Description Length principle to discover the full causal network, including latent confounders. Based on this score, we develop an effective algorithm that finds those sets of nodes for which the addition of a confounding factor $Z$ is most beneficial, then fits a new causal network over both observed as well as inferred latent variables. 
 ID: 396 | When are Post-Hoc Conceptual Explanations Identifiable?   
  
 Tobias Leemann, Michael Kirchhof, Yao Rong, Enkelejda Kasneci, Gjergji Kasneci  

  TL;DR:  We derive conditions under which conceptual explanation methods recover the ground truth concepts and additionally propose two new methods for the case of dependent concept distributions.   Abstract:   
 Interest in understanding and factorizing learned embedding spaces through conceptual explanations is steadily growing. When no human concept labels are available, concept discovery methods search trained embedding spaces for interpretable concepts like object shape or color that can be used to provide post-hoc explanations for decisions. Unlike previous work, we argue that concept discovery should be identifiable, meaning that a number of known concepts can be provably recovered to guarantee reliability of the explanations. As a starting point, we explicitly make the connection between concept discovery and classical methods like Principal Component Analysis and Independent Component Analysis by showing that they can recover independent concepts with non-Gaussian distributions. For dependent concepts, we propose two novel approaches that exploit functional compositionality properties of image-generating processes. Our provably identifiable concept discovery methods substantially outperform competitors on a battery of experiments including hundreds of trained models and dependent concepts, where they exhibit up to 29 % better alignment with the ground truth. Our results provide a rigorous foundation for reliable concept discovery without human labels. 
 ID: 397 | Differentially Private Synthetic Data Using KD-Trees   
  
 Eleonora Kreacic, Navid Nouri, Vamsi K. Potluru, Tucker Balch, Manuela Veloso  

  TL;DR:  We propose data independent and data dependent algorithms for differentially private synthetic data generation whose kernel density resembles that of the real dataset.   Abstract:   
 We propose both data independent and data dependent algorithms for $\epsilon$-differentially private synthetic data generation whose kernel density resembles that of the real dataset. Creation of a synthetic dataset that faithfully represents the data distribution and simultaneously preserves privacy is a major research challenge. Many space partitioning based approaches have emerged in recent years for answering statistical queries in a differentially private manner. However, for synthetic data generation problem, recent research has been mainly focused on deep generative models. In contrast, we exploit space partitioning techniques together with noise perturbation and thus achieve intuitive and transparent algorithms. We provide theoretical results on the utility-privacy trade-offs and show how our data dependent approach overcomes the curse of dimensionality and leads to a scalable algorithm. We show empirical utility improvements over the prior work, and discuss performance of our algorithm on a downstream classification task on a real dataset. 
 ID: 402 | An Improved Variational Approximate Posterior for the Deep Wishart Process   
 [oral]  
 Sebastian W. Ober, Ben Anson, Edward Milsom, Laurence Aitchison  
   
    [slides]   
   
    Abstract:   
 Deep kernel processes are a recently introduced class of deep Bayesian models that have the flexibility of neural networks, but work entirely with Gram matrices. They operate by alternately sampling a Gram matrix from a distribution over positive semi-definite matrices, and applying a deterministic transformation. When the distribution is chosen to be Wishart, the model is called a deep Wishart process (DWP). This particular model is of interest because its prior is equivalent to a deep Gaussian process (DGP) prior, but at the same time it is invariant to rotational symmetries, leading to a simpler posterior distribution. Practical inference in the DWP was made possible in recent work ("A variational approximate posterior for the deep Wishart process" Ober and Aitchison, 2021a) where the authors used a generalisation of the Bartlett decomposition of the Wishart distribution as the variational approximate posterior. However, predictive performance in that paper was less impressive than one might expect, with the DWP only beating a DGP on a few of the UCI datasets used for comparison. In this paper, we show that further generalising their distribution to allow linear combinations of rows and columns in the Bartlett decomposition results in better predictive performance, while incurring negligible additional computation cost. 
 ID: 406 | Learning Good Interventions in Causal Graphs via Covering   
  
 Ayush Sawarni, Rahul Madhavan, Gaurav Sinha, Siddharth Barman  

  TL;DR:  State-of-the-art guarantees for the causal bandit problem   Abstract:   
 We study the causal bandit problem that entails identifying a near-optimal intervention from a specified set $\cal{A}$ of (possibly non-atomic) interventions over a given causal graph. Here, an optimal intervention in $\cal{A}$ is one that maximizes the expected value for a designated reward variable in the graph, and we use the standard notion of simple regret to quantify near optimality. Considering Bernoulli random variables and for causal graphs on $N$ vertices with constant in-degree, prior work has achieved a worst case guarantee of $\widetilde{O} (N/\sqrt{T})$ for simple regret. The current work utilizes the idea of covering interventions (which are not necessarily contained within $\cal{A}$) and establishes a simple regret guarantee of $\widetilde{O}(\sqrt{N/T})$. Notably, and in contrast to prior work, our simple regret bound depends only on explicit parameters of the problem instance. We also go beyond prior work and achieve a simple regret guarantee for causal graphs with unobserved variables. Further, we perform experiments to show improvements over baselines in this setting. 
 ID: 407 | Variable Importance Matching for Causal Inference   
  
 Quinn Lanners, Harsh Parikh, Alexander Volfovsky, Cynthia Rudin, David Page  
   
    [link to video]   
   
  TL;DR:  Variable importance can be used as a distance metric for almost exact matching.   Abstract:   
 Our goal is to produce methods for observational causal inference that are auditable, easy to troubleshoot, yield accurate treatment effect estimates, and scalable to high-dimensional data. We describe a general framework called Model-to-Match that achieves these goals by (i) learning a distance metric via outcome modeling, (ii) creating matched groups using the distance metric, and (iii) using the matched groups to estimate treatment effects. Model-to-Match uses variable importance measurements to construct a distance metric, making it a flexible framework that can be adapted to various applications. Concentrating on the scalability of the problem in the number of potential confounders, we operationalize the Model-to-Match framework with LASSO. We derive performance guarantees for settings where LASSO outcome modeling consistently identifies all confounders (importantly without requiring the linear model to be correctly specified). We also provide experimental results demonstrating the auditability of matches, as well as extensions to more general nonparametric outcome modeling. 
 ID: 420 | Corrigibility: Definitions, Algorithms & Implications   
  
 Ryan Carey, Tom Everitt  

  TL;DR:  A formal analysis of algorithms that would lead to safe shutdown behaviour   Abstract:   
 How can humans stay in control of advanced artificial intelligence systems? One proposal is corrigibility, which requires the agent to follow the instructions of a human overseer, without inappropriately influencing them. In this paper, we provide the first formal definition of corrigibility, and show that it implies appropriate shutdown behavior, retention of human autonomy, and safety in low-stakes settings. We also analyse the related concepts of non-obstruction and counterfactual obedience, as well as three previously proposed corrigibility algorithms, and one new algorithm. 
 ID: 421 | Benefits of Monotonicity in Safe Exploration with Gaussian Processes   
  
 Arpan Losalka, Jonathan Scarlett  

    Abstract:   
 We consider the problem of sequentially maximising an unknown function over a set of actions while ensuring that every sampled point has a function value below a given safety threshold. We model the function using kernel-based and Gaussian process methods, while differing from previous works in our assumption that the function is monotonically increasing with respect to a safety variable. This assumption is motivated by various practical applications such as adaptive clinical trial design and robotics. Taking inspiration from the GP-UCB and SAFEOPT algorithms, we propose an algorithm, monotone safe UCB (M-SafeUCB) for this task. We show that M-SafeUCB enjoys theoretical guarantees in terms of safety, a suitably-defined regret notion, and approximately finding the entire safe boundary. In addition, we illustrate that the monotonicity assumption yields significant benefits in terms of the guarantees obtained, as well as algorithmic simplicity and efficiency. We support our theoretical findings by performing empirical evaluations on a variety of functions, including a simulated clinical trial experiment. 
 ID: 430 | Local Message Passing on Frustrated Systems   
 [oral]  
 Luca Schmid, Joshua Brenk, Laurent Schmalen  
   
    [slides]   
   
  TL;DR:  This work proposes a novel method to derive efficient message passing algorithms for approximate inference on graphs with many cycles.   Abstract:   
 Message passing on factor graphs is a powerful framework for probabilistic inference, which finds important applications in various scientific domains. The most wide-spread message passing scheme is the sum-product algorithm (SPA) which gives exact results on trees but often fails on graphs with many small cycles. We search for an alternative message passing algorithm which works particularly well on such cyclic graphs. Therefore, we challenge the extrinsic principle of the SPA, which loses its purpose on graphs with cycles. We further replace the local SPA message update rule at the factor nodes of the underlying graph with a generic mapping, which is optimized in a data-driven fashion. These modifications lead to a considerable improvement of the performance, while preserving the simplicity of the SPA. We evaluate our method for two classes of cyclic graphs: the 2x2 fully connected Ising grid and factor graphs for symbol detection on linear communication channels with inter-symbol interference. To enable the method for large graphs as they occur in practical applications, we develop a novel loss function which is inspired by the Bethe approximation from statistical physics and allows for training in an unsupervised fashion. 
 ID: 432 | Learning from Low Rank Tensor Data: A Random Tensor Theory Perspective   
 [oral]  
 Mohamed El Amine Seddik, Malik Tiomoko, Alexis Decurninge, Maxime Guillaud, Maxim Panov  
   
    [slides]   
   
    Abstract:   
 Under a simplified data model, this paper provides a theoretical analysis of learning from data that have an underlying low-rank tensor structure in both supervised and unsupervised settings. For the supervised setting, we provide an analysis of a Ridge classifier (with high regularization parameter) with and without knowledge of the low-rank structure of the data. Our results quantify analytically the gain in misclassification errors achieved by exploiting the low-rank structure for denoising purposes, as opposed to treating data as mere vectors. We further provide a similar analysis in the context of clustering, thereby quantifying the exact performance gap between tensor methods and standard approaches which treat data as simple vectors. 
 ID: 433 | Concurrent Misclassification and Out-of-Distribution Detection for Semantic Segmentation via Energy-Based Normalizing Flow   
  
 Denis A Gudovskiy, Tomoyuki Okuno, Yohei Nakata  

  TL;DR:  A normalizing flow model with the energy-based inputs to detect in-distribution misclassifications and out-of-distribution examples for semantic segmentation application   Abstract:   
 Recent semantic segmentation models accurately classify test-time examples that are similar to a training dataset distribution. However, their discriminative closed-set approach is not robust in practical data setups with distributional shifts and out-of-distribution (OOD) classes. As a result, the predicted probabilities can be very imprecise when used as confidence scores at test time. To address this, we propose a generative model for concurrent in-distribution misclassification (IDM) and OOD detection that relies on a normalizing flow framework. The proposed flow-based detector with an energy-based inputs (FlowEneDet) can extend previously deployed segmentation models without their time-consuming retraining. Our FlowEneDet results in a low-complexity architecture with marginal increase in the memory footprint. FlowEneDet achieves promising results on Cityscapes, Cityscapes-C, FishyScapes and SegmentMeIfYouCan benchmarks in IDM/OOD detection when applied to pretrained DeepLabV3+ and SegFormer semantic segmentation models. 
 ID: 434 | Scalable and Robust Tensor Ring Decomposition for Large-scale Data   
  
 Yicong He, George K. Atia  

    Abstract:   
 Tensor ring (TR) decomposition has recently received increased attention due to its superior expressive performance for high-order tensors. However, the applicability of traditional TR decomposition algorithms to real-world applications is hindered by prevalent large data sizes, missing entries, and corruption with outliers. In this work, we propose a scalable and robust TR decomposition algorithm capable of handling large-scale tensor data with missing entries and gross corruptions. We first develop a novel auto-weighted steepest descent method that can adaptively fill the missing entries and identify the outliers during the decomposition process. Further, taking advantage of the tensor ring model, we develop a novel fast Gram matrix computation (FGMC) approach and a randomized subtensor sketching (RStS) strategy which yield significant reduction in storage and computational complexity. Experimental results demonstrate that the proposed method outperforms existing TR decomposition methods in the presence of outliers, and runs significantly faster than existing robust tensor completion algorithms. 
 ID: 437 | Quantifying lottery tickets under label noise: accuracy, calibration, and complexity   
  
 Viplove Arora, Daniele Irto, Sebastian Goldt, Guido Sanguinetti  

  TL;DR:  Pruning networks with sizes ranging over orders of magnitude can be pruned to obtain small networks of comparable sizes that have low test error and good calibration.   Abstract:   
 Pruning deep neural networks is a widely used strategy to alleviate the computational burden in machine learning. Overwhelming empirical evidence suggests that pruned models retain very high accuracy even with a tiny fraction of parameters. However, relatively little work has gone into characterising the small pruned networks obtained, beyond a measure of their accuracy. In this paper, we study small networks obtained via the iterative magnitude pruning (IMP) procedure on data with label noise. We observe empirically that, for a given task, IMP tends to converge to networks of comparable sizes even when starting from full networks with sizes ranging over orders of magnitude. We analyse the best pruned models in a controlled experimental setup and show that their number of parameters reflects task difficulty and that they are much better than full networks at capturing the true conditional probability distribution of the labels. On real data, we similarly observe that pruned models are less prone to overconfident predictions. Our results suggest that pruned models obtained via IMP not only have advantageous computational properties but also provide a better representation of uncertainty in learning. 
 ID: 442 | Vacant Holes for Unsupervised Detection of the Outliers in Compact Latent Representation   
  
 Misha Glazunov, Apostolis Zarras  

  TL;DR:  A method for unsupervised outlier detection utilizing holes based on the compact latent space with constrained factors of variation   Abstract:   
 Detection of the outliers is pivotal for any machine learning model deployed and operated in real-world. It is essential for the Deep Neural Networks that were shown to be overconfident with such inputs. Moreover, even deep generative models that allow estimation of the probability density of the input fail in achieving this task. In this work, we concentrate on the specific type of these models: Variational Autoencoders (VAEs). First, we unveil a significant theoretical flaw in the assumption of the classical VAE model. Second, we enforce an accommodating topological property to the image of the deep neural mapping to the latent space: compactness to alleviate the flaw and obtain the means to provably bound it within the determined limits by squeezing both inliers and outliers together. We enforce compactness using two approaches: Alexandroff extension and fixed Lipschitz continuity constant on the mapping of the encoder of the VAEs. Finally and most importantly, we discover that the anomalous inputs predominantly tend to land on the vacant latent holes within the compact space, enabling their successful identification. For that reason, we introduce a specifically devised score for hole detection and evaluate the solution against several baseline benchmarks achieving promising results. 
 ID: 443 | SubMix: Learning to Mix Graph Sampling Heuristics   
  
 Sami Abu-El-Haija, Bahare Fatemi, Kyriakos Axiotis, Neslihan Bulut, Johannes Gasteiger, Joshua V. Dillon, Bryan Perozzi, Mohammadhossein Bateni  

  TL;DR:  We develop subgraph sampling procedure that is end-to-end trainable, that we train jointly with graph neural networks.   Abstract:   
 Sampling subgraphs for training Graph Neural Networks (GNNs) is receiving much attention from the GNN community. While a variety of methods have been proposed, each method samples the graph according to its own heuristic. However, there has been little work in mixing these heuristics in an end-to-end trainable manner. In this work, we design a generative framework for graph sampling. Our method, SubMix, parameterizes graph sampling as a convex combination of heuristics. We show that a continuous relaxation of the discrete sampling process allows us to efficiently obtain analytical gradients for training the sampling parameters. Our experimental results illustrate the usefulness of learning graph sampling in three scenarios: (1) robust training of GNNs by automatically learning to discard noisy edge sources; (2) improving model performance by trainable and online edge subset selection; and (3) by integrating our framework into state-of-the-art (SOTA) decoupled GNN models, for homogeneous OGBN datasets. Our method raises the SOTA on challenging ogbn-arxiv and ogbn-products, respectively, by over 4 and 0.5 percentage points. 
 ID: 445 | SPDF: Sparse Pre-training and Dense Fine-tuning for Large Language Models   
  
 Vithursan Thangarasa, Abhay Gupta, William Marshall, Tianda Li, Kevin Leong, Dennis DeCoste, Sean Lie, Shreyas Saxena  

  TL;DR:  We show how pre-training GPT models can be accelerated by using unstructured weight sparsity to reduce the training FLOPs by up to 2.5x, while retaining the benefits of pre-trained textual representations in large language models.   Abstract:   
 The pre-training and fine-tuning paradigm has contributed to a number of breakthroughs in Natural Language Processing (NLP). Instead of directly training on a downstream task, language models are first pre-trained on large datasets with cross-domain knowledge (e.g., Pile, MassiveText, etc.) and then fine-tuned on task-specific data (e.g., natural language generation, text summarization, etc.). Scaling the model and dataset size has helped improve the performance of LLMs, but unfortunately, this also lead to highly prohibitive computational costs. Pre-training LLMs often require orders of magnitude more FLOPs than fine-tuning and the model capacity often remains the same between the two phases. To achieve training efficiency~w.r.t training FLOPs, we propose to decouple the model capacity between the two phases and introduce Sparse Pre-training and Dense Fine-tuning (SPDF). In this work, we show the benefits of using unstructured weight sparsity to train only a subset of weights during pre-training (Sparse Pre-training) and then recover the representational capacity by allowing the zeroed weights to learn (Dense Fine-tuning). We demonstrate that we can induce up to 75\% sparsity into a 1.3B parameter GPT-3 XL model resulting in a 2.5x reduction in pre-training FLOPs, without a significant loss in accuracy on the downstream tasks relative to the dense baseline. By rigorously evaluating multiple downstream tasks, we also establish a relationship between sparsity, task complexity and dataset size. Our work presents a promising direction to train large GPT models at a fraction of the training FLOPs using weight sparsity, while retaining the benefits of pre-trained textual representations for downstream tasks. 
 ID: 447 | Meta-learning Control Variates: Variance Reduction with Limited Data   
 [oral]  
 Zhuo Sun, Chris J. Oates, Francois-Xavier Briol  
   
    [slides]   
   
    Abstract:   
 Control variates can be a powerful tool to reduce the variance of Monte Carlo estimators, but constructing effective control variates can be challenging when the number of samples is small. In this paper, we show that when a large number of related integrals need to be computed, it is possible to leverage the similarity between these integration tasks to improve performance even when the number of samples per task is very small. Our approach, called meta learning CVs (Meta-CVs), can be used for up to hundreds or thousands of tasks. Our empirical assessment indicates that Meta-CVs can lead to significant variance reduction in such settings, and our theoretical analysis establishes general conditions under which Meta-CVs can be successfully trained. 
 ID: 449 | Expectation consistency for calibration of neural networks   
  
 Lucas Clarté, Bruno Loureiro, Florent Krzakala, Lenka Zdeborova  

  TL;DR:  We describe a new method to calibrate the prediction of neural networks, similar to temperature scaling   Abstract:   
 Despite their incredible performance, it is well reported that deep neural networks tend to be overoptimistic about their prediction confidence. Finding effective and efficient calibration methods for neural networks is therefore an important endeavour towards better uncertainty quantification in deep learning. In this manuscript, we introduce a novel calibration technique named expectation consistency (EC), consisting of a post-training rescaling of the last layer weights by enforcing that the average validation confidence coincides with the average proportion of correct labels. First, we show that the EC method achieves similar calibration performance to temperature scaling (TS) across different neural network architectures and data sets, all while requiring similar validation samples and computational resources. However, we argue that EC provides a principled method grounded on a Bayesian optimality principle known as the Nishimori identity. Next, we provide an asymptotic characterization of both TS and EC in a synthetic setting and show that their performance crucially depends on the target function. In particular, we discuss examples where EC significantly outperforms TS. 
 ID: 457 | Correcting for Nonignorable Selection Bias and Missing Response in Regression using Privileged Information   
  
 Philip Boeken, Arnoud De Kroon, Mathijs de Jong, Joris Mooij, Onno Zoeter  

  TL;DR:  We propose a novel imputation based method that uses privileged information for correcting for selection bias or missing response. The method appropriately corrects for bias, and extrapolates better than importance weighted regression.   Abstract:   
 When estimating a regression model, we might have data where some labels are missing, or our data might be biased by a selection mechanism. When the response or selection mechanism is ignorable (i.e., independent of the response variable given the features) one can use off-the-shelf regression methods; in the nonignorable case one typically has to adjust for bias. We observe that privileged data (i.e. data that is only available during training) might render a nonignorable selection mechanism ignorable. We refer to this scenario as Privilegedly Missing at Random (PMAR). We propose a novel imputation-based regression method, named repeated regression, that is suitable for PMAR. We also consider an importance weighted regression method, and a doubly robust combination of the two. The proposed methods are easy to implement with most popular out-of-the-box regression algorithms. We empirically assess the performance of the proposed methods with extensive simulated experiments and on a synthetically augmented real-world dataset. We conclude that repeated regression can appropriately correct for bias, and can have considerable advantage over weighted regression, especially when extrapolating to regions of the feature space where response is never observed. 
 ID: 458 | Mnemonist: Locating Model Parameters that Memorize Training Examples   
  
 Ali Shahin Shamsabadi, Jamie Hayes, Borja Balle, Adrian Weller  

    Abstract:   
 Recent work has shown that an adversary can reconstruct training examples given access to the parameters of a deep learning image classification model. We show that the quality of reconstruction depends heavily on the type of activation functions used. In particular, we show that ReLU activations lead to much lower quality reconstructions compared to smooth activation functions. We explore if this phenomenon is a fundamental property of models with ReLU activations, or if it is a weakness of current attack strategies. We first study the training dynamics of models with ReLU activations and identify redundant model parameters that do not memorise training examples. Building on this, we propose our Mnemonist method, which is able to detect redundant model parameters, and then guide current attacks to focus on informative parameters to improve the quality of reconstructions of training examples from ReLU models. 
 ID: 460 | Logit-Based Ensemble Distribution Distillation for Robust Autoregressive Sequence Uncertainties   
  
 Yassir Fathullah, Guoxuan Xia, Mark Gales  

  TL;DR:  Propose to distribution distill an autoregressive ensemble using a student Laplace distribution   Abstract:   
 Efficiently and reliably estimating uncertainty is an important objective in deep learning. It is especially pertinent to autoregressive sequence tasks, where training and inference costs are typically very high. However, existing research has predominantly focused on tasks with static data such as image classification. In this work, we investigate Ensemble Distribution Distillation (EDD) applied to large-scale natural language sequence-to-sequence data. EDD aims to compress the superior uncertainty performance of an expensive (teacher) ensemble into a cheaper (student) single model. Importantly, the ability to separate knowledge (epistemic) and data (aleatoric) uncertainty is retained. Existing probability-space approaches to EDD, however, are difficult to scale to large vocabularies. We show, for modern transformer architectures on large-scale translation tasks, that modelling the ensemble \textit{logits}, instead of softmax probabilities, leads to significantly better students. Moreover, the students surprisingly even \textit{outperform Deep Ensembles} by up to $\sim$10\% AUROC on out-of-distribution detection, whilst matching them at in-distribution translation. 
 ID: 462 | Bandits with Costly Reward Observations   
  
 Aaron David Tucker, Caleb Biddulph, Claire Wang, Thorsten Joachims  

  TL;DR:  We provide algorithms, a regret lower bound, and experiments (synthetic and real data) for bandit problems where you need to pay a cost to observe the reward.   Abstract:   
 Many machine learning applications rely on large datasets that are conveniently collected from existing sources or that are labeled automatically as a by-product of user actions. However, in settings such as content moderation, accurately and reliably labeled data comes at substantial cost. If a learning algorithm has to pay for reward information, for example by asking a human for feedback, how does this change the exploration/exploitation tradeoff? We study this question in the context of bandit learning. Specifically, we investigate Bandits with Costly Reward Observations, where a cost needs to be paid in order to observe the reward of the bandit's action. We show that the observation cost implies an $\Omega(c^{1/3}T^{2/3})$ lower bound on the regret. Furthermore, we develop a general non-adaptive bandit algorithm which matches this lower bound, and we present several competitive adaptive learning algorithms for both k-armed and contextual bandits. 
 ID: 465 | Graph Classification Gaussian Processes via Spectral Features   
  
 Felix Opolka, Yin-Cong Zhi, Pietro Lio, Xiaowen Dong  
   
    [link to video]   
   
  TL;DR:  Combining Gaussian processes with spectral features of attributed graphs leads to surprisingly strong performance for the task of graph classification.   Abstract:   
 Graph classification aims to categorise graphs based on their structure and node attributes. In this work, we propose to tackle this task using tools from graph signal processing by deriving spectral features within the framework of Bayesian modelling with Gaussian processes. We present two variants of spectral Gaussian processes for graph classification. The first variant uses spectral features based on the distribution of energy of a node feature signal over the spectrum of the graph. We show that even such a simple approach, having no learnt parameters, can yield competitive performance compared to strong neural network and graph kernel baselines. A second, more sophisticated variant is designed to capture multi-scale and localised patterns in the graph by learning spectral graph wavelet filters, obtaining improved performance on synthetic and real-world data sets. Finally, we show that both models produce well calibrated uncertainty estimates, enabling reliable decision making based on the model predictions. 
 ID: 466 | Provably Efficient Representation Selection in Low-rank Markov Decision Processes: From Online to Offline RL   
  
 Weitong Zhang, Jiafan He, Dongruo Zhou, Amy Zhang, Quanquan Gu  

    Abstract:   
 The success of deep reinforcement learning (DRL) lies in its ability to learn a representation that is well-suited for the exploration and exploitation task. To understand how the choice of representation can improve the efficiency of reinforcement learning (RL), we study representation selection for a class of low-rank Markov Decision Processes (MDPs) where the transition kernel can be represented in a bilinear form. We propose an efficient algorithm, called ReLEX, for representation learning in both online and offline RL. Specifically, we show that the online version of ReLEX, calledReLEX-UCB, always performs no worse than the state-of-the-art algorithm without representation selection, and achieves a strictly better constant regret if the representation function class has a "coverage" property over the entire state-action space. For the offline counterpart, ReLEX-LCB, we show that the algorithm can find the optimal policy if the representation class can cover the state-action space and achieves gap-dependent sample complexity. This is the first result with constant sample complexity for representation learning in offline RL. 
 ID: 467 | Deep Gaussian Mixture Ensembles   
  
 Yousef El-Laham, Niccolo Dalmasso, Elizabeth Fons, Svitlana Vyetrenko  

    Abstract:   
 This work introduces a novel probabilistic deep learning technique called deep Gaussian mixture ensembles (DGMEs), which enables accurate quantification of both epistemic and aleatoric uncertainty. By assuming the data generating process follows that of a Gaussian mixture, DGMEs are capable of approximating complex probability distributions, such as heavy tailed or multimodal distributions. Our contributions include the derivation of an expectation-maximization (EM) algorithm used for learning the model parameters, which results in an upper-bound on the log-likelihood of training data over that of standard deep ensembles. Additionally, the proposed EM training procedure allows for learning of mixture weights, which is not commonly done in ensembles. Our experimental results demonstrate that DGMEs outperform state-of-the-art uncertainty quantifying deep learning models in handling complex predictive densities. 
 ID: 470 | Gaussian Process Surrogate Models for Neural Networks   
  
 Michael Y. Li, Erin Grant, Thomas L. Griffiths  

  TL;DR:  Interpretability and model selection for neural networks by learning a Gaussian process surrogate model for a neural network hyperparameter configuration.   Abstract:   
 Not being able to understand and predict the behavior of deep learning systems makes it hard to decide what architecture and algorithm to use for a given problem. In science and engineering, modeling is a methodology used to understand complex systems whose internal processes are opaque. Modeling replaces a complex system with a simpler surrogate that is more interpretable. Drawing inspiration from this, we construct a class of surrogate models for neural networks using Gaussian processes. Rather than deriving kernels for infinite neural networks, we learn kernels empirically from the naturalistic behavior of finite neural networks. We demonstrate our approach captures existing phenomena related to the spectral bias of neural networks, and then show that our surrogate models can be used to solve practical problems such as identifying which points most influence the behavior of specific neural networks and predicting which architectures and algorithms will generalize well for specific datasets. 
 ID: 472 | Residual-Based Error Bound for Physics-Informed Neural Networks   
 [spotlight]  
 Shuheng Liu, Xiyue Huang, Pavlos Protopapas  

  TL;DR:  We propose algorithms to bound error of any PINN solution to linear ODEs, certain nonlinear ODEs, and first-order linear PDEs. Only residual information and equation structure are required. No network architecture assumptions needed.   Abstract:   
 Neural networks are universal approximators and are studied for their use in solving differential equations. However, a major criticism is the lack of error bounds for obtained solutions. This paper proposes a technique to rigorously evaluate the error bound of Physics-Informed Neural Networks (PINNs) on most linear ordinary differential equations (ODEs), certain nonlinear ODEs, and first-order linear partial differential equations (PDEs). The error bound is based purely on equation structure and residual information and does not depend on assumptions of how well the networks are trained. We propose algorithms that bound the error efficiently. Some proposed algorithms provide tighter bounds than others at the cost of longer run time. 
 ID: 476 | Causal Inference With Outcome-Dependent Missingness And Self-Censoring   
 [spotlight]  
 Jacob Morris Chen, Daniel Malinsky, Rohit Bhattacharya  

  TL;DR:  We propose a method to estimate causal effects under outcome-dependent self-censoring and when the full structure of the causal graph is unknown.   Abstract:   
 We consider missingness in the context of causal inference when the outcome of interest may be missing. If the outcome directly affects its own missingness status, i.e., it is "self-censoring", this may lead to severely biased causal effect estimates. Miao et al., [2015] proposed the shadow variable method to correct for bias due to self-censoring, however, verifying the required model assumptions can be difficult. Here, we propose a test based on a randomized incentive variable offered to encourage reporting of the outcome that can be used to verify identification assumptions that are sufficient to correct for both self-censoring and confounding bias. Concretely, the test confirms whether a given set of pre-treatment covariates are sufficient to block all backdoor paths between the treatment and outcome as well as all paths between the treatment and missinginess indicator after conditioning on the outcome. We show that under these conditions, the causal effect is identified by using the treatment as a shadow variable, and it leads to an intuitive inverse probability weighting estimator that uses a product of the treatment and response weights. We evaluate the efficacy of our test and downstream estimator via simulations. 
 ID: 477 | Double Penalty Integration Estimator for Combining Randomized Experiments and Historical Controls   
  
 Yuwen Cheng, Lili Wu, Shu Yang  
   
    [link to video]   
   
    Abstract:   
 Randomized experiments (REs) are the cornerstone for treatment effect evaluation. However, due to the practical considerations, REs may encounter difficulty recruiting sufficient patients. Historical controls (HCs) may supplement REs to boost estimation efficiency. Yet, it is possible that there is incomparability between HCs and CCs, resulting in misleading treatment effect evaluation. We introduce a new bias function to measure the difference between the outcome mean function between HCs and REs. We show that the ANCOVA model augmented the bias function for HCs renders a consistent estimator of the average treatment effect, regardless whether the ANCOVA model is correct or not. To accommodate possibly different structure of the ANCOVA model and the bias function, we propose a double penalty integration estimator (DPIE) with different penalization terms for the two functions. With an appropriate choice of penalty parameters, our DPIE ensures consistency, oracle property, and asymptotic normality even in the presence of model misspecification. DPIE is at least as efficient as the estimator derived from REs alone, which is validated through both theoretical and experimental results. 
 ID: 480 | Investigating a Generalization of Probabilistic Material Implication and Bayesian Conditional   
 [spotlight]  
 Matthias Scheutz, Michael Jahn  

  TL;DR:  We investigate properties of a generalized rule that subsumes probabilistic material implication and Bayesian conditionals as special cases.   Abstract:   
 Probabilistic "if A then B" rules are typically formalized as Bayesian conditionals P(B|A), as many (e.g., Pearl) have argued that Bayesian conditionals are the correct way to think about such rules. However, there are challenges with standard inferences such as modus ponens and modus tollens that might make probabilistic material implication a better candidate at times for rule-based systems employing forward-chaining; and arguably material implication is still suitable when information about prior or conditional probabilities is not available at all. We investigate a generalization of probabilistic material implication and Bayesian conditionals that combines the advantages of both formalisms in a systematic way and prove basic properties of the generalized rule, in particular, for inference chains in graphs. 
 ID: 482 | Is the Volume of a Credal Set a Good Measure for Epistemic Uncertainty?   
 [oral]  
 Yusuf Sale, Michele Caprio, Eyke Hüllermeier  
   
    [link to video]  [slides]   
   
  TL;DR:  We show that the volume of a credal set is a good measure for epistemic uncertainty in a binary classification setting, while it ceases to be so in multi-class setting.   Abstract:   
 Adequate uncertainty representation and quantification have become imperative in various scientific disciplines, especially in machine learning and artificial intelligence. As an alternative to representing uncertainty via one single probability measure, we consider credal sets (convex sets of probability measures). The geometric representation of credal sets as $d$-dimensional polytopes implies a geometric intuition about (epistemic) uncertainty. In this paper, we show that in the case of binary classification, the volume of the geometric representation of a credal set is a good measure of epistemic uncertainty, while for multi-class classification it ceases to be appealing. Our theoretical findings highlight the crucial role of specifying and employing appropriate measures of uncertainty in machine learning tasks and generally call for awareness of possible pitfalls. 
 ID: 486 | Functional Causal Bayesian Optimization   
 [oral]  
 Limor Gultchin, Virginia Aglietti, Alexis Bellot, Silvia Chiappa  
   
    [slides]   
   
  TL;DR:  We propose the functional causal Bayesian optimization method for finding functional interventions that optimize a target variable in a known causal graph.   Abstract:   
 We propose the functional causal Bayesian optimization method (fCBO) for finding interventions that optimize a target variable in a known causal graph. fCBO extends CBO to perform, in addition to hard interventions, functional interventions which consist in setting a variable to be a deterministic function of a set of other variables in the graph. This is achieved by modelling the unknown objective with Gaussian processes whose inputs are defined in a reproducing kernel Hilbert space, thus allowing to compute distances among vector-valued functions. In turn, this enables to sequentially select functions to explore by maximizing an expected improvement acquisition functional while keeping the typical computational tractability of standard BO settings. We show that functional interventions can attain better target effects compared to hard interventions and ensure that the found optimal policy is also optimal for sub-groups. We demonstrate the benefits of the method in a synthetic setting and in a real-world causal graph. 
 ID: 494 | Uniform-PAC Guarantees for Model-Based RL with Bounded Eluder Dimension   
  
 Yue Wu, Jiafan He, Quanquan Gu  

  TL;DR:  We propose uniform-PAC, model-based algorithms for both bandit and episodic RL with the notion of eluder dimension.   Abstract:   
 Recently, there has been remarkable progress in reinforcement learning (RL) with general function approximation. However, all these works only provide regret or sample complexity guarantees. It is still an open question if one can achieve stronger performance guarantees, i.e., the uniform probably approximate correctness (Uniform-PAC) guarantee that can imply both a sub-linear regret bound and a polynomial sample complexity for any target learning accuracy. We study this problem by proposing algorithms for both nonlinear bandits and model-based episodic RL using the general function class with a bounded eluder dimension. The key idea of the proposed algorithms is to assign each action to different levels according to its width with respect to the confidence set. The achieved uniform-PAC sample complexity is tight in the sense that it matches the state-of-the-art regret bounds or sample complexity guarantees when reduced to the linear case. To the best of our knowledge, this is the first work for uniform-PAC guarantees on bandit and RL that goes beyond linear cases. 
 ID: 495 | Pandering in a (Flexible) Representative Democracy   
  
 Xiaolin Sun, Jacob Masur, Ben Abramowitz, Nicholas Mattei, Zizhan Zheng  

  TL;DR:  We formalize and study a novel model of election attack, pandering, where candidates report their positions strategically and study the complexity of and algorithms for reasoning in this domain.   Abstract:   
 In representative democracies, the election of new representatives in regular election cycles is meant to prevent misbehavior by elected officials and keep them accountable to the ``will of the people." This ideal is undermined when candidates are dishonest when campaigning for election over these rounds. Much of the work on COMSOC to date has investigated strategic actions in only a single round. We introduce a novel formal model of pandering, or strategic preference reporting by candidates, and examine the resilience of two voting systems, Representative Democracy (RD) and Flexible Representative Democracy (FRD), to pandering within a single round and across multiple rounds. For each voting system, our analysis centers on the types of strategies candidates employ and how voters update their views of candidates based on how the candidates have pandered in the past. We provide theoretical results on the complexity of pandering in our setting for a single cycle, formulate our problem for multiple cycles as a Markov Decision Process, and use reinforcement learning to study the effects of pandering by both single candidates and groups of candidates across a number of rounds. 
 ID: 496 | Sample Boosting Algorithm (SamBA) - An Interpretable Greedy Ensemble Classifier Based On Local Expertise For Fat Data   
  
 Baptiste Bauvin, Cécile Capponi, Florence Clerc, Pascal Germain, Sokol Koço, Jacques Corbeil  

  TL;DR:  We porpose a framewok and an algorithm to include local knowledge in boosting, with thoeretical and experiemental guarantees.   Abstract:   
 Ensemble methods are a very diverse family of algorithms with a wide range of applications. One of the most commonly used is boosting, with the prominent Adaboost. Adaboost relies on greedily learning base classifiers that rectify the error from previous iteration. Then, it combines them through a weighted majority vote, based on their quality on the learning set. In this paper, we propose a supervised binary classification framework that propagates the local knowledge acquired during the boosting iterations to the prediction function. Based on this general framework, we introduce SamBA, an interpretable greedy ensemble method designed for fat datasets with a large number of dimensions and a small number of samples. SamBA learns local classifiers and combines them, using a similarity function, to optimize its efficiency in data extraction. We provide a theoretical analysis of SamBA, yielding convergence and generalization guarantees. In addition, we highlight SamBA's empirical behavior in an extensive experimental analysis on both real biological and generated datasets, comparing it to state-of-the-art ensemble methods and similarity-based approaches. 
 ID: 499 | Hallucinated Adversarial Control for Conservative Offline Policy Evaluation   
  
 Jonas Rothfuss, Bhavya Sukhija, Tobias Birchler, Parnian Kassraie, Andreas Krause  

  TL;DR:  A practical method for conservative off-policy evaluation, useful for safety critical applications.   Abstract:   
 We study the problem of conservative off-policy evaluation (COPE) where given an offline dataset of environment interactions, collected by other agents, we seek to obtain a (tight) lower bound on a policy's performance. This is crucial when deciding whether a given policy satisfies certain minimal performance/safety criteria before it can be deployed in the real world. To this end, we introduce HAMBO, which builds on an uncertainty-aware learned model of the transition dynamics. To form a conservative estimate of the policy's performance, HAMBO hallucinates worst-case trajectories that the policy may take, within the margin of the models' epistemic confidence regions. We prove that the resulting COPE estimates are valid lower bounds, and, under regularity conditions, show their convergence to the true expected return. Finally, we discuss scalable variants of our approach based on Bayesian Neural Networks and empirically demonstrate that they yield reliable and tight lower bounds in various continuous control environments. 
 ID: 500 | The Past Does Matter: Correlation of Subsequent States in Trajectory Predictions of Gaussian Process Models   
  
 Steffen Ridderbusch, Sina Ober-Blöbaum, Paul James Goulart  

  TL;DR:  Predicting trajectories with uncertainty is challenging and we show an approximate way to do it while including correlation with past states.   Abstract:   
 Computing the distribution of trajectories from a Gaussian Process model of a dynamical system is an important challenge in utilizing such models. Motivated by the computational cost of sampling-based approaches, we consider approximations of the model's output and trajectory distribution. We show that previous work on uncertainty propagation, focussed on discrete state-space models, incorrectly included an independence assumption between subsequent states of the predicted trajectories. Expanding these ideas to continuous ordinary differential equation models, we illustrate the implications of this assumption and propose a novel piecewise linear approximation of Gaussian Processes to mitigate them. 
 ID: 503 | Two Sides of Mis-Calibration: Identifying Over and Under-Confidence Prediction for Network Calibration   
  
 Shuang Ao, Stefan Rueger, Advaith Siddharthan  
   
    [link to video]   
   
  TL;DR:  We address the necessity of paying attention to the under-confidence issue   Abstract:   
 Proper confidence calibration of deep neural networks is essential in safety-critical tasks for reliable predictions. Miscalibration can lead to model over-confidence and/or under-confidence; i.e., the predicted confidence can be greater or less than model accuracy. Recent studies have highlighted the over-confidence issue by introducing calibration techniques and demonstrated success on various tasks. However, miscalibration through under-confidence has not yet to receive much attention. In this paper, we address the necessity of paying attention to the under-confidence issue. We first introduce a novel metric, a miscalibration score, to identify the overall and class-wise calibration status, including being over or under-confident. Our proposed metric reveals the pitfalls of existing calibration techniques, where they often overly calibrate the model and worsen under-confident predictions. Then we utilize the class-wise miscalibration score as a proxy to design a calibration technique that can tackle both over and under-confidence. We report extensive experiments that show that our proposed methods substantially outperform existing calibration techniques. We also validate the automatic failure detection of the proposed calibration technique using our class-wise miscalibration score with a risk-coverage curve. Results show that our methods significantly improve failure detection as well as trustworthiness of the model. 
 ID: 504 | Establishing Markov Equivalence in Cyclic Directed Graphs   
 [oral]  
 Tom Claassen, Joris Mooij  
   
    [slides]   
   
  TL;DR:  A new ancestral perspective on the Cyclic Equivalence Theorem leads to a simplified and much faster procedure to decide on Markov equivalence between directed cyclic graphs.   Abstract:   
 We present a new, efficient procedure to establish Markov equivalence between directed graphs that may or may not contain cycles. It is based on the Cyclic Equivalence Theorem (CET) in the seminal works on cyclic models by Thomas Richardson in the mid '90s, but now rephrased from an ancestral perspective. The resulting characterization leads to a procedure for establishing Markov equivalence between graphs that no longer requires explicit tests for \textit{d}-separation, leading to a significantly reduced algorithmic complexity. The conceptually simplified characterization may help to reinvigorate theoretical research towards sound and complete cyclic discovery in the presence of latent confounders. 
 ID: 505 | ASTRA: Understanding the Practical Impact of Robustness for Probabilistic Programs   
  
 Zixin Huang, Saikat Dutta, Sasa Misailovic  

    Abstract:   
 We present the first systematic study of effectiveness of robustness transformations on a diverse set of 24 probabilistic programs representing generalized linear models, mixture models, and time-series models. We evaluate five robustness transformations from literature on each model. We quantify and present insights on (1) the improvement of the posterior prediction accuracy and (2) the execution time overhead of the robustified programs, in the presence of three input noise models. To automate the evaluation of various robustness transformations, we developed ASTRA ‚Äì a novel framework for quantifying the robustness of probabilistic programs and exploring the trade-offs between robustness and execution time. Our experimental results indicate that the existing transformations are often suitable only for specific noise models, can significantly increase execution time, and have non-trivial interaction with the inference algorithms. 
 ID: 507 | Towards Better Certified Segmentation via Diffusion Models   
  
 Othmane Laousy, Alexandre Araujo, Guillaume Chassagnon, Marie-Pierre Revel, Siddharth Garg, Farshad Khorrami, Maria Vakalopoulou  

  TL;DR:  Better certified segmentation leveraging randomized smoothing as well as off-the-shelf denoising diffusion and segmentation models.   Abstract:   
 The robustness of image segmentation has been an important research topic in the past few years as segmentation models have reached production-level accuracy. However, like classification models, segmentation models can be vulnerable to adversarial perturbations, which hinders their use in critical-decision systems like healthcare or autonomous driving. Recently, randomized smoothing has been proposed to certify segmentation predictions by adding Gaussian noise to the input to obtain theoretical guarantees. Nonetheless, this method exhibits a trade-off between the amount of added noise and the level of certification achieved. In this paper, we address the problem of certifying segmentation prediction using a combination of randomized smoothing and diffusion models. Our experiments show that combining randomized smoothing and diffusion models significantly improves certified robustness, with results indicating a mean improvement of 21 points in accuracy compared to previous state-of-the-art methods on Pascal-Context and Cityscapes public datasets. Our method is independent of the selected segmentation model and does not need any additional specialized training procedure. Our pipeline and code will be made publicly available online. 
 ID: 516 | CUE: An Uncertainty Interpretation Framework for Text Classifiers Built on Pre-Trained Language Models   
 [spotlight]  
 Jiazheng Li, ZHAOYUE SUN, Bin Liang, Lin Gui, Yulan He  
   
    [link to video]   
   
    Abstract:   
 Text classifiers built on Pre-trained Language Models (PLMs) have achieved remarkable progress in various tasks including sentiment analysis, natural language inference, and question-answering. However, these text classifiers sometimes make uncertain predictions, which challenges their trustworthiness during deployment in practical applications. Much effort has been devoted to designing various probes in order to understand what PLMs capture. But few works have explored factors influencing PLM-based classifiers' predictive uncertainty. In this paper, we propose a novel framework CUE for interpreting uncertainties of PLM-based models' predictions. In particular, we first map PLM-encoded representations to a latent space via a variational auto-encoder. We then generate text representations by perturbing the latent space which causes fluctuation in predictive uncertainty. By comparing the predictive uncertainty difference between the perturbed text representation and the original text representation, we are able to identify the latent dimensions that cause uncertainty and thus trace back to input features that lead to uncertainty. Our extensive experiments on four benchmark datasets for linguistic acceptability classification, emotion classification, and natural language inference show the feasibility of our proposed framework. 
 ID: 517 | On Minimizing the Impact of Dataset Shifts on Actionable Explanations   
 [oral]  
 Anna P. Meyer, Dan Ley, Suraj Srinivas, Himabindu Lakkaraju  
   
    [slides]   
   
    Abstract:   
 The Right to Explanation is an important regulatory principle which allows individuals to request actionable explanations for algorithmic decisions. However, several technical challenges arise when providing such actionable explanations in practice. For instance, models are periodically retrained to handle dataset shifts, and this may in turn invalidate some of the previously prescribed explanations thus rendering them unactionable. But, it is unclear if and when such invalidations occur, and what factors determine explanation stability i.e., if an explanation remains unchanged amidst model retraining due to dataset shifts. In this paper, we address the aforementioned gaps and provide one of the first theoretical and empirical characterizations of the factors influencing explanation stability. To this end, we conduct rigorous theoretical analysis to demonstrate that model curvature and robustness, weight decay parameters, and the magnitude of the dataset shift are key factors that determine the extent of explanation (in)stability. Extensive experimentation with real-world datasets not only validates our theoretical results, but also demonstrates that the aforementioned factors dramatically impact the stability of explanations produced by various state-of-the-art methods. 
 ID: 520 | Improvable Gap Balancing for Multi-Task Learning   
  
 Yanqi Dai, Nanyi Fei, Zhiwu Lu  

  TL;DR:  We propose two novel improvable gap balancing algorithms for multi-task learning, instead of the classic loss balancing strategy.   Abstract:   
 In multi-task learning (MTL), gradient balancing has recently attracted more research interest than loss balancing since it often leads to better performance. However, loss balancing is much more efficient than gradient balancing, and thus it is still worth further exploration in MTL. Note that prior studies typically ignore that there exist varying improvable gaps across multiple tasks, where the improvable gap per task is defined as the distance between the current training progress and desired final training progress. Therefore, after loss balancing, the performance imbalance still arises in many cases. In this paper, following the loss balancing framework, we propose two novel improvable gap balancing (IGB) algorithms for MTL: one takes a simple heuristic, and the other (for the first time) deploys deep reinforcement learning for MTL. Particularly, instead of directly balancing the losses in MTL, both algorithms choose to dynamically assign task weights for improvable gap balancing. Moreover, since IGB is shown to be complementary to gradient balancing, we also provide a fusion paradigm to combine both loss balancing and gradient balancing for MTL. Extensive experiments on two benchmark datasets demonstrate that our IGB algorithms lead to the best results in MTL via loss balancing and achieve further improvements when combined with gradient balancing. 
 ID: 521 | Causal Information Splitting: Engineering Proxy Features for Robustness to Distribution Shifts   
  
 Bijan Mazaheri, Atalanti A. Mastakouri, Dominik Janzing, Michaela Hardt  
   
    [link to video]   
   
  TL;DR:  Causal perspectives to distribution shift robustness break down when we only have proxies for the causal model, but training auxiliary tasks can help.   Abstract:   
 Statistical prediction models are often trained on data that is drawn from different probability distributions than their eventual use cases. One approach to proactively prepare for these shifts harnesses the intuition that causal mechanisms should remain invariant between environments. Here we focus on a challenging setting in which the causal and anticausal variables of the target are unobserved. Leaning on information theory, we develop feature selection and engineering techniques for the observed downstream variables that act as proxies. We identify proxies that help to build stable models and moreover utilize auxiliary training tasks to extract stability-enhancing information from proxies. We demonstrate the effectiveness of our techniques on synthetic and real data. 
 ID: 524 | A One-Sample Decentralized Proximal Algorithm for Non-Convex Stochastic Composite Optimization   
  
 Tesi Xiao, Xuxing Chen, Krishna Balasubramanian, Saeed Ghadimi  

    Abstract:   
 We focus on decentralized stochastic non-convex optimization, where $n$ agents work together to optimize a composite objective function which is a sum of a smooth term and a non-smooth convex term. To solve this problem, we propose two single-time scale algorithms: Prox-DASA and Prox-DASA-GT. These algorithms can find $\epsilon$-stationary points in $\mathcal{O}(n^{-1}\epsilon^{-2})$ iterations using constant batch sizes (i.e., $\mathcal{O}(1)$). Unlike prior work, our algorithms achieve a comparable complexity result without requiring large batch sizes, more complex per-iteration operations (such as double loops), or stronger assumptions. Our theoretical findings are supported by extensive numerical experiments, which demonstrate the superiority of our algorithms over previous approaches. 
 ID: 526 | Probabilistic Flow Circuits: Towards Unified Deep Models for Tractable Probabilistic Inference   
 [oral]  
 Sahil Sidheekh, Kristian Kersting, Sriraam Natarajan  
   
    [slides]   
   
  TL;DR:  A principled approach to building expressive and tractable generative models by integrating normalizing flows with probabilistic circuits.   Abstract:   
 We consider the problem of increasing the expressivity of probabilistic circuits by augmenting them with the successful generative models of normalizing flows. To this effect, we theoretically establish the requirement of decomposability for such combinations to retain tractability of the learned models. Our model, called Probabilistic Flow Circuits, essentially extends circuits by allowing for normalizing flows at the leaves. Our empirical evaluation clearly establishes the expressivity and tractability of this new class of probabilistic circuits. 
 ID: 527 | A Data-Driven State Aggregation Approach for Dynamic Discrete Choice Models   
  
 Sinong Geng, houssam nassif, Charlie Manzanares  

    Abstract:   
 We study dynamic discrete choice models, where a commonly studied problem involves estimating parameters of agent reward functions (also known as "structural" parameters), using agent behavior data. Maximum likelihood estimation for such models requires dynamic programming, which incurs the curse of dimensionality [Bellman, 1957]. In this work, we present a novel algorithm that provides a data-driven method for selecting and aggregating states, which lowers the computational and sample complexity of estimation. Our method works in two stages. In the first stage, we use a flexible inverse reinforcement learning approach to estimate agent Q-functions. We use these estimated Q-functions, along with a clustering algorithm, to select a subset of states that are the most pivotal for driving changes in Q functions. In the second stage, with these selected "aggregated" states, we conduct maximum likelihood estimation using a commonly used nested fixed-point algorithm [Rust, 1987]. The proposed two-stage approach mitigates the curse of dimensionality by reducing the problem dimension. Theoretically, we derive finite-sample bounds on the associated estimation error, which also characterize the trade-off of computational complexity, estimation error, and sample complexity. We demonstrate the empirical performance of the algorithm in two classic dynamic discrete choice estimation applications. 
 ID: 529 | Probabilistically Robust Conformal Prediction   
  
 SUBHANKAR GHOSH, Yuanjie Shi, Taha Belkhouja, Yan Yan, Jana Doppa, Brian Jones  
   
    [link to video]   
   
  TL;DR:  A theoretically-sound algorithm for probabilistically robust conformal prediction which ensures robust uncertainty quantification to most perturbations around clean input examples.   Abstract:   
 Conformal prediction (CP) is a framework to quantify uncertainty of machine learning classifiers including deep neural networks. Given a testing example and a trained classifier, CP produces a prediction set of candidate labels with a user-specified coverage (i.e., true class label is contained with high probability). Almost all the existing work on CP assumes clean testing data and there is not much known about the robustness of CP algorithms w.r.t natural/adversarial perturbations to testing examples. This paper studies the problem of probabilistically robust conformal prediction (PRCP) which ensures robustness to most perturbations around clean input examples. PRCP generalizes the standard CP (cannot handle perturbations) and adversarially robust CP (ensures robustness w.r.t worst-case perturbations) to achieve better trade-offs between nominal performance and robustness. We propose a novel adaptive PRCP (aPRCP) algorithm to achieve probabilistically robust coverage. The key idea behind aPRCP is to determine two parallel thresholds, one for data samples and another one for the perturbations on data (aka "quantile-of-quantile'' design). We provide theoretical analysis to show that aPRCP algorithm achieves robust coverage. Our experiments on CIFAR-10, CIFAR-100, and ImageNet datasets using deep neural networks demonstrate that aPRCP achieves better trade-offs than state-of-the-art CP and adversarially robust CP algorithms. 
 ID: 530 | Maximizing Submodular Functions under Submodular Constraints   
  
 Madhavan Rajagopal Padmanabhan, Yanhui Zhu, Samik Basu, A. Pavan  
   
    [link to video]   
   
    Abstract:   
 We consider the problem of maximizing submodular functions under submodular constraints by formulating the problem in two ways: SCSK-C and Diff-C. Given two submodular functions $f$ and $g$ where $f$ is monotone, the objective of SCSK-C problem is to find a set $S$ of size at most $k$ that maximizes $f(S)$ under the constraint that $g(S)\leq \theta$, for a given value of $\theta$. The problem of Diff-C focuses on finding a set $S$ of size at most $k$ such that $h(S) = f(S)-g(S)$ is maximized. It is known that these problems are highly inapproximable and do not admit any constant factor multiplicative approximation algorithms unless NP is easy. Known approximation algorithms involve data-dependent approximation factors that are not efficiently computable. We initiate a study of the design of approximation algorithms where the approximation factors are efficiently computable. For the problem of SCSK-C, we prove that the greedy algorithm produces a solution whose value is at least $(1-1/e)f(OPT) - A$, where $A$ is the data-dependent additive error. For the Diff-C problem, we design an algorithm that uses the SCSK-C greedy algorithm as a subroutine. This algorithm produces a solution whose value is at least $(1-1/e)h(OPT)-B$, where $B$ is also a data-dependent additive error. A salient feature of our approach is that the additive error terms can be computed efficiently, thus enabling us to ascertain the quality of the solutions produced. 
 ID: 531 | Two-phase Attacks in Security Games   
  
 Andrzej Nagorko, Pawe≈Ç Ciosmak, Tomasz Pawel Michalak  

  TL;DR:  We propose a version of a security game that takes into account a possibility of a two-phase attack.   Abstract:   
 A standard model of a security game assumes a one-off assault during which the attacker cannot update their strategy even if new actionable insights are gained in the process. In this paper, we propose a version of a security game that takes into account a possibility of a two-phase attack. Specifically, in the first phase, the attacker makes a preliminary move to gain extra information about this particular instance of the game. Based on this information, the attacker chooses an optimal concluding move. We derive a compact-form mixed-integer linear program that computes an optimal strategy of the defender. Our simulation shows that this strategy mitigates serious losses incurred to the defender by a two-phase attack while still protecting well against less sophisticated attackers. 
 ID: 536 | Bounding the Optimal Value Function in Compositional Reinforcement Learning   
  
 Jacob Adamczyk, Volodymyr Makarenko, Argenis Arriojas, Stas Tiomkin, Rahul V Kulkarni  

  TL;DR:  We derive double-sided bounds on the optimal value function for compositions of primitive tasks.   Abstract:   
 In the field of reinforcement learning (RL), agents are often tasked with solving a variety of problems differing only in their reward functions. In order to quickly obtain solutions to unseen problems with new reward functions, a popular approach involves functional composition of previously solved tasks. However, previous work using such functional composition has primarily focused on specific instances of composition functions, whose limiting assumptions allow for exact zero-shot composition. Our work unifies these examples and provides a more general framework for compositionality in both standard and entropy-regularized RL. We find that, for a broad class of functions, the optimal solution for the composite task of interest can be related to the known primitive task solutions. Specifically, we present double-sided inequalities relating the optimal composite value function to the value functions for the primitive tasks. We also show that the regret of using a zero-shot policy can be bounded for this class of functions. The derived bounds can be used to develop clipping approaches for reducing uncertainty during training, allowing agents to quickly adapt to new tasks. 
 ID: 537 | Finite-sample Guarantees for Nash Q-learning with Linear Function Approximation   
  
 Pedro Cisneros-Velarde, Oluwasanmi O Koyejo  

    Abstract:   
 Nash Q-learning may be considered one of the first and most known algorithms in multi-agent reinforcement learning (MARL) for learning policies that constitute a Nash equilibrium of an underlying general-sum Markov game. Its original proof was in the asymptotic domain and for the tabular case. Recently, finite-sample guarantees have been provided using more modern RL techniques for the tabular case. Our work analyzes Nash Q-learning using linear function approximation ‚Äì a representation regime introduced when the state space is large or continuous ‚Äì and provides finite-sample guarantees that indicate its sample efficiency. We find that the obtained performance nearly matches an existing efficient result for single-agent RL under the same representation and has a polynomial gap when compared to the best-known result for the tabular case. 
 ID: 540 | Bayesian Inference for Vertex-Series-Parallel Partial Orders   
  
 Chuxuan Jiang, Geoff Keith Nicholls, Kate Lee  
   
    [link to video]   
   
  TL;DR:  This is the first work performing Bayesian inference on vertex-series-parallel partial orders (VSP's). We propose a prior over VSP's and extend an existing observation model for queue-like noisy rank data.   Abstract:   
 Partial orders are a natural model for the social hierarchies that may constrain ``queue-like'' rank data. However, the computational cost of counting the LE's of a general partial order on a ground set with more than a few tens of elements is prohibitive. Vertex-series-parallel partial orders (VSP's) are a subclass of partial orders which admit rapid counting and represent the sorts of relations we expect to see in a social hierarchy. However, no Bayesian analysis of VSP's has been given to date. We construct a marginally consistent family of priors over VSP's with a parameter controlling the prior distribution over VSP depth. The distribution function is given in closed form. We extend an existing observation model for queue-like rank data to represent noise in our list-data and carry out Bayesian inference on rank lists from ``Royal Acta'' data. Model comparison shows our model is a better fit to the data and also compares favorably with a Plackett-Luce mixture. 
 ID: 541 | A Near-optimal High-probability Swap-Regret Upper Bound for Multi-agent Bandits in Unknown General-sum Games   
  
 ZHIMING HUANG, jianping pan  
   
    [link to video]   
   
  TL;DR:  We prove a high-probability bound for the instantaneous swap regret with respect to the randmoness of both learner and adversaries.   Abstract:   
 In this paper, we study a multi-agent bandit problem in an unknown general-sum game repeated for a number of rounds~(i.e., learning in a black-box game with bandit feedback), where a set of agents have no information about the underlying game structure and cannot observe each other's actions and rewards. In each round, each agent needs to play an arm~(i.e., action) from a (possibly different) arm set~(i.e., action set), and \emph{only} receives the reward of the \emph{played} arm that is affected by other agents' actions. The objective of each agent is to minimize her own cumulative swap regret, where the swap regret is a generic performance measure for online learning algorithms. We are the first to give a near-optimal high-probability swap-regret upper bound based on a refined martingale analysis for the exponential-weighting-based algorithms with the implicit exploration technique, which can further bound the expected swap regret instead of the pseudo-regret studied in the literature. It is also guaranteed that correlated equilibria can be achieved in a polynomial number of rounds if the algorithm is played by all agents. Furthermore, we conduct numerical experiments to verify the performance of the studied algorithm. 
 ID: 549 | Knowledge Intensive Learning of Cutset Networks   
  
 Saurabh Mathur, Vibhav Giridhar Gogate, Sriraam Natarajan  
   
    [link to video]   
   
  TL;DR:  We propose an algorithm to learn cutset networks from sparse and noisy data using qualitative influences   Abstract:   
 Cutset networks (CNs) are interpretable probabilistic representations that combine probability trees and tree Bayesian networks, to model and reason about large multi-dimensional probability distributions. Motivated by high-stakes applications in domains such as healthcare where (a) rich domain knowledge in the form of qualitative influences is readily available and (b) use of interpretable models that the user can efficiently probe and infer over is often necessary, we focus on learning CNs in the presence of qualitative influences. We propose a penalized objective function that uses the influences as constraints, and develop a gradient-based learning algorithm, KICN. We show that because CNs are tractable, KICN is guaranteed to converge to a local maximum of the penalized objective function. Our experiments on several benchmark data sets show that our new algorithm is superior to the LearnCNet algorithm proposed in previous work, especially when the data is scarce or noisy. 
 ID: 551 | Why Out-of-Distribution Detection Experiments Are Not Reliable - Subtle Experimental Artifacts Muddle the OOD Detector Rankings   
  
 Kamil Szyc, Tomasz Walkowiak, Henryk Maciejewski  

  TL;DR:  We identify experimental artifacts in OOD detection benchmark studies, so we question the reliability of OOD detector rankings.   Abstract:   
 Reliable detection of out-of-distribution (OOD) instances is becoming a critical requirement for machine learning systems deployed in safety-critical applications. Recently, many OOD detectors have been developed in the literature, and their performance has been evaluated using empirical studies based on well-established benchmark datasets. However, these studies do not provide a conclusive recommendation because the performance of OOD detection depends on the benchmark datasets. In this work, we want to question the reliability of the OOD detection performance numbers obtained from many of these empirical experiments. We report several experimental conditions that are not controlled and lead to significant changes in OOD detector performance and rankings of OOD methods. These include the technicalities related to how the DNN was trained (such as seed, train/test split, etc.), which do not change the accuracy of closed-set DNN models but may significantly change the performance of OOD detection methods that rely on representation from these DNNs. We performed extensive sensitivity studies to quantify the instability of OOD performance measures due to unintuitive experimental artifacts, which need to be more rigorously controlled and accounted for in many current OOD experiments. Experimental studies in OOD detection should improve methodological standards regarding experiment control and replication. 
 ID: 552 | A Trajectory is Worth Three Sentences: Multimodal Transformer for Offline Reinforcement Learning   
  
 Yiqi Wang, Mengdi Xu, Laixi Shi, Yuejie Chi  
   
    [link to video]   
   
  TL;DR:  We encourage the community to view transformer-based offline reinforcement learning approach from a multimodal perspective.   Abstract:   
 Transformers hold tremendous promise in solving offline reinforcement learning (RL) by formulating it as a sequence modeling problem derived from language modeling (LM). Prior works using transformers usually model the sample trajectory of RL as one sequence analogous to one sentence in LM, despite the fact that each trajectory includes tokens from three diverse modalities: state, action, and reward while a sentence contains words only. Rather than taking a modality-agnostic approach which uniformly models the tokens from different modalities into one sequence, we propose a multimodal sequence modeling approach in which a trajectory (one sentence) of three modalities (state, action, reward) is disentangled into three uni-modal ones (three sentences). We investigate the correlation of different modalities during sequential decision-making and use the insights to design our multimodal transformer, named Decision Transducer (DTd). DTd outperforms prior art in offline RL on the D4RL benchmarks and enjoys better sample efficiency and algorithm flexibility. 
 ID: 554 | Efficiently Learning the Graph for Semi-supervised Learning   
  
 Dravyansh Sharma, Maxwell Jones  

  TL;DR:  We show how to efficiently learning the graph (Gaussian bandwidth) parameter in classic semi-supervised learning, by exploiting sparsity and conjugate gradient approximations.   Abstract:   
 Computational efficiency is a major bottleneck in using classic graph-based approaches for semi-supervised learning on datasets with a large number of unlabeled examples. Known techniques to improve efficiency typically involve an approximation of the graph regularization objective, but suffer two major drawbacks ‚Äì first the graph is assumed to be known or constructed with heuristic hyperparameter values, second they do not provide a principled approximation guarantee for learning over the full unlabeled dataset. Building on recent work on learning graphs for semi-supervised learning from multiple datasets for problems from the same domain, and leveraging techniques for fast approximations for solving linear systems in the graph Laplacian matrix, we propose algorithms that overcome both the above limitations. We show a formal separation in the learning-theoretic complexity of sparse and dense graph families. We further show how to approximately learn the best graphs from the sparse families efficiently using the conjugate gradient method. Our approach can also be used to learn the graph efficiently online with sub-linear regret, under mild smoothness assumptions. Our online learning results are stated generally, and may be useful for approximate and efficient parameter tuning in other problems. We implement our approach and demonstrate significant (~10-100x) speedups over prior work on semi-supervised learning with learned graphs on benchmark datasets. 
 ID: 555 | KrADagrad: Kronecker Approximation-Domination Gradient Preconditioned Stochastic Optimization   
  
 Jonathan Mei, Alexander Moreno, Luke Walters  

  TL;DR:  Second order optimizer that avoids matrix inversion   Abstract:   
 Second order stochastic optimizers allow parameter update step size and direction to adapt to loss curvature, but have traditionally required too much memory and compute for deep learning. Recently, Shampoo [Gupta et al., 2018] introduced a Kronecker factored preconditioner to reduce these requirements: it is used for large deep models [Anil et al., 2020] and in production [Anil et al., 2022]. However, it takes inverse matrix roots of ill-conditioned matrices. This requires 64-bit precision, imposing strong hardware constraints. In this paper, we propose a novel factorization, Kronecker Approximation-Domination (KrAD). Using KrAD, we update a matrix that directly approximates the inverse empirical Fisher matrix (like full matrix AdaGrad), avoiding inversion and hence 64-bit precision. We then propose KrADagrad$^\star$, with similar computational costs to Shampoo and the same regret. Synthetic ill-conditioned experiments show improved performance over Shampoo for 32-bit precision, while for several real datasets we have comparable or better generalization. 
 ID: 556 | Fast and Scalable Score-Based Kernel Calibration Tests   
 [spotlight]  
 Pierre Glaser, David Widmann, Fredrik Lindsten, Arthur Gretton  

  TL;DR:  We introduce a Fast and Scalable Score-Based Kernel Calibration Test.   Abstract:   
 We introduce the Kernel Calibration Conditional Stein Discrepancy test (KCCSD test), a nonparametric, kernel-based test for assessing the calibration of probabilistic models with well-defined scores. In contrast to previous methods, our test avoids the need for possibly expensive expectation approximations while providing control over its type-I error. We achieve these improvements by using a new family of kernels for score-based probabilities that can be estimated without probability density samples, and by using a Conditional Goodness of Fit criterion for the KCCSD test's U-statistic. The tractability of the KCCSD test widens the surface area of calibration measures to new promising use-cases, such as regularization during model training. We demonstrate the properties of our test on various synthetic settings. 
 ID: 558 | Neural Tangent Kernel at Initialization: Linear Width Suffices   
  
 Arindam Banerjee, Pedro Cisneros-Velarde, Libin Zhu, Misha Belkin  

    Abstract:   
 In this paper we study the problem of lower bounding the minimum eigenvalue of the neural tangent kernel (NTK) at initialization, an important quantity for the theoretical analysis of training in neural networks. We consider feedforward neural networks with smooth activation functions. Without any distributional assumptions on the input, we present a novel result: we show that for suitable initialization variance, $\widetilde{\Omega}(n)$ width, where $n$ is the number of training samples, suffices to ensure that the NTK at initialization is positive definite, improving prior results for smooth activations under our setting. Prior to our work, the sufficiency of linear width has only been shown either for networks with ReLU activation functions, and sublinear width has been shown for smooth networks but with additional conditions on the distribution of the data. The technical challenge in the analysis stems from the layerwise inhomogeneity of smooth activation functions and we handle the challenge using generalized Hermite series expansion of such activations. 
 ID: 559 | "Private Prediction Strikes Back!" Private Kernelized Nearest Neighbors with Individual R\'{e}nyi Filter   
 [spotlight]  
 Yuqing Zhu, Xuandong Zhao, Chuan Guo, Yu-Xiang Wang  

  TL;DR:  We propose a new private prediction mechanism that easily adapted to the changing private dataset and improve over existing private prediction methods.   Abstract:   
 Most existing approaches of differentially private (DP) machine learning focus on private training. Despite its many advantages, private training lacks the flexibility in adapting to incremental changes to the training dataset such as deletion requests from exercising GDPR‚Äôs right to be forgotten. We revisit a long-forgotten alternative, known as private prediction, and propose a new algorithm named Individual Kernelized Nearest Neighbor (Ind-KNN). Ind-KNN is easily updatable over dataset changes and it allows precise control of the R\'{e}nyi DP at an individual user level --- a user's privacy loss is measured by the exact amount of her contribution to predictions; and a user is removed if her prescribed privacy budget runs out. Our results show that Ind-KNN consistently improves the accuracy over existing private prediction methods for a wide range of $\epsilon$ on four vision and language tasks. We also illustrate several cases under which Ind-KNN is preferable over private training with NoisySGD. 
 ID: 560 | Online Heavy-tailed Change-point detection   
  
 Abishek Sankararaman, Murali Balakrishnan  

  TL;DR:  We give the first algorithm to have provable false positive rate for online change point detection with heavy tailed data   Abstract:   
 We study algorithms for online sequential change-point detection, where samples are presented one at a time, a change in the underlying mean must be detected as early as possible, and the data distribution could be heavy tailed. We present an algorithm based on clipped Stochastic Gradient Descent (SGD), that works even if we only assume that the second moment of the data generating process is bounded. We derive guarantees on worst-case, finite-sample false-positive rate (FPR) over the family of all distributions with bounded second moment. Thus, our method is the first online change point detection mechanism that guarantees finite-sample FPR, even if the underlying observations are drawn from a heavy-tailed distribution. The technical contribution of our paper is to show that clipped-SGD can estimate the mean of a random vector and simultaneously provide confidence bounds at all confidence values. We use this robust estimate via a simple union bound and construct a sequential change-point algorithm with finite-sample FPR guarantees. We further demonstrate through simulations that our algorithm works well in a variety of situations whether the underlying data are heavy-tailed, light-tailed, high dimensional or discrete. No other algorithm achieves bounded FPR theoretically or empirically, over all the settings we study simultaneously. 
 ID: 561 | Fairness-Aware Class Imbalanced Learning on Multiple Subgroups   
  
 Davoud Ataee Tarzanagh, Bojian Hou, Boning Tong, Qi Long, Li Shen  

    Abstract:   
 Overparameterized models fail to generalize well in the presence of data imbalance even when combined with standard re-weighting and margin adjustment of loss for mitigating imbalances. This concern is further exacerbated when the data contains multiple or even \textit{many} subgroups, each with a \textit{limited number of samples}. We design a Bayesian-based three-level optimization framework to improve the performance in such scenarios. In the middle and lower levels, the \textit{local} (subgroup-specific) predictors are learned through a small amount of training data and the fair and class-balanced predictor. Specifically, our lower-level formulation uses sharpness-aware minimization (SAM) algorithm to effectively escape saddle points for minority classes. The upper-level problem automatically tunes the loss function by monitoring the validation loss and updates the \textit{global} predictor to be close to all local predictors. We theoretically show that our method leads to the potentially improved generalization bound. Empirical results demonstrate the benefits of our three-level framework over state-of-the-art approaches. 
 ID: 566 | Active Metric Learning and Classification using Similarity Queries   
  
 Namrata Nadagouda, Austin Xu, Mark A. Davenport  
   
    [link to video]   
   
  TL;DR:  This paper describes a unified active query framework that can be applied to any problem which involves learning a representation of the data that reflects similarity.   Abstract:   
 Active learning is commonly used to train label-efficient models by adaptively selecting the most informative queries. However, most active learning strategies are designed to either learn a representation of the data (e.g., embedding or metric learning) or perform well on a task (e.g., classification) on the data. However, many machine learning tasks involve a combination of both representation learning and a task-specific goal. Motivated by this, we propose a novel unified query framework that can be applied to any problem in which a key component is learning a representation of the data that reflects similarity. Our approach builds on similarity or nearest neighbor (NN) queries which seek to select samples that result in improved embeddings. The queries consist of a reference and a set of objects, with an oracle selecting the object most similar (i.e., nearest) to the reference. In order to reduce the number of solicited queries, they are chosen adaptively according to an information theoretic criterion. We demonstrate the effectiveness of the proposed strategy on two tasks -- active metric learning and active classification -- using a variety of synthetic and real world datasets. In particular, we demonstrate that actively selected NN queries outperform recently developed active triplet selection methods in a deep metric learning setting. Further, we show that in classification, actively selecting class labels can be reformulated as a process of selecting the most informative NN query, allowing direct application of our method. 
 ID: 567 | On the Convergence of Continual Learning with Adaptive Methods   
  
 Seungyub Han, Yeongmo Kim, Taehyun Cho, Jungwoo Lee  

    Abstract:   
 One of the objectives of continual learning is to prevent catastrophic forgetting in learning multiple tasks sequentially, and the existing solutions have been driven by the conceptualization of the plasticity-stability dilemma. However, the convergence of continual learning for each sequential task is less studied so far. In this paper, we provide a convergence analysis of memory-based continual learning with stochastic gradient descent and empirical evidence that training current tasks causes the cumulative degradation of previous tasks. We propose an adaptive method for nonconvex continual learning (NCCL), which adjusts step sizes of both previous and current tasks with the gradients. The proposed method can achieve the same convergence rate as the SGD method when the catastrophic forgetting term which we define in the paper is suppressed at each iteration. Further, we demonstrate that the proposed algorithm improves the performance of continual learning over existing methods for several image classification tasks. 
 ID: 571 | Robust Quickest Change Detection for Unnormalized Models   
  
 Suya Wu, Enmao Diao, Taposh Banerjee, Jie Ding, Vahid Tarokh  

  TL;DR:  We propose a new robust score-based quickest change detection algorithm that can be applied to unnormalized models.   Abstract:   
 Detecting an abrupt and persistent change in the underlying distribution of online data streams is an important problem in many applications. This paper proposes a new robust score-based algorithm called RSCUSUM, which can be applied to unnormalized models and addresses the issue of unknown post-change distributions. RSCUSUM replaces the Kullback-Leibler divergence with the Fisher divergence between pre- and post-change distributions for computational efficiency in unnormalized statistical models and introduces a notion of the ``least favorable'' distribution for robust change detection. The algorithm and its theoretical analysis are demonstrated through simulation studies. 
 ID: 576 | Identifiability and Estimation under Missing Not at Random Mechanisms   
  
 Anna Guo, Jiwei Zhao, Razieh Nabi  

    Abstract:   
 Conducting valid statistical analyses is challenging in the presence of missing-not-at-random (MNAR) data, where the missingness mechanism is dependent on the missing values themselves even conditioned on the observed data. Here, we consider a MNAR model that generalizes several prior popular MNAR models in two ways: first, it is less restrictive in terms of statistical independence assumptions imposed on the underlying joint data distribution, and second, it allows for all variables in the observed sample to have missing values. This MNAR model corresponds to a so-called criss-cross structure considered in the literature on graphical models of missing data that prevents nonparametric identification of the entire missing data model. Nonetheless, part of the complete-data distribution remains nonparametrically identifiable. By exploiting this fact and considering a rich class of exponential family distributions, we establish sufficient conditions for identification of the complete-data distribution as well as the entire missingness mechanism. We then propose methods for testing the independence restrictions encoded in such models using odds ratio as our parameter of interest. We adopt two semiparametric approaches for estimating the odds ratio parameter and establish the corresponding asymptotic theories: one involves maximizing a conditional likelihood with order statistics and the other uses estimating equations. The utility of our methods is illustrated via simulation studies. 
 ID: 579 | Optimistic Thompson Sampling-based Algorithms for Episodic Reinforcement Learning   
  
 Bingshan Hu, Tianyue H. Zhang, Nidhi Hegde, Mark Schmidt  
   
    [link to video]   
   
    Abstract:   
 We propose two Thompson Sampling-like, model-based learning algorithms for episodic Markov decision processes (MDPs) with a finite time horizon. Our proposed algorithms are inspired by Optimistic Thompson Sampling (O-TS) previously empirically studied in Chapelle and Li [2011], May et al. [2012] for stochastic multi-armed bandits. The key idea for the original O-TS is to clip the posterior distribution in an optimistic way. Both of our proposed algorithms are easy to implement and only need one posterior sample to construct an episode-dependent model. Our first algorithm, Optimistic Thompson Sampling for MDPs (O-TS-MDP), achieves a $\widetilde{O} \left(\sqrt{AS^2H^4T} \right)$ regret bound, where $S$ is the size of the state space, $A$ is the size of the action space, $H$ is the number of time-steps per episode and $T$ is the number of episodes. Our second algorithm, Optimistic Thompson Sampling plus for MDPs (O-TS-MDP$^+$), achieves the (near)-optimal $\widetilde{O} \left(\sqrt{ASH^3T} \right)$ regret bound by taking a more aggressive clipping strategy. Since O-TS was only empirically studied before, we derive regret bounds of O-TS for stochastic bandits. In addition, we propose, O-TS-Bandit$^+$, for stochastic bandits. Both O-TS and O-TS-Bandit$^+$ achieve the optimal $O\left(\frac{A\ln(T)}{\Delta} \right)$ problem-dependent regret bound, where $\Delta$ denotes the sub-optimality gap. 
 ID: 580 | Short-term Temporal Dependency Detection under Heterogeneous Event Dynamic with Hawkes Processes   
  
 Yu Chen, Fengpei Li, Anderson Schneider, Yuriy Nevmyvaka, Asohan Amarasingham, Henry Lam  

    Abstract:   
 Many \textit{event sequence} data exhibit mutually exciting or inhibiting patterns. Reliable detection of such temporal dependency is crucial for scientific investigation. The \textit{de facto} model is the Multivariate Hawkes Process (MHP), whose impact function naturally encodes a causal structure in Granger causality. However, the vast majority of existing methods use direct or nonlinear transform of \textit{standard} MHP intensity with constant baseline, inconsistent with real-world data. Under irregular and unknown heterogeneous intensity, capturing temporal dependency is hard as one struggles to distinguish the effect of mutual interaction from that of intensity fluctuation. In this paper, we address the short-term temporal dependency detection issue. We show the maximum likelihood estimation (MLE) for cross-impact from MHP has an error that can not be eliminated but may be reduced by order of magnitude, using heterogeneous intensity not of the target HP but of the interacting HP. Then we proposed a robust and computationally-efficient method modified from MLE that does not rely on the prior estimation of the heterogeneous intensity and is thus applicable in a data-limited regime (e.g., few-shot, no repeated observations). Extensive experiments on various datasets show that our method outperforms existing ones by notable margins, with highlighted novel applications in neuroscience. 
 ID: 583 | Content Sharing Design for Social Welfare in Networked Disclosure Game   
  
 Feiran Jia, Chenxi Qiu, Sarah Rajtmajer, Anna Squicciarini  

    Abstract:   
 This work models the costs and benefits of personal information sharing, or self-disclosure, in online social networks as a networked disclosure game. In a networked population where edges represent visibility amongst users, we assume a leader can influence network structure through content promotion, and we seek to optimize social welfare through network design. Our approach considers user interaction non-homogeneously, where pairwise engagement amongst users can involve or not involve sharing personal information. We prove that this problem is NP-hard. As a solution, we develop a Mixed-integer Linear Programming algorithm by linearization, which can achieve an exact solution, and also develop a time-efficient heuristic algorithm that can be used at scale. We conduct numerical experiments to demonstrate the properties of the algorithms and map theoretical results to a dataset of posts and comments in 2020 and 2021 in a COVID-related Subreddit community where privacy risks and sharing tradeoffs were particularly pronounced. 
 ID: 584 | Scalable Nonparametric Bayesian Learning for Dynamic Velocity Fields   
  
 Sunrit Chakraborty, Aritra Guha, Rayleigh Lei, XuanLong Nguyen  

  TL;DR:  Proposed a Bayesian nonparametric model to extract interpretable patterns from complex spatio-temporal data and proposed a scalable inference algorithm to analyze large volume of data, which we demonstrate on the NGSIM traffic dataset.   Abstract:   
 Learning and understanding heterogeneous patterns in complex spatio-temporal data is an important and challenging task across domains in science and engineering. In this work we develop a model for learning heterogeneous and dynamic patterns of velocity field data, motivated by applications in the transportation domain. We draw from basic nonparametric Bayesian modeling elements such as infinite hidden Markov model and Gaussian process, and focus on making the learning of such a stochastic model scalable for voluminous and streaming data. This is achieved by employing sequential MAP estimates from the infinite HMM model, an efficient sequential sparse GP posterior computation and refinement of the estimates using Viterbi algorithm, which is shown to work effectively on a careful simulation study. We demonstrate the efficacy of our techniques to the NGSIM dataset of complex multi-vehicle interactions. 
 ID: 587 | Reward-Machine-Guided, Self-Paced Reinforcement Learning   
  
 Cevahir Koprulu, ufuk topcu  
   
    [link to video]   
   
  TL;DR:  We propose a curriculum reinforcement learning approach, for long-horizon planning tasks, guided via reward machines that encode the non-Markovian reward function of the environment.   Abstract:   
 Self-paced reinforcement learning (RL) aims to improve the data efficiency of learning by automatically creating sequences, namely curricula, of probability distributions over contexts. However, existing techniques for self-paced RL fail in long-horizon planning tasks that involve temporally extended behaviors. We hypothesize that taking advantage of prior knowledge about the underlying task structure can improve the effectiveness of self-paced RL. We develop a self-paced RL algorithm guided by reward machines, i.e., a type of finite-state machine that encodes the underlying task structure. The algorithm integrates reward machines in 1) the update of the policy and value functions obtained by any RL algorithm of choice, and 2) the update of the automated curriculum that generates context distributions. Our empirical results evidence that the proposed algorithm achieves optimal behavior reliably even in cases in which existing baselines cannot make any meaningful progress. It also decreases the curriculum length and reduces the variance in the curriculum generation process by up to one-fourth and four orders of magnitude, respectively. 
 ID: 589 | Copula-Based Deep Survival Models for Dependent Censoring   
  
 Ali Hossein Gharari Foomani, Michael Cooper, Russell Greiner, Rahul G Krishnan  
   
    [link to video]   
   
  TL;DR:  This paper applies copulas to model unobserved dependencies between times of event and censorship in survival analysis, reducing bias in learned survival curves.   Abstract:   
 Survival datasets describe a set of instances (e.g., patients), and provide, for each, either the time until an event (e.g., death), or the censoring time (e.g., when lost to follow-up ‚Äì which is a lower bound on the time until the event). We consider the challenge of survival prediction: learning, from such data, a predictive model that can produce an individual survival distribution for a novel instance. Many contemporary methods of survival prediction implicitly assume that the event and censoring distributions are independent conditional on the instance‚Äôs covariates ‚Äì a strong assumption that is difficult to verify (as we observe only one outcome for each instance) and which can induce significant bias when it does not hold. This paper presents a parametric model of survival that extends modern non-linear survival analysis by relaxing the assumption of conditional independence. Experiments on synthetic and semi-synthetic data demonstrate that our approach significantly improves estimates of survival distributions compared to the standard that assumes conditional independence in the data. 
 ID: 590 | Optimal Budget Allocation for Crowdsourcing Labels for Graphs   
  
 Adithya Kulkarni, Mohna Chakraborty, Sihong Xie, Qi Li  
   
    [link to video]   
   
    Abstract:   
 Crowdsourcing is an effective and efficient paradigm for obtaining labels for unlabeled corpus employing crowd workers. This work considers the budget allocation problem for a generalized setting on a graph of instances to be labeled where edges encode instance dependencies. Specifically, given a graph and a labeling budget, we propose an optimal policy to allocate the budget among the instances to maximize the overall labeling accuracy. We formulate the problem as a Bayesian Markov Decision Process (MDP), where we define our task as an optimization problem that maximizes the overall label accuracy under budget constraints. Then, we propose a novel stage-wise reward function that considers the effect of worker labels on the whole graph at each timestamp. This reward function is utilized to find an optimal policy for the optimization problem. Theoretically, we show that our proposed policies are consistent when the budget is infinite. We conduct extensive experiments on five real-world graph datasets and demonstrate the effectiveness of the proposed policies to achieve a higher label accuracy under budget constraints. 
 ID: 594 | Risk-limiting Financial Audits via Weighted Sampling without Replacement   
  
 Shubhanshu Shekhar, Ziyu Xu, Zachary Chase Lipton, Pierre Jinghong Liang, Aaditya Ramdas  

  TL;DR:  A general approach to auditing financial transactions using confidence sequences for estimating weighted means under adaptive sampling without replacement.   Abstract:   
 We introduce the notion of a risk-limiting financial auditing (RLFA): given $N$ transactions, the goal is to estimate the total misstated monetary fraction ($m^*$) to a given accuracy $\epsilon$, with confidence $1-\delta$. We do this by constructing new confidence sequences (CSs) for the weighted average of $N$ unknown values, based on samples drawn without replacement according to a (randomized) weighted sampling scheme. Using the idea of importance weighting to construct test martingales, we first develop a framework to construct CSs for arbitrary sampling strategies. Next, we develop methods to improve the quality of CSs by incorporating side information about the unknown values associated with each item. We show that when the side information is sufficiently predictive, it can directly drive the sampling. Addressing the case where the accuracy is unknown *a priori*, we introduce a method that incorporates side information via control variates. Crucially, our construction is adaptive: if the side information is highly predictive of the unknown misstated amounts, then the benefits of incorporating it are significant; but if the side information is uncorrelated, our methods learn to ignore it. Our methods recover state-of-the-art bounds for the special case when the weights are equal, which has already found applications in election auditing. The harder weighted case solves our more challenging problem of AI-assisted financial auditing. 
 ID: 595 | No-Regret Linear Bandits beyond Realizability   
  
 Chong Liu, Ming Yin, Yu-Xiang Wang  

  TL;DR:  A no-regret algorithm solves linear bandit problem without realizability.   Abstract:   
 We study linear bandits when the underlying reward function is not linear. Existing work relies on a uniform misspecification parameter $\epsilon$ that measures the sup-norm error of the best linear approximation. This results in an unavoidable linear regret whenever $\epsilon > 0$. We describe a more natural model of misspecification which only requires the approximation error at each input $x$ to be proportional to the suboptimality gap at $x$. It captures the intuition that, for optimization problems, near-optimal regions should matter more and we can tolerate larger approximation errors in suboptimal regions. Quite surprisingly, we show that the classical LinUCB algorithm --- designed for the realizable case --- is automatically robust against such gap-adjusted misspecification. It achieves a near-optimal $\sqrt{T}$ regret for problems that the best-known regret is almost linear in time horizon $T$. Technically, our proof relies on a novel self-bounding argument that bounds the part of the regret due to misspecification by the regret itself. 
 ID: 596 | Counting Background Knowledge Consistent Markov Equivalent Directed Acyclic Graphs   
  
 Vidya Sagar Sharma  

  TL;DR:  This paper gives a fixed-parameter tractable algorithm to count the number of directed acyclic graphs in a Markov equivalence class under background knowledge constraint.   Abstract:   
 We study the problem of counting the number of directed acyclic graphs in a Markov equivalence class (MEC) that are consistent with background knowledge specified in the form of the directions of some additional edges in the MEC. A polynomial-time algorithm for the special case of the problem when no background knowledge constraints are specified was given by Wienöbst, Bannach, and Li≈õkiewicz (AAAI 2021), who also showed that the general case is NP-hard (in fact, #P-hard). In this paper, we show that the problem is nevertheless tractable in an interesting class of instances, by establishing that it is ``fixed-parameter tractable'': we give an algorithm that runs in time $O(k! k^2 n^4)$, where $n$ is the number of nodes in the MEC and $k$ is the maximum number of nodes in any maximal clique of the MEC that participate in the specified background knowledge constraints. In particular, our algorithm run in polynomial time in the well-studied special case of MECs of bounded treewidth or bounded maximum clique size. 
 ID: 597 | On Testability and Goodness of Fit Tests in Missing Data Models   
 [oral]  
 Razieh Nabi, Rohit Bhattacharya  
   
    [slides]   
   
    Abstract:   
 Significant progress has been made in developing identification and estimation techniques for missing data problems where modeling assumptions can be described via a directed acyclic graph. The validity of results using such techniques rely on the assumptions encoded by the graph holding true; however, verification of these assumptions has not received sufficient attention in prior work. In this paper, we provide new insights on the testable implications of three broad classes of missing data graphical models, and design goodness-of-fit tests for them. The classes of models explored are: sequential missing-at-random and missing-not-at-random models which can be used for modeling longitudinal studies with dropout/censoring, and a no self-censoring model which can be applied to cross-sectional studies and surveys. 
 ID: 598 | Conditionally Optimistic Exploration for Cooperative Deep Multi-Agent Reinforcement Learning   
  
 Xutong Zhao, Yangchen Pan, Chenjun Xiao, Sarath Chandar, Janarthanan Rajendran  

  TL;DR:  We introduce a conditional optimism-based exploration method for cooperative multi-agent reinforcement learning.   Abstract:   
 Efficient exploration is critical in cooperative deep Multi-Agent Reinforcement Learning (MARL). In this paper, we propose an exploration method that efficiently encourages cooperative exploration based on the idea of the theoretically justified tree search algorithm UCT (Upper Confidence bounds applied to Trees). The high-level intuition is that to perform optimism-based exploration, agents would achieve cooperative strategies if each agent's optimism estimate captures a structured dependency relationship with other agents. At each node (i.e., action) of the search tree, UCT performs optimism-based exploration using a bonus derived by conditioning on the visitation count of its parent node. We provide a perspective to view MARL as tree search iterations and develop a method called Conditionally Optimistic Exploration (COE). We assume agents take actions following a sequential order, and consider nodes at the same depth of the search tree as actions of one individual agent. COE computes each agent's state-action value estimate with an optimistic bonus derived from the visitation count of the state and joint actions taken by agents up to the current agent. COE is adaptable to any value decomposition method for centralized training with decentralized execution. Experiments across various cooperative MARL benchmarks show that COE outperforms current state-of-the-art exploration methods on hard-exploration tasks. 
 ID: 601 | Robust Distillation for Worst-class Performance: On the Interplay Between Teacher and Student Objectives   
  
 Serena Lutong Wang, Harikrishna Narasimhan, Yichen Zhou, Sara Hooker, Michal Lukasik, Aditya Krishna Menon  

  TL;DR:  We explore the interplay between robust optimization objectives for the teacher and student in a knowledge distillation setting.   Abstract:   
 Knowledge distillation is a popular technique that has been shown to produce remarkable gains in average accuracy. However, recent work has shown that these gains are not uniform across subgroups in the data, and can often come at the cost of accuracy on rare subgroups and classes. Robust optimization is a common remedy to improve worst-class accuracy in standard learning settings, but in distillation it is unknown whether it is best to apply robust objectives when training the teacher, the student, or both. This work studies the interplay between robust objectives for the teacher and student. Empirically, we show that that jointly modifying the teacher and student objectives can lead to better worst-class student performance and even Pareto improvement in the tradeoff between worst-class and overall performance. Theoretically, we show that the *per-class calibration* of teacher scores is key when training a robust student. Both the theory and experiments support the surprising finding that applying a robust teacher training objective does not always yield a more robust student. 
 ID: 604 | Differentially Private Stochastic Convex Optimization in (Non)-Euclidean Space Revisited   
  
 Jinyan Su, Changhong Zhao, Di Wang  

  TL;DR:  We revisit the problem of Differentially Private Stochastic Convex Optimization (DP-SCO) in Euclidean and general $\ell_p^d$ spaces.   Abstract:   
 In this paper, we revisit the problem of Differentially Private Stochastic Convex Optimization (DP-SCO) in Euclidean and general $\ell_p^d$ spaces. Specifically, we focus on three settings that are still far from well understood: (1) DP-SCO over a constrained and bounded (convex) set in Euclidean space; (2) unconstrained DP-SCO in $\ell_p^d$ space; (3) DP-SCO with heavy-tailed data over a constrained and bounded set in $\ell_p^d$ space. For problem (1), for both convex and strongly convex loss functions, we propose methods whose outputs could achieve (expected) excess population risks that are only dependent on the Gaussian width of the constraint set, rather than the dimension of the space. Moreover, we also show the bound for strongly convex functions is optimal up to a logarithmic factor. For problems (2) and (3), we propose several novel algorithms and provide the first theoretical results for both cases when $1 
 ID: 605 | CrysMMNet: Multimodal Representation for Crystal Property Prediction.   
  
 KISHALAY DAS, Pawan Goyal, Seung-Cheol Lee, Satadeep Bhattacharjee, Niloy Ganguly  

  TL;DR:  In this paper, we propose a simple multi-modal framework for crystalline materials, which fuse both graph structural and textual representation together to improve property prediction accuracy.   Abstract:   
 Machine Learning models have emerged as a powerful tool for fast and accurate prediction of different crystalline properties. Exiting state-of-the-art models rely on a single modality of crystal data i.e crystal graph structure, where they construct multi-graph by establishing edges between nearby atoms in 3D space and apply GNN to learn materials representation. Thereby, they encode local chemical semantics around the atoms successfully but fail to capture important global periodic structural information like space group number, crystal symmetry, rotational information etc, which influence different crystal properties. In this work, we leverage textual descriptions of materials to model global structural information into graph structure to learn a more robust and enriched representation of crystalline materials. To this effect, we first curate a textual dataset for crystalline material databases containing descriptions of each material. Further, we propose CrysMMNet, a simple multi- modal framework, which fuses both structural and textual representation together to generate a joint multimodal representation of crystalline materials. We conduct extensive experiments on benchmark datasets across ten different properties to show that CrysMMNet outperforms existing state-of-the-art baseline methods with a good margin. We also observe fusing textual representation with crystal graph structure provides consistent improvement for all the SOTA GNN models compared to their own vanilla version. We are going to share the textual dataset, that we have curated for both the benchmark material databases with the community for future use. 
 ID: 606 | Graph Self-supervised Learning via Proximity Divergence Minimization   
  
 Tianyi Zhang, Zhenwei DAI, Zhaozhuo Xu, Anshumali Shrivastava  

    Abstract:   
 Self-supervised learning (SSL) for graphs is an essential problem since graph data are ubiquitous and labeling can be costly. We argue that existing SSL approaches for graphs have two limitations. First, they rely on corruption techniques such as node attribute perturbation and edge dropping to generate graph views for contrastive learning. These unnatural corruption techniques require extensive tuning efforts and provide marginal improvements. Second, the current approaches require the computation of multiple graph views, which is memory and computationally inefficient. These shortcomings of graph SSL call for a corruption-free single-view learning approach, but the strawman approach of using neighboring nodes as positive examples suffers two problems: it ignores the strength of connections between nodes implied by the graph structure on a macro level, and cannot deal with the high noise in real-world graphs. We propose Proximity Divergence Minimization (PDM), a corruption-free single-view graph SSL approach that overcomes these problems by leveraging node proximity to measure connection strength and denoise the graph structure. Through extensive experiments, we show that PDM achieves up to $4.55\%$ absolute improvement in ROC-AUC on graph SSL tasks over state-of-the-art approaches while being more memory efficient. Moreover, PDM even outperforms supervised training on node classification tasks of ogbn-proteins dataset. 
 ID: 607 | TCE: A Test-Based Approach to Measuring Calibration Error   
  
 Takuo Matsubara, Niek Tax, Richard Mudd, Ido Guy  

  TL;DR:  We propose a new calibration error metric that is interpretable and stable under class imbalance. In addition, we address an optimal criterion of binning in calibration.   Abstract:   
 This paper proposes a new metric to measure the calibration error of probabilistic binary classifiers, called the test-based calibration error (TCE). TCE incorporates a novel loss function based on a statistical test to examine the extent to which model predictions differ from probabilities estimated from data. It offers (i) a clear interpretation, (ii) a consistent scale that is unaffected by class imbalance, and (iii) an enhanced visual representation alternative to the standard reliability diagram. In addition, we introduce an optimality criterion for the binning procedure of calibration error metrics based on a minimal estimation error of the empirical probabilities. We provide a new computational algorithm for optimal bins under bin-size constraints. We demonstrate properties of TCE through a range of experiments, including multiple real-world imbalanced datasets and ImageNet 1000. 
 ID: 608 | Overcoming Language Priors for Visual Question Answering via Loss Rebalancing Label and Global Context   
  
 Runlin Cao, Zhixin Li  

  TL;DR:  We propose a novel training strategy called Loss Rebalancing Label and Global Context (LRLGC) to mitigate language priors in visual question answering.   Abstract:   
 Despite the advances in Visual Question Answering (VQA), many VQA models currently suffer from language priors (i.e. generating answers directly from questions without using images), which severely reduces their robustness in real-world scenarios. We propose a novel training strategy called Loss Rebalancing Label and Global Context (LRLGC) to alleviate the above problem. Specifically, the Loss Rebalancing Label (LRL) is dynamically constructed based on the degree of sample bias to accurately adjust losses across samples and ensure a more balanced form of total losses in VQA. In addition, the Global Context (GC) provides the model with valid global information to assist the model in predicting answers more accurately. Finally, the model is trained through an ensemble-based approach that retains the beneficial effects of biased samples on the model while reducing their importance. Our approach is model-agnostic and enables end-to-end training. Extensive experimental results show that LRLGC (1) improves performance for various VQA models and (2) performs competitively in the VQA-CP v2 benchmark test. 
 ID: 611 | Bayesian Inference Approach for Entropy Regularized Reinforcement Learning with Stochastic Dynamics   
 [spotlight]  
 Argenis Arriojas, Jacob Adamczyk, Stas Tiomkin, Rahul V Kulkarni  

    Abstract:   
 We develop a novel approach to determine the optimal policy in entropy-regularized reinforcement learning (RL) with stochastic dynamics. For deterministic dynamics, the optimal policy can be derived using Bayesian inference in the control-as-inference framework; however, for stochastic dynamics, the direct use of this approach leads to risk-taking optimistic policies. To address this issue, current approaches in entropy-regularized RL involve a constrained optimization procedure which fixes system dynamics to the original dynamics, however this approach is not consistent with the unconstrained Bayesian inference framework. In this work we resolve this inconsistency by developing an exact mapping from the constrained optimization problem in entropy-regularized RL to a different optimization problem which can be solved using the unconstrained Bayesian inference approach. We show that the optimal policies are the same for both problems, thus our results lead to the exact solution for the optimal policy in entropy-regularized RL with stochastic dynamics through Bayesian inference. 
 ID: 617 | On the Informativeness of Supervision Signals   
 [spotlight]  
 Ilia Sucholutsky, Ruairidh McLennan Battleday, Katherine M. Collins, Raja Marjieh, Joshua Peterson, Pulkit Singh, Umang Bhatt, Nori Jacoby, Adrian Weller, Thomas L. Griffiths  

  TL;DR:  We propose a framework that enables comparison of supervision signals to help users optimize data annotation for supervised learning.   Abstract:   
 Supervised learning typically focuses on learning transferable representations from training examples annotated by humans. While rich annotations (like soft labels) carry more information than sparse annotations (like hard labels), they are also more expensive to collect. We use information theory to compare how a number of commonly used supervision signals contribute to representation-learning performance, as well as how their capacity is affected by factors such as the number of labels, classes, dimensions, and noise. Our framework provides theoretical justification for using hard labels in the big-data regime, but richer supervision signals for few-shot learning and out-of-distribution generalization. We validate these results empirically in a series of experiments with over 1 million crowdsourced image annotations and conduct a cost-benefit analysis to establish a tradeoff curve that enables users to optimize the cost of supervising representation learning on their own datasets. 
 ID: 621 | Keep-Alive Caching for the Hawkes process   
 [oral]  
 Sushirdeep Narayana, Ian A. Kash  
   
    [slides]   
   
  TL;DR:  We study the design of caching policies in applications such as serverless computing where there is not a fixed size cache to be filled , but rather there is a cost associated with the time an item stays in the cache.   Abstract:   
 We study the design of caching policies in applications such as serverless computing where there is not a fixed size cache to be filled, but rather there is a cost associated with the time an item stays in the cache. We present a model for such caching policies which captures the trade-off between this cost and the cost of cache misses. We characterize optimal caching policies in general and apply this characterization by deriving a closed form for Hawkes processes. Since optimal policies for Hawkes processes depend on the history of arrivals, we also develop history-independent policies which achieve near-optimal average performance. We evaluate the performances of the optimal policy and approximate polices using simulations and a data trace of Azure Functions, Microsoft's FaaS (Function as a Service) platform for serverless computing. 
 ID: 631 | Parity Calibration   
 [oral]  
 Youngseog Chung, Aaron Rumack, Chirag Gupta  
   
    [slides]   
   
  TL;DR:  We connect calibration in regression and classification with the notion of parity (whether the next observation increases or decreases w.r.t. the current observation), and propose methods to produce parity calibrated predictions.   Abstract:   
 In a sequential prediction setting, a decision-maker may be primarily concerned with whether the continuous-valued future observation will increase or decrease compared to the current one, rather than the actual value of the future observation. We introduce the parity calibration framework, where the goal is to provide calibrated uncertainty estimates for the increase-decrease event in a timeseries. While these ``parity" probabilities can be extracted from a distributional forecast, such a strategy does not work as expected and can have poor practical performance. We then observe that although the original task was regression, parity calibration can be expressed as binary calibration. Drawing on this connection, we use a recently proposed online binary calibration method to achieve parity calibration. We demonstrate the effectiveness of our method on real-world case studies in epidemiology, weather forecasting, and model-based control in nuclear fusion. 
 ID: 632 | Efficient Failure Pattern Identification of Predictive Algorithms   
  
 Bao Nguyen, Viet Anh Nguyen  
   
    [link to video]   
   
  TL;DR:  We propose a sampling mechanism for annotation queries to detect failure patterns from an unlabeled dataset   Abstract:   
 Given a (machine learning) classifier and a collection of unlabeled data, how can we efficiently identify misclassification patterns presented in this dataset? To address this problem, we propose a human-machine collaborative framework that consists of a team of human annotators and a sequential recommendation algorithm. The recommendation algorithm is conceptualized as a stochastic sampler that, in each round, queries the annotators a subset of samples for their true labels and obtains the information on whether the samples are misclassified. The sampling mechanism needs to balance between discovering new patterns of misclassification (exploration) and confirming the potential patterns of classification (exploitation). We construct a determinantal point process, whose intensity balances the exploration-exploitation trade-off through the weighted update of the posterior at each round to form the generator of the stochastic sampler. The numerical results empirically demonstrate the competitive performance of our framework on multiple dataset at various signal-to-noise ratios. 
 ID: 636 | Discovering Novel Subgroups Under Distribution Shift With Constrained Learning   
  
 Yoav Wald, Suchi Saria  
   
    [link to video]   
   
  TL;DR:  Constrained learning for the problem of novel class detection under distribution shift; Guaranteed solution under relatively mild assumptions   Abstract:   
 In this work, we solve the problem of novel class detection under distribution shift. This problem is critical to ensuring the safety and efficacy of machine learning models, particularly in domains such as healthcare where timely detection of novel subgroups of patients is crucial. To address this problem, we propose a method based on constrained learning. Our approach is guaranteed to detect a novel class under a relatively weak assumption, namely that rare events in past data have bounded frequency under the shifted distribution. Prior works on the problem do not provide such guarantees, as they either attend to very specific types of distribution shift or make stringent assumptions that limit their guarantees. We demonstrate favorable performance of our method on challenging novel class detection problems over real world datasets. 
 ID: 643 | Testing Conventional Wisdom (of the Crowd)   
 [spotlight]  
 Noah Burrell, Grant Schoenebeck  

  TL;DR:  We explore the extent to which common assumptions about the way that crowd workers make mistakes in microtask (labeling) applications manifest in real crowdsourcing data.   Abstract:   
 Do common assumptions about the way that crowd workers make mistakes in microtask (labeling) applications manifest in real crowdsourcing data? Prior work only addresses this question indirectly. Instead, it primarily focuses on designing new label aggregation algorithms, seeming to imply that better performance justifies any additional assumptions. However, empirical evidence in past instances has raised significant challenges to common assumptions. We continue this line of work, using crowdsourcing data itself as directly as possible to interrogate several basic assumptions about workers and tasks. We find strong evidence that the assumption that workers respond correctly to each task with a constant probability, which is common in theoretical work, is implausible in real data. We also illustrate how heterogeneity among tasks and workers can take different forms, which have different implications for the design and evaluation of label aggregation algorithms. 
 ID: 644 | USIM-DAL: Uncertainty-aware Statistical Image Modeling-based Dense Active Learning for Super-resolution   
  
 Vikrant Rangnekar, Uddeshya Upadhyay, Zeynep Akata, Biplab Banerjee  
   
    [link to video]   
   
  TL;DR:  Our work uses probabilistic deep networks with statistical image models to learn informative priors for structured images allowing active learning for dense regression tasks, like super-resolution.   Abstract:   
 Dense regression is a widely used approach in computer vision for tasks such as image super-resolution, enhancement, depth estimation, etc. However, the high cost of annotation and labeling makes it challenging to achieve accurate results. We propose incorporating active learning into dense regression models to address this problem. Active learning allows models to select the most informative samples for labeling, reducing the overall annotation cost while improving performance. Despite its potential, active learning has not been widely explored in high-dimensional computer vision regression tasks like super-resolution. We address this research gap and propose a new framework called USIM-DAL that leverages the statistical properties of colour images to learn informative priors using probabilistic deep neural networks that model the heteroscedastic predictive distribution allowing uncertainty quantification. Moreover, the aleatoric uncertainty from the network serves as a proxy for error that is used for active learning. Our experiments on a wide variety of datasets spanning applications in natural images (visual genome, BSD100), medical imaging (histopathology slides), and remote sensing (satellite images) demonstrate the efficacy of the newly proposed USIM-DAL and superiority over several dense regression active learning methods. 
 ID: 646 | Size-Constrained $k$-Submodular Maximization in Near-Linear Time   
  
 Guanyu Nie, Yanhui Zhu, Yididiya Y Nadew, Samik Basu, A. Pavan, Christopher John Quinn  
   
    [link to video]   
   
    Abstract:   
 We investigate the problems of maximizing $k$-submodular functions over total size constraints and over individual size constraints. $k$-submodularity is a generalization of submodularity beyond just picking items of a ground set, instead associating one of $k$ types to chosen items. For sensor selection problems, for instance, this enables modeling of which type of sensor to put at a location, not simply whether to put a sensor or not. We propose and analyze threshold-greedy algorithms for both types of constraints. We prove that our proposed algorithms achieve the best known approximation ratios, up to a user-chosen parameter $\varepsilon>0$, for both constraint types while using only $\widetilde{\mathcal{O}}(nk)$ function evaluations; other algorithms that achieve the best-known deterministic approximation ratios use $\widetilde{\mathcal{O}}(nkB)$ function evaluations, where $B\leq n$ is the total cardinality and sum of cardinalities respectively, $n$ is the number of elements, and $k$ is the number of types, and $\widetilde{\mathcal{O}}(\cdot)$ suppresses logarithmic terms. We empirically demonstrate our algorithms' performance in an application of influence maximization with $k$ topics. 
 ID: 648 | Contrastive Learning for Supervised Graph Matching   
  
 Gathika Ratnayaka, Qing Wang, Yang Li  

  TL;DR:  This paper introduces a contrastive learning framework for deep graph matching.   Abstract:   
 Deep graph matching techniques have shown promising results in recent years. In this work, we cast deep graph matching as a contrastive learning task and introduce a new objective function for contrastive mapping to exploit the relationships between matches and non-matches. To this end, we develop a hardness attention mechanism to select negative samples which captures the relatedness and informativeness of positive and negative samples. Further, we propose a novel deep graph matching framework, \emph{Stable Graph Matching} (StableGM), which incorporates Sinkhorn ranking into a stable marriage algorithm to efficiently compute one-to-one node correspondences between graphs. We prove that the proposed objective function for contrastive matching is both positive and negative informative, offering theoretical guarantees to achieve dual-optimality in graph matching. We empirically verify the effectiveness of our proposed approach by conducting experiments on standard graph matching benchmarks. 
 ID: 651 | Adaptivity Complexity for Causal Graph Discovery   
 [spotlight]  
 Davin Choo, Kirankumar Shiragur  
   
    [link to video]   
   
  TL;DR:  On the problem of recovering causal DAGs via interventions, we study the trade-off between the number of adaptive rounds used and the number of interventions required; we give matching upper and lower bounds.   Abstract:   
 Causal discovery from interventional data is an important problem, where the task is to design an interventional strategy that learns the hidden ground truth causal graph $G(V,E)$ on $|V| = n$ nodes while minimizing the number of performed interventions. Most prior interventional strategies broadly fall into two categories: non-adaptive and adaptive. Non-adaptive strategies decide on a single fixed set of interventions to be performed while adaptive strategies can decide on which nodes to intervene on sequentially based on past interventions. While adaptive algorithms may use exponentially fewer interventions than their non-adaptive counterparts, there are practical concerns that constrain the amount of adaptivity allowed. Motivated by this trade-off, we study the problem of $r$-adaptivity, where the algorithm designer recovers the causal graph under a total of $r$ sequential rounds whilst trying to minimize the total number of interventions. For this problem, we provide a $r$-adaptive algorithm that achieves $O(\min\{r,\log n\} \cdot n^{1/\min\{r,\log n\}})$ approximation with respect to the verification number, a well-known lower bound for adaptive algorithms. Furthermore, for every $r$, we show that our approximation is tight. Our definition of $r$-adaptivity interpolates nicely between the non-adaptive ($r=1$) and fully adaptive ($r=n$) settings where our approximation simplifies to $O(n)$ and $O(\log n)$ respectively, matching the best-known approximation guarantees for both extremes. Our results also extend naturally to the bounded size interventions. 
 ID: 654 | Dirichlet Proportions Model for Hierarchically Coherent Probabilistic Forecasting   
 [spotlight]  
 Abhimanyu Das, Weihao Kong, Biswajit Paria, Rajat Sen  

  TL;DR:  Top down inspired end to end method for hierarchically coherent probabilistic forecasting   Abstract:   
 Probabilistic, hierarchically coherent forecasting is a key problem in many practical forecasting applications -- the goal is to obtain coherent probabilistic predictions for a large number of time series arranged in a pre-specified tree hierarchy. In this paper, we present an end-to-end deep probabilistic model for hierarchical forecasting that is motivated by a classical top-down strategy. It jointly learns the distribution of the root time series, and the (dirichlet) proportions according to which each parent time-series is split among its children at any point in time. The resulting forecasts are naturally coherent, and provide probabilistic predictions over all time series in the hierarchy. We experiment on several public datasets and demonstrate significant improvements of up to 26% on most datasets compared to state-of-the-art baselines. Finally, we also provide theoretical justification for the superiority of our top-down approach compared to the more traditional bottom-up modeling. 
 ID: 657 | FLASH: Automating Federated Learning using CASH   
  
 Md Ibrahim Ibne Alam, Koushik Kar, Theodoros Salonidis, Horst Samulowitz  

  TL;DR:  We are proposing a method (FLASH), which solves the CASH problem for an FL setting in a decentralized way and do not need any FL training in the solution of CASH   Abstract:   
 In this paper, we present FLASH, a framework which addresses for the first time the central AutoML problem of Combined Algorithm Selection and HyperParameter (HP) Optimization (CASH) in the context of Federated Learning (FL). To limit training cost, FLASH incrementally adapts the set of algorithms to train based on their projected loss rates, while supporting decentralized (federated) implementation of the embedded hyperparameter optimization (HPO), model selection and loss calculation problems. We provide a theoretical analysis of the training and validation loss under FLASH, and their tradeoff with the training cost measured as the data wasted in training sub-optimal algorithms. The bounds depend on the degree of dissimilarity between the datasets of the clients, a result of FL restriction that client datasets remain private. Through extensive experimental investigation on several datasets, we evaluate three variants of FLASH, and show that FLASH performs close to centralized CASH methods. 
 ID: 658 | Aligned Diffusion Schrödinger Bridges   
 [spotlight]  
 Vignesh Ram Somnath, Matteo Pariset, Ya-Ping Hsieh, Maria Rodriguez Martinez, Andreas Krause, Charlotte Bunne  

    Abstract:   
 Diffusion Schrödinger Bridges (DSBs) have recently emerged as a powerful framework for recovering stochastic dynamics via their marginal observations at different time points. Despite numerous successful applications, existing algorithms for solving DSBs have so far failed to utilize the structure of aligned data, which naturally arises in many biological phenomena. In this paper, we propose a novel algorithmic framework that, for the first time, solves DSBs while respecting the data alignment. Our approach hinges on a combination of two decades-old ideas: The classical Schrödinger bridge theory and Doob's $h$-transform. Compared to prior methods, our approach leads to a simpler training procedure with lower variance, which we further augment with principled regularization schemes. This ultimately leads to sizeable improvements across experiments on synthetic and real data, including the tasks of rigid protein docking and temporal evolution of cellular differentiation processes. 
 ID: 663 | Molecule Design by Latent Space Energy-Based Modeling and Gradual Distribution Shifting   
  
 Deqian Kong, Bo Pang, Tian Han, Ying Nian Wu  

  TL;DR:  We propose to use latent space energy-based model to capture the joint distribution of molecules and their properties and optimize molecule properties by sampling with gradual distribution shifting.   Abstract:   
 Generation of molecules with desired chemical and biological properties such as high drug-likeness, high binding affinity to target proteins, is critical for drug discovery. In this paper, we propose a probabilistic generative model to capture the joint distribution of molecules and their properties. Our model assumes an energy-based model (EBM) in the latent space. Conditional on the latent vector, the molecule and its properties are modeled by a molecule generation model and a property regression model respectively. To search for molecules with desired properties, we propose a sampling with gradual distribution shifting (SGDS) algorithm, so that after learning the model initially on the training data of existing molecules and their properties, the proposed algorithm gradually shifts the model distribution towards the region supported by molecules with desired values of properties. Our experiments show that our method achieves competitive performances on various molecule design tasks. 
 ID: 665 | A Constrained Bayesian Approach to Out-of-Distribution Prediction   
  
 Ziyu Wang, Binjie Yuan, Jiaxun Lu, Bowen Ding, yunfeng shao, Qibin Wu, Jun Zhu  

    Abstract:   
 Consider the problem of out-of-distribution prediction given data from multiple environments. While a sufficiently diverse collection of training environments will facilitate the identification of an invariant predictor, with an optimal generalization performance, many applications only provide us with a limited number of environments. It is thus necessary to consider adapting to distribution shift using a handful of labeled test samples. We propose a constrained Bayesian approach for this task, which restricts to models with a worst-group training loss above a prespecified threshold. Our method avoids a pathology of the standard Bayesian posterior, which occurs when spurious correlations improve in-distribution prediction. We also show that on certain high-dimensional linear problems, constrained modeling improves the sample efficiency of adaptation. Synthetic and real-world experiments demonstrate the robust performance of our approach. 
 ID: 669 | Does Momentum Help in Stochastic Optimization? A Sample Complexity Analysis.   
  
 Swetha Ganesh, Rohan Deb, Gugan Thoppe, Amarjit Budhiraja  
   
    [link to video]   
   
    Abstract:   
 Stochastic Heavy Ball (SHB) and Nesterov's Accelerated Stochastic Gradient (ASG) are popular momentum methods in optimization. While the benefits of these acceleration ideas in deterministic settings are well understood, their advantages in stochastic optimization are unclear. Several works have recently claimed that SHB and ASG always help in stochastic optimization. Our work shows that i.) these claims are either flawed or one-sided (e.g., consider only the bias term but not the variance), and ii.) when both these terms are accounted for, SHB and ASG do not always help. Specifically, for \textit{any} quadratic optimization, we obtain a lower bound on the sample complexity of SHB and ASG, accounting for both bias and variance, and show that the vanilla SGD can achieve the same bound. 
 ID: 672 | Bidirectional Attention as Mixture of Continuous Word Experts   
  
 Kevin Christian Wibisono, Yixin Wang  
   
    [link to video]   
   
  TL;DR:  This paper shows that bidirectional attention is equivalent to continuous bag of words with mixture-of-experts weights, and builds on this equivalence to argue about linear structures on the embeddings and give extensions to sequence and tabular data   Abstract:   
 Bidirectional attention has emerged as a key component of modern large language models, which includes self-attention mechanism, position encodings, and the MLM objective. Despite its widespread use, few studies have examined the inductive bias underlying bidirectional attention: What sets bidirectional attention models apart from its non-attention predecessors like CBOW? Are they completely different model classes? In this paper, we show that, upon reparameterization, bidirectional attention---namely training single-head single-layer attention with position encodings using the MLM objective---is equivalent to CBOW with mixture-of-experts weights, hence bidirectional attention as mixture of continuous word experts. This viewpoint enables us to characterize when embeddings from bidirectional attention exhibit a similar linear structure to its non-attention predecessors (e.g., word2vec, GloVe). It also suggests immediate extensions of bidirectional attention beyond text, including general non-textual sequence data and tabular data. Empirically, we demonstrate the attention-based approach to tabular data improves out-of-distribution generalization. 
 ID: 676 | Inference of a Rumor's Source in the Independent Cascade Model   
  
 Petra Berenbrink, Max Hahn-Klimroth, Dominik Kaaser, Lena Krieg, Malin Rau  

    Abstract:   
 We consider the so-called \emph{Independent Cascade Model} for rumor spreading or epidemic processes popularized by Kempe et al.\ (2003). In this model, a node of a network is the source of a rumor -- it is \emph{informed}. In discrete time steps, each informed node ``infects'' each of its uninformed neighbors with probability $p$. While many facets of this process are studied in the literature, less is known about the inference problem: given a number of infected nodes in a network, can we learn the source of the rumor? In the context of epidemiology this problem is often referred to as \emph{patient zero problem}. It belongs to a broader class of problems where the goal is to infer parameters of the underlying spreading model. In this work we present a maximum likelihood estimator for the rumor's source, given a snapshot of the process in terms of a set of active nodes $X$ after $t$ steps. Our results show that, for acyclic graphs, the likelihood estimator undergoes a phase transition as a function of $t$. We provide a rigorous analysis for two prominent classes of acyclic network, namely $d$-regular trees and Galton-Watson trees, and verify empirically that our heuristics work well in various general networks. 
 ID: 677 | A policy gradient approach for optimization of smooth risk measures   
  
 Nithia Vijayan, Prashanth L A  
   
    [link to video]   
   
    Abstract:   
 We propose policy gradient algorithms for solving a risk-sensitive reinforcement learning problem in on-policy as well as off-policy settings. We consider episodic Markov decision processes and model the risk using the broad class of smooth risk measures of the cumulative discounted reward. We propose two template policy gradient algorithms that optimize a smooth risk measure in on-policy and off-policy RL settings, respectively. We derive non-asymptotic bounds that quantify the rate of convergence to our proposed algorithms to a stationary point of the smooth risk measure. As special cases, we establish that our algorithms apply to the optimization of mean-variance and distortion risk measures, respectively. 
 ID: 679 | Interpretable Differencing of Machine Learning Models   
  
 Swagatam Haldar, Diptikalyan Saha, Dennis Wei, Rahul Nair, Elizabeth M. Daly  

  TL;DR:  We provide a framework to understand the similarities and differences between two models trained for the same task in an interpretable fashion.   Abstract:   
 Understanding the differences between machine learning (ML) models is of interest in scenarios ranging from choosing amongst a set of competing models, to updating a deployed model with new training data. In these cases, we wish to go beyond differences in overall metrics such as accuracy to identify where in the feature space do the differences occur. We formalize this problem of model differencing as one of predicting a dissimilarity function of two ML models‚Äô outputs, subject to the representation of the differences being human-interpretable. Our solution is to learn a Joint Surrogate Tree (JST), which is composed of two conjoined decision tree surrogates for the two models. A JST provides an intuitive representation of differences and places the changes in the context of the models‚Äô decision logic. Context is important as it helps users to map differences to an underlying mental model of an AI system. We also propose a refinement procedure to increase the precision of a JST. We demonstrate, through an empirical evaluation, that such contextual differencing is concise and can be achieved with no loss in fidelity over naive approaches. 
 ID: 688 | On the Relation between Policy Improvement and Off-Policy Minimum-Variance Policy Evaluation   
  
 Alberto Maria Metelli, Samuele Meta, Marcello Restelli  
   
    [link to video]   
   
    Abstract:   
 Off-policy methods are the basis of a large number of effective Policy Optimization (PO) algorithms. In this setting, Importance Sampling (IS) is typically employed as a what-if analysis tool, with the goal of estimating the performance of a target policy, given samples collected with a different behavioral policy. However, in Monte Carlo simulation, IS represents a variance minimization approach. In this field, a suitable behavioral distribution is employed for sampling, allowing diminishing the variance of the estimator below the one achievable when sampling from the target distribution. In this paper, we analyze IS in these two guises in the context of PO. We provide a novel view of off-policy PO, showing a connection between the policy improvement and variance minimization objectives. Then, we illustrate how minimizing the off-policy variance can, in some circumstances, lead to a policy improvement, with the advantage, compared with direct off-policy learning, of implicitly enforcing a trust region. Finally, we present numerical simulations on continuous RL benchmarks, with a particular focus on the robustness to small batch sizes. 
 ID: 695 | On the Role of Generalization in Transferability of Adversarial Examples   
  
 Yilin Wang, Farzan Farnia  

    Abstract:   
 Black-box adversarial attacks designing adversarial examples for unseen deep neural networks (DNNs) have received great attention over the past years. However, the underlying factors driving the transferability of black-box adversarial examples still lack a thorough understanding. In this paper, we aim to demonstrate the role of the generalization behavior of the substitute classifier used for generating adversarial examples in the transferability of the attack scheme to unobserved DNN classifiers. To do this, we apply the max-min adversarial example game framework and show the importance of the generalization properties of the substitute DNN from training to test data in the success of the black-box attack scheme in application to different DNN classifiers. We prove theoretical generalization bounds on the difference between the attack transferability rates on training and test samples. Our bounds suggest that operator norm-based regularization methods could improve the transferability of the designed adversarial examples. We support our theoretical results by performing several numerical experiments showing the role of the substitute network's generalization in generating transferable adversarial examples. Our empirical results indicate the power of Lipschitz regularization and early stopping methods in improving the transferability of designed adversarial examples. 
 ID: 696 | Greed is good: correspondence recovery for unlabeled linear regression   
  
 Hang Zhang, Ping Li  

    Abstract:   
 We consider the unlabeled linear regression reading as $\mathbf{Y} = \mathbf{\Pi}^{*}\mathbf{X}\mathbf{B}^* + \mathbf{W}$, where $\mathbf{\Pi}^{*}, \mathbf{B}^*$ and $\mathbf{W}$ represents missing (or incomplete) correspondence information, signals, and additive noise, respectively. Our goal is to perform data alignment between $\mathbf{Y}$ and $\mathbf{X}$, or equivalently, reconstruct the correspondence information encoded by $\mathbf{\Pi}^*$. Based on whether signal $\mathbf{B}^*$ is given a prior, we separately propose two greedy-selection based estimators, which both reach the mini-max optimality. Compared with previous works, our work $(i)$ supports partial recovery of the correspondence information; and $(ii)$ applies to a general matrix family rather than the permutation matrices, to put more specifically, selection matrices, where multiple rows of $\mathbf{X}$ can correspond to the same row in $\mathbf{Y}$. Moreover, numerical experiments are provided to corroborate our claims. 
 ID: 701 | Conditional Abstraction Trees for Sample-Efficient Reinforcement Learning   
 [oral]  
 Mehdi Dadvar, Rashmeet Kaur Nayyar, Siddharth Srivastava  
   
    [slides]   
   
    Abstract:   
 In many real-world problems, the learning agent needs to learn a problem‚Äôs abstractions and solution simultaneously. However, most such abstractions need to be designed and refined by hand for different problems and domains of application. This paper presents a novel top-down approach for constructing state abstractions while carrying out reinforcement learning (RL). Starting with state variables and a simulator, it presents a novel domain-independent approach for dynamically computing an abstraction based on the dispersion of Q-values in abstract states as the agent continues acting and learning. Extensive empirical evaluation on multiple domains and problems shows that this approach automatically learns abstractions that are finely-tuned to the problem, yield powerful sample efficiency, and result in the RL agent significantly outperforming existing approaches. 
 ID: 704 | Time-Conditioned Generative Modeling of Object-Centric Representations for Video Decomposition and Prediction   
  
 Chengmin Gao, Bin Li  

    Abstract:   
 When perceiving the world from multiple viewpoints, humans have the ability to reason about the complete objects in a compositional manner even when the object is completely occluded from partial viewpoints. Meanwhile, humans can imagine the novel views after observing multiple viewpoints. The remarkable recent advance in multiview object-centric learning leaves some problems: 1) the partially or completely occluded shape of objects can not be well reconstructed. 2) the novel viewpoint prediction depends on expensive viewpoint annotations rather than implicit view rules. This makes the agent fail to perform like humans. In this paper, we introduce a time-conditioned generative model for videos. To reconstruct the complete shape of the object accurately, we enhance the disentanglement between different latent representations: view latent representations are jointly inferred based on the Transformer and then cooperate with the sequential extension of Slot Attention to learn object-centric representations. The model also achieves the new ability: Gaussian processes are employed as priors of view latent variables for generation and novel-view prediction without viewpoint annotations. Experiments on multiple specifically designed synthetic datasets have shown that the proposed model can 1) make the video decomposition, 2) reconstruct the complete shapes of objects, and 3) make the novel viewpoint prediction without viewpoint annotations. 
 ID: 707 | Phase-shifted Adversarial Training   
 [spotlight]  
 Yeachan Kim, Seongyeon Kim, Ihyeok Seo, Bonggun Shin  

  TL;DR:  we present a novel approach to adversarial training, coined phase-shifted adversarial training, to learn the adversarial examples in an efficient manner.   Abstract:   
 While adversarial training (AT) has been considered an imperative component for safely deploying neural network-based applications, it comes with slow convergence and worse performance on clean samples. In this work, we analyze the behavior of neural networks when learning with adversarial samples through the lens of response frequency. Interestingly, we empirically observe that AT causes neural networks to have slow convergence to high-frequency information, resulting in highly oscillated predictions near each data. To learn high-frequency contents efficiently, we first prove that a universal phenomenon of frequency principle, i.e., \textit{lower frequencies are learned first}, still holds in AT. Built upon such theoretical ground, we present a novel approach to adversarial training, coined phase-shifted adversarial training (PhaseAT). In PhaseAT, the high-frequency components, which are susceptible factor for slow convergence, are adaptively shifted into the low-frequency range where the fast convergence occurs. For evaluations, we conduct the extensive experiments on CIFAR-10 and ImageNet with the adaptive attack carefully designed for reliable evaluation. Comprehensive results show that PhaseAT substantially improves the convergence for high-frequency information, thereby leading to the improved adversarial robustness in an efficient manner with better accuracy on clean samples. 
 ID: 713 | Regularized Online DR-Submodular Optimization   
  
 Pengyu Zuo, Yao Wang, Shaojie Tang  

  TL;DR:  This paper proposes a regularized online optimization problem with concave and DR-submodular regularizers, and presents efficient algorithms for both cases with theoretical performance guarantees.   Abstract:   
 The utilization of online optimization techniques is prevalent in many fields of artificial intelligence, enabling systems to continuously learn and adjust to their surroundings. This paper outlines a regularized online optimization problem, where the regularizer is defined on the average of the actions taken. The objective is to maximize the sum of rewards and the regularizer value while adhering to resource constraints, where the reward function is assumed to be DR-submodular. Both concave and DR-submodular regularizers are analyzed. Concave functions are useful in describing the impartiality of decisions, while DR-submodular functions can be employed to represent the overall effect of decisions on all relevant parties. We have developed two algorithms for each of the concave and DR-submodular regularizers. These algorithms are easy to implement, efficient, and produce sublinear regret in both cases. The performance of the proposed algorithms and regularizers has been verified through numerical experiments in the context of internet advertising. 
 ID: 722 | Mitigating Transformer Overconfidence via Lipschitz Regularization   
  
 Wenqian Ye, Yunsheng Ma, Xu Cao, Kun Tang  

    Abstract:   
 Though Transformers have achieved promising results in many computer vision tasks, they tend to be over-confident in predictions, as the standard Dot Product Self-Attention (DPSA) can barely preserve distance for the unbounded input domain. In this work, we fill this gap by proposing a novel Lipschitz Regularized Transformer (LRFormer). Specifically, we present a new similarity function with the distance within Banach Space to ensure the Lipschitzness and also regularize the term by a contractive Lipschitz Bound. The proposed method is analyzed with a theoretical guarantee, providing a rigorous basis for its effectiveness and reliability. Extensive experiments conducted on standard vision benchmarks demonstrate that our method outperforms the state-of-the-art single forward pass approaches in prediction, calibration, and uncertainty estimation. 
 ID: 731 | Risk-aware Curriculum Generation for Heavy-tailed Task Distributions   
  
 Cevahir Koprulu, Thiago D. Simão, Nils Jansen, ufuk topcu  
   
    [link to video]   
   
  TL;DR:  We propose a risk-aware curriculum generation algorithm that, given a heavy-tailed distribution over target tasks, generates two curricula: one to maximize the expected discounted return, and another to identify and over-sample rare and risky tasks.   Abstract:   
 Automated curriculum generation facilitates reinforcement learning (RL) by designing a sequence of tasks. It typically aims to optimize a distribution over tasks with exponentially bounded tails. In this setting, the agent might be underexposed to rare tasks, leading to a sub-optimal behavior. This issue is exacerbated in task distributions with heavy tails. To mitigate this issue, we propose a risk-aware curriculum generation algorithm that mixes two curricula: 1) a primary curriculum that aims to maximize the expected discounted return with respect to a distribution over target tasks, and 2) an auxiliary curriculum that identifies and over-samples rare tasks observed in the primary curriculum. Our empirical results in two domains with heavy-tailed distributions evidence that the proposed algorithm achieves higher returns in frequent as well as rare tasks compared to the state-of-the-art curriculum generation methods. 
 ID: 732 | Practical Privacy-Preserving Gaussian Process Regression via Secret Sharing   
  
 Jinglong Luo, Yehong Zhang, Jiaqi Zhang, Shuang Qin, Yue Yu, Hui Wang, Zenglin Xu  

  TL;DR:  This is the first work that considers to protect the privacy of a Gaussian process regression model via secret sharing.   Abstract:   
 Gaussian process regression (GPR) is a non-parametric model that has been used in many real-world applications that involve sensitive personal data (e.g., healthcare, finance, etc.) from multiple data owners. To fully and securely exploit the value of different data sources, this paper proposes a privacy-preserving GPR method based on secret sharing (SS), a secure multi-party computation (SMPC) technique. In contrast to existing studies that protect the data privacy of GPR via homomorphic encryption, differential privacy, or federated learning, our proposed method is more practical and can be used to preserve the data privacy of both the model inputs and outputs for various data-sharing scenarios (e.g., horizontally/vertically-partitioned data). However, it is non-trivial to directly apply SS on the conventional GPR algorithm, as it includes some operations whose accuracy and/or efficiency have not been well-enhanced in the current SMPC protocol. To address this issue, we derive a new SS-based exponentiation operation through the idea of ‚Äúconfusion-correction‚Äù and constructing a privacy-preserving matrix inversion algorithm based on Cholesky decomposition. More importantly, we theoretically analyze the communication cost and the security of the proposed SS-based operations. Empirical evaluation on two real-world datasets shows that our proposed method can achieve reasonable accuracy and efficiency under the premise of preserving data privacy. 
 ID: 741 | BeaU-PPG: Uncertainty-aware Heart Rate Estimation from PPG signals via Belief Propagation   
  
 Valentin Bieri, Paul Streli, Berken Utku Demirel, Christian Holz  

  TL;DR:  A Belief Propagation method for PPG-based heart rate estimation.   Abstract:   
 We present a novel learning-based method that achieves state-of-the-art performance on several heart rate estimation benchmarks extracted from photoplethysmography signals (PPG). We consider the evolution of the heart rate in the context of a discrete-time stochastic process that we represent as a hidden Markov model. We derive a distribution over possible heart rate values for a given PPG signal window through a trained neural network. Using belief propagation, we incorporate the statistical distribution of heart rate changes to refine these estimates in a temporal context. From this, we obtain a quantized probability distribution over the range of possible heart rate values that captures a meaningful and well-calibrated estimate of the inherent predictive uncertainty. We show the robustness of our method on eight public datasets with three-different cross-validation experiments. 
 ID: 747 | A Decoder Suffices for Query-Adaptive Variational Inference   
 [spotlight]  
 Sakshi Agarwal, Gabriel Hope, Ali Younis, Erik B. Sudderth  
   
    [link to video]   
   
    Abstract:   
 Deep generative models like variational autoencoders (VAEs) are widely used for density estimation and dimensionality reduction, but infer latent representations via amortized inference algorithms that require observations of all data dimensions. VAEs thus lack a key strength of probabilistic graphical models: the ability to infer posteriors for test queries with arbitrary structure. We demonstrate that many prior methods for imputation with VAEs are costly and ineffective, and achieve superior performance via query-adaptive variational inference (QAVI) algorithms based directly on the generative decoder. By analytically marginalizing arbitrary sets of missing features, and optimizing expressive posteriors including mixtures and density flows, our non-amortized QAVI algorithms achieve excellent performance while avoiding expensive model retraining. On standard image and tabular datasets, our approach substantially outperforms prior methods in the plausibility and diversity of imputations. We also show that QAVI effectively generalizes to recent hierarchical VAE models for high-dimensional images. 
 ID: 748 | Incentivizing honest performative predictions with proper scoring rules   
  
 Caspar Oesterheld, Johannes Treutlein, Emery Cooper, Rubi Hudson  

  TL;DR:  Oracle AI, proper scoring rules, self-fulfilling prophecy, performative prediction, AI safety   Abstract:   
 Proper scoring rules incentivize experts to accurately report beliefs, assuming predictions cannot influence outcomes. We relax this assumption and investigate incentives when predictions are performative, i.e., when they can influence the outcome of the prediction, such as when making public predictions about the stock market. We say a prediction is a fixed point if it accurately reflects the expert‚Äôs beliefs after that prediction has been made. We show that in this setting, reports maximizing expected score generally do not reflect an expert‚Äôs beliefs, and we give bounds on the inaccuracy of such reports. We show that, for binary predictions, if the influence of the expert‚Äôs prediction on outcomes is bounded, it is possible to define scoring rules under which optimal reports are arbitrarily close to fixed points. However, this is impossible for predictions over more than two outcomes. We also perform numerical simulations in a toy setting, showing that our bounds are tight in some situations and that prediction error is often substantial (greater than 5-10%). Lastly, we discuss alternative notions of optimality, including performative stability, and show that they incentivize reporting fixed points. 
 ID: 750 | Universal Graph Contrastive Learning with a Novel Laplacian Perturbation   
  
 Taewook Ko, Yoonhyuk Choi, Chong-Kwon Kim  

  TL;DR:  We introcued a novel universal graph contrastive learning by defining a Laplacian peturbation.   Abstract:   
 Graph Contrastive Learning (GCL) is an effective method for discovering meaningful patterns in graph data. By evaluating diverse augmentations of the graph, GCL learns discriminative representations and provides a flexible and scalable mechanism for various graph mining tasks. This paper proposes a novel contrastive learning framework based on Laplacian perturbation. The framework employs a complex Hermitian adjacency matrix which enables the application of a novel graph Laplacian. Unlike existing GCL methods, the proposed framework is not restricted to specific graph types and enjoys a wider range of applicability. We demonstrate that a spectral graph convolution based on the Laplacian extracts the representations of diverse graph types successfully. Our extensive experiments on a variety of real-world datasets, covering multiple graph types, show that the proposed model outperforms state-of-the-art baselines in both node classification and link sign prediction tasks. 
 ID: 753 | Do we become wiser with time? On causal equivalence with tiered background knowledge.   
  
 Christine W. Bang, Vanessa Didelez  
   
    [link to video]   
   
  TL;DR:  We show formally why and when incorporating tiered background knowledge into equivalence classes of DAGs leads to considerable gains in informativeness and computational efficiency.   Abstract:   
 Equivalence classes of DAGs (represented by CPDAGs) may be too large to provide useful causal information. Here, we address incorporating tiered background knowledge yielding restricted equivalence classes represented by ‚Äòtiered MPDAGs‚Äô. Tiered knowledge leads to considerable gains in informativeness and computational efficiency: We show that construction of tiered MPDAGs only requires application of Meeks 1st rule, and that tiered MPDAGs (unlike general MPDAGs) are chain graphs with chordal components. This entails simplifications e.g. of determining valid adjustment sets for causal effect estimation. Further, we characterise when one tiered ordering is more informative than another, providing insights into useful aspects of background knowledge. 
 ID: 756 | Structure-aware robustness certificates for graph classification   
  
 Pierre Osselin, Henry Kenlay, Xiaowen Dong  

  TL;DR:  Randomized smooothing with anisotropic noise is introduced in the context of graph classification leading to more flexible robustness certificates.   Abstract:   
 Certifying the robustness of a graph-based machine learning model poses a critical challenge for safety. Current robustness certificates for graph classifiers guarantee output invariance with respect to the total number of node pair flips (edge addition or edge deletion), which amounts to an $l_{0}$ ball centred on the adjacency matrix. Although theoretically attractive, this type of isotropic structural noise can be too restrictive in practical scenarios where some node pairs are more critical than others in determining the classifier's output. The certificate, in this case, gives a pessimistic depiction of the robustness of the graph model. To tackle this issue, we develop a randomised smoothing method based on adding an anisotropic noise distribution to the input graph structure. We show that our process generates structural-aware certificates for our classifiers, whereby the magnitude of robustness certificates can vary across different pre-defined structures of the graph. We demonstrate the benefits of these certificates in both synthetic and real-world experiments. 
 ID: 757 | Scaling Integer Arithmetic in Probabilistic Programs   
  
 William Cao, Poorva Garg, Ryan Tjoa, Steven Holtzen, Todd Millstein, Guy Van den Broeck  

  TL;DR:  A binary encoding combined with knowledge compilation allows for scaled inference on integer distributions.   Abstract:   
 Probabilistic programming languages (PPLs) allow a program to define a probabilistic model. Within the framework of a programming language, they provide the ability to declare random variables and condition on complex events. Much like traditional programming languages, where integers are perhaps the most common data type, one natural feature of PPLs is their ability to manipulate distributions over integers. Although most PPLs provide the ability to express distributions over integers, their support for inference over these distributions is limited. Most approaches essentially reduce to enumeration of all possible values, a strategy that does not scale well, or to general-purpose sampling. Our insight is that there is structure in arithmetic that these approaches are not using. We present a binary encoding strategy for random integers where binary-number bits are replaced by Boolean functions of random coin flips. This binary encoding then enables the circuit compilation approach to probabilistic inference to naturally exploit the structure behind arithmetic operations. This inference strategy scales to much larger integer distributions with arithmetic, further allowing us to support more language constructs such as parametrised flips and Beta priors, which enables Bayesian parameter learning from incomplete data. 
 ID: 761 | Boosting AND/OR-Based Computational Protein Design: Dynamic Heuristics and Generalizable UFO   
  
 Bobak Pezeshki, Radu Marinescu, Alexander Ihler, Rina Dechter  
   
    [link to video]   
   
  TL;DR:  This work presents several improvements upon existing computational protein re-design algorithm, AOBB-K*, noticeably improving scalability and leading to schemes that can be generalized to other well known tasks over graphical models.   Abstract:   
 Scientific computing has experienced a boom empowered by advancements in technologies such as neural networks. However, certain important tasks are less amenable to these technologies, benefiting from innovations to traditional inference schemes. One such task is protein re-design. Recently a new re-design algorithm, AOBB-K*, was introduced and was competitive with state-of-the art BBK* on small protein re-design problems that assume rigid backbone and rotamers. However, AOBB-K* suffered scalability issues. In this work, we address issues that limited AOBB-K* and present three new variants: AOBB-K*-b (boosted), AOBB-K*-DH (with dynamic heuristics), and AOBB-K*-UFO (with underflow optimization) that noticeably improve scalability. From their founding principles, we also present generalized schemes useful for other well known inference tasks. 
 ID: 764 | Robust Gaussian Process Regression with the Trimmed Marginal Likelihood   
 [spotlight]  
 Daniel Andrade, Akiko Takeda  

  TL;DR:  Optimizing the marginal likelihood for outlier detection with an efficient projected gradient descent method.   Abstract:   
 Accurate outlier detection is not only a necessary preprocessing step, but can itself give important insights into the data. However, especially, for non-linear regression the detection of outliers is non-trivial, and actually ambiguous. We propose a new method that identifies outliers by finding a subset of data points $T$ such that the marginal likelihood of all remaining data points $S$ is maximized. Though the idea is more general, it is particular appealing for Gaussian processes regression, where the marginal likelihood has an analytic solution. While maximizing the marginal likelihood for hyper-parameter optimization is a well established non-convex optimization problem, optimizing the set of data points $S$ is not. Indeed, even a greedy approximation for optimizing the set of data points $S$ is computationally challenging due to the high cost of evaluating the marginal likelihood. As a remedy, we propose an efficient projected gradient descent method with provable convergence guarantees. Moreover, we also establish the breakdown point when jointly optimizing hyper-parameters and $S$. For various datasets and types of outliers, our experiments demonstrate that the proposed method can improve outlier detection and robustness when compared with several popular alternatives, like the student-t likelihood. 
 ID: 773 | Finding Invariant Predictors Efficiently via Causal Structure   
  
 Kenneth Lee, Md Musfiqur Rahman, Murat Kocaoglu  

  TL;DR:  We develop a sound algorithm for finding invariant predictors that runs in polynomial time and yields predictive performance that is comparable to the existing work.   Abstract:   
 One fundamental problem in machine learning is out-of-distribution generalization. A method named the surgery estimator incorporates the causal structure in the form of a directed acyclic graph (DAG) to find predictors that are invariant across target domains using distributional invariances via Pearl‚Äôs do-calculus. However, finding a surgery estimator can take exponential time as the current methods need to search through all possible predictors. In this work, we first provide a graphical characterization of the identifiability of conditional causal queries. Next, we leverage this characterization together with a greedy search step to develop a polynomial-time algorithm for finding invariant predictors using the causal graph. Given the correct causal graph, our method is guaranteed to find at least one invariant predictor, if it exists. We show that our proposed algorithm can significantly reduce the run-time both in simulated and semi-synthetic data experiments and have predictive performance that is comparable to the existing work that runs in exponential time. 
 ID: 775 | Exploiting Long-Range Influences in Learning Generalized Neural Policies for RDDL Relational MDPs   
  
 Vishal Sharma, Daman Arora, Mausam ., Parag Singla  

  TL;DR:  We propose a novel method for handling long range dependencies in neural policies for RDDL RMDPs   Abstract:   
 We focus on the learning of generalized neural policies for Relational Markov Decision Processes (RMDPs) expressed in RDDL. Recent work first converts the instances of a relational domain into an instance graph, and then trains a Graph Attention Network (GAT) of fixed depth with parameters shared across instances to learn a state representation, which can be decoded to get the policy Sharma et al. [2022]. Unfortunately, this approach struggles to learn policies that exploit long-range dependencies -- a fact we formally prove in this paper. As a remedy, we first construct a novel influence graph characterized by edges capturing one-step influence (dependence) between nodes based on the transition model. We then define influence distance between two nodes as the shortest path between them in this graph -- a feature we exploit to represent long-range dependencies. We show that our architecture, referred to as Symbolic Influence Network (SINet), with its distance-based features, does not suffer from the representational issues faced by earlier approaches. Extensive experimentation demonstrates that we are competitive with existing baselines on 12 standard IPPC domains, and perform significantly better on six additional domains (including IPPC variants), designed to test a model's capability in capturing long-range dependencies. Further analysis shows that SINet automatically learns to focus on nodes that have key information for representing policies that capture long-range dependencies. 
 ID: 777 | Heavy-tailed Linear Bandit with Huber Regression   
  
 Minhyun Kang, Gi-Soo Kim  

    Abstract:   
 Linear bandit algorithms have been extensively studied and have shown successful in sequential decision tasks despite their simplicity. Many algorithms however work under the assumption that the reward is the sum of linear function of observed contexts and a sub-Gaussian error. In practical applications, errors can be heavy-tailed, especially in financial data. In such reward environments, algorithms designed for sub-Gaussian error may underexplore, resulting in suboptimal regret. In this paper, we propose a novel algorithm for linear bandits with heavy-tailed errors. The proposed algorithm utilizes Huber regression. When the $(1+\delta)$-th moment of the error is bounded by a constant, we show that the high-probability upper bound of the regret is $O(\sqrt{d}T^{\frac{1}{1+\delta}}(\log T)^{\frac{\delta}{1+\delta}})$, where $d$ is the dimension of context variables, $T$ is the time horizon, and $\delta\in (0,1]$. This bound improves on the state-of-the-art regret bound of the Median of Means and Truncation algorithm by a factor of $\sqrt{\log T}$ and $\sqrt{d}$ for the case where the time horizon $T$ is unknown. We also remark that when $\delta=1$, the order is the same as the regret bound of linear bandit algorithms designed for sub-Gaussian errors. We support our theoretical findings with synthetic experiments. 
 ID: 780 | Best Arm Identification in Rare Events   
  
 Anirban Bhattacharjee, Sushant Vijayan, Sandeep Kumar Juneja  

  TL;DR:  We consider bandit problems where arms return rewards sporadically, and examine interesting approximations that speed up existing best arm algorithms.   Abstract:   
 We consider the best arm identification (BAI) problem in the stochastic multi-armed bandit framework where each arm has a tiny probability of realizing large rewards while with overwhelming probability the reward is zero. A key application of this framework is in online advertising where click rates of advertisements could be a fraction of a single percent and final conversion to sales, while highly profitable, may again be a small fraction of the click rates. Lately, algorithms for BAI problems have been developed that minimise sample complexity while providing statistical guarantees on the correct arm selection. As we observe, these algorithms can be computationally prohibitive. We exploit the fact that the reward process for each arm is well approximated by a Compound Poisson process to arrive at algorithms that are faster, with a small increase in sample complexity. We analyze the problem in an asymptotic regime as rarity of reward occurrence reduces to zero, and reward amounts increase to infinity. This helps illustrate the benefits of the proposed algorithm. It also sheds light on the underlying structure of the optimal BAI algorithms in the rare event setting. 
 ID: 789 | Exact Count of Boundary Pieces of ReLU Classifiers: Towards the Proper Complexity Measure for Classification   
  
 Pawel Piwek, Adam Klukowski, Tianyang Hu  

  TL;DR:  We propose a method to count the exact number of boundary pieces of ReLU classifiers and empirically demonstrate distinctive features of such boundary complexity vs other function complexities.   Abstract:   
 Classic learning theory suggests that proper regularization is the key to good generalization and robustness. In classification, current training schemes only target the complexity of the classifier itself, which can be misleading and ineffective. Instead, we advocate directly measuring the complexity of the decision boundary. Existing literature is limited in this area with few well-established definitions of boundary complexity. As a proof of concept, we start by analyzing ReLU neural networks, whose boundary complexity can be conveniently characterized by the number of affine pieces. With the help of tropical geometry, we develop a novel method that can explicitly count the exact number of boundary pieces, and as a by-product, the exact number of total affine pieces. Numerical experiments are conducted and distinctive properties of our boundary complexity are uncovered. First, the boundary piece count appears largely independent of other measures, e.g., total piece count, and $l_2$ norm of weights, during the training process. Second, the boundary piece count is negatively correlated with robustness, where popular robust training techniques, e.g., adversarial training or random noise injection, are found to reduce the number of boundary pieces. 
 ID: 793 | Efficient Learning of Minimax Risk Classifiers in High Dimensions   
  
 Kartheek Bondugula, Santiago Mazuelas, Aritz Pérez  
   
    [link to video]   
   
  TL;DR:  In this paper, we leverage constraint generation methods to obtain an efficient learning algorithm for the recently proposed minimax risk classifiers (MRCs).   Abstract:   
 High-dimensional} data is common in multiple areas, such as health care and genomics, where the number of features can be hundreds of thousands. In such scenarios, the large number of features often lead to inefficient learning. Constraint generation methods have recently enabled efficient learning of L1-regularized support vector machines (SVM). In this paper, we leverage such methods to obtain an efficient learning algorithm for the recently proposed minimax risk classifiers (MRC). The proposed iterative algorithm also provides a sequence of worst-case error probabilities and performs feature selection. Experiments on multiple high-dimensional datasets show that the proposed algorithm is efficient in high-dimensional scenarios. In addition, the worst-case error probability provides useful information about the classifier performance, and the features selected by the algorithm are competitive with the state-of-the-art. 
 ID: 797 | Inference for Probabilistic Dependency Graphs   
 [spotlight]  
 Oliver Ethan Richardson, Joseph Halpern, Christopher De Sa  

  TL;DR:  we give the first inference algorithm for probabilistic dependency graphs, prove that it is correct and runs in polynomial time, implement it, and evaluate its performance.   Abstract:   
 Probabilistic dependency graphs (PDGs) are a flexible class of probabilistic graphical models, subsuming Bayesian Networks and Factor Graphs. They can also capture inconsistent beliefs, and provide a way of measuring the degree of this inconsistency. We present the first tractable inference algorithm for PDGs with discrete variables, making the asymptotic complexity of PDG inference similar that of the graphical models they generalize. The key components are: (1) the observation that PDG inference can be reduced to convex optimization with exponential cone constraints, (2) a construction that allows us to express these problems compactly for PDGs of boundeed treewidth, for which we needed to further develop the theory of PDGs, and (3) an appeal to interior point methods that can solve such problems in polynomial time. We verify the correctness and time complexity of our approach, and provide an implementation of it. We then evaluate our implementation, and demonstrate that it outperforms baselines approaches. 
 ID: 804 | Fast Proximal Gradient Descent for Support Regularized Sparse Graph   
 [spotlight]  
 Dongfang Sun, Yingzhen Yang  

  TL;DR:  We propose Support Regularized Sparse Graph (SRSG) and a fast proximal gradient descent method to solve the non-convex optimization problem of SRSG with the convergence matching the Nesterov's optimal convergence rate.   Abstract:   
 Sparse graphs built by sparse representation has been demonstrated to be effective in clustering high-dimensional data. Albeit the compelling empirical performance, the vanilla sparse graph ignores the geometric information of the data by performing sparse representation for each datum separately. In order to obtain a sparse graph aligned with the local geometric structure of data, we propose a novel Support Regularized Sparse Graph, abbreviated as SRSG, for data clustering. SRSG encourages local smoothness on the neighborhoods of nearby data points by a well-defined support regularization term. We propose a fast proximal gradient descent method to solve the non-convex optimization problem of SRSG with the convergence matching the Nesterov's optimal convergence rate of first-order methods on smooth and convex objective function with Lipschitz continuous gradient. Extensive experimental results on various real data sets demonstrate the superiority of SRSG over other competing clustering methods. 

  The list above is provisional. Conference proceedings will be published by PMLR  .    

  Sponsors

51. APORS_0 conference:
Skip to content  Mobile: +63927 877 5219   secretariat@orsp.org.ph     

  Home 
  About | Mission & Vision 
  Officers 
  History 
  History Photos 
  ORSP Corps 
  Membership Application 
  Online Resources | Calendar 
  ORSP Technical Forum Series 
  Newsletter 
  Links 
  Members Only | 14th National Conference Materials 
  2019 National Conference Speakers Talk 
  Speakers Presentation 
  PJOR 
  August 2014 Workshop Materials 
  5th National Conference Materials 
  6th National Conference Materials 
  7th National Conference Materials 
  8th National Conference Materials 
  9th National Conference Materials 
  10th National Conference Materials 
  12th National Conference Materials 
  Gallery 
  Contact Us 

 13th Triennial International Conference of the Association of Asia Pacific Operational Research Societies (APORS)  

 June 4, 2021  November 23, 2022   orspadmin      
 Post navigation  

 Theme:  Onward to Recovery through Operations Research  
 Date:  November 9-12, 2022  
  Venue: Eastwood Richmonde Hotel, Eastwood City, Bagumbayan, Quezon City, Philippines 1110  
 Eastwood Richmonde Hotel | Official Hotel Website | Hotel in Eastwood City : Eastwood Richmonde Hotel   
  
  Hosted by The Operations Research Society of the Philippines (ORSP)   
 INVITATION   
 While the massive negative short term impact caused by the pandemic has been widely felt, the long term impact brought about by border restrictions and lockdown measures remains uncertain. This conference will provide a forum to discuss the role that Operations Research (OR) has played or could play on the path to Asia-Pacific regional and world recovery. How has the experience affected organizational decision-making process? Has the adoption of OR techniques impacted operations and business resilience?  
   
  With the theme Onwards to Recovery through OR   , the conference seeks to bring together OR researchers, academicians and practitioners, whose collective work has sustained OR contribution to decision-making and whose current work is expected to play a vital role in surmounting challenges on the road to recovery from the global pandemic.  
   
  The APORS 13th Conference  aims to provide a forum where:  
   
  • Practitioners will share their experiences on the problems, methodologies and outcomes of applying OR to solve real-world problems in Asia Pacific and beyond;  
  • Decision-makers will share new applications of OR in non-traditional areas;  
  • Researchers will present their findings dealing with the theoretical, computational, and application aspects of OR;  
  • OR workers will discuss pertinent academic-, theoretical- and application- oriented issues;  
  • Decision-makers could gain insights from experiences of others who have benefited from the use of OR in the public and private sectors in different countries; and  
  • Participants will be given the opportunity to exchange ideas on how OR and Analytics can help deal with issues that will contribute to economic resurgence in the different regions of Asia Pacific and beyond.  
  • Everyone can share unique experiences, challenges, and OR-related solutions in surviving and rising from the global pandemic.  
 INVITED SESSION   
   
  An Invited Session consists of a presentation session of six papers on a specific topic relevant to the themes of the conference, organized as half or full day mini-conference. We invite professors and practitioners of OR who have a special interest in a specific conference topic to take responsibility for a session, gathering papers from a range of research expertise around the world.  
   
  The organizer of an invited session shall:  
 Select a topic of interest to themselves and to conference delegates. 
  Obtain four ​papers on this topic. If there are sufficient papers the session may become a workshop. 
  Ensure the papers are submitted through the APORS EasyChair online review system. Authors will just have to indicate the name of the invited session where the paper will be under. 
  Coordinate with the APORS Conference Technical Committee on the review and acceptance of all papers that will be submitted under the invited session. 
  Ensure the final versions of the publication files for the papers are uploaded onto EasyChair before the deadline. 
  Attend the conference and chair the session. 
  Researchers who would like to organize one or more Sessions on topics falling within the scope of the conference are invited to submit a proposal for consideration to include session title, description, chair and contact details, and short CV of Chair (s).  
   
  We will be honored to have you organize and chair an invited session. Should you be willing to, please fill up the information listed in this form.   
 KEYNOTE AND INVITED SPEAKERS   
 Prominent OR practitioners, academicians, and businessmen have been invited by the organizers to deliver keynote speeches. Speakers and delegates from different parts of the world will share their work in the parallel sessions.  
   
  Click here to view the Plenary Speakers and their abstracts.    
 CONFERENCE TOPICS   
  Submissions of papers aligned with the Conference Theme, Onward to Recovery through OR   , in the following areas are welcome: Banking and Finance, Complexity and Approximation, Control Theory, Customer Relationship Management, Decision Support Systems, Economic Modeling, Energy Applications, Expert Systems and Neural Networks, Forecasting, Healthcare, Information Systems, Inventory, Knowledge Engineering and Management, Logistics and Distribution Management, Marketing, Mathematical Programming Modeling for Optimization, Modeling Systems and Languages, Production, Project Management and Scheduling, Queuing Systems, Soft OR, Strategic Planning and Management, Supply Chain Management, and Transport. Papers reporting original and unpublished research results and experience are solicited. Guidelines for abstract submission follow.   
 ABSTRACT SUBMISSION   
  Abstracts must be written in English. Each attendee is allowed to present ONE paper at the  
  conference.  
   
  The abstract should be typed in English, should not include mathematical notations, and must  
  contain the following:  
   
  • Paper/proposal title;  
  • Abstract of not more than 500 words (no formulas or mathematical notation allowed);  
  • Author(s) name(s), organization, full mailing address, email address, with an indication of  
  author(s) presenting the paper; and  
  • Topic (at most three, chosen from the Conference Topics List) under which paper falls and  
  additional topics if not included in the list.  
   
  Email abstracts to https://easychair.org/conferences/?conf=apors2022   
  Please direct all other inquiries to secretariat@orsp.org.ph   
 PUBLICATION OF CONTRIBUTED PAPERS   
 Authors are encouraged to submit extended versions of their manuscripts or their full papers to the Asia Pacific Journal of Operations Research (ISSN (print): 0217-5959 | ISSN (online): 1793-7019) ( http://orss.org.sg/apjor.html  ).  
 The paper will go through the regular review process of the journal. The APJOR Editors had been alerted to expect submissions from the APORS 2022.  
 PROGRAM SCHEDULE   
  Nov 9 : City Tour / Welcome cocktails in the evening  
  Nov 10 -12 : Conference  
  Nov 11 evening : Evening Banquet  
  From Nov 13 : Post Conference Optional Tours  
 IMPORTANT DATES in 2022   
   
  Abstracts:    
  Submission of abstracts – EXTENDED  : 1 February to 31 August 2022  
  Deadline for receipt of abstracts (500 words): 31 August 2022  
  Notification of acceptance : TBC  
   
  Registration:    
  Registration Opens : 1 April 2022  
  Early bird Registration Deadline : 31 August 2022  
  Speaker registration and payment deadline : 15 September 2022  
 REGISTRATION FEES   
   The following onsite fees entitles the attendee to participation in the City Tour, Cocktails, Banquet and Conference materials. Online participants could present/ get access to all the sessions.  
 TO REGISTER   
 ON SITE PARTICIPANTS   
 ON SITE Local ORSP Members, | click here 
  ON SITE Local non-ORSP members, | click here 
  ON SITE Local Student participants, | click here 
  ON SITE Foreign Delegates, | click here 
  ON SITE Foreign Students, | click here 
  VIRTUAL PARTICIPANTS   
 VIRTUAL Local ORSP Members, | click here 
  VIRTUAL Local non-ORSP members, | click here 
  VIRTUAL Local Student participants, | click here 
  VIRTUAL Foreign Delegates, | click here 
  VIRTUAL Foreign Students, | click here 
  To apply for membership,  click here.   
 Payment Methods   
 Bank Deposit 
  GCash Number: 0917 863 4196 (Marie Shella Mariscal) 
  If paying by credit card and means other than above, | click here | . Payment via this mode has a service fee of 3.5%. 
  If you are an ORSP member, make sure your membership fees are paid for the year. 
  For more information and inquiries, please contact Jenny Alzate, viber No.: +63 917 138 3653, mobile +63 927 877 5219; e-mail secretariat@orsp.org.ph  or visit the website www.apors.org   
 ACCOMMODATION   
 For those booking at Richmonde Hotel, click this link eastwoodrichmondehotel.com.ph   and enter promo code APORS2022 to get the special rate. The special rates are as follows:  
  
 Room Type | Single Occupancy 
 Superior Room | Php 3,950.00 nett 
 Deluxe Room | Php 4,550.00 nett 
 One Bedroom Suite | Php 6,050.00 nett 
  
  Alternative accommodation at lower rates at a venue within walking distance (15 minutes crossing a pedestrian bridge) is available at https://www.microtelacropolis.com    
   
  Please contact secretariat@orsp.org.ph   for rates and reservation.  
 Guide on Arrival and Quarantine Procedures    
       Complete info can be found here:  Arriving In The Philippines (philippineairlines.com)    
   
  For US Citizens, please visit this link:  
   COVID-19 and Travel Information | Last Updated: August 22, 2022 – U.S. Embassy in the Philippines (usembassy.gov)    
 Covid 19 Protocols for Visiting the Philippines   
 COVID 19 Protocol  for entering the Philippines is contained in  IATF 168 issued in May 2022 can be accessed in this link: https://doh.gov.ph/sites/default/files/health-update/20220526-IATF-Resolution-168-RRD.pdf   
 Highlighted below are provisions that delegates may find useful.  
 Section A. Foreign Nationals Entering the Philippines must comply with the applicable visa requirements and immigration entry and departure formalities; and provided further they   
 Are fully vaccinated against COVID-19, as defined in Section 2 below, except only for minor children below (12) years of age travelling with their fully-vaccinated foreign parent/s; 
  Carry/possess any of the following acceptable proof of COVID-19 vaccination, which shall be presented prior to departing/boarding from the country of origin/port of embarkation and upon arrival in the country: 
  World Health Organization International Certificate of Vaccination and Prophylaxis; 
  VaxCertPH; 
  National or state manual/digital vaccination certificate of the country/foreign government; 
  Other proof of vaccination permitted by the IATF 
  Fully vaccinated Filipino Nationals may enter the Philippines provided that they carry/possess an acceptable proof of vaccination, as set out in Section A (1)(b) above.   
 For Filipinos and Foreign Delegates: All inbound passengers, whether Filipinos or foreign nationals, shall register with the One Health Pas ( https://onehealthpass.com.ph/  )   prior to arrival in the Philippines unless exempted under relevant IATF Resolutions.   
 Please read the whole IATF document in case some provisions apply to you.  
 Additional information:   
 Wearing of masks in public places is required. Please have one on hand when you go out of the airport.   
 For Pre and Post Conference Tours    
 Discover more fun! | Department of Tourism Philippines   

 Latest News    
  
 Post navigation  
 Upcoming Webinars    
 Technologies for the Changing Logistics Landscape Discussed in 2nd Quarter ORSP Webinar    

 News and Updates  
 September 2024 Technical Forum: Environmental Sustainability 
  2024 National Conference Call for Papers: 15th National Conference Operations Research and Analytics: Empowering Decision-Making Across Industries and Sectors 
  June 2024 Technical Workshop: The Digital Entrepreneur: Setting Up Your Company with ChatGPT 
  14th National Conference: Data-Driven OR and Analytics for National Resilience and Sustainability 
  September 2023 Technical Forum: Data Science and Analytics – Operations Research Tools in Action 
  June 2023 Technical Workshop: ChatGPT and Python: A Productivity and Machine Learning / Operations Research Powerhouse 
  October 2022 Webinar: Political Manipulation through Social Media 
  June 2022 Online Technical Forum Series: Understanding Cryptocurrencies in the Philippines 
   
 About This Site  
 This may be a good place to introduce yourself and your site or include some credits.  

 Search  
 Search for:       

 © 2024 Operations Research Society of the Philippines (ORSP)   Theme by Puro

52. CSIT_1 conference:
The requested URL was rejected. Please consult with your administrator.  
   
  Your support ID is: < 8203162004121767793>  
   
  [Go Back]

53. AMTA_0 conference:
menu   close    search     
  Home 
  Machine Translation 
  Resources 
  Events 
  About Us 
  Contact 
  Login 

 Home  
   
 Home 
  Machine Translation 
  Resources 
  Events 
  About Us 
  Contact 
  Login 
    
 search   close    search     

  Learn More | Sep 30, 2024 – Oct 2, 2024 

 MT  News  

 AMTA 2024: Main Conference Program | August 9, 2024 | – | AMTA 2024 Program (All times in Central Daylight Savings) Register Already Registered? Enter Event Having trouble with the… Read more 

 AMTA 2024: Virtual Tutorial Day Program | August 9, 2024 | – | AMTA 2024 Program Virtual Tutorial Day Wednesday, 18 September 2024 (All times in Central Daylight Savings) Register Already Registered?… Read more 

 Registration for AMTA 2024 now open | July 29, 2024 | – | The stars are aligning for a great AMTA 2024 conference! This year marks the 30th anniversary of the first AMTA… Read more 

 *Deadline Extended* Final Call for Papers & Presentations | June 5, 2024 | – | Association for Machine Translations in the Americas Final Call for Papers & Presentations For AMTA 2024, a three-day event… Read more 

 MT for Translators | – | During the last couple of years, machine translation post-editing has become one of the hottest most discussed topics in the translation industry as evidenced by conferences, forums and webinars. Read more 
  MT as part of a translation service | – | Machine translation as a service can be either a byproduct for some teams and companies that develop MT technology for above mentioned use cases, or they focus on MT technology development Read more 
  Government MT Users | – | Features of machine translation (MT) implementations and project efforts in official settings, regardless of jurisdiction, are guided by at least three attributes common to administration of authority. Read more 

 NEW IN MACHINE TRANSLATION?    

 BOOKSHELF    

 BECOME A MEMBER!    

 Previous Conference Proceedings & Recordings    
  Subscribe to AMTA News & Conference Updates    
  Books on Machine Translation    
  Contact Us     

 Sep 30, 2024 - Oct 2, 2024  

 MT  News  

 AMTA 2024: Main Conference Program | August 9, 2024 | - | AMTA 2024 Program (All times in Central Daylight Savings) Register Already Registered? Enter Event Having trouble with the… Read more 
  AMTA 2024: Virtual Tutorial Day Program | August 9, 2024 | - | AMTA 2024 Program Virtual Tutorial Day Wednesday, 18 September 2024 (All times in Central Daylight Savings) Register Already Registered?… Read more 
  Registration for AMTA 2024 now open | July 29, 2024 | - | The stars are aligning for a great AMTA 2024 conference! This year marks the 30th anniversary of the first AMTA… Read more 
  *Deadline Extended* Final Call for Papers & Presentations | June 5, 2024 | - | Association for Machine Translations in the Americas Final Call for Papers & Presentations For AMTA 2024, a three-day event… Read more 

 Previous Conferences      

 Subscribe to AMTA News & Conference Updates      

 Books on Machine Translation      

 Contact Us      

  Sitemap  
   
 AMTA is a 501(c)3 non-profit educational association.  

       Home 
  Machine Translation 
  Resources 
  Events 
  About Us 
  Contact 
  Login

54. APORS_1 conference:
INFORMS.org 
  Certified Analytics Professional 
  PubsOnline 
  Career Center 
  2025 INFORMS Analytics+ Conference 

 Skip main navigation (Press Enter).    

 Log in    
   
 Toggle navigation         
     Search Options        

 Log in    

 Home 
  Communities | All Communities 
  My Communities 
  Discussions 
  Directory | Member Directory 
  Events 
  Discussion Posts 
  Browse | Library Entries 
  Blogs 

                     INFORMS Open Forum  

 ×     

  Back to discussions    
 Expand all  |  Collapse all      

 Online Resources for DCs (IFORS)  

 1.  Online Resources for DCs (IFORS)   
  0  Like             Gerhard-Wilhelm Weber  Connect Champion         Posted 5 days ago      Options Dropdown    
    To access information regarding IFORS Developing Countries resources, its regular updates – and to submit your possible "free" (not copyright protected) material, you may occasionally visit the link:   
    
  http://ifors.org/developing_countries/index.php?title=Main_Page     .   
  With this open online resources page we aim to provide a platform to make research and applications of OR widely accessible to the entire OR community including researchers, academicians and scholars in the Developing Countries (DCs).   
  For this purpose we invite scholarly contributions spanning across all areas and sectors ranging from arts and science, to communication and education.   
  The International Federation of Operational Research Societies ( https://www.ifors.org     ) is a 65-year-old organization which is currently composed of 54 national societies. Regional Groups of are: ALIO (The Latin American Ibero Association on Operations Research), APORS (The Association of Asian-Pacific Operational Research Societies), EURO (The Association of European Operational Research Societies), NORAM (The Association of North American Operations Research Societies). conferences are held every three years. The conference 2023 was held very successfully in Santiago, Chile; the next exciting IFORS conference will be celebrated in 2026 in Vienna. Please visit the following link for details regarding the same: https://www.ifors2026.at/home/     .   
  Thank you very much for your attention. We look forward to your enthusiastic participation and scholarly contributions. 

 ×  New Best Answer  
   
 This thread already has a best answer. Would you like to mark this message as the new best answer?    
   No    

 Related Content  
 Online resources for DCs --- contribution added --- IFORS   

 Gerhard-Wilhelm Weber  
     
 Added 04-02-2020   
 Discussion Thread 1     

 new works for DCs - OR (Online Resources, IFORS)   

 Gerhard-Wilhelm Weber  
     
 Added 08-01-2020   
 Discussion Thread 1     

 new contribution --- OR for DCs - (IFORS online resources)   

 Gerhard-Wilhelm Weber  
     
 Added 05-01-2020   
 Discussion Thread 1     

 online resources for DCs - OR responsibility - creativity - optimization (IFORS)   

 Gerhard-Wilhelm Weber  
     
 Added 08-02-2021   
 Discussion Thread 1     

 online resources for DCs - OR responsibility - creativity - optimization (IFORS)   

 Gerhard-Wilhelm Weber  
     
 Added 07-02-2021   
 Discussion Thread 0     

 Institute for Operations Research and the Management Sciences   
 5521 Research Park Drive, Suite 200  
  Catonsville, MD 21228 USA  phone 1  443-757-3500   
 phone 2  800-4INFORMS (800-446-3676)   
 fax  443-757-3515  
 email   

 Discover INFORMS 
  Explore OR & Analytics 
  Get Involved 
  Impact 
  Join Us 
  Recognizing Excellence 
  Professional Development 
  Resource Center 
  Meetings & Conferences 
  Publications 
  About INFORMS 
  PubsOnLine 
  2025 INFORMS Analytics+ Conference 
  Certified Analytics Professional 
  Career Center 
  INFORMS Connect 

 Copyright 2024 INFORMS. All Rights Reserved.  INFORMS Code of Conduct  | Terms of Use  | Privacy Policy  | Contact INFORMS    

 Copyright 2024. All rights reserved.   

 Powered by Higher Logic

55. CSIT_2 conference:
Main Page 
 Dates 
 LIVE BROADCAST 
 Locations 
 Hotel Information 
 Schedule &  
  Program  New! 
 Proceedings  New! 
 Committees 
 Workshops 
 Social Program 
 Paper Submission 
 Final version 
 Invited Speakers 
 Expenses 
 Registration 
 Workshop Participation Registration 
 Photogallery 
 Contacts 
 1-st Call 
 2-nd Call 
 About NAS RA 
 About IIAP 
 Armenia Overview 
 Previous conferences: 
 CSIT 1997 
 CSIT 1999 
 CSIT 2001 
 CSIT 2003 
 CSIT 2005 
 CSIT 2007 
 CSIT 2009 
 CSIT 2011 
 CSIT 2013 
 CSIT 2015 
 CSIT 2017 
 CSIT 2019 
 CSIT 2021 | Main Page | Dates | LIVE BROADCAST | Locations | Hotel Information | Schedule &  
  Program  New! | Proceedings  New! | Committees | Workshops | Social Program | Paper Submission | Final version | Invited Speakers | Expenses | Registration | Workshop Participation Registration | Photogallery | Contacts | 1-st Call | 2-nd Call | About NAS RA | About IIAP | Armenia Overview | Previous conferences: | CSIT 1997 | CSIT 1999 | CSIT 2001 | CSIT 2003 | CSIT 2005 | CSIT 2007 | CSIT 2009 | CSIT 2011 | CSIT 2013 | CSIT 2015 | CSIT 2017 | CSIT 2019 | CSIT 2021 | Important Dates (deadlines):   

 Workshop Proposals: | June 30, 2023 
 Papers submission deadline: | July 23, 2023 
 Notification of acceptance: | August 13, 2023 
 Final papers due: | August 23, 2023 
 Deadline for early registration: | August 31, 2023 

  Conference dates: September 25 - 30, 2023 | Workshop Proposals: | June 30, 2023 | Papers submission deadline: | July 23, 2023 | Notification of acceptance: | August 13, 2023 | Final papers due: | August 23, 2023 | Deadline for early registration: | August 31, 2023 |  
 Workshop Proposals: | June 30, 2023 
 Papers submission deadline: | July 23, 2023 
 Notification of acceptance: | August 13, 2023 
 Final papers due: | August 23, 2023 
 Deadline for early registration: | August 31, 2023 | Important Dates (deadlines):   

 Workshop Proposals: | June 30, 2023 
 Papers submission deadline: | July 23, 2023 
 Notification of acceptance: | August 13, 2023 
 Final papers due: | August 23, 2023 
 Deadline for early registration: | August 31, 2023 

  Conference dates: September 25 - 30, 2023 | Workshop Proposals: | June 30, 2023 | Papers submission deadline: | July 23, 2023 | Notification of acceptance: | August 13, 2023 | Final papers due: | August 23, 2023 | Deadline for early registration: | August 31, 2023 |  
 Main Page 
 Dates 
 LIVE BROADCAST 
 Locations 
 Hotel Information 
 Schedule &  
  Program  New! 
 Proceedings  New! 
 Committees 
 Workshops 
 Social Program 
 Paper Submission 
 Final version 
 Invited Speakers 
 Expenses 
 Registration 
 Workshop Participation Registration 
 Photogallery 
 Contacts 
 1-st Call 
 2-nd Call 
 About NAS RA 
 About IIAP 
 Armenia Overview 
 Previous conferences: 
 CSIT 1997 
 CSIT 1999 
 CSIT 2001 
 CSIT 2003 
 CSIT 2005 
 CSIT 2007 
 CSIT 2009 
 CSIT 2011 
 CSIT 2013 
 CSIT 2015 
 CSIT 2017 
 CSIT 2019 
 CSIT 2021 
 Important Dates (deadlines):   

 Workshop Proposals: | June 30, 2023 
 Papers submission deadline: | July 23, 2023 
 Notification of acceptance: | August 13, 2023 
 Final papers due: | August 23, 2023 
 Deadline for early registration: | August 31, 2023 

  Conference dates: September 25 - 30, 2023 | Workshop Proposals: | June 30, 2023 | Papers submission deadline: | July 23, 2023 | Notification of acceptance: | August 13, 2023 | Final papers due: | August 23, 2023 | Deadline for early registration: | August 31, 2023 |  
 Workshop Proposals: | June 30, 2023 
 Papers submission deadline: | July 23, 2023 
 Notification of acceptance: | August 13, 2023 
 Final papers due: | August 23, 2023 
 Deadline for early registration: | August 31, 2023 
 NAS RA  , IIAP  , ASNET-AM  © 1997-2023

56. AMTA_1 conference:
menu   close    search     
  Home 
  Machine Translation 
  Resources 
  Events 
  About Us 
  Contact 
  Login 

 AMTA · About Us  
   
 Home 
  Machine Translation 
  Resources 
  Events 
  About Us 
  Contact 
  Login 
    
 search   close    search     

 Association   

 AMTA is the North American component of the International Association for Machine Translation ( IAMT  ), which also includes the Asian-Pacific Association for Machine Translation ( AAMT  ) and the European Association for Machine Translation ( EAMT  ). The IAMT Council comprises a balanced representation of all regions. Members of any of the three regional associations automatically become part of the IAMT network. AMTA is governed by the by-laws codified in this document.   
 AMTA was founded in 1991 as a part of the International Association for Machine Translation  , along with the AAMT  and the EAMT.   

 BOARD OF DIRECTORS  

 President  

 Jay Marciano  

 Lengoo  

 Vice-President  

 Alex Yanishevsky  

 Smartling  

 Secretary  

 Janice Campbell  

 Consultant  

 Treasurer  

 David Bishop  

 SOS International (SOSI)  

 Director – MT Researchers  

 Akiko Eriguchi  

 Microsoft  

 Director – MT Researchers  

 Rebecca Knowles  

 National Research Council of Canada (NRC)  

 Director – MT Users and Providers  

 Steve LaRocca  

 U.S. Army Research Laboratory  

 Director – MT Users and Providers  

 Marianna Martindale  

 Center for Applied Machine Translation/PhD Candidate U. Maryland  

 Director – MT Users and Providers  

 Cecilia Yalangozian  

 Machine Translate Non-profit  

 Director – MT Users and Providers  

 Konstantin Savenkov  

 Intento  

 Counselor  

 Steve Richardson  

 BYU  

 Consultant  

 Alon Lavie  

 Unbabel  

 Ad hoc Director, Marketing  

 Derick Fajardo  

 .   

 Webmaster  

 Kelly Ko  

 BYU  

 Former AMTA Presidents  

 1991 – 1996: | Muriel Vasconcellos 
 1996 – 2000: | Eduard Hovy 
 2000 – 2004: | Elliott Macklovitch 
 2004 – 2006: | Laurie Gerber 
 2006 – 2008: | Mike Dillinger 
 2008 – 2012: | Alon Lavie 
 2012 – 2014: | Mike Dillinger 
 2014 – 2016: | George Foster 
 2016 – 2018: | Olga Beregovaya 
 2018 – 2022: | Steve Richardson 

  Sitemap  
   
 AMTA is a 501(c)3 non-profit educational association.  

       Home 
  Machine Translation 
  Resources 
  Events 
  About Us 
  Contact 
  Login

57. APORS_2 conference:
ASOR Australian Society for Operations Research   
   
 Skip to content 
  Jump to main navigation and login 
  Nav view search  
 Navigation  

 Search  

 About ASOR | Office Bearers / Representatives 
  Affiliation 
  Membership 
  Social Media 
  Events and Services | ASOR Conferences 
  Seminars 
  Awards and Medals | ASOR Ren Potts Award 
  Rising Star Award 

 ASOR Conferences  
 APORS 2022  
 ASOR is a member of the Asia-Pacific Operations Research Societies (APORS), and the APORS 2022 conference is being held Nov 9-12 in Manila, Philippines. APORS is an abstract-only conference. This means that to attend the conference as a speaker you need to submit an abstract of up to 500 words, and the program committee then invites you to give a presentation (in person or virtual) based on an assessment of your abstract and its relevance to Operations Research.  
 The abstract submission date was recently extended to 17 July 2022. To submit your abstract visit https://easychair.org/conferences/?conf=apors2022  , and visit http://apors.org  for more information.  
 ASOR 2022  
 Due to the proximity of APORS 2022 and MODSIM/ASOR 2023, ASOR will be holding a workshop-style conference in late 2022, rather than a conference made up of presentations. More information to come.  
 MODSIM/ASOR 2023  
 ASOR is very pleased to announce that we will once again be holding an annual national conference joint with the Modelling and Simulation Society of Australia and New Zealand (MSSANZ) - this time, at MODSIM 2023 in Darwin  . This is much earlier in the year than usual for MODSIM, but allows us all to be in Darwin at the best possible time of year. The conference organising committee has opened the conference up to early registrations. This is prior to 30 June 2022 so as to assist intending participants to commit 2021-2022 financial year funding if this suits their present financial situation. There are several more months until the full paper or extended abstract submission due dates.  
 Past Conferences  
 ASOR National Conference 2021 - ASOR at MODSIM 2021  
 The MODSIM Conference in 2021 was held at U. Sydney and ASOR was again a partner in the conference. It was our national conference for 2021.  
  IFORS 2021 - South Korea  
 The IFORS 2020 conference has been postponed until August 2021. See the IFORS website  for more information.  
 ASOR is a member of IFORS, through the Asia-Pacific OR Societies (APORS).  
  ASOR National Conference 2019 - ASOR and DORS at MODSIM 2019  
 We are very grateful to MSSANZ for inviting us to once again be part of their major event, MODSIM, in Canberra from 1-6 December 2019. The call for papers has closed. Visit https://mssanz.org.au/modsim2019/index.html  for information and registration.  
 ASOR's plenary speaker and special guest is Jerry Brown  : Gerald G. Brown, Ph.D., is an Emeritus Distinguished Professor of Operations Research at the Naval Postgraduate School, where he has taught and conducted research in optimization and optimization-based decision support since 1973, earning awards for both outstanding teaching and research. His military research has been applied by every uniformed service, in areas ranging from strategic nuclear targeting to capital planning. He has been awarded the Barchi, Mennekin, Rist, and Thomas prizes for military operations research, is credited with guiding investments of more than a trillion dollars, and has earned the INFORMS President and Steinhardt Prizes for lifetime achievements. He has designed and implemented decision support software used by the majority of the Fortune 50, in areas ranging from vehicle routing to supply chain optimization. His research has earned patents and appears in scores of open-literature publications and classified reports, some of which are seminal references. Brown is an elected member of the National Academy of Engineering, a recipient of two US Navy Distinguished Civilian Service Medals, and an INFORMS Fellow.   
   
  ASOR will once again offer a Student Presentation Prize for the ASOR/DORS stream at the conference. Students, please do make sure we know you are in contention, by emailing info@asor.org   before the conference. We are good, but not perfect, at identifying who is and isn't a student based on the conference program. Three aspects with equal weight - presentation style, presentation structure, and presentation scientific/technical content - will form the basis of our selection of prize winner.  
   
  See https://mssanz.org.au/modsim2019/  for more information about the conference, plenaries and events.  
  ASOR National Conference 2018  
 ASOR 2018 / DORS 2018 was the 26th National Conference of the Australian Society of Operations Research. It was held in Melbourne from 4 to 6 December 2018. The ASOR / DORS 2018 conference brought together 260 delegates in optimisation, operations planning, informatics, operations research, defence, simulation and modelling of industrial operations, statistics and big data analytics. The Full Papers (peer reviewed) will be published as a monograph by Springer later in 2019.  
 The dedicated website for the conference is at http://www.confer.nz/asor-dors2018/  .  
   
 ( Above  ) Kyle Rogers from SCLAA speaking as part of the Last Mile Logistics  workshop on Day 3 of the ASOR-DORS 2018 Conference.  
  
  ASOR National Conference 2016  
 The 24th National Conference of the Australian Society for Operations Research was held on 16-17 November 2016 in Canberra, joint with the Defence OR Symposium (DORS). The conference included two types of submissions: Extended Abstracts and Full-Papers. Extended abstracts were published on the conference CD, and full papers were published by Springer in Lecture Notes in Management and Industrial Engineering (LNMIE) under the title Data and Decision Sciences in Action  . Full details are available at the Conference Website  .  
  Past Conferences  
 Past conferences we have hosted and organised:  
 Recent Advances 2016 
  ASOR/MODSIM/DORS 2015 
  ASOR Recent Advances 2015 
  ASOR/MODSIM/DORS 2013 
  IFORS 2011 in Melbourne 
  ASOR National Conference 2009 
  ASOR National Conference 2007 
  ASOR Recent Advances (annually) 

 Contact ASOR: info@asor.org.au

58. APORS_3 conference:
Sorry, we're having trouble connecting you to the JiscMail service.  
   
  If you continue to encounter this message, please contact help@jisc.ac.uk  with the message ID below.  
 Message ID: 000984205605

59. CGI_2 conference:
Skip to content      

 Menu   Home 
  About 
  Activities 
  News 
  Contact 
  Join Us 

 CGI’23 Computer Graphics International – August 28 – September 1, Shangai, China  
 Posted on December 18, 2023  December 18, 2023    by cgs-admin      

 This year, CGI 2023 is organized by Shanghai Jiao Tong University and University of Sydney, and supported by the Computer Graphics Society (CGS), with the assistance of Wuhan Textile University and the STATE KEY LABORATORY OF COMPUTER SCIENCE (SKLCS), CGI 2023 will (hopefully) be held as a hybrid event-allowing both onsite and online participation – in Shanghai. The Visual Computer is the official journal of the Computer Graphics Society.  
 More info:  
 Home   

 Search for:       
 CGS Events  
  
 M | T | W | T | F | S | S 
 1 | 2 | 3 
 4 | 5 | 6 | 7 | 8 | 9 | 10 
 11 | 12 | 13 | 14 | 15 | 16 | 17 
 18 | 19 | 20 | 21 | 22 | 23 | 24 
 25 | 26 | 27 | 28 | 29 | 30 | 31 
  
 « Jan      

 Recent Posts  
 CGI’24 Computer Graphics International – JULY 1 – 5, Geneva, Switzerland 
  CASA’24Computer Animation and Social Agents – June 5 – 7, Wuhan, China 
  CGI’23 Computer Graphics International – August 28 – September 1, Shangai, China 
  CASA’23 Computer Animation and Social Agents – May 29 – 31, Limassol, Cyprus 
  CGI’22 Computer Graphics International – 12-16 September, Virtual (from Geneva, Switzerland) 
   
 Archives  
 December 2023 
  January 2021 
  January 2020 
  January 2019 
  October 2018 
  March 2018 
  February 2017 
  March 2016 

 Copyright © 2024 Computer Graphics Society –  OnePress  theme by FameThemes

60. AMTA_2 conference:
menu   close    search     
  Home 
  Machine Translation 
  Resources 
  Events 
  About Us 
  Contact 
  Login 

 Releases > Uncategorized  
   
 Home 
  Machine Translation 
  Resources 
  Events 
  About Us 
  Contact 
  Login 
    
 search   close    search     

 < Go Back    
 AMTA 2023 Virtual | 2nd Call for Proposals  
 by Darius Hughes    | June 13, 2023   read   

 Association for Machine Translations in the Americas  
  
 Second Call for Proposals for   
 Generative AI and the Future of Machine Translation   
 A virtual one-day event under the auspices of AMTA   
 Wednesday, 8 November 2023   
   
 The Board of Directors of AMTA (the Association for Machine Translation in the Americas) is pleased to announce the first call for proposals for  Generative AI and the Future of Machine Translation  , a one-day virtual event to be held on Wednesday, 8 November 2023.   
 Generative AI and the Future of Machine Translation  will focus on advances in cross-lingual technology and processes that leverage Large Language Models. Moving beyond the explosion of hype that began with the general availability of ChatGPT in November 2022, this event is intended as a forum for a thoughtful exchange of ideas informed by a year of successes and failures in applying Large Language Models to the challenges of cross-lingual communication and data processing.   
 Like all AMTA events,  Generative AI and the Future of Machine Translation  will bring together researchers, practitioners, and providers of MT and related cross-lingual technology from academia, industry, and government and will include a keynote address by Christian Federmann, Principal Researcher Manager, Microsoft, expert panel discussions, individual presentations, succinct tutorials for both beginners and more experienced practitioners, and demonstrations from technology providers.   
 The organizing committee of  Generative AI and the Future of Machine Translation  is seeking proposals for presentations and tutorials on all topics related to research, development, application, and evaluation of cross-lingual technology(ies). Our goal is to have a program that appeals to the various constituents of the MT community (researchers, developers, users, and language professionals). Therefore we welcome not only proposals on technical research and development topics but also on, for instance, the collection and curation of training data, best practices in training models, human/computer interaction among translators, interpreters, and other users of generative output in cross-lingual use cases, and the evolution of translation automation in the commercial translation production pipeline.   
 Developers, practitioners, and analysts from industry, the language industry, and government are encouraged to submit proposals that cover leading-edge R&D and practical applications of LLMs as they relate to Machine Translation and the creation of processing of cross-lingual content.   
 Members of the research community are encouraged to submit proposals to this non-archival event that treat recent research directions, trends and concerns about the use of generative AI from the perspective of researchers, or suggestions for research projects, including for industry players.   
 We seek submissions for:   
 20-minute talks (15 minute presentations, plus 5 minutes for questions), 
  40-minute tutorials (practical description or exercises concerning the use of Large Language Models, generative AI, Machine Translation, and/or related tools, processes and technologies for cross-lingual tasks to support real-world goals 
  Topics of interest might include, but are not limited to, the following:   
 Open-source Large Language Models for Translation, Transcreation, and other cross-lingual use cases: | development, deployment, and adaptation to specific use-cases. 
  Adaptation and customization of large language models for cross-lingual use cases: | case studies on applying few-shot learning, prompt-tuning and fine-tuning, comparison of methodologies used to adapt and customize foundation models for specific tasks with respect to business, technical and linguistic requirements. 
  Combining narrow and large models to improve performance of specific tasks | , such as translation, OCR, ASR and others. 
  Augmenting MT systems with generative AI: | including approaches to leveraging TM and end-user feedback, classification, context awareness, content moderation, sentiment analysis. 
  Training Data: | data sources, processing, cleaning of data, terminology, data augmentation, multimodal data, etc. 
  Output quality and confidence scoring for cross-lingual tasks | : | tools, methods and metrics, such as human evaluations, automatic scoring, reference-based and source-only scoring. 
  Challenges to adopting LLMs in cross-lingual use cases: | Responsible deployment and regulatory considerations of generative AI (such as technical, ethical, social, legal, and environmental challenges). 
  Generative AI use for professional translation: | Approaches, success and failure stories, applicability to content-types, fair pricing models, and working with customers, buyers or providers. 
  Business Cases: | making the business case for or against adopting generative AI to drive business requirements. 
  Future research directions | : open problems that researchers are/should be considering in this area. 
  Important dates   
 Submission deadline: Extended to | 15 August 2023 
  Notification of acceptance: | 15 September 2023 
  Submission Instructions   
 Proposals should be submitted in PDF format by  15 August 2023  , to  submissions@amtaweb.org   and include:   
 Title of proposed session 
  Type of proposed session (20-minute presentation or 40-minute tutorial) 
  A 250-500 word description of the proposed session 
  Name and e-mail address of the person who is submitting the proposal 
  Name(s) and e-mail address(es) of proposed speakers 
  A short (<100 words) biographical introduction to the proposed presenter(s) 
  Any special technical requirements you may have 
  Publication and recording   
 This is a non-archival event.   Print proceedings of the event will not be produced. However, video recordings will be made of each presentation and will be made available to association members on the AMTA website. Submission of a proposal will be understood by the Organizing Committee as your tacit permission for AMTA to create an audio and video recording of your presentation and make it available to conference attendees and, through archiving, to members of AMTA, EAMT, and AAMT.   
 Background   
 AMTA, the Association for Machine Translation in the Americas, is well known for its biennial conferences, held since 1994, and for its sponsorship and organization of the MT Summit in 1991, 1997, 2003, 2009, 2015, and 2021. Although the next full AMTA conference will not be held until 2024, the board of directors unanimously agreed that the pace of development in and rapid adoption of large language models and generative AI warranted organizing and hosting an out-of-cycle virtual event.   
  
 We look forward to receiving your proposal!   
   
 AMTA Board of Directors   
  
 Contacts:  Jay Marciano, President (  president@amtaweb.org   )   
 Alex Yanishevsky, Vice President (  vicepresident@amtaweb.org   )   
 Janice Campbell, Secretary (  secretary@amtaweb.org  )   

  Sitemap  
   
 AMTA is a 501(c)3 non-profit educational association.  

       Home 
  Machine Translation 
  Resources 
  Events 
  About Us 
  Contact 
  Login

61. CISIS_0 conference:
Skip to search  Skip to main content    
  
    Login  My Account  Feedback    

 Reporting from:    
 Check system status    

   Report wrong cover image     

      Message     
   
 Your name     
   
 Your email     

 (Stanford users can avoid this Captcha by logging in.)  

 Send  Cancel    

   Select search scope, currently:  catalog  all  catalog, articles, website, & more in one search   catalog  books, media & more in the Stanford Libraries' collections   articles+  journal articles & other e-resources     

 Search in  All fields  Title  Author/Contributor  Subject  Call number  Series    search for   Search       

 Toggle navigation   Menu  Help | Need help?  Chat with us (limited to Stanford community)   Email a reference question  Using SearchWorks  Connection  Connect to e-resources  Report a connection problem  If we don't have it  Interlibrary borrowing  System status 
  Advanced search 
  Course reserves 
  Selections ( 0  )  Clear all lists 

  Back to results     
 Toggle navigation    Cite 
  Send to | text   email   RefWorks      EndNote   printer 

  International joint conference 16th International Conference on Computational Intelligence in Security for Information Systems (CISIS 2023) 14th International Conference on EUropean Transnational Education (ICEUTE 2023) : proceedings   
    
 Responsibility  Pablo García Bringas, Hilde Pérez García, Francisco Javier Martínez de Pisón, Francisco Martínez Álvarez, Alicia Troncoso Lora, Álvaro Herrero, José Luis Calvo Rolle, Héctor Quintián, Emilio Corchado, editors.  Publication  Cham : Springer, 2023.  Physical description  1 online resource (xviii, 370 pages) : illustrations (some color).  Series  Lecture notes in networks and systems ;  748. 2367-3389     
   
 Online  
 Available online  
   
 SpringerLink 
  (Full view) 
    
 Report a connection problem    

 More options  
   
 Find it at other libraries via WorldCat 
  (Limited preview) 

 Top 
  Contributors 
  Summary 
  Subjects 
  Info 
  Browse 
  Bottom 
  Description  
  Creators/Contributors  
   
 Meeting  International Conference on Computational Intelligence in Security for Information Systems (16th : 2023 : Salamanca, Spain)   Contributor  García Bringas, Pablo,  editor.  Pérez García, Hilde,  editor.  Martínez de Pisón, Francisco Javier,  editor.  Martínez-Alvarez, Francisco (Professor of Engineering),  editor.  Troncoso Lora, Alicia,  editor.  Herrero, Alvaro,  editor.  Calvo Rolle, José Luis,  editor.  Quintián, Héctor,  editor.  Corchado, Emilio,  editor.  International Conference on EUropean Transnational Education (14th : 2023 : Salamanca, Spain) ;  jointly held conference.     
   
  Contents/Summary  
   
 Contents  Finding and removing infected T -trees in IoT networks 
  Intrusion Detection and Prevention in Industrial Internet of Things: A Study 
  Critical analysis of global models for malware propagation on wireless sensor networks 
  A novel method for failure detection based on real-time systems identification 
  Accountability & explainability in robotics: a proof of concept for ROS 2- and Nav2-based mobile robots 
  Reducing the security margin against a differential attack in the TinyJambu cryptosystem 
  Analysis of extractive text summarization methods as a binary classification problem 
  Systematic literature review of methods used for SQL injection detection based on intelligent algorithms 
  Benchmarking Classifiers for DDoS Attack Detection in Industrial IoT Networks 
  Impact of the Keep-Alive Parameter on SQL Injection Attack Detection in Network Flow Data 
  QuantumSolver Composer: Automatic Quantum Transformation of Classical Circuits. 
   Summary  This book of Lecture Notes in Networks and Systems contains accepted papers presented at the 16th International Conference on Computational Intelligence in Security for Information Systems (CISIS 2023) and the 14th International Conference on EUropean Transnational Education (ICEUTE 2023). These conferences were held in the beautiful city of Salamanca, Spain, in September 2023. The aim of the CISIS 2023 conference is to offer a meeting opportunity for academic and industry-related researchers belonging to the various, vast communities of computational intelligence, information security, and data mining. The need for intelligent, flexible behavior by large, complex systems, especially in mission-critical domains, is intended to be the catalyst and the aggregation stimulus for the overall event. The aim of ICEUTE 2023 conference is to offer a meeting point for people working on transnational education within Europe. It provides a stimulating and fruitful forum for presenting and discussing the latest works and advances on transnational education within European countries.     
   
  Subjects  
   
 Subjects  Computer networks  > Security measures  > Congresses.   Computer security  > Congresses.   Computational intelligence  > Congresses.   Transnational education  > Congresses.   Educational technology  > Congresses.   Réseaux d'ordinateurs  > Sécurité  > Mesures  > Congrès.   Sécurité informatique  > Congrès.   Intelligence informatique  > Congrès.   Éducation transnationale  > Congrès.   Technologie éducative  > Congrès.      
   
  Bibliographic information  
   
 Publication date  2023  Title variation  CISIS 2023  ICEUTE 2023  Series  Lecture notes in networks and systems, 2367-3389 ; 748  Note  Includes author index.  ISBN  9783031425196 (electronic bk.)  3031425197 (electronic bk.)  9783031425189  3031425189  DOI  10.1007/978-3-031-42519-6     

  Browse related items  
 Start at call number: TK5105.59 .I58 2023eb     
 View full page    

 Librarian view  | Catkey: in00000043480   

 Hours & locations 
  My Account 
  Ask us 
  System status 

 Stanford Home 
  Maps & Directions 
  Search Stanford 
  Emergency Info 
  Terms of Use 
  Privacy 
  Copyright 
  Trademarks 
  Non-Discrimination 
  Accessibility 

 © Stanford University  , Stanford  , California  94305   .

62. CSIT_3 conference:
Open Journal Systems    
 User   
 Username |  
 Password |  
 Remember me 

 Journal Help    
 Quick Links  Author Guidelines 
  CSIT article template 
  Editorial Boards 
  Focus and Scope 
  Online Submission 
  Peer Review Process 
  Publication Fee 
  Publication Ethics 
  Abstracting and Indexing 
  Contact Us 
  Similarity Report 

 Citation Analysis  Crossref 
  Dimensions 
  Google Scholar 
  Scopus 
  Scilit 

 Notifications  View 
  Subscribe 
    
 Journal Content   
 Search 
 Search Scope  
  All  Authors  Title  Abstract  Index terms  Full Text 

  Browse  By Issue 
  By Author 
  By Title 
  Other Journals 
    
 Font Size    

  Information  For Readers 
  For Authors 
  For Librarians 

 Home 
  About 
  Login 
  Register 
  Search 
  Current 
  Archives 
  Announcements 
    
 Home  > Vol 5, No 3    
 Computer Science and Information Technologies  
 Computer Science and Information Technologies  ISSN 2722-323X, e-ISSN 2722-3221 is an open access, peer-reviewed international journal that publishes original research articles, review papers, and short communications that will have an immediate impact on the ongoing research in all areas of Computer Science/Informatics, Electronics, Communication and Information Technologies. The major topics include, but are not limited to the following: Algorithms, Artificial intelligence, Automata and logic, Big data, Cloud and high-performance computing, Coding theory, Cognitive algorithms and models, Combinatorial analysis, Computational science, Computer architecture and engineering, Computer graphics and visualization, Computer security and cryptography, Concurrent, parallel and distributed systems, Cryptography and cyber-security, Data manipulation, Data retrieval, Data storage, Data structures, Data transmission, Databases, Design and test, Discrete mathematics, Distributed systems, Electromagnetics, Image processing, Information and coding theory, Information and communications technology (ICT), Information retrieval, Information science, Information systems, Information technologies applications, Information theory, Internet of things (IoT), Machine learning, Microelectronics, Nanoelectronics, Networking, Pattern recognition, Programming language theory, Signal processing, Software engineering, Telecommunication, Theory of computation, Transmission lines, and Wave propagation.   
 Papers for publication in this journal are selected through rigorous peer review, to ensure originality, timeliness, relevance, and readability. According to the decree No. 164/E/KPT/2021 of the Directorate General of Higher Education, Research and Technology, dated December 27 th, 2021, this journal is recognized  ( accredited  )  " SINTA 2   " by the Ministry of Education, Culture, Research, and Technology of the Republic of Indonesia.  This journal is published by the Institute of Advanced Engineering and Science (IAES)  in collaboration  with Intelektual Pustaka Media Utama (IPMU)  and Universitas Ahmad Dahlan  .  

 The journal is published four-monthly (March, July and November). Submit your manuscripts today!      
  Kindly please download the CSIT template in MS Word   or LaTeX    

 All Issues:   
 2024: | Vol. 5 No. 1 | , | Vol. 5 No. 2 | , Vol. 5 No. 3 
  2023: | Vol. 4 No. 1 | , | Vol. 4 No. 2 | , | Vol. 4 No. 3 
  2022: | Vol. 3 No. 1 | , | Vol. 3 No. 3 | , | Vol. 3 No. 3 
  2021: | Vol. 2 No. 1 | , | Vol. 2 No. 2 | , | Vol. 2 No. 3 
  2020: | Vol. 1 No. 1 | , | Vol. 1 No. 2 | , | Vol. 1 No. 3 

 Announcements  
  
 No announcements have been published. 

 More Announcements... 

  Vol 5, No 3: November 2024  
   
 Table of Contents  
  
 Optimizing classification models for medical image diagnosis: a comparative analysis on multi-class datasets    
 Abdul Rachman Manga, Aulia Putri Utami, Huzain Azis, Yulita Salim, Amaliah Faradibah | PDF    
 205-214 

 Adversarial attacks in signature verification: a deep learning approach    
 Abhisek Hazra, Shuvajit Maity, Barnali Pal, Asok Bandyopadhyay | PDF    
 215-226 

 Securing DNS over HTTPS traffic: a real-time analysis tool    
 Abid Dhiya Eddine, Ghazli Abdelkader | PDF    
 227-234 

 Analysis of ensemble machine learning classification comparison on the skin cancer MNIST dataset    
 Poetri Lestari Lokapitasari Belluano, Reyna Aprilia Rahma, Herdianti Darwis, Abdul Rachman Manga | PDF    
 235-242 

 Company clustering based on financial report data using k-means    
 Gusti Aditya Aromatica Firdaus, Lili Ayu Wulandhari | PDF    
 243-253 

 Capabilities of cellebrite universal forensics extraction device in mobile device forensics    
 Tole Sutikno, Iqbal Busthomi | PDF    
 254-264 

 Unraveling Indonesian heritage through pattern recognition using YOLOv5    
 Rosalina Rosalina, Genta Sahuri | PDF    
 265-271 

 Optimizing development and operations from the project success perspective using the analytic hierarchy process    
 Sani Novi Nugraheni, Teguh Raharjo, Ni Wayan Trisnawaty | PDF    
 272-282 

 Technology adoption model for smart urban farming-a proposed conceptual model    
 Amirul Asyraf Zhahir, Mohd Ilias M Shuhud, Siti Munirah Mohd, Shafinah Kamarudin, Azuan Ahmad, Rossly Salleh, Norita Md Norwawi | PDF    
 283-291 

 Electro-capacitive cancer therapy using wearable electric field detector: a review    
 Tole Sutikno, Fadlil Fadlil, Ardiansyah Ardiansyah, Warsito P Taruno, Lina Handayani | PDF    
 292-305 

 Vector space model, term frequency-inverse document frequency with linear search, and object-relational mapping Django on hadith data search    
 Ichsan Taufik, Agra Agra, Yana Aditia Gerhana | PDF    
 306-314 

  Computer Science and Information Technologies    
   ISSN: 2722-323X, e-ISSN: 2722-3221  
  This journal is published by the Institute of Advanced Engineering and Science (IAES)  in collaboration with Intelektual Pustaka Media Utama (IPMU)  .  
  
 &amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;a title="Web Analytics" href="https://statcounter.com/" target="_blank"&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;img class="statcounter" src="https://c.statcounter.com/11992001/0/5fa2f457/0/" alt="Web Analytics"&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;/div&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt; &amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;br&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;  CSIT Stats   
    
  This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License  .

63. AMTA_3 conference:
Skip to main content  Link      Menu       Expand     (external link)      Document      Search      Copy      Copied         
 Machine Translate       
 Events 
  Calls for papers 
   APIs | Niutrans 
  Google Translate 
  Alibaba Translate 
  ModernMT 
  Baidu Translate 
  Microsoft Translator 
  NeuralSpace 
  Youdao Translate 
  LingvaNex 
  Yandex Translate 
  TexTra 
  Amazon Translate 
  AppTek 
  Language Weaver 
  Wordlingo 
  Omniscien Technologies 
  SYSTRAN 
  KantanMT 
  Watson Language Translator 
  Iconic 
  Lilt 
  IP Translator 
  DeepL 
  Apertium 
  XL8 
  PROMT 
  Globalese 
  Kodensha MT 
  SAP Translation Hub 
  eTranslation 
  Unbabel 
  Lingmo Translation 
  Reverso 
  Rozetta T-400 
  Tilde 
  Textshuttle 
  Sogou Translate 
  Tencent Machine Translation 
  AISA 
  Kakao 
  Mirai Translator 
  T-tact-AN-ZIN 
  Alexa Translations A.I. 
  Lingo24 
  Papago Translation 
  PangeaMT 
  Lucy 
  TranslateMe 
  Language Wire 
  Phrase NextMT 
  CloudTranslation 
  TAPTA 
  Elia 
  Trebe 
  Tauyou 
  Judicio 
  Moses 
  Belazar 
  Lengoo 
  Opus CAT 
  Sunda Translator 
  Tarjama MT 
  Ubiqus NMT 
  YeeKit 
  Acolad 
  Fairtrade 
  Geofluent 
  Lingua Custodia 
  LT Gear 
  MoraviaMT 
  NpatMT 
  OctaveMT 
  Plata Vicomtech 
  Skrivanek 
  Slate Desktop 
  TransPerfect NMT 
  Safaba 
  Features | Customisation | Adaptive machine translation 
  Fine-tuning 
  Formality 
  Glossaries 
  File translation 
  Data confidentiality 
  Pricing 
  Integrations | Trados Studio 
  Phrase TMS 
  memoQ 
  XTM 
  Crowdin 
  MateCat 
  Wordbee 
  Wordfast 
  GlobalLink 
  OmegaT 
  Smartcat 
  translate5 
  Across 
  Multitrans 
  Smartling 
  TransitNXT 
  Tolgee 
  Transifex 
  Passolo 
  eLUNa 
  Weglot 
  KantanStream 
  Google Cloud Translation Hub 
  WorldServer 
  GroupShare 
  Lilt 
  SDL TMS 
  Aggregators | Intento 
  Custom.MT 
  TMXmall 
  Eden AI 
  Crosslang MT Gateway 
  MTrans 
  Human Science 
  Quality estimation | ModelFront 
  DeMT Estimate 
  Phrase MTQE 
  Omniscien Confidence Scores 
  KantanQES 
  Google Translation Hub MTQP 
  Languages 
   Building and research | Automatic post-editing 
  Approaches | Rule-based machine translation 
  Statistical machine translation 
  Neural machine translation 
  Data 
  Training 
  Quality evaluation 
  Metrics | BLEU 
  METEOR 
  COMET 
  YiSi 
  chrF 
  NIST 
  BERTScore 
  TER 
  Human evaluation metrics 
  Multi-engine machine translation 
  Tags and placeholders 
  Locale 
  Other input types | Speech 
  Bridging 
  Human-in-the-loop 
  Libraries and frameworks 
  Zero-shot translation 
  Concepts | Attention 
  Language model 
  N-gram 
  Sentence splitting 
  String 
  Token 
  Vector 
  Vocabulary 
  Word embeddings 
  Resources | Tutorials 
  Education 
  Publications 
  Reports 
  More | People | Warren Weaver 
  Petr Troyanskii 
  Yehoshua Bar-Hillel 
  Georges Artsrouni 
  Margaret Masterman 
  Peter Toma 
  John Hutchins 
  Hermann Ney 
  Salim Roukos 
  Jaime Carbonell 
  Andy Way 
  Daniel Marcu 
  Alon Lavie 
  Philipp Koehn 
  Franz Josef Och 
  Ondřej Bojar 
  Matt Post 
  Jean Senellart 
  Kishore Papineni 
  Martin Popel 
  Lucia Specia 
  Companies 
  Research laboratories 
  Communities 
  Associations | AAMT 
  AMTA 
  EAMT 
  IAMT 
  MT Summit 
  SIGMT 
  SIGSLT 
  WMT 
   About the Machine Translate Foundation 
  Community 
  Newsletter 
  Contributing | Style 
  Coming soon 
  Contributors 
  Roadmap 
   
 This site uses Just the Docs  , a documentation theme for Jekyll.  

 Events 
  AMTA 2023 
   
 AMTA 2023  
 Generative AI and the Future of Machine Translation  
  The Generative AI and the Future of Machine Translation ( AMTA 2023  ) took place Online on 08 November, 2023.  
 Generative AI and the Future of Machine Translation will focus on advances in cross-lingual technology and processes that leverage Large Language Models. Moving beyond the explosion of hype that began with the general availability of ChatGPT in November 2022, this event is intended as a forum for a thoughtful exchange of ideas informed by a year of successes and failures in applying Large Language Models to the challenges of cross-lingual communication and data processing.  
  Generative AI and the Future of Machine Translation included a keynote talk, expert panel discussions, presentations, tutorials for both beginners and more experienced practitioners, and demonstrations from technology providers.  
  
 Location  
 Online 
  Links  
 amtaweb.org/program-for-generative-ai-and-the-future-of-machine-translation/ 
  Important Dates  
  
 Submission deadline | 15 August 
 Notification of acceptance | 15 September 
 Conference | 08 November 

 Schedule  
  
 9:30 | Networking 
 10:00 | Introduction, housekeeping 
 10:15 | Keynote  
  Hype cycle, promising potential and everything in between: MT in the age of LLMs  
  Christian Federmann 
 11:10 | The Limits of Language AI  
  Kirti Vashee 
 11:10 | Evaluation of a Large Language Model for Speech-to-Text and Speech Translation  
  Brendan Hatch, Evelyne Tzoukermann 
 11:35 | Lost in GenAI, Found in MT  
  Konstantin Savenkov 
 11:35 | On-the-Fly Adaptation for Machine Translation using Large Language Models  
  Kevin Duh, Suzanna Sia 
 12:00 | “Self-driving” generative AI: How can we take our hands off the wheel?  
  Adam Bittlingmayer 
 12:00 | Domain and terminology adaptation with large language models: A comparative user study  
  Yuri Balashov 
 12:25 | Assessing the Accuracy and Uses of a Fine-Tuned LLM's Prediction of the Need for Human Intervention  
  Serge Gladkoff 
 12:25 | Anti-LM Decoding for Zero-shot In-Context Machine Translation**  
  Suzanna Sia 
 12:45 | 🍴 
 13:15 | Panel  
  Automation and/or Augmentation: “What could AI do on its own?” becomes “What should we do and when?  
  Donald Barabé, Markus Freitag, Giovanna Lester, Arle Lommel  
  Moderator: Steve Richardson 
 14:05 | The Promise of a Brand, New Day: Time to Switch to LLMs?**  
  Alex Yanishevsky 
 14:05 | The Future of MT: from Sequence Transduction to Machine-In-The-Loop Communication Across Languages  
  Marine Carpuat 
 14:30 | Proposal for a Joint Case Study by Google and Welocalize - Custom Translation**  
  Sarah Weldon, Elaine O’Curran 
 14:30 | Performance Evaluation on Human-Machine Teaming Augmented Machine Translation Enabled by GPT-4  
  Ming Quian 
 14:55 | Leveraging ChatGPT machine translation capabilities for UGC  
  Lucie Bovyn 
 14:55 | Human-Centered Augmented Translation  
  Sharon O'Brien 
 15:15 | Mindful AI: Establishing an effective AI Ethics Board**  
  Jay Marciano 
 15:15 | Improving Machine Translation Quality with Contextual Prompts in Large Language Models  
  Albert LLorens 
 15:35 | ☕️ 
 15:50 | Tutorial  
  Prompt Engineering 101  
  Mei Chai Zheng 
 15:50 | Tutorial  
  Five daily linguistic tasks enhanced by generative AI + MT solutions  
  Luciana Ramos 
 16:15 | Learnings from a Year of Generative AI: Customers need Control, Customizability, Contextualization, Transparency, and Security**  
  Chris Kränzler 
 16:15 | Cultural Transcreation for East Asian Languages with LLMs  
  Beatriz Silva, et al 
 16:40 | From research to production, releasing AI tools and products at scale / Exploring Product Management for Machine Learning Products  
  Jennifer Wong 
 16:40 | Freely Available LLMs and Poetry Translation: A Game Changer?  
  Natalia Resende 
 17:05 | Embrace LLM: Opportunities and Challenges  
  Martin Lei Xiao 
 17:05 | Using LLMs to Automate Multilingual QAs  
  Robert Brodowicz 
 17:30 | Thanks and Introduce AMTA Thesis Award 
 17:45 | Afterhours networking 

 Calls For Papers  
 Submissions  
 20-minute talks (15 minute presentations, 5 minutes for questions) 
  40-minute tutorials (practical description or exercises concerning the use of large language models, generative AI, machine translation, or related tools, processes and technologies for cross-lingual tasks) 
  Topics  
 Open-source large Llanguage models for translation, transcreation, and other cross-lingual use cases 
  Adaptation and customization of large language models for cross-lingual use cases 
  Combining narrow and large models to improve performance of specific tasks 
  Augmenting machine translation systems with generative AI 
  Training Data 
  Output quality and confidence scoring for cross-lingual tasks 
  Challenges to adopting large language models in cross-lingual use cases: Responsible deployment and regulatory considerations of generative AI 
  Generative AI use for professional translation 
  Business Cases 
  Future research directions 
  Last updated on 16 September, 2023, from amtaweb.org/generative-ai-and-the-future-of-machine-translation  .   
  
  ↑   
 Want to learn more about AMTA 2023?  
 Search the community for AMTA 2023    
 Ask a question about AMTA 2023    
   Edited on  by  .  
  
 Edit this article →    
  Machine Translate is created and edited by contributors like you!  
 Learn more about contributing →   
 Licensed under CC-BY-SA-4.0  .  
 Cite this article →

64. CGI_3 conference:
Home 
  About us | KeAi 
  Mission and objectives 
  Management and governance 
  Publishing team 
  Careers 
  Contact 
  Journals | All Journals 
  Engineering and Technology 
  Health and Medical Sciences 
  Life Sciences 
  Multidisciplinary 
  Physical Sciences 
  Social Sciences 
  Events | All events 
  Conferences 
  Webinars 
  Partners | Our partners 
  Publishing 
  Marketing 
  For authors | Publishing guide 
  Author benefits 
  Publishing process 
  Peer review process 
  Publishing ethics 
  Training and workshops 
  Author services 
  ScienceDirect 
  For editors | Editorial information 
  Publishing roles 
  Finding reviewers 
  Online submission system 
  Publishing ethics 
  ScienceDirect 
  Editorial policies 
  For reviewers | Reviewer information 
  Publishing process 
  Peer review process 
  Training and workshops 
  News 

 Home 
  Journals 
  Virtual Reality & Intelligent Hardware 
  Call for Papers 
  “Graphics and Visual Image Synthesis for Metaverse”“Visual Media Analytics for Virtual Reality”― Special issue of Computer Graphics International 2023 (CGI 2023) 

 “Graphics and Visual Image Synthesis for Metaverse”“Visual Media Analytics for Virtual Reality”― Special issue of Computer Graphics International 2023 (CGI 2023)  
 Published 10 May, 2023  

 Computer Graphics International (CGI) has been a prominent annual international conference in the field of computer graphics and virtual reality. It provides researchers with a unique platform to exchange their experiences, gains and various achievements. Previously, CGI was held in different places around the world such as Sydney (2014), Strasbourg (2015), Heraklion (2016), Yokohama (2017), Bintan (2018) and Calgary (2019). Due to the pandemic, the event turned into a virtual one between 2020 and 2022. This year, CGI is scheduled to take place again in Shanghai with the joint efforts of Shanghai Jiao Tong University and University of Sydney with the support of Computer Graphics Society. With its hybrid feature allowing both onsite and online presence it will be an exemplary experience for all participants.  
 You are invited to submit your full paper to CGI 2023 by 12 June 2023 for possible publication in the CAVW Journal, VRIH journal and CGI Conference Proceedings (LNCS, Springer). VRIH journal will publish two special issues on CGI 2023 conference papers.  
 Topics of interest:   
 Rendering Techniques 
  Metaverse (VR/MR/XR) 
  Physically Based Modeling 
  Machine Learning for Computer Graphics 
  Data Compression for Graphics 
  Image Based Rendering and Modeling 
  Computer Animation 
  Shape Analysis and Image Retrieval 
  Digital Cultural Heritage 
  Image Processing and Analysis 
  Global Illumination 
  Digital Humans 
  Stylized Rendering 
  Geometry Processing and Analysis 
  Shape and Surface Modeling 
  Computer Vision for Computer Graphics 
  Scientific Visualization 
  Computational Geometry 
  Computational Photography 
  Visual Analytics 
  Volume Rendering 
  Computational Fabrication 
  3D Reconstruction 
  Graphical Human-Computer Interaction 
  Sketch-based Modelling 
  Key dates  :   
 Submissions close: 12 Jun 2023 
  First reviews due: 13 July 2023 
  Final decision: 05 August 2023 
  Submission instructions:   
 Please read the “For authors” in CGI2023 conference website( https://www.cgs-network.org/cgi23/  ) before submitting your paper for the CGI 2023 second call  . Submissions should be made via the easychair system https://easychair.org/conferences/?conf=cgi2023  . For the paper submissions to VRIH special issues, please select “VRIH track” in the easychair system.  
 Guest  Editors:   
 Bin Sheng, Shanghai Jiao Tong University, China, Email: | shengbin@sjtu.edu.cn 
  Daniel Thalmann, École Polytechnique Fédérale de Lausanne (EPFL), Switzerland, Email: | daniel.thalmann@epfl.ch 
  Stephen Lin, Microsoft Research Asia, Email: | stevelin@microsoft.com 
  Jinman Kim, The University of Sydney, Australia, Email: | jinman.kim@sydney.edu.au 
  Dagan Feng, The University of Sydney, Australia, Email: | dagan.feng@sydney.edu.au 
  Enhua Wu, Chinese Academy of Sciences / University of Macau, China， Email： | ehwu@um.edu.mo 
  Nadia Magnenat Thalmann, University of Geneva, Switzerland, Email: | thalmann@miralab.ch 

  Back to Call for Papers   
   
         Stay Informed  
 Register your interest and receive email alerts tailored to your needs. Sign up below.  

   First name *     
   Surname *     
   Email address *     
  Engineering and Technology  Health and Medical Sciences  Life Sciences  Multidisciplinary  Physical Sciences  Proceedings  Social Sciences    Subject area *     

    KeAi may contact you to share the latest updates about products, services, promotions, and events. If you do not wish to receive such messages, please check this box.    

 Stay up to date  

 KeAi   
 About us 
  Mission and objectives 
  Management and governance 
  Publishing team 
  Careers 
  Contact 

 All Journals   
 Journals 
  Engineering and Technology 
  Health and Medical Sciences 
  Life Sciences 
  Multidisciplinary 
  Physical Sciences 
  Social Sciences 

 Publishing guide   
 For authors 
  Author benefits 
  Publishing process 
  Peer review process 
  Publishing ethics 
  Training and workshops 
  Author services 
  ScienceDirect 

 Editorial information   
 For editors 
  Publishing roles 
  Finding reviewers 
  Online submission system 
  Publishing ethics 
  ScienceDirect 
  Editorial policies 

 Reviewer information   
 For reviewers 
  Publishing process 
  Peer review process 
  Training and workshops 

 All events   
 Events 
  Conferences 
  Webinars 

 News 

 Privacy policy  |  Cookie preferences  |  Sitemap  |  Umbraco Web Design   

 Copyright © 2024 KeAi, its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies.  

 Cookie notice  
   
 We use cookies to analyse and improve our service, to improve and personalise content, advertising and your digital experience. We also share information about your use of our site with our social media, advertising and analytics partners.  
   
 More options  I’m fine with this    
   
 Your cookie preferences  
   
 We use cookies and similar technologies on our website. Cookies are text files containing small amounts of information, which your computer or mobile device downloads when you visit a website. When you return to websites, or visit websites that use the same cookies, they recognise these cookies and therefore your browsing device.  
 We use different types of cookies for different things, such as:  
 Analysing how you use our website 
  Giving you a better, more personalised experience 
  Recognising when you’ve sign in 
  We split our cookies into three distinct categories. You can turn Functional and Performance cookies on and off right here. Strictly necessary cookies can’t be turned off.  

 Strictly necessary cookies  
   
 Always on     

 These cookies are necessary for the website to function and cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information.  

 Performance cookies  
   
 On     

 These cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site.  

 Functional cookies  
   
 On     

 These cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages. If you do not allow these cookies then some or all of these services may not function properly.  

 Targeting cookies  
   
 On     

 These cookies are set by a range of social media services that we have added to the site to enable you to share our content with your friends and networks. They are capable of tracking your browser across other sites and building up a profile of your interests. This may impact the content and messages you see on other websites you visit. If you do not allow these cookies you may not be able to use or see these sharing tools.  

 Save preferences  Accept all

65. CISIS_1 conference:
Skip to content    Library Home    
 Start Over 
  Research Databases 
  E-Journals 
  Course Reserves 
  Library Home 
  Login to library account 
  English 
  Deutsch 
  Español 
  Français 
  Italiano 
  日本語 
  Nederlands 
  Português 
  Português (Brasil) 
  中文(简体) 
  中文（繁體） 
  Türkçe 
  עברית 
  Gaeilge 
  Cymraeg 
  Ελληνικά 
  Català 
  Euskara 
  Русский 
  Čeština 
  Suomi 
  Svenska 
  polski 
  Dansk 
  slovenščina 
  اللغة العربية 
  বাংলা 
  Galego 
  Tiếng Việt 
  Hrvatski 
  हिंदी 
  Հայերէն 
  Українська | Language 

 Library Catalog    
  All Fields  Title  Author  Subject  Call Number  ISBN/ISSN     Find   
  Advanced Search  |  Browse  |  Search Tips     

 International joint conference... 

 Cite this 
  Text this 
  Email this 
  Print 
  Export Record | Export to RefWorks 
  Export to EndNoteWeb 
  Export to EndNote 
  Save to List 
  Permanent link 

 International joint conference 16th International Conference on Computational Intelligence in Security for Information Systems (CISIS 2023) 14th International Conference on EUropean Transnational Education (ICEUTE 2023) : proceedings / Pablo García Bringas, Hilde Pérez García, Francisco Javier Martínez de Pisón, Francisco Martínez Álvarez, Alicia Troncoso Lora, Álvaro Herrero, José Luis Calvo Rolle, Héctor Quintián, Emilio Corchado, editors.  
 This book of Lecture Notes in Networks and Systems contains accepted papers presented at the 16th International Conference on Computational Intelligence in Security for Information Systems (CISIS 2023) and the 14th International Conference on EUropean Transnational Education (ICEUTE 2023). These con...  
 Full description   
 Saved in:    
  
 Corporate Authors: | International Conference on Computational Intelligence in Security for Information Systems Salamanca, Spain   , International Conference on EUropean Transnational Education 
 Other Authors: | García Bringas, Pablo  (Editor)   , Pérez García, Hilde  (Editor)   , Martínez de Pisón, Francisco Javier  (Editor)   , Martínez-Alvarez, Francisco (Professor of Engineering)  (Editor)   , Troncoso Lora, Alicia  (Editor)   , Herrero, Alvaro  (Editor)   , Calvo Rolle, José Luis  (Editor)   , Quintián, Héctor  (Editor)   , Corchado, Emilio  (Editor) 
 Format: | eBook 
 Language: | English 
 Published: | Cham :  Springer,   2023. 
 Series: | Lecture notes in networks and systems ;  748. 
 Subjects: | Computer networks  > Security measures  > Congresses.    
 Computer security  > Congresses.    
 Computational intelligence  > Congresses.    
 Transnational education  > Congresses.    
 Educational technology  > Congresses.    
 Computational intelligence    
 Computer networks  > Security measures    
 Computer security    
 Educational technology    
 Transnational education    
 Electronic books.    
 proceedings (reports)    
 Conference papers and proceedings    
 Conference papers and proceedings.    
 Actes de congrès. 
 Online Access: | Click for online access 

  Holdings 
  Description 
  Table of Contents 
  Similar Items 
  Staff View 
  Login for hold information    
 ‌  
 Click for online access   
  Online  
  
 Status: | Available 

 Similar Items  
 International Joint Conference 15th International Conference on Computational Intelligence in Security for Information Systems (CISIS 2022) 13th International Conference on EUropean Transnational Education (ICEUTE 2022) : Proceedings | Published: (2023) 
  14th International Conference on Computational Intelligence in Security for Information Systems and 12th International Conference on European Transnational Educational (CISIS 2021 and ICEUTE 2021) | Published: (2022) 
  International Joint Conference : 12th International Conference on Computational Intelligence in Security for Information Systems (CISIS 2019) and 10th International Conference on EUropean Transnational Education (ICEUTE 2019) : Seville, Spain, May 13th-15th, 2019 : proceedings | Published: (2019) 
  13th International Conference on Computational Intelligence in Security for Information Systems (CISIS 2020) | Published: (2021) 
  Proceedings of third International Conference on Computing, Communications, and Cyber-Security : IC4S 2021 | Published: (2023) 

 Other Services   
 Interlibrary Loan 
  Request a Purchase 
    
 Search Options   
 Guided Call Number Browse 
  Search History 
    
 Contact   
 libref@holycross.edu 
   508.793.2642 
  Meet with a librarian

66. EAMT_0 conference:
Skip to content      
   About the EAMT | What is the EAMT 
  What is Machine Translation? 
  Sponsored projects 
  EAMT executive committee 
  Related associations 
  Ethics 
  IAMT | International Association for Machine Translation 
  Bylaws of the International Association for Machine Translation Inc. (IAMT) 
  IAMT Award of Honour 
  Membership | Become a member 
  Institutional members 
  Corporate members 
  Conferences | The EAMT Annual Conference | EAMT Annual Conference Peer Review Policy 
  The MT Summit Biannual Conference | MT Summit Peer Review Policy 
  Best thesis award 
  MT resources | MT Archive 
  MT-List 
  Software compendium 

  Site Search   Search for:    Search      

 EAMT Annual Conference  
  
 EAMT 2025  
 when:  TBA, 2025   
  where:  TBA  
    
 Past editions of the EAMT Annual Conference  
 EAMT 2024   June 24-27, Sheffield, United Kingdom.  
 EAMT 2023   June 12-15, Tampere, Finland.  
 EAMT 2022   June 1-3, Ghent, Belgium.  
 EAMT 2020   May 4-6, Lisbon, Portugal.  
 MT Summit 2019   August 19-23, Dublin, Ireland.  
 EAMT 2018   May 28-30, Alacant, Spain.  
 EAMT 2017   May 29-31, Prague, Czech Republic.  
 EAMT 2016   May 30 – June 1, Riga, Latvia.  
 EAMT 2015   May 11-13, Antalya, Turkey.  
 EAMT 2014   June 16-18, Dubrovnik, Croatia.  
 MT Summit 2013   September 2-6, Nice, France.  
 EAMT 2012   May 28-30, Trento, Italy.  
 EAMT 2011   May 30-31, Leuven, Belgium.  
 EAMT 2010   May 27-28, Saint-Raphaël, France.  
 EAMT 2009  May 14-15, Barcelona, Spain.  
 EAMT 2008  September 22-23, Hamburg, Germany.  
 MT Summit 2007  September 10-14, Copenhagen, Denmark.  
 EAMT 2006   June 19-20, Oslo, Norway.  
 EAMT 2005   May 30-31, Budapest, Hungary.  
 EAMT 2004   April 26-27, Malta.  
 EAMT 2003  May 15-17, Dublin, Ireland.  
 EAMT 2002  November 14-15, Manchester, UK.  
 MT Summit 2001  September 18-23, Santiago de Compostela, Galicia, Spain.  
 EAMT 2000  May 11-12, Ljubljana, Slovenia.  
 EAMT 1999  April 22-23, Prague, Czech Republic.  
 EAMT 1998  April 2-3, Geneva, Switzerland.  
 EAMT 1997  May 21-22, Copenhagen, Denmark.  
 EAMT 1996  August 29-30, Vienna, Austria.  
 MT Summit 1995  July 10-13  , Luxembourg.  
 EAMT 1994  September 14-16, Hildesheim, Germany.  
 EAMT 1993  April 26-28, Heidelberg, Germany.  
 MT Summit 1989  August 16-18, Munich, Germany  

 Theme by Colorlib  Powered by WordPress

67. EUSFLAT_0 conference:
EUROPEAN SOCIETY FOR FUZZY LOGIC AND TECHNOLOGY  
  Facebook 
    
 EUSFLAT  is a non-profit European society devoted to promote and disseminate the methods, techniques and developments of Fuzzy Logic and related technologies. Founded in 1999, EUSFLAT encourages the scientific communication and collaboration among its members, organizing, promoting and sponsoring conferences workshops and seminars. Indeed, the biannual EUSFLAT conferences bring together researchers in Fuzzy Logic and related technologies from all over the world. The society advises associates and companies on subjects regarding Fuzzy Logic and it is a member of the International Fuzzy Systems Association (IFSA) representing the European researchers at the IFSA council.  

  OFFICIAL DECLARATION FROM EUSFLAT   
   
  We express our solidarity with people of Ukraine and all other people suffering from war, violence, and oppression. In the words of Martin Luther King Jr., "let peace and justice roll down like a mighty stream."  

   Endorsed Events Calendar  
 All the members receive automatically info about endorsed conferences, news from the field and other pro tips.  

   Membership  
 Become a member of the community or renew your old membership in order to obtain reduced conferences fee and many others benefits!  

   Research Centre  
 The concept of the EUSFLAT Research Centre aims at centres that are focused on fuzzy logic and related technologies and that are strongly engaged in EUSFLAT activities.  

   Summer School  
 We are regularly organizing summer school on fuzzy logic and application for our members. Enjoy lectures given by the most-qualified experts in the area!  

   Renew your membership  
 EUSFLAT 2024 Membership costs only 40EUR (20EUR for students). Do not lose your chance do not waste your money. Become a member.  
 More 
   
   SFLA 2024  
 The shool will be hold in a nice historical city - Toledo, Spain. The school will be organized by ORETO research group: Applied Intelligent Systems, Castilla-La Mancha University, Spain.  
 More 

 Society | Mission and board 
  Bylaws 
  Guidelines 
  Assemblies 
  Working groups 
  Eusflat Research Centre 
  Agreements 
  Membership | Membership 
  Students grants programme 
  Scientific Excellence Award 
  Best PhD Thesis Award 
  Best Student Paper Award 
  Honorary Members 
  Publications | Mathware and Soft Computing 
  ASUM Proceedings 
  IJCIS 
  MDPI 
  EUSFLAT Proceedings 
  Events | Conference network 
  Eusflat events 
  Summer school 
  Members Area 
   
 Short news  
   Susana Montes was reelected as president of EUSFLAT for the 2023-2025 term.  
  
   EUSFLAT 2023 was held in Palma, Spain, gathering 203 participants.  

  © EUSFLAT.  
  Design: HTML5 UP  .  
  
   Member of the International Fuzzy Systems Association (IFSA).

68. CISIS_2 conference:
Skip to main content    .sg     
   
 Deliver to  Vietnam    

 All     
  All Departments  Black Friday  Amazon International Store  Automotive  Baby  Beauty & Personal Care  Books  CDs and Vinyl  Clothing, Shoes & Jewellery  Computer & Accessories  Electronics  Garden & Outdoor  Gift Cards  Grocery  Health, Household & Personal Care  Home  Industrial & Scientific  Kitchen & Dining  Luggage & Travel Gear  Luxury Beauty  Movies & TV  Musical Instruments  Office Products  Pet Supplies  Prime Video  Software  Sports and Outdoors  Tools & Home Improvement  Toys and Games  Video Games     

 Search Amazon.sg     

   EN   
     Hello, sign in    
 Account and Lists    Returns  & Orders    0     
  Cart     

  All     
   
 Black Friday Deals  Best Sellers  Prime    Books  Electronics  Toys and Games  Home  Gift Ideas  Computers  Gift Cards    Beauty and Personal Care  Groceries  Pet Supplies  Sports and Outdoors  Baby  Home Improvement  Health & Personal Care  Video Games  Sell    

 All Books   Arts & Photography   Business & Investing   Children's Books   Fiction   History   Mystery & Suspense   School Books   Travel & Holiday   STEAM store   Education Books   Best Books of the Month     

     International Joint Conference 16th International Conference on Computational Intelligence in Security for Information Systems (CISIS 2023) 14th ... Education (ICEUTE 2023): Proceedings: 748 : García Bringas, Pablo, Pérez García, Hilde, Martínez de Pisón, Francisco Javier, Martínez Álvarez, Francisco, Troncoso Lora, Alicia, Herrero, Álvaro, Calvo Rolle, José Luis, Quintián, Héctor, Corchado, Emilio: Amazon.sg: Books                             

 Books 
  › 
  Computing and Internet 
  › 
  Databases 

 Paperback   
   S$275.83    

 Other New from  S$268.64     Paperback from  S$268.64      

 S$275.83   S$  275 .   83       

 This item cannot be shipped to your selected delivery location. Please choose a different delivery location.    

 Deliver to  Vietnam    

 Usually dispatched within 4 to 6 weeks   

 Japan Imports may differ from local products. Additional terms  apply.  Learn More.    Amazon International Store  
 International products  have separate terms,  are sold from abroad and may differ from local products, including fit, age ratings, and language of product, labeling or instructions. 
  Manufacturer warranty may not apply. 
  Learn more  about Amazon International Store. 

  Quantity:  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30   Quantity:  1         

    S$  S$275.83   275 .   83      (  )  Includes selected options.  Includes initial monthly payment and selected options.  Details    Price   (  S$  275 .   83  x  )      
   S$  275 .   83      

  Subtotal    
 S$  S$275.83   275 .   83        

 Subtotal    

  Initial payment breakdown    

 Postage cost, delivery date and order total (including tax) shown at checkout   

   Add to Cart       

    Buy Now      

 Payment    
   
 Secure transaction    Your transaction is secure    
 We work hard to protect your security and privacy. Our payment security system encrypts your information during transmission. We don’t share your credit card details with third-party sellers and we don’t sell your information to others.  Find out more    

 Ships from    
   
 Amazon Japan    
   
 Sold by    
   
 Amazon Japan     

  Details     
   
 Payment    
 Secure transaction    
 We work hard to protect your security and privacy. Our payment security system encrypts your information during transmission. We don’t share your credit card details with third-party sellers and we don’t sell your information to others.  Find out more     

  Ships from    
 Amazon Japan    

  Sold by    
 Amazon Japan     

  Add to Wish List      

  Added to    

  Unable to add item to List. Please try again.    

 Sorry, there was a problem.  
 There was an error retrieving your Wish Lists. Please try again.    

 Sorry, there was a problem.  
 List unavailable.    

  Other sellers on Amazon    
  New (2) from   S$275.83  S$  275 .   83         

 Image Unavailable  
  Image not available for  
  Color:     

    To view this video download Flash Player 

 VIDEOS 
  360° VIEW 
  IMAGES 

 International Joint Conference 16th International Conference on Computational Intelligence in Security for Information Systems (CISIS 2023) 14th ... Education (ICEUTE 2023): Proceedings: 748  Paperback – 27 August 2023   

 by Pablo García Bringas  (Editor),    Hilde Pérez García  (Editor),    Francisco Javier Martínez de Pisón  (Editor),    Francisco Martínez Álvarez  (Editor),    Alicia Troncoso Lora  (Editor),    Álvaro Herrero  (Editor),    José Luis Calvo Rolle  (Editor),    Héctor Quintián  (Editor),    Emilio Corchado  (Editor)    & 6  more     

 See all formats and editions    

  Sorry, there was a problem loading this page.Try again.   

 Sign in to redeem.  Get S$15  off S$220 with PayLater by Grab. Enter code GRABBFS at checkout. Discount Provided by Amazon. Terms     off S$220 with PayLater by Grab. Promo code GRABBFS is saved to your account. Discount Provided by Amazon. Terms        

 Get S$12 off S$200 with Citi Mastercard. Enter code CITIMCBFS12 at checkout. Discount Provided by Amazon.     4 applicable promotion(s)      Get S$12 off S$200 with Citi Mastercard. Enter code CITIMCBFS12 at checkout. Discount Provided by Amazon. Terms        Sign in to redeem. 
  Get S$10 Off S$180 with DBS Cards. Enter code DBSBFS10 at checkout. Discount Provided by Amazon. Terms        Sign in to redeem. 
  Get S$8 off with HSBC Credit Cards. Enter code HSBCBFS8 at checkout. Discount Provided by Amazon. Terms        Sign in to redeem. 
  Get S$5 Off with Mastercard W/WE Cards Terms 

 {"desktop_buybox_group_1":[{"displayPrice":"S$275.83","priceAmount":275.83,"currencySymbol":"S$","integerValue":"275","decimalSeparator":".","fractionalValue":"83","symbolPosition":"left","hasSpace":false,"showFractionalPartIfEmpty":true,"offerListingId":"WT1R43I7JYsmRsSuhIiFEraianl0Wvt5z4HeShQtMASQyE86jQUxfUnYu8juuuScMsmwHmXmzndijppxdXXA5%2FVd9ltCwQZiXsmnH3JljipVBp5NJpHDF3iRvkWVQECWpufvuX7waWxEhxBIo9S%2BzK4a7asc86r%2Bl%2FHoIyVlRpkaqAUt6FUeGpUZfvavojPN","locale":"en-SG","buyingOptionType":"NEW","aapiBuyingOptionIndex":0}]}   
 Purchase options and add-ons  

 This book of Lecture Notes in Networks and Systems contains accepted papers presented at the 16th International Conference on Computational Intelligence in Security for Information Systems (CISIS 2023) and the 14th International Conference on EUropean Transnational Education (ICEUTE 2023). These conferences were held in the beautiful city of Salamanca, Spain, in September 2023.   
 The aim of the CISIS 2023 conference is to offer a meeting opportunity for academic and industry-related researchers belonging to the various, vast communities of computational intelligence, information security, and data mining. The need for intelligent, flexible behavior by large, complex systems, especially in mission-critical domains, is intended to be the catalyst and the aggregation stimulus for the overall event.   
  
 The aim of ICEUTE 2023 conference is to offer a meeting point for people working on transnational education within Europe. It provides a stimulating and fruitful forum for presenting and discussing the latest works and advances on transnational education within European countries.   

  Read more     

  Report an issue with this product    

   Previous slide of product details       
 Print length     370 pages 
  Language     English 
  Publication date     27 August 2023 
  ISBN-10     3031425189 
  ISBN-13     978-3031425189 
  See all details 

 Next slide of product details       

 Product description  
 From the Back Cover   
 This book of Lecture Notes in Networks and Systems contains accepted papers presented at the 16th International Conference on Computational Intelligence in Security for Information Systems (CISIS 2023) and the 14th International Conference on EUropean Transnational Education (ICEUTE 2023). These conferences were held in the beautiful city of Salamanca, Spain, in September 2023.   
 The aim of the CISIS 2023 conference is to offer a meeting opportunity for academic and industry-related researchers belonging to the various, vast communities of computational intelligence, information security, and data mining. The need for intelligent, flexible behavior by large, complex systems, especially in mission-critical domains, is intended to be the catalyst and the aggregation stimulus for the overall event.   
  
 The aim of ICEUTE 2023 conference is to offer a meeting point for people working on transnational education within Europe. It provides a stimulating and fruitful forum for presenting and discussing the latest works and advances on transnational education within European countries.   

  Product details  
 Language ‏ : ‎  English 
  Paperback ‏ : ‎  370 pages 
  ISBN-10 ‏ : ‎  3031425189 
  ISBN-13 ‏ : ‎  978-3031425189 

     Customer reviews  
   
 5 star  4 star  3 star  2 star  1 star  5 star     0%  0%  0%  0%  0%  0% 
  5 star  4 star  3 star  2 star  1 star  4 star     0%  0%  0%  0%  0%  0% 
  5 star  4 star  3 star  2 star  1 star  3 star     0%  0%  0%  0%  0%  0% 
  5 star  4 star  3 star  2 star  1 star  2 star     0%  0%  0%  0%  0%  0% 
  5 star  4 star  3 star  2 star  1 star  1 star     0%  0%  0%  0%  0%  0% 

  How are ratings calculated?   To calculate the overall star rating and percentage breakdown by star, we do not use a simple average. Instead, our system considers things like how recent a review is and if the reviewer bought the item on Amazon. It also analyses reviews to verify trustworthiness.   

   Review this product  
 Share your thoughts with other customers   
 Write a customer review      

 View Image Gallery     

 Amazon Customer    
    
 5.0 out of 5 stars     
     
  Images in this review    

 No customer reviews   

 Your recently viewed items and featured recommendations   
 ›   
 View or edit your browsing history    
   
 After viewing product detail pages, look here to find an easy way to navigate back to pages you are interested in.    

  Your recently viewed items and featured recommendations   
 ›   
 View or edit your browsing history    
   
 After viewing product detail pages, look here to find an easy way to navigate back to pages you are interested in.    

 Back to top    
  Get to Know Us   
 About Us 
  Careers 
  Press Releases 
  Amazon Science 

 Connect with Us   
 Facebook 
  Twitter 
  Instagram 

 Make Money with Us   
 Protect and Build Your Brand 
  Advertise Your Products 
  Sell on Amazon 
  Supply to Amazon 
  Associates Programme 
  Fulfillment by Amazon 

 Let Us Help You   
 COVID-19 and Amazon 
  Your Account 
  Your Orders 
  Shipping Rates and Policies 
  Recycling 
  Recalls and Product Safety Alerts 
  Help 

   Singapore     

 Amazon Web Services  
  Scalable Cloud  
  Computing Services | Amazon Fresh  
  Groceries & More  
  Right To Your Door | Goodreads  
  Book reviews  
  & recommendations | Shopbop  
  Designer  
  Fashion Brands 
 AbeBooks  
  Books, art  
  & collectables | Alexa  
  Actionable Analytics  
  for the Web | IMDb  
  Movies, TV  
  & Celebrities |  

 Conditions of Use 
  Privacy Notice 
  Interest-Based Ads 
  © 1996–2024, Amazon.com, Inc. or its affiliates

69. EAMT_1 conference:
Skip to content       

 The 24th Annual Conference of The European Association for Machine Translation   

 Search 

   Search      
   
 Front page 
  Programme   Programme sub-menu | Day 1, Monday June 12 
  Day 2, Tuesday June 13 
  Day 3, Wednesday June 14 
  Day 4, Thursday June 15, workshops & tutorials 
  Keynote speakers 
  Guidelines for speakers and posters 
  Evening activities 
  Proceedings 
  Registration 
  Conference venue   Conference venue sub-menu | How to get to Tampere 
  How to get to the conference 
  Where to stay 
  Getting around Tampere 
  Connecting to Internet 
  Where to eat 
  Things to do 
  Sustainability 
  Sponsors   Sponsors sub-menu | Sponsorship opportunities 
  Contacts 
  Ethics 
  Calls for papers   Calls for papers sub-menu | 2nd Сall for Papers 
  2nd Call for Tutorial Proposals 
  2nd Call for Workshop Proposals 

    Menu      
   
 Front page 
  Programme   Programme sub-menu | Day 1, Monday June 12 
  Day 2, Tuesday June 13 
  Day 3, Wednesday June 14 
  Day 4, Thursday June 15, workshops & tutorials 
  Keynote speakers 
  Guidelines for speakers and posters 
  Evening activities 
  Proceedings 
  Registration 
  Conference venue   Conference venue sub-menu | How to get to Tampere 
  How to get to the conference 
  Where to stay 
  Getting around Tampere 
  Connecting to Internet 
  Where to eat 
  Things to do 
  Sustainability 
  Sponsors   Sponsors sub-menu | Sponsorship opportunities 
  Contacts 
  Ethics 
  Calls for papers   Calls for papers sub-menu | 2nd Сall for Papers 
  2nd Call for Tutorial Proposals 
  2nd Call for Workshop Proposals 

 EAMT 2023   

 The 24th Annual Conference of the European Association for Machine Translation  
  12 – 15 June 2023  
  Tampere, Finland  

 About the conference  
 The 24th Annual Conference of the European Association for Machine Translation (EAMT 2023) will take place in Tampere, Finland, June 12-15 2023 and is jointly organized by European Association for Machine Translation, Tampere University and the University of Eastern Finland.  

 Organising Committee  
 General chair   
 Helena Moniz, EAMT President, University of Lisbon, INESC-ID  
 Track chairs   
 Tharindu Ranasinghe, University of Wolverhampton (research: technical track)  
 Eva Vanmassenhove, Tilburg University (research: technical track)  
 Sergi Alvarez Vidal, Universitat Oberta de Catalunya (research: translators & users track)  
 Nora Aranberri, University of the Basque Country (UPV/EHU) (research: translators & users track)  
 Mara Nunziatini, Welocalize (implementations & case studies track)  
 Carla Parra Escartín, RWS Language Weaver (implementations & case studies track)  
 Mikel Forcada, Universitat d’Alacant (products & projects track)  
 Helena Moniz, University of Lisbon, INESC-ID (products & projects track)  
 Judith Brenner, University of Eastern Finland (tutorials & workshops)  
 Maja Popovic, DCU (tutorials & workshops)  

 Local Organising Committee  
 Mary Nurminen, Tampere University (chair)  
 Judith Brenner, University of Eastern Finland  
 Maarit Koponen, University of Eastern Finland  
 Sirkku Latomaa, Tampere University  
 Mikhail Mikhailov, Tampere University  
 Frederike Schierl, Tampere University  

 https://www.youtube.com/watch?v=G1jGVU9cBNA   

 Organisers  

 Back to top      

 Contact → 
  Data protection → 
  Accessibility evaluation report → 
  Cookie policy →

70. EUSFLAT_1 conference:
EUROPEAN SOCIETY FOR FUZZY LOGIC AND TECHNOLOGY  
  Facebook 
    
 EUSFLAT and Endorsed Events Calendar  
 Next EUSFLAT Conference  
 14th Conference of the European Society for Fuzzy Logic and Technology (EUSFLAT 2025) | , July 21-25, 2025, Riga, Latvia. 
  Upcoming EUSFLAT-Endorsed Events  
 2025 IFSA-NAFIPS Joint Congress | , June 15-18, 2025, Banff, Alberta, Canada. 
  Past EUSFLAT Conferences  
 13th Conference of the European Society for Fuzzy Logic and Technology (EUSFLAT 2023) | , September 4-8, 2023, Palma, Spain. 
  Joint 19th World Congress of the International Fuzzy Systems Association and 12th Conference of the European Society for Fuzzy Logic and Technology (EUSFLAT 2021) | , September 19-24, 2021 Bratislava, Slovak Republic. 
  11th Conference of the European Society for Fuzzy Logic and Technology (EUSFLAT 2019) | , September 9-13, 2019 Prague, Czech Republic. 
  10th Conference of the European Society for Fuzzy Logic and Technology (EUSFLAT 2017) | , September 12-15, 2017, Warsaw, Poland. 
  Joint 16th World Congress of the International Fuzzy Systems Association and 9th Conference of the European Society for Fuzzy Logic and Technology (IFSA-EUSFLAT 2015) | , June 30-July 3, Gijon, Spain. 
  8th Conference of the European Society for Fuzzy Logic and Technology (EUSFLAT-2013) | , Milan, Italy, September 11-13, 2013. 
  The | 7th Conference of the European Society for Fuzzy Logic and Technology (EUSFLAT 2011) | July 18-22, 2011, jointly with Les Rencontres Francophones sur la Logique Floue et ses Applications (LFA 2011, aka French Days on Fuzzy Logic and Applications) in Aix-les-Bains, France. 
  Joint 13th IFSA World Congress and 6th EUSFLAT Conference | Lisbon, Portugal, July 20-24, 2009. 
  5th Conference of the European Society for Fuzzy Logic and Technology, Ostrava Czech Republic, September 11-14, 2007. 
  Joint 4th Conference of the European Society for Fuzzy Logic and Technology (EUSFLAT 2005) and the 11th Rencontres Francophones sur la Logique Floue et ses Applications (LFA 2005), Barcelona, Spain, September 7-9, 2005. 
  3rd International Conference in Fuzzy Logic and Technology (EUSFLAT 2003), Zittau Germany, September 10-12, 2003. 
  2nd International Conference in Fuzzy Logic and Technology (EUSFLAT 2001), Leicester, UK, September 5-7, 2001. 
  1999 EUSFLAT-ESTYLF Joint Conference, Palma de Mallorca, September 22-25, 1999. 

 Society | Mission and board 
  Bylaws 
  Guidelines 
  Assemblies 
  Working groups 
  Eusflat Research Centre 
  Agreements 
  Membership | Membership 
  Students grants programme 
  Scientific Excellence Award 
  Best PhD Thesis Award 
  Best Student Paper Award 
  Honorary Members 
  Publications | Mathware and Soft Computing 
  ASUM Proceedings 
  IJCIS 
  MDPI 
  EUSFLAT Proceedings 
  Events | Conference network 
  Eusflat events 
  Summer school 
  Members Area 
   
 Short news  
   Susana Montes was reelected as president of EUSFLAT for the 2023-2025 term.  
  
   EUSFLAT 2023 was held in Palma, Spain, gathering 203 participants.  

  © EUSFLAT.  
  Design: HTML5 UP  .  
  
   Member of the International Fuzzy Systems Association (IFSA).

71. CALCO_0 conference:
Skip to content    
   
      CALCO 2023 & MFPS XXXIX    
 General Information    

  Initializing search   

 Home 
  CALCO 
  MFPS 
  Local Information 
  Programme 
  Registration 

   CALCO 2023 & MFPS XXXIX  Home 
  CALCO | CALCO  General Information | General Information | Table of contents  Important Dates 
  Invited Speakers 
  Special Sessions 
  Chairs 
  Programme Committee 
  Submission Information 
  Awards 
  Accepted Papers 
  Full Call For Papers 
  MFPS | MFPS  General Information 
  Accepted Papers 
  Local Information 
  Programme 
  Registration 

 10th Conference on Algebra and Coalgebra in Computer Science  
 CALCO aims to bring together researchers and practitioners with interests in foundational aspects, and both traditional and emerging uses of algebra and coalgebra in computer science. It is a high-level bi-annual conference formed by joining the forces and reputations of CMCS  (the International Workshop on Coalgebraic Methods in Computer Science), and WADT  (the Workshop on Algebraic Development Techniques). Previous CALCO editions took place in Swansea  (Wales, 2005), Bergen  (Norway, 2007), Udine  (Italy, 2009), Winchester  (UK, 2011), Warsaw  (Poland, 2013), Nijmegen  (The Netherlands, 2015), Ljubljana  (Slovenia, 2017), London  (United Kingdom, 2019), and Salzburg  (Austria, 2021).  
 The proceedings of both CALCO 2023  and MFPS XXXIX  are published.  
 Important Dates  
 Abstract submission: | March 22, 2023 | (was | March 8 | , | March 10 | before) 
  Full Paper submission: | March 26, 2023 | (was | March 8 | , | March 19 | before) 
  Author notification: | April 28, 2023 
  Final version due: | June 6, 2023 | (was | May 19 | ) 
  All dates are Anywhere on Earth  .  
 Invited Speakers  
 Robert Harper | , Carnegie Mellon University (Joint with MFPS) 
  Assia Mahboubi | , Inria (Joint with MFPS) 
  Roberto Bruni | , University of Pisa 
  Elaine Pimentel | , University College London 
  Jeremy Siek | , Indiana University 
  Special Sessions  
 “Category Theory in Machine Learning” Organised by Brendan Fong  and Brandon Shapiro  (Topos Institute), Fabio Zanasi  (University College London) 
  “Machine-checked proofs in mathematics and meta-mathematics” Organised by Assia Mahboubi  , Inria (joint with MFPS) 
  Chairs  
 Paolo Baldan | (University of Padua) 
  Valeria de Paiva | (Topos Institute, Berkeley) 
  Programme Committee  
 Carlos Gustavo Lopez Pombo | (University of Buenos Aires) 
  Andreas Abel | (Gothenburg University) 
  Vincenzo Ciancia | (Consiglio Nazionale delle Ricerche, Pisa) 
  Patricia Johann | (Appalachian State University) 
  Ionut Tutu | (Simion Stoilow Institute of Mathematics of the Romanian Academy) 
  Martin Escardo | (University of Birmingham) 
  Tarmo Uustalu | (Reykjavik University) 
  Giorgio Bacci | (Aalborg University) 
  Thorsten Wißmann | (FAU Erlangen-Nürnberg) 
  Fabio Gadducci | (University of Pisa) 
  Shin-Ya Katsumata | (National Institute of Informatics, Tokyo) 
  Holger Giese | (Hasso Plattner Institute at the University of Potsdam) 
  Peter Ölveczky | (University of Oslo) 
  Michael Johnson | (Macquarie University) 
  Nicolas Behr | (CNRS Université Paris Cité) 
  Henning Urbat | (FAU Erlangen-Nürnberg) 
  Valentina Castiglioni | (Reykjavik University) 
  Fernando Orejas | (Universitat Politècnica de Catalunya) 
  Mehrnoosh Sadrzadeh | (University College London) 
  Georgiana Caltais | (University of Twente) 
  Sławomir Lasota | (University of Warsaw) 
  Aleks Kissinger | (University of Oxford) 
  Thomas Colcombet | (CNRS, IRIF, Université de Paris) 
  Sandra Kiefer | (University of Oxford) 
  Peter Selinger | (Dalhousie University) 
  Natasha Alechina | (Utrecht University) 
  Sara Kalvala | (University of Warwick) 

 Made with Material for MkDocs

72. XP_0 conference:
Toggle navigation      XP2023     

 About 
  Registration | Registration 
  Registration Fees 
  Agenda 
  Speakers 
  Sponsors 
  Location | Location 
  Venue 
  Hotels 

 Registration is now open for XP 2023, the 24th International Conference on Agile Software Development   

 June 13-16, 2023 • Amsterdam, The Netherlands   

 XP is the premier Agile software development conference combining research and practice. It is a unique forum where Agile researchers, practitioners, thought leaders, coaches, and trainers gather to present and discuss their most recent innovations and research results.  
 At its inception over 20 years ago, the XP conference focused solely on eXtreme Programming. It quickly widened its scope to include all modern Agile approaches and Agility’s developing aspects. XP draws people from around the globe, providing a diverse and inclusive environment for learning and inspiring conversations.  

 The theme for XP 2023 is “Whole Team Sustainability”  

 The theme for XP2023 is “Whole Team Sustainability,” a multi-faceted theme centering on the need to band together to solve the complex challenges of our time. Agile has long focused on the ability to truly work as a whole team, bringing all our different skills and viewpoints to bear on our common purpose: strong engineering skills working hand-in-hand with top-level product vision, supported and sustained by modern management and a focus on resilience over efficiency.   

 Agile processes promote sustainable development  

 Sustainability is also represented in the form of a resilient, healthy, and diverse team working at a healthy pace. After all, “Agile processes promote sustainable development.” What is the long-term effect of an Agile mindset and practices? How can we keep teams stable and resilient in times of high growth or decline?  
 The worldwide necessity to take action for our environment makes the need for that philosophy in more aspects of our society starkly clear.  

 An in-person conference in the heart of Amsterdam!  

 For the first time in its long history, XP 2023 will be in The Netherlands, at “Pakhuis De Zwijger” right in the middle of Amsterdam. In the center of the city, on the waterfront, there’s no better place to get together with colleagues from across the world and no better base from which to explore Amsterdam.  

 XP 2023 Program Components   

 Research Workshops   
 A forum for small group discussions to present and discuss results of scientific research and practice, and to explore innovative and cutting-edge topics. Full- and half day research workshops will take place on Tuesday.  
 The call for proposals for research workshops is open! Contact the chair to discuss your topics.  

 Experience Reports   
 Authors of Experience Report share their first-hand experience of challenges faced, approaches taken, and observations and insights gained. These personal stories are are a resource to those who want perspectives on what others are doing and the lessons they have learned along the way in practicing Agile and Lean software development. Experience Reports will be published on the Agile Alliance website.  

 Research Papers   
 Presentation of research papers on topics across the full spectrum of Agile software development and broader Agile issues of interest to both researchers and practitioners.  

 Interactive Track (with Engineering!)   
 Next to our planned content programming, XP 2023 will have a full, guided, interactive track aimed at bringing participants together, facilitate networking and shared learning, and making room for everyone to be fully engaged. We will also have a unique Engineering Interactive Track, where we can practice what we preach and build software together throughout the conference in a continuous, ensemble programming, session.  

 Industry & Practice   
 Workshops, demonstrations, and presentations based on the speaker’s experience and practice working in the industry. The theme for these session reflects that of the conference: “Whole Team Sustainability” with main topics around Leadership and Culture, Engineering, Product and Design, Process Innovation, Agile in Education and Training, and Sustainability  

 Open Access Publication   
 All peer-reviewed academic research presented at the conference will be available on the website as an open access Springer publication. We believe that research is useful to practitioners and should be shared widely, not hidden behind a paywall. There will be two publications, one before and one after the conference, containing research papers and workshop papers.  

 Register Now     

 Cancellations/Substitutions/Refunds   
  All regular cancellations must be received in writing by email no later than May 13, 2023, at 5:00 pm EDT. A €150 processing fee will be incurred. Cancellations made after the deadline of July 1, 2023, at 5:00 pm EDT as well as “no-shows” are liable for the full registration fee.   
 Substitutions  from the same organization are welcome with no additional fee as long as the substitute qualifies for the same type of registration (member/non-member/academic). If the substitute attendee does not qualify for your rate, an additional fee may be required.   
 Email registration@agilealliance.org    with requests.   
 No-shows are liable for the entire conference fee.   
 Agile Alliance reserves the right to cancel the event or substitute speakers. In the unlikely event that Agile Alliance should have to cancel the Agile2023 conference, attendees will be refunded for the amount paid for the conference.    

 ©2023 Agile Alliance

73. EUSFLAT_2 conference:


74. CALCO_1 conference:
Skip to content    
   
      CALCO 2023 & MFPS XXXIX    
 Home    

  Initializing search   

 Home 
  CALCO 
  MFPS 
  Local Information 
  Programme 
  Registration 

   CALCO 2023 & MFPS XXXIX  Home | Home | Table of contents  CALCO 
  MFPS 
  Local Organization 
  Publicity Chair 
  Supporting Organizations 
  CALCO | CALCO  General Information 
  Submission Information 
  Awards 
  Accepted Papers 
  Full Call For Papers 
  MFPS | MFPS  General Information 
  Accepted Papers 
  Local Information 
  Programme 
  Registration 

 CALCO 2023 & MFPS XXXIX  
   
 The 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)  and the 39th Conference on the Mathematical Foundations of Programming Semantics (MFPS XXXIX)  take place together at Indiana University Bloomington  on June 19 – 23, 2023.  
    The CALCO awards  for best papers and best presentation have been announced!  
   
    The proceedings of both CALCO 2023  and MFPS XXXIX  are published!  
   
 CALCO   
 Important Dates (Deadline extension by another week!):  
 Abstract: | March 22, 2023 
  Full-Paper: | March 26, 2023 
  Notification: | April 28, 2023 
  Final version: | June 6, 2023 
  PC Chairs:  
 Paolo Baldan 
  Valeria de Paiva 
  more information...   
   
 MFPS   
 Important Dates (Deadline extension):  
 Abstract: | April 1, 2023 
  Full-Paper: | April 8, 2023 
  Notification: | May 12, 2023 
  Pre-proceedings : | June 2, 2023 
  PC Chairs:  
 Marie Kerjean 
  Paul Levy 
  more information...   

 Local Organization  
 Larry Moss | (Chair), Devendra, Osanda Illeperuma, Pavel Kovalev, Caleb Schultz Kisby, Darshal Shetty, Zixiu Su, Cathy Wyss 
  Publicity Chair  
 Thorsten Wißmann 
  Supporting Organizations  

 Made with Material for MkDocs

75. XP_1 conference:
Skip to content      

 Membership | Membership  
   Join Agile Alliance 
  Why Join? 
  Membership FAQ 
  Corporate Member Directory 
  Product/Service Providers 
  Member Portal > 
   
 Join Agile Alliance 
  Why Join? 
  Membership FAQ 
  Corporate Member Directory 
  Product/Service Providers 
  Member Portal > 
   
    Members-only Content  
   Monthly Member Events 
  Event Session Videos 
  Experience Reports 
  Research Papers 
  Share a Community Event 
  Submit an Article to the Blog 
  Submit a Member Initiative 
  Promote a Training Event 
         Become an Agile Alliance member!  
   Your membership  enables us to offer a wealth of resources, present renowned international events, support global community groups, and so much more! And, while you’re supporting our non-profit mission, you’ll also gain access to a range of valuable member benefits. Learn more | Join Us Today 
  Why Join? 
  Member Portal 
  Pricing 
  Membership FAQs 
  Terms and Conditions 
  Corporate Members 
  Events | Agile Conferences  
   All Agile Alliance Events 
  Agile MiniCon – When Agile Fails 
  Agile2025 
  XP 2025 
  Past Conferences 
  Become an Event Sponsor 
     Virtual Events  
   Member Events Calendar 
  BYOC Lean Coffee 
  Game On 
  Agile Tech Talks 
  Member Meet & Greet 
  Agile Coaching Network 
  Full Events Calendar 
     Community Events  
   Community Events Calendar 
  Agile Training Calendar 
  Sponsored Meetup Groups 
  Submit a Non-profit Event 
  Submit a For-profit Training 
  Event Funding Request 
  Global Events Calendars 
         When Agile Fails: Solutions for You and Your Team   
  Transformations often encounter obstacles when core Agile principles and values are not fully implemented. These issues can stall progress and demoralize teams. This event will focus on common challenges Agile teams encounter, offering practical solutions to help you overcome obstacles and drive success. | Events Calendar 
  Agile2023 
  Monthly Events | Game On! 
  Agile Coaching Network 
  BYOC – Lean Coffee 
  Member Meet & Greet 
  Agile Tech Talks 
  Agile Training 
  Community Events | View All Events 
  Submit an Event 
  Meetup Groups 
  Past Conferences & Events 
  Agile Essentials | Agile Essentials  is designed to bring you up to speed on the basic concepts and principles of Agile with articles, videos, glossary terms, and more.  
         Agile Essentials  
   Essentials Overview 
  Agile 101 – What is Agile? 
  Agile Glossary 
  Agile Manifesto 
  The 12 Principles 
  Introductory Videos 
  Short History of Agile 
  Agile Practices Timeline 
  Agile Practice Subway Map 
   
 Essentials Overview 
  Agile 101 – What is Agile? 
  Agile Glossary 
  Agile Manifesto 
  The 12 Principles 
  Introductory Videos 
  Short History of Agile 
  Agile Practices Timeline 
  Agile Practice Subway Map 
   
         Download the Agile Manifesto  
   To download a free PDF copy of the Agile Manifesto and 12 Principles of Agile, simply sign-up for our newsletter. Agile Alliance members can download it for free.  
     Sign-up now | Agile Essentials Overview 
  Agile 101 
  Agile Manifesto 
  12 Principles Behind the Manifesto 
  A Short History of Agile 
  Subway Map to Agile Practices 
  Agile Glossary 
  Introductory Videos 
  Resources | Recent Blog Posts  
        Turning Sprint reviews into a powerhouse of feedback   
   Joe Foley        
      From copy-paste Agile to true transformation   
   Joe Foley        
      7 researched-backed reasons Agile projects falter   
   Joe Foley        
     View all blog posts   
      Agile Resources  
   Agile Resource Guide 
  The Blog 
  Agile Glossary 
  Event Sessions 
  Agile Videos 
  Experience Reports 
  Research Papers 
  Agile Games 
  Agile Bookstore 
  Agile Career Center 
   
 Agile Resource Guide 
  The Blog 
  Agile Glossary 
  Event Sessions 
  Agile Videos 
  Experience Reports 
  Research Papers 
  Agile Games 
  Agile Bookstore 
  Agile Career Center 
   
    The NEW Agile Resource Guide  
       Find Agile services and products from our member companies in our new Agile Resource Guide  . Many listings in the guide feature exclusive offers just for Agile Alliance members. View the guide | Remote Working Guide 
  Blog 
  Agile Glossary 
  Event Sessions 
  Videos 
  Experience Reports 
  Books 
  Research Papers 
  Content Library 
  Community | Reimagining Agile  
   Reimagine Agile is an initiative to promote Agile and Agility by re-examining and clarifying Agile’s core values and principles   and extending those values and principles into new areas and communities. Learn more   
    MEMBER INITIATIVES  
   Agile Sustainability Initiative 
  Principle 12 Initiative 
  Agile in Color Initiative 
  Agile Coach Camp Worldwide 
  Agile Coaching Ethics 
    View all initiatives   
      Your Community  
   Reimagining Agile 
  Community Groups 
  Community Events 
  Sponsored MeetUp Groups 
  Community Services 
  Member Initiatives 
  Volunteer Signup 
   
 Reimagining Agile 
  Community Groups 
  Community Events 
  Sponsored MeetUp Groups 
  Community Services 
  Member Initiatives 
  Volunteer Signup 
   
    Global Development  
   LATAM Community 
  India Community 
    Global Affiliates  
   Agile Alliance Brazil 
  Agile Alliance New Zealand 
   
 Agile Alliance Brazil 
  Agile Alliance New Zealand | Community Groups 
  Community Events 
  Community Services 
  Member Initiatives 
  Community Development | LATAM Community Development 
  India Community Development 
  Volunteer Signup 
  Corporate Members 
  About Us | Global Affiliates  
   Agile Alliance Brazil 
  Agile Alliance New Zealand 
   
 Agile Alliance Brazil 
  Agile Alliance New Zealand 
   
        OUR POLICIES  
   Code of Conduct 
  Policies, Reports & Bylaws 
  Financial Reports 
  Content Standards 
  Privacy Policy 
  Cookie Policy 
   
 Code of Conduct 
  Policies, Reports & Bylaws 
  Financial Reports 
  Content Standards 
  Privacy Policy 
  Cookie Policy 
   
    ABOUT US  
   About the Alliance 
  Our Team 
  Board of Directors 
  Logo Files 
  Become a Sponsor 
  Newsletter Signup 
  Contact Us 
   
 About the Alliance 
  Our Team 
  Board of Directors 
  Logo Files 
  Become a Sponsor 
  Newsletter Signup 
  Contact Us 
   
    Sign up for Agile News  
   Get the latest Agile Alliance news and updates, including event announcements, special offers, discounts, and more by becoming a newsletter subscriber today.  
   Sign Up Now | About Agile Alliance 
  Code of Conduct 
  Board of Directors 
  Our Team 
  Global Affiliates | Agile Alliance Brazil 
  Agile Alliance New Zealand 
  Policies, Reports & Bylaws 
  Logo and Media Files 
  Become a Sponsor 
  Contact Us 

   Log in      

 Search    Search     

   Profile      

 Past Events  

 XP 2023  

 June 13-16 | Amsterdam, The Netherlands  

 XP is the premier Agile software development conference to combine both research and practice. It is a unique forum where Agile researchers, practitioners, thought leaders, coaches, and trainers get together to present and discuss their most recent innovations and research results.  

 XP 2023 Keynote Speakers  

 Dave Snowden   

 Coral Colero   

 Eelco Rustenburg   

 Jutta Eckstein   

 XP 2023 Program Chairs  

 Wouter Lagerweij   

 Conference Chair  

 Suzanne Lagerweij    

 Conference Co-Chair  

 XP 2023 Co-Chairs  

 Christoph Stettina   
  Academic Program  
  Co-Chair  
 Juan Garbajosa   
  Academic Program  
  Co-Chair  
 Sabina Renshof   
  Industry & Practice  
  Co-Chair for  
  Leadership and Culture  
 Torsten Hansen   
  Industry & Practice  
  Co-Chair for  
  Leadership and Culture  

 Astrid Claessen   
  Industry & Practice  
  Co-Chair for  
  Product and Design  
 Frank Olsen   
  Experience Reports  
  Co-Chair  
 Maarit Laanti   
  Agile Education and  
  Training Track  
  Co-Chair  
 Peggy Gregory   
  Research Workshops Co-Chair  
  Proceedings Co-Chair  
 Philippe Kruchten   
  Proceedings Chair  
 Martin Kropp   
  Agile Education and Training Track Co-Chair  
 Michael Spaans   
  Industry & Practice Co-Chair  
  for Product and Design  
 Leonor Barocca   
  Research Workshops  
  Co-Chair  
 Nathalie Hammering   
  Experience Reports  
  Co-Chair  
 Maryse Meinen   
  Industry & Practice  
  Co-Chair for  
  Sustainability  
 Deepti Jain   
  Interactive Track Chair  
 Rob Westgeest   
  Industry & Practice  
  Co-Chair for Engineering  
 Willem van den Ende   
  Industry & Practice  
  Co-Chair for Engineering  

 Discover the many benefits of membership  

 Your membership enables Agile Alliance to offer a wealth of first-rate resources, present renowned international events, support global community groups, and more — all geared toward helping Agile practitioners reach their full potential and deliver innovative, Agile solutions.  

 Log in now      

 Learn more      

 Thank you to our valued Agile Alliance Annual Partners  

 Our new Annual Partner Program  offers a new and exciting level of engagement beyond event sponsorship.  

   Agile Alliance Official Partner     
   
   Agile Alliance Corporate Partner     

 Our Cornerstone Corporate Supporting Members  

 Our Corporate Supporting Members are vital to the mission of Agile Alliance. Click here to view all corporate members.   

 Our Corporate Supporting Members are vital to the mission of Agile Alliance.  
  Click here to view all corporate members.   

 Agile Community  

 Reimagining Agile 
  Community Groups 
  Community Events 
  Sponsored MeetUp Groups 
  Community Services 
  Member Initiatives 
  Volunteer Signup 
   
 Reimagining Agile 
  Community Groups 
  Community Events 
  Sponsored MeetUp Groups 
  Community Services 
  Member Initiatives 
  Volunteer Signup 

 Agile Essentials  

 Essentials Overview 
  Agile 101 – What is Agile? 
  Agile Glossary 
  Agile Manifesto 
  The 12 Principles 
  Introductory Videos 
  Short History of Agile 
  Agile Practices Timeline 
  Agile Practice Subway Map 
   
 Essentials Overview 
  Agile 101 – What is Agile? 
  Agile Glossary 
  Agile Manifesto 
  The 12 Principles 
  Introductory Videos 
  Short History of Agile 
  Agile Practices Timeline 
  Agile Practice Subway Map 

 Agile Resources  

 Agile Resource Guide 
  The Blog 
  Agile Glossary 
  Event Sessions 
  Agile Videos 
  Experience Reports 
  Research Papers 
  Agile Games 
  The Agile Practice Guide 
  Agile Bookstore 
  Agile Career Center 
  Resources Overview 
   
 Agile Resource Guide 
  The Blog 
  Agile Glossary 
  Event Sessions 
  Agile Videos 
  Experience Reports 
  Research Papers 
  Agile Games 
  The Agile Practice Guide 
  Agile Bookstore 
  Agile Career Center 
  Resources Overview 

 Global Affiliates  

 Agile Alliance Brazil 
  Agile Alliance New Zealand 
   
 Agile Alliance Brazil 
  Agile Alliance New Zealand 

 Agile Events  

 Events Calendar 
  Community Events 
  Meetup Groups 
  Submit an Event 
  Global Events Calendars 
  Agile Training 
  Past Conferences 
   
 Events Calendar 
  Community Events 
  Meetup Groups 
  Submit an Event 
  Global Events Calendars 
  Agile Training 
  Past Conferences 

 About Us  

 About the Alliance 
  Our Team 
  Board of Directors 
  Logo Files 
  Become a Sponsor 
  Newsletter Signup 
  Contact Us 
   
 About the Alliance 
  Our Team 
  Board of Directors 
  Logo Files 
  Become a Sponsor 
  Newsletter Signup 
  Contact Us 

 Membership  

 Join Agile Alliance 
  Why Join? 
  Membership FAQ 
  Corporate Member Directory 
  Product/Service Providers 
  Member Portal > 
   
 Join Agile Alliance 
  Why Join? 
  Membership FAQ 
  Corporate Member Directory 
  Product/Service Providers 
  Member Portal > 

 Policies + Principles  

 Code of Conduct 
  Policies, Reports & Bylaws 
  Financial Reports 
  Content Standards 
  Privacy Policy 
  Cookie Policy 
   
 Code of Conduct 
  Policies, Reports & Bylaws 
  Financial Reports 
  Content Standards 
  Privacy Policy 
  Cookie Policy 

 Sign up for Agile News  

 Get the latest Agile Alliance news and updates, including event announcements, special offers, discounts, and more by becoming a newsletter subscriber today.  

 Sign Up Now      

 ©2024 Agile Alliance | All Rights Reserved | Privacy Policy    

 Linkedin-in     Mastodon     Facebook-f     Instagram     Envelope       

 Membership | Join Us Today 
  Why Join? 
  Pricing 
  Renew Membership 
  Membership FAQs 
  Terms and Conditions 
  Corporate Members 
  Member Portal 
  Events Calendar | Agile Alliance Events 
  Game On! 
  BYOC – Lean Coffee 
  Member Meet & Greet 
  Agile Tech Talks 
  Agile Coaching Network 
  Past Conferences & Events 
  Community Events | Community Events 
  Agile Training 
  Sponsored Meetup Groups 
  Submit an Event 
  Agile Essentials | Agile Essentials Overview 
  Agile 101 
  Agile Manifesto 
  12 Principles Behind the Manifesto 
  A Short History of Agile 
  Subway Map to Agile Practices 
  Agile Glossary 
  Introductory Videos 
  Resources | Resources Overview 
  Blog 
  Event Sessions 
  Videos 
  Experience Reports 
  Research Papers 
  Agile Glossary 
  Agile Books 
  Content Library by Category 
  Community | Member Initiatives 
  Community Events 
  Community Groups 
  Volunteer Signup 
  Community Services 
  Community Development | LATAM Community Development 
  India Community Development 
  About The Alliance | About Agile Alliance 
  Board of Directors 
  Our Team 
  Logo and Media Files 
  Become a Sponsor 
  Corporate Members 
  Contact Us 
  Our Policies | Code of Conduct 
  Policies, Reports & Bylaws 
  Content Standards 
  Privacy Policy 
  Cookie Policy 
  Global Affiliates | Agile Alliance Brazil 
  Agile Alliance New Zealand 

 Get the Latest Agile News  

 Get the latest news and updates from Agile Alliance, including event announcements, special offers, discounts, and more by becoming a newsletter subscriber today.  

 Sign Up Now      

 ©2024 Agile Alliance  
  All Rights Reserved | Privacy Policy    

 Linkedin-in     Mastodon     X-twitter     Facebook-f     Instagram       

    Privacy Preference Center  

 Options    
 Consent Management 

 Consent Management  

 OK   

 Welcome back! 

 IMPORTANT:  We have transitioned to a new membership platform. If you have not already done so, you will need to set up an account  on the new platform to establish your user profile.  

 When you see the login screen, choose “ Set up Account  ” and follow the prompts to create your new account. You can choose to log in using your social credentials for either Google or Linkedin (recommended), or you can set up your account using an email address.  

 Log in now      

 Membership Links 

  Username or Email Address     
 Password     
  Remember Me    
 Log In     
 Lost your password?  |  Register    

 Search    Search     

 Membership | Join Us Today 
  Why Join? 
  Pricing 
  Renew Membership 
  Membership FAQs 
  Terms and Conditions 
  Corporate Members 
  Member Portal 
  Events Calendar | Agile Alliance Events 
  Game On! 
  BYOC – Lean Coffee 
  Member Meet & Greet 
  Agile Tech Talks 
  Agile Coaching Network 
  Past Conferences & Events 
  Community Events | Community Events 
  Agile Training 
  Sponsored Meetup Groups 
  Submit an Event 
  Agile Essentials | Agile Essentials Overview 
  Agile 101 
  Agile Manifesto 
  12 Principles Behind the Manifesto 
  A Short History of Agile 
  Subway Map to Agile Practices 
  Agile Glossary 
  Introductory Videos 
  Resources | Resources Overview 
  Blog 
  Event Sessions 
  Videos 
  Experience Reports 
  Research Papers 
  Agile Glossary 
  Agile Books 
  Content Library by Category 
  Community | Member Initiatives 
  Community Events 
  Community Groups 
  Volunteer Signup 
  Community Services 
  Community Development | LATAM Community Development 
  India Community Development 
  About The Alliance | About Agile Alliance 
  Board of Directors 
  Our Team 
  Logo and Media Files 
  Become a Sponsor 
  Corporate Members 
  Contact Us 
  Our Policies | Code of Conduct 
  Policies, Reports & Bylaws 
  Content Standards 
  Privacy Policy 
  Cookie Policy 
  Global Affiliates | Agile Alliance Brazil 
  Agile Alliance New Zealand 

 Welcome back! 

  Username or Email Address     
 Password     
  Remember Me    
 Log In     
 Lost your password?  |  Register    

 Not yet a member? Sign up now   

 We use cookies on our website to give you the most relevant experience by remembering your preferences and repeat visits. By clicking “Accept”, you consent to the use of ALL the cookies. However you may visit Cookie Settings to provide a controlled consent.   
 Cookie settings  ACCEPT    

 Manage consent    
    Close   Privacy Overview  
 This website uses cookies to improve your experience while you navigate through the website. Out of these cookies, the cookies that are categorized as necessary are stored on your browser as they are essential for the working of basic functionalities of the website. We also use third-party cookies that help us analyze and understand how you use this website. These cookies will be stored in your browser only with your consent. You also have the option to opt-out of these cookies. But opting out of some of these cookies may have an effect on your browsing experience.  
   
  Please see our Privacy Notice  for further information.   

 Necessary   Necessary    
 Always Enabled    
 Necessary cookies are absolutely essential for the website to function properly. These cookies ensure basic functionalities and security features of the website, anonymously.  
  
 Cookie | Duration | Description 
 __cfduid | 1 month | The cookie is used by cdn services like CloudFare to identify individual clients behind a shared IP address and apply security settings on a per-client basis. It does not correspond to any user ID in the web application and does not store any personally identifiable information. 
 _csrf | session | This cookie is essential for the security of the website and visitor. It ensures visitor browsing security by preventing cross-site request forgery. 
 _GRECAPTCHA | 5 months 27 days | This cookie is set by Google. In addition to certain standard Google cookies, reCAPTCHA sets a necessary cookie (_GRECAPTCHA) when executed for the purpose of providing its risk analysis. 
 cookielawinfo-checbox-analytics | 11 months | This cookie is set by GDPR Cookie Consent plugin. The cookie is used to store the user consent for the cookies in the category "Analytics". 
 cookielawinfo-checbox-functional | 11 months | The cookie is set by GDPR cookie consent to record the user consent for the cookies in the category "Functional". 
 cookielawinfo-checbox-others | 11 months | This cookie is set by GDPR Cookie Consent plugin. The cookie is used to store the user consent for the cookies in the category "Other. 
 cookielawinfo-checkbox-advertisement | 1 year | The cookie is set by GDPR cookie consent to record the user consent for the cookies in the category "Advertisement". 
 cookielawinfo-checkbox-necessary | 11 months | This cookie is set by GDPR Cookie Consent plugin. The cookies is used to store the user consent for the cookies in the category "Necessary". 
 cookielawinfo-checkbox-performance | 11 months | This cookie is set by GDPR Cookie Consent plugin. The cookie is used to store the user consent for the cookies in the category "Performance". 
 gdpr[allowed_cookies] | 1 year | This cookie is set by the GDPR WordPress plugin. It is used to store the cookies allowed by the logged-in users and the visitors of the website. 
 JSESSIONID | session | Used by sites written in JSP. General purpose platform session cookies that are used to maintain users' state across page requests. 
 PHPSESSID | session | This cookie is native to PHP applications. The cookie is used to store and identify a users' unique session ID for the purpose of managing user session on the website. The cookie is a session cookies and is deleted when all the browser windows are closed. 
 pmpro_visit | The cookie is set by PaidMembership Pro plugin. The cookie is used to manage user memberships. 
 viewed_cookie_policy | 11 months | The cookie is set by the GDPR Cookie Consent plugin and is used to store whether or not user has consented to the use of cookies. It does not store any personal data. 

 Functional   functional     
   
 Functional cookies help to perform certain functionalities like sharing the content of the website on social media platforms, collect feedbacks, and other third-party features.  
  
 Cookie | Duration | Description 
 __atuvc | 1 year 1 month | This cookie is set by Addthis to make sure you see the updated count if you share a page and return to it before our share count cache is updated. 
 __atuvs | 30 minutes | This cookie is set by Addthis to make sure you see the updated count if you share a page and return to it before our share count cache is updated. 
 __jid | 30 minutes | Used to remember the user's Disqus login credentials across websites that use Disqus 
 aka_debug | This cookie is set by the provider Vimeo.This cookie is essential for the website to play video functionality. The cookie collects statistical information like how many times the video is displayed and what settings are used for playback. 
 bcookie | 2 years | This cookie is set by linkedIn. The purpose of the cookie is to enable LinkedIn functionalities on the page. 
 CONSENT | 16 years 8 months 15 days 5 hours | Description Pending 
 disqus_unique | 1 year | Disqus.com internal statistics 
 lang | session | This cookie is used to store the language preferences of a user to serve up content in that stored language the next time user visit the website. 
 language | This cookie is used to store the language preference of the user. 
 lidc | 1 day | This cookie is set by LinkedIn and used for routing. 
 locale | 3 days | This cookie is used to store the language preference of a user allowing the website to content relevant to the preferred language. 
 STYXKEY_aa_signup_visited | session | No description 

 Performance   performance     
   
 Performance cookies are used to understand and analyze the key performance indexes of the website which helps in delivering a better user experience for the visitors.  
  
 Cookie | Duration | Description 
 _gat_UA-17319182-1 | 1 minute | Set by Google Analytics and Google Tag Manager to enable website owners to track visitor behaviour and measure site performance. These cookies are used to collect information about how you use our website. The information collected includes number of visitors, pages visited and time spent on the website. The information is collected by Google Analytics in aggregated and anonymous form, and we use the data to help us make improvements to the website. 
 YSC | session | This cookies is set by Youtube and is used to track the views of embedded videos. 

 Analytics   analytics     
   
 Analytical cookies are used to understand how visitors interact with the website. These cookies help provide information on metrics the number of visitors, bounce rate, traffic source, etc.  
  
 Cookie | Duration | Description 
 _ga | 2 years | This cookie is installed by Google Analytics. The cookie is used to calculate visitor, session, campaign data and keep track of site usage for the site's analytics report. The cookies store information anonymously and assign a randomly generated number to identify unique visitors. 
 _gat_gtag_UA_17319182_1 | 1 minute | Set by Google Analytics and Google Tag Manager to enable website owners to track visitor behaviour and measure site performance. These cookies are used to collect information about how you use our website. The information collected includes number of visitors, pages visited and time spent on the website. The information is collected by Google Analytics in aggregated and anonymous form, and we use the data to help us make improvements to the website. 
 _gat_UA-0000000-1 | 1 minute | Set by Google Analytics and Google Tag Manager to enable website owners to track visitor behaviour and measure site performance. These cookies are used to collect information about how you use our website. The information collected includes number of visitors, pages visited and time spent on the website. The information is collected by Google Analytics in aggregated and anonymous form, and we use the data to help us make improvements to the website. 
 _gid | 1 day | This cookie is installed by Google Analytics. The cookie is used to store information of how visitors use a website and helps in creating an analytics report of how the website is doing. The data collected including the number visitors, the source where they have come from, and the pages visted in an anonymous form. 
 eud | 1 year 24 days | The domain of this cookie is owned by Rocketfuel. This cookie is used to sync with partner systems to identify the users. This cookie contains partner user IDs and last successful match time. 
 S | 1 hour | domain .google.com 
 uvc | 1 year 1 month | The cookie is set by addthis.com to determine the usage of Addthis.com service. 
 vuid | 2 years | This domain of this cookie is owned by Vimeo. This cookie is used by vimeo to collect tracking information. It sets a unique ID to embed videos to the website. 

 Advertisement   advertisement     
   
 Advertisement cookies are used to provide visitors with relevant ads and marketing campaigns. These cookies track visitors across websites and collect information to provide customized ads.  
  
 Cookie | Duration | Description 
 _fbp | 3 months | This cookie is set by Facebook to deliver advertisement when they are on Facebook or a digital platform powered by Facebook advertising after visiting this website. 
 AnalyticsSyncHistory | 1 month | Used to store information about the time a sync with the lms_analytics cookie took place for users in the Designated Countries 
 bscookie | 2 years | This cookie is a browser ID cookie set by Linked share Buttons and ad tags. 
 euds | session | These cookies are from Rocket Fuel (rfihub.com) and are used to deliver targeted advertising across their network sites ensuring users see relevant advertising. 
 fr | 3 months | The cookie is set by Facebook to show relevant advertisments to the users and measure and improve the advertisements. The cookie also tracks the behavior of the user across the web on sites that have Facebook pixel or Facebook social plugin. 
 IDE | 1 year 24 days | Used by Google DoubleClick and stores information about how the user uses the website and any other advertisement before visiting the website. This is used to present users with ads that are relevant to them according to the user profile. 
 loc | 1 year 1 month | This cookie is set by Addthis. This is a geolocation cookie to understand where the users sharing the information are located. 
 NID | 6 months | This cookie is used to a profile based on user's interest and display personalized ads to the users. 
 pxrc | 2 months | The purpose of the cookie is to identify a visitor to serve relevant advertisement. 
 rlas3 | 1 year | The cookie is set by rlcdn.com. The cookie is used to serve relevant ads to the visitor as well as limit the time the visitor sees an and also measure the effectiveness of the campaign. 
 rud | 1 year 24 days | The domain of this cookie is owned by Rocketfuel. The main purpose of this cookie is advertising. This cookie is used to identify an user by an alphanumeric ID. It register the user data like IP, location, visited website, ads clicked etc with this it optimize the ads display based on user behaviour. 
 ruds | session | The domain of this cookie is owned by Rocketfuel. This cookie is a session cookie version of the 'rud' cookie. It contain the user ID information. It is used to deliver targeted advertising across the networks. 
 sd-session-id | 1 year 24 days | Registers data on visitors from multiple visits and on multiple websites. This information is used to measure the efficiency of advertisement on websites. | Registers data on visitors from multiple visits and on multiple websites. This information is used to measure the efficiency of advertisement on websites. 
 Registers data on visitors from multiple visits and on multiple websites. This information is used to measure the efficiency of advertisement on websites. 
 test_cookie | 15 minutes | This cookie is set by doubleclick.net. The purpose of the cookie is to determine if the user's browser supports cookies. 
 UID | 2 years | This cookie is used by AddThis as a unique user ID that recognises the user on returning visits. 
 UserMatchHistory | 1 month | Linkedin - Used to track visitors on multiple websites, in order to present relevant advertisement based on the visitor's preferences. 
 uuid2 | 3 months | This cookies is set by AppNexus. The cookies stores information that helps in distinguishing between devices and browsers. This information us used to select advertisements served by the platform and assess the performance of the advertisement and attribute payment for those advertisements. 
 VISITOR_INFO1_LIVE | 5 months 27 days | This cookie is set by Youtube. Used to track the information of the embedded YouTube videos on a website. 
 xtc | 1 year 1 month | Anonymously tracks user behaviour on the websites that allow a user to share pages on social media using the AddThis tool. AddThis log the anonymous use to generate usage trends to improve the relevance of their services and advertising. 
 zync-uuid | 1 year 23 days 17 hours | The purpose of the cookie is to serve visitors with relevant advertisement. 

 Others   others     
   
 Other uncategorized cookies are those that are being analyzed and have not been classified into a category as yet.  
  
 Cookie | Duration | Description 
 CP5XKN6QLDFWUC | This cookie is provided by the Calculated Fields form. This cookie is used by the online calculators on the website. Without the Calculated Fields cookie the instant quotation may not work. 

 Save & Accept

76. EAMT_2 conference:
ACL Anthology     News (current) 
  FAQ (current) 
  Corrections (current) 
  Submissions (current) 
  Github 

 Conference of the European Association for Machine Translation (2023)  
  Volumes  
 Proceedings of the 24th Annual Conference of the European Association for Machine Translation | 62 papers 
  Proceedings of the Second International Workshop on Automatic Translation for Signed and Spoken Languages | 7 papers 
  Proceedings of the 1st Workshop on Open Community-Driven Machine Translation | 6 papers 
  Proceedings of the First Workshop on Gender-Inclusive Translation Technologies | 10 papers 
  Proceedings of the 1st International Workshop on Multilingual, Multimodal and Multitask Language Generation | 8 papers 

 Show all abstracts   Hide all abstracts     up   pdf (full)   
  bib (full)   Proceedings of the 24th Annual Conference of the European Association for Machine Translation   
 pdf  bib   
   Proceedings of the 24th Annual Conference of the European Association for Machine Translation    
  Mary Nurminen  | Judith Brenner  | Maarit Koponen  | Sirkku Latomaa  | Mikhail Mikhailov  | Frederike Schierl  | Tharindu Ranasinghe  | Eva Vanmassenhove  | Sergi Alvarez Vidal  | Nora Aranberri  | Mara Nunziatini  | Carla Parra Escartín  | Mikel Forcada  | Maja Popovic  | Carolina Scarton  | Helena Moniz    
 pdf  bib   
   Towards Efficient Universal Neural Machine Translation    
  Biao Zhang    
 pdf  bib  abs   
   Tailoring Domain Adaptation for Machine Translation Quality Estimation    
  Javad Pourmostafa Roshan Sharami  | Dimitar Shterionov  | Frédéric Blain  | Eva Vanmassenhove  | Mirella De Sisto  | Chris Emmery  | Pieter Spronck    
 While quality estimation (QE) can play an important role in the translation process, its effectiveness relies on the availability and quality of training data. For QE in particular, high-quality labeled data is often lacking due to the high-cost and effort associated with labeling such data. Aside from the data scarcity challenge, QE models should also be generalizabile, i.e., they should be able to handle data from different domains, both generic and specific. To alleviate these two main issues — data scarcity and domain mismatch — this paper combines domain adaptation and data augmentation within a robust QE system. Our method is to first train a generic QE model and then fine-tune it on a specific domain while retaining generic knowledge. Our results show a significant improvement for all the language pairs investigated, better cross-lingual inference, and a superior performance in zero-shot learning scenarios as compared to state-of-the-art baselines.   
   
 pdf  bib  abs   
   Example-Based Machine Translation from Textto a Hierarchical Representation of Sign Language    
  Elise Bertin-Lemée  | Annelies Braffort  | Camille Challant  | Claire Danet  | Michael Filhol    
 This article presents an original method for Text-to-Sign Translation. It compensates data scarcity using a domain-specific parallel corpus of alignments between text and hierarchical formal descriptions of Sign Language videos. Based on the detection of similarities present in the source text, the proposed algorithm recursively exploits matches and substitutions of aligned segments to build multiple candidate translations for a novel statement. This helps preserving Sign Language structures as much as possible before falling back on literal translations too quickly, in a generative way. The resulting translations are in the form of AZee expressions, designed to be used as input to avatar synthesis systems. We present a test set tailored to showcase its potential for expressiveness and generation of idiomatic target language, and observed limitations. This work finally opens prospects on how to evaluate this kind of translation.   
   
 pdf  bib  abs   
   Unsupervised Feature Selection for Effective Parallel Corpus Filtering    
  Mikko Aulamo  | Ona de Gibert  | Sami Virpioja  | Jörg Tiedemann    
 This work presents an unsupervised method of selecting filters and threshold values for the OpusFilter parallel corpus cleaning toolbox. The method clusters sentence pairs into noisy and clean categories and uses the features of the noisy cluster center as filtering parameters. Our approach utilizes feature importance analysis to disregard filters that do not differentiate between clean and noisy data. A randomly sampled subset of a given corpus is used for filter selection and ineffective filters are not run for the full corpus. We use a set of automatic evaluation metrics to assess the quality of translation models trained with data filtered by our method and data filtered with OpusFilter’s default parameters. The trained models cover English-German and English-Ukrainian in both directions. The proposed method outperforms the default parameters in all translation directions for almost all evaluation metrics.   
   
 pdf  bib  abs   
   Filtering and rescoring the CCM  atrix corpus for Neural Machine Translation training    
  Antoni Oliver González  | Sergi Álvarez    
 There are several parallel corpora available for many language pairs, such as CCMatrix, built from mass downloads of web content and automatic detection of segments in one language and the translation equivalent in another. These techniques can produce large parallel corpora, but of questionable quality. In many cases, the segments are not in the required languages, or if they are, they are not translation equivalents. In this article, we present an algorithm for filtering out the segments in languages other than the required ones and re-scoring the segments using SBERT. A use case on the Spanish-Asturian and Spanish-Catalan CCMatrix corpus is presented.   
   
 pdf  bib  abs   
   BLEU  Meets COMET  : Combining Lexical and Neural Metrics Towards Robust Machine Translation Evaluation    
  Taisiya Glushkova  | Chrysoula Zerva  | André F. T. Martins    
 Although neural-based machine translation evaluation metrics, such as COMET or BLEURT, have achieved strong correlations with human judgements, they are sometimes unreliable in detecting certain phenomena that can be considered as critical errors, such as deviations in entities and numbers. In contrast, traditional evaluation metrics such as BLEU or chrF, which measure lexical or character overlap between translation hypotheses and human references, have lower correlations with human judgements but are sensitive to such deviations. In this paper, we investigate several ways of combining the two approaches in order to increase robustness of state-of-the-art evaluation methods to translations with critical errors. We show that by using additional information during training, such as sentence-level features and word-level tags, the trained metrics improve their capability to penalize translations with specific troublesome phenomena, which leads to gains in correlations with humans and on the recent DEMETR benchmark on several language pairs.   
   
 pdf  bib  abs   
   Exploiting large pre-trained models for low-resource neural machine translation    
  Aarón Galiano-Jiménez  | Felipe Sánchez-Martínez  | Víctor M. Sánchez-Cartagena  | Juan Antonio Pérez-Ortiz    
 Pre-trained models have drastically changed the field of natural language processing by providing a way to leverage large-scale language representations to various tasks. Some pre-trained models offer general-purpose representations, while others are specialized in particular tasks, like neural machine translation (NMT). Multilingual NMT-targeted systems are often fine-tuned for specific language pairs, but there is a lack of evidence-based best-practice recommendations to guide this process. Moreover, the trend towards even larger pre-trained models has made it challenging to deploy them in the computationally restrictive environments typically found in developing regions where low-resource languages are usually spoken. We propose a pipeline to tune the mBART50 pre-trained model to 8 diverse low-resource language pairs, and then distil the resulting system to obtain lightweight and more sustainable models. Our pipeline conveniently exploits back-translation, synthetic corpus filtering, and knowledge distillation to deliver efficient, yet powerful bilingual translation models 13 times smaller than the original pre-trained ones, but with close performance in terms of BLEU.   
   
 pdf  bib  abs   
   Enhancing Supervised Learning with Contrastive Markings in Neural Machine Translation Training    
  Nathaniel Berger  | Miriam Exel  | Matthias Huck  | Stefan Riezler    
 Supervised learning in Neural Machine Translation (NMT) standardly follows a teacher forcing paradigm where the conditioning context in the model’s prediction is constituted by reference tokens, instead of its own previous predictions. In order to alleviate this lack of exploration in the space of translations, we present a simple extension of standard maximum likelihood estimation by a contrastive marking objective. The additional training signals are extracted automatically from reference translations by comparing the system hypothesis against the reference, and used for up/down-weighting correct/incorrect tokens. The proposed new training procedure requires one additional translation pass over the training set, and does not alter the standard inference setup. We show that training with contrastive markings yields improvements on top of supervised learning, and is especially useful when learning from postedits where contrastive markings indicate human error corrections to the original hypotheses.   
   
 pdf  bib  abs   
   Return to the Source: Assessing Machine Translation Suitability    
  Francesco Fernicola  | Silvia Bernardini  | Federico Garcea  | Adriano Ferraresi  | Alberto Barrón-Cedeño    
 We approach the task of assessing the suitability of a source text for translation by transferring the knowledge from established MT evaluation metrics to a model able to predict MT quality a priori from the source text alone. To open the door to experiments in this regard, we depart from reference English-German parallel corpora to build a corpus of 14,253 source text-quality score tuples. The tuples include four state-of-the-art metrics: cushLEPOR, BERTScore, COMET, and TransQuest. With this new resource at hand, we fine-tune XLM-RoBERTa, both in a single-task and a multi-task setting, to predict these evaluation scores from the source text alone. Results for this methodology are promising, with the single-task model able to approximate well-established MT evaluation and quality estimation metrics - without looking at the actual machine translations - achieving low RMSE values in the [0.1-0.2] range and Pearson correlation scores up to 0.688.   
   
 pdf  bib  abs   
   Empirical Analysis of Beam Search Curse and Search Errors with Model Errors in Neural Machine Translation    
  Jianfei He  | Shichao Sun  | Xiaohua Jia  | Wenjie Li    
 Beam search is the most popular decoding method for Neural Machine Translation (NMT) and is still a strong baseline compared with the newly proposed sampling-based methods. To better understand beam search, we investigate its two well-recognized issues, beam search curse and search errors, at the sentence level. We find that only less than 30% of sentences in the test set experience these issues. Meanwhile, there is a related phenomenon. For the majority of sentences, their gold references have lower probabilities than the predictions from beam search. We also test with different levels of model errors including a special test using training samples and models without regularization. We find that these phenomena still exist even for a model with an accuracy of 95% although they are mitigated. These findings show that it is not promising to improve beam search by seeking higher probabilities in searching and further reducing its search errors. The relationship between the quality and the probability of predictions at the sentence level in our results provides useful information to find new ways to improve NMT.   
   
 pdf  bib  abs   
   An Empirical Study of Leveraging Knowledge Distillation for Compressing Multilingual Neural Machine Translation Models    
  Varun Gumma  | Raj Dabre  | Pratyush Kumar    
 Knowledge distillation (KD) is a well-known method for compressing neural models. However, works focusing on distilling knowledge from large multilingual neural machine translation (MNMT) models into smaller ones are practically nonexistent, despite the popularity and superiority of MNMT. This paper bridges this gap by presenting an empirical investigation of knowledge distillation for compressing MNMT models. We take Indic to English translation as a case study and demonstrate that commonly used language-agnostic and language-aware KD approaches yield models that are 4-5x smaller but also suffer from performance drops of up to 3.5 BLEU. To mitigate this, we then experiment with design considerations such as shallower versus deeper models, heavy parameter sharing, multistage training, and adapters. We observe that deeper compact models tend to be as good as shallower non-compact ones and that fine-tuning a distilled model on a high-quality subset slightly boosts translation quality. Overall, we conclude that compressing MNMT models via KD is challenging, indicating immense scope for further research.   
   
 pdf  bib  abs   
   Empirical Assessment of k NN  - MT  for Real-World Translation Scenarios    
  Pedro Henrique Martins  | João Alves  | Tânia Vaz  | Madalena Gonçalves  | Beatriz Silva  | Marianna Buchicchio  | José G. C. de Souza  | André F. T. Martins    
 This paper aims to investigate the effectiveness of the k-Nearest Neighbor Machine Translation model (kNN-MT) in real-world scenarios. kNN-MT is a retrieval-augmented framework that combines the advantages of parametric models with non-parametric datastores built using a set of parallel sentences. Previous studies have primarily focused on evaluating the model using only the BLEU metric and have not tested kNN-MT in real world scenarios. Our study aims to fill this gap by conducting a comprehensive analysis on various datasets comprising different language pairs and different domains, using multiple automatic metrics and expert evaluated Multidimensional Quality Metrics (MQM). We compare kNN-MT with two alternate strategies: fine-tuning all the model parameters and adapter-based finetuning. Finally, we analyze the effect of the datastore size on translation quality, and we examine the number of entries necessary to bootstrap and configure the index.   
   
 pdf  bib  abs   
   Evaluation of C  hinese- E  nglish Machine Translation of Emotion-Loaded Microblog Texts: A Human Annotated Dataset for the Quality Assessment of Emotion Translation    
  Shenbin Qian  | Constantin Orasan  | Felix Do Carmo  | Qiuliang Li  | Diptesh Kanojia    
 In this paper, we focus on how current Machine Translation (MT) engines perform on the translation of emotion-loaded texts by evaluating outputs from Google Translate according to a framework proposed in this paper. We propose this evaluation framework based on the Multidimensional Quality Metrics (MQM) and perform detailed error analyses of the MT outputs. From our analysis, we observe that about 50% of MT outputs are erroneous in preserving emotions. After further analysis of the erroneous examples, we find that emotion carrying words and linguistic phenomena such as polysemous words, negation, abbreviation etc., are common causes for these translation errors.   
   
 pdf  bib  abs   
   Assessing the Importance of Frequency versus Compositionality for Subword-based Tokenization in NMT     
  Benoist Wolleb  | Romain Silvestri  | Georgios Vernikos  | Ljiljana Dolamic  | Andrei Popescu-Belis    
 Subword tokenization is the de-facto standard for tokenization in neural language models and machine translation systems. Three advantages are frequently put forward in favor of subwords: shorter encoding of frequent tokens, compositionality of subwords, and ability to deal with unknown words. As their relative importance is not entirely clear yet, we propose a tokenization approach that enables us to separate frequency (the first advantage) from compositionality, thanks to the use of Huffman coding, which tokenizes words using a fixed amount of symbols. Experiments with CS-DE, EN-FR and EN-DE NMT show that frequency alone accounts for approximately 90% of the BLEU scores reached by BPE, hence compositionality has less importance than previously thought.   
   
 pdf  bib  abs   
   What Works When in Context-aware Neural Machine Translation?    
  Harritxu Gete  | Thierry Etchegoyhen  | Gorka Labaka    
 Document-level Machine Translation has emerged as a promising means to enhance automated translation quality, but it is currently unclear how effectively context-aware models use the available context during translation. This paper aims to provide insight into the current state of models based on input concatenation, with an in-depth evaluation on English–German and English–French standard datasets. We notably evaluate the impact of data bias, antecedent part-of-speech, context complexity, and the syntactic function of the elements involved in discursive phenomena. Our experimental results indicate that the selected models do improve the overall translation in context, with varying sensitivity to the different factors we examined. We notably show that the selected context-aware models operate markedly better on regular syntactic configurations involving subject antecedents and pronouns, with degraded performance as the configurations become more dissimilar.   
   
 pdf  bib  abs   
   Investigating the Translation Performance of a Large Multilingual Language Model: the Case of BLOOM     
  Rachel Bawden  | François Yvon    
 The NLP community recently saw the release of a new large open-access multilingual language model, BLOOM (BigScience et al., 2022) covering 46 languages. We focus on BLOOM’s multilingual ability by evaluating its machine translation performance across several datasets (WMT, Flores-101 and DiaBLa) and language pairs (high- and low-resourced). Our results show that 0-shot performance suffers from overgeneration and generating in the wrong language, but this is greatly improved in the few-shot setting, with very good results for a number of language pairs. We study several aspects including prompt design, model sizes, cross-lingual transfer and the use of discursive context.   
   
 pdf  bib  abs   
   The MT  @ BZ  corpus: machine translation & legal language    
  Flavia De Camillis  | Egon W. Stemle  | Elena Chiocchetti  | Francesco Fernicola    
 The paper reports on the creation, annotation and curation of the MT@BZ corpus, a bilingual (Italian–South Tyrolean German) corpus of machine-translated legal texts from the officially multilingual Province of Bolzano, Italy. It is the first human error-annotated corpus (using an adapted SCATE taxonomy) of machine-translated legal texts in this language combination that includes a lesser-used standard variety. The data of the project will be made available on GitHub and another repository. The output of the customized engine achieved notably better BLEU, TER and chrF2 scores than the baseline. Over 50% of the segments needed no human revision due to customization. The most frequent error categories were mistranslations and bilingual (legal) terminology errors. Our contribution brings fine-grained insights to Machine translation evaluation research, as it concerns a less common language combination, a lesser-used language variety and a societally relevant specialized domain. Such results are necessary to implement and inform the use of MT in institutional contexts of smaller language communities.   
   
 pdf  bib  abs   
   Investigating Lexical Sharing in Multilingual Machine Translation for I  ndian Languages    
  Sonal Sannigrahi  | Rachel Bawden    
 Multilingual language models have shown impressive cross-lingual transfer ability across a diverse set of languages and tasks. To improve the cross-lingual ability of these models, some strategies include transliteration and finer-grained segmentation into characters as opposed to subwords. In this work, we investigate lexical sharing in multilingual machine translation (MT) from Hindi, Gujarati, Nepali into English. We explore the trade-offs that exist in translation performance between data sampling and vocabulary size, and we explore whether transliteration is useful in encouraging cross-script generalisation. We also verify how the different settings generalise to unseen languages (Marathi and Bengali). We find that transliteration does not give pronounced improvements and our analysis suggests that our multilingual MT models trained on original scripts are already robust to cross-script differences even for relatively low-resource languages.   
   
 pdf  bib  abs   
   Large Language Models Are State-of-the-Art Evaluators of Translation Quality    
  Tom Kocmi  | Christian Federmann    
 We describe GEMBA, a GPT-based metric for assessment of translation quality, which works both with a reference translation and without. In our evaluation, we focus on zero-shot prompting, comparing four prompt variants in two modes, based on the availability of the reference. We investigate seven versions of GPT models, including ChatGPT. We show that our method for translation quality assessment only works with GPT 3.5 and larger models. Comparing to results from WMT22’s Metrics shared task, our method achieves state-of-the-art accuracy in both modes when compared to MQM-based human labels. Our results are valid on the system level for all three WMT22 Metrics shared task language pairs, namely English into German, English into Russian, and Chinese into English. This provides a first glimpse into the usefulness of pre-trained, generative large language models for quality assessment of translations. We publicly release all our code and prompt templates used for the experiments described in this work, as well as all corresponding scoring results, to allow for external validation and reproducibility.   
   
 pdf  bib  abs   
   State Spaces Aren’t Enough: Machine Translation Needs Attention    
  Ali Vardasbi  | Telmo Pessoa Pires  | Robin Schmidt  | Stephan Peitz    
 Structured State Spaces for Sequences (S4) is a recently proposed sequence model with successful applications in various tasks, e.g. vision, language modelling, and audio. Thanks to its mathematical formulation, it compresses its input to a single hidden state, and is able to capture long range dependencies while avoiding the need for an attention mechanism. In this work, we apply S4 to Machine Translation (MT), and evaluate several encoder-decoder variants on WMT’14 and WMT’16. In contrast with the success in language modeling, we find that S4 lags behind the Transformer by approximately 4 BLEU points, and that it counter-intuitively struggles with long sentences. Finally, we show that this gap is caused by S4’s inability to summarize the full source sentence in a single hidden state, and show that we can close the gap by introducing an attention mechanism.   
   
 pdf  bib  abs   
   Automatic Discrimination of Human and Neural Machine Translation in Multilingual Scenarios    
  Malina Chichirau  | Rik van Noord  | Antonio Toral    
 We tackle the task of automatically discriminating between human and machine translations. As opposed to most previous work, we perform experiments in a multilingual setting, considering multiple languages and multilingual pretrained language models. We show that a classifier trained on parallel data with a single source language (in our case German–English) can still perform well on English translations that come from different source languages, even when the machine translations were produced by other systems than the one it was trained on. Additionally, we demonstrate that incorporating the source text in the input of a multilingual classifier improves (i) its accuracy and (ii) its robustness on cross-system evaluation, compared to a monolingual classifier. Furthermore, we find that using training data from multiple source languages (German, Russian and Chinese) tends to improve the accuracy of both monolingual and multilingual classifiers. Finally, we show that bilingual classifiers and classifiers trained on multiple source languages benefit from being trained on longer text sequences, rather than on sentences.   
   
 pdf  bib  abs   
   Adaptive Machine Translation with Large Language Models    
  Yasmin Moslem  | Rejwanul Haque  | John D. Kelleher  | Andy Way    
 Consistency is a key requirement of high-quality translation. It is especially important to adhere to pre-approved terminology and adapt to corrected translations in domain-specific projects. Machine translation (MT) has achieved significant progress in the area of domain adaptation. However, real-time adaptation remains challenging. Large-scale language models (LLMs) have recently shown interesting capabilities of in-context learning, where they learn to replicate certain input-output text generation patterns, without further fine-tuning. By feeding an LLM at inference time with a prompt that consists of a list of translation pairs, it can then simulate the domain and style characteristics. This work aims to investigate how we can utilize in-context learning to improve real-time adaptive MT. Our extensive experiments show promising results at translation time. For example, GPT-3.5 can adapt to a set of in-domain sentence pairs and/or terminology while translating a new sentence. We observe that the translation quality with few-shot in-context learning can surpass that of strong encoder-decoder MT systems, especially for high-resource languages. Moreover, we investigate whether we can combine MT from strong encoder-decoder models with fuzzy matches, which can further improve translation quality, especially for less supported languages. We conduct our experiments across five diverse language pairs, namely English-to-Arabic (EN-AR), English-to-Chinese (EN-ZH), English-to-French (EN-FR), English-to-Kinyarwanda (EN-RW), and English-to-Spanish (EN-ES).   
   
 pdf  bib  abs   
   Segment-based Interactive Machine Translation at a Character Level    
  Angel Navarro  | Miguel Domingo  | Francisco Casacuberta    
 To produce high quality translations, human translators need to review and correct machine translation hypothesis in what it is known as post-editing. In order to reduce the human effort of this process, interactive machine translation proposed a collaborative framework in which human and machine work together to generate the translations. Among the many protocols proposed throughout the years, the segment-based one established a paradigm in which the post-editor was allowed to validate correct word sequences from a translation hypothesis and introduced a word correction to help the system improve the next hypothesis. In this work we propose an extension to this protocol: instead of having to the type the complete word correction, the system will complete the user’s correction while they are typing. We evaluated our proposal under a simulated environment, achieving a significant reduction of the human effort.   
   
 pdf  bib  abs   
   Gender-Fair Post-Editing: A Case Study Beyond the Binary    
  Manuel Lardelli  | Dagmar Gromann    
 Machine Translation (MT) models are well-known to suffer from gender bias, especially for gender beyond a binary conception. Due to the multiplicity of language-specific strategies for gender representation beyond the binary, debiasing MT is extremely challenging. As an alternative, we propose a case study on gender-fair post-editing. In this study, six professional translators each post-edited three English to German machine translations. For each translation, participants were instructed to use a different gender-fair language strategy, that is, gender-neutral rewording, gender-inclusive characters, and a neosystem. The focus of this study is not on translation quality but rather on the ease of integrating gender-fair language into the post-editing process. Findings from non-participant observation and interviews show clear differences in temporal and cognitive effort between participants and strategy as well as in the success of using gender-fair language.   
   
 pdf  bib  abs   
   “Translationese” (and “post-editese”?) no more: on importing fuzzy conceptual tools from Translation Studies in MT  research    
  Miguel A. Jimenez-Crespo    
 During recent years, MT research has imported a number of conceptual tools from Translation Studies such as “translationese” or “translation universals”. These notions were the object of intense conceptual debates in Corpus-Based Translation Studies (CBTS), and number of seminal publications and conference forums recommended substituting them by less problematic terms such as “the language of translation” or “typical” or “general features of translated language”. This paper critically analyses the arguments put forward in the early 2000’s in CBTS to against the use of these terms, and whether the same issues apply to current MT re-search using them. Here, the paper will discuss, (1) the impact of the negative or pejorative nature of the term “translationese” on the status of professional translators and translation products in academia and society (2) the danger of over-generalizations or overextending claims found in specific and very limited textual subsets, as well as (3) the need to reframe the search of tendencies in translated language away from “universals” towards probabilistic, situational or conditional tendencies. It will be argued that MT re-search would benefit from clearly defined terms to deal with notions related to language variation in specific new variants of translation, proposing neutral terms such as “NMT translated language” or “the language of NMT”, as well as “general features/ tendencies in NMT / PE translations”. A proposal will be made in order to reach a “convergence” of MT and TS research and the probabilistic and descriptive study of features of (NMT or human) translated language.   
   
 pdf  bib  abs   
   A social media NMT  engine for a low-resource language combination    
  María Do Campo Bayón  | Pilar Sánchez-Gijón    
 The aim of this article is to present a new Neural Machine Translation (NMT) from Spanish into Galician for the social media domain that was trained with a Twitter corpus. Our main goal is to outline the methods used to build the corpus and the steps taken to train the engine in a low-resource language context. We have evalu-ated the engine performance both with regular automatic metrics and with a new methodology based on the non-inferiority process and contrasted this information with an error classification human evalua-tion conducted by professional linguists. We will present the steps carried out fol-lowing the conclusions of a previous pilot study, describe the new process followed, analyze the new engine and present the final conclusions.   
   
 pdf  bib  abs   
   Analysing Mistranslation of Emotions in Multilingual Tweets by Online MT  Tools    
  Hadeel Saadany  | Constantin Orasan  | Rocio Caro Quintana  | Felix Do Carmo  | Leonardo Zilio    
 It is common for websites that contain User-Generated Text (UGT) to provide an automatic translation option to reach out to their linguistically diverse users. In such scenarios, the process of translating the users’ emotions is entirely automatic with no human intervention, neither for post-editing, nor for accuracy checking. In this paper, we assess whether automatic translation tools can be a successful real-life utility in transferring emotion in multilingual tweets. Our analysis shows that the mistranslation of the source tweet can lead to critical errors where the emotion is either completely lost or flipped to an opposite sentiment. We identify linguistic phenomena specific to Twitter data which pose a challenge in translation of emotions and show how frequent these features are in different language pairs. We also show that commonly-used quality metrics can lend false confidence in the performance of online MT tools specifically when the source emotion is distorted in telegraphic messages such as tweets.   
   
 pdf  bib  abs   
   D  ata L  it MT  – Teaching Data Literacy in the Context of Machine Translation Literacy    
  Janiça Hackenbuchner  | Ralph Krüger    
 This paper presents the DataLitMT project conducted at TH Koln – University of Applied Sciences. The project develops learning resources for teaching data literacy in its translation-specific form of professional machine translation (MT) literacy to students of translation and specialised communication programmes at BA and MA levels. We discuss the need for data literacy teaching in a translation/specialised communication context, present the three theoretical pillars of the project (consisting of a Professional MT Literacy Framework, an MT-specific data literacy framework and a competence matrix derived from these frameworks) and give an overview of the learning resources developed as part of the project.   
   
 pdf  bib  abs   
   Do Humans Translate like Machines? Students’ Conceptualisations of Human and Machine Translation    
  Salmi Leena  | Aletta G. Dorst  | Maarit Koponen  | Katinka Zeven    
 This paper explores how students conceptualise the processes involved in human and machine translation, and how they describe the similarities and differences between them. The paper presents the results of a survey involving university students (B.A. and M.A.) taking a course on translation who filled out an online questionnaire distributed in Finnish, Dutch and English. Our study finds that students often describe both human translation and machine translation in similar terms, suggesting they do not sufficiently distinguish between them and do not fully understand how machine translation works. The current study suggests that training in Machine Translation Literacy may need to focus more on the conceptualisations involved and how conceptual and vernacular misconceptions may affect how translators understand human and machine translation.   
   
 pdf  bib  abs   
   Adapting Machine Translation Education to the Neural Era: A Case Study of MT  Quality Assessment    
  Lieve Macken  | Bram Vanroy  | Arda Tezcan    
 The use of automatic evaluation metrics to assess Machine Translation (MT) quality is well established in the translation industry. Whereas it is relatively easy to cover the word- and character-based metrics in an MT course, it is less obvious to integrate the newer neural metrics. In this paper we discuss how we introduced the topic of MT quality assessment in a course for translation students. We selected three English source texts, each having a different difficulty level and style, and let the students translate the texts into their L1 and reflect upon translation difficulty. Afterwards, the students were asked to assess MT quality for the same texts using different methods and to critically reflect upon obtained results. The students had access to the MATEO web interface, which contains word- and character-based metrics as well as neural metrics. The students used two different reference translations: their own translations and professional translations of the three texts. We not only synthesise the comments of the students, but also present the results of some cross-lingual analyses on nine different language pairs.   
   
 pdf  bib  abs   
   PE  effort and neural-based automatic MT  metrics: do they correlate?    
  Sergi Alvarez  | Antoni Oliver    
 Neural machine translation (NMT) has shown overwhelmingly good results in recent times. This improvement in quality has boosted the presence of NMT in nearly all fields of translation. Most current translation industry workflows include postediting (PE) of MT as part of their process. For many domains and language combinations, translators post-edit raw machine translation (MT) to produce the final document. However, this process can only work properly if the quality of the raw MT output can be assured. MT is usually evaluated using automatic scores, as they are much faster and cheaper. However, traditional automatic scores have not been good quality indicators and do not correlate with PE effort. We analyze the correlation of each of the three dimensions of PE effort (temporal, technical and cognitive) with COMET, a neural framework which has obtained outstanding results in recent MT evaluation campaigns.   
   
 pdf  bib  abs   
   Migrant communities living in the N  etherlands and their use of MT  in healthcare settings    
  Susana Valdez  | Ana Guerberof Arenas  | Kars Ligtenberg    
 As part of a larger project on the use of MT in healthcare settings among migrant communities, this paper investigates if, when, how and with what (potential) challenges migrants use MT based on a survey of 201 non-native speakers of Dutch currently living in the Netherlands. Three main findings stand out from our analysis. First, most migrants use MT to understand health information in Dutch and communicate with health professionals. How MT is used and received varies depending on the context and the L2 language level, as well as age, but not on the educational level. Second, some users face challenges of different kinds, including a lack of trust or perceived inaccuracies. Some of these challenges are related to comprehension, which brings us to our third point. We argue that a more nuanced understanding of medical translation is needed in expert-to-non-expert health communication. This questionnaire helped us identify several topics we hope to explore in the project’s next phase.   
   
 pdf  bib  abs   
   Measuring Machine Translation User Experience ( MTUX  ): A Comparison between A  ttrak D  iff and User Experience Questionnaire    
  Vicent Briva-Iglesias  | Sharon O’Brien    
 Perceptions and experiences of machine translation (MT) users before, during, and after their interaction with MT systems, products or services has been overlooked both in academia and in industry. Tradi-tionally, the focus has been on productivi-ty and quality, often neglecting the human factor. We propose the concept of Ma-chine Translation User Experience (MTUX) for assessing, evaluating, and getting further information about the user experiences of people interacting with MT. By conducting a human-computer in-teraction (HCI)-based study with 15 pro-fessional translators, we analyse which is the best method for measuring MTUX, and conclude by suggesting the use of the User Experience Questionnaire (UEQ). The measurement of MTUX will help eve-ry stakeholder in the MT industry - devel-opers will be able to identify pain points for the users and solve them in the devel-opment process, resulting in better MTUX and higher adoption of MT systems or products by MT users.   
   
 pdf  bib  abs   
   Coming to Terms with Glossary Enforcement: A Study of Three Approaches to Enforcing Terminology in NMT     
  Fred Bane  | Anna Zaretskaya  | Tània Blanch Miró  | Celia Soler Uguet  | João Torres    
 Enforcing terminology constraints is less straight-forward in neural machine translation (NMT) than statistical machine translation. Current methods, such as alignment-based insertion or the use of factors or special tokens, each have their strengths and drawbacks. We describe the current state of research on terminology enforcement in transformer-based NMT models, and present the results of our investigation into the performance of three different approaches. In addition to reference based quality metrics, we also evaluate the linguistic quality of the translations thus produced. Our results show that each approach is effective, though a negative impact on translation fluency remains evident.   
   
 pdf  bib  abs   
   Quality Analysis of Multilingual Neural Machine Translation Systems and Reference Test Translations for the E  nglish- R  omanian language pair in the Medical Domain    
  Miguel Angel Rios Gaona  | Raluca-Maria Chereji  | Alina Secara  | Dragos Ciobanu    
 Multilingual Neural Machine Translation (MNMT) models allow to translate across multiple languages based on only one system. We study the quality of a domain-adapted MNMT model in the medical domain for English-Romanian with automatic metrics and a human error typology annotation based on the Multidimensional Quality Metrics (MQM). We further expand the MQM typology to include terminology-specific error categories. We compare the out-of-domain MNMT with the in-domain adapted MNMT on a standard test dataset of abstracts from medical publications. The in-domain MNMT model outperforms the out-of-domain MNMT in all measured automatic metrics and produces fewer errors. In addition, we perform the manual annotation over the reference test dataset to study the quality of the reference translations. We identify a high number of omissions, additions, and mistranslations in the reference dataset, and comment on the assumed accuracy of existing datasets. Finally, we compare the correlation between the COMET, BERTScore, and chrF automatic metrics with the MQM annotated translations. COMET shows a better correlation with the MQM scores compared to the other metrics.   
   
 pdf  bib  abs   
   Computational analysis of different translations: by professionals, students and machines    
  Maja Popovic  | Ekaterina Lapshinova-Koltunski  | Maarit Koponen    
 In this work, we analyse different translated texts in terms of various text features. We compare two types of human translations, professional and students’, and machine translation outputs in terms of lexical and grammatical variety, sentence length,as well as frequencies of different POS tags and POS-trigrams. Our experimentsare carried out on parallel translations into three languages, Croatian, Finnish andRussian, all originating from the same source English texts. Our results indicatethat machine translations are closest to the source text, followed by student translations. Also, student translations are similar both to professional as well as to MT, sometimes even more to MT. Furthermore, we identify sets of features which are convenient for distinguishing machine from human translations.   
   
 pdf  bib  abs   
   Quality in Human and Machine Translation: An Interdisciplinary Survey    
  Bettina Hiebl  | Dagmar Gromann    
 Quality assurance is a central component of human and machine translation. In translation studies, translation quality focuses on human evaluation and dimensions, such as purpose, comprehensibility, target audience among many more. Within the field of machine translation, more operationalized definitions of quality lead to automated metrics relying on reference translations or quality estimation. A joint approach to defining and assessing translation quality holds the promise to be mutually beneficial. To contribute towards that objective, this systematic survey provides an interdisciplinary analysis of the concept of translation quality from both perspectives. Thereby, it seeks to inspire cross-fertilization between both fields and further development of an interdisciplinary concept of translation quality.   
   
 pdf  bib  abs   
   How can machine translation help generate A  rab melodic improvisation?    
  Fadi Al-Ghawanmeh  | Alexander Jensenius  | Kamel Smaili    
 This article presents a system to generate Arab music improvisation using machine translation. To reach this goal, we developed a machine translation model to translate a vocal improvisation into an automatic instrumental oud (Arab lute) response. Given the melodic and non-metric musical form, it was necessary to develop efficient textual representations for classical machine translation models to be as successful as NLP applications. We experimented with SMT and NMT to train our parallel corpus (Vocal to Instrumental) of 6991 sentences. The best model was then used to generate improvisation by iteratively translating thThis article presents a system to generate Arab music improvisation using machine translation (MT). To reach this goal, we developed a MT model to translate a vocal improvisation into an automatic instrumental oud (Arab lute) response. Given the melodic and non-metric musical form, it was necessary to develop efficient textual representations in order for classical MT models to be as successful as in common NLP applications. We experimented with Statistical and Neural MT to train our parallel corpus (Vocal to Instrument) of 6991 sentences. The best model was then used to generate improvisation by iteratively translating the translations of the most common patterns of each maqām (n-grams), producing elaborated variations conditioned to listener feedback. We constructed a dataset of 717 instrumental improvisations to extract their n-grams. Objective evaluation of MT was conducted at two levels: a sentence-level evaluation using the BLEU metric, and a higher level evaluation using musically informed metrics. Objective measures were consistent with one another. Subjective evaluations by experts from the maqām music tradition were promising, and a useful reference for understanding objective results.e translations of the most common patterns of each maqām (n-grams), producing elaborated variations conditioned to listener feedback. We constructed a dataset of 717 instrumental improvisations to extract their n-grams. Objective evaluation of machine translation was conducted at two levels: a sentence-level evaluation using the BLEU metric, and a higher level evaluation using musically informed metrics. Objective measures were consistent with one another. Subjective evaluations by experts from the maqām music tradition were promising, and a useful reference for understanding objective results.   
   
 pdf  bib  abs   
   Do online Machine Translation Systems Care for Context? What About a GPT  Model?    
  Sheila Castilho  | Clodagh Quinn Mallon  | Rahel Meister  | Shengya Yue    
 This paper addresses the challenges of evaluating document-level machine translation (MT) in the context of recent advances in context-aware neural machine translation (NMT). It investigates how well online MT systems deal with six context-related issues, namely lexical ambiguity, grammatical gender, grammatical number, reference, ellipsis, and terminology, when a larger context span containing the solution for those issues is given as input. Results are compared to the translation outputs from the online ChatGPT. Our results show that, while the change of punctuation in the input yields great variability in the output translations, the context position does not seem to have a great impact. Moreover, the GPT model seems to outperform the NMT systems but performs poorly for Irish. The study aims to provide insights into the effectiveness of online MT systems in handling context and highlight the importance of considering contextual factors in evaluating MT systems.   
   
 pdf  bib  abs   
   Incorporating Human Translator Style into E  nglish- T  urkish Literary Machine Translation    
  Zeynep Yirmibeşoğlu  | Olgun Dursun  | Harun Dalli  | Mehmet Şahin  | Ena Hodzik  | Sabri Gürses  | Tunga Güngör    
 Although machine translation systems are mostly designed to serve in the general domain, there is a growing tendency to adapt these systems to other domains like literary translation. In this paper, we focus on English-Turkish literary translation and develop machine translation models that take into account the stylistic features of translators. We fine-tune a pre-trained machine translation model by the manually-aligned works of a particular translator. We make a detailed analysis of the effects of manual and automatic alignments, data augmentation methods, and corpus size on the translations. We propose an approach based on stylistic features to evaluate the style of a translator in the output translations. We show that the human translator style can be highly recreated in the target machine translations by adapting the models to the style of the translator.   
   
 pdf  bib  abs   
   Machine translation of anonymized documents with human-in-the-loop    
  Konstantinos Chatzitheodorou  | M. Ángeles García Escrivá  | Carmen Grau Lacal    
 In this paper, we introduce a workflow that utilizes human-in-the-loop for post-editing anonymized texts, with the aim of reconciling the competing needs of data privacy and data quality. By combining the strengths of machine translation and human post-editing, our methodology facilitates the efficient and effective translation of anonymized texts, while ensuring the confidentiality of sensitive information. Our experimental results validate that this approach is capable of providing all necessary information to the translators for producing high-quality translations effectively. Overall, our workflow offers a promising solution for organizations seeking to achieve both data privacy and data quality in their translation processes.   
   
 pdf  bib  abs   
   Context-aware and gender-neutral Translation Memories    
  Marjolene Paulo  | Vera Cabarrão  | Helena Moniz  | Miguel Menezes  | Rachel Grewcock  | Eduardo Farah    
 This work proposes an approach to use Part-Of-Speech (POS) information to automatically detect context-dependent Translation Units (TUs) from a Translation Memory database pertaining to the customer support domain. In line with our goal to minimize context-dependency in TUs, we show how this mechanism can be deployed to create new gender-neutral and context-independent TUs. Our experiments, conducted across Portuguese (PT), Brazilian Portuguese (PT-BR), Spanish (ES), and Spanish-Latam (ES-LATAM), show that the occurrence of certain POS with specific words is accurate in identifying context dependency. In a cross-client analysis, we found that ~10% of the most frequent 13,200 TUs were context-dependent, with gender determining context-dependency in 98% of all confirmed cases. We used these findings to suggest gender-neutral equivalents for the most frequent TUs with gender constraints. Our approach is in use in the Unbabel translation pipeline, and can be integrated into any other Neural Machine Translation (NMT) pipeline.   
   
 pdf  bib  abs   
   Improving Machine Translation in the E  -commerce Luxury Space. A case study    
  José-Manuel De-la-Torre-Vilariño  | Juan-Luis García-Mendoza  | Alessia Petrucci    
 This case study presents a Multilingual e-commerce Project, which principal aim is to create an improved system that translates product titles and descriptions, plus other content in multiple languages. The project consisted of two main phases; a research-intensive solution using state-of-the-art Machine Translation systems and baseline language models for two language pairs, and the development of a Machine Translation system. The features implemented included Quality Estimation, model benchmarking, entity recognizers, and automatic domain detection. mBART model was used to create the system for the specific domain of e-commerce, for luxury items.   
   
 pdf  bib  abs   
   Quality Fit for Purpose: Building Business Critical Errors Test Suites    
  Mariana Cabeça  | Marianna Buchicchio  | Madalena Gonçalves  | Christine Maroti  | João Godinho  | Pedro Coelho  | Helena Moniz  | Alon Lavie    
 This paper illustrates a new methodology based on Test Suites (Avramidis et al., 2018) with focus on Business Critical Errors (BCEs) (Stewart et al., 2022) to evaluate the output of Machine Translation (MT) and Quality Estimation (QE) systems. We demonstrate the value of relying on semi-automatic evaluation done through scalable BCE-focused Test Suites to monitor both MT and QE systems’ performance for 8 language pairs (LPs) and a total of 4 error categories. This approach allows us to not only track the impact of new features and implementations in a real business environment, but also to identify strengths and weaknesses in models regarding different error types, and subsequently know what to improve henceforth.   
   
 pdf  bib  abs   
   Using MT  for multilingual covid-19 case load prediction from social media texts    
  Maja Popovic  | Vasudevan Nedumpozhimana  | Meegan Gower  | Sneha Rautmare  | Nishtha Jain  | John Kelleher    
 In the context of an epidemiological study involving multilingual social media, this paper reports on the ability of machine translation systems to preserve content relevant for a document classification task designed to determine whether the social media text is related to covid. The results indicate that machine translation does provide a feasible basis for scaling epidemiological social media surveillance to multiple languages. Moreover, a qualitative error analysis revealed that the majority of classification errors are not caused by MT errors.   
   
 pdf  bib  abs   
   Building Machine Translation Tools for Patent Language: A Data Generation Strategy at the E  uropean Patent Office    
  Matthias Wirth  | Volker D. Hähnke  | Franco Mascia  | Arnaud Wéry  | Konrad Vowinckel  | Marco del Rey  | Raúl Mohedano del Pozo  | Pau Montes  | Alexander Klenner-Bajaja    
 The European Patent Office (EPO) is an international organisation responsible for granting patents and promoting global cooperation in the intellectual property world. With three official languages (English, German, French) and a need to constantly access and manipulate information in multiple languages, machine translation is essential for the EPO. Over the last years we have developed internal machine translation engines, specifically for the translation of patent language. This article presents our data generation strategy: it describes our approach to the generation of parallel corpora of documents, training datasets of aligned sentences, and respective evaluation datasets. Details on the challenges and technical implementation are presented, as well as statistics of the training dataset generation process.   
   
 pdf  bib  abs   
   Terminology in Neural Machine Translation: A Case Study of the C  anadian H  ansard    
  Rebecca Knowles  | Samuel Larkin  | Marc Tessier  | Michel Simard    
 Incorporating terminology into a neural machine translation (NMT) system is a feature of interest for many users of machine translation. In this case study of English-French Canadian Parliamentary text, we examine the performance of standard NMT systems at handling terminology and consider the tradeoffs between potential performance improvements and the efforts required to maintain terminological resources specifically for NMT.   
   
 pdf  bib  abs   
   Developing User-centred Approaches to Technological Innovation in Literary Translation ( DUAL  - T  )    
  Paola Ruffo  | Joke Daems  | Lieve Macken    
 DUAL-T is an EU-funded project which aims at involving literary translators in the testing of technology-inclusive workflows. Participants will be asked to translate three short stories using, respectively, (1) a text editor combined with online resources, (2) a Computer-Aided Translation (CAT) tool, and (3) a Machine Translation Post-editing (MTPE) tool.   
   
 pdf  bib  abs   
   The Post-Edit Me! project    
  Marie-Aude Lefer  | Romane Bodart  | Adam Obrusnik  | Justine Piette    
 In this paper, we present the Post-Edit Me! project, which aims to support machine translation post-editing training and learning in translator education, with particular emphasis on quality evaluation of students’ productions. We describe the main components of the project, from the perspectives of both translation lecturers and translation students, and the project’s outcomes to date, namely the MTPEAS annotation system used to assess students’ post-edited texts and the postedit.me app we are currently developing to automate the evaluation workflow.   
   
 pdf  bib  abs   
   TAN  - IBE  : Neural Machine Translation for the romance languages of the I  berian Peninsula    
  Antoni Oliver  | Mercè Vàzquez  | Marta Coll-Florit  | Sergi Álvarez  | Víctor Suárez  | Claudi Aventín-Boya  | Cristina Valdés  | Mar Font  | Alejandro Pardos    
 The main goal of this project is to explore the techniques for training NMT systems applied to Spanish, Portuguese, Catalan, Galician, Asturian, Aragonese and Aranese. These languages belong to the same Romance family, but they are very different in terms of the linguistic resources available. Asturian, Aragonese and Aranese can be considered low resource languages. These characteristics make this setting an excellent place to explore training techniques for low-resource languages: transfer learning and multilingual systems, among others. The first months of the project have been dedicated to the compilation of monolingual and parallel corpora for Asturian, Aragonese and Aranese.   
   
 pdf  bib  abs   
   GAMETRAPP  : Training app for post-editing neural machine trans-lation using gamification in professional settings    
  Cristina Toledo Báez    
 The GAMETRAPP project, funded by Spanish Ministry for Science and Inno-vation, aims to facilitate industry profes-sionals training on full post-editing of neural machine translation by means of a gamified environment.   
   
 pdf  bib  abs   
   MATEO  : MA  chine Translation Evaluation Online    
  Bram Vanroy  | Arda Tezcan  | Lieve Macken    
 We present MAchine Translation Evaluation Online (MATEO), a project that aims to facilitate machine translation (MT) evaluation by means of an easy-to-use interface that can evaluate given machine translations with a battery of automatic metrics. It caters to both experienced and novice users who are working with MT, such as MT system builders, teachers and students of (machine) translation, and researchers.   
   
 pdf  bib  abs   
   S  ign ON  : Sign Language Translation. Progress and challenges.    
  Vincent Vandeghinste  | Dimitar Shterionov  | Mirella De Sisto  | Aoife Brady  | Mathieu De Coster  | Lorraine Leeson  | Josep Blat  | Frankie Picron  | Marcello Paolo Scipioni  | Aditya Parikh  | Louis ten Bosch  | John O’Flaherty  | Joni Dambre  | Jorn Rijckaert  | Bram Vanroy  | Victor Ubieto Nogales  | Santiago Egea Gomez  | Ineke Schuurman  | Gorka Labaka  | Adrián Núnez-Marcos  | Irene Murtagh  | Euan McGill  | Horacio Saggion    
 SignON ( https://signon-project.eu/  ) is a Horizon 2020 project, running from 2021 until the end of 2023, which addresses the lack of technology and services for the automatic translation between sign languages (SLs) and spoken languages, through an inclusive, human-centric solution, hence contributing to the repertoire of communication media for deaf, hard of hearing (DHH) and hearing individuals. In this paper, we present an update of the status of the project, describing the approaches developed to address the challenges and peculiarities of SL machine translation (SLMT).   
   
 pdf  bib  abs   
   G  o S  t- P  ar C  -Sign: Gold Standard Parallel Corpus of Sign and spoken language    
  Mirella De Sisto  | Vincent Vandeghinste  | Lien Soetemans  | Caro Brosens  | Dimitar Shterionov    
 Good quality training data for Sign Language Machine Translation (SLMT) is extremely scarce, and this is one of the challenges that any project focusing on Machine Translation (MT) which also targets sign languages is currently facing. The goal of this ongoing project is to create a parallel corpus of authentic Flemish Sign Language (VGT) and written Dutch which can be employed as gold standard in automated sign language translation. The availability of a gold standard corpus like Gost-ParC-Sign can facilitate the advances of SLMT; consequently, it supports and promotes inclusiveness in MT and, on a more general level, in language technology   
   
 pdf  bib  abs   
   M  a C  o C  u: Massive collection and curation of monolingual and bilingual data: focus on under-resourced languages    
  Marta Bañón  | Mălina Chichirău  | Miquel Esplà-Gomis  | Mikel Forcada  | Aarón Galiano-Jiménez  | Taja Kuzman  | Nikola Ljubešić  | Rik van Noord  | Leopoldo Pla Sempere  | Gema Ramírez-Sánchez  | Peter Rupnik  | Vit Suchomel  | Antonio Toral  | Jaume Zaragoza-Bernabeu    
 We present the most relevant results of the project MaCoCu: Massive collection and curation of monolingual and bilingual data: focus on under-resourced languages in its second year. To date, parallel and monolingual corpora have been produced for seven low-resourced European languages by crawling large amounts of textual data from selected top-level domains of the Internet; both human and automatic evaluation show its usefulness. In addition, several large language models pretrained on MaCoCu data have been published, as well as the code used to collect and curate the data.   
   
 pdf  bib  abs   
   First WMT  Shared Task on Sign Language Translation ( WMT  - SLT  22)    
  Mathias Müller  | Sarah Ebling  | Eleftherios Avramidis  | Alessia Battisti  | Michèle Berger  | Richard Bowden  | Annelies Braffort  | Necati Cihan Camgoz  | Cristina España-Bonet  | Roman Grundkiewicz  | Zifan Jiang  | Oscar Koller  | Amit Moryossef  | Regula Perrollaz  | Sabine Reinhard  | Annette Rios Gonzales  | Dimitar Shterionov  | Sandra Sidler-Miserez  | Katja Tissi  | Davy Van Landuyt    
 This paper is a brief summary of the First WMT Shared Task on Sign Language Translation (WMT-SLT22), a project partly funded by EAMT. The focus of this shared task is automatic translation between signed and spoken languages. Details can be found on our website ( https://www.wmt-slt.com/  ) or in the findings paper (Müller et al., 2022).   
   
 pdf  bib  abs   
   DECA  : Democratic epistemic capacities in the age of algorithms    
  Maarit Koponen  | Mary Nurminen  | Nina Havumetsä  | Juha Lång    
 The DECA project consortium investigates epistemic capacities, defined as an individual’s access to reliable knowledge, their ability to participate in knowledge production, and society’s capacity to make informed, sustainable policy decisions. In this paper, we focus specifically on the parts of the project examining the challenges posed by multilinguality in these processes and the potential role of MT in supporting access to, and production of, knowledge.   
   
 pdf  bib  abs   
   C  or C  o D  ial - Machine translation techniques for corpus-based computational dialectology    
  Yves Scherrer  | Olli Kuparinen  | Aleksandra Miletic    
 This paper presents CorCoDial, a research project funded by the Academy of Finland aiming to leverage machine translation technology for corpus-based computational dialectology. In this paper, we briefly present intermediate results of our project-related research.   
   
 pdf  bib  abs   
   How STAR  Transit NXT  can help translators measure and increase their MT  post-editing efficiency    
  Julian Hamm  | Judith Klein    
 As machine translation (MT) is being more tightly integrated into modern CAT-based translation workflows, measuring and increasing MT efficiency has become one of the main concerns of LSPs and companies trying to optimise their processes in terms of quality and performance. When it comes to measur-ing MT efficiency, STAR’s CAT tool Transit NXT offers post-editing distance (PED) and MT error categorisation as two core features of Transit’s compre-hensive QA module. With DeepL glossa-ry integration and MT confidence scores, translators will also have access to two new features which can help them in-crease their MT post-editing efficiency.   
   
 pdf  bib  abs   
   PROPICTO  : Developing Speech-to-Pictograph Translation Systems to Enhance Communication Accessibility    
  Lucía Ormaechea  | Pierrette Bouillon  | Maximin Coavoux  | Emmanuelle Esperança-Rodier  | Johanna Gerlach  | Jerôme Goulian  | Benjamin Lecouteux  | Cécile Macaire  | Jonathan Mutal  | Magali Norré  | Adrien Pupier  | Didier Schwab    
 PROPICTO is a project funded by the French National Research Agency and the Swiss National Science Foundation, that aims at creating Speech-to-Pictograph translation systems, with a special focus on French as an input language. By developing such technologies, we intend to enhance communication access for non-French speaking patients and people with cognitive impairments.   
   
 pdf  bib  abs   
   HPLT  : High Performance Language Technologies    
  Mikko Aulamo  | Nikolay Bogoychev  | Shaoxiong Ji  | Graeme Nail  | Gema Ramírez-Sánchez  | Jörg Tiedemann  | Jelmer van der Linde  | Jaume Zaragoza    
 We describe the High Performance Language Technologies project (HPLT), a 3-year EU-funded project started in September 2022. HPLT will build a space combining petabytes of natural language data with large-scale model training. It will derive monolingual and bilingual datasets from the Internet Archive and CommonCrawl and build efficient and solid machine translation (MT) as well as large language models (LLMs). HPLT aims at providing free, sustainable and reusable datasets, models and workflows at scale using high-performance computing (HPC).   

   up   pdf (full)   
  bib (full)   Proceedings of the Second International Workshop on Automatic Translation for Signed and Spoken Languages   
 pdf  bib   
   Proceedings of the Second International Workshop on Automatic Translation for Signed and Spoken Languages    
  Dimitar Shterionov  | Mirella De Sisto  | Mathias Muller  | Davy Van Landuyt  | Rehana Omardeen  | Shaun Oboyle  | Annelies Braffort  | Floris Roelofsen  | Fred Blain  | Bram Vanroy  | Eleftherios Avramidis    
 pdf  bib  abs   
   Analyzing the Potential of Linguistic Features for Sign Spotting: A Look at Approximative Features    
  Natalie Hollain  | Martha Larson  | Floris Roelofsen    
 Sign language processing is the field of research that aims to recognize, retrieve, and spot signs in videos. Various approaches have been developed, varying in whether they use linguistic features and whether they use landmark detection tools or not. Incorporating linguistics holds promise for improving sign language processing in terms of performance, generalizability, and explainability. This paper focuses on the task of sign spotting and aims to expand on the approximative linguistic features that have been used in previous work, and to understand when linguistic features deliver an improvement over landmark features. We detect landmarks with Mediapipe and extract linguistically relevant features from them, including handshape, orientation, location, and movement. We compare a sign spotting model using linguistic features with a model operating on landmarks directly, finding that the approximate linguistic features tested in this paper capture some aspects of signs better than the landmark features, while they are worse for others.   
   
 pdf  bib  abs   
   A Linked Data Approach for linking and aligning Sign Language and Spoken Language Data    
  Thierry Declerck  | Sam Bigeard  | Fahad Khan  | Irene Murtagh  | Sussi Olsen  | Mike Rosner  | Ineke Schuurman  | Andon Tchechmedjiev  | Andy Way    
 We present work dealing with a Linked Open Data (LOD)-compliant representation of Sign Language (SL) data, with the goal of supporting the cross-lingual alignment of SL data and their linking to Spoken Language (SpL) data. The proposed representation is based on activities of groups of researchers in the field of SL who have investigated the use of Open Multilingual Wordnet (OMW) datasets for (manually) cross-linking SL data or for linking SL and SpL data. Another group of researchers is proposing an XML encoding of articulatory elements of SLs and (manually) linking those to an SpL lexical resource. We propose an RDF-based representation of those various data. This unified formal representation offers a semantic repository of information on SL and SpL data that could be accessed for supporting the creation of datasets for training or evaluating NLP applications dealing with SLs, thinking for example of Machine Translation (MT) between SLs and between SLs and SpLs.   
   
 pdf  bib  abs   
   An Open-Source Gloss-Based Baseline for Spoken to Signed Language Translation    
  Amit Moryossef  | Mathias Müller  | Anne Göhring  | Zifan Jiang  | Yoav Goldberg  | Sarah Ebling    
 Sign language translation systems are complex and require many components. As a result, it is very hard to compare methods across publications. We present an open-source implementation of a text-to-gloss-to-pose-to-video pipeline approach, demonstrating conversion from German to Swiss German Sign Language, French to French Sign Language of Switzerland, and Italian to Italian Sign Language of Switzerland. We propose three different components for the text-to-gloss translation: a lemmatizer, a rule-based word reordering and dropping component, and a neural machine translation system. Gloss-to-pose conversion occurs using data from a lexicon for three different signed languages, with skeletal poses extracted from videos. To generate a sentence, the text-to-gloss system is first run, and the pose representations of the resulting signs are stitched together.   
   
 pdf  bib  abs   
   A New E  nglish- D  utch- NGT  Corpus for the Hospitality Domain    
  Mirella De Sisto  | Vincent Vandeghinste  | Dimitar Shterionov    
 One of the major challenges hampering the development of language technology which targets sign languages is the extremely limited availability of good quality data geared towards machine learning and deep learning approaches. In this paper we introduce the NGT-Dutch Hotel Review Corpus (NGT-HoReCo), which addresses this issue by providing multimodal parallel data in English, Dutch and Sign Language of the Netherlands (NGT). The corpus contains 283 hotel reviews in written English, translated into written Dutch and into NGT videos. It will be made publicly available through CLARIN and through the ELG platform.   
   
 pdf  bib  abs   
   BSL  - H  ansard: A parallel, multimodal corpus of E  nglish and interpreted B  ritish S  ign L  anguage data from parliamentary proceedings    
  Euan McGill  | Horacio Saggion    
 BSL-Hansard is a novel open source and multimodal resource composed by combining Sign Language video data in BSL and English text from the official transcription of British parliamentary sessions. This paper describes the method followed to compile BSL-Hansard including time alignment of text using the MAUS (Schiel, 2015) segmentation system, gives some statistics about this dataset, and suggests experiments. These primarily include end-to-end Sign Language-to-text translation, but is also relevant for broader machine translation, and speech and language processing tasks.   
   
 pdf  bib  abs   
   Towards Accommodating Gerunds within the Sign Language Lexicon    
  Zaid Mohammed  | Irene Murtagh    
 This work is part of ongoing research work that focuses on the linguistic analysis and computational description of five different Sign Languages (SLs), namely Irish Sign Language (ISL), Flemish Sign Language (VGT), Dutch Sign Language (NGT), Spanish Sign Language (LSE), and British Sign Language (BSL). This work will be leveraged to inform the development of SL lexicon entries for a Sign Language Machine Translation (SLMT) system. In particular, this research focuses on ISL. We investigate the existence of constructions similar to or equivalent in functionality to gerunds in spoken language, in particular, English. The initial findings indicate that such constructions do indeed exist and that they can take many forms.   

   up   pdf (full)   
  bib (full)   Proceedings of the 1st Workshop on Open Community-Driven Machine Translation   
 pdf  bib   
   Proceedings of the 1st Workshop on Open Community-Driven Machine Translation    
  Miquel Esplà-Gomis  | Mikel L. Forcada  | Taja Kuzman  | Nikola Ljubešić  | Rik van Noord  | Gema Ramírez-Sánchez  | Jörg Tiedemann  | Antonio Toral    
 pdf  bib  abs   
   Training and integration of neural machine translation with MTUOC     
  Antoni Oliver  | Sergi Alvarez    
 In this paper the goals and main objectives of the project MTUOC are presented. This project aims to ease the process of training and integrating neural machine translation (NMT) systems into professional translation environments. The MTUOC project distributes a series of auxiliary tools that allow to perform parallel corpus compilation and preprocessing, as well as the training of NMT systems. The project also distributes a server that implements most of the communication protocols used in computer assisted translation tools.   
   
 pdf  bib  abs   
   Design of an Open-Source Architecture for Neural Machine Translation    
  Séamus Lankford  | Haithem Afli  | Andy Way    
 adaptNMT is an open-source application that offers a streamlined approach to the development and deployment of Recurrent Neural Networks and Transformer models. This application is built upon the widely-adopted OpenNMT ecosystem, and is particularly useful for new entrants to the field, as it simplifies the setup of the development environment and creation of train, validation, and test splits. The application offers a graphing feature that illustrates the progress of model training, and employs SentencePiece for creating subword segmentation models. Furthermore, the application provides an intuitive user interface that facilitates hyperparameter customization. Notably, a single-click model development approach has been implemented, and models developed by adaptNMT can be evaluated using a range of metrics. To encourage eco-friendly research, adaptNMT incorporates a green report that flags the power consumption and kgCO2 emissions generated during model development. The application is freely available.   
   
 pdf  bib  abs   
   Creating a parallel F  innish- E  asy F  innish dataset from news articles    
  Anna Dmitrieva  | Aleksandra Konovalova    
 Modern natural language processing tasks such as text simplification or summarization are typically formulated as monolingual machine translation tasks. This requires appropriate datasets to train, tune, and evaluate the models. This paper describes the creation of a parallel Finnish-Easy Finnish dataset from the Yle News archives. The dataset contains 1919 manually verified pairs of articles, each containing an article in Easy Finnish (selkosuomi) and a corresponding article from Standard Finnish news. Standard Finnish texts total 687555 words, and Easy Finnish texts have 106733 words. This new aligned resource was created automatically based on the Yle News archives from the Language Bank of Finland (Kielipankki) and manually checked by a human expert. The dataset is available for download from Kielipankki. This resource will allow for more effective Easy Language research and for creating applications for automatic simplification and/or summarization of Finnish texts.   
   
 pdf  bib   
   A P  ython Tool for Selecting Domain-Specific Data in Machine Translation    
  Javad Pourmostafa Roshan Sharami  | Dimitar Shterionov  | Pieter Spronck    
 pdf  bib   
   MutNMT  , an open-source NMT  tool for educational purposes    
  Gema Ramírez Sánchez    
   
   up   pdf (full)   
  bib (full)   Proceedings of the First Workshop on Gender-Inclusive Translation Technologies   
 pdf  bib   
   Proceedings of the First Workshop on Gender-Inclusive Translation Technologies    
  Eva Vanmassenhove  | Beatrice Savoldi  | Luisa Bentivogli  | Joke Daems  | Janiça Hackenbuchner    
 pdf  bib  abs   
   The User-Aware A  rabic Gender Rewriter    
  Bashar Alhafni  | Ossama Obeid  | Nizar Habash    
 We introduce the User-Aware Arabic Gender Rewriter, a user-centric web-based system for Arabic gender rewriting in contexts involving two users. The system takes either Arabic or English sentences as input, and provides users with the ability to specify their desired first and/or second person target genders. The system outputs gender rewritten alternatives of the Arabic sentences (provided directly or as translation outputs) to match the target users’ gender preferences.   
   
 pdf  bib  abs   
   Gender-Fair Language in Translation: A Case Study    
  Angela Balducci Paolucci  | Manuel Lardelli  | Dagmar Gromann    
 With an increasing visibility of non-binary individuals, a growing number of language-specific strategies to linguistically include all genders or neutralize any gender references can be observed. Due to this multiplicity of proposed strategies and gender-specific grammatical differences across languages, selecting the one option to translate gender-fair language is challenging for machines and humans alike. As a first step towards gender-fair translation, we conducted a survey with translators to compare four gender-fair translations from a notional gender language, English, to a grammatical gender language, German. Proposed translations were rated by means of best-worst scaling as well as regarding their readability and comprehensibility. Participants expressed a clear preference for strategies with gender-inclusive character, i.e., colon.   
   
 pdf  bib  abs   
   Gender Lost In Translation: How Bridging The Gap Between Languages Affects Gender Bias in Zero-Shot Multilingual Translation    
  Lena Cabrera  | Jan Niehues    
 Neural machine translation (NMT) models often suffer from gender biases that harm users and society at large. In this work, we explore how bridging the gap between languages for which parallel data is not available affects gender bias in multilingual NMT, specifically for zero-shot directions. We evaluate translation between grammatical gender languages which requires preserving the inherent gender information from the source in the target language. We study the effect of encouraging language-agnostic hidden representations on models’ ability to preserve gender and compare pivot-based and zero-shot translation regarding the influence of the bridge language (participating in all language pairs during training) on gender preservation. We find that language-agnostic representations mitigate zero-shot models’ masculine bias, and with increased levels of gender inflection in the bridge language, pivoting surpasses zero-shot translation regarding fairer gender preservation for speaker-related gender agreement.   
   
 pdf  bib  abs   
   Gender-inclusive translation for a gender-inclusive sport: strategies and translator perceptions at the International Quadball Association    
  Joke Daems    
 Gender-inclusive language is of key importance to the IQA, the international governing body for quadball, a mixed-gender contact sport that explicitly welcomes players of all genders. While relatively straightforward for English, the picture becomes more complicated for most of the other IQA working languages. This paper provides an overview of the strategies currently chosen by translation team leaders for different IQA languages, the factors that influenced this decision and their connection with existing research on inclusive language strategies. It further explores the awareness and attitudes of IQA translators towards those strategies and factors.   
   
 pdf  bib  abs   
   Participatory Research as a Path to Community-Informed, Gender-Fair Machine Translation    
  Dagmar Gromann  | Manuel Lardelli  | Katta Spiel  | Sabrina Burtscher  | Lukas Daniel Klausner  | Arthur Mettinger  | Igor Miladinovic  | Sigrid Schefer-Wenzl  | Daniela Duh  | Katharina Bühn    
 Recent years have seen a strongly increased visibility of non-binary people in public discourse. Accordingly, considerations of gender-fair language go beyond a binary conception of male/female. However, language technology, especially machine translation (MT), still suffers from binary gender bias. Proposing a solution for gender-fair MT beyond the binary from a purely technological perspective might fall short to accommodate different target user groups and in the worst case might lead to misgendering. To address this challenge, we propose a method and case study building on participatory action research to include experiential experts, i.e., queer and non-binary people, translators, and MT experts, in the MT design process. The case study focuses on German, where central findings are the importance of context dependency to avoid identity invalidation and a desire for customizable MT solutions.   
   
 pdf  bib  abs   
   Reducing Gender Bias in NMT  with FUDGE     
  Tianshuai Lu  | Noëmi Aepli  | Annette Rios    
 Gender bias appears in many neural machine translation (NMT) models and commercial translation software. Research has become more aware of this problem in recent years and there has been work on mitigating gender bias. However, the challenge of addressing gender bias in NMT persists. This work utilizes a controlled text generation method, Future Discriminators for Generation (FUDGE), to reduce the so-called Speaking As gender bias. This bias emerges when translating from English to a language that openly marks the gender of the speaker. We evaluate the model on MuST-SHE, a challenge set to specifically evaluate gender translation. The results demonstrate improvements in the translation accuracy of the feminine terms.   
   
 pdf  bib  abs   
   Gender Neutralization for an Inclusive Machine Translation: from Theoretical Foundations to Open Challenges    
  Andrea Piergentili  | Dennis Fucci  | Beatrice Savoldi  | Luisa Bentivogli  | Matteo Negri    
 Gender inclusivity in language technologies has become a prominent research topic. In this study, we explore gender-neutral translation (GNT) as a form of gender inclusivity and a goal to be achieved by machine translation (MT) models, which have been found to perpetuate gender bias and discrimination. Specifically, we focus on translation from English into Italian, a language pair representative of salient gender-related linguistic transfer problems. To define GNT, we review a selection of relevant institutional guidelines for gender-inclusive language, discuss its scenarios of use, and examine the technical challenges of performing GNT in MT, concluding with a discussion of potential solutions to encourage advancements toward greater inclusivity in MT.   
   
 pdf  bib  abs   
   Gender, names and other mysteries: Towards the ambiguous for gender-inclusive translation    
  Danielle Saunders  | Katrina Olsen    
 The vast majority of work on gender in MT focuses on ‘unambiguous’ inputs, where gender markers in the source language are expected to be resolved in the output. Conversely, this paper explores the widespread case where the source sentence lacks explicit gender markers, but the target sentence contains them due to richer grammatical gender. We particularly focus on inputs containing person names. Investigating such sentence pairs casts a new light on research into MT gender bias and its mitigation. We find that many name-gender co-occurrences in MT data are not resolvable with ‘unambiguous gender’ in the source language, and that gender-ambiguous examples can make up a large proportion of training examples. From this, we discuss potential steps toward gender-inclusive translation which accepts the ambiguity in both gender and translation.   
   
 pdf  bib  abs   
   How adaptive is adaptive machine translation, really? A gender-neutral language use case    
  Aida Kostikova  | Joke Daems  | Todor Lazarov    
 This study examines the effectiveness of adaptive machine translation (AMT) for gender-neutral language (GNL) use in English-German translation using the ModernMT engine. It investigates gender bias in initial output and adaptability to two distinct GNL strategies, as well as the influence of translation memory (TM) use on adaptivity. Findings indicate that despite inherent gender bias, machine translation (MT) systems show potential for adapting to GNL with appropriate exposure and training, highlighting the importance of customisation, exposure to diverse examples, and better representation of different forms for enhancing gender-fair translation strategies.   

   up   pdf (full)   
  bib (full)   Proceedings of the 1st International Workshop on Multilingual, Multimodal and Multitask Language Generation   
 pdf  bib   
   Proceedings of the 1st International Workshop on Multilingual, Multimodal and Multitask Language Generation    
  Anabela Barreiro  | Max Silberztein  | Elena Lloret  | Marcin Paprzycki    
 pdf  bib   
   Controllability for E  nglish- U  krainian Machine Translation Based on Specialized Corpora    
  Daniil Maksymenko  | Olena Turuta  | Nataliia Saichyshyna  | Maksym Yerokhin  | Oleksii Turuta    
 pdf  bib   
   R  oo A  d: A Computationally Creative Online Advertisement Generator    
  Mika Hämäläinen  | Khalid Alnajjar    
 pdf  bib   
   Variable-length Neural Interlingua Representations for Zero-shot Neural Machine Translation    
  Zhuoyuan Mao  | Haiyue Song  | Raj Dabre  | Chenhui Chu  | Sadao Kurohashi    
 pdf  bib   
   Towards an Efficient Approach for Controllable Text Generation    
  Iván Martínez-Murillo  | Paloma Moreda  | Elena Lloret    
 pdf  bib   
   Natural Language Generation in the Logos Model    
  Sara Amato  | Kutz Arrieta    
 pdf  bib   
   Improving P  olish to E  nglish Neural Machine Translation with Transfer Learning: Effects of Data Volume and Language Similarity    
  Juuso Eronen  | Michal Ptaszynski  | Karol Nowakowski  | Zheng Lin Chia    
 pdf  bib   
   A Multilingual Paraphrasary of Multiwords    
  Anabela Barreiro  | Cristina Mota    

    ACL materials are Copyright © 1963–2024 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License  . Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a Creative Commons Attribution 4.0 International License  .  
 The ACL Anthology is managed and built by the ACL Anthology team  of volunteers.  
 Site last built on 29 November 2024 at 02:48 UTC with commit ff763a8  .

77. EUSFLAT_3 conference:
Please enable cookies.   
 Sorry, you have been blocked  
 You are unable to access  10times.com  

 Why have I been blocked?  
 This website is using a security service to protect itself from online attacks. The action you just performed triggered the security solution. There are several actions that could trigger this block including submitting a certain word or phrase, a SQL command or malformed data.  
   
 What can I do to resolve this?  
 You can email the site owner to let them know you were blocked. Please include what you were doing when this page came up and the Cloudflare Ray ID found at the bottom of this page.  

 Cloudflare Ray ID: 8ea88803ed485fdf   •  Your IP: Click to reveal  14.237.32.203  •   Performance & security by  Cloudflare

78. CALCO_2 conference:


79. XP_2 conference:
JavaScript is not available.  
 We’ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.  
 Help Center   
 Terms of Service  Privacy Policy  Cookie Policy  Imprint  Ads info  © 2024 X Corp.  

 Something went wrong, but don’t fret — let’s give it another shot.    
  
   Try again    
   Some privacy related extensions may cause issues on x.com. Please disable them and try again.

80. EAMT_3 conference:
Skip to content      
   About the EAMT | What is the EAMT 
  What is Machine Translation? 
  Sponsored projects 
  EAMT executive committee 
  Related associations 
  Ethics 
  IAMT | International Association for Machine Translation 
  Bylaws of the International Association for Machine Translation Inc. (IAMT) 
  IAMT Award of Honour 
  Membership | Become a member 
  Institutional members 
  Corporate members 
  Conferences | The EAMT Annual Conference | EAMT Annual Conference Peer Review Policy 
  The MT Summit Biannual Conference | MT Summit Peer Review Policy 
  Best thesis award 
  MT resources | MT Archive 
  MT-List 
  Software compendium 

  Site Search   Search for:    Search      

   EAMT best thesis award    
 The Anthony C. Clarke Award for the 2024 EAMT Best Thesis   
 November 28, 2024 (updated on November 28, 2024) 
    
 The European Association for Machine Translation (EAMT,  http://www.eamt.org  ) is an organization that serves the growing community of people interested in MT and translation tools, including translators, users, developers, and researchers of this increasingly viable technology.  
 The EAMT invites entries for its thirteenth EAMT Best Thesis Award for a PhD or equivalent thesis on a topic related to machine translation.  
 Previous year winners can be found at https://eamt.org/best-thesis-award/  .  
 Eligibility  
 Researchers who  
 have completed a PhD (or equivalent) thesis on a relevant topic in a European, African or Middle Eastern | [1] | institution within calendar | year 2024 | , 
  have not previously won another international award for that thesis, and, 
  are members of the EAMT at the time of submission, 
  are invited to submit their theses to the EAMT for consideration.  
 [1]  Bahrain, Iran, Iraq, Israel, Jordan, Kuwait, Oman, Palestine, Qatar, Saudi Arabia, Syria, United Arab Emirates, Yemen.  
 Panel  
 The submissions will be judged by a panel of experts who will be specifically appointed, and which will be ratified by the Executive Board of the EAMT.  
  Selection criteria  
 Each thesis will be judged according to how challenging the problem was, to how relevant the results are for machine translation as a field, and to the strength of their impact in terms of scientific publications.  
 Scope  
 The scope of the thesis does not need to be confined to a technical area, and applications are also invited from students who carried out their research into commercial and management aspects of machine translation.  
 Possible areas of research include:  
 development of machine translation or advanced computer-assisted translation: methods, software or resources 
  machine translation for less-resourced languages 
  the use of these systems in professional environments (freelance translators, translation agencies, and professionals outside of the language industry) 
  the increasing impact of machine translation on non-professional Internet users and its impact in communications, social networking, etc. 
  spoken language translation 
  the integration of machine translation software in larger IT applications 
  the evaluation of machine translation systems in real tasks such as those above 
  the cross-fertilisation between machine translation and other language technologies 
  multilingual language technologies, including with large language models 
  Prize  
 The winner will be announced in March 2025 and will receive a prize of €500, together with an inscribed certificate. The recipient of the award will be required to briefly present their research at MT Summit 2025 to be held from 23th to 27th June 2025 in Geneva, Switzerland ( https://mtsummit2025.unige.ch  ). In order to facilitate this, the EAMT will waive the winner’s registration costs, and will make available a travel bursary of €200 to enable the recipient of the award to attend the said conference. The prize includes complimentary membership in the EAMT for 2026.  
 Submission  
 Candidates will submit, using EasyChair  
 ( https://easychair.org/conferences/?conf=eamt2025bta  ), a single PDF file containing:  
 a 2-page summary of your thesis in English, containing: | your full contact details, | the name and contact details of your supervisor(s), | the main aspects of your work, namely goal/objectives, methodology and results. 
  a copy of your CV in English (at most one page, plus a complete list of publications directly related to the thesis) 
  an electronic copy of your thesis 
  optionally, an appendix with any other relevant information on the thesis 
  By submitting their work, authors  
 agree that, in case they are granted the award, any subsequently published version of the thesis should carry the citation “The Anthony C. Clarke Award for the 2024 EAMT Best Thesis” and 
  acknowledge the right of the EAMT to publicize the granting of the award. 
  For this year’s Best Thesis Award we are requiring candidates to be an individual EAMT member at the time of submission. For EAMT memberships, please visit: https://eamt.org/101-2/  .  
 Closing date  
 Submission deadline: | January 31, 2025, 23:59 CET. 
  Award notification: | March 2025. 

   EAMT conference    
 EAMT 2026: CALL FOR BIDS   
 August 9, 2024 (updated on September 22, 2024) 
    
 The European Association for Machine Translation (EAMT) invites expressions of interest to host the EAMT 2026 conference, to be held in Europe, the Middle East or Africa (EMEA) between May-June 2026. This will be the 26th EAMT conference.  
 At this stage, we are seeking draft proposals from prospective bidders. These will be evaluated and promising bidders will be asked to provide additional information for the final selection. The EAMT president will act as general chair and will work together with local organisers to design and shape the conference, including the appointment of chairs.  
 Draft proposals (due September 13th, 2024) should include information on all of the following items:  
 1. Proposed dates: between May – June 2026 (3 days main conference + 1 day for workshops and tutorials)  
 2. Location: city and conference venue. Indicate whether the conference would be held at a university, hotel or convention centre. Bear in mind that EAMT is growing: Ghent (EAMT 2022) had around 120 registered participants, Tampere (EAMT 2023) and Sheffield (EAMT 2024) had around 190 registered participants. So please suggest a location that could host 200+ people for the main conference sessions, plus room for registration, a large poster or exhibit room, and at least 4 conference rooms for hosting parallel workshops and tutorials on the last day (about 100 people each).  
 3. Local arrangements team: local chair/co-chairs, committee (identifying a coordinator to be co-opted as EAMT executive committee member), volunteer labour (e.g. students), registration handling. The local arrangements team will be responsible for activities such as arranging meeting rooms, equipment, refreshments, accommodation, on-site registration, participant internet access, the welcome reception, the conference dinner, and working with the other chairs and the EAMT Board to develop the budget and registration materials. Indicate whether any national/regional computational linguistics or translation studies association would be on the board of the local organisation  
 4. Computing/wifi/audiovisual: whether there will be desktops/laptops in conference rooms and high-speed wireless Internet access, what the audiovisual facilities are, etc. There should be sufficient sound and microphones that can go around the room for Q&A.  
 5. Food catering including breaks (two coffee breaks and one lunch break for all days of the conference), reception and conference dinner  
 6. Social events, including infrastructure for banquet/other social events and welcome reception  
 7. Potential for sponsorships: local organisers partner with the EAMT EC to engage sponsors and align track chairs and keynotes. Bids should include strategies for outreach, anticipated sponsor tiers, and potential benefits for sponsors.  
 8. Co-location with other meetings and events: demonstrate that you have researched the dates to avoid clashes with other events and considered opportunities for co-location with other meetings  
 9. Cost estimates: while a finalised budget is not expected at this stage, it is essential that proposers provide well-researched estimates with some level of detail related to all of the above items. These estimates should be documented in the expenses spreadsheet (template provided by the EAMT upon request).  
 Proposals will be evaluated with respect to a number of criteria (unordered):  
 ● Adequacy of conference and exhibit facilities for the anticipated number of registrants  
 ● Adequacy of accommodations and food services (in a range of price categories) and proximity to the conference facilities  
 ● Adequacy of expense projections and expected surplus  
 ● Appropriateness of proposed dates  
 ● Geographical and national balance with regard to previous EACL and ACL conferences, and other major natural-language processing and translation studies conferences held in EMEA  
 ● Co-location with national/regional conferences  
 ● Experience of the local arrangements team  
 ● Local machine translation and translation studies community support  
 ● Local government and industry support  
 ● Appropriateness of expected registration fees  
 ● Accessibility of proposed site via public transportation  
 ● Alignment with the EAMT ethics statement and policies: https://eamt.org/ethics/  
 Please send your expressions of interest electronically to the EAMT president:  
 Helena Moniz <<helena.moniz “at” campus.ul.pt>>  
 The EAMT board encourages groups who intend to submit a proposal to ask questions about how to prepare the proposal.  
 Important Dates:  
 September 13th, 2024 | > October 14th, 2024: Bids submission deadline 
  September 20th, 2024 | > October 21st, 2024: Shortlist and feedback to bidders 
  September 27th, 2024 | > October 28th, 2024: Final bids due 
  October 4th, 2024 | > November 4th, 2024: Final bid chosen 

   EAMT best thesis award    
 2023 Anthony C Clarke Award for the EAMT Best Thesis: awardee announcement   
 April 17, 2024 (updated on July 24, 2024) 
    
 Nine PhD theses defended in 2023 were received as candidates for the 2022 edition of the EAMT Best Thesis Award, and all nine were eligible. 20 reviewers were recruited to examine and score the theses, considering how challenging the problem tackled in each thesis was, how relevant the results were for machine translation as a field, and what the strength of its impact in terms of scientific publications was. Two EAMT Executive Committee members also analysed all theses. It became very clear that 2023 was another very good year for PhD theses in machine translation.  
 All theses had merit, all candidates had strong CVs and, therefore, it was very difficult to select a winner.  
 A panel of two EAMT Executive Committee members (Barry Haddow and Helena Moniz) was assembled to process the reviews and select a winner that was later ratified by the EAMT executive committee.  
 We are pleased to announce that the winner of the 2023 edition of the EAMT Best Thesis Award is Marco Gaido’s’ thesis “Direct Speech Translation Toward High-Quality, Inclusive, and Augmented Systems”  (FBK, Italy), supervised by Dr Marco Turchi and Dr. Matteo Negri.  
 In addition, the committee judged that the following theses, were “highly commended”:  
 Jannis Vamvas: “Model-based Evaluation of Multilinguality” (University of Zurich, Switzerland), supervised by Rico Sennrich and Lena A. Jäger 
  Javier Iranzo-Sánchez: “Streaming Neural Speech Translation” ( UPV, Spain), supervised by Jorge Civera and Alfons Juan 
  The awardee will receive a prize of €500, together with a suitably-inscribed certificate. In addition, Dr. Gaido will present a summary of their thesis at the 25th Annual Conference of the European Association for Machine Translation (EAMT 2024: https://eamt2024.sheffield.ac.uk/) which will take place from June 24th to 27th in Sheffield, UK. In order to facilitate this, the EAMT will waive the winner’s registration costs, and will make available a travel bursary of €200.  
 Barry Haddow, chair, EAMT BTA award 2023  
 Helena Moniz, EAMT president  
 Program committee   
 Daniel Beck, Royal Melbourne Institute of Technology  
 Bram Vanroy, KU Leuven  
 Philipp Koehn, Johns Hopkins University  
 Danielle Saunders, DeepL  
 Alexandra Birch, University of Edinburgh  
 Felix Stahlberg, Google  
 Bill Byrne, Amazon  
 Sheila Castilho, Dublin City University  
 John E. Ortega, Northeastern University  
 Anna Currey, Amazon  
 Rachel Bawden, Inria  
 Xingyi Song, University of Sheffield  
 Miquel Esplà-Gomis, Universidad de Alicante  
 Marcello Federico, Amazon  
 Antonio Toral, University of Groningen  
 Diptesh Kanojia, University of Surrey  
 José G. C. de Souza, Unbabel  
 Mikel L. Forcada, Universidad de Alicante  
 Liane Guillou, University of Edinburgh  
 Vera Cabarrão, Unbabel  

   EAMT conference    
 EAMT 2024: Bursaries for Translators   
 March 28, 2024 (updated on March 28, 2024) 
    
 Call for Participation   
 The European Association for Machine Translation (EAMT) is an organisation that serves the growing community of people interested in MT and translation tools, including translators, users, developers, and researchers of this increasingly viable technology.  
 As part of its commitment to promote research, development and awareness about translation technologies, the EAMT opens a call for a small number of bursaries to support translators and Translation Studies’ students, in attending the 25th Annual Conference of the European Association for Machine Translation (EAMT 2024) conference will be held in Sheffield, United Kingdom, from June 24th to June 27th.  
 Purpose of the Call   
 This call is dedicated to support translators and Translation Studies’ students, working or studying in European, Middle-Eastern or African countries, that do not have fundings to attend the conference.  
 The EAMT particularly encourages applications from early-career translators  .  
 All applications will be screened by EAMT executive committee members.  
 Application information   
 Eligibility requirements   
 In order to qualify for this call, the individual must be a translator or enrolled in a Master or PhD course in Translation Studies. The support is only available to individuals working or studying in European, Middle-Eastern or African countries. Freelance translators  and students  will have priority. We will also give priority to people with accepted papers in the main conference.  
 Selection criteria   
 The selection will be made based on the information submitted to the provided Google Forms (link below). 
  One of the fields in the form is a “motivation letter”, where you should describe your motivation for attending the EAMT 2024 conference and explain why you do not have other funds to sponsor your attendance. 
  You should also submit a CV, highlighting your years of experience in the translation area and your experience working with MT. 
  For students: you should also submit an official proof of student status, signed by your University. 
  Bursaries   
 EAMT anticipates funding several applications. Selected participants will be announced on the 26th April 2024 and will receive complimentary membership in the EAMT for 2024 and 2025, free registration at the EAMT 2024 conference and paid accommodation in Sheffield.  
 Contact for enquiries   
 Sara Szoc  
 EAMT member  
 e-mail: saraszoc@gmail.com  
 Applications   
 Candidates should submit their applications via a Google Form: https://forms.gle/7JUDDhC7TDNXUEaq8   
 Important Dates   
 Circulation of the Call: March 28th, 2024 
  Submission deadline for applications: | April 19th, 2024, 23:59 CEST 
  Notification: April 26th, 2024 
  Additional provisions   
 Only complete applications will be reviewed. 
  All information submitted with applications will be regarded as confidential and will only be used in the context of this call. 
  You may be asked to share the accommodation room with other awardees. However, we will commit to respect any requirements / concerns that you inform us (e.g. religion, gender, etc). 

   EAMT conference    
 EAMT 2024: Support for participants from low-income countries and war zones   
 March 28, 2024 (updated on March 28, 2024) 
    
 Call for Participation   
 The European Association for Machine Translation (EAMT) is an organisation that serves the growing community of people interested in MT and translation tools, including translators, users, developers, and researchers of this increasingly viable technology.  
 As part of its commitment to promote research, development and awareness about translation technologies, the EAMT opens a call for a small number of bursaries to support EAMT 2024 attendees from areas affected by war and low-income countries. The 25th Annual Conference of the European Association for Machine Translation (EAMT 2024) conference will be held in Sheffield, United Kingdom, from June 24th to June 27th.  
 Purpose of the Call   
 This call is dedicated to support EAMT 2024 attendees that do not have fundings to attend the conference, from areas affected by war or low-income countries in Europe, Middle East or Africa.  
 The EAMT particularly encourages applications from early career researchers  .  
 All applications will be screened by EAMT executive committee members.  
 Application information   
 Eligibility requirements   
 In order to qualify for this call, the individual must be a student or an employee of an institution located in areas affected by war or in low-income countries in Europe, Middle East or Africa, that would not be able to attend the conference without this support. Students  and early-career researchers/academics  will have priority. We will also give priority to people with accepted papers in the main conference.  
 Selection criteria   
 The selection will be made based on the information submitted to the provided Google Forms (link below). 
  One of the fields in the form is a “motivation letter”, where you should describe your motivation for attending the EAMT 2024 conference and explain why you do not have other funds to sponsor your attendance. 
  You should also submit a CV, highlighting your years of experience in the MT area. 
  Bursaries   
 EAMT anticipates funding several applications. Selected participants will be announced on the 26th April 2024 and will receive complimentary membership in the EAMT for 2024 and 2025, free registration at the EAMT 2024 conference and paid accommodation in Sheffield.  
 Contact for enquiries   
 Sara Szoc  
 EAMT member  
 e-mail: saraszoc@gmail.com  
 Applications   
 Candidates should submit their applications via a Google Form: https://forms.gle/jS314WGUszZ2fMUT9   
 Important Dates   
 Circulation of the Call: March 28th, 2024 
  Submission deadline for applications: | April 19th, 2024, 23:59 CEST 
  Notification: April 26th, 2024 
  Additional provisions   
 Only complete applications will be reviewed. 
  All information submitted with applications will be regarded as confidential and will only be used in the context of this call. 
  You may be asked to share the accommodation room with other awardees. However, we will commit to respect any requirements / concerns that you inform us (e.g. religion, gender, etc). 
  No obligation to award the bursaries   
 The EAMT shall be under no obligation to fund the applications pursuant to this call for participation. EAMT shall not be liable for any compensation with respect to candidates whose applications have not been approved. Nor shall it be liable in the event of it deciding not to award the bursaries.  

   EAMT best thesis award    
 The Anthony C. Clarke Award for the 2023 EAMT Best Thesis   
 December 3, 2023 (updated on July 24, 2024) 
    
 The European Association for Machine Translation (EAMT, http://www.eamt.org  ) is an organization that serves the growing community of people interested in MT and translation tools, including translators, users, developers, and researchers of this increasingly viable technology.  
 The EAMT invites entries for its twelfth EAMT Best Thesis Award for a PhD or equivalent thesis on a topic related to machine translation.  
 Previous year winners can be found at https://eamt.org/best-thesis-award/  .  
 Eligibility   
 Researchers who  
 have completed a PhD (or equivalent) thesis on a relevant topic in a European, African or Middle Eastern institution within calendar | year 2023 | , 
  have not previously won another international award for that thesis, and, 
  are members of the EAMT at the time of submission, 
  are invited to submit their theses to the EAMT for consideration.  
 Panel   
 The submissions will be judged by a panel of experts who will be specifically appointed, based on the EAMT 2024 program committee, and which will be ratified by the Executive Board of the EAMT.  
 Selection criteria   
 Each thesis will be judged according to how challenging the problem was, to how relevant the results are for machine translation as a field, and to the strength of their impact in terms of scientific publications.  
 Scope   
 The scope of the thesis does not need to be confined to a technical area, and applications are also invited from students who carried out their research into commercial and management aspects of machine translation.  
 Possible areas of research include:  
 development of machine translation or advanced computer-assisted translation: methods, software or resources 
  machine translation for less-resourced languages 
  the use of these systems in professional environments (freelance translators, translation agencies, localisation, etc.) 
  the increasing impact of machine translation on non-professional Internet users and its impact in communications, social networking, etc. 
  spoken language translation 
  the integration of machine translation and translation memory systems 
  the integration of machine translation software in larger IT applications 
  the evaluation of machine translation systems in real tasks such as those above 
  the cross-fertilisation between machine translation and other language technologies 
  Prize   
 The winner will be announced on the 8th of March 2024 and will receive a prize of €500, together with an inscribed certificate. The recipient of the award will be required to briefly present their research at EAMT 2024 to be held from 24th June to 27th June 2024 in Sheffield, UK. In order to facilitate this, the EAMT will waive the winner’s registration costs, and will make available a travel bursary of €200 to enable the recipient of the award to attend the said conference. The prize includes complimentary membership in the EAMT for 2025.  
 Submission   
 Candidates will submit, using OpenReview ( https://openreview.net/group?id=EAMT.org/2024/Thesis_Award  ) a single PDF file containing:  
 a 2-page summary of your thesis in English, containing: | your full contact details, 
  the name and contact details of your supervisor(s), 
  the main aspects of your work, namely goal/objectives, methodology and results; 
  a copy of your CV in English (at most one page, plus a complete list of publications directly related to the thesis) 
  an electronic copy of your thesis 
  optionally, an appendix with any other relevant information on the thesis 
  By submitting their work, authors  
 agree that, in case they are granted the award, any subsequently published version of the thesis should carry the citation “The Anthony C. Clarke Award for the 2023 EAMT Best Thesis” and 
  acknowledge the right of the EAMT to publicize the granting of the award. 
  For this year’s Best Thesis Award we are requiring candidates to be an individual EAMT member at the time of submission. For EAMT memberships, please visit: https://eamt.org/101-2/  .  
 Closing date   
 Submission deadline: | February 8, 2024, 23:59 CEST. 
  Award notification: | March 8, 2024. 

   EAMT best thesis award    
 2022 Anthony C Clarke Award for the EAMT Best Thesis: awardee announcement   
 April 20, 2023 (updated on April 17, 2024) 
    
 Nine PhD theses defended in 2022 were received as candidates for the 2022 edition of the EAMT Best Thesis Award, and all nine were eligible. 28 reviewers and six EAMT Executive Committee members were recruited to examine and score the theses, considering how challenging the problem tackled in each thesis was, how relevant the results were for machine translation as a field, and what the strength of its impact in terms of scientific publications was. Two EAMT Executive Committee members also analysed all theses. It became very clear that 2022 was another very good year for PhD theses in machine translation.  
 All theses had merit, all candidates had strong CVs and, therefore, it was very difficult to select a winner.  
 A panel of two EAMT Executive Committee members (Carolina Scarton and Helena Moniz) was assembled to process the reviews and select a winner that was later ratified by the EAMT executive committee.  
 We are pleased to announce that the awardee of the 2022 edition of the EAMT Best Thesis is Biao Zhang’s thesis “Towards Efficient Universal Neural Machine Translation”  (University of Edinburgh, UK), supervised by Dr Rico Sennrich and Dr Ivan Titov.  
 The awardee will receive a prize of €500, together with a suitably-inscribed certificate. In addition, Dr. Zhang will present a summary of their thesis at the 24th Annual Conference of the European Association for Machine Translation (EAMT 2023: https://events.tuni.fi/eamt23/  ) which will take place from June 12th to 15th in Tampere, Finland. In order to facilitate this, the EAMT will waive the winner’s registration costs, and will make available a travel bursary of €200.  
 Helena Moniz, EAMT President  
 Carolina Scarton, EAMT Secretary  
 Program committee   
 Rachel Bawden, Inria  
 Daniel Beck, The University of Melbourne  
 William Byrne, University of Cambridge  
 José G. C. de Souza, Unbabel  
 Vera Cabarrão, Unbabel / INESC-ID  
 Sheila Castilho, Dublin City University  
 Anna Currey, Amazon Web Services  
 Mattia Antonino Di Gangi, AppTek  
 Maha Elbayad, LIG/ Inria  
 Miquel Esplà-Gomis, Universitat d’Alacant  
 Marcello Federico, Amazon AI  
 Mikel Forcada, DLSI – Universitat d’Alacant  
 Barry Haddow, The University of Edinburgh  
 Diptesh Kanojia, IIT Bombay  
 Philipp Koehn, Johns Hopkins University  
 Helena Moniz, INESC/FLUL  
 Mary Nurminen, Tampere University  
 Constantin Orasan, University of Surrey  
 John E. Ortega, Northeastern University  
 Santanu Pal, Wipro Limited  
 Pavel Pecina, Charles University  
 Maja Popovic, ADAPT Centre @ DCU  
 Celia Rico, Universidad Complutense de Madrid  
 Víctor M. Sánchez-Cartagena, Universitat d’Alacant  
 Marina Sánchez-Torrón, Unbabel  
 Danielle Saunders, University of Cambridge  
 Dimitar Shterionov, Tilburg University  
 Felix Stahlberg, Google Research  
 Arda Tezcan, Ghent University  
 Antonio Toral, University of Groningen  
 Ualsher Tukeyev, al-Farabi Kazakh National University  
 Bram Vanroy, KU Leuven; Ghent University  
 Longyue Wang, Tencent AI Lab  

   EAMT conference    
 EAMT 2023: Bursaries for Translators – Call for Participation   
 April 3, 2023 (updated on July 24, 2024) 
    
 Call for Participation   
 The European Association for Machine Translation (EAMT) is an organisation that serves the growing community of people interested in MT and translation tools, including translators, users, developers, and researchers of this increasingly viable technology.  
 As part of its commitment to promote research, development and awareness about translation technologies, the EAMT opens a call for a small number of bursaries to support translators and Translation Studies’ students, in attending the 24th Annual Conference of the European Association for Machine Translation (EAMT 2023) conference will be held in Tampere, Finland, from June 12th to June 15th.  
 Purpose of the Call   
 This call is dedicated to support translators and Translation Studies’ students, working or studying in European, Middle-Eastern or African countries, that do not have fundings to attend the conference.  
 The EAMT particularly encourages applications from early-career translators  .  
 All applications will be screened by EAMT executive committee members.  
 Application information   
 Eligibility requirements   
 In order to qualify for this call, the individual must be a translator or enrolled in a Master or PhD course in Translation Studies. The support is only available to individuals working or studying in European, Middle-Eastern or African countries. Freelance translators  and students  will have priority. We will also give priority to people with accepted papers in the main conference.  
 Selection criteria   
 The selection will be made based on the information submitted to the provided Google Forms (link below). 
  One of the fields in the form is a “motivation letter”, where you should describe your motivation for attending the EAMT 2023 conference and explain why you do not have other funds to sponsor your attendance. 
  You should also submit a CV, highlighting your years of experience in the translation area and your experience working with MT. 
  For students: you should also submit an official proof of student status, signed by your University. 
  Bursaries   
 EAMT anticipates funding several applications. Selected participants will be announced on the 21st April 2023 and will receive complimentary membership in the EAMT for 2023 and 2024, free registration at the EAMT 2023 conference and paid accommodation in Tampere.  
 Contact for enquiries   
 Carolina Scarton  
 EAMT Secretary  
 e-mail: c.scarton@sheffield.ac.uk  
 Applications   
 Candidates should submit their applications via a Google Form: https://forms.gle/TzXQaRLypJD1t7qB7   
 Important Dates   
 Circulation of the Call: April 3rd, 2023 
  Submission deadline for applications: | April 14th, 2023, 23:59 CEST 
  Notification: April 21st, 2023 
  Additional provisions   
 Only complete applications will be reviewed. 
  All information submitted with applications will be regarded as confidential and will only be used in the context of this call. 
  You may be asked to share the accommodation room with other awardees. However, we will commit to respect any requirements / concerns that you inform us (e.g. religion, gender, etc). 
  No obligation to award the bursaries   
 The EAMT shall be under no obligation to fund the applications pursuant to this call for participation. EAMT shall not be liable for any compensation with respect to candidates whose applications have not been approved. Nor shall it be liable in the event of it deciding not to award the bursaries.  

   EAMT conference    
 EAMT 2023: Support for participants from low-income countries and war zones   
 April 3, 2023 (updated on July 24, 2024) 
    
 Call for Participation   
 The European Association for Machine Translation (EAMT) is an organisation that serves the growing community of people interested in MT and translation tools, including translators, users, developers, and researchers of this increasingly viable technology.  
 As part of its commitment to promote research, development and awareness about translation technologies, the EAMT opens a call for a small number of bursaries to support EAMT 2023 attendees from areas affected by war and low-income countries. The 24th Annual Conference of the European Association for Machine Translation (EAMT 2023) conference will be held in Tampere, Finland, from June 12th to June 15th.  
 Purpose of the Call   
 This call is dedicated to support EAMT 2023 attendees that do not have fundings to attend the conference, from areas affected by war or low-income countries in Europe, Middle East or Africa.  
 The EAMT particularly encourages applications from early career researchers  .  
 All applications will be screened by EAMT executive committee members.  
 Application information   
 Eligibility requirements   
 In order to qualify for this call, the individual must be a student or an employee of an institution located in areas affected by war or in low-income countries in Europe, Middle East or Africa, that would not be able to attend the conference without this support. Students  and early-career researchers/academics  will have priority. We will also give priority to people with accepted papers in the main conference.  
 Selection criteria   
 The selection will be made based on the information submitted to the provided Google Forms (link below). 
  One of the fields in the form is a “motivation letter”, where you should describe your motivation for attending the EAMT 2023 conference and explain why you do not have other funds to sponsor your attendance. 
  You should also submit a CV, highlighting your years of experience in the MT area. 
  Bursaries   
 EAMT anticipates funding several applications. Selected participants will be announced on the 21st April 2023 and will receive complimentary membership in the EAMT for 2023 and 2024, free registration at the EAMT 2023 conference and paid accommodation in Tampere.  
 Contact for enquiries   
 Carolina Scarton  
 EAMT Secretary  
 e-mail: c.scarton@sheffield.ac.uk  
 Applications   
 Candidates should submit their applications via a Google Form: https://forms.gle/HQNF5jwEDT1bG1NK6   
 Important Dates   
 Circulation of the Call: April 3rd, 2023 
  Submission deadline for applications: | April 14th, 2023, 23:59 CEST 
  Notification: April 21st, 2023 
  Additional provisions   
 Only complete applications will be reviewed. 
  All information submitted with applications will be regarded as confidential and will only be used in the context of this call. 
  You may be asked to share the accommodation room with other awardees. However, we will commit to respect any requirements / concerns that you inform us (e.g. religion, gender, etc). 
  No obligation to award the bursaries   
 The EAMT shall be under no obligation to fund the applications pursuant to this call for participation. EAMT shall not be liable for any compensation with respect to candidates whose applications have not been approved. Nor shall it be liable in the event of it deciding not to award the bursaries.  

   EAMT best thesis award    
 The Anthony C. Clarke Award for the 2022 EAMT Best Thesis   
 January 9, 2023 (updated on April 20, 2023) 
    
 The European Association for Machine Translation (EAMT, http://www.eamt.org  ) is an organization that serves the growing community of people interested in MT and translation tools, including translators, users, developers, and researchers of this increasingly viable technology.  
 The EAMT invites entries for its eleventh EAMT Best Thesis Award for a PhD or equivalent thesis on a topic related to machine translation.  
 Previous year winners can be found at https://eamt.org/best-thesis-award/  .  
 Eligibility   
 Researchers who  
 have completed a PhD (or equivalent) thesis on a relevant topic in a European, African or Middle Eastern (1) institution within calendar | year 2022 | , 
  have not previously won another international award for that thesis, and, 
  are members of the EAMT at the time of submission, 
  are invited to submit their theses to the EAMT for consideration.  
 (1) Bahrain, Iran, Iraq, Israel, Jordan, Kuwait, Oman, Palestine, Qatar, Saudi Arabia, Syria, United Arab Emirates, Yemen.  
 Panel   
 The submissions will be judged by a panel of experts who will be specifically appointed, based on the EAMT 2023 program committee, and which will be ratified by the Executive Board of the EAMT.  
 Selection criteria   
 Each thesis will be judged according to how challenging the problem was, to how relevant the results are for machine translation as a field, and to the strength of their impact in terms of scientific publications.  
 Scope   
 The scope of the thesis does not need to be confined to a technical area, and applications are also invited from students who carried out their research into commercial and management aspects of machine translation.  
 Possible areas of research include:  
 development of machine translation or advanced computer-assisted translation: methods, software or resources 
  machine translation for less-resourced languages 
  the use of these systems in professional environments (freelance translators, translation agencies, localisation, etc.) 
  the increasing impact of machine translation on non-professional Internet users and its impact in communications, social networking, etc. 
  spoken language translation 
  the integration of machine translation and translation memory systems 
  the integration of machine translation software in larger IT applications 
  the evaluation of machine translation systems in real tasks such as those above 
  the cross-fertilisation between machine translation and other language technologies 
  Prize   
 The winner will be announced on the 31st of March 2023 and will receive a prize of €500, together with an inscribed certificate. The recipient of the award will be required to briefly present their research at EAMT 2023 to be held from 12th June to 15th June 2022 in Tampere, Finland. In order to facilitate this, the EAMT will waive the winner’s registration costs, and will make available a travel bursary of €200 to enable the recipient of the award to attend the said conference. The prize includes complimentary membership in the EAMT for 2024.  
 Submission   
 Candidates will submit using EasyChair: https://easychair.org/conferences/?conf=eamt2023  (Submission type: Thesis Award), a single PDF file containing:  
 a 2-page summary of your thesis in English, containing: | your full contact details, 
  the name and contact details of your supervisor(s), 
  a copy of your CV in English (at most one page, plus a complete list of publications directly related to the thesis) 
  an electronic copy of your thesis 
  optionally, an appendix with any other relevant information on the thesis 
  By submitting their work, authors  
 agree that, in case they are granted the award, any subsequently published version of the thesis should carry the citation “The Anthony C. Clarke Award for the 2022 EAMT Best Thesis” and 
  acknowledge the right of the EAMT to publicize the granting of the award. 
  For this year’s Best Thesis Award we are requiring candidates to be an individual EAMT member at the time of submission. For EAMT memberships, please visit: http://www.eamt.org/membership.php.  
 Closing date   
 Submission deadline: | March 3  March 10, 2023, 23:59 CEST. 
  Award notification: | March 31  April 6, 2023. 

 Posts pagination  
 1  2  3      

 Theme by Colorlib  Powered by WordPress

81. CALCO_3 conference:
DROPS 
  Series | LIPIcs – Leibniz International Proceedings in Informatics 
  OASIcs – Open Access Series in Informatics 
  Dagstuhl Follow-Ups 
  Schloss Dagstuhl Jahresbericht 
   Discontinued Series 
  Journals | DARTS – Dagstuhl Artifacts Series 
  Dagstuhl Reports 
  Dagstuhl Manifestos 
  LITES – Leibniz Transactions on Embedded Systems 
  TGDK – Transactions on Graph Data and Knowledge 
  Conferences | AFT 
  AIB 
  AofA 
  APPROX 
  ATMOS 
  CALCO 
  CCC 
  CONCUR 
  COSIT 
  CP 
  CPM 
  CSL 
  DISC 
  DITAM 
  DNA 
  ECOOP 
  ECRTS 
  ESA 
  FAB 
  FMBC 
   FORC 
  FSCD 
  FSTTCS 
  FUN 
  GD 
  GIScience 
  ICALP 
  ICDT 
  ICPEC 
  IPEC 
  iPMVM 
  ISAAC 
  ITC 
  ITCS 
  ITP 
  LDK 
  MFCS 
  Microservices 
  NG-RES 
  OPODIS 
   PARMA 
  RANDOM 
  SAND 
  SAT 
  SEA 
  SLATE 
  SNAPL 
  SoCG 
  STACS 
  SWAT 
  TIME 
  Tokenomics 
  TQC 
  TYPES 
  WABI 
  WCET 
  Artifacts | Supplementary Materials (Software, Datasets, ...) 
  dblp Artifacts 
   DARTS (Evaluated Artifacts) 
        
  Metadata Export | Metadata Export 
  OAI Interface 

  Volume    Export XML 
  Export ACM-XML 
  Export DOAJ-XML 
  Export Schema.org 
  Export HTML 

  LIPIcs, Volume 270  
 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)  
   
  Part of: | Series: | Leibniz International Proceedings in Informatics (LIPIcs) | Part of: | Conference: | Conference on Algebra and Coalgebra in Computer Science (CALCO) 

 Event  
 CALCO 2023, June 19-21, 2023, Indiana University Bloomington, IN, USA   
 Editors  
  Paolo Baldan            
 University of Padova, Italy 
    
  Valeria de Paiva            
 Topos Institute, Berkeley, CA, USA 

 Publication Details  
 published at: 2023-09-02 
  Publisher: Schloss Dagstuhl – Leibniz-Zentrum für Informatik 
  ISBN: 978-3-95977-287-7 
  DBLP: | db/conf/calco/calco2023 

  Access Numbers  
 Detailed Access Statistics available here 
  Total Document Accesses (updated on a weekly basis): | 0   PDF Downloads   0   Metadata Views 

 Documents   
 No documents found matching your filter selection.   
  Document   
 Complete Volume   
 DOI: 10.4230/LIPIcs.CALCO.2023    

 LIPIcs, Volume 270, CALCO 2023, Complete Volume   
 Authors:  Paolo Baldan and Valeria de Paiva  
  Abstract    
 LIPIcs, Volume 270, CALCO 2023, Complete Volume   

  Cite as    
 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 1-336, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @Proceedings{baldan_et_al:LIPIcs.CALCO.2023 title = {{LIPIcs, Volume 270, CALCO 2023, Complete Volume}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {1--336}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023}, URN = {urn:nbn:de:0030-drops-187967}, doi = {10.4230/LIPIcs.CALCO.2023}, annote = {Keywords: LIPIcs, Volume 270, CALCO 2023, Complete Volume} }  @Proceedings{baldan_et_al:LIPIcs.CALCO.2023 title = {{LIPIcs, Volume 270, CALCO 2023, Complete Volume}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {1--336}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023}, URN = {urn:nbn:de:0030-drops-187967}, doi = {10.4230/LIPIcs.CALCO.2023}, annote = {Keywords: LIPIcs, Volume 270, CALCO 2023, Complete Volume} }    

  Document   
 Front Matter   
 DOI: 10.4230/LIPIcs.CALCO.2023.0    

 Front Matter, Table of Contents, Preface, Conference Organization   
 Authors:  Paolo Baldan and Valeria de Paiva  
  Abstract    
 Front Matter, Table of Contents, Preface, Conference Organization   

  Cite as    
 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 0:i-0:x, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{baldan_et_al:LIPIcs.CALCO.2023.0 author = {Baldan, Paolo and de Paiva, Valeria}, title = {{Front Matter, Table of Contents, Preface, Conference Organization}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {0:i--0:x}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.0}, URN = {urn:nbn:de:0030-drops-187976}, doi = {10.4230/LIPIcs.CALCO.2023.0}, annote = {Keywords: Front Matter, Table of Contents, Preface, Conference Organization} }  @InProceedings{baldan_et_al:LIPIcs.CALCO.2023.0 author = {Baldan, Paolo and de Paiva, Valeria}, title = {{Front Matter, Table of Contents, Preface, Conference Organization}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {0:i--0:x}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.0}, URN = {urn:nbn:de:0030-drops-187976}, doi = {10.4230/LIPIcs.CALCO.2023.0}, annote = {Keywords: Front Matter, Table of Contents, Preface, Conference Organization} }    

  Document   
 Invited Talk   
 DOI: 10.4230/LIPIcs.CALCO.2023.1    

 Integrating Cost and Behavior in Type Theory (Invited Talk)   
 Authors:  Robert Harper  
  Abstract    
 The computational view of intuitionistic dependent type theory is as an intrinsic logic of (functional) programs in which types are viewed as specifications of their behavior. Equational reasoning is particularly relevant in the functional case, where correctness can be formulated as equality between two implementations of the same behavior. Besides behavior, it is also important to specify and verify the cost of programs, measured in terms of their resource usage, with respect to both sequential and parallel evaluation. Although program cost can - and has been - verified in type theory using an extrinsic formulation of programs as data objects, what we seek here is, instead, an intrinsic account within type theory itself. In this talk we discuss Calf, the Cost-Aware Logical Framework, which is an extension of dependent call-by-push-value type theory that provides an intrinsic account of both parallel and sequential resource usage for a variety of problem-specific measures of cost. Thus, for example, it is possible to prove that insertion sort and merge sort are equal as regards behavior, but differ in terms of the number of comparisons required to achieve the same results. But how can equal functions have different cost? To provide an intrinsic account of both intensional and extensional properties of programs, we make use of Sterling’s notion of Synthetic Tait Computability, a generalization of Tait’s method originally developed for the study of higher type theory. In STC the concept of a "phase" plays a central role: originally as the distinction between the syntactic and semantic aspects of a computability structure, but more recently applied to the formulation of type theories for program modules and for information flow properties of programs. In Calf we distinguish two phases, the intensional and extensional, which differ as regards the significance of cost accounting - extensionally it is neglected, intensionally it is of paramount importance. Thus, in the extensional phase insertion sort and merge sort are equal, but in the intensional phase they are distinct, and indeed one is proved to have optimal behavior as regards comparisons, and the other not. Importantly, both phases are needed in a cost verification - the proof of the complexity of an algorithm usually relies on aspects of its correctness. We will provide an overview of Calf itself, and of its application in the verification of the cost and behavior of a variety of programs. So far we have been able to verify cost bounds on Euclid’s Algorithm, amortized bounds on batched queues, parallel cost bounds on a joinable form of red-black trees, and the equivalence and cost of the aforementioned sorting methods. In a companion paper at this meeting Grodin and I develop an account of amortization that relates the standard inductive view of instruction seequences with the coinductive view of data structures characterized by the same operations. In ongoing work we are extending the base of verified deterministic algorithms to those taught in the undergraduate parallel algorithms course at Carnegie Mellon, and are extending Calf itself to account for probabilistic methods, which are also used in that course. (This talk represents joint work with Yue Niu, Harrison Grodin, and Jon Sterling.)   

  Cite as    
 Robert Harper. Integrating Cost and Behavior in Type Theory (Invited Talk). In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 1:1-1:2, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{harper:LIPIcs.CALCO.2023.1 author = {Harper, Robert}, title = {{Integrating Cost and Behavior in Type Theory}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {1:1--1:2}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.1}, URN = {urn:nbn:de:0030-drops-187980}, doi = {10.4230/LIPIcs.CALCO.2023.1}, annote = {Keywords: type theory, analysis of algorithms, program verification} }  @InProceedings{harper:LIPIcs.CALCO.2023.1 author = {Harper, Robert}, title = {{Integrating Cost and Behavior in Type Theory}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {1:1--1:2}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.1}, URN = {urn:nbn:de:0030-drops-187980}, doi = {10.4230/LIPIcs.CALCO.2023.1}, annote = {Keywords: type theory, analysis of algorithms, program verification} }    

  Document   
 Invited Talk   
 DOI: 10.4230/LIPIcs.CALCO.2023.2    

 Local Completeness for Program Correctness and Incorrectness (Invited Talk)   
 Authors:  Roberto Bruni  
  Abstract    
 Program correctness techniques aim to prove the absence of bugs, but can yield false alarms because they tend to over-approximate program semantics. Vice versa, program incorrectness methods are aimed to detect true bugs, without false alarms, but cannot be used to prove correctness, because they under-approximate program semantics. In this invited talk we will overview our ongoing research on the use of the abstract interpretation framework to combine under- and over-approximation in the same analysis and distill a logic for program correctness and incorrectness.   

  Cite as    
 Roberto Bruni. Local Completeness for Program Correctness and Incorrectness (Invited Talk). In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 2:1-2:2, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{bruni:LIPIcs.CALCO.2023.2 author = {Bruni, Roberto}, title = {{Local Completeness for Program Correctness and Incorrectness}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {2:1--2:2}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.2}, URN = {urn:nbn:de:0030-drops-187993}, doi = {10.4230/LIPIcs.CALCO.2023.2}, annote = {Keywords: Program analysis, program verification, Hoare logic, incorrectness logic, abstract interpretation, local completeness} }  @InProceedings{bruni:LIPIcs.CALCO.2023.2 author = {Bruni, Roberto}, title = {{Local Completeness for Program Correctness and Incorrectness}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {2:1--2:2}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.2}, URN = {urn:nbn:de:0030-drops-187993}, doi = {10.4230/LIPIcs.CALCO.2023.2}, annote = {Keywords: Program analysis, program verification, Hoare logic, incorrectness logic, abstract interpretation, local completeness} }    

  Document   
 Invited Talk   
 DOI: 10.4230/LIPIcs.CALCO.2023.3    

 A Tour on Ecumenical Systems (Invited Talk)   
 Authors:  Elaine Pimentel and Luiz Carlos Pereira  
  Abstract    
 Ecumenism can be understood as a pursuit of unity, where diverse thoughts, ideas, or points of view coexist harmoniously. In logic, ecumenical systems refer, in a broad sense, to proof systems for combining logics. One captivating area of research over the past few decades has been the exploration of seamlessly merging classical and intuitionistic connectives, allowing them to coexist peacefully. In this paper, we will embark on a journey through ecumenical systems, drawing inspiration from Prawitz' seminal work [Dag Prawitz, 2015]. We will begin by elucidating Prawitz' concept of "ecumenism" and present a pure sequent calculus version of his system. Building upon this foundation, we will expand our discussion to incorporate alethic modalities, leveraging Simpson’s meta-logical characterization. This will enable us to propose several proof systems for ecumenical modal logics. We will conclude our tour with some discussion towards a term calculus proposal for the implicational propositional fragment of the ecumenical logic, the quest of automation using a framework based in rewriting logic, and an ecumenical view of proof-theoretic semantics.   

  Cite as    
 Elaine Pimentel and Luiz Carlos Pereira. A Tour on Ecumenical Systems (Invited Talk). In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 3:1-3:15, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{pimentel_et_al:LIPIcs.CALCO.2023.3 author = {Pimentel, Elaine and Pereira, Luiz Carlos}, title = {{A Tour on Ecumenical Systems}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {3:1--3:15}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.3}, URN = {urn:nbn:de:0030-drops-188003}, doi = {10.4230/LIPIcs.CALCO.2023.3}, annote = {Keywords: Intuitionistic logic, classical logic, modal logic, ecumenical systems, proof theory} }  @InProceedings{pimentel_et_al:LIPIcs.CALCO.2023.3 author = {Pimentel, Elaine and Pereira, Luiz Carlos}, title = {{A Tour on Ecumenical Systems}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {3:1--3:15}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.3}, URN = {urn:nbn:de:0030-drops-188003}, doi = {10.4230/LIPIcs.CALCO.2023.3}, annote = {Keywords: Intuitionistic logic, classical logic, modal logic, ecumenical systems, proof theory} }    

  Document   
 Invited Talk   
 DOI: 10.4230/LIPIcs.CALCO.2023.4    

 The Metatheory of Gradual Typing: State of the Art and Challenges (Invited Talk)   
 Authors:  Jeremy G. Siek  
  Abstract    
 Gradually typed languages offer both static and dynamic checking of program invariants, from simple properties such as type safety, to more advanced ones such as information flow control (security), relational parametricity (theorems for free), and program correctness. To ensure that gradually typed languages behave as expected, researchers prove theorems about their language designs. For example, the Gradual Guarantee Theorem states that a programmer can migrate their program to become more or less statically checked and the resulting program will behave the same (modulo errors). As another example, the Noninterference Theorem (for information flow control) states that high security inputs do not affect the low security outputs of a program. These theorems are often proved using simulation arguments or via syntactic logical relations and modal logics. Sometimes the proofs are mechanized in a proof assistant, but often they are simply written in LaTeX. However, as researchers consider gradual languages of growing complexity, the time to conduct such proofs, and/or the likelihood of errors in the proofs, also grows. As a result there is a need for improved proof techniques and libraries of mechanized results that would help to streamline the development of the metatheory of gradually typed languages.   

  Cite as    
 Jeremy G. Siek. The Metatheory of Gradual Typing: State of the Art and Challenges (Invited Talk). In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, p. 4:1, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{siek:LIPIcs.CALCO.2023.4 author = {Siek, Jeremy G.}, title = {{The Metatheory of Gradual Typing: State of the Art and Challenges}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {4:1--4:1}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.4}, URN = {urn:nbn:de:0030-drops-188019}, doi = {10.4230/LIPIcs.CALCO.2023.4}, annote = {Keywords: gradual typing, type safety, gradual guarantee, noninterference, simulation, logical relation, mechanized metatheory} }  @InProceedings{siek:LIPIcs.CALCO.2023.4 author = {Siek, Jeremy G.}, title = {{The Metatheory of Gradual Typing: State of the Art and Challenges}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {4:1--4:1}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.4}, URN = {urn:nbn:de:0030-drops-188019}, doi = {10.4230/LIPIcs.CALCO.2023.4}, annote = {Keywords: gradual typing, type safety, gradual guarantee, noninterference, simulation, logical relation, mechanized metatheory} }    

  Document   
 Invited Talk   
 DOI: 10.4230/LIPIcs.CALCO.2023.5    

 Machine-Checked Computational Mathematics (Invited Talk)   
 Authors:  Assia Mahboubi  
  Abstract    
 This talk shall discuss the potential impact of formal methods, and in particular, of interactive theorem proving, on computational mathematics. Geared with increasingly fast computer algebra libraries and scientific computing software, computers have become amazing instruments for mathematical guesswork. In fact, computer calculations are even sometimes used to substantiate actual reasoning steps in proofs, later published in major venues of the mathematical literature. Yet surprisingly, little of the now standard techniques available today for verifying critical software (e.g., cryptographic components, airborne commands, etc.) have been applied to the programs used to produce mathematics. In this talk, we propose to discuss this state of affairs.   

  Cite as    
 Assia Mahboubi. Machine-Checked Computational Mathematics (Invited Talk). In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, p. 5:1, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{mahboubi:LIPIcs.CALCO.2023.5 author = {Mahboubi, Assia}, title = {{Machine-Checked Computational Mathematics}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {5:1--5:1}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.5}, URN = {urn:nbn:de:0030-drops-188024}, doi = {10.4230/LIPIcs.CALCO.2023.5}, annote = {Keywords: Type theory, computer algebra, interactive theorem proving} }  @InProceedings{mahboubi:LIPIcs.CALCO.2023.5 author = {Mahboubi, Assia}, title = {{Machine-Checked Computational Mathematics}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {5:1--5:1}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.5}, URN = {urn:nbn:de:0030-drops-188024}, doi = {10.4230/LIPIcs.CALCO.2023.5}, annote = {Keywords: Type theory, computer algebra, interactive theorem proving} }    

  Document   
 DOI: 10.4230/LIPIcs.CALCO.2023.6    

 Forward and Backward Steps in a Fibration   
 Authors:  Ruben Turkenburg, Harsh Beohar, Clemens Kupke, and Jurriaan Rot  
  Abstract    
 Distributive laws of various kinds occur widely in the theory of coalgebra, for instance to model automata constructions and trace semantics, and to interpret coalgebraic modal logic. We study steps, which are a general type of distributive law, that allow one to map coalgebras along an adjunction. In this paper, we address the question of what such mappings do to well known notions of equivalence, e.g., bisimilarity, behavioural equivalence, and logical equivalence. We do this using the characterisation of such notions of equivalence as (co)inductive predicates in a fibration. Our main contribution is the identification of conditions on the interaction between the steps and liftings, which guarantees preservation of fixed points by the mapping of coalgebras along the adjunction. We apply these conditions in the context of lax liftings proposed by Bonchi, Silva, Sokolova (2021), and generalise their result on preservation of bisimilarity in the construction of a belief state transformer. Further, we relate our results to properties of coalgebraic modal logics including expressivity and completeness.   

  Cite as    
 Ruben Turkenburg, Harsh Beohar, Clemens Kupke, and Jurriaan Rot. Forward and Backward Steps in a Fibration. In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 6:1-6:18, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{turkenburg_et_al:LIPIcs.CALCO.2023.6 author = {Turkenburg, Ruben and Beohar, Harsh and Kupke, Clemens and Rot, Jurriaan}, title = {{Forward and Backward Steps in a Fibration}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {6:1--6:18}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.6}, URN = {urn:nbn:de:0030-drops-188032}, doi = {10.4230/LIPIcs.CALCO.2023.6}, annote = {Keywords: Coalgebra, Fibration, Bisimilarity} }  @InProceedings{turkenburg_et_al:LIPIcs.CALCO.2023.6 author = {Turkenburg, Ruben and Beohar, Harsh and Kupke, Clemens and Rot, Jurriaan}, title = {{Forward and Backward Steps in a Fibration}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {6:1--6:18}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.6}, URN = {urn:nbn:de:0030-drops-188032}, doi = {10.4230/LIPIcs.CALCO.2023.6}, annote = {Keywords: Coalgebra, Fibration, Bisimilarity} }    

  Document   
 DOI: 10.4230/LIPIcs.CALCO.2023.7    

 Structural Operational Semantics for Heterogeneously Typed Coalgebras   
 Authors:  Harald König, Uwe Wolter, and Tim Kräuter  
  Abstract    
 Concurrently interacting components of a modular software architecture are heterogeneously structured behavioural models. We consider them as coalgebras based on different endofunctors. We formalize the composition of these coalgebras as specially tailored segments of distributive laws of the bialgebraic approach of Turi and Plotkin. The resulting categorical rules for structural operational semantics involve many-sorted algebraic specifications, which leads to a description of the components together with the composed system as a single holistic behavioural system. We evaluate our approach by showing that observational equivalence is a congruence with respect to the algebraic composition operation.   

  Cite as    
 Harald König, Uwe Wolter, and Tim Kräuter. Structural Operational Semantics for Heterogeneously Typed Coalgebras. In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 7:1-7:17, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{konig_et_al:LIPIcs.CALCO.2023.7 author = {K\"{o}nig, Harald and Wolter, Uwe and Kr\"{a}uter, Tim}, title = {{Structural Operational Semantics for Heterogeneously Typed Coalgebras}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {7:1--7:17}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.7}, URN = {urn:nbn:de:0030-drops-188048}, doi = {10.4230/LIPIcs.CALCO.2023.7}, annote = {Keywords: Coalgebra, Bialgebra, Structural operational semantics, Compositionality} }  @InProceedings{konig_et_al:LIPIcs.CALCO.2023.7 author = {K\"{o}nig, Harald and Wolter, Uwe and Kr\"{a}uter, Tim}, title = {{Structural Operational Semantics for Heterogeneously Typed Coalgebras}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {7:1--7:17}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.7}, URN = {urn:nbn:de:0030-drops-188048}, doi = {10.4230/LIPIcs.CALCO.2023.7}, annote = {Keywords: Coalgebra, Bialgebra, Structural operational semantics, Compositionality} }    

  Document   
 DOI: 10.4230/LIPIcs.CALCO.2023.8    

 Interpolation Is (Not Always) Easy to Spoil   
 Authors:  Andrzej Tarlecki  
  Abstract    
 We study a version of the Craig interpolation theorem as formulated in the framework of the theory of institutions. This formulation proved crucial in the development of a number of key results concerning foundations of software specification and formal development. We investigate preservation of interpolation under extensions of institutions by new models and sentences. We point out that some interpolation properties remain stable under such extensions, even if quite arbitrary new models or sentences are permitted. We give complete characterisations of such situations for institution extensions by new models, by new sentences, as well as by new models and sentences, respectively.   

  Cite as    
 Andrzej Tarlecki. Interpolation Is (Not Always) Easy to Spoil. In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 8:1-8:19, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{tarlecki:LIPIcs.CALCO.2023.8 author = {Tarlecki, Andrzej}, title = {{Interpolation Is (Not Always) Easy to Spoil}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {8:1--8:19}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.8}, URN = {urn:nbn:de:0030-drops-188059}, doi = {10.4230/LIPIcs.CALCO.2023.8}, annote = {Keywords: interpolation, institutions, institutional abstract model theory, specification theory} }  @InProceedings{tarlecki:LIPIcs.CALCO.2023.8 author = {Tarlecki, Andrzej}, title = {{Interpolation Is (Not Always) Easy to Spoil}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {8:1--8:19}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.8}, URN = {urn:nbn:de:0030-drops-188059}, doi = {10.4230/LIPIcs.CALCO.2023.8}, annote = {Keywords: interpolation, institutions, institutional abstract model theory, specification theory} }    

  Document   
 DOI: 10.4230/LIPIcs.CALCO.2023.9    

 String Diagram Rewriting Modulo Commutative (Co)Monoid Structure   
 Authors:  Aleksandar Milosavljević, Robin Piedeleu, and Fabio Zanasi  
  Abstract    
 String diagrams constitute an intuitive and expressive graphical syntax that has found application in a very diverse range of fields including concurrency theory, quantum computing, control theory, machine learning, linguistics, and digital circuits. Rewriting theory for string diagrams relies on a combinatorial interpretation as double-pushout rewriting of certain hypergraphs. As previously studied, there is a "tension" in this interpretation: in order to make it sound and complete, we either need to add structure on string diagrams (in particular, Frobenius algebra structure) or pose restrictions on double-pushout rewriting (resulting in "convex" rewriting). From the string diagram viewpoint, imposing a full Frobenius structure may not always be natural or desirable in applications, which motivates our study of a weaker requirement: commutative monoid structure. In this work we characterise string diagram rewriting modulo commutative monoid equations, via a sound and complete interpretation in a suitable notion of double-pushout rewriting of hypergraphs.   

  Cite as    
 Aleksandar Milosavljević, Robin Piedeleu, and Fabio Zanasi. String Diagram Rewriting Modulo Commutative (Co)Monoid Structure. In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 9:1-9:17, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{milosavljevic_et_al:LIPIcs.CALCO.2023.9 author = {Milosavljevi\'{c}, Aleksandar and Piedeleu, Robin and Zanasi, Fabio}, title = {{String Diagram Rewriting Modulo Commutative (Co)Monoid Structure}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {9:1--9:17}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.9}, URN = {urn:nbn:de:0030-drops-188067}, doi = {10.4230/LIPIcs.CALCO.2023.9}, annote = {Keywords: String diagrams, Double-pushout rewriting, Commutative monoid} }  @InProceedings{milosavljevic_et_al:LIPIcs.CALCO.2023.9 author = {Milosavljevi\'{c}, Aleksandar and Piedeleu, Robin and Zanasi, Fabio}, title = {{String Diagram Rewriting Modulo Commutative (Co)Monoid Structure}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {9:1--9:17}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.9}, URN = {urn:nbn:de:0030-drops-188067}, doi = {10.4230/LIPIcs.CALCO.2023.9}, annote = {Keywords: String diagrams, Double-pushout rewriting, Commutative monoid} }    

  Document   
 DOI: 10.4230/LIPIcs.CALCO.2023.10    

 Strongly Finitary Monads for Varieties of Quantitative Algebras   
 Authors:  Jiří Adámek, Matěj Dostál, and Jiří Velebil  
  Abstract    
 Quantitative algebras are algebras enriched in the category Met of metric spaces or UMet of ultrametric spaces so that all operations are nonexpanding. Mardare, Plotkin and Panangaden introduced varieties (aka 1-basic varieties) as classes of quantitative algebras presented by quantitative equations. We prove that, when restricted to ultrametrics, varieties bijectively correspond to strongly finitary monads T on UMet. This means that T is the left Kan extension of its restriction to finite discrete spaces. An analogous result holds in the category CUMet of complete ultrametric spaces.   

  Cite as    
 Jiří Adámek, Matěj Dostál, and Jiří Velebil. Strongly Finitary Monads for Varieties of Quantitative Algebras. In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 10:1-10:14, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{adamek_et_al:LIPIcs.CALCO.2023.10 author = {Ad\'{a}mek, Ji\v{r}{\'\i} and Dost\'{a}l, Mat\v{e}j and Velebil, Ji\v{r}{\'\i}}, title = {{Strongly Finitary Monads for Varieties of Quantitative Algebras}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {10:1--10:14}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.10}, URN = {urn:nbn:de:0030-drops-188078}, doi = {10.4230/LIPIcs.CALCO.2023.10}, annote = {Keywords: quantitative algebras, ultra-quantitative algebras, strongly finitary monads, varieties} }  @InProceedings{adamek_et_al:LIPIcs.CALCO.2023.10 author = {Ad\'{a}mek, Ji\v{r}{\'\i} and Dost\'{a}l, Mat\v{e}j and Velebil, Ji\v{r}{\'\i}}, title = {{Strongly Finitary Monads for Varieties of Quantitative Algebras}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {10:1--10:14}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.10}, URN = {urn:nbn:de:0030-drops-188078}, doi = {10.4230/LIPIcs.CALCO.2023.10}, annote = {Keywords: quantitative algebras, ultra-quantitative algebras, strongly finitary monads, varieties} }    

  Document   
 DOI: 10.4230/LIPIcs.CALCO.2023.11    

 Generators and Bases for Monadic Closures   
 Authors:  Stefan Zetzsche, Alexandra Silva, and Matteo Sammartino  
  Abstract    
 It is well-known that every regular language admits a unique minimal deterministic acceptor. Establishing an analogous result for non-deterministic acceptors is significantly more difficult, but nonetheless of great practical importance. To tackle this issue, a number of sub-classes of non-deterministic automata have been identified, all admitting canonical minimal representatives. In previous work, we have shown that such representatives can be recovered categorically in two steps. First, one constructs the minimal bialgebra accepting a given regular language, by closing the minimal coalgebra with additional algebraic structure over a monad. Second, one identifies canonical generators for the algebraic part of the bialgebra, to derive an equivalent coalgebra with side effects in a monad. In this paper, we further develop the general theory underlying these two steps. On the one hand, we show that deriving a minimal bialgebra from a minimal coalgebra can be realized by applying a monad on an appropriate category of subobjects. On the other hand, we explore the abstract theory of generators and bases for algebras over a monad.   

  Cite as    
 Stefan Zetzsche, Alexandra Silva, and Matteo Sammartino. Generators and Bases for Monadic Closures. In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 11:1-11:19, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{zetzsche_et_al:LIPIcs.CALCO.2023.11 author = {Zetzsche, Stefan and Silva, Alexandra and Sammartino, Matteo}, title = {{Generators and Bases for Monadic Closures}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {11:1--11:19}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.11}, URN = {urn:nbn:de:0030-drops-188084}, doi = {10.4230/LIPIcs.CALCO.2023.11}, annote = {Keywords: Monads, Category Theory, Generators, Automata, Coalgebras, Bialgebras} }  @InProceedings{zetzsche_et_al:LIPIcs.CALCO.2023.11 author = {Zetzsche, Stefan and Silva, Alexandra and Sammartino, Matteo}, title = {{Generators and Bases for Monadic Closures}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {11:1--11:19}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.11}, URN = {urn:nbn:de:0030-drops-188084}, doi = {10.4230/LIPIcs.CALCO.2023.11}, annote = {Keywords: Monads, Category Theory, Generators, Automata, Coalgebras, Bialgebras} }    

  Document   
 DOI: 10.4230/LIPIcs.CALCO.2023.12    

 Bisimilar States in Uncertain Structures   
 Authors:  Jurriaan Rot and Thorsten Wißmann  
  Abstract    
 We provide a categorical notion called uncertain bisimilarity, which allows to reason about bisimilarity in combination with a lack of knowledge about the involved systems. Such uncertainty arises naturally in automata learning algorithms, where one investigates whether two observed behaviours come from the same internal state of a black-box system that can not be transparently inspected. We model this uncertainty as a set functor equipped with a partial order which describes possible future developments of the learning game. On such a functor, we provide a lifting-based definition of uncertain bisimilarity and verify basic properties. Beside its applications to Mealy machines, a natural model for automata learning, our framework also instantiates to an existing compatibility relation on suspension automata, which are used in model-based testing. We show that uncertain bisimilarity is a necessary but not sufficient condition for two states being implementable by the same state in the black-box system. We remedy the lack of sufficiency by a characterization of uncertain bisimilarity in terms of coalgebraic simulations.   

  Cite as    
 Jurriaan Rot and Thorsten Wißmann. Bisimilar States in Uncertain Structures. In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 12:1-12:17, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{rot_et_al:LIPIcs.CALCO.2023.12 author = {Rot, Jurriaan and Wi{\ss}mann, Thorsten}, title = {{Bisimilar States in Uncertain Structures}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {12:1--12:17}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.12}, URN = {urn:nbn:de:0030-drops-188094}, doi = {10.4230/LIPIcs.CALCO.2023.12}, annote = {Keywords: Coalgebra, Relation Lifting, Bisimilarity, Mealy Machines, ioco} }  @InProceedings{rot_et_al:LIPIcs.CALCO.2023.12 author = {Rot, Jurriaan and Wi{\ss}mann, Thorsten}, title = {{Bisimilar States in Uncertain Structures}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {12:1--12:17}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.12}, URN = {urn:nbn:de:0030-drops-188094}, doi = {10.4230/LIPIcs.CALCO.2023.12}, annote = {Keywords: Coalgebra, Relation Lifting, Bisimilarity, Mealy Machines, ioco} }    

  Document   
 DOI: 10.4230/LIPIcs.CALCO.2023.13    

 A Category for Unifying Gaussian Probability and Nondeterminism   
 Authors:  Dario Stein and Richard Samuelson  
  Abstract    
 We introduce categories of extended Gaussian maps and Gaussian relations which unify Gaussian probability distributions with relational nondeterminism in the form of linear relations. Both have crucial and well-understood applications in statistics, engineering, and control theory, but combining them in a single formalism is challenging. It enables us to rigorously describe a variety of phenomena like noisy physical laws, Willems' theory of open systems and uninformative priors in Bayesian statistics. The core idea is to formally admit vector subspaces D ⊆ X as generalized uniform probability distribution. Our formalism represents a first bridge between the literature on categorical systems theory (signal-flow diagrams, linear relations, hypergraph categories) and notions of probability theory.   

  Cite as    
 Dario Stein and Richard Samuelson. A Category for Unifying Gaussian Probability and Nondeterminism. In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 13:1-13:18, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{stein_et_al:LIPIcs.CALCO.2023.13 author = {Stein, Dario and Samuelson, Richard}, title = {{A Category for Unifying Gaussian Probability and Nondeterminism}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {13:1--13:18}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.13}, URN = {urn:nbn:de:0030-drops-188107}, doi = {10.4230/LIPIcs.CALCO.2023.13}, annote = {Keywords: systems theory, hypergraph categories, Bayesian inference, category theory, Markov categories} }  @InProceedings{stein_et_al:LIPIcs.CALCO.2023.13 author = {Stein, Dario and Samuelson, Richard}, title = {{A Category for Unifying Gaussian Probability and Nondeterminism}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {13:1--13:18}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.13}, URN = {urn:nbn:de:0030-drops-188107}, doi = {10.4230/LIPIcs.CALCO.2023.13}, annote = {Keywords: systems theory, hypergraph categories, Bayesian inference, category theory, Markov categories} }    

  Document   
 DOI: 10.4230/LIPIcs.CALCO.2023.14    

 Fractals from Regular Behaviours   
 Authors:  Todd Schmid, Victoria Noquez, and Lawrence S. Moss  
  Abstract    
 We are interested in connections between the theory of fractal sets obtained as attractors of iterated function systems and process calculi. To this end, we reinterpret Milner’s expressions for processes as contraction operators on a complete metric space. When the space is, for example, the plane, the denotations of fixed point terms correspond to familiar fractal sets. We give a sound and complete axiomatization of fractal equivalence, the congruence on terms consisting of pairs that construct identical self-similar sets in all interpretations. We further make connections to labelled Markov chains and to invariant measures. In all of this work, we use important results from process calculi. For example, we use Rabinovich’s completeness theorem for trace equivalence in our own completeness theorem. In addition to our results, we also raise many questions related to both fractals and process calculi.   

  Cite as    
 Todd Schmid, Victoria Noquez, and Lawrence S. Moss. Fractals from Regular Behaviours. In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 14:1-14:18, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{schmid_et_al:LIPIcs.CALCO.2023.14 author = {Schmid, Todd and Noquez, Victoria and Moss, Lawrence S.}, title = {{Fractals from Regular Behaviours}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {14:1--14:18}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.14}, URN = {urn:nbn:de:0030-drops-188111}, doi = {10.4230/LIPIcs.CALCO.2023.14}, annote = {Keywords: fixed-point terms, labelled transition system, fractal, final coalgebra, equational logic, completeness} }  @InProceedings{schmid_et_al:LIPIcs.CALCO.2023.14 author = {Schmid, Todd and Noquez, Victoria and Moss, Lawrence S.}, title = {{Fractals from Regular Behaviours}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {14:1--14:18}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.14}, URN = {urn:nbn:de:0030-drops-188111}, doi = {10.4230/LIPIcs.CALCO.2023.14}, annote = {Keywords: fixed-point terms, labelled transition system, fractal, final coalgebra, equational logic, completeness} }    

  Document   
 DOI: 10.4230/LIPIcs.CALCO.2023.15    

 Coinductive Control of Inductive Data Types   
 Authors:  Paige Randall North and Maximilien Péroux  
  Abstract    
 We combine the theory of inductive data types with the theory of universal measurings. By doing so, we find that many categories of algebras of endofunctors are actually enriched in the corresponding category of coalgebras of the same endofunctor. The enrichment captures all possible partial algebra homomorphisms, defined by measuring coalgebras. Thus this enriched category carries more information than the usual category of algebras which captures only total algebra homomorphisms. We specify new algebras besides the initial one using a generalization of the notion of initial algebra.   

  Cite as    
 Paige Randall North and Maximilien Péroux. Coinductive Control of Inductive Data Types. In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 15:1-15:17, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{north_et_al:LIPIcs.CALCO.2023.15 author = {North, Paige Randall and P\'{e}roux, Maximilien}, title = {{Coinductive Control of Inductive Data Types}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {15:1--15:17}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.15}, URN = {urn:nbn:de:0030-drops-188129}, doi = {10.4230/LIPIcs.CALCO.2023.15}, annote = {Keywords: Inductive types, enriched category theory, algebraic data types, algebra, coalgebra} }  @InProceedings{north_et_al:LIPIcs.CALCO.2023.15 author = {North, Paige Randall and P\'{e}roux, Maximilien}, title = {{Coinductive Control of Inductive Data Types}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {15:1--15:17}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.15}, URN = {urn:nbn:de:0030-drops-188129}, doi = {10.4230/LIPIcs.CALCO.2023.15}, annote = {Keywords: Inductive types, enriched category theory, algebraic data types, algebra, coalgebra} }    

  Document   
 DOI: 10.4230/LIPIcs.CALCO.2023.16    

 Weakly Markov Categories and Weakly Affine Monads   
 Authors:  Tobias Fritz, Fabio Gadducci, Paolo Perrone, and Davide Trotta  
  Abstract    
 Introduced in the 1990s in the context of the algebraic approach to graph rewriting, gs-monoidal categories are symmetric monoidal categories where each object is equipped with the structure of a commutative comonoid. They arise for example as Kleisli categories of commutative monads on cartesian categories, and as such they provide a general framework for effectful computation. Recently proposed in the context of categorical probability, Markov categories are gs-monoidal categories where the monoidal unit is also terminal, and they arise for example as Kleisli categories of commutative affine monads, where affine means that the monad preserves the monoidal unit. The aim of this paper is to study a new condition on the gs-monoidal structure, resulting in the concept of weakly Markov categories, which is intermediate between gs-monoidal categories and Markov ones. In a weakly Markov category, the morphisms to the monoidal unit are not necessarily unique, but form a group. As we show, these categories exhibit a rich theory of conditional independence for morphisms, generalising the known theory for Markov categories. We also introduce the corresponding notion for commutative monads, which we call weakly affine, and for which we give two equivalent characterisations. The paper argues that these monads are relevant to the study of categorical probability. A case at hand is the monad of finite non-zero measures, which is weakly affine but not affine. Such structures allow to investigate probability without normalisation within an elegant categorical framework.   

  Cite as    
 Tobias Fritz, Fabio Gadducci, Paolo Perrone, and Davide Trotta. Weakly Markov Categories and Weakly Affine Monads. In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 16:1-16:17, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{fritz_et_al:LIPIcs.CALCO.2023.16 author = {Fritz, Tobias and Gadducci, Fabio and Perrone, Paolo and Trotta, Davide}, title = {{Weakly Markov Categories and Weakly Affine Monads}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {16:1--16:17}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.16}, URN = {urn:nbn:de:0030-drops-188133}, doi = {10.4230/LIPIcs.CALCO.2023.16}, annote = {Keywords: String diagrams, gs-monoidal and Markov categories, categorical probability, affine monads} }  @InProceedings{fritz_et_al:LIPIcs.CALCO.2023.16 author = {Fritz, Tobias and Gadducci, Fabio and Perrone, Paolo and Trotta, Davide}, title = {{Weakly Markov Categories and Weakly Affine Monads}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {16:1--16:17}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.16}, URN = {urn:nbn:de:0030-drops-188133}, doi = {10.4230/LIPIcs.CALCO.2023.16}, annote = {Keywords: String diagrams, gs-monoidal and Markov categories, categorical probability, affine monads} }    

  Document   
 DOI: 10.4230/LIPIcs.CALCO.2023.17    

 Many-Valued Coalgebraic Logic: From Boolean Algebras to Primal Varieties   
 Authors:  Alexander Kurz and Wolfgang Poiger  
  Abstract    
 We study many-valued coalgebraic logics with primal algebras of truth-degrees. We describe a way to lift algebraic semantics of classical coalgebraic logics, given by an endofunctor on the variety of Boolean algebras, to this many-valued setting, and we show that many important properties of the original logic are inherited by its lifting. Then, we deal with the problem of obtaining a concrete axiomatic presentation of the variety of algebras for this lifted logic, given that we know one for the original one. We solve this problem for a class of presentations which behaves well with respect to a lattice structure on the algebra of truth-degrees.   

  Cite as    
 Alexander Kurz and Wolfgang Poiger. Many-Valued Coalgebraic Logic: From Boolean Algebras to Primal Varieties. In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 17:1-17:17, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{kurz_et_al:LIPIcs.CALCO.2023.17 author = {Kurz, Alexander and Poiger, Wolfgang}, title = {{Many-Valued Coalgebraic Logic: From Boolean Algebras to Primal Varieties}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {17:1--17:17}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.17}, URN = {urn:nbn:de:0030-drops-188147}, doi = {10.4230/LIPIcs.CALCO.2023.17}, annote = {Keywords: coalgebraic modal logic, many-valued logic, primal algebras, algebraic semantics, presenting functors} }  @InProceedings{kurz_et_al:LIPIcs.CALCO.2023.17 author = {Kurz, Alexander and Poiger, Wolfgang}, title = {{Many-Valued Coalgebraic Logic: From Boolean Algebras to Primal Varieties}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {17:1--17:17}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.17}, URN = {urn:nbn:de:0030-drops-188147}, doi = {10.4230/LIPIcs.CALCO.2023.17}, annote = {Keywords: coalgebraic modal logic, many-valued logic, primal algebras, algebraic semantics, presenting functors} }    

  Document   
 DOI: 10.4230/LIPIcs.CALCO.2023.18    

 Composition and Recursion for Causal Structures   
 Authors:  Henning Basold and Tanjona Ralaivaosaona  
  Abstract    
 Causality appears in various contexts as a property where present behaviour can only depend on past events, but not on future events. In this paper, we compare three different notions of causality that capture the idea of causality in the form of restrictions on morphisms between coinductively defined structures, such as final coalgebras and chains, in fairly general categories. We then focus on one presentation and show that it gives rise to a traced symmetric monoidal category of causal morphisms. This shows that causal morphisms are closed under sequential and parallel composition and, crucially, under recursion.   

  Cite as    
 Henning Basold and Tanjona Ralaivaosaona. Composition and Recursion for Causal Structures. In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 18:1-18:17, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{basold_et_al:LIPIcs.CALCO.2023.18 author = {Basold, Henning and Ralaivaosaona, Tanjona}, title = {{Composition and Recursion for Causal Structures}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {18:1--18:17}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.18}, URN = {urn:nbn:de:0030-drops-188157}, doi = {10.4230/LIPIcs.CALCO.2023.18}, annote = {Keywords: Causal morphisms, Final Coalgebras, Final Chains, Metric Maps, Guarded Recursion, Traced Symmetric Monoidal Category} }  @InProceedings{basold_et_al:LIPIcs.CALCO.2023.18 author = {Basold, Henning and Ralaivaosaona, Tanjona}, title = {{Composition and Recursion for Causal Structures}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {18:1--18:17}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.18}, URN = {urn:nbn:de:0030-drops-188157}, doi = {10.4230/LIPIcs.CALCO.2023.18}, annote = {Keywords: Causal morphisms, Final Coalgebras, Final Chains, Metric Maps, Guarded Recursion, Traced Symmetric Monoidal Category} }    

  Document   
 DOI: 10.4230/LIPIcs.CALCO.2023.19    

 Aczel-Mendler Bisimulations in a Regular Category   
 Authors:  Jérémy Dubut  
  Abstract    
 Aczel-Mendler bisimulations are a coalgebraic extension of a variety of computational relations between systems. It is usual to assume that the underlying category satisfies some form of axiom of choice, so that the theory enjoys desirable properties, such as closure under composition. In this paper, we accommodate the definition in a general regular category - which does not necessarily satisfy any form of axiom of choice. We show that this general definition 1) is closed under composition without using the axiom of choice, 2) coincides with other types of coalgebraic formulations under milder conditions, 3) coincides with the usual definition when the category has the regular axiom of choice. We then develop the particular case of toposes, where the formulation becomes nicer thanks to the power-object monad, and extend the formalism to simulations. Finally, we describe several examples in Stone spaces, toposes for name-passing, and modules over a ring.   

  Cite as    
 Jérémy Dubut. Aczel-Mendler Bisimulations in a Regular Category. In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 19:1-19:18, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{dubut:LIPIcs.CALCO.2023.19 author = {Dubut, J\'{e}r\'{e}my}, title = {{Aczel-Mendler Bisimulations in a Regular Category}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {19:1--19:18}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.19}, URN = {urn:nbn:de:0030-drops-188163}, doi = {10.4230/LIPIcs.CALCO.2023.19}, annote = {Keywords: Regular Categories, Toposes, Bisimulations, Coalgebra} }  @InProceedings{dubut:LIPIcs.CALCO.2023.19 author = {Dubut, J\'{e}r\'{e}my}, title = {{Aczel-Mendler Bisimulations in a Regular Category}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {19:1--19:18}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.19}, URN = {urn:nbn:de:0030-drops-188163}, doi = {10.4230/LIPIcs.CALCO.2023.19}, annote = {Keywords: Regular Categories, Toposes, Bisimulations, Coalgebra} }    

  Document   
 (Co)algebraic pearls   
 DOI: 10.4230/LIPIcs.CALCO.2023.20    

 Completeness for Categories of Generalized Automata ((Co)algebraic pearls)   
 Authors:  Guido Boccali, Andrea Laretto, Fosco Loregian, and Stefano Luneia  
  Abstract    
 We present a slick proof of completeness and cocompleteness for categories of F-automata, where the span of maps E ←d E⊗ I s→ O that usually defines a deterministic automaton of input I and output O in a monoidal category (K,⊗) is replaced by a span E ← FE → O for a generic endofunctor F : K → K of a generic category K: these automata exist in their "Mealy" and "Moore" version and form categories F-Mly and F-Mre; such categories can be presented as strict 2-pullbacks in Cat and whenever F is a left adjoint, both F-Mly and F-Mre admit all limits and colimits that K admits. We mechanize our main results using the proof assistant Agda and the library https://github.com/agda/agda-categories.   

  Cite as    
 Guido Boccali, Andrea Laretto, Fosco Loregian, and Stefano Luneia. Completeness for Categories of Generalized Automata ((Co)algebraic pearls). In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 20:1-20:14, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{boccali_et_al:LIPIcs.CALCO.2023.20 author = {Boccali, Guido and Laretto, Andrea and Loregian, Fosco and Luneia, Stefano}, title = {{Completeness for Categories of Generalized Automata}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {20:1--20:14}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.20}, URN = {urn:nbn:de:0030-drops-188174}, doi = {10.4230/LIPIcs.CALCO.2023.20}, annote = {Keywords: Deterministic automata, Moore machines, Mealy machines, coalgebras, cocomplete category} }  @InProceedings{boccali_et_al:LIPIcs.CALCO.2023.20 author = {Boccali, Guido and Laretto, Andrea and Loregian, Fosco and Luneia, Stefano}, title = {{Completeness for Categories of Generalized Automata}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {20:1--20:14}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.20}, URN = {urn:nbn:de:0030-drops-188174}, doi = {10.4230/LIPIcs.CALCO.2023.20}, annote = {Keywords: Deterministic automata, Moore machines, Mealy machines, coalgebras, cocomplete category} }    

  Document   
 (Co)algebraic pearls   
 DOI: 10.4230/LIPIcs.CALCO.2023.21    

 On Kripke, Vietoris and Hausdorff Polynomial Functors ((Co)algebraic pearls)   
 Authors:  Jiří Adámek, Stefan Milius, and Lawrence S. Moss  
  Abstract    
 The Vietoris space of compact subsets of a given Hausdorff space yields an endofunctor V on the category of Hausdorff spaces. Vietoris polynomial endofunctors on that category are built from V, the identity and constant functors by forming products, coproducts and compositions. These functors are known to have terminal coalgebras and we deduce that they also have initial algebras. We present an analogous class of endofunctors on the category of extended metric spaces, using in lieu of V the Hausdorff functor ℋ. We prove that the ensuing Hausdorff polynomial functors have terminal coalgebras and initial algebras. Whereas the canonical constructions of terminal coalgebras for Vietoris polynomial functors takes ω steps, one needs ω + ω steps in general for Hausdorff ones. We also give a new proof that the closed set functor on metric spaces has no fixed points.   

  Cite as    
 Jiří Adámek, Stefan Milius, and Lawrence S. Moss. On Kripke, Vietoris and Hausdorff Polynomial Functors ((Co)algebraic pearls). In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 21:1-21:20, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{adamek_et_al:LIPIcs.CALCO.2023.21 author = {Ad\'{a}mek, Ji\v{r}{\'\i} and Milius, Stefan and Moss, Lawrence S.}, title = {{On Kripke, Vietoris and Hausdorff Polynomial Functors}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {21:1--21:20}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.21}, URN = {urn:nbn:de:0030-drops-188189}, doi = {10.4230/LIPIcs.CALCO.2023.21}, annote = {Keywords: Hausdorff functor, Vietoris functor, initial algebra, terminal coalgebra} }  @InProceedings{adamek_et_al:LIPIcs.CALCO.2023.21 author = {Ad\'{a}mek, Ji\v{r}{\'\i} and Milius, Stefan and Moss, Lawrence S.}, title = {{On Kripke, Vietoris and Hausdorff Polynomial Functors}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {21:1--21:20}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.21}, URN = {urn:nbn:de:0030-drops-188189}, doi = {10.4230/LIPIcs.CALCO.2023.21}, annote = {Keywords: Hausdorff functor, Vietoris functor, initial algebra, terminal coalgebra} }    

  Document   
 Early Ideas   
 DOI: 10.4230/LIPIcs.CALCO.2023.22    

 CRDTs, Coalgebraically (Early Ideas)   
 Authors:  Nathan Liittschwager, Stelios Tsampas, Jonathan Castello, and Lindsey Kuper  
  Abstract    
 We describe ongoing work that models conflict-free replicated data types (CRDTs) from a coalgebraic point of view. CRDTs are data structures designed for replication across multiple physical locations in a distributed system. We show how to model a CRDT at the local replica level using a novel coalgebraic semantics for CRDTs. We believe this is the first step towards presenting a unified theory for specifying and verifying CRDTs and replicated state machines. As a case study, we consider emulation of CRDTs in terms of coalgebra.   

  Cite as    
 Nathan Liittschwager, Stelios Tsampas, Jonathan Castello, and Lindsey Kuper. CRDTs, Coalgebraically (Early Ideas). In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 22:1-22:5, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{liittschwager_et_al:LIPIcs.CALCO.2023.22 author = {Liittschwager, Nathan and Tsampas, Stelios and Castello, Jonathan and Kuper, Lindsey}, title = {{CRDTs, Coalgebraically}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {22:1--22:5}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.22}, URN = {urn:nbn:de:0030-drops-188198}, doi = {10.4230/LIPIcs.CALCO.2023.22}, annote = {Keywords: Coalgebra, Distributed Systems, Concurrency, Bisimulation} }  @InProceedings{liittschwager_et_al:LIPIcs.CALCO.2023.22 author = {Liittschwager, Nathan and Tsampas, Stelios and Castello, Jonathan and Kuper, Lindsey}, title = {{CRDTs, Coalgebraically}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {22:1--22:5}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.22}, URN = {urn:nbn:de:0030-drops-188198}, doi = {10.4230/LIPIcs.CALCO.2023.22}, annote = {Keywords: Coalgebra, Distributed Systems, Concurrency, Bisimulation} }    

  Document   
 Early Ideas   
 DOI: 10.4230/LIPIcs.CALCO.2023.23    

 Amortized Analysis via Coinduction (Early Ideas)   
 Authors:  Harrison Grodin and Robert Harper  
  Abstract    
 Amortized analysis is a program cost analysis technique for data structures in which the cost of operations is specified in aggregate, under the assumption of continued sequential use. Typically, amortized analyses are presented inductively, in terms of finite sequences of operations. We give an alternative coinductive formulation and prove that it is equivalent to the standard inductive definition. We describe a classic amortized data structure, the batched queue, and outline a coinductive proof of its amortized efficiency in calf, a dependent type theory for cost analysis.   

  Cite as    
 Harrison Grodin and Robert Harper. Amortized Analysis via Coinduction (Early Ideas). In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 23:1-23:6, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{grodin_et_al:LIPIcs.CALCO.2023.23 author = {Grodin, Harrison and Harper, Robert}, title = {{Amortized Analysis via Coinduction}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {23:1--23:6}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.23}, URN = {urn:nbn:de:0030-drops-188201}, doi = {10.4230/LIPIcs.CALCO.2023.23}, annote = {Keywords: amortized analysis, coinduction, data structure, mechanized proof} }  @InProceedings{grodin_et_al:LIPIcs.CALCO.2023.23 author = {Grodin, Harrison and Harper, Robert}, title = {{Amortized Analysis via Coinduction}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {23:1--23:6}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.23}, URN = {urn:nbn:de:0030-drops-188201}, doi = {10.4230/LIPIcs.CALCO.2023.23}, annote = {Keywords: amortized analysis, coinduction, data structure, mechanized proof} }    

  Document   
 Early Ideas   
 DOI: 10.4230/LIPIcs.CALCO.2023.24    

 Higher-Order Mathematical Operational Semantics (Early Ideas)   
 Authors:  Sergey Goncharov, Stefan Milius, Lutz Schröder, Stelios Tsampas, and Henning Urbat  
  Abstract    
 We present a higher-order extension of Turi and Plotkin’s abstract GSOS framework that retains the key feature of the latter: for every language whose operational rules are represented by a higher-order GSOS law, strong bisimilarity on the canonical operational model is a congruence with respect to the operations of the language. We further extend this result to weak (bi-)similarity, for which a categorical account of Howe’s method is developed. It encompasses, for instance, Abramsky’s classical compositionality theorem for applicative similarity in the untyped λ-calculus. In addition, we give first steps of a theory of logical relations at the level of higher-order abstract GSOS.   

  Cite as    
 Sergey Goncharov, Stefan Milius, Lutz Schröder, Stelios Tsampas, and Henning Urbat. Higher-Order Mathematical Operational Semantics (Early Ideas). In 10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 270, pp. 24:1-24:3, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2023)  
   Copy BibTex To Clipboard    
   
  @InProceedings{goncharov_et_al:LIPIcs.CALCO.2023.24 author = {Goncharov, Sergey and Milius, Stefan and Schr\"{o}der, Lutz and Tsampas, Stelios and Urbat, Henning}, title = {{Higher-Order Mathematical Operational Semantics}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {24:1--24:3}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.24}, URN = {urn:nbn:de:0030-drops-188213}, doi = {10.4230/LIPIcs.CALCO.2023.24}, annote = {Keywords: Abstract GSOS, lambda-calculus, applicative bisimilarity, bialgebra} }  @InProceedings{goncharov_et_al:LIPIcs.CALCO.2023.24 author = {Goncharov, Sergey and Milius, Stefan and Schr\"{o}der, Lutz and Tsampas, Stelios and Urbat, Henning}, title = {{Higher-Order Mathematical Operational Semantics}}, booktitle = {10th Conference on Algebra and Coalgebra in Computer Science (CALCO 2023)}, pages = {24:1--24:3}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-287-7}, ISSN = {1868-8969}, year = {2023}, volume = {270}, editor = {Baldan, Paolo and de Paiva, Valeria}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.CALCO.2023.24}, URN = {urn:nbn:de:0030-drops-188213}, doi = {10.4230/LIPIcs.CALCO.2023.24}, annote = {Keywords: Abstract GSOS, lambda-calculus, applicative bisimilarity, bialgebra} }    

 Filters  

 Authors 
   Show All  Collapse 
  Show All 
  A 
  Adámek, Jiří 
  B 
  Baldan, Paolo 
  Basold, Henning 
  Beohar, Harsh 
  Boccali, Guido 
  Bruni, Roberto 
  C 
  Castello, Jonathan 
  D 
  de Paiva, Valeria 
  Dostál, Matěj 
  Dubut, Jérémy 
  F 
  Fritz, Tobias 
  G 
  Gadducci, Fabio 
  Goncharov, Sergey 
  Grodin, Harrison 
  H 
  Harper, Robert 
  K 
  König, Harald 
  Kräuter, Tim 
  Kuper, Lindsey 
  Kupke, Clemens 
  Kurz, Alexander 
  L 
  Laretto, Andrea 
  Liittschwager, Nathan 
  Loregian, Fosco 
  Luneia, Stefano 
  M 
  Mahboubi, Assia 
  Milius, Stefan 
  Milosavljević, Aleksandar 
  Moss, Lawrence S. 
  N 
  Noquez, Victoria 
  North, Paige Randall 
  P 
  Pereira, Luiz Carlos 
  Péroux, Maximilien 
  Perrone, Paolo 
  Piedeleu, Robin 
  Pimentel, Elaine 
  Poiger, Wolfgang 
  R 
  Ralaivaosaona, Tanjona 
  Rot, Jurriaan 
  S 
  Sammartino, Matteo 
  Samuelson, Richard 
  Schmid, Todd 
  Schröder, Lutz 
  Siek, Jeremy G. 
  Silva, Alexandra 
  Stein, Dario 
  T 
  Tarlecki, Andrzej 
  Trotta, Davide 
  Tsampas, Stelios 
  Turkenburg, Ruben 
  U 
  Urbat, Henning 
  V 
  Velebil, Jiří 
  W 
  Wißmann, Thorsten 
  Wolter, Uwe 
  Z 
  Zanasi, Fabio 
  Zetzsche, Stefan 

  Subjects 
   Show All  Collapse 
  Show All 
  Computing methodologies 
  Computing methodologies → Theorem proving algorithms 
  Mathematics of computing 
  Mathematics of computing → Probability and statistics 
  Software and its engineering 
  Software and its engineering → Context specific languages 
  Software and its engineering → Functional languages 
  Software and its engineering → Semantics 
  Theory of computation 
  Theory of computation 
  Theory of computation → Abstract machines 
  Theory of computation → Abstraction 
  Theory of computation → Algebraic semantics 
  Theory of computation → Automata extensions 
  Theory of computation → Automata over infinite objects 
  Theory of computation → Categorical semantics 
  Theory of computation → Concurrency 
  Theory of computation → Design and analysis of algorithms 
  Theory of computation → Distributed computing models 
  Theory of computation → Equational logic and rewriting 
  Theory of computation → Formal languages and automata theory 
  Theory of computation → Formalisms 
  Theory of computation → Hoare logic 
  Theory of computation → Logic 
  Theory of computation → Logic and verification 
  Theory of computation → Modal and temporal logics 
  Theory of computation → Models of computation 
  Theory of computation → Operational semantics 
  Theory of computation → Probabilistic computation 
  Theory of computation → Process calculi 
  Theory of computation → Program reasoning 
  Theory of computation → Programming logic 
  Theory of computation → Proof theory 
  Theory of computation → Quantum computation theory 
  Theory of computation → Rewrite systems 
  Theory of computation → Semantics and reasoning 
  Theory of computation → Type structures 
  Theory of computation → Type theory 

  Questions / Remarks / Feedback   X  Feedback for Dagstuhl Publishing  
     
  Send    
   
  Thanks for your feedback!  
 Feedback submitted   
 OK    
  Could not send message  
 Please try again later or send an E-mail    
 OK    
   About DROPS  
 Schloss Dagstuhl - Leibniz Center for Informatics has been operating the Dagstuhl Research Online Publication Server (short: DROPS) since 2004. DROPS enables publication of the latest research findings in a fast, uncomplicated manner, in addition to providing unimpeded, open access to them. All the requisite metadata on each publication is administered in accordance with general guidelines pertaining to online publications (cf. Dublin Core). This enables the online publications to be authorized for citation and made accessible to a wide readership on a permanent basis. Access is free of charge for readers following the open access idea which fosters unimpeded access to scientific publications.  
 More about DROPS 
    
 Instructions for Authors  
 Dagstuhl Series   
  LIPIcs 
  OASIcs 
  Dagstuhl Follow-Ups 
    
 Dagstuhl Journals   
  DARTS – Dagstuhl Artifacts Series 
  Dagstuhl Reports 
  Dagstuhl Manifestos 
  LITES 
  TGDK – Transactions on Graph Data and Knowledge 

 Instructions for Editors  
 Dagstuhl Series   
  LIPIcs 
  OASIcs 
  Dagstuhl Follow-Ups 
    
 Dagstuhl Journals   
  DARTS – Dagstuhl Artifacts Series 
  Dagstuhl Reports 
  Dagstuhl Manifestos 
  LITES 
  TGDK – Transactions on Graph Data and Knowledge 

 © 2023-2024 Schloss Dagstuhl – LZI GmbH  About DROPS  Imprint  Privacy  Contact

82. CoNLL_0 conference:
ACL Anthology     News (current) 
  FAQ (current) 
  Corrections (current) 
  Submissions (current) 
  Github 

 Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL)   
 Jing Jiang  , David Reitter  , Shumin Deng  (Editors)   
  Anthology ID:  2023.conll-1  Month:  December  Year:  2023  Address:  Singapore  Venue:  CoNLL   SIG:   Publisher:  Association for Computational Linguistics  URL:  https://aclanthology.org/2023.conll-1   DOI:   Bib Export formats:  BibTeX  MODS XML  EndNote   PDF:  https://aclanthology.org/2023.conll-1.pdf      
  PDF (full)     Bib  TeX    Search     
   
  Show all abstracts   Hide all abstracts    pdf  bib   
   Proceedings of the 27th Conference on Computational Natural Language Learning (CoNLL)    
  Jing Jiang  | David Reitter  | Shumin Deng    
 pdf  bib  abs   
     Can Language Models Be Tricked by Language Illusions? Easier with Syntax, Harder with Semantics    
  Yuhan Zhang  | Edward Gibson  | Forrest Davis    
 Language models (LMs) have been argued to overlap substantially with human beings in grammaticality judgment tasks. But when humans systematically make errors in language processing, should we expect LMs to behave like cognitive models of language and mimic human behavior? We answer this question by investigating LMs’ more subtle judgments associated with “language illusions” – sentences that are vague in meaning, implausible, or ungrammatical but receive unexpectedly high acceptability judgments by humans. We looked at three illusions: the comparative illusion (e.g. “More people have been to Russia than I have”), the depth-charge illusion (e.g. “No head injury is too trivial to be ignored”), and the negative polarity item (NPI) illusion (e.g. “The hunter who no villager believed to be trustworthy will ever shoot a bear”). We found that probabilities represented by LMs were more likely to align with human judgments of being “tricked” by the NPI illusion which examines a structural dependency, compared to the comparative and the depth-charge illusions which require sophisticated semantic understanding. No single LM or metric yielded results that are entirely consistent with human behavior. Ultimately, we show that LMs are limited both in their construal as cognitive models of human language processing and in their capacity to recognize nuanced but critical information in complicated language materials.   
   
 pdf  bib  abs   
     T  o MC  hallenges: A Principle-Guided Dataset and Diverse Evaluation Tasks for Exploring Theory of Mind    
  Xiaomeng Ma  | Lingyu Gao  | Qihui Xu    
 Theory of Mind (ToM), the capacity to comprehend the mental states of distinct individuals, is essential for numerous practical applications. With the development of large language models (LLMs), there is a heated debate about whether they are able to perform ToM tasks. Previous studies have used different tasks and prompts to test the ToM on LLMs and the results are inconsistent: some studies asserted these models are capable of exhibiting ToM, while others suggest the opposite. In this study, We present ToMChallenges, a dataset for comprehensively evaluating the Theory of Mind based on Sally-Anne and Smarties tests with a diverse set of tasks. In addition, we also propose an auto-grader to streamline the answer evaluation process. We tested three models: davinci, turbo, and gpt-4. Our evaluation results and error analyses show that LLMs have inconsistent behaviors across prompts and tasks. Performing the ToM tasks robustly remains a challenge for the LLMs. In addition, our paper wants to raise awareness in evaluating the ToM in LLMs and we want to invite more discussion on how to design the prompts and tasks for ToM tasks that can better access the LLMs’ ability.   
   
 pdf  bib  abs   
       The Z  ipfian Challenge: Learning the statistical fingerprint of natural languages    
  Christian Bentz    
 Human languages are often claimed to fundamentally differ from other communication systems. But what is it exactly that unites them as a separate category? This article proposes to approach this problem – here termed the Zipfian Challenge – as a standard classification task. A corpus with textual material from diverse writing systems and languages, as well as other symbolic and non-symbolic systems, is provided. These are subsequently used to train and test binary classification algorithms, assigning labels “writing” and “non-writing” to character strings of the test sets. The performance is generally high, reaching 98% accuracy for the best algorithms. Human languages emerge to have a statistical fingerprint: large unit inventories, high entropy, and few repetitions of adjacent units. This fingerprint can be used to tease them apart from other symbolic and non-symbolic systems.   
   
 pdf  bib  abs   
       On the Effects of Structural Modeling for Neural Semantic Parsing    
  Xiang Zhang  | Shizhu He  | Kang Liu  | Jun Zhao    
 Semantic parsing aims to map natural language sentences to predefined formal languages, such as logic forms and programming languages, as the semantic annotation. From the theoretic views of linguistic and programming language, structures play an important role in both languages, which had motivated semantic parsers since the task was proposed in the beginning. But in the neural era, semantic parsers treating both natural and formal language as sequences, such as Seq2Seq and LLMs, have got more attentions. On the other side, lots of neural progress have been made for grammar induction, which only focuses on natural languages. Although closely related in the sense of structural modeling, these techniques hadn’t been jointly analyzed on the semantic parsing testbeds. To gain the better understanding on structures for semantic parsing, we design a taxonomy of structural modeling methods, and evaluate some representative techniques on semantic parsing, including both compositional and i.i.d. generalizations. In addition to the previous opinion that structures will help in general, we find that (1) structures must be designed for the specific dataset and generalization level, and (2) what really matters is not the structure choice of either source or target side, but the choice combination of both sides. Based on the finding, we further propose a metric that can evaluate the structure choice, which we believe can boost the automation of grammar designs for specific datasets and domains.   
   
 pdf  bib  abs   
   Humans and language models diverge when predicting repeating text    
  Aditya Vaidya  | Javier Turek  | Alexander Huth    
 Language models that are trained on the next-word prediction task have been shown to accurately model human behavior in word prediction and reading speed. In contrast with these findings, we present a scenario in which the performance of humans and LMs diverges. We collected a dataset of human next-word predictions for five stimuli that are formed by repeating spans of text. Human and GPT-2 LM predictions are strongly aligned in the first presentation of a text span, but their performance quickly diverges when memory (or in-context learning) begins to play a role. We traced the cause of this divergence to specific attention heads in a middle layer. Adding a power-law recency bias to these attention heads yielded a model that performs much more similarly to humans. We hope that this scenario will spur future work in bringing LMs closer to human behavior.   
   
 pdf  bib  abs   
   Investigating the Nature of Disagreements on Mid-Scale Ratings: A Case Study on the Abstractness-Concreteness Continuum    
  Urban Knupleš  | Diego Frassinelli  | Sabine Schulte im Walde    
 Humans tend to strongly agree on ratings on a scale for extreme cases (e.g., a CAT is judged as very concrete), but judgements on mid-scale words exhibit more disagreement. Yet, collected rating norms are heavily exploited across disciplines. Our study focuses on concreteness ratings and (i) implements correlations and supervised classification to identify salient multi-modal characteristics of mid-scale words, and (ii) applies a hard clustering to identify patterns of systematic disagreement across raters. Our results suggest to either fine-tune or filter mid-scale target words before utilising them.   
   
 pdf  bib  abs   
     A  rch BERT  : Bi-Modal Understanding of Neural Architectures and Natural Languages    
  Mohammad Akbari  | Saeed Ranjbar Alvar  | Behnam Kamranian  | Amin Banitalebi-Dehkordi  | Yong Zhang    
 Building multi-modal language models has been a trend in the recent years, where additional modalities such as image, video, speech, etc. are jointly learned along with natural languages (i.e., textual information). Despite the success of these multi-modal language models with different modalities, there is no existing solution for neural network architectures and natural languages. Providing neural architectural information as a new modality allows us to provide fast architecture-2-text and text-2-architecture retrieval/generation services on the cloud with a single inference. Such solution is valuable in terms of helping beginner and intermediate ML users to come up with better neural architectures or AutoML approaches with a simple text query. In this paper, we propose ArchBERT, a bi-modal model for joint learning and understanding of neural architectures and natural languages, which opens up new avenues for research in this area. We also introduce a pre-training strategy named Masked Architecture Modeling (MAM) for a more generalized joint learning. Moreover, we introduce and publicly release two new bi-modal datasets for training and validating our methods. The ArchBERT’s performance is verified through a set of numerical experiments on different downstream tasks such as architecture-oriented reasoning, question answering, and captioning (summarization). Datasets, codes, and demos are available as supplementary materials.   
   
 pdf  bib  abs   
   A Comparative Study on Textual Saliency of Styles from Eye Tracking, Annotations, and Language Models    
  Karin de Langis  | Dongyeop Kang    
 There is growing interest in incorporating eye-tracking data and other implicit measures of human language processing into natural language processing (NLP) pipelines. The data from human language processing contain unique insight into human linguistic understanding that could be exploited by language models. However, many unanswered questions remain about the nature of this data and how it can best be utilized in downstream NLP tasks. In this paper, we present EyeStyliency, an eye-tracking dataset for human processing of stylistic text (e.g., politeness). We develop an experimental protocol to collect these style-specific eye movements. We further investigate how this saliency data compares to both human annotation methods and model-based interpretability metrics. We find that while eye-tracking data is unique, it also intersects with both human annotations and model-based importance scores, providing a possible bridge between human- and machine-based perspectives. We propose utilizing this type of data to evaluate the cognitive plausibility of models that interpret style. Our eye-tracking data and processing code are publicly available.   
   
 pdf  bib  abs   
   PROPRES  : Investigating the Projectivity of Presupposition with Various Triggers and Environments    
  Daiki Asami  | Saku Sugawara    
 What makes a presupposition of an utterance —information taken for granted by its speaker— different from other pragmatic inferences such as an entailment is projectivity (e.g., the negative sentence the boy did not stop shedding tears presupposes the boy had shed tears before). The projectivity may vary depending on the combination of presupposition triggers and environments. However, prior natural language understanding studies fail to take it into account as they either use no human baseline or include only negation as an entailment-canceling environment to evaluate models’ performance. The current study attempts to reconcile these issues. We introduce a new dataset, projectivity of presupposition (PROPRES), which includes 12k premise–hypothesis pairs crossing six triggers involving some lexical variety with five environments. Our human evaluation reveals that humans exhibit variable projectivity in some cases. However, the model evaluation shows that the best-performed model, DeBERTa, does not fully capture it. Our findings suggest that probing studies on pragmatic inferences should take extra care of the human judgment variability and the combination of linguistic items.   
   
 pdf  bib  abs   
   A Minimal Approach for Natural Language Action Space in Text-based Games    
  Dongwon Ryu  | Meng Fang  | Gholamreza Haffari  | Shirui Pan  | Ehsan Shareghi    
 Text-based games (TGs) are language-based interactive environments for reinforcement learning. While language models (LMs) and knowledge graphs (KGs) are commonly used for handling large action space in TGs, it is unclear whether these techniques are necessary or overused. In this paper, we revisit the challenge of exploring the action space in TGs and propose 𝜖  -admissible exploration, a minimal approach of utilizing admissible actions, for training phase. Additionally, we present a text-based actor-critic (TAC) agent that produces textual commands for game, solely from game observations, without requiring any KG or LM. Our method, on average across 10 games from Jericho, outperforms strong baselines and state-of-the-art agents that use LM and KG. Our approach highlights that a much lighter model design, with a fresh perspective on utilizing the information within the environments, suffices for an effective exploration of exponentially large action spaces.   
   
 pdf  bib  abs   
   Structural Ambiguity and its Disambiguation in Language Model Based Parsers: the Case of D  utch Clause Relativization    
  Gijs Wijnholds  | Michael Moortgat    
 This paper addresses structural ambiguity in Dutch relative clauses. By investigating the task of disambiguation by grounding, we study how the presence of a prior sentence can resolve relative clause ambiguities. We apply this method to two parsing architectures in an attempt to demystify the parsing and language model components of two present-day neural parsers. Results show that a neurosymbolic parser, based on proof nets, is more open to data bias correction than an approach based on universal dependencies, although both set-ups suffer from a comparable initial data bias.   
   
 pdf  bib  abs   
   On the utility of enhancing BERT  syntactic bias with Token Reordering Pretraining    
  Yassir El Mesbahi  | Atif Mahmud  | Abbas Ghaddar  | Mehdi Rezagholizadeh  | Phillippe Langlais  | Prasanna Parthasarathi    
 Self-supervised Language Modelling (LM) objectives —like BERT masked LM— have become the default choice for pretraining language models. TOken Reordering (TOR) pretraining objectives, beyond token prediction, have not been extensively studied yet. In this work, we explore challenges that underlie the development and usefulness of such objectives on downstream language tasks. In particular, we design a novel TOR pretraining objective which predicts whether two tokens are adjacent or not given a partial bag-of-tokens input. In addition, we investigate the usefulness of Graph Isomorphism Network (GIN), when placed on top of the BERT encoder, in order to enhance the overall model ability to leverage topological signal from the encoded representations. We compare language understanding abilities of TOR to the one of MLM on word-order sensitive (e.g. Dependency Parsing) and insensitive (e.g. text classification) tasks in both full training and few-shot settings. Our results indicate that TOR is competitive to MLM on the GLUE language understanding benchmark, and slightly superior on syntax-dependent datasets, especially in the few-shot setting.   
   
 pdf  bib  abs   
   Quirk or Palmer: A Comparative Study of Modal Verb Frameworks with Annotated Datasets    
  Risako Owan  | Maria Gini  | Dongyeop Kang    
 Modal verbs, such as can, may, and must, are commonly used in daily communication to convey the speaker’s perspective related to the likelihood and/or mode of the proposition. They can differ greatly in meaning depending on how they’re used and the context of a sentence (e.g. “They must help each other out.” vs. “They must have helped each other out.”). Despite their practical importance in natural language understanding, linguists have yet to agree on a single, prominent framework for the categorization of modal verb senses. This lack of agreement stems from high degrees of flexibility and polysemy from the modal verbs, making it more difficult for researchers to incorporate insights from this family of words into their work. As a tool to help navigate this issue, this work presents MoVerb, a dataset consisting of 27,240 annotations of modal verb senses over 4,540 utterances containing one or more sentences from social conversations. Each utterance is annotated by three annotators using two different theoretical frameworks (i.e., Quirk and Palmer) of modal verb senses. We observe that both frameworks have similar inter-annotator agreements, despite having a different number of sense labels (eight for Quirk and three for Palmer). With RoBERTa-based classifiers fine-tuned on MoVerb, we achieve F1 scores of 82.2 and 78.3 on Quirk and Palmer, respectively, showing that modal verb sense disambiguation is not a trivial task.   
   
 pdf  bib  abs   
       Quantifying Information of Tokens for Simple and Flexible Simultaneous Machine Translation    
  DongHyun Lee  | Minkyung Park  | Byung-Jun Lee    
 Simultaneous Translation (ST) involves translating with only partial source inputs instead of the entire source inputs, a process that can potentially result in translation quality degradation. Previous approaches to balancing translation quality and latency have demonstrated that it is more efficient and effective to leverage an offline model with a reasonable policy. However, using an offline model also leads to a distribution shift since it is not trained with partial source inputs, and it can be improved by training an additional module that informs us when to translate. In this paper, we propose an Information Quantifier (IQ) that models source and target information to determine whether the offline model has sufficient information for translation, trained with oracle action sequences generated from the offline model. IQ, by quantifying information, helps in formulating a suitable policy for Simultaneous Translation that better generalizes and also allows us to control the trade-off between quality and latency naturally. Experiments on various language pairs show that our proposed model outperforms baselines.   
   
 pdf  bib  abs   
   Enhancing Code-mixed Text Generation Using Synthetic Data Filtering in Neural Machine Translation    
  Dama Sravani  | Radhika Mamidi    
 Code-Mixing, the act of mixing two or more languages, is a common communicative phenomenon in multi-lingual societies. The lack of quality in code-mixed data is a bottleneck for NLP systems. On the other hand, Monolingual systems perform well due to ample high-quality data. To bridge the gap, creating coherent translations of monolingual sentences to their code-mixed counterparts can improve accuracy in code-mixed settings for NLP downstream tasks. In this paper, we propose a neural machine translation approach to generate high-quality code-mixed sentences by leveraging human judgements. We train filters based on human judgements to identify natural code-mixed sentences from a larger synthetically generated code-mixed corpus, resulting in a three-way silver parallel corpus between monolingual English, monolingual Indian language and code-mixed English with an Indian language. Using these corpora, we fine-tune multi-lingual encoder-decoder models viz, mT5 and mBART, for the translation task. Our results indicate that our approach of using filtered data for training outperforms the current systems for code-mixed generation in Hindi-English. Apart from Hindi-English, the approach performs well when applied to Telugu, a low-resource language, to generate Telugu-English code-mixed sentences.   
   
 pdf  bib  abs   
   Towards Better Evaluation of Instruction-Following: A Case-Study in Summarization    
  Ondrej Skopek  | Rahul Aralikatte  | Sian Gooding  | Victor Carbune    
 Despite recent advances, evaluating how well large language models (LLMs) follow user instructions remains an open problem. While evaluation methods of language models have seen a rise in prompt-based approaches, limited work on the correctness of these methods has been conducted. In this work, we perform a meta-evaluation of a variety of metrics to quantify how accurately they measure the instruction-following abilities of LLMs. Our investigation is performed on grounded query-based summarization by collecting a new short-form, real-world dataset riSum, containing 300 document-instruction pairs with 3 answers each. All 900 answers are rated by 3 human annotators. Using riSum, we analyze the agreement between evaluation methods and human judgment. Finally, we propose new LLM-based reference-free evaluation methods that improve upon established baselines and perform on par with costly reference-based metrics that require high-quality summaries.   
   
 pdf  bib  abs   
   Syntactic Inductive Bias in Transformer Language Models: Especially Helpful for Low-Resource Languages?    
  Luke Gessler  | Nathan Schneider    
 A line of work on Transformer-based language models such as BERT has attempted to use syntactic inductive bias to enhance the pretraining process, on the theory that building syntactic structure into the training process should reduce the amount of data needed for training. But such methods are often tested for high-resource languages such as English. In this work, we investigate whether these methods can compensate for data sparseness in low-resource languages, hypothesizing that they ought to be more effective for low-resource languages. We experiment with five low-resource languages: Uyghur, Wolof, Maltese, Coptic, and Ancient Greek. We find that these syntactic inductive bias methods produce uneven results in low-resource settings, and provide surprisingly little benefit in most cases.   
   
 pdf  bib  abs   
   Attribution and Alignment: Effects of Local Context Repetition on Utterance Production and Comprehension in Dialogue    
  Aron Molnar  | Jaap Jumelet  | Mario Giulianelli  | Arabella Sinclair    
 Language models are often used as the backbone of modern dialogue systems. These models are pre-trained on large amounts of written fluent language. Repetition is typically penalised when evaluating language model generations. However, it is a key component of dialogue. Humans use local and partner specific repetitions; these are preferred by human users and lead to more successful communication in dialogue. In this study, we evaluate (a) whether language models produce human-like levels of repetition in dialogue, and (b) what are the processing mechanisms related to lexical re-use they use during comprehension. We believe that such joint analysis of model production and comprehension behaviour can inform the development of cognitively inspired dialogue generation systems.   
   
 pdf  bib  abs   
     The Validity of Evaluation Results: Assessing Concurrence Across Compositionality Benchmarks    
  Kaiser Sun  | Adina Williams  | Dieuwke Hupkes    
 NLP models have progressed drastically in recent years, according to numerous datasets proposed to evaluate performance. Questions remain, however, about how particular dataset design choices may impact the conclusions we draw about model capabilities. In this work, we investigate this question in the domain of compositional generalization. We examine the performance of six modeling approaches across 4 datasets, split according to 8 compositional splitting strategies, ranking models by 18 compositional generalization splits in total. Our results show that: i) the datasets, although all designed to evaluate compositional generalization, rank modeling approaches differently; ii) datasets generated by humans align better with each other than with synthetic datasets, or than the latter among themselves; iii) generally, whether datasets are sampled from the same source is more predictive of the resulting model ranking than whether they maintain the same interpretation of compositionality; and iv) specific lexical items in dataset impacts the measurement consistency. Overall, our results demonstrate that much work remains to be done when it comes to assessing whether popular evaluation datasets measure what they intend to measure, and suggests that elucidating more rigorous standards for establishing the validity of evaluation sets could benefit the field.   
   
 pdf  bib  abs   
   Mind the instructions: a holistic evaluation of consistency and interactions in prompt-based learning    
  Lucas Weber  | Elia Bruni  | Dieuwke Hupkes    
 Finding the best way of adapting pre-trained language models to a task is a big challenge in current NLP. Just like the previous generation of task-tuned  models (TT), models that are adapted to tasks via in-context-learning (ICL) or instruction tuning (IT) are robust in some setups, but not in others. Here, we present a detailed analysis of which design choices cause instabilities and inconsistencies in LLM predictions. First, we show how spurious correlations between input distributions and labels – a known issue in TT models – form only a minor problem for prompted models. Then we engage in a systematic, holistic evaluation of different factors that have been found to influence predictions in a prompting setup. We test all possible combinations of a range of factors on both vanilla and instruction-tuned LLMs of different scale, and statistically analyse the results to show which factors are the most influential, the most interactive or the most stable. From our results, we deduce which factors can be used without precautions, should be avoided or handled with care in most settings.   
   
 pdf  bib  abs   
   M  ed- HALT  : Medical Domain Hallucination Test for Large Language Models    
  Ankit Pal  | Logesh Kumar Umapathi  | Malaikannan Sankarasubbu    
 This research paper focuses on the challenges posed by hallucinations in large language models (LLMs), particularly in the context of the medical domain. Hallucination, wherein these models generate plausible yet unverified or incorrect information, can have serious consequences in healthcare applications. We propose a new benchmark and dataset, Med-HALT (Medical Domain Hallucination Test), designed specifically to evaluate and reduce hallucinations. Med-HALT provides a diverse multinational dataset derived from medical examinations across various countries and includes multiple innovative testing modalities. Med-HALT includes two categories of tests reasoning and memory-based hallucination tests, designed to assess LLMs’ problem-solving and information retrieval abilities. Our study evaluated leading LLMs, including Text Davinci, GPT-3.5, LlaMa-2, MPT, and Falcon, revealing significant differences in their performance. The paper provides detailed insights into the dataset, promoting transparency and reproducibility. Through this work, we aim to contribute to the development of safer and more reliable language models in healthcare. Our benchmark can be found at medhalt.github.io   
   
 pdf  bib  abs   
   Revising with a Backward Glance: Regressions and Skips during Reading as Cognitive Signals for Revision Policies in Incremental Processing    
  Brielen Madureira  | Pelin Çelikkol  | David Schlangen    
 In NLP, incremental processors produce output in instalments, based on incoming prefixes of the linguistic input. Some tokens trigger revisions, causing edits to the output hypothesis, but little is known about why models revise when they revise. A policy that detects the time steps where revisions should happen can improve efficiency. Still, retrieving a suitable signal to train a revision policy is an open problem, since it is not naturally available in datasets. In this work, we investigate the appropriateness of regressions and skips in human reading eye-tracking data as signals to inform revision policies in incremental sequence labelling. Using generalised mixed-effects models, we find that the probability of regressions and skips by humans can potentially serve as useful predictors for revisions in BiLSTMs and Transformer models, with consistent results for various languages.   
   
 pdf  bib  abs   
   C  hi SC  or: A Corpus of Freely-Told Fantasy Stories by D  utch Children for Computational Linguistics and Cognitive Science    
  Bram van Dijk  | Max van Duijn  | Suzan Verberne  | Marco Spruit    
 In this resource paper we release ChiSCor, a new corpus containing 619 fantasy stories, told freely by 442 Dutch children aged 4-12. ChiSCor was compiled for studying how children render character perspectives, and unravelling language and cognition in development, with computational tools. Unlike existing resources, ChiSCor’s stories were produced in natural contexts, in line with recent calls for more ecologically valid datasets. ChiSCor hosts text, audio, and annotations for character complexity and linguistic complexity. Additional metadata (e.g. education of caregivers) is available for one third of the Dutch children. ChiSCor also includes a small set of 62 English stories. This paper details how ChiSCor was compiled and shows its potential for future work with three brief case studies: i) we show that the syntactic complexity of stories is strikingly stable across children’s ages; ii) we extend work on Zipfian distributions in free speech and show that ChiSCor obeys Zipf’s law closely, reflecting its social context; iii) we show that even though ChiSCor is relatively small, the corpus is rich enough to train informative lemma vectors that allow us to analyse children’s language use. We end with a reflection on the value of narrative datasets in computational linguistics.   
   
 pdf  bib  abs   
     HNC  : Leveraging Hard Negative Captions towards Models with Fine-Grained Visual-Linguistic Comprehension Capabilities    
  Esra Dönmez  | Pascal Tilli  | Hsiu-Yu Yang  | Ngoc Thang Vu  | Carina Silberer    
 Image-Text-Matching (ITM) is one of the defacto methods of learning generalized representations from a large corpus in Vision and Language (VL). However, due to the weak association between the web-collected image–text pairs, models fail to show fine-grained understanding of the combined semantics of these modalities. To this end, we propose Hard Negative Captions (HNC): an automatically created dataset containing foiled hard negative captions for ITM training towards achieving fine-grained cross-modal comprehension in VL. Additionally, we provide a challenging manually-created test set for benchmarking models on a fine-grained cross-modal mismatch with varying levels of compositional complexity. Our results show the effectiveness of training on HNC by improving the models’ zero-shot capabilities in detecting mismatches on diagnostic tasks and performing robustly under noisy visual input scenarios. Also, we demonstrate that HNC models yield a comparable or better initialization for fine-tuning. Our code and data are publicly available.   
   
 pdf  bib  abs   
   Theory of Mind in Large Language Models: Examining Performance of 11 State-of-the-Art models vs. Children Aged 7-10 on Advanced Tests    
  Max van Duijn  | Bram van Dijk  | Tom Kouwenhoven  | Werner de Valk  | Marco Spruit  | Peter van der Putten    
 To what degree should we ascribe cognitive capacities to Large Language Models (LLMs), such as the ability to reason about intentions and beliefs known as Theory of Mind (ToM)? Here we add to this emerging debate by (i) testing 11 base- and instruction-tuned LLMs on capabilities relevant to ToM beyond the dominant false-belief paradigm, including non-literal language usage and recursive intentionality; (ii) using newly rewritten versions of standardized tests to gauge LLMs’ robustness; (iii) prompting and scoring for open besides closed questions; and (iv) benchmarking LLM performance against that of children aged 7-10 on the same tasks. We find that instruction-tuned LLMs from the GPT family outperform other models, and often also children. Base-LLMs are mostly unable to solve ToM tasks, even with specialized prompting. We suggest that the interlinked evolution and development of language and ToM may help explain what instruction-tuning adds: rewarding cooperative communication that takes into account interlocutor and context. We conclude by arguing for a nuanced perspective on ToM in LLMs.   
   
 pdf  bib  abs   
   A Block Metropolis-Hastings Sampler for Controllable Energy-based Text Generation    
  Jarad Forristal  | Fatemehsadat Mireshghallah  | Greg Durrett  | Taylor Berg-Kirkpatrick    
 Recent work has shown that energy-based language modeling is an effective framework for controllable text generation because it enables flexible integration of arbitrary discriminators. However, because energy-based LMs are globally normalized, approximate techniques like Metropolis-Hastings (MH) are required for inference. Past work has largely explored simple proposal distributions that modify a single token at a time, like in Gibbs sampling. In this paper, we develop a novel MH sampler that, in contrast, proposes re-writes of the entire sequence in each step via iterative prompting of a large language model. Our new sampler (a) allows for more efficient and accurate sampling from a target distribution and (b) allows generation length to be determined through the sampling procedure rather than fixed in advance, as past work has required. We perform experiments on two controlled generation tasks, showing both downstream performance gains and more accurate target distribution sampling in comparison with single-token proposal techniques.   
   
 pdf  bib  abs   
   How Fragile is Relation Extraction under Entity Replacements?    
  Yiwei Wang  | Bryan Hooi  | Fei Wang  | Yujun Cai  | Yuxuan Liang  | Wenxuan Zhou  | Jing Tang  | Manjuan Duan  | Muhao Chen    
 Relation extraction (RE) aims to extract the relations between entity names from the textual context. In principle, textual context determines the ground-truth relation and the RE models should be able to correctly identify the relations reflected by the textual context. However, existing work has found that the RE models memorize the entity name patterns to make RE predictions while ignoring the textual context. This motivates us to raise the question: are RE models robust to the entity replacements? In this work, we operate the random and type-constrained entity replacements over the RE instances in TACRED and evaluate the state-of-the-art RE models under the entity replacements. We observe the 30% - 50% F1 score drops on the state-of-the-art RE models under entity replacements. These results suggest that we need more efforts to develop effective RE models robust to entity replacements. We release the source code at https://github.com/wangywUST/RobustRE.   
   
 pdf  bib  abs   
   J  a SPICE  : Automatic Evaluation Metric Using Predicate-Argument Structures for Image Captioning Models    
  Yuiga Wada  | Kanta Kaneda  | Komei Sugiura    
 Image captioning studies heavily rely on automatic evaluation metrics such as BLEU and METEOR. However, such n-gram-based metrics have been shown to correlate poorly with human evaluation, leading to the proposal of alternative metrics such as SPICE for English; however, no equivalent metrics have been established for other languages. Therefore, in this study, we propose an automatic evaluation metric called JaSPICE, which evaluates Japanese captions based on scene graphs. The proposed method generates a scene graph from dependencies and the predicate-argument structure, and extends the graph using synonyms. We conducted experiments employing 10 image captioning models trained on STAIR Captions and PFN-PIC and constructed the Shichimi dataset, which contains 103,170 human evaluations. The results showed that our metric outperformed the baseline metrics for the correlation coefficient with the human evaluation.   
   
 pdf  bib  abs   
   M  u LER  : Detailed and Scalable Reference-based Evaluation    
  Taelin Karidi  | Leshem Choshen  | Gal Patel  | Omri Abend    
 We propose a novel methodology (namely, MuLER) that transforms any reference-based evaluation metric for text generation, such as machine translation (MT) into a fine-grained analysis tool. Given a system and a metric, MuLER quantifies how much the chosen metric penalizes specific error types (e.g., errors in translating names of locations). MuLER thus enables a detailed error analysis which can lead to targeted improvement efforts for specific phenomena. We perform experiments in both synthetic and naturalistic settings to support MuLER’s validity and showcase its usability in MT evaluation, and other tasks, such as summarization. Analyzing all submissions to WMT in 2014-2020, we find consistent trends. For example, nouns and verbs are among the most frequent POS tags. However, they are among the hardest to translate. Performance on most POS tags improves with overall system performance, but a few are not thus correlated (their identity changes from language to language). Preliminary experiments with summarization reveal similar trends.   
   
 pdf  bib  abs   
   The Impact of Familiarity on Naming Variation: A Study on Object Naming in M  andarin C  hinese    
  Yunke He  | Xixian Liao  | Jialing Liang  | Gemma Boleda    
 Different speakers often produce different names for the same object or entity (e.g., “woman” vs. “tourist” for a female tourist). The reasons behind variation in naming are not well understood. We create a Language and Vision dataset for Mandarin Chinese that provides an average of 20 names for 1319 naturalistic images, and investigate how familiarity with a given kind of object relates to the degree of naming variation it triggers across subjects. We propose that familiarity influences naming variation in two competing ways: increasing familiarity can either expand vocabulary, leading to higher variation, or promote convergence on conventional names, thereby reducing variation. We find evidence for both factors being at play. Our study illustrates how computational resources can be used to address research questions in Cognitive Science.   
   
 pdf  bib  abs   
     PSST  ! Prosodic Speech Segmentation with Transformers    
  Nathan Roll  | Calbert Graham  | Simon Todd    
 We develop and probe a model for detecting the boundaries of prosodic chunks in untranscribed conversational English speech. The model is obtained by fine-tuning a Transformer-based speech-to-text (STT) model to integrate the identification of Intonation Unit (IU) boundaries with the STT task. The model shows robust performance, both on held-out data and on out-of-distribution data representing different dialects and transcription protocols. By evaluating the model on degraded speech data, and comparing it with alternatives, we establish that it relies heavily on lexico-syntactic information inferred from audio, and not solely on acoustic information typically understood to cue prosodic structure. We release our model as both a transcription tool and a baseline for further improvements in prosodic segmentation.   
   
 pdf  bib  abs   
   Alignment via Mutual Information    
  Shinjini Ghosh  | Yoon Kim  | Ramon Fernandez Astudillo  | Tahira Naseem  | Jacob Andreas    
 Many language learning tasks require learners to infer correspondences between data in two modalities. Often, these alignments are many-to-many and context-sensitive. For example, translating into morphologically rich languages requires learning not just how words, but morphemes, should be translated; words and morphemes may have different meanings (or groundings) depending on the context in which they are used. We describe an information-theoretic approach to context-sensitive, many-to-many alignment. Our approach first trains a masked sequence model to place distributions over missing spans in (source, target) sequences. Next, it uses this model to compute pointwise mutual information between source and target spans conditional on context. Finally, it aligns spans with high mutual information. We apply this approach to two learning problems: character-based word translation (using alignments for joint morphological segmentation and lexicon learning) and visually grounded reference resolution (using alignments to jointly localize referents and learn word meanings). In both cases, our proposed approach outperforms both structured and neural baselines, showing that conditional mutual information offers an effective framework for formalizing alignment problems in general domains.   
   
 pdf  bib  abs   
   Challenging the “One Single Vector per Token” Assumption    
  Mathieu Dehouck    
 In this paper we question the almost universal assumption that in neural networks each token should be represented by a single vector. In fact, it is so natural to use one vector per word that most people do not even consider it as an assumption of their various models. Via a series of experiments on dependency parsing, in which we let each token in a sentence be represented by a sequence of vectors, we show that the “one single vector per token” assumption might be too strong for recurrent neural networks. Indeed, biaffine parsers seem to work better when their encoder accesses its input’s tokens’ representations in several time steps rather than all at once. This seems to indicate that having only one occasion to look at a token through its vector is too strong a constraint for recurrent neural networks and calls for further studies on the way tokens are fed to neural networks.   
   
 pdf  bib  abs   
   Strategies to Improve Low-Resource Agglutinative Languages Morphological Inflection    
  Gulinigeer Abudouwaili  | Wayit Ablez  | Kahaerjiang Abiderexiti  | Aishan Wumaier  | Nian Yi    
 Morphological inflection is a crucial task in the field of morphology and is typically considered a sequence transduction task. In recent years, it has received substantial attention from researchers and made significant progress. Models have achieved impressive performance levels for both high- and low-resource languages. However, when the distribution of instances in the training dataset changes, or novel lemma or feature labels are predicted, the model’s accuracy declines. In agglutinative languages, morphological inflection involves phonological phenomena while generating new words, which can alter the syllable patterns at the boundary between the lemma and the suffixes. This paper proposes four strategies for low-resource agglutinative languages to enhance the model’s generalization ability. Firstly, a convolution module extracts syllable-like units from lemmas, allowing the model to learn syllable features. Secondly, the lemma and feature labels are represented separately in the input, and the position encoding of the feature labels is marked so that the model learns the order between suffixes and labels. Thirdly, the model recognizes the common substrings in lemmas through two special characters and copies them into words. Finally, combined with syllable features, we improve the data augmentation method. A series of experiments show that the proposed model in this paper is superior to other baseline models.   
   
 pdf  bib  abs   
   Exploring Transformers as Compact, Data-efficient Language Models    
  Clayton Fields  | Casey Kennington    
 Large scale transformer models, trained with massive datasets have become the standard in natural language processing. The huge size of most transformers make research with these models impossible for those with limited computational resources. Additionally, the enormous pretraining data requirements of transformers exclude pretraining them with many smaller datasets that might provide enlightening results. In this study, we show that transformers can be significantly reduced in size, with as few as 5.7 million parameters, and still retain most of their downstream capability. Further we show that transformer models can retain comparable results when trained on human-scale datasets, as few as 5 million words of pretraining data. Overall, the results of our study suggest transformers function well as compact, data efficient language models and that complex model compression methods, such as model distillation are not necessarily superior to pretraining reduced size transformer models from scratch.   
   
 pdf  bib  abs   
   Tree-shape Uncertainty for Analyzing the Inherent Branching Bias of Unsupervised Parsing Models    
  Taiga Ishii  | Yusuke Miyao    
 This paper presents the formalization of tree-shape uncertainty that enables us to analyze the inherent branching bias of unsupervised parsing models using raw texts alone. Previous work analyzed the branching bias of unsupervised parsing models by comparing the outputs of trained parsers with gold syntactic trees. However, such approaches do not consider the fact that texts can be generated by different grammars with different syntactic trees, possibly failing to clearly separate the inherent bias of the model and the bias in train data learned by the model. To this end, we formulate tree-shape uncertainty and derive sufficient conditions that can be used for creating texts that are expected to contain no biased information on branching. In the experiment, we show that training parsers on such unbiased texts can effectively detect the branching bias of existing unsupervised parsing models. Such bias may depend only on the algorithm, or it may depend on seemingly unrelated dataset statistics such as sequence length and vocabulary size.   
   
 pdf  bib  abs   
   Future Lens: Anticipating Subsequent Tokens from a Single Hidden State    
  Koyena Pal  | Jiuding Sun  | Andrew Yuan  | Byron Wallace  | David Bau    
 We conjecture that hidden state vectors corresponding to individual input tokens encode information sufficient to accurately predict several tokens ahead. More concretely, in this paper we ask: Given a hidden (internal) representation of a single token at position t in an input, can we reliably anticipate the tokens that will appear at positions ≥ t + 2? To test this, we measure linear approximation and causal intervention methods in GPT-J-6B to evaluate the degree to which individual hidden states in the network contain signal rich enough to predict future hidden states and, ultimately, token outputs. We find that, at some layers, we can approximate a model’s output with more than 48% accuracy with respect to its prediction of subsequent tokens through a single hidden state. Finally we present a “Future Lens” visualization that uses these methods to create a new view of transformer states.   
   
 pdf  bib  abs   
   Cross-Document Event Coreference Resolution: Instruct Humans or Instruct GPT  ?    
  Jin Zhao  | Nianwen Xue  | Bonan Min    
 This paper explores utilizing Large Language Models (LLMs) to perform Cross-Document Event Coreference Resolution (CDEC) annotations and evaluates how they fare against human annotators with different levels of training. Specifically, we formulate CDEC as a multi-category classification problem on pairs of events that are represented as decontextualized sentences, and compare the predictions of GPT-4 with the judgment of fully trained annotators and crowdworkers on the same data set. Our study indicates that GPT-4 with zero-shot learning outperformed crowd-workers by a large margin and exhibits a level of performance comparable to trained annotators. Upon closer analysis, GPT-4 also exhibits tendencies of being overly confident, and force annotation decisions even when such decisions are not warranted due to insufficient information. Our results have implications on how to perform complicated annotations such as CDEC in the age of LLMs, and show that the best way to acquire such annotations might be to combine the strengths of LLMs and trained human annotators in the annotation process, and using untrained or undertrained crowdworkers is no longer a viable option to acquire high-quality data to advance the state of the art for such problems.   
   
 pdf  bib  abs   
     Implications of Annotation Artifacts in Edge Probing Test Datasets    
  Sagnik Ray Choudhury  | Jushaan Kalra    
 Edge probing tests are classification tasks that test for grammatical knowledge encoded in token representations coming from contextual encoders such as large language models (LLMs). Many LLM encoders have shown high performance in EP tests, leading to conjectures about their ability to encode linguistic knowledge. However, a large body of research claims that the tests necessarily do not measure the LLM’s capacity to encode knowledge, but rather reflect the classifiers’ ability to learn the problem. Much of this criticism stems from the fact that often the classifiers have very similar accuracy when an LLM vs a random encoder is used. Consequently, several modifications to the tests have been suggested, including information theoretic probes. We show that commonly used edge probing test datasets have various biases including memorization. When these biases are removed, the LLM encoders do show a significant difference from the random ones, even with the simple non-information theoretic probes.   
   
 pdf  bib  abs   
     REFER  : An End-to-end Rationale Extraction Framework for Explanation Regularization    
  Mohammad Reza Ghasemi Madani  | Pasquale Minervini    
 Human-annotated textual explanations are becoming increasingly important in Explainable Natural Language Processing. Rationale extraction aims to provide faithful (i.e. reflective of the behavior of the model) and plausible (i.e. convincing to humans) explanations by highlighting the inputs that had the largest impact on the prediction without compromising the performance of the task model. In recent works, the focus of training rationale extractors was primarily on optimizing for plausibility using human highlights, while the task model was trained on jointly optimizing for task predictive accuracy and faithfulness. We propose REFER, a framework that employs a differentiable rationale extractor that allows to back-propagate through the rationale extraction process. We analyze the impact of using human highlights during training by jointly training the task model and the rationale extractor. In our experiments, REFER yields significantly better results in terms of faithfulness, plausibility, and downstream task accuracy on both in-distribution and out-of-distribution data. On both e-SNLI and CoS-E, our best setting produces better results in terms of composite normalized relative gain than the previous baselines by 11% and 3%, respectively.   

    ACL materials are Copyright © 1963–2024 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License  . Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a Creative Commons Attribution 4.0 International License  .  
 The ACL Anthology is managed and built by the ACL Anthology team  of volunteers.  
 Site last built on 29 November 2024 at 02:48 UTC with commit ff763a8  .

83. CoNLL_1 conference:


84. FAST_0 conference:
usenix_logo_notag_white                         Sign In 
  Conferences 

   Attend | Registration Information 
  Registration Discounts 
    Grant Opportunities 
  Venue, Hotel, and Travel 
  Program | Technical Sessions 
  Activities 
    Poster Session and Reception 
  Work-in-Progress Reports (WiPs) 
  Participate | Call for Papers 
  Double-Blind Guidance 
  Author Response Advice 
    Call for Posters and WiPs 
  Instructions for Presenters 
  Sponsors | Exhibitor Services 
  About | Past Conferences 
  Conference Organizers 
    Conference Policies 
  Code of Conduct 
  Questions 

 FAST '23 Call for Papers  

 Sponsored by USENIX  in cooperation with ACM SIGOPS.   
 The 21st USENIX Conference on File and Storage Technologies (FAST '23)  will take place on February 21–23, 2023, at the Hyatt Regency Santa Clara in Santa Clara, CA, USA.  
 Important Dates  
 Paper submissions due: | Thursday, September 22, 2022, 11:59 pm PDT 
  Author response period begins: | Monday, November 28, 2022 
  Author response period ends: | Thursday, December 1, 2022, 11:59 pm PST 
  Notification to authors: | Friday, December 9, 2022 
  Final paper files due: | Tuesday, January 24, 2023 
  Download Call for Papers PDF    
 Conference Organizers  

 Program Co-Chairs   
 Ashvin Goel, University of Toronto    

 Dalit Naor, The Academic College of Tel Aviv–Yaffo    

 Program Committee   
 Nitin Agrawal, Google    

 Deniz Altinbüken, Google Research    

 Lakshmi N. Bairavasundaram, VMware, Inc.    

 Randal Burns, Johns Hopkins University    

 Ali R. Butt, Virginia Tech    

 Rong Chen, Shanghai Jiao Tong University    

 Sangyeun Cho, Samsung Electronics Co.    

 Young-ri Choi, UNIST (Ulsan National Institute of Science and Technology)​    

 Alex Conway, VMware Research    

 Peter Desnoyers, Northeastern University and Red Hat    

 Yu Hua, Huazhong University of Science and Technology    

 Sudarsun Kannan, Rutgers University    

 Sanidhya Kashyap, EPFL    

 Kimberly Keeton, Google    

 Geoff Kuenning, Harvey Mudd College    

 Patrick P. C. Lee, The Chinese University of Hong Kong    

 Youyou Lu, Tsinghua University    

 Xiaosong Ma, Qatar Computer Research Institute, HBKU    

 Peter Macko, MongoDB    

 Ethan Miller, University of California, Santa Cruz, and Pure Storage    

 Hyungon Moon, UNIST (Ulsan National Institute of Science and Technology)    

 Adam Morrison, Tel Aviv University    

 Beomseok Nam, Sungkyunkwan University (SKKU)    

 Sam H. Noh, UNIST (Ulsan National Institute of Science and Technology) and Virginia Tech    

 Raju Rangaswami, Florida International University    

 Rob Ross, Argonne National Laboratory    

 Jiri Schindler, Tranquil Data    

 Philip Shilane, Dell Technologies    

 Liuba Shrira, Brandeis University    

 Keith A. Smith, MongoDB    

 Haris Volos, University of Cyprus    

 Carl Waldspurger, Carl Waldspurger Consulting    

 Avani Wildani, Emory University    

 Youjip Won, Korea Advanced Institute of Science and Technology (KAIST)    

 Gala Yadgar, Technion—Israel Institute of Technology    

 Work-in-Progress/Posters Co-Chairs   
 Ram Alagappan, University of Illinois at Urbana–Champaign    

 Aishwarya Ganesan, University of Illinois at Urbana–Champaign    

 Test of Time Awards Committee   
 Nitin Agrawal, Google    

 Jiri Schindler, Tranquil Data    

 Steering Committee   
 Nitin Agrawal, Google    

 Marcos K. Aguilera, VMware Research    

 Casey Henderson, USENIX Association    

 Dean Hildebrand, Google    

 Kimberly Keeton, Google    

 Geoff Kuenning, Harvey Mudd College    

 Arif Merchant, Google    

 Sam H. Noh, UNIST (Ulsan National Institute of Science and Technology) and Virginia Tech    

 Don Porter, The University of North Carolina at Chapel Hill    

 Raju Rangaswami, Florida International University    

 Erik Riedel   

 Jiri Schindler, Tranquil Data    

 Bianca Schroeder, University of Toronto    

 Keith A. Smith, MongoDB    

 Eno Thereska, Alcion    

 Carl Waldspurger, Carl Waldspurger Consulting    

 Hakim Weatherspoon, Cornell University    

 Brent Welch, Google    

 Ric Wheeler, Facebook    

 Gala Yadgar, Technion—Israel Institute of Technology    

 Erez Zadok, Stony Brook University    

 Overview  
 The 21st USENIX Conference on File and Storage Technologies (FAST '23) brings together storage-system researchers and practitioners to explore new directions in the design, implementation, evaluation, and deployment of storage systems. The program committee interprets "storage systems" broadly: submissions on low-level storage devices, distributed storage systems, and information management are all of interest. The conference will consist of technical presentations including refereed papers, and poster sessions.  
 Topics  
 Topics of interest to FAST should include files and/or storage, and may overlap with other topics including, but not limited to:  
 Archival systems 
  Auditing and provenance 
  Big data, analytics, and data sciences 
  Caching, replication, and consistency 
  Cloud, multi- and hybrid-cloud environments 
  Data deduplication 
  Database storage 
  Distributed and networked storage (wide-area, grid, peer-to-peer) 
  Emerging memory hierarchy design 
  Empirical evaluation 
  Experience with deployed systems 
  File system design 
  HPC systems (including parallel I/O) 
  Key-value and NoSQL storage 
  Management 
  Memory-only storage systems 
  Mobile, personal, embedded, and home storage 
  Networking 
  Novel and emerging storage technologies (e.g., byte-addressable NVM, flash, SMR, IMR, DNA storage, glass) 
  Performance and QoS 
  Power-aware storage architectures 
  RAID and erasure coding 
  Reliability, availability, and disaster tolerance 
  Search and data retrieval 
  Security 
  In evaluating the fit of a paper for FAST, a key ingredient is the design of storage software. A paper with only hardware-level contributions will be out-of-scope; a paper could be brought into scope for FAST by demonstrating for example how software can leverage novel hardware.  
 Submission Instructions  
 Please submit your paper by 11:59 pm PDT on September 22, 2022, in PDF format via the submission form  . Do not email submissions. There is no separate deadline for abstract submissions.  
 The complete submission must be no longer than 12 pages excluding references. | There is no short-paper category. | The program committee values conciseness: if you can express an idea in fewer pages than the limit, do so. Supplemental material may be added as a single separate file without page limits. However, the reviewers are not required to read or consider such material. Content that should be considered to judge the paper is not supplemental and counts toward the page limit. 
  Papers must be typeset on U.S. letter-sized pages in two columns using 10-point Times Roman font on 12-point leading (single-spaced), within a text block | 7" wide by 9" deep | . 
  Labels, captions, and other text in figures, graphs, and tables must use font sizes that, when printed, do not require magnification to be legible. References must not be set in a smaller font. Submissions that violate these requirements will not be reviewed. Limits will be interpreted strictly. No extensions will be given for reformatting. 
  A LaTeX template and style file are available on the | USENIX templates page | . 
  Double-blind policy: | Authors must not be identified in the submissions, either explicitly or by implication. To refer to your previous work, consider it as written by a third party. Do not say "reference removed for blind review." Supplemental material must be anonymized. Submissions violating anonymization rules will not be considered for review. If you are uncertain about how to anonymize your submission, please contact the program co-chairs, | fast23chairs@usenix.org | , well in advance of the submission deadline. 
  Prior Workshop Paper Policy: | If a submission extends a prior workshop paper, please include an anonymized copy of the workshop paper in the submission field. This should be the same as the published version, with any identifying information removed. 
  Simultaneous submission of the same work to multiple venues, submission of previously published work, or plagiarism constitutes dishonesty or fraud. USENIX, like other scientific and technical conferences and journals, prohibits these practices and may take action against authors who have committed them. See the | USENIX Conference Submissions Policy | for details. 
  If you are uncertain whether your submission meets USENIX's guidelines, contact the program co-chairs, | fast23chairs@usenix.org | , or the USENIX office, | submissionspolicy@usenix.org | . 
  Papers accompanied by nondisclosure agreement forms will not be considered. 
  Submissions should abide by the Conflict Identification guidelines (see below). 
  The program committee and external reviewers will judge papers on technical merit, significance, relevance, and presentation. Research papers on new and unexplored problems are encouraged. A good research paper:  
 addresses a significant problem; 
  presents an interesting, compelling solution; 
  demonstrates the benefits and drawbacks of the solution; 
  draws appropriate conclusions using sound experimental methods; 
  clearly describes what the authors have done; and 
  clearly articulates the advances beyond previous work. 
  Program committee members, USENIX, and the broader community generally value a paper more highly if it clearly defines and is accompanied by artifacts not previously available. These artifacts may include traces, original data, source code, or tools developed as part of the submitted work.  
 Blind reviewing of all papers will be done by the program committee, assisted by outside referees when necessary. Accepted papers will be shepherded by a member of the program committee.  
  Deployed-Systems Papers  
 In addition to papers that describe original research, FAST '23 also solicits papers that describe real operational systems, including systems currently in production. Such papers should address experience with the practical design, implementation, analysis, deployment, or operation of such systems. We encourage submission of papers that disprove or strengthen existing assumptions, deepen the understanding of existing problems, and validate known techniques in environments in which they were never before used or tested, with preference given to experimental results based on production data. Deployed-system papers will be treated similarly to other papers for publication purposes; they need not present new ideas or results to be accepted, but should offer useful guidance to practitioners.  
 A good deployed-system paper:  
 clearly articulates lessons learned from deploying in production; 
  describes an operational system of broad interest; 
  discusses practical problems encountered in production; and 
  supports the lessons with appropriate evidence, potentially including statistical data from the deployment, empirical evaluation of the system, and anecdotes. 
  For deployed systems papers, the title should be prefixed with "Deployed System: "  , followed by the title. Authors must also indicate in the submission form that they are submitting a deployed-system paper.  
 Double-blind Policy for Deployed-system Paper:  All submissions for FAST '23 are required to follow the double-blind policy (see above). However, for only deployed-system papers, the product or company described in the paper need not be anonymized (authors still need to be anonymized).  
 Author Response Period  
 FAST '23 will allow authors to respond to reviews prior to final decision, according to the schedule above. Authors must limit their response to correcting factual errors in the reviews, to addressing questions posed by reviewers, and to clarifying the ideas in the paper. Responses may include new experiments and data in response to a reviewer request. Responses are optional and limited to 1000 words. This is a soft limit—you may write a longer response, but the reviewers are not required to read past this limit; you may include a pdf only if you add a diagram or a figure.  
 Conflict Identification  
 Upon submitting your paper, authors must indicate conflicts with PC members. A conflict exists in one of the following cases:  
 Institution:  You are currently employed at the same institution, have been previously employed at the same institution within the past two years, or are going to begin employment at the same institution. A completed internship does not constitute an institutional conflict.  
 Advisor/Advisee:  Doctoral thesis advisor and post-doctoral advisor (if relevant) are conflicts for life.  
 Collaboration:  You have a collaboration on a project, publication, grant proposal, or editorship within the past two years.  
 Close friends and family:  Close family relations (e.g., spouse, parent/child, sibling) and close friends are conflicts forever, if they are potential reviewers.  
 The PC will review paper conflicts to ensure the integrity of the reviewing process, adding conflicts if necessary. If there is no basis for conflicts indicated by authors, such conflicts will be removed. Do not identify PC members as a conflict solely to avoid having them as reviewers. If you have any questions about conflicts, contact the program co-chairs.  
 Author Notification and Beyond  
 Authors will be notified of paper acceptance or rejection according to the schedule above. If your paper is accepted and you need an invitation letter to apply for a visa to attend the conference, contact conference@usenix.org  as soon as possible. Visa applications can take at least 30 working days to process. Identify yourself as a presenter and include your mailing address in your email.  
 Early Rejection Notification.  This year, we will notify authors of papers that are rejected early in the process, prior to the author response period. The goal is to allow authors of early rejected papers to use reviewer feedback earlier and resubmit to another conference as soon as possible. Early rejected papers will no longer be considered under submission (for the purposes of multiple submission policies) upon receipt of a rejection notification.  
 All papers will be available online to registered attendees no earlier than Thursday, January 26, 2023. If your accepted paper should not be published prior to the event, please notify production@usenix.org  . The papers will be available online to everyone beginning on the first day of the main conference, February 21, 2023. Accepted submissions will be treated as confidential prior to publication on the USENIX FAST '23 website; rejected submissions will be permanently treated as confidential.  
 By submitting a paper, you agree that at least one of the authors will attend the conference to present it. If the conference registration fee will pose a hardship for the presenter of the accepted paper, please contact conference@usenix.org  .  
 SUBMIT YOUR WORK    

 Attend | Registration Information 
  Registration Discounts 
  Grant Opportunities 
  Venue, Hotel, and Travel 
  Program | Technical Sessions 
  Activities 
  Poster Session and Reception 
  Work-in-Progress Reports (WiPs) 
  Participate | Call for Papers 
  Double-Blind Guidance 
  Author Response Advice 
  Call for Posters and WiPs 
  Instructions for Presenters 
  Sponsors | Exhibitor Services 
  About | Past Conferences 
  Conference Organizers 
  Conference Policies 
  Code of Conduct 
  Questions 

  Twitter    Facebook    Youtube     

 Privacy Policy 
  Contact Us 

 © USENIX 2024

85. FedCSIS_0 conference:
By using this website, you consent to us using cookies as described in this policy  OK   
   
 Toggle navigation          
 Invitation 
  FedCSIS HOMEPAGE 
  Rough Set School 
  Travelling | Conference venue 
  Social events 
  About Warsaw 
  Airport transfers 
  Accommodation 
  General information 

     FedCSIS 2023  
  
  18th Conference on Computer Science and Intelligence Systems   
   
  Warsaw, Poland, 17-20 September 2023  

 FedCSIS 2023  
  
  18th Conference on Computer Science and Intelligence Systems   
   
  Warsaw, Poland, 17-20 September 2023  

 FedCSIS 2023  
  
  18th Conference on Computer Science and Intelligence Systems   
   
  Warsaw, Poland, 17-20 September 2023  

 FedCSIS 2023  
  
  18th Conference on Computer Science and Intelligence Systems   
   
  Warsaw, Poland, 17-20 September 2023  

 FedCSIS: REGISTRATION & PAYMENT    
   
 To complete your registration and make a payment for the conference you must follow the steps below:     
   
 Create your account on Registration    bookmark. 
  Log in    and book services on Payment   bookmark 
  Finalise payment (registration fee & other orders) 
  After making a payment you will receive an invoice by an email. 
  Available methods of payments: bank transfer or online payment (Przelewy24)    
 For any registration and payment queries please contact us writing an email to: fedcsis2023@jordan.pl    
  
 FedCSIS: CONFERENCE FEES     
  
 All registration fees (excluding the companion fee) include the publication of one paper. More than one paper can be published by one registered participant, for an extra fee (see below).   

 Early registration    
 payment   before August 18, 2023 | Late registration    
 payment  after August 18, 2023 
 Regular fee | 600€ / $650 | 700€ / $750 
 IEEE and  PTI   member fee | 550€ / $585 | 650€ / $690 
 Student fee | 450€ / $480 | 550€ / $585 
 Accompanying person fee     
 (paper publication NOT included) | 500€ / $550 | 600€ / $650 

 The conference fee includes:   
 Publication of a single paper (except the accompanying person fee) 
  Lunches 
  Coffee breaks 
  Social events on Sunday (17.09) and on Monday (18.09) 
  Conference Banquet on Tuesday (19.09) 
  Conference materials 

 Additional fees:   
 Extra page:  150€ / $160 | Limit: 2 extra pages for regular, communication, and position papers. 
  Extra pages cannot be bought for short papers. 
  Extra paper  : 250€ / $270 

 FedCSIS: DISCOUNTS & CONDITIONS    
 A limited number of grants are available for researchers affiliated to Ukrainian Academic Institutions. Researchers in this situation should contact us at | secretariat@fedcsis.org 
  Travel/accommodation expenses are not covered / included! 
  There are no discounts for 2nd, 3rd and consequtive authors of accepted papers. 
  Cancellations of the registration received (in writing, to the | secretariat@fedcsis.org | email address) on, or | before, August 15, 2023 | , are entitled to receive a 70-percent refund. 
  Cancellations received | after August 15, 2023 | are not entitled to a refund. 
  FedCSIS conference | strictly adheres | to the IEEE no-show policy. Papers not presented at the conference will not be included in the Conference Proceedings / Position Papers volumes. 
  All money transfer costs imposed by the bank of the payee | must | be covered by the participant (in case when the full payment is not received, supplemental payment will be requested and required). 
   
 LINK to the FedCSIS 2023   HOMEPAGE    

   Organizing Committee    
 queries regarding:    
  conference and finacial details     

 Executive Officer     
 Katarzyna Wasielewska-Michniewska,     
  Systems Research Institute,    
 Polish Academy of Sciences, Warsaw, Poland    
 Contact  :   executive.officer@fedcsis.org    
 Financial Chair:     financial.officer@fedcsis.org    
 Website:  https://fedcsis.org/    

 Get connected:    
 Join FedCSIS on:     

 Professional Congress Organizer    
 queries regarding:  
  registration & payment process, transfers & accommodation support    

 JORDAN Congress Bureau    
 22/2 Sobieskiego St.  31-136 Kraków     
 Ph:  +48 12 341 46 40  , 508 042 215    
 Contact:  fedcsis2023@jordan.pl    
 Website:  https://kongres.jordan.pl/en    

 © 2024 FedCSIS 2023  . Bootstrap HTML Template.

86. FedCSIS_1 conference:
The requested URL was rejected. Please consult with your administrator.  
   
  Your support ID is: < 8203162004105604435>  
   
  [Go Back]

87. CoNLL_2 conference:
Skip to main content         
 CoNLL    

 Menu      
 Main navigation  
 Home 
  Previous editions 
  Previous tasks 
  SIGNLL 
  Contact 
   
 User account menu  Log in 

 CoNLL 2024   

 May 24, 2024   
 CoNLL is a yearly conference organized by SIGNLL  (ACL's Special Interest Group on Natural Language Learning), focusing on theoretically, cognitively and scientifically motivated approaches to computational linguistics. This year, CoNLL will be colocated with EMNLP 2024  . Registrations for CoNLL can be made through EMNLP (workshop 1).  
 Submission page available here  .  
 Papers that have received reviews in current or previous ARR cycles can be committed to CoNLL 2024  here   by August 30, 2024.   
 Accepted papers   
 A list of papers that have been accepted for CoNLL 2024 is available here  .  
 Program   
 The program for CoNLL 2024 is available here  .  
 Call for Papers  
 SIGNLL invites submissions to the 28th Conference on Computational Natural Language Learning (CoNLL 2024). The focus of CoNLL is on theoretically, cognitively and scientifically motivated approaches to computational linguistics, rather than on work driven by particular engineering applications  . Such approaches include:  
 Computational learning theory and other techniques for theoretical analysis of machine learning models for NLP 
  Models of first, second and bilingual language acquisition by humans 
  Models of sign language acquisition, understanding, and production 
  Models of language evolution and change 
  Computational simulation and analysis of findings from psycholinguistic and neurolinguistic experiments 
  Analysis and interpretation of NLP models, using methods inspired by cognitive science or linguistics or other methods 
  Data resources, techniques and tools for scientifically-oriented research in computational linguistics 
  Connections between computational models and formal languages or linguistic theories 
  Linguistic typology, translation, and other multilingual work 
  Theoretically, cognitively and scientifically motivated approaches to text generation 
  We welcome work targeting any aspect of language, including:  
 Speech and phonology 
  Syntax and morphology 
  Lexical, compositional and discourse semantics 
  Dialogue and interactive language use 
  Sociolinguistics 
  Multimodal and grounded language learning 
  We do not restrict the topic of submissions to fall into this list. However, the submissions’ relevance to the conference’s focus on theoretically, cognitively and scientifically motivated approaches  will play an important role in the review process.  
 Submitted papers must be anonymous  and use the EMNLP 2024 template  . Submitted papers may consist of up to 8 pages  of content plus unlimited space for references. Authors of accepted papers will have an additional page to address reviewers’ comments in the camera-ready version (9 pages of content in total, excluding references). Optional anonymized supplementary materials and a PDF appendix  are allowed. The appendix should be submitted as a separate PDF file (reviewers are not required to consider the materials in the appendix so it should not include any essential content to the understanding of the paper). Please refer to the EMNLP 2024 Call for Papers  for more details on the submission format. Note that, unlike EMNLP, we do not mandate that papers have a discussion section of the limitations of the work. However, we strongly encourage authors to have such a section in the appendix.  
 Please submit via Open Review  . CoNLL 2024 will accept ARR submission depending on the full review to be completed by Jul 1, 2024  . Please note that CoNLL 2024 is an in-person conference. We expect all accepted papers to be presented physically and presenting authors must register through EMNLP (workshop).</p>  
 Timeline   
  (All deadlines are 11:59pm UTC-12h, AoE)  
  Submission deadline: Monday July 1, 2024  (EXTENDED) Sunday, July 7, 2024  
  ARR Commitment deadline: Friday, August 30, 2024  
  Notification of acceptance: Friday, September 20  (DELAYED), Tuesday, September 24, 2024  
  Camera ready papers due: Friday, October 11, 2024  
  Conference: November 15 - 16, 2024  
 Venue   
  CoNLL 2024 will be held in-person, along with EMNLP  in Miami, Florida  .  
 Multiple submission policy   
  CoNLL 2024 will refuse papers that are currently under submission, or that will be submitted to other meetings or publications, including EMNLP. Papers submitted elsewhere and papers that overlap significantly in content or results with papers that will be (or have been) published elsewhere will be rejected. Authors submitting more than one paper to CoNLL 2024 must ensure that the submissions do not overlap significantly (>25%) with each other in content or results.  
 Information About Travel Visas   
  If you will be requiring travel visas to Miami, Florida, please fill out this form: Travel Visa Form   
 This has been prepared by the EMNLP organizers to facilitate the process of acquiring visas. If visas are needed, your information should be provided as early as possible. If you have more questions, please contact Mark Finlayson and Zoey Liu, who are the local chairs here: EMNLP Organizers   
 CoNLL 2024 Chairs and Organizers  
 The conference's co-chairs are:   
 Malihe Alikhani  (Northeastern University, MA, USA)  
   
 Libby Barak  (Montclair State university, NJ, USA)  
   
  Publication chairs:   
 Mert Inan  (Northeastern University, MA, USA)  
   
  Julia Watson  (University of Toronto, ON, Canada)  
   
 SIGNLL   
 SIGNLL President: | Omri Abend | ( | Hebrew University of Jerusalem, Israel) 
  SIGNLL Secretary: | Antske Fokkens | ( | Vrije Universiteit Amsterdam, Netherlands | ) 
  Invited speakers  
   
 Thamar Solorio  (Mohamed bin Zayed University of Artificial Intelligence, MBZUAI)  
 Title:  Towards AI models that can help us to become better global social beings  
 Abstract:  Cultural norms and values fundamentally shape our social interactions. Communication within any society reflects these cultural contexts. For example, while direct eye contact is often seen as a sign of confidence in many Western cultures, it may be viewed as disrespectful in other parts of the world. Moreover, human-human interactions include so much more than just the words we utter; nonverbal communication, including body language and other cues, provides rich signals to those around us.   
 As vision language models (VLMs) are increasingly integrated into user-facing applications, it is becoming relevant to wonder if and to what extent this technology can robustly process these signals. My research group is interested in developing evaluation frameworks to assess the abilities of VLMs concerning interpreting social cues and in developing new approaches that can assist us and, perhaps, enhance our cross-cultural human-human interactions.   
  
 Bio:  Thamar Solorio is a professor in the NLP department at MBZUAI. She is also a tenured professor of Computer Science at the University of Houston. She is the director and founder of the RiTUAL Lab. Her research interests include NLP for low-resource settings and multilingual data, including code-switching and information extraction. More recently, she was moved towards language and vision problems, focusing on developing inclusive NLP. She received a National Science Foundation (NSF) CAREER award for her work on authorship attribution and was awarded the 2014 Emerging Leader ABIE Award in Honor of Denice Denton. She served two terms as an elected board member of the North American Chapter of the Association of Computational Linguistics (NAACL) and was PC co-chair for NAACL 2019. She is an Editor in Chief for the ACL Rolling Review (ARR) initiative and was a member of the advisory board for ARR. She serves as general chair for the 2024 Conference on Empirical Methods in Natural Language Processing.   

  Lorna Quandt  (Gallaudet University)  
 Title:  Integrating AI-Driven Sign Language Technologies in Education: Recognition, Generation, and Interaction  
 Abstract:  This talk explores integrating AI-driven technologies in sign language research, covering the unique challenges of sign language recognition and generation. Dr. Quandt will explore these cutting-edge considerations through the lens of two research projects, ASL Champ! and BRIDGE. Both projects focus on sign language recognition and generation, which is crucial for advancing interaction in virtual and educational environments. ASL Champ! utilizes a dataset of 3D signs to enhance deep-learning-powered sign recognition in virtual reality. At the same time, BRIDGE extends this work by incorporating both recognition and generation of signs to create a more robust, interactive experience. This dual focus underscores the importance of pursuing recognition and generation in tandem rather than treating them as entirely distinct challenges. By leveraging advances in AI and natural language processing (NLP), we can create technologies that recognize and generate signs and facilitate deeper understanding and use of signed languages. These advancements hold great educational potential, particularly in providing more accessible tools for deaf students and enabling broader instruction in sign language. The talk will also address how these innovations can reshape the NLP field by widening the focus beyond spoken/written language and into multimodal, signed, and nonverbal aspects of language, which can inform all linguistic research.  
 Bio:  Dr. Lorna Quandt is the Action & Brain Lab director at Gallaudet University in Washington, D.C. She serves as Co-Director of the VL2 Research Center alongside Melissa Malzkuhn. Dr. Quandt is an Associate Professor in the Ph.D. in Educational Neuroscience (PEN) program and the Science Director of the Motion Light Lab. Dr. Quandt founded the Action & Brain lab in early 2016. Before that, Dr. Quandt obtained her BA in Psychology from Haverford College and a PhD in Psychology, specializing in Brain & Cognitive Sciences, from Temple University. She completed a postdoctoral fellowship at the University of Pennsylvania, working with Dr. Anjan Chatterjee. Her research examines how knowledge of sign language changes perception, particularly visuospatial processing. Dr. Quandt is also pursuing the development of research-based educational technology to create new ways to learn signed languages in virtual reality.  
  
  Areas and ACs   
 Computational Psycholinguistics, Cognition and Linguistics: Nathan Schneider 
  Computational Social Science: Kate Atwell 
  Interaction and Grounded Language Learning: Anthony Sicilia 
  Lexical, Compositional and Discourse Semantics: Shira Wein 
  Multilingual Work and Translation: Yuval Marton 
  Natural Language Generation: Tuhin Chakrabarty 
  Resources and Tools for Scientifically Motivated Research: Venkat 
  Speech and Phonology: Huteng Dai 
  Syntax and Morphology: Leshem Choshen 
  Theoretical Analysis and Interpretation of ML Models for NLP: Kevin Small | Sponsor 

 Webmaster: Jens Lemmens   

 RSS feed        

 Powered by Drupal

88. FAST_1 conference:
usenix_logo_notag_white                         Sign In 
  Conferences 

 USENIX supports diversity, equity, and inclusion and condemns hate and discrimination  .  

   Attend | Registration Information 
  Registration Discounts 
    Grant Opportunities 
  Venue, Hotel, and Travel 
  Program | Technical Sessions 
  Activities 
    Poster Session and Reception 
  Work-in-Progress Reports (WiPs) 
  Participate | Call for Papers 
  Double-Blind Guidance 
  Author Response Advice 
    Call for Posters and WiPs 
  Instructions for Presenters 
  Sponsors | Exhibitor Services 
  About | Past Conferences 
  Conference Organizers 
    Conference Policies 
  Code of Conduct 
  Questions 

  21st USENIX Conference on File and Storage Technologies  
   
 February 21–23, 2023   

 Santa Clara, CA, USA   

 Sponsored by USENIX in cooperation with ACM SIGOPS   

   Thanks to those who joined us for the 21st USENIX Conference on File and Storage Technologies (FAST '23). We hope you enjoyed the event.  
 FAST brings together storage-system researchers and practitioners to explore new directions in the design, implementation, evaluation, and deployment of storage systems.  
 As part of our commitment to open access to research, the full proceedings and presentation slides are free and open to the public on the technical sessions page  . Videos are posted within a few weeks of the end of the event.  

 Registration Information  
 Early Bird Registration Deadline: Monday, February 6, 2023.   
 See the Registration Information page  for details.  
 Authors and Speakers  
 Please contact the Conference Department  for registration information.  
 Discounts  
 In addition to our member discounts  , USENIX offers several discounts  to help you to attend FAST '23.  
 Coronavirus/COVID-19 Health and Safety Plan  
 Please review USENIX's Coronavirus/COVID-19 Health and Safety Plan  prior to registering for the event. We appreciate your willingness to help safeguard your fellow event attendees and respect their personal safety choices.  

 USENIX Conference Policies  
 We encourage you to learn more about USENIX's values  and how we put them into practice at our conferences.  
 Accessibility Requests  
 USENIX is committed to ensuring that our meetings are fully accessible to all attendees. Visit our Accessibility information page  to find out about options and how to make a request. To ensure that we meet your needs, please make your request by Friday, February 3, 2023  . We cannot guarantee that we can meet requests received after this date, although we will make every reasonable effort to do so.  
 Refunds and Cancellations  
 The cancellation deadline is Monday, February 13, 2023  . Please review the USENIX Registration Substitution and Cancellation Policy  for more information.  

 Venue  
 Hyatt Regency Santa Clara   
  5101 Great America Parkway  
  Santa Clara, CA, 95054  
  USA  
  +1 408.200.1234  
  +1 800.397.3342  
 Hotel Discount Deadline: Monday, February 6, 2023   
 Special Attendee Room Rate  
 USENIX has negotiated a special conference attendee room rate of US$314 plus tax for single/double occupancy, including in-room wireless internet. To receive this rate, book your room online  or call the hotel and mention USENIX or FAST '23.  
 The group rate is available until February 6, 2023,  or until the block sells out, whichever occurs first. After this date, contact the hotel directly to inquire about room availability.  
 Parking  
 Daily parking is available for $25/day. See the hotel's website for additional parking information and rates  .  

 About FAST '23  
 Conference Policies   
  Code of Conduct   
  View Past Conferences   

 Questions?  
 Review our Conference FAQs  , and send direct queries via email:  
 Registration: conference@usenix.org   
  Membership: membership@usenix.org   
  Sponsorship: sponsorship@usenix.org   
  Student Grants: students@usenix.org   
  Proceedings Papers: production@usenix.org   

 Conference Organizers  

 Ashvin Goel   
 University of Toronto   
 Program Co-Chair   

 Dalit Naor   
 The Academic College of Tel Aviv–Yaffo   
 Program Co-Chair   

 Program Committee   
 Nitin Agrawal, Google    

 Deniz Altinbüken, Google Research    

 Lakshmi N. Bairavasundaram, VMware, Inc.    

 Randal Burns, Johns Hopkins University    

 Ali R. Butt, Virginia Tech    

 Rong Chen, Shanghai Jiao Tong University    

 Sangyeun Cho, Samsung Electronics Co.    

 Young-ri Choi, UNIST (Ulsan National Institute of Science and Technology)​    

 Alex Conway, VMware Research    

 Peter Desnoyers, Northeastern University and Red Hat    

 Yu Hua, Huazhong University of Science and Technology    

 Sudarsun Kannan, Rutgers University    

 Sanidhya Kashyap, EPFL    

 Kimberly Keeton, Google    

 Geoff Kuenning, Harvey Mudd College    

 Patrick P. C. Lee, The Chinese University of Hong Kong    

 Youyou Lu, Tsinghua University    

 Xiaosong Ma, Qatar Computer Research Institute, HBKU    

 Peter Macko, MongoDB    

 Ethan Miller, University of California, Santa Cruz, and Pure Storage    

 Hyungon Moon, UNIST (Ulsan National Institute of Science and Technology)    

 Adam Morrison, Tel Aviv University    

 Beomseok Nam, Sungkyunkwan University (SKKU)    

 Sam H. Noh, UNIST (Ulsan National Institute of Science and Technology) and Virginia Tech    

 Raju Rangaswami, Florida International University    

 Rob Ross, Argonne National Laboratory    

 Jiri Schindler, Tranquil Data    

 Philip Shilane, Dell Technologies    

 Liuba Shrira, Brandeis University    

 Keith A. Smith, MongoDB    

 Haris Volos, University of Cyprus    

 Carl Waldspurger, Carl Waldspurger Consulting    

 Avani Wildani, Emory University    

 Youjip Won, Korea Advanced Institute of Science and Technology (KAIST)    

 Gala Yadgar, Technion—Israel Institute of Technology    

 Work-in-Progress/Posters Co-Chairs   
 Ram Alagappan, University of Illinois at Urbana–Champaign    

 Aishwarya Ganesan, University of Illinois at Urbana–Champaign    

 Test of Time Awards Committee   
 Nitin Agrawal, Google    

 Jiri Schindler, Tranquil Data    

 Steering Committee   
 Nitin Agrawal, Google    

 Marcos K. Aguilera, VMware Research    

 Casey Henderson, USENIX Association    

 Dean Hildebrand, Google    

 Kimberly Keeton, Google    

 Geoff Kuenning, Harvey Mudd College    

 Arif Merchant, Google    

 Sam H. Noh, UNIST (Ulsan National Institute of Science and Technology) and Virginia Tech    

 Don Porter, The University of North Carolina at Chapel Hill    

 Raju Rangaswami, Florida International University    

 Erik Riedel   

 Jiri Schindler, Tranquil Data    

 Bianca Schroeder, University of Toronto    

 Keith A. Smith, MongoDB    

 Eno Thereska, Alcion    

 Carl Waldspurger, Carl Waldspurger Consulting    

 Hakim Weatherspoon, Cornell University    

 Brent Welch, Google    

 Ric Wheeler, Facebook    

 Gala Yadgar, Technion—Israel Institute of Technology    

 Erez Zadok, Stony Brook University    

 Gold Sponsors  

 Silver Sponsor  

 Bronze Sponsors  

 Open Access Sponsor  

 Media Sponsor  

 Conference Sponsorship  
 Become a Sponsor:  Sponsorship exposes your brand to highly qualified attendees, funds our grants program, supports open access to our conference content, and keeps USENIX conferences affordable. USENIX is a 501(c)(3) non-profit organization that relies on sponsor support to fulfill its mission. To learn more, please contact the Sponsorship Department  with the conference name in your subject line.  
 The acceptance of any organization as a sponsor does not imply explicit or implicit approval by USENIX of the donor organization’s values or actions. In addition, sponsorship does not provide any control over conference program content. Questions? Contact the Sponsorship Department  .  

 Attend | Registration Information 
  Registration Discounts 
  Grant Opportunities 
  Venue, Hotel, and Travel 
  Program | Technical Sessions 
  Activities 
  Poster Session and Reception 
  Work-in-Progress Reports (WiPs) 
  Participate | Call for Papers 
  Double-Blind Guidance 
  Author Response Advice 
  Call for Posters and WiPs 
  Instructions for Presenters 
  Sponsors | Exhibitor Services 
  About | Past Conferences 
  Conference Organizers 
  Conference Policies 
  Code of Conduct 
  Questions 

  Twitter    Facebook    Youtube     

 Privacy Policy 
  Contact Us 

 © USENIX 2024

89. CoNLL_3 conference:
Skip to main content         
 CoNLL    

 Menu      
 Main navigation  
 Home 
  Previous editions 
  Previous tasks 
  SIGNLL 
  Contact 
   
 User account menu  Log in 

 Breadcrumb  
 Home 

 Previous shared tasks   

 2023 | BabyLM Challenge | English | Proceedings 
 2020 | Cross-Framework Meaning Representation Parsing | English | Proceedings 
 2019 | Cross-Framework Meaning Representation Parsing | English | Proceedings 
 2018 | Universal Morphological Reinflection | multilingual | Proceedings 
 2018 | Multilingual Parsing from Raw Text to Universal Dependencies | multilingual | Proceedings 
 2017 | Multilingual Parsing from Raw Text to Universal Dependencies | multilingual | Proceedings 
 2017 | Universal Morphological Reinflection | multilingual | Proceedings 
 2016 | Multilingual Shallow Discourse Parsing | English, Chinese | Proceedings 
 2015 | Shallow Discourse Parsing | English | Proceedings 
 2014 | Grammatical Error Correction | English | Proceedings 
 2013 | Grammatical Error Correction | English | Proceedings 
 2012 | Modelling Multilingual Unrestricted Coreference in OntoNotes | English, Chinese, Arabic | Proceedings 
 2011 | Modelling Unrestricted Coreference in OntoNotes | English | Proceedings 
 2010 | Hedge Detection | English | Proceedings 
 2009 | Syntactic and Semantic Dependencies in Multiple Languages | multilingual | Proceedings 
 2008 | Joint Parsing of Syntactic and Semantic Dependencies | English | Proceedings 
 2007 | Dependency Parsing: Multilingual & Domain Adaptation | multilingual |  
 2006 | Multi-Lingual Dependency Parsing | multilingual |  
 2005 | Semantic Role Labeling | English |  
 2004 | Semantic Role Labeling | English |  
 2003 | Language-Independent Named Entity Recognition | English, German |  
 2002 | Language-Independent Named Entity Recognition | Spanish, Dutch |  
 2001 | Clause Identification | English |  
 2000 | Chunking | English |  
 1999 | NP Bracketing | English |  

 Webmaster: Jens Lemmens   

 RSS feed        

 Powered by Drupal

90. FAST_2 conference:
usenix_logo_notag_white                         Sign In 
  Conferences 

   Attend | Registration Information 
  Registration Discounts 
    Grant Opportunities 
  Venue, Hotel, and Travel 
  Program | Technical Sessions 
  Activities 
    Poster Session and Reception 
  Work-in-Progress Reports (WiPs) 
  Participate | Call for Papers 
  Double-Blind Guidance 
  Author Response Advice 
    Call for Posters and WiPs 
  Instructions for Presenters 
  Sponsors | Exhibitor Services 
  About | Past Conferences 
  Conference Organizers 
    Conference Policies 
  Code of Conduct 
  Questions 

 FAST '23 Call for Papers  

 Sponsored by USENIX  in cooperation with ACM SIGOPS.   
 The 21st USENIX Conference on File and Storage Technologies (FAST '23)  will take place on February 21–23, 2023, at the Hyatt Regency Santa Clara in Santa Clara, CA, USA.  
 Important Dates  
 Paper submissions due: | Thursday, September 22, 2022, 11:59 pm PDT 
  Author response period begins: | Monday, November 28, 2022 
  Author response period ends: | Thursday, December 1, 2022, 11:59 pm PST 
  Notification to authors: | Friday, December 9, 2022 
  Final paper files due: | Tuesday, January 24, 2023 
  Download Call for Papers PDF    
 Conference Organizers  

 Program Co-Chairs   
 Ashvin Goel, University of Toronto    

 Dalit Naor, The Academic College of Tel Aviv–Yaffo    

 Program Committee   
 Nitin Agrawal, Google    

 Deniz Altinbüken, Google Research    

 Lakshmi N. Bairavasundaram, VMware, Inc.    

 Randal Burns, Johns Hopkins University    

 Ali R. Butt, Virginia Tech    

 Rong Chen, Shanghai Jiao Tong University    

 Sangyeun Cho, Samsung Electronics Co.    

 Young-ri Choi, UNIST (Ulsan National Institute of Science and Technology)​    

 Alex Conway, VMware Research    

 Peter Desnoyers, Northeastern University and Red Hat    

 Yu Hua, Huazhong University of Science and Technology    

 Sudarsun Kannan, Rutgers University    

 Sanidhya Kashyap, EPFL    

 Kimberly Keeton, Google    

 Geoff Kuenning, Harvey Mudd College    

 Patrick P. C. Lee, The Chinese University of Hong Kong    

 Youyou Lu, Tsinghua University    

 Xiaosong Ma, Qatar Computer Research Institute, HBKU    

 Peter Macko, MongoDB    

 Ethan Miller, University of California, Santa Cruz, and Pure Storage    

 Hyungon Moon, UNIST (Ulsan National Institute of Science and Technology)    

 Adam Morrison, Tel Aviv University    

 Beomseok Nam, Sungkyunkwan University (SKKU)    

 Sam H. Noh, UNIST (Ulsan National Institute of Science and Technology) and Virginia Tech    

 Raju Rangaswami, Florida International University    

 Rob Ross, Argonne National Laboratory    

 Jiri Schindler, Tranquil Data    

 Philip Shilane, Dell Technologies    

 Liuba Shrira, Brandeis University    

 Keith A. Smith, MongoDB    

 Haris Volos, University of Cyprus    

 Carl Waldspurger, Carl Waldspurger Consulting    

 Avani Wildani, Emory University    

 Youjip Won, Korea Advanced Institute of Science and Technology (KAIST)    

 Gala Yadgar, Technion—Israel Institute of Technology    

 Work-in-Progress/Posters Co-Chairs   
 Ram Alagappan, University of Illinois at Urbana–Champaign    

 Aishwarya Ganesan, University of Illinois at Urbana–Champaign    

 Test of Time Awards Committee   
 Nitin Agrawal, Google    

 Jiri Schindler, Tranquil Data    

 Steering Committee   
 Nitin Agrawal, Google    

 Marcos K. Aguilera, VMware Research    

 Casey Henderson, USENIX Association    

 Dean Hildebrand, Google    

 Kimberly Keeton, Google    

 Geoff Kuenning, Harvey Mudd College    

 Arif Merchant, Google    

 Sam H. Noh, UNIST (Ulsan National Institute of Science and Technology) and Virginia Tech    

 Don Porter, The University of North Carolina at Chapel Hill    

 Raju Rangaswami, Florida International University    

 Erik Riedel   

 Jiri Schindler, Tranquil Data    

 Bianca Schroeder, University of Toronto    

 Keith A. Smith, MongoDB    

 Eno Thereska, Alcion    

 Carl Waldspurger, Carl Waldspurger Consulting    

 Hakim Weatherspoon, Cornell University    

 Brent Welch, Google    

 Ric Wheeler, Facebook    

 Gala Yadgar, Technion—Israel Institute of Technology    

 Erez Zadok, Stony Brook University    

 Overview  
 The 21st USENIX Conference on File and Storage Technologies (FAST '23) brings together storage-system researchers and practitioners to explore new directions in the design, implementation, evaluation, and deployment of storage systems. The program committee interprets "storage systems" broadly: submissions on low-level storage devices, distributed storage systems, and information management are all of interest. The conference will consist of technical presentations including refereed papers, and poster sessions.  
 Topics  
 Topics of interest to FAST should include files and/or storage, and may overlap with other topics including, but not limited to:  
 Archival systems 
  Auditing and provenance 
  Big data, analytics, and data sciences 
  Caching, replication, and consistency 
  Cloud, multi- and hybrid-cloud environments 
  Data deduplication 
  Database storage 
  Distributed and networked storage (wide-area, grid, peer-to-peer) 
  Emerging memory hierarchy design 
  Empirical evaluation 
  Experience with deployed systems 
  File system design 
  HPC systems (including parallel I/O) 
  Key-value and NoSQL storage 
  Management 
  Memory-only storage systems 
  Mobile, personal, embedded, and home storage 
  Networking 
  Novel and emerging storage technologies (e.g., byte-addressable NVM, flash, SMR, IMR, DNA storage, glass) 
  Performance and QoS 
  Power-aware storage architectures 
  RAID and erasure coding 
  Reliability, availability, and disaster tolerance 
  Search and data retrieval 
  Security 
  In evaluating the fit of a paper for FAST, a key ingredient is the design of storage software. A paper with only hardware-level contributions will be out-of-scope; a paper could be brought into scope for FAST by demonstrating for example how software can leverage novel hardware.  
 Submission Instructions  
 Please submit your paper by 11:59 pm PDT on September 22, 2022, in PDF format via the submission form  . Do not email submissions. There is no separate deadline for abstract submissions.  
 The complete submission must be no longer than 12 pages excluding references. | There is no short-paper category. | The program committee values conciseness: if you can express an idea in fewer pages than the limit, do so. Supplemental material may be added as a single separate file without page limits. However, the reviewers are not required to read or consider such material. Content that should be considered to judge the paper is not supplemental and counts toward the page limit. 
  Papers must be typeset on U.S. letter-sized pages in two columns using 10-point Times Roman font on 12-point leading (single-spaced), within a text block | 7" wide by 9" deep | . 
  Labels, captions, and other text in figures, graphs, and tables must use font sizes that, when printed, do not require magnification to be legible. References must not be set in a smaller font. Submissions that violate these requirements will not be reviewed. Limits will be interpreted strictly. No extensions will be given for reformatting. 
  A LaTeX template and style file are available on the | USENIX templates page | . 
  Double-blind policy: | Authors must not be identified in the submissions, either explicitly or by implication. To refer to your previous work, consider it as written by a third party. Do not say "reference removed for blind review." Supplemental material must be anonymized. Submissions violating anonymization rules will not be considered for review. If you are uncertain about how to anonymize your submission, please contact the program co-chairs, | fast23chairs@usenix.org | , well in advance of the submission deadline. 
  Prior Workshop Paper Policy: | If a submission extends a prior workshop paper, please include an anonymized copy of the workshop paper in the submission field. This should be the same as the published version, with any identifying information removed. 
  Simultaneous submission of the same work to multiple venues, submission of previously published work, or plagiarism constitutes dishonesty or fraud. USENIX, like other scientific and technical conferences and journals, prohibits these practices and may take action against authors who have committed them. See the | USENIX Conference Submissions Policy | for details. 
  If you are uncertain whether your submission meets USENIX's guidelines, contact the program co-chairs, | fast23chairs@usenix.org | , or the USENIX office, | submissionspolicy@usenix.org | . 
  Papers accompanied by nondisclosure agreement forms will not be considered. 
  Submissions should abide by the Conflict Identification guidelines (see below). 
  The program committee and external reviewers will judge papers on technical merit, significance, relevance, and presentation. Research papers on new and unexplored problems are encouraged. A good research paper:  
 addresses a significant problem; 
  presents an interesting, compelling solution; 
  demonstrates the benefits and drawbacks of the solution; 
  draws appropriate conclusions using sound experimental methods; 
  clearly describes what the authors have done; and 
  clearly articulates the advances beyond previous work. 
  Program committee members, USENIX, and the broader community generally value a paper more highly if it clearly defines and is accompanied by artifacts not previously available. These artifacts may include traces, original data, source code, or tools developed as part of the submitted work.  
 Blind reviewing of all papers will be done by the program committee, assisted by outside referees when necessary. Accepted papers will be shepherded by a member of the program committee.  
  Deployed-Systems Papers  
 In addition to papers that describe original research, FAST '23 also solicits papers that describe real operational systems, including systems currently in production. Such papers should address experience with the practical design, implementation, analysis, deployment, or operation of such systems. We encourage submission of papers that disprove or strengthen existing assumptions, deepen the understanding of existing problems, and validate known techniques in environments in which they were never before used or tested, with preference given to experimental results based on production data. Deployed-system papers will be treated similarly to other papers for publication purposes; they need not present new ideas or results to be accepted, but should offer useful guidance to practitioners.  
 A good deployed-system paper:  
 clearly articulates lessons learned from deploying in production; 
  describes an operational system of broad interest; 
  discusses practical problems encountered in production; and 
  supports the lessons with appropriate evidence, potentially including statistical data from the deployment, empirical evaluation of the system, and anecdotes. 
  For deployed systems papers, the title should be prefixed with "Deployed System: "  , followed by the title. Authors must also indicate in the submission form that they are submitting a deployed-system paper.  
 Double-blind Policy for Deployed-system Paper:  All submissions for FAST '23 are required to follow the double-blind policy (see above). However, for only deployed-system papers, the product or company described in the paper need not be anonymized (authors still need to be anonymized).  
 Author Response Period  
 FAST '23 will allow authors to respond to reviews prior to final decision, according to the schedule above. Authors must limit their response to correcting factual errors in the reviews, to addressing questions posed by reviewers, and to clarifying the ideas in the paper. Responses may include new experiments and data in response to a reviewer request. Responses are optional and limited to 1000 words. This is a soft limit—you may write a longer response, but the reviewers are not required to read past this limit; you may include a pdf only if you add a diagram or a figure.  
 Conflict Identification  
 Upon submitting your paper, authors must indicate conflicts with PC members. A conflict exists in one of the following cases:  
 Institution:  You are currently employed at the same institution, have been previously employed at the same institution within the past two years, or are going to begin employment at the same institution. A completed internship does not constitute an institutional conflict.  
 Advisor/Advisee:  Doctoral thesis advisor and post-doctoral advisor (if relevant) are conflicts for life.  
 Collaboration:  You have a collaboration on a project, publication, grant proposal, or editorship within the past two years.  
 Close friends and family:  Close family relations (e.g., spouse, parent/child, sibling) and close friends are conflicts forever, if they are potential reviewers.  
 The PC will review paper conflicts to ensure the integrity of the reviewing process, adding conflicts if necessary. If there is no basis for conflicts indicated by authors, such conflicts will be removed. Do not identify PC members as a conflict solely to avoid having them as reviewers. If you have any questions about conflicts, contact the program co-chairs.  
 Author Notification and Beyond  
 Authors will be notified of paper acceptance or rejection according to the schedule above. If your paper is accepted and you need an invitation letter to apply for a visa to attend the conference, contact conference@usenix.org  as soon as possible. Visa applications can take at least 30 working days to process. Identify yourself as a presenter and include your mailing address in your email.  
 Early Rejection Notification.  This year, we will notify authors of papers that are rejected early in the process, prior to the author response period. The goal is to allow authors of early rejected papers to use reviewer feedback earlier and resubmit to another conference as soon as possible. Early rejected papers will no longer be considered under submission (for the purposes of multiple submission policies) upon receipt of a rejection notification.  
 All papers will be available online to registered attendees no earlier than Thursday, January 26, 2023. If your accepted paper should not be published prior to the event, please notify production@usenix.org  . The papers will be available online to everyone beginning on the first day of the main conference, February 21, 2023. Accepted submissions will be treated as confidential prior to publication on the USENIX FAST '23 website; rejected submissions will be permanently treated as confidential.  
 By submitting a paper, you agree that at least one of the authors will attend the conference to present it. If the conference registration fee will pose a hardship for the presenter of the accepted paper, please contact conference@usenix.org  .  
 SUBMIT YOUR WORK    

 Attend | Registration Information 
  Registration Discounts 
  Grant Opportunities 
  Venue, Hotel, and Travel 
  Program | Technical Sessions 
  Activities 
  Poster Session and Reception 
  Work-in-Progress Reports (WiPs) 
  Participate | Call for Papers 
  Double-Blind Guidance 
  Author Response Advice 
  Call for Posters and WiPs 
  Instructions for Presenters 
  Sponsors | Exhibitor Services 
  About | Past Conferences 
  Conference Organizers 
  Conference Policies 
  Code of Conduct 
  Questions 

  Twitter    Facebook    Youtube     

 Privacy Policy 
  Contact Us 

 © USENIX 2024

91. FedCSIS_2 conference:


92. FAST_3 conference:
usenix_logo_notag_white                         Sign In 
  Conferences 

   Attend | Registration Information 
  Registration Discounts 
    Grant Opportunities 
  Venue, Hotel, and Travel 
  Program | Technical Sessions 
  Activities 
    Poster Session and Reception 
  Work-in-Progress Reports (WiPs) 
  Participate | Call for Papers 
  Double-Blind Guidance 
  Author Response Advice 
    Call for Posters and WiPs 
  Instructions for Presenters 
  Sponsors | Exhibitor Services 
  About | Past Conferences 
  Conference Organizers 
    Conference Policies 
  Code of Conduct 
  Questions 

 FAST '23 Venue, Hotel, and Travel  

 The conference—and all activities unless otherwise noted—will be held at the Hyatt Regency Santa Clara.  
 Hotel Discount Deadline: Monday, February 6, 2023  
 Hotel Information  
 Hyatt Regency Santa Clara   
  5101 Great America Parkway  
  Santa Clara, CA, 95054  
  USA  
  +1 408.200.1234  
  +1 800.397.3342  
 USENIX has negotiated a special conference attendee room rate of US$314 plus tax for single/double occupancy, including in-room wireless internet. To receive this rate, book your room online  or call the hotel and mention USENIX or FAST '23. The group rate is available until February 6, 2023,  or until the block sells out, whichever occurs first.  
 Room Sharing  
 USENIX utilizes Google Groups  to facilitate room sharing. You can sign up for free to find attendees with whom you can share a hotel room, taxi, etc. Please include "FAST '23"  in the subject line when posting a new room share request.  

 Why Stay in the Conference Hotel?  
 One way USENIX reduces meeting room rental fees is via our contracted hotel room block. When our room block is not utilized by attendees, we face significant financial penalties, which may ultimately force us to raise registration fees. For this reason, we encourage attendees to stay in the conference hotel and to identify themselves as USENIX conference attendees when making reservations.  
 Privacy Statement  
 USENIX never sells or rents your contact information. All communications regarding your registration will come via email from conference@usenix.org  . Anyone contacting you regarding registration or hotel and travel accommodations who is not acknowledged on the USENIX website is not affiliated with USENIX. Please make your hotel reservations by calling the hotel directly, or via the link on this page.  

 Parking  
 Daily parking is available for $25/day. See the hotel's website for additional parking information and rates  .  
 About Santa Clara  
 Have some time to explore before or after the conference? Check out the Santa Clara Convention and Visitors Bureau  for recommendations and information.  
 Traveling to FAST '23 from outside the USA?  
 See detailed advice  from the National Academies of Sciences, Engineering, and Medicine about visiting the United States.  

 Attend | Registration Information 
  Registration Discounts 
  Grant Opportunities 
  Venue, Hotel, and Travel 
  Program | Technical Sessions 
  Activities 
  Poster Session and Reception 
  Work-in-Progress Reports (WiPs) 
  Participate | Call for Papers 
  Double-Blind Guidance 
  Author Response Advice 
  Call for Posters and WiPs 
  Instructions for Presenters 
  Sponsors | Exhibitor Services 
  About | Past Conferences 
  Conference Organizers 
  Conference Policies 
  Code of Conduct 
  Questions 

  Twitter    Facebook    Youtube     

 Privacy Policy 
  Contact Us 

 © USENIX 2024

93. FedCSIS_3 conference:
18th Conference on Computer Science and Intelligence Systems  
 September 17–20, 2023  . Warsaw, Poland  
  
 Annals of Computer Science and Intelligence Systems, Volume 35   
 ISSN 2300-5963   
   
 Volume 34  Volume 36    
 Proceedings of the 18th Conference on Computer Science and Intelligence Systems  
 ISBN 978-83-967447-8-4 (Web),  
  978-83-967447-9-1 (USB),  
  978-83-969601-0-8 (ART)   
 IEEE  Catalog Number: CFP2385N-ART (ART),  
  CFP2385N-USB (USB)   
 DOI: http://dx.doi.org/10.15439/978-83-967447-8-4    
   
 Complete FedCSIS Proceedings (PDF, 76.459 M)    
 Search results for    
 Search this volume:     
 Main track | Invited 
  Regular 
  Short 
  Thematic tracks | Regular 
  Short 
  Competitions | PolEval 
  Cybersecurity… 
  CAICCAIC 
  TICRC 
  Top 
  🔎 
   
 Preface   
 Dear  it is our pleasure to present to you Proceedings of the 18 th  Conference on Computer Science and Intelligence Systems (FedCSIS 2023), which took place on September 17-20, 2023, in Warsaw, Poland.  
 FedCSIS 2023 was chaired by Jarosław Arabas and Sławomir Zadrożny, while Przemysław Biecek acted as the Chair of the Organizing Committee. This year, FedCSIS was organized by the Polish Information Processing Society (Mazovia Chapter), IEEE Poland Section Computer Society Chapter, Systems Research Institute of Polish Academy of Sciences, as well as Faculty of Electronics and Information Technology and Faculty of Mathematics and Information Sciences of Warsaw University of Technology.  
 FedCSIS 2023 was technically co-sponsored by IEEE Poland Section, IEEE Czechoslovakia Section Computer Society Chapter, IEEE Poland Section Systems, Man, and Cybernetics Society Chapter, IEEE Poland Section Computational Intelligence Society Chapter, Committee of Computer Science of Polish Academy of Sciences, and Mazovia Cluster ICT. Moreover, two years ago, the FedCSIS conference series formed strategic alliance with QED Software, a Polish software company developing AI-based products, and this collaboration has been continued.  
 FedCSIS 2023 was sponsored by QED Software, Samsung, Hewlett Packard Enterprise, Łukasiewicz Research Network – Institute of Innovative Technologies EMAG, MDPI, Sages, Efigo, and CloudFerro.  
 This year, another round of evolutionary adaptations, to the FedCSIS conference series, took place. Specifically, they concerned the conference structure. Post conference publications (Proceedings, Position Papers and Communication Papers volumes) illustrate the direction of this evolutionary process. In short, starting from 2023, FedCSIS conferences have Main Track with five Topical Areas, Thematic Tracks and, possibly, Competitions. The new structure emphasizes the integrity of the conference. For all five Topical Areas, situated within a general domain of Computer Science, the continually emerging topic of Intelligence Systems, stands as the common denominator. All Thematic Tracks refer to Intelligence Systems as well, from different perspectives. Even Competitions, having strong roots in the realm of AI, data science, machine learning, computer vision, and natural language processing, are regarded as a path toward introducing more Intelligence into Computer Science and IT.  
 In this context, these Proceedings consist of six parts. Part 1 contains Invited Contributions. Part 2 collects Main Track full contributions (arranged alphabetically, according to the last name of the first author, with Topical Area represented in the metadata). Part 3 contains Main Track short contributions. Part 4 contains full contributions, originating from Thematic Tracks. (Again, texts are arranged alphabetically, according to the last name of the first author, with the name of Thematic Track stated in the metadata.) Part 5 collects short papers from all Thematic Tracks. Finally, Part 6 is devoted to Competitions that run within the context of FedCSIS conferences.  
 Keeping this in mind, let us now introduce Keynote Speakers, the remaining Invited Contributions, and the five Topical Areas of FedCSIS 2023 Main Track.  
 I. Invited Contributions  
 FedCSIS 2023 invited four keynote lecturers to deliver lectures matching Topical Areas and thus providing a broader context for the conference participants. Moreover, two past FedCSIS keynote speakers have been invited to prepare contributions, which refer to the core focus of the conference series. There are also two contributions corresponding to the additional invited talks and three contributions corresponding to tutorials. The aforementioned common denominator of all FedCSIS Topical Areas is clearly visible in this part. First, we can see here the core AI works on trustworthiness and robustness of neuro-symbolic and neural network models. Second, there are contributions related to the foundations of intelligent decision making and uncertainty modeling, using tools taken e.g. from soft computing and information theory. On the other hand, we have also contributions referring to machine learning and data science software, as well as examples of applications of AI methods in practical domains. This generally reflects our understanding of the place of Intelligence Systems in the realm of Computer Science. Namely, according to our vision, it is to develop and adjust the AI-related methods to let them work efficiently as the essential component of modern software systems and solutions.  
 II. Advanced Artificial Intelligence in Applications  
 This Topical Area is a conceptual continuation of a series of international AAIA Symposiums, which have been held since 2006. It aims at covering wide range of core aspects of AI. Nowadays, AI is usually perceived as closely related to the data, therefore, the scope of this Topical Area includes elements of machine learning, data science, and big data processing, with important emerging aspects such as interactive learning and human-centered AI, as well as interpretable learning, explainable AI, and the aforementioned topic of trustworthiness. Furthermore, since the realm of AI is far richer, the ultimate goal of this Topical Area is to show relationships between all of AI subareas, emphasizing a cross-disciplinary nature of various research branches. In 2023, the collection of papers accepted to this Topical Area has reflected this cross-disciplinary nature particularly well. We can see here various areas of AI (also outside so-called “core AI”), as well as a mix of theoretical and practical contributions. From the perspective of the general scope of FedCSIS, this Topical Area embraces particularly AI methods and examples of their applications in different practical fields.  
 This Topical Area is curated by:  
 + Corizzo, Roberto, American University, USA  
 + Sosnowski, Łukasz, Systems Research Institute of Polish Academy of Sciences, Poland  
 + Szczuka, Marcin, University of Warsaw, Poland  
 + Zdravevski, Eftim, Ss. Cyril and Methodius University, Macedonia  
 III. Computer Science & Systems  
 This Topical Area aims at integrating and creating synergy between Computer Science and related disciplines, with AI being of the core interest. The area’s scope spans themes ranging from hardware issues close to computer engineering via software issues tackled by the theory and applications of Computer Science. When compared to the previously-discussed Topical Area on “Advanced Artificial Intelligence in Applications”, herein we are interested more in software system realizations and computational aspects. Therefore, we make a step from AI regarded as the set of methods towards Intelligence Systems understood as software systems with the elements of AI. As an example, the domains such as reinforcement learning or AI-based games and simulations are studied here not only from the perspective of the quality of obtained results but also taking into account their performance, resource consumption, and scalability.  
 This Topical Area is curated by:  
 + Casalino, Gabriella, University of Bari "Aldo Moro", Italy  
 + Ducange, Pietro, University of Pisa, Italy  
 + Pawłowski, Wiesław, University of Gdańsk, Poland  
 + Świechowski, Maciej, QED Software, Poland  
 + Wasielewska-Michniewska, Katarzyna, Systems Research Institute of Polish  
 Academy of Sciences, Poland  
 IV. Network Systems & Applications  
 Modern network systems encompass a wide range of solutions and technologies, including wireless and wired networks, network systems, services, and applications. On the one hand, network technologies are used in majority of areas that make human life easier and more comfortable. On the other hand, the rapid need for network deployment brings new challenges in network management and network design, which are reflected in hardware, software, services, and security-related problems. Going back to the main scope of FedCSIS, it is obvious that appropriate network solutions are one of the crucial layers of scalable modern software systems, including those with the elements of AI. On the other hand, equally obviously, AI methods can be useful to make network systems and their applications more efficient. Accordingly, the aim of this Topical Area is to bring more Intelligence into network systems. Moreover, besides network systems, one should think also about network models, network algorithms, etc. Therefore, this Topical Area covers not only the technological side, but also the societal and social impacts of network developments. This Topical Area is curated by:  
 + Armando, Alessandro, University of Genova, Italy  
 + Awad, Ali Ismail, United Arab Emirates University, United Arab Emirates  
 + Furtak, Janusz, Military University of Technology, Poland  
 + Hodoň, Michal, University of Žilina, Slovakia  
 + Suri, Niranjan, Institute of Human and Machine Cognition, United States  
 V. Information Technology for Business & Society  
 The aim this Topical Area is to integrate and create synergy between disciplines of IT, Intelligence Systems, and social sciences. Collected contributions address issues relevant to IT and necessary for practical, everyday needs of business, other organizations and society at large. Moreover, they take a socio-technical view on Intelligence Systems and, at the same time, relate to ethical, social and political issues that they raise. Thus, from the viewpoint of the FedCSIS as a whole, this Topical Area goes beyond Computer Science itself. It refers to the fact that every software system or solution, and especially a system or solution with some flavors of Intelligence, needs to be carefully deployed in real life. In other words, it is not only about machines – it is also about humans. Accordingly, this Topical Area embraces particularly research on methods and processes of adoption of AI and Intelligence Systems in society and particular markets of business applications. Going back to one of the aforementioned invited contributions, the means for trustworthiness can be regarded as an important tool in such processes too.  
 This Topical Area is curated by:  
 + Cano, Alberto, Virginia Commonwealth University, United States  
 + Dias, Gonçalo, University of Aveiro, Portugal  
 + Miller, Gloria, Maxmetrics, Germany  
 + Naldi, Maurizio, LUMSA University, Italy  
 + Wątróbski, Jarosław, University of Szczecin, Poland  
 + Ziemba, Ewa, University of Economics in Katowice, Poland  
 VI. Software, System & Service Engineering  
 For decades, an open question in the software industry remains, how to provide fast and effective software process and software services, and how to come to software systems, embedded systems, autonomous systems, or cyber-physical systems that will address the open issue of supporting information management process in many, particularly complex organization systems. Even more, it is a hot issue how to provide a synergy between systems in common, and software services as a mandatory component of each modern organization, particularly in terms of IoT, big data, and Industry 4.0 paradigms. Therefore, the main goal of this Topical Area is to address open questions and real potentials for various applications of modern approaches and technologies to develop and implement effective software services in a support of information management and system engineering. We can see here a clear linkage to AI and Intelligence Systems as well. On the one hand (going back to one of invited talks reported in Invited Contributions), AI tools can be applied to improve the quality of software and to optimize the performance of computer systems. While on the other hand (going back again to one of the papers associated with the FedCSIS 2023 keynote lectures), AI-based models and algorithms need to be tested, maintained and monitored just like any other components of complex software systems. This Topical Area is curated by:  
 + Luković, Ivan, University of Belgrade, Serbia  
 + Kolukısa Tarhan, Ayça, Hacettepe University, Turkey  
 + Mernik, Marjan, University of Maribor, Slovenia  
 + Popović, Aleksandar, University of Montenegro, Montenegro  
 VII. Zdzisław Pawlak Awards  
 The above-described five Topical Areas of FedCSIS Main Track reflect five fundamental aspects of understanding, developing, and applying Intelligence Systems. This topical integrity is emphasized by the Professor Zdzisław Pawlak award, considered in four categories: Best Paper, Young Researcher, Industry Cooperation, and International Cooperation. Over time, this award has gone through significant evolution together with the FedCSIS conference series. Originally, it was granted only to papers published within the series of AAIA Symposiums. However, although Professor Zdzisław Pawlak has been often recognized as “the father of Polish AI”, his research achievements have gone far beyond AI itself, in particular, toward AI applications and Intelligence Systems as we mean them. Accordingly, over time, we decided to expand this award to the whole conference – not only all Main Track Topical Areas but also all Thematic Tracks.  
 This year, Award Committee (a part of FedCSIS Senior Program Committee) had a particularly hard task to select a single winner of Best Paper Award. Therefore, after discussion, additional paper was distinguished with Distinction Award. The following contributions have been awarded:  
 In the category | Best Paper: | Julian Premm, Hagen Peukert, Dennis Rössel, Mareike Silber, for the paper „Analysis of a GPT-3 chatbot with respect to its input in a sales dialogue” 
  Additional | Distinction Award: | Giovanna Castellano, Pasquale De Marinis, Gennaro Vessio, for the paper „Applying Knowledge Distillation to Improve Weed Mapping With Drones” 
  In the category | Young Researcher: | Anastasiya Danilenka, for the paper „Mitigating the effects of non-IID data in federated learning with a self-adversarial balancing method” 
  In the category | Industry Cooperation: | Mikołaj Pudo, Mateusz Wosik, Artur Janicki, for the paper „Open Vocabulary Keyword Spotting with Small-Footprint ASR-based Architecture and Language Models” 
  In the category | International Cooperation Award: | Samaneh Mohammadi, Mohammadreza Mohammadi, Sima Sinaei, Ehsan Nowroozi, Francesco Flammini, Mauro Conti, for the paper „Balancing Privacy and Accuracy in Federated Learning for Speech Emotion Recognition” 
  Industry Cooperation Award was sponsored by QED Software, International Cooperation Award – by MDPI, while the remaining awards were sponsored by Mazovia Branch of Polish Information Processing Society. Here, it is also worth noting that each of those five papers comes from a different Topical Area or Thematic Track. Yet, they are all aligned with what we described before as the FedCSIS common denominator.  
 VIII. Statistics  
 Each contribution, found in this volume, was refereed by at least two referees and the acceptance rate of regular full papers was approximately 19% (68 accepted contributions, out of 358 general submissions).  
 IX. Committees  
 The Senior Program Committee of FedCSIS 2023 consisted of:  
 van der Aalst, Wil, RWTH Aachen University, Germany 
  Alba, Enrique, University of Málaga, Spain 
  Aiello, Marco, University of Stuttgart, Germany 
  Armando, Alessandro, University of Genova, Italy 
  Atiquzzaman, Mohammed, University of Oklahoma, Norman, USA 
  Awad, Ali Ismail, United Arab Emirates University, United Arab Emirates 
  Blum, Christian, Artificial Intelligence Research Institute (IIIA-CSIC), Spain 
  Bosch, Jan, Chalmers University of Technology, Sweden 
  Boustras, George, European University, Cyprus 
  Bryant, Barrett, University of North Texas, USA 
  Buyya, Rajkumar, University of Melbourne, Australia 
  Cano, Alberto, Virginia Commonwealth University, United States 
  Casalino, Gabriella, University of Bari "Aldo Moro", Italy 
  Corizzo, Roberto, American University, USA 
  Cornelis, Chris, Ghent University, Belgium 
  Dias, Gonçalo, University of Aveiro, Portugal 
  Djidjev, Hristo, Los Alamos National Laboratory, USA and Institute of Information and Communication Technologies, Bulgaria 
  Ducange, Pietro, University of Pisa, Italy 
  Duch, Włodzisław, Nicolaus Copernicus University, Poland 
  Fill, Hans-George, University of Fribourg, Switzerland 
  Fred, Ana, Instituto Superior Técnico (IST—Technical University of Lisbon), Portugal 
  Furtak, Janusz, Military University of Technology, Poland 
  Giancarlo Guizzardi, Free University of Bolzano-Bozen, Italy 
  Herrera, Francisco, University of Granada, Spain 
  Hinchey, Mike, Lero, University of Limerick, Ireland 
  Hodoň, Michal, University of Žilina, Slovakia 
  Kacprzyk, Janusz, Systems Research Institute, Polish Academy of Sciences, Poland 
  King, Irwin, The Chinese University of Hong Kong, China 
  Kolukısa Tarhan, Ayça, Hacettepe University, Turkey 
  Komorowski, Jan, Uppsala University, Sweden 
  Kwaśnicka, Halina, Wrocław University of Science and Technology, Poland 
  Luck, Michael, King's College London, United Kingdom 
  Luković, Ivan, University of Belgrade, Serbia 
  Matwin, Stan, Dalhousie University, University of Ottawa, Canada and Institute of Computer Science, Polish Academy of Science, Poland 
  Mernik, Marjan, University of Maribor, Slovenia 
  Michalewicz, Zbigniew, University of Adelaide, Australia 
  Miller, Gloria, maxmetrics, Germany 
  Naldi, Maurizio, LUMSA University, Italy 
  Pawłowski, Wiesław, University of Gdańsk and Systems Research Institute, Polish Academy of Sciences, Poland 
  Pedrycz, Witold, University of Alberta, Canada 
  Popović, Aleksandar, University of Montenegro, Montenegro 
  Raś, Zbigniew, University of North Carolina, United States 
  Segal, Michael, Ben-Gurion University of the Negev, Israel 
  Skowron, Andrzej, Systems Research Institute, Polish Academy of Sciences, Poland 
  Słowiński, Roman, Poznań University of Technology, Poland 
  Sosnowski, Łukasz, Systems Research Institute, Polish Academy of Sciences, Poland 
  Sowa, John F., VivoMind Research, LLC, USA 
  Spanoudakis George, University of London, United Kingdom 
  Suri, Niranjan, Institute of Human and Machine Cognition, United States 
  Świechowski, Maciej, QED Software, Poland 
  Szczuka, Marcin, University of Warsaw, Poland 
  Wasielewska-Michniewska, Katarzyna, Systems Research Institute, Polish Academy of Sciences, Poland 
  Wątróbski, Jarosław, University of Szczecin, Poland 
  Zdravevski, Eftim, Ss. Cyril and Methodius University, Macedonia 
  Ziemba, Ewa, University of Econmics in Katowice, Poland 
  The FedCSIS 2023 Program Committee consisted of:  
 Abramowicz, Witold, Poznań University of Economics and Business, Poland 
  Ahad, Mohd Abdul, Jamia Hamdard, India 
  Ahmad, Muhammad Ovais, Karlstad University, Sweden 
  Al-Naday, Mays, University of Essex, United Kingdom 
  Almeida, Luis, University of Porto, Portugal 
  Alshayeb, Mohammad, King Fahd University of Petroleum & Minerals, Saudi Arabia 
  Anastassi, Zacharias, ASPETE School of Pedagogical and Technological Education, Greece 
  Andres, Frederic, National Institute of Informatics, Japan 
  Aneta Poniszewska-Maranda, Lodz University of Technology, Poland 
  Arabas, Jaroslaw, Warsaw University of Technology, Poland 
  Arruda Filho, Emílio José, University FUMEC, Brasil 
  Atanassov, Krassimir T., Bulgarian Academy of Sciences, Bulgaria 
  Atasever, Mesut, Uşak University, Turkey 
  Azad, Mohammad, Jouf University, Saudi Arabia 
  Aziz, Shariq, University of Lahore, Pakistan 
  Babur, Önder, Wageningen University & Research, the Netherlands 
  Bacco, Manlio, Institute of Information Science and Technologies, National Research Council, Italy 
  Bachan, Jolanta, Adam Mickiewicz University, Poland 
  Badica, Amelia, University of Craiova, Romania 
  Badica, Costin, University of Craiova, Romania 
  Bajdor, Paula, Czestochowa University of Technology, Poland 
  Balazs, Krisztian, Budapest University of Technology and Economics, Hungary 
  Baldán Lozano, Francisco Javier, University of Granada, Spain 
  Ballas, Rüdiger G., Mobile University of Technology, Germany 
  Banach, Richard, University of Manchester, United Kingdom 
  Banaszak, Zbigniew, Warsaw University of Technology, Poland 
  Barisic, Ankica, Université Côte d'Azur, France 
  Barreiro, Anabela, Universidade de Lisboa, Portugal 
  Bartosz Walter, Poznań University of Technology, Poland 
  Bauer, Markus, InfAI, Germany 
  Belciug, Smaranda, University of Craiova, Romania 
  Bellinger, Colin, National Research Council of Canada, Canada 
  Ben-Assuli, Ofir, Ono Academic College, Israel 
  Białas, Andrzej, Institute of Innovative Technologies EMAG, Poland 
  Bicevskis, Janis, University of Latvia, Riga 
  Bielecki, Wlodzimierz, ZUT Szczecin, Poland 
  Bigi, Brigitte, Laboratoire Parole et Langage, CNRS, France 
  Binnewitt, Johanna, BIBB, and University of Cologne, Germany 
  Biro, M, Software Competence Center Hagenberg, Austria 
  Bjeladinovic, Srdja, University of Belgrade, Serbia 
  Blachnik, Marcin, Silesian University of Technology, Poland 
  Blasband, Darius, RainCode, Belgium 
  Bluemke, Ilona, Warsaw University of Technology, Poland 
  Bodyanskiy, Yevgeniy, Kharkiv National University of Radio Electronics, NURE, Ukraine 
  Boeva, Veselka, Blekinge Institute of Technology, Sweden 
  Bogumiła Hnatkowska, Wrocław University of Science and Technology, Poland 
  Boiński, Tomasz, Gdańsk University of Technology, Poland 
  Bolanowski, Marek, Rzeszow University of Technology, Poland 
  Borkowski, Bolesław, University of Warsaw, Poland 
  Borzemski, Leszek, Wroclaw University of Technology, Poland 
  Brezovan, Marius, University of Craiova, Romania 
  Bridova, Ivana, University of Zilina, Slovakia 
  Bronselaer, Antoon, Ghent University, Belgium 
  Brugnano, Luigi, Università di Firenze, Italy 
  Brzoza-Woch, Ada, AGH University of Science and Technology, Poland 
  Bubak, Marian, AGH Krakow, Poland and University of Amsterdam, the Netherlands 
  Buchalcevova, Alena, University of Economics, Czech Republic 
  Burczynski, Tadeusz, Polish Academy of Sciences, Poland 
  Byrski, Aleksander, AGH University Science and Technology, Poland 
  Cabri, Giacomo, Università di Modena e Reggio Emilia, Italy 
  Camilli, Matteo, Politecnico di Milano, Italy 
  Cano, Alberto, Virginia Commonwealth University, USA 
  Caraffini, Fabio, Swansea University, United Kingdom 
  Carbone, Roberto, Security & Trust Unit, FBK, Italy 
  Carchiolo, Vincenza, Universita di Catania, Italy 
  Casalino, Gabriella, Università degli studi di Bari "A.Moro", Italy 
  Castrillon-Santana, Modesto, University of Las Palmas de Gran Canaria, Spain 
  Ceci, Michelangelo, University of Bari "A. Moro", Italy 
  Charytanowicz, Malgorzata, Catholic University of Lublin, Poland 
  Chelly, Zaineb, Université Paris-Saclay, UVSQ, DAVID, France 
  Cherukuri, Aswani Kumar, VIT University, India 
  Chomiak-Orsa, Iwona, Wroclaw University of Economics and Business, Poland 
  Chren, Stanislav, Aalto University, Finland 
  Christozov, Dimitar, American University in Bulgaria, Bulgaria 
  Chudán, David, Prague University of Economics and Business, Czech Republic 
  Cicirelli, Franco, Dimes - Unical, Italy 
  Ciucci, Davide, Università di Milano-Bicocca, Italy 
  Clarke, Nathan, University of Plymouth, United Kingdom 
  Colantonio, Sara, ISTI-CNR, Italy 
  Corpetti, Thomas, University of Rennes, France 
  Courty, Nicolas, University of Bretagne Sud, France 
  Coviello, Giuseppe, Politecnico di Bari, Italy 
  Cyganek, Bogusław, AGH University of Science and Technology, Poland 
  Czarnacka-Chrobot, Beata, Warsaw School of Economics, Poland 
  D'Ambra, Pasqua, IAC-CNR, Italy 
  da Silva, Marcelino Silva, Federal University of Pará, Brasil 
  Dabrowski, Wlodzimierz, Warsaw University of Technology, Poland 
  Dahyot, Rozenn, Maynooth University, Dublin, Ireland 
  Dajda, Jacek, AGH University Of Science And Technology, Poland 
  Damasevicius, Robertas, Silesian University of Technology, Poland 
  Daszczuk, Wiktor, Warsaw University of Technology, Poland 
  De Juana-Espinosa, Susana, Universidad de Alicante, Spain 
  de Souza, Efren Lopes, Universidade Federal do Oeste do Pará, Brasil 
  De Tré, Guy, Ghent University, Belgium 
  Derezinska, Anna, Warsaw University of Technology, Poland 
  Dettmer, Sandra, Swansea University, United Kingdom 
  Dey, Lipika, Innovation Labs, TCS, India 
  Dimitrieski, Vladimir, Faculty Of Technical Sciences, Serbia 
  Domanska, Joanna, Institute of Theoretical and Applied Informatics, Poland 
  Drag, Pawel, Wroclaw University, Poland 
  Drezewski, Rafal, AGH University of Science and Technology, Poland 
  Düntsch, Ivo, Brock University, Canada 
  Duarte Salinas, Diana, Emory University, USA 
  Dupas, Remy, Université de Bordeaux, France 
  Durillo, Juan J., Leibniz Supercomputing Centre (LRZ), Germany 
  Dutta, Arpita, National University of Singapore, Singapore 
  Dutta, Arpita, National University of Singapore 
  Dutta, Soma, University of Warmia and Mazury in Olsztyn, Poland 
  Eisenbardt, Monika, Univeristy of Economics Katowice, Poland 
  Ekpenyong, Moses, University of Uyo, Nigeria 
  El-Halim, Essam H. Houssein, Minia University, Egypt 
  Engelbrecht, Andries, University of Stellenbosch, South Africa 
  Erata, Ferhat, Yale University, USA 
  Escalona, M. J., University of Seville, Spain 
  Fafoutis, Xenofon, Technical University of Denmark 
  Fareh, Messa, University Blida 1, Algeria 
  Farooq, Ali, University of Turku, Finland 
  Fechner, Richard, University of Tübingen, Germany 
  Felkner, Anna, NASK – Research and Academic Computer Network, Poland 
  Fialko, Sergiy, Cracow University of Technology, Poland 
  Filipe, Vitor, INESC TEC / UTAD, Portugal 
  Flasinski, Mariusz, Jagiellonian University, Poland 
  Fonseca, José Manuel, UNINOVA, Portugal 
  Fourneau, Jean-Michel, DAVID, Universite de Versailles St Quentin, France 
  Fournier-Viger, Philippe, University of Moncton, Canada 
  Fuchs, Christoph, University of Bonn, Germany 
  Fujita, Hamido, Iwate Prefectural University, Japan 
  Furnell, Steven, University of Nottingham, United Kingdom 
  G. Barbosa, Jorge, University of Porto, Portugal 
  G.-Tóth, Boglárka, University of Szeged, Hungary 
  Gabryelczyk, Renata, University of Warsaw, Poland 
  Ganea, Eugen, University of Craiova, Romania 
  García-Mireles, Gabriel, Universidad de Sonora, Mexico 
  Gawin, Bartłomiej, University of Gdańsk, Poland 
  Gawkowski, Piotr, Warsaw University of Technology, Poland 
  Gburzyński, Paweł, University of Alberta, Canada; Vistula University, Poland 
  Ge, Mouzhi, Deggendorf Institute of Technology, Germany 
  Georgiev, Krassimir, Bulgarian Academy of Sciences, Institute of Information and Communication Technologies, Bulgaria 
  Gepner, Pawel, PAWEŁ GEPNER AI, Poland 
  Geri, Nitza, The Open University of Israel, Israel 
  Gheisari, Mehdi, Islamic Azad University, Iran 
  Giannoutakis, Konstantinos, University of Macedonia, Greece 
  Girardi, Rosario, UFMA, Brazil 
  Gjoreski, Hristijan, Ss. Cyril and Methodius University in Skopje, North Macedonia 
  Gobov, Denys, NTUU KPI, Ukraine 
  Goczyła, Krzysztof, Gdańsk University of Technology, Poland 
  Godboley, Sangharatna, NIT Nagpur, India 
  Göknil, Arda, SINTEF Digital, Norway 
  Gomes, Luis, Universidade NOVA de Lisboa, Portugal 
  Gomolinska, Anna, University of Bialystok, Poland 
  González-Deleito, Nicolás, Sirris, Belgium 
  Gora, Paweł, University of Warsaw, Poland 
  Grabara, Dariusz, University of Economics in Katowice, Poland 
  Grabowski, Mariusz, Cracow University of Economics, Poland 
  Gracanin, Denis, Virginia Tech, United States 
  Graliński, Filip, Adam Mickiewicz University, Poznań, Poland 
  Gravvanis, George, Democritus University of Thrace, Greece 
  Grochla, Krzysztof, Institute of Theoretical and Applied Informatics of PAS, Poland 
  Grönman, Jere, Tampere University, Finland 
  Gunasekaran, Karthick, University of Massachusetts / Amazon, United States 
  Habela, Piotr, Polish-Japanese Institute of Information Technology, Poland 
  Hadj Salem, Khadija, INESC TEC, Portugal 
  Hakius, Bettina, BTA Wiedenest, Germany 
  Halasz, David, Masaryk University, Czech Republic 
  Halawi, Leila, Embry-Riddle Aeronautical University, USA 
  Hamel, Oussama, University Blida 1, Algeria 
  Hammoudeh, Mohammad, Manchester Metropolitan University, United Kingdom 
  Hanslo, Ridewaan, University of Pretoria, South Africa 
  Harężlak, Katarzyna, Silesian University of Technology, Poland 
  Hasso, Hussein, Fraunhofer FKIE, Wachtberg, Germany 
  Heil, Sebastian, Technische Universität Chemnitz, Germany 
  Hein, Kristine, BIBB, Bonn, Germany 
  Helsingius, Mika, Finnish Defence Research Agency, Finland 
  Hernes, Marcin, Wroclaw University of Economics and Business, Poland 
  Herold, Sebastian, Karlstad University, Sweden 
  Herrera Viedma, Enrique, University of Granada, Spain 
  Hnatkowska, Bogumila, Wroclaw University of Technology, Poland 
  Horváth, Zoltán, Eötvös Loránd University, Hungary 
  Hosobe, Hiroshi, Hosei University, Japan 
  Hrach, Christian, InfAI, Germany 
  Hsiao, Michael, Virginia Tech, United States 
  Hu, Bao-Gang, Institute of Automation, Chinese Academy of Sciences, China 
  Hübenthal, Tobias, University of Cologne, Germany 
  Hullam, Gabor, Budapest University of Technology and Economics, Hungary 
  Hussain, Shahid, Institute of Business Administration, Pakistan 
  Huzar, Zbigniew, Wroclaw University of Technology, Poland 
  Ienco, Dino, Territories, Environment, Remote Sensing and Spatial Information, France 
  Ignaciuk, Przemyslaw, Lodz University of Technology, Poland 
  Inayat, Irum, National University of Computers and Emerging Sciences, Pakistan 
  Iserte, Sergio, Universitat Jaume I, Spain 
  Iwanowski, Marcin, Warsaw University of Technology, Poland 
  Jakovljevic, Niksa, University of Novi Sad, Serbia 
  Jana, Purbita, The Institute of Mathematical Sciences (IMSc.), India 
  Janicki, Artur, Warsaw University of Technology, Poland 
  Janicki, Ryszard, McMaster University, Canada 
  Janousek, Jan, Czech Technical University Prague, Czechia 
  Jarzabek, Stanislaw, Bialystok University of Technology, Poland 
  Jassem, Krzysztof, Adam Mickiewicz University, Poland 
  Jaworski, Rafał, Adam Mickiewicz University, Poland 
  Jelonek, Dorota, Czestochowa University of Technology, Poland 
  Jensen, Richard, Aberystwyth University, United Kingdom 
  Johnsen, Frank, Norwegian Defence Research Establishment, FFI, Norway 
  Jovanovik, Milos, Ss. Cyril and Methodius University in Skopje, North Macedonia 
  Kacprzyk, Janusz, Systems Research Institute, Polish Academy of Sciences, Poland 
  Kaczmarek, Katarzyna, University of Strathclyde, United Kingdom 
  Kaloyanova, Kalinka, University of Sofia, Bulgaria 
  Kanciak, Krzysztof, Military University of Technology, Poland 
  Kania, Krzysztof, University of Economics in Katowice, Poland 
  Kapczyński, Adrian, Silesian University of Technology, Poland 
  Karaduman, Burak, University of Antwerp, Belgium 
  Kasprzak, Wlodzimierz, Politechnika Warszawska, Poland 
  Katic, Marija, University of London, United Kingdom 
  Keir, Paul, University of the West of Scotland, Scotland 
  Kelner, Jan, Military University of Technology, Poland 
  Keswani, Bright, Suresh Gyan Vihar University, Jaipur, India 
  Khan, Md. Aquil, Indian Institute of Technology Indore, India 
  Khlif, Wiem, FSEGS, Tunisia 
  Kieraś, Witold, Institute of Computer Science, Polish Academy of Sciences, Poland 
  Kimovski, Dragi, University of Klagenfurt, Austria 
  Kitchenham, Barbara, Keele University, United Kingdom 
  Klapp, Iftach, Institute of Agricultural Engineering, Volcani Institute, Agricultural Research Organization Bet Dagan, Israel 
  Klein, Sarah, Sirris, Belgium 
  Kliegr, Tomáš, Prague University of Economics and Business, Czech Republic 
  Kluza, Krzysztof, AGH University of Science and Technology, Poland 
  Kobylinski, Andrzej, Warsaw School of Economics, Poland 
  Koczy, Laszlo, Szechenyi Istvan University, Hungary 
  Kokosinski, Zbigniew, Cracow University of Technology, Poland 
  Kolog, Emmanuel Awuni, University of Ghana, Ghana 
  Kononova, Anna, LIACS, Leiden University, the Netherlands 
  Kopczyńska, Sylwia, Poznan University of Technology, Poland 
  Koržinek, Danijel, Polish-Japanese Academy of Information Technology, Poland 
  Kosar, Tomaz, University of Maribor, Slovenia 
  Kosiuczenko, Piotr, ISI, WAT, Poland 
  Koumaras, Harilaos, National Centre For Scientific Research Demokritos, Greece 
  Kovatcheva, Eugenia, University of Library Studies and Information Technologies, Bulgaria 
  Kozak, Jan, University of Economics in Katowice, Poland 
  Kozielski, Stanislaw, Silesian University of Technology, Poland 
  Kozłowski, Artur, Łukasiewicz Research Network, Poland 
  Krajsic, Philippe, University Leipzig, Germany 
  Krawczyk, Henryk, Gdańsk University of Technology, Poland 
  Krawiec, Krzysztof, Poznan University of Technology, Poland 
  Krdžavac, Nenad, Technische Informationsbibliothek (TIB), Germany 
  Kretowski, Marek, Bialystok University of Technology, Poland 
  Kropp, Martin, University of Applied Sciences and Arts Northwestern Switzerland, Switzerland 
  Krüger, Kai, BIBB, Bonn, Germany 
  Kryvinska, Natalia, Comenius University in Bratislava, Slovakia 
  Kryvyi, Serhii, Taras Shevchenko National University of Kyiv, Ukraine 
  Kuchanskyy, Vladislav, National Academy of Sciences in Ukraine, Institute of Electrodynamics of the National Academy of Sciences of Ukraine 
  Kulakov, Andrea, University "Ss.Cyril and Methodius", North Macedonia 
  Kulczycki, Piotr, Systems Research Institute, Polish Academy of Sciences, Poland 
  Kurasova, Olga, Institute of Mathematics and Informatics, Bulgaria 
  Kusy, Maciej, Rzeszow University of Technology, Poland 
  Kwasnicka, Halina, Politechnika Wroclawska, Poland 
  Kwater, Tadeusz, Państwowa Wyższa Szkoła Techniczno-Ekonomiczna, Poland 
  Kwolek, Bogdan, AGH University of Science and Technology, Poland 
  Lacalle Úbeda, Ignacio, Universitat Politècnica de València, Spain 
  Laccetti, Giuliano, University of Naples Federico II and INFN, Italy 
  Lameski, Petre, Ss. Cyril and Methodius University in Skopje, North Macedonia 
  Lano, Kevin, King's College London, United Kingdom 
  Lasek, Piotr, University of Rzeszów, Poland 
  Laskov, Lasko, New Bulgarian University, Bulgaria 
  Lastovetsky, Alexey, University College Dublin, Ireland 
  Lech Madeyski, Wrocław University of Science and Technology, Poland 
  Lencastre, Maria, Escola Politécnica de Pernambuco – UPE, Brasil 
  Lerga, Jonatan, University of Rijeka, Croatia 
  Leszczyna, Rafał, Gdańsk University of Technology, Poland 
  Lewowski, Tomasz, Wrocław University of Science and Technology, Poland 
  Li, Tianrui, Southwest Jiaotong University, China 
  Ligeza, Antoni, AGH University of Science and Technology, Poland 
  Lilik, Ferenc, Szechenyi Istvan University, Hungary 
  Lin, Zhe, Department of Philosophy Xiamen University Xiamen, China 
  Lirkov, Ivan, Institute of Information and Communication Technologies, Bulgarian Academy of Sciences, Bulgaria 
  Ljubić, Sandi, University of Rijeka, Croatia 
  Lloret, Elena, University of Alicante, Spain 
  Lobato, Fábio, Federal University of Western Pará, Brasil 
  Lovassy, Rita, Obuda University, Hungary 
  Ltaief, Hatem, King Abdullah University of Science and Technology, Saudi Arabia 
  Luna, Jose, University of Cordoba, Spain 
  Lunesu, Ilaria, University of Cagliari, Italy 
  Luque, Gabriel, University of Málaga, Spain 
  Luszczek, Piotr, University of Tennessee Knoxville, USA 
  Machado, José, Universidade do Minho, Portugal 
  Madeyski, Lech, Wroclaw University of Science and Technology, Poland 
  Majdik, Andras, Institute for Computer Science and Control, Hungary 
  Malecki, Piotr, Institute of Nuclear Physics PAN, Poland 
  Mangioni, Giuseppe, University of Catania, Italy 
  Manso, Marco, PARTICLE LTD., Portugal 
  Mansurova, Madina, al-Farabi Kazakh National University, Kazakhstan 
  Maravilla, Javier Calpe, University of Valencia, Spain 
  Marchiori, Massimo, UNIPD and EISMD, Italy 
  Marcińczuk, Michał, Wroclaw University of Science and Technology, Poland 
  Marciniak, Jacek, Adam Mickiewicz University, Poland 
  Marcinkowski, Bartosz, University of Gdansk, Poland 
  Marek Bolanowski, Rzeszow University of Technology, Poland 
  Marghitu, Daniela, Auburn University, USA 
  Martínez López, Pablo E., UNQ, Argentina 
  Maślankowski, Jacek, University of Gdańsk, Poland 
  Mathà, Roland, Distributed and Parallel Systems Group, Austria 
  Matson, Eric, Purdue University, USA 
  Matthies, Christoph, Hasso Plattner Institute, University of Potsdam, Germany 
  Melzer, Sylvia, Universität Hamburg, Germany 
  Mele, Valeria, University of Naples Federico II, Italy 
  Meneses, Claudio, Pontificia Universidad Católica de Chile, Chile 
  Mercier-Laurent, Eunika, Jean Moulin Lyon 3 University, France 
  Mernik, Marjan, University of Maribor, Slovenia 
  Mesiar, Radko, Slovak University of Technology, Slovakia 
  Michał Smialek, Warsaw University of Technology, Poland 
  Michalik, Krzysztof, University of Economics in Katowice, Poland 
  Micota, Flavia, West University of Timisoara, Romania 
  Mignone, Paolo, Bari University, Italy 
  Mihaescu, Marian Cristian, University of Craiova, Romania 
  Mihajlov, Martin, Jozef Stefan Institute, Slovenia 
  Mihálydeák, Tamás, University of Debrecen, Hungary 
  Milašinović, Boris, University of Zagreb, Croatia 
  Mildorf, Tomas, University of West Bohemia, Czech Republic 
  Milella, Annalisa, Institute of Intelligent and Industrial Technologies and Systems for Advanced Manufacturing, National Research Council, Italy 
  Miler, Jakub, Gdansk University of Technology, Poland 
  Miller, Gloria, maxmetrics, Germany 
  Millham, Richard, Durban University of Technology, South Africa 
  Milosavljevic, Gordana, Faculty of Technical Sciences, Serbia 
  Mirosław Ochodek, Poznań University of Technology, Poland 
  Misra, Sanjay, Østfold University, Norway 
  Mocanu, Mihai, University of Craiova, Romania 
  Modoni, Gianfranco, STIIMA-CNR, Italy 
  Mohapatra, Durga Prasad, NIT, India 
  Mongay Batalla, Jordi, National Institute of Technology, Poland 
  Mora, André Damas, UNINOVA, Portugal 
  Morales Trujillo, Miguel Ehécatl, University of Canterbury, New Zealand 
  Moshkov, Mikhail, King Abdullah University of Science and Technology, Saudi Arabia 
  Mozgovoy, Maxim, The University of Aizu, Japan 
  Mullins, Roisin, University of Wales Trinity Saint David, United Kingdom 
  Muñoz, Andres, Cadiz University, Spain 
  Muszyńska, Karolina, University of Szczecin, Poland 
  Myszkowski, Pawel, Wrocław University of Science and Technology, Poland 
  Nawrocki, Jerzy, Poznan University of Technology, Poland 
  Nazaruka, Erika, Riga Technical University, Latvia 
  Neumann, Michael, Hochschule Hannover, Germany 
  Ng, Yen Ying, Nicolaus Copernicus University, Poland 
  Niewiadomska-Szynkiewicz, Ewa, Warsaw University of Technology, Poland 
  Noguera i Clofent, Carles, Institute of Information Theory and Automation (UTIA), Academy of Sciences of the Czech Republic, Czech Republic 
  Nosović, Novica, University of Sarajevo, Bosnia and Herzegovina 
  Noyer, Arne, Ostfalia University of Applied Sciences, Germany 
  Nutini, Francesco, Institute for Electromagnetic Sensing of the Environment, National Research Council, Milano, Italy 
  Ó Cinnéide, Mel, National University of Ireland, Dublin, Ireland 
  Ochodek, Mirosław, Poznan University of Technology, Poland 
  Ogrodniczuk, Maciej, Institute of Computer Science, Polish Academy of Sciences, Poland 
  Okarma, Krzysztof, West Pomeranian University of Technology in Szczecin, Poland 
  Oppermann, Alexander, Physikalisch-Technische Bundesanstalt, Germany 
  Ota, Daniel, Fraunhofer, Germany 
  Ozkan, Necmettin, Kuveyt Turk Participation Bank, Turkey 
  Ozkaya, Mert, Yeditepe University, Turkey 
  Palau, Carlos, Universitat Politècnica de València, Spain 
  Paliwoda-Pękosz, Grażyna, Cracow University of Economics, Poland 
  Palma, Raul, Supercomputing and Networking Center, Poland 
  Palmigiano, Alessandra, The Vrije Universiteit Amsterdam, the Netherlands 
  Paluszyński, Wiesław, TIC sp. z o.o., Poland 
  Pamin, Jerzy, Cracow University of Technology, Poland 
  Pancerz, Krzysztof, Academy of Zamosc, Poland 
  Panda, Subhrakanta, BITS-PILANI Hyderabad Campus, India 
  Pandey, Dr. Rajiv, Amity University, India 
  Pandey, Sushant Kumar, University of Gothenburg, Sweden 
  Pankowska, Malgorzata, University of Economics in Katowice, Poland 
  Papaspyrou, Nikolaos S., National Technical University of Athens, Greece 
  Paszkiewicz, Andrzej, Politechnika Rzeszowska im. I. Łukasiewicza, Poland 
  Pataricza, András, Budapest University of Technology and Economics, Hungary 
  Pazienza, Andrea, Innovation Lab, Exprivia S.p.A., Italy 
  Pekergin N., Nihal, Univ. Paris-Est-Creteil, France 
  Peralta, Daniel, Ghent University, Belgium 
  Perechuda, Kazimierz, Wroclaw University of Economics and Business, Poland 
  Pereira Nunes, Bernardo, The Australian National University, Australia 
  Pereira, Rui Humberto, ISCAP/IPP, Portugal 
  Petcu, Dana, West University of Timisoara, Romania 
  Peters, Georg, Hochschule München, Germany 
  Petrik, Milan, Czech University of Life Sciences Prague, Czech Republic 
  Petrovska, Biserka, Goce Delcev University, North Macedonia 
  Pęzik, Piotr, University of Lodz, Poland 
  Piasecki, Maciej, Wroclaw University of Science and Technology, Poland 
  Piotr Kosiuczenko, Military University of Technology in Warsaw, Poland 
  Pires, Ivan Miguel, Universidade da Beira Interior, Portugal 
  Po, Laura, Universitá di Modena e Reggio Emilia, Italy 
  Poniszewska-Maranda, Aneta, Lodz University of Technology, Poland 
  Porta, Marco, University of Pavia, Italy 
  Porubän, Jaroslav, Technical University of Košice, Slovakia 
  Provotar, Oleksandr, Taras Shevchenko National University of Kyiv, Ukraine 
  Przybyła-Kasperek, Małgorzata, Uniwersytet Śląski w Katowicach, Poland 
  Przybylek, Michal, Warsaw University, Poland 
  Ptaszynski, Michal, Kitami Institute of Technology, Japan 
  Puime, Felix, Universidade de A Coruña, Spain 
  Queirós, Ricardo, ESMAD-P.PORTO & CRACS – INESC TEC, Portugal 
  Radlinski, Lukasz, West Pomeranian University of Technology, Poland 
  Ramanna, Sheela, University of Winnipeg, Canada 
  Rangel Henriques, Pedro, University of Minho, Portugal 
  Rantanen, Petri, Tampere University of Technology, Finland 
  Rauch, Jan, Prague University of Economics and Business, Czech Republic 
  Rechavi, Amit, Ruppin Academic Center, Israel 
  Reformat, Marek, University of Alberta, Canada 
  Ristic, Sonja, University of Novi Sad, Serbia 
  Rojek, Krzysztof, Czestochowa University of Technology, Poland 
  Rollo, Federica, University of Modena and Reggio Emilia, Italy 
  Roman, Adam, Jagiellonian University, Poland 
  Rossi, Bruno, Masaryk University, Czech Republic 
  Rossi, Bruno, Masaryk University, Czechia 
  Roszczyk, Radosław, Warsaw University of Technology, Poland 
  Rot, Artur, Wroclaw University of Economics, Poland 
  Rozevskis, Uldis, University of Latvia, Latvia 
  Rusho, Yonit, Shenkar College of Engineering and Design, Israel 
  Rycerz, Katarzyna, AGH University of Science and Technology, Poland 
  Sá, Juliana, Universidade da Beira Interior, Portugal Hospital Center of Cova da Beira, Portugal 
  Saari, Mika, Tampere University of Technology, Finland 
  Sachdeva, Shelly, NIT, DELHI, India 
  Sachenko, Anatoly, Ternopil State Economic University, Ukraine 
  Sadowska, Małgorzata, Politechnika Wrocławska, Poland 
  Salem, Abdel-Badeeh, Ain Shams University, Egypt 
  Salvetti, Ovidio, Institute of Information Science and Technologies, National Research Council, Pisa, Italy 
  Samolej, Slawomir, Rzeszow University of Technology, Poland 
  Samotyy, Volodymyr, Lviv State University of Life Safety, Ukraine 
  Santiago, Joanna, ISEG - University of Lisbon, Portugal 
  Santos, Pedro Miguel, Instituto Superior de Engenharia do Porto, ISEP, Portugal 
  Saraiva, João, University of Minho, Portugal 
  Sarwas, Grzegorz, Warsaw University, Poland 
  Saurabh, Nishant, Utrecht University, the Netherlands 
  Sawerwain, Marek, University of Zielona Góra, Poland 
  Schaefer, Gerald, Loughborough University, Leicestershire, United Kingdom 
  Schnepf, Timo, BIBB, Bonn, Germany 
  Schön, Eva-Maria, University of Applied Sciences Emden/Leer, Germany 
  Schreiner, Wolfgang, Johannes Kepler University Linz, Austria 
  Schreiner, Wolfgang, Research Institute for Symbolic Computation (RISC), Austria 
  Schreurs, Jeanne, Hasselt University, Belgium 
  Scozzari, Andrea, Institute of Information Science and Technologies, National Research Council, Italy 
  Segedinac, Milan, Faculty of Technical Scieneces, Serbia 
  Sekerinski, Emil, McMaster University, Canada 
  Sen, Jayanta, Government General Degree College, India 
  Shen, Hong, The University of Adelaide, Australia 
  Sidje, Roger B., University of Alabama, USA 
  Sierra, Jose Luis, Universidad Complutense de Madrid, Spain 
  Sifaleras, Angelo, University of Macedonia, School of Information Sciences, North Macedonia 
  Sikorski, Marcin, Gdansk University of Technology, Poland 
  Sikorski, Marcin, Gdansk University, Poland 
  Silaghi, Gheorghe Cosmin, Babes-Bolyai University, Romania 
  Silva, Lincoln, UERJ, Brazil 
  Singer, Jeremy, University of Glasgow, Scotland 
  Singh, Pradeep, KIET Group of Institutions, India 
  Singh, Yashwant, Jaypee University of Information Technology Waknaghat, India 
  Sinkala, Zipani Tom, Karlstad Univeristy, Sweden 
  Skonieczny, Łukasz, Warsaw University of Technology, Poland 
  Skórzewski, Paweł, Adam Mickiewicz University, Poland 
  Skowron, Andrzej, Systems Research Institute, Polish Academy of Sciences and Cardinal Stefan Wyszynski University, Poland 
  Skruch, Pawel, AGH University of Krakow, Poland 
  Skubalska-Rafajłowicz, Ewa, Wrocław University of Science and Technology, Poland 
  Slivnik, Bostjan, University of Ljubljana, Slovenia 
  Smialek, Michal, Warsaw University of Technology, Poland 
  Smywiński-Pohl, Aleksander, AGH University of Science and Technology in Krakow, Poland 
  Soares, Michel, Federal University of Sergipe, Brazil 
  Sobczak, Andrzej, SGH, Poland 
  Sobińska, Małgorzata, Wroclaw University of Economics and Business, Poland 
  Sojka, Michal, Czech Technical University in Prague, Czechia 
  Solanki, Vijender Kumar, CMR Institute of Technology (Autonomous), India 
  Soltysik-Piorunkiewicz, Anna, University of Economics in Katowice, Poland 
  Sosnowski, Janusz, Institute of Computer Science, Poland 
  Sosnowski, Zenon A., Bialystok University of Technology, Poland 
  Sousa Pinto, Agostinho, Instituto Politécnico do Porto, Portugal 
  Sozer, Hasan, Ozyegin University, Turkey 
  Stanczyk, Urszula, Silesian University of Technology, Poland 
  Stanislaw Jarzabek, Bialystok University of Technology, Poland 
  Stankosky, Michael, The University of Scranton, United States 
  Stark, Sandra, University Leipzig, Germany 
  Stasiak, Andrzej, Wojskowa Akademia Techniczna, Poland 
  Stavness, Ian, University of Saskatchewan, Canada 
  Steinbrink, Nicholas, the Bertelsmann Stiftung, Germany 
  Stencel, Krzysztof, University of Warsaw, Poland 
  Štěpánek, Lubomír, Charles University; Prague University of Economics and Business, Czech Republic 
  Stoean, Catalin, Romanian Institute of Science and Technology, Cluj-Napoca, and Universidad de Malaga, Romania 
  Stoean, Catalin, University of Craiova, Romania 
  Stoica, Cosmin, University of Craiova, Romania 
  Stój, Jacek, Silesian University of Technology, Poland 
  Stojanov, Riste, Faculty of Computer Science and Engineering, North Macedonia 
  Subbotin, Sergey, National University "Zaporizhzhia Polytechnic", Ukraine 
  Suraj, Zbigniew, Rzeszów University, Poland 
  Swacha, Jakub, University of Szczecin, Poland 
  Świechowski, Maciej, QED Software, Poland 
  Sylwia Kopczyńska, Poznań University of Technology, Poland 
  Symeonidis, Symeon, Democritus Univesity of Thrace, Greece 
  Szafran, Bartlomiej, AGH University of Science and Technology, Poland 
  Szczech, Izabela, Poznan University of Technology, Poland 
  Szczerbicki, Edward, University of New Castle, Australia 
  Szmit, Maciej, University of Lodz, Poland 
  Szmuc, Tomasz, AGH University of Science and Technology, Poland 
  Szpyrka, Marcin, AGH University of Science and Technology, Poland 
  Szumski, Oskar, University of Warsaw Faculty of Management, Poland 
  Szwoch, Mariusz, Gdansk University of Technology, Poland 
  Szyjewski, Zdzislaw, Uniwersytet Szczeciński, Poland 
  Taglino, Francesco, IASI-CNR, Italy 
  Tanwar, Sudeep, Nirma University, India 
  Terra, Marcus, University of Londrina, Brazil 
  Timpel, Patrick, WIG2, Germany 
  Tomasz, Andrysiak, University of Technology and Life Sciences (UTP), Poland 
  Tomczyk, Łukasz, Jagiellonian University, Poland 
  Toraldo, Gerardo, Università della Campania "l.Vanvitelli", Italy 
  Tormasi, Alex, Szechenyi Istvan University, Hungary 
  Töreyin, Behçet Uğur, Technical University, Turkey 
  Toscano, Piero, Institute of Bioeconomy, National Research Council, Italy 
  Trendowicz, Adam, Fraunhofer, Germany 
  Trocan, Maria, Institut Supérieur d'Électronique de Paris, France 
  Trocan, Maria, Institut Supérieur d'Electronique de Paris, France 
  Trybus, Bartosz, Rzeszów University of Technology, Poland 
  Trybus, Leszek, Rzeszow University of Technology, Poland 
  Tudoroiu, Nicolae, John Abbott College, Canada 
  Tudruj, Marek, Institute of Computer Science, Polish Academy of Sciences, Poland 
  Tyagi, Sudhanshu, Thapar Institute of Engineering & Technology, India 
  Unland, Rainer, University of Duisburg-Essen, Germany 
  Ustimenko, Vasyl, The University of Maria Curie Sklodowska in Lublin, Poland 
  Van Landuyt, Dimitri, Katholieke Universiteit Leuven, Belgium 
  Varanda Pereira, Maria João, Instituto Politécnico de Bragança, Portugal 
  Vardanega, Tullio, University of Padua, Italy 
  Vasiliev, Julian, University of Economics, Bulgaria 
  Vazquez-Poletti, Jose Luis, Universidad Complutense de Madrid, Spain 
  Vecchio, Massimo, Fondazione Bruno Kessler (FBK), Italy 
  Vega Vega-Rodríguez, Miguel A., University of Extremadura, Spain 
  Velev, Miroslav, Aries Design Automation, United States 
  Verstraete, Jörg, Systems Research Institute, Polish Academy of Sciences, Poland 
  Vescoukis, Vassilios, National Technical University of Athens, Greece 
  Vitek, Jan, Northeastern University, USA 
  Vogiatzis, Chrysafis, University of Illinois at Urbana-Champaign, United States 
  Wahid, Khan Ferdous, Airbus Group, Germany 
  Walkowiak-Gall, Anita, Politechnika Wroclawska, Poland 
  Walkowska, Justyna, DeepL, Poland 
  Waloszek, Wojciech, Gdańsk University of Technology, Poland 
  Walter, Bartosz, PCSS & PPoz, Poland 
  Wardziński, Andrzej, Gdańsk University of Technology, Poland 
  Wasielewska, Katarzyna, Systems Research Institute, Polish Academy of Sciences, Poland 
  Wątróbski, Jarosław, West Pomeranian University of Technology, Poland 
  Weber, Richard, Universidad de Chile, Chile 
  Węcel, Krzysztof, Poznań University of Economics and Business, Poland 
  Weerasinghe, Shakthi, Deakin University, Australia 
  Wegrzynowicz, Patrycja, NASK Research and Academic Computer Network, Poland 
  Wei, Wei, Xi'an University of Technology, China 
  Weil, Vera, University of Cologne, Germany 
  Werewka, Jan, AGH University of Science and Technology, Poland 
  Wielki, Janusz, Opole University of Technology, Poland 
  Wierzchoń, Piotr, Adam Mickiewicz University, Poland 
  Winnige, Stefan, BIBB, Bonn, Germany 
  Wisniewski, Piotr, Nicolaus Copernicus University, Poland 
  Wiszniewski, Bogdan, Gdansk University of Technology, Poland 
  Wnuk, Krzysztof, BTH, Sweden 
  Woliński, Marcin, Institute of Computer Science, Polish Academy of Sciences, Poland 
  Wróblewska, Alina, Institute of Computer Science, Polish Academy of Sciences, Poland 
  Wróblewska, Anna, Warsaw University of Technology, Poland 
  Wrona, Konrad, NATO Communications and Information Agency, the Netherlands 
  Wysocki, Marian, Rzeszow University of Technology, Poland 
  Wyrzykowski, Krzysztof, NET PC, Poland 
  Xenakis, Christos, University of Piraeus, Greece 
  Xuetao, Jin, Communication University of China, China 
  Yang, Yujiu, Tsinghua University, China 
  Yao, Yiyu, University of Regina, Canada 
  Zadrożny, Slawomir, Systems Research Institute, Poland 
  Zaitsev, Dmitry 
  Zajac, Mieczyslaw, Cracow University of Technology, Poland 
  Zalewski, Andrzej, Warsaw University of Technology, Poland 
  Zalewski, Janusz, Florida Gulf Coast University, USA 
  Zawadzka, Teresa, Gdańsk University of Technology, Poland 
  Zaytsev, Vadim, Universiteit Twente, the Netherlands 
  Zborowski, Marek, University of Warsaw, Poland 
  Zdravevski, Eftim, University "Ss.Cyril and Methodius", Macedonia 
  Zhang, Hongyu, The University of Newcastle, United Kingdom 
  Zhu, Yungang, Jilin University, China 
  Zieliński, Zbigniew, Military University of Technology, Poland 
  Zielosko, Beata, Uniwersytet Śląski w Katowicach, Poland 
  Ziemba, Ewa, University of Economics in Katowice, Poland 
  Ziemba, Paweł, University of Szczecin, Poland 
  Zitouni, M. Sami, University of Dubai, United Arab Emirates 
  X. Acknowledgments  
 In conclusion, let us emphasize that delivery of FedCSIS 2023 required a dedicated effort of many people. We would like to express our warmest gratitude to all Topical Area Curators, to the members of the Senior Program Committee and to the members of the Program Committee, for their hard work in attracting and reviewing all submissions. We thank the authors of papers for their great contribution to the theory and practice of Computer Science and Intelligence Systems. We are grateful to Keynote, Invited, and Tutorial Speakers, for sharing their knowledge and wisdom with the participants. Last, but not least, we acknowledge one more time Jarosław Arabas, Sławomir Zadrożny, and Przemysław Biecek. We are very grateful for your efforts!  
 We hope that you all had an inspiring conference. We also hope to meet you again for the 19th Conference on Computer Science and Intelligence Systems (FedCSIS 2024) which will take place in Belgrade, Serbia on September 8-11, 2024. Finally, we hope that you will find the evolution of the FedCSIS Conference concept as something that properly addresses the current needs of research and applications. We want to continue looking at Computer Science from different angles but in the same time, acknowledging the topic Intelligence Systems as the central point of everything that we are considering.  
 Co-Chairs of the FedCSIS Conference Series   
 Maria Ganzha  , Warsaw University of Technology, and Systems Research Institute Polish Academy of Sciences, Poland.  
 Leszek Maciaszek  (Honorary Chair), Macquarie University, Australia and Wrocław University of Economics, Poland.  
 Marcin Paprzycki  , Systems Research Institute Polish Academy of Sciences, and Warsaw University of Management, Poland.  
 Dominik Ślęzak  , University of Warsaw, Poland and QED Software, Poland and DeepSeas, USA.  
   
 Hide Preface    
 Main Track  
 Main Track Invited Contributions  
 Measuring Trustworthiness in Neuro-Symbolic Integration | 6019 | Trustworthiness, Neuro-Symbolic Integration, symbolic knowledge extraction, symbolic knowledge injection | Andrea Agiollo, Andrea Omicini, | pages 1–10. | Invited 
  Deciphering Clinical Narratives - Augmented Intelligence for Decision Making in Healthcare Sector | 3385 | Clinical Notes, BioNER, Clustering, Anomaly Detection, Autoencoder, Shapley Value | Lipika Dey, Sudeshna Jana, Tirthankar Dasgupta, Tanay Gupta, | pages 11–24. | Invited 
  When to Trust AI: Advances and Challenges for Certification of Neural Networks | 2324 | neural network certification, AI safety, AI robustness | Marta Kwiatkowska, Xiyue Zhang, | pages 25–37. | Invited 
  Multiple Criteria Decision Aiding by Constructive Preference Learning (Keynote Lecture — Extended Abstract) | 6419 | Multiple Criteria Decision Aiding, Constructive Preference Learning, Dominance Relations | Roman Słowiński, | pages 39–39. | Invited 
  Online Learning Framework for Radio Link Failure Prediction in FANETs | 8996 | Online learning, RLF prediction, UAV | Kiril Danilchenko, Nir Lazmi, Michael Segal, | pages 41–48. | Invited 
  A Survey on Congestion Control and Scheduling for Multipath TCP: Machine Learning vs Classical Approaches | 9832 | Multipath TCP, congestion control, scheduling, deep reinforcement learning, machine learning | Maisha Maliha, Golnaz Habibi, Mohammed Atiquzzaman, | pages 49–61. | Invited 
  Abstract Approach to Entropy and Co-Entropy in Measurable and Probability Spaces (Invited Lecture — Extended Abstract) | 0004 | Gianpiero Cattaneo, | pages 63–64. | Invited 
  Towards reliable rule mining about code smells: The McPython approach (Invited Lecture — Extended Abstract) | 2071 | Code smells, SLR, | Maciej Ziobrowski, Mirosław Ochodek, Jerzy Nawrocki, Bartosz Walter, | pages 65–66. | Invited 
  Combination of Fuzzy Sets and Rough Sets for Machine Learning Purposes (Tutorial Lecture — Extended Abstract) | 0001 | Chris Cornelis, Henri Bollaert, | pages 67–67. | Invited 
  Rough Sets: Introduction, History and Selected Applications (Tutorial Lecture — Extended Abstract) | 0003 | Soma Dutta, Davide Ciucci, | pages 69–70. | Invited 
  Reducts in Rough Sets: Algorithmic Insights, Open Source Libraries and Applications (Tutorial – Extended Abstract) | 0002 | Andrzej Janusz, Sebastian Stawicki, | pages 71–71. | Invited 
  Main Track Regular Papers  
 Type 1 Diabetes Mellitus Saudi Patients' Perspective on the Adopting IoT-Enabled CGM: Validation of Critical Factors in the IAI-CGM A Framework | 4851 | IAI-CGM, TIDM, | Hamad Almansour, Natalia Beloff, Martin White, | pages 73–81. | ITBS 
  Defect Backlog Size Prediction for Open-Source Projects with the Autoregressive Moving Average and Exponential Smoothing Models | 5474 | Defect backlog, ARIMA, | Paulina Anioła, Sushant Kumar Pandey, Miroslaw Staron, Mirosław Ochodek, | pages 83–92. | S3E 
  Can Unlabelled Data Improve AI Applications? A Comparative Study on Self-Supervised Learning in Computer Vision. | 8371 | Artificial Intelligence, Self-Supervised Learning, Computer Vision | Markus Bauer, Christoph Augenstein, | pages 93–101. | AAIA 
  CADM: Big Data to Limit Creative Accounting in Saudi-Listed Companies | 3888 | Creative Accounting, Bigdata, | Maysoon Bineid, Natalia Beloff, Martin White, Anastasia Khanina, | pages 103–110. | ITBS 
  Toward an Optimal Solution to the Network Partitioning Problem | 2832 | ‎Graph partitioning‎, ‎Community detection‎‎, | Arman Ferdowsi, Maryam Dehghan Chenary, | pages 111–117. | NSA 
  Diffusion Limits for Shortest Remaining Processing Time Queues with Multiple Customer Types | 4407 | Heavy traffic, Queueing, | Robert Gieroba, Łukasz Kruk, | pages 119–130. | NSA 
  Genetic Algorithm for Planning and Scheduling Problem -- StarCraft II Build Order case study | 6015 | Build Order Planning, Genetic Algorithm, Cumulative Scheduling, Producer/Consumer Problem, StarCraft II | Konrad Gmyrek, Michał Antkiewicz, Pawel Myszkowski, | pages 131–140. | AAIA 
  Discovering relationships between data in enterprise system using log analysis | 4617 | knowledge discovery, log analysis, | Łukasz Korzeniowski, Krzysztof Goczyła, | pages 141–150. | S3E 
  The Use of Digital Technologies in German Business Consultancies | 7831 | Digitalization, Digital Technology, Consulting, Business Consultancy | Christian Leyh, Marcel Lange, Alisa Lorenz, | pages 151–160. | ITBS 
  A Framework for Assessing the Sustainability of Intelligent Transport Systems in the Smart City Context | 6002 | smart city, smart mobility, smart traffic management, intelligent transport systems, sustainability | Alisa Lorenz, Nils Madeja, Christian Leyh, | pages 161–169. | ITBS 
  Time-series Anomaly Detection and Classification with Long Short-Term Memory Network on Industrial Manufacturing Systems | 5263 | anomaly detection, anomaly classification, | Tijana Markovic, Alireza Dehlaghi-Ghadim, Miguel Leon, Ali Balador, Sasikumar Punnekkat, | pages 171–181. | AAIA 
  XOR-based decomposition and its application in memory-based and reversible logic synthesis | 4382 | reversible logic synthesis, memory-based logic synthesis, | Tomasz Mazurkiewicz, | pages 183–190. | CSS 
  Balancing Privacy and Accuracy in Federated Learning for Speech Emotion Recognition | 444 | Federated Learning, Privacy-preserving Mechanism, Differential Privacy, Speech Emotion Recognition | Samaneh Mohammadi, Mohammadreza Mohammadi, Sima Sinaei, Ali Balador, Ehsan Nowroozi, Francesco Flammini, Mauro Conti, | pages 191–199. | AAIA 
  Back to the Essential: A Literature-Based Review on Agile Mindset | 6360 | Agility, Agile Mindset, systematic literature review, SLR, project management, Scrum | Necmettin Ozkan, Karen Eilers, Mehmet Şahin Gök, | pages 201–211. | ITBS 
  Sign language interpreting - relationships between research in different areas - overview | 2503 | sign language, automatic interpreting, | Barbara Probierz, Jan Kozak, Adam Piasecki, Angelika Podlaszewska, | pages 213–223. | ITBS 
  Enhancing naive classifier for positive unlabeled data based on logistic regression approach | 1402 | binary classification, logistic regression, | Mateusz Płatek, Jan Mielniczuk, | pages 225–233. | AAIA 
  Improving the Efficiency of Meta AutoML via Rule-based Training Strategies | 708 | Meta AutoML, AutoML, Green AI, Training strategies, OMA-ML | Alexander Zender, Bernhard G. Humm, Tim Pachmann, | pages 235–246. | AAIA 
  Main Track Short Papers  
 Towards automated detection of adversarial attacks on tabular data | 3838 | machine learning diagnostics, rough sets, | Piotr Biczyk, Łukasz Wawrowski, | pages 247–251. | AAIA 
  Change of Brand Management in Social Media During the Russia-Ukraine War: Findings from Poland | 3585 | social media, brand management, | Magdalena Grzanka, Artur Strzelecki, | pages 253–258. | ITBS 
  Continual learning of a time series model using a mixture of HMMs with application to the IoT fuel sensor verification | 1856 | Hidden Markov Model, HMM mixture model, | Przemysław Głomb, Michal Cholewa, Pawel Foszner, Jakub Bularz, | pages 259–264. | AAIA 
  Towards an HPC cluster digital twin and scheduling framework for improved energy efficiency | 3797 | HPC, energy efficiency, | Alexander Kammeyer, Florian Burger, Daniel Lübbert, Katinka Wolter, | pages 265–268. | ITBS 
  Perception of vector and triangle representations of fuzzy number most possible value changes | 9557 | Fuzzy number visualization, Fuzzy number vector representation, Visual processing, Project uncertainty, Usability. | Dorota Kuchta, Jerzy Grobelny, Rafał Michalski, Jan Schneider, | pages 269–274. | ITBS 
  Emotion-Based Literature Books Recommender Systems | 8647 | Recommender Systems, Emotions Analysis, Social Media Book Reviews | Elena-Ruxandra Luțan, Costin Bădică, | pages 275–280. | ITBS 
  BERT-CLSTM model for the classification of Moroccan commercial courts verdicts | 3561 | AI, Commercial court, | Taoufiq El Moussaoui, Loqman Chakir, | pages 281–284. | AAIA 
  Calculating and comparing solar radiation results using GIS in the City Sarajevo area | 6245 | QGIS, PVGIS, SAGA, GRASS, DEM | Nedim Mujić, Almir Karabegović, | pages 285–290. | CSS 
  Towards Industry 4.0: Machine malfunction prediction based on IIoT streaming data | 677 | Industrial Internet of Things, Industry 4.0, Machine malfunction prediction, Machine failure prediction | Dragana Nikolova, Petre Lameski, Ivan Miguel Pires, Eftim Zdravevski, | pages 291–296. | AAIA 
  Reranking for a Polish Medical Search Engine | 1627 | rerankinkg, medical search, | Jakub Pokrywka, Krzysztof Jassem, Piotr Wierzchoń, Piotr Badylak, Grzegorz Kurzyp, | pages 297–302. | AAIA 
  Developing Field Theory in Mizar | 3409 | Interactive theorem proving, Mizar system, | Christoph Schwarzweller, | pages 303–308. | AAIA 
  Clusterization methods for multi-variant e-commerce interfaces | 1377 | e-commerce, personalization, | Adam Wasilewski, | pages 309–313. | ITBS 
  QMAK: Interacting with Machine Learning Models and Visualizing Classification Process | 4101 | explainable machine learning, classification visualization, | Arkadiusz Wojna, Katarzyna Jachim, Łukasz Kosson, Łukasz Kowalski, Damian Mański, Michał Mański, Krzysztof Mroczek, Krzysztof Niemkiewicz, Robert Piszczatowski, Maciej Próchniak, Tomasz Romańczuk, Piotr Skibiński, Marcin Staszczyk, Michał Szostakiewicz, Leszek Tur, Damian Wójcik, Maciej Zuchniak, | pages 315–318. | AAIA 
  Thematic Tracks  
 Preface to Thematic Tracks   
 Parts  4 and 5 of FedCSIS 2023 Proceedings contain contributions originating from Thematic Tracks. Let us present each one of them.  
 I. Advances in Programming Languages  
 Programming languages are programmers' most basic tools. With appropriate programming languages one can drastically reduce the cost of building new applications, as well as maintaining existing ones. In the last decades, there have been many advances in programming languages technology, in traditional programming paradigms such as functional, logic, and object-oriented programming, as well as the development of new paradigms, such as aspect-oriented programming. The main driving force was, and will be, to better express programmers' ideas. Therefore, research in programming languages is an endless activity and the core of computer science. New language features, new programming paradigms, and better compile-time and run-time mechanisms can be foreseen in the future. Here, the potential future role of AI models in programming should also be taken into account. In this context, the aim of this Thematic Track was to provide a forum for exchange of ideas and experience in topics concerned with programming languages and systems.  
 Thematic Track organizers:  
 + Janousek, Jan, Czech Technical University, Czech Republic  
 + Luković, Ivan, University of Belgrade, Serbia  
 + Mernik, Marjan, University of Maribor, Slovenia  
 + Rangel Henriques, Pedro, Universidade do Minho, Portugal  
 + Slivnik, Boštjan, University of Ljubljana, Slovenia  
 + Varanda Pereira, Maria Joao, Instituto Politecnico de Braganca, Portugal  
 II. Artificial Intelligence in Agriculture  
 AI is increasingly used in agriculture, to address multiple issues, from plant disease detection to weeding automation, soil status monitoring, crop prediction, irrigation management, and decreased use of resources, for improving product quality and process productivity. AI can, in fact, provide highly positive effects on precision agriculture by optimizing, automating and forecasting multiple aspects of farming and revolutionizing the sector, providing helpful information and driving decisions using multiple sources of data and different sensors. Moreover, in the climate change era, AI can improve sustainability by optimizing the use of resources, such as in the case of water and soil management. This Thematic Track welcomed contributions concerning all aspects of interdisciplinary research and applications related to AI in agriculture.  
 Thematic Track organizers:  
 + Charvat, Karel, Czech Center for Science and Society, Czech Republic  
 + Martinelli, Massimo, National Research Council of Italy, Italy  
 + Moroni, Davide, National Research Council of Italy, Italy  
 + Procházka, Ales, University of Chemistry and Technology & Czech Technical University CIIRC, Czech Republic  
 III. Artificial Intelligence in Digital Humanities, Computational Social Sciences and Economics Research  
 This Thematic Track was dedicated to the computational study of social sciences, economics and humanities, including all subjects like, for example, education, labor market, history, religious studies, theology, cultural heritage, and informative predictions for decision-making and behavioral-science perspectives. Besides new discoveries, it was dedicated to the reflections about their growth within the field of computer science and it emphasized the interdisciplinary exchange and dissemination with a clear focus on computational and AI-based methods. Since there is a clear methodological overlap between the considered domains of social sciences, economics and humanities, and often similar algorithms and AI approaches are considered for them, this track should be seen as a place for discussing a “joint toolbox” as a support for scholars from these fields with human and context-aware agents. It included also research related to trustworthy data infrastructure housing both quantitative and qualitative data.  
 Thematic Track organizers:  
 + Cooper, Anthony-Paul, Durham University, United Kingdom and University of Turku, Finland  
 + Dörpinghaus, Jens, BIBB and University of Koblenz, Germany  
 + Helmrich, Robert, BIBB and University of Bonn, Germany  
 + Speckesser, Stefan, Brighton University, United Kingdom  
 IV. Challenges for Natural Language Processing  
 This Thematic Track consisted of contributions related to all aspects of NLP. Of particular interest were works addressing NLP tools, multimodal problems, cross-lingual learning and processing of natural languages. Moreover, this track was also hosting the NLP-related competitions, results of which are presented in Part 6 of these proceedings. This Thematic Track was co-organized by the Multi-task, Multilingual, Multi-modal Language Generation COST Action (CA18231).  
 Thematic Track organizers:  
 + Kobyliński, Łukasz, Institute of Computer Science, Polish Academy of Sciences, Poland  
 + Kubis, Marek, Faculty of Mathematics and Computer Science, Adam Mickiewicz University, Poland  
 V. Complex Networks: Theory and Application  
 In the nature and the world around us, one can observe many network structures that interconnect various elements such as cells, people, urban centers, network devices, companies, manufacturing machines, etc. Moreover, it is easy to notice that most of them evolve over time. The analysis of such systems from the complex networks point of view allows for better understanding of the processes within them, which can be used to optimize their structure, improve their management methods, detect failures, improve their operating efficiency and plan their development and evolution. The main goal of this Thematic Track was to exchange knowledge and experience between specialists from different areas who, in their research and design work, use theories and solutions characteristic for complex systems.  
 This Thematic Track was organized within framework of the project financed by the Minister of Education and Science of the Republic of Poland within the “Regional Initiative of Excellence” program for years 2019–2023. Project number 027/RID/2018/19, amount granted 11 999 900 PLN.  
 Thematic Track organizers:  
 + Bolanowski, Marek, Rzeszów University of Technology, Poland  
 + Kondratenko, Yuriy, Petro Mohyla Black Sea National University, Ukraine  
 + Paszkiewicz, Andrzej, Rzeszów University of Technology, Poland  
 VI. Computational Optimization  
 Many real world problems, arising in engineering, economics, medicine and other domains, can be formulated as optimization tasks. These problems are frequently characterized by non-convex, non-differentiable, discontinuous, noisy or dynamic objective functions and constraints, which ask for adequate computational methods. The aim of this Thematic Track was to stimulate the communication between researchers working on different fields of optimization and practitioners who need reliable and efficient computational optimization methods. Contributions related to both theoretical and practical aspects of optimization methods were represented.  
 Thematic Track organizers:  
 + Fidanova, Stefka, Bulgarian Academy of Sciences, Bulgaria  
 + Mucherino, Antonio, IRISA, University of Rennes, France  
 + Zaharie, Daniela, West University of Timisoara, Romania  
 VII. Computer Aspects of Numerical Algorithms  
 Numerical algorithms are widely used by scientists engaged in various areas. There is a special need of highly efficient and easy-to-use scalable tools for solving large scale problems. This Thematic Track was devoted to numerical algorithms, with the particular attention focused on the latest scientific trends in this area and on problems related to implementation of libraries of efficient numerical algorithms. The main goal of this track was to facilitate meeting of researchers and exchange of their experiences.  
 Thematic Track organizers:  
 + Bylina, Beata, Maria Curie-Skłodowska University, Poland  
 + Bylina, Jarosław, Maria Curie-Skłodowska University, Poland  
 + Cyganek, Bogusław, AGH University of Science and Technology, Poland  
 + Lirkov, Ivan, Bulgarian Academy of Sciences, Bulgaria  
 + Stpiczyński, Przemysław, Maria Curie-Skłodowska University, Poland  
 VIII. Cyber-Physical Systems Software Engineering  
 This Thematic Track has its roots in the IEEE Software Engineering Workshop (SEW), which is the oldest Software Engineering event in the world, dating back to 1969. It was originally run as the NASA Software Engineering Workshop and focused on software engineering issues relevant to NASA and the space industry. After the 25th edition, it became the NASA/IEEE Software Engineering Workshop and expanded its remit to address many more areas of software engineering, with emphasis on practical issues, industrial experience and case studies in addition to traditional technical papers. Since its 31st edition, it has been sponsored by IEEE and has continued to broaden its areas of interest. Now it is an integral part of the FedCSIS conference series, as one of important Thematic Tracks.  
 One extremely hot new area are Cyber-Physical Systems (CPS), which encompass the investigation of approaches related to the development and use of modern software systems interfacing with real world and controlling their surroundings. CPS are physical and engineering systems closely integrated with their typically networked environment. Modern airplanes, automobiles, or medical devices are practically networks of computers. Sensors, robots, and intelligent devices are abundant. Human life depends on them. CPS systems transform how people interact with the physical world just like the Internet transformed how people interact with one another. Accordingly, this Thematic Track brought together researchers with interest in software engineering, both with CPS and broader focus. Moreover, it provided a forum for reporting on past experiences, for describing new and emerging results and approaches, and for exchanging ideas on best practice and future directions.  
 Thematic Track organizers:  
 + Bowen, Jonathan, Museophile Ltd., United Kingdom  
 + Hinchey, Mike, Irish Software Engineering Research Centre, Ireland  
 + Szmuc, Tomasz, AGH University of Science and Technology, Poland  
 + Zalewski, Janusz, Florida Gulf Coast University, United States  
 IX. Cyber Security, Privacy, and Trust  
 Nowadays, information security is a backbone for protecting both user data and electronic transactions. Protecting communications and data infrastructures of an increasingly inter-connected world have become vital. Security has also emerged as an important scientific discipline whose many multifaceted complexities require synergy of computer science, engineering, and information systems communities. Information security has some well-founded technical research directions which encompass access level (user authentication and authorization), protocol security, software security, and data cryptography. Moreover, some other emerging topics related to organizational security aspects have appeared beyond the long-standing research directions. In this context, this Thematic Track focused on the diversity of the cyber information security developments and deployments in order to highlight the most recent challenges and report the most recent researches. It was designed as an umbrella for all cyber security technical aspects, user privacy techniques, and trust. In addition, it went beyond the technicalities and covered some emerging topics like social and organizational security research directions. Thematic Track organizers:  
 + Białas, Andrzej, Institute of Innovative Technologies EMAG, Poland  
 + Masud, Mohammad, United Arab Emirates University, United Arab Emirates  
 X. Data Science in Health, Ecology and Commerce  
 This Thematic Track was a forum for exchange of ideas concerning all forms of data analysis, data economics, information systems and data based research, focusing on the interaction of those three fields. Here, data-driven solutions can be generated by understanding complex real-world (health-related) problems, critical thinking and analytics to derive knowledge from (Big) data. The past years have shown a forthcoming interest on innovative data technology and analytics solutions that link and utilize large amounts of data across individual digital ecosystems. Here, scenarios, in the field of health, smart cities or agriculture, merge data from various IoT devices, social media or applications and demonstrate the great potential for gaining new insights, supporting decisions, or providing smarter services. Together with inexpensive sensors and computing power they provide foundation of a world that bases its decisions on data. However, this is only the beginning of the journey, and the pertinent methods and technologies, and the potential application fields, as well as the impact on society and economy, have to be explored. This endeavor needs the knowledge of researchers from different fields applying diverse perspectives and using different methodological directions to find a way to grasp and fully understand the power and opportunities of data science. Bringing together researchers and practitioners of pertinent fields was one of focal points of this Thematic Track.  
 Thematic Track organizers:  
 + Bumberger, Jan, Helmholtz‐Centre for Environmental Research – UFZ, Germany  
 + Franczyk, Bogdan, University of Leipzig, Germany  
 + Häckl, Dennis, University of Leipzig and WIG2 Institute for Health Economics and Health Service Research, Germany  
 + Militzer-Horstmann, Carsta, WIG2 Institute for Health Economics and Health Service Research, Germany  
 + Reinhold, Olaf, University of Leipzig / Social CRM Research Center, Germany  
 XI. Distributed Edge AI – Risks and Challenges  
 The advent of end and edge nodes, with increased computational and storage capabilities, makes it possible to perform a large range of computations, with special focus on AI-based tasks on privacy-sensitive data, locally at the edge. This makes it possible to rely on a backend cloud only for communicating results of non-private data, for example by aggregation, or performing computations requiring the combination and further processing of results from different edge devices, or historical data sources, as it is done in the federated learning approaches. In addition, this increase in computation capabilities enables also neighboring edge devices to perform tasks collaboratively, leveraging each other's computational resources, before offloading data and computations to the cloud backend. This Thematic Track focused on AI and ML techniques related to edge computing systems, and security and privacy approaches in view of data sharing, in order to enable smart and sustainable planning and operation of resource constrained IoT ecosystems, and edge computing applications. It was organized within the scope of the European ITEA3 MIRAI R&D project. Thematic Track organizers:  
 + Hristoskova, Anna, Sirris, Belgium  
 + Klein, Sarah, Sirris, Belgium  
 XII. Information Systems Management  
 This Thematic Track facilitated a forum for exchange of ideas, for practitioners and theorists working in the broad area of information systems management in organizations. It focused on three complimentary directions: management of information systems in an organization, uses of information systems to empower managers, and information systems for sustainable development. Here, the interest encompassed all aspects of planning, organizing, resourcing, coordinating, controlling and leading the management function to ensure a smooth operation of information systems in organizations. Moreover, the contributions discussing the uses of intelligence systems and information technology to automate or otherwise facilitate the management function were included. Researches on the influence of intelligence systems on sustainability were welcomed as well.  
 Thematic Track organizers:  
 + Bicevska, Zane, University of Latvia, Latvia  
 + Chmielarz, Witold, University of Warsaw, Poland  
 + Duan, Yanqing, University of Bedfordshire, United Kingdom  
 + Leyh, Christian, University of Applied Sciences, Germany  
 XIII. Internet of Things – Enablers, Challenges and Applications  
 The Internet of Things (IoT) is a technology which is rapidly emerging around the world. IoT applications include: smart city initiatives, wearable devices aimed to real-time health monitoring, smart homes and buildings, smart vehicles, environment monitoring, intelligent border protection, logistics support. IoT is a paradigm that assumes a pervasive presence in the environment of many smart things, including sensors, actuators, embedded systems and other similar devices. Widespread connectivity, getting cheaper smart devices and a great demand for data, testify to that the IoT will continue to grow by leaps and bounds. The business models of various industries are being redesigned on basis of the IoT paradigm. This Thematic Track focused on the IoT challenges in networking and information management, security and privacy, logistics, situation awareness, and medical care. It was organized within the scope of the European ASSIST-IoT and aerOS projects.  
 Thematic Track organizers:  
 + Chudzikiewicz, Jan, Military University of Technology, Poland  
 + Zieliński, Zbigniew, Military University of Technology, Poland  
 XIV. Knowledge Acquisition and Management  
 Knowledge management is a large multidisciplinary field having its roots in management and AI. Activity of an extended organization should be supported by an organized and optimized flow of knowledge to effectively help all participants in their work. The aim of this Thematic Track was to discuss approaches, techniques and tools in the knowledge acquisition and other knowledge management areas with a focus on contribution of AI for improvement of human-machine intelligence and face the challenges of this century. It shared information and experiences, as well as delved into current trends of methodological, technological and implementation aspects of knowledge management processes.  
 Thematic Track organizers:  
 + Berka, Petr, Prague University of Economics and Business, Czech Republic  
 + Hauke, Krzysztof, Wrocław University of Economics, Poland  
 + Owoc, Mieczyslaw, Wrocław University of Economics, Poland  
 + Pondel, Maciej, Wrocław University of Economics, Poland  
 XV. Meta Environment for Citizens, Business and Entertainment  
 This Thematic Track was focused on the development of Web 3.0, in particular in relation to the use of virtual reality (VR) and augmented reality (AR), on top of emerging technologies such as blockchain and widely understood IoT. The genesis of those ideas and components came from the video game industry, but also, its strong presence in business, medicine, banking, government, etc. All that, placed on top of IoT and other solicited concepts, as well as blockchain technologies, allowed discussion of new ideas related to the amalgamation of the technology aspects. The goals of the track were to expand understanding of current composition of different technologies cross business areas, including those that indicate the initial or minor presence in business and its opportunity to strengthen its presence, discover new areas of development of discussed subjects, as well as redesign well known applications with the new approach and concepts. Moreover, researches and observations related to the use of technology in business, medicine or science in a way that increases efficiency as well as ensuring a qualitative leap were welcome. Thematic Track organizers:  
 + Szumski, Oskar, University of Warsaw, Poland  
 + Tan, Qing, Athabasca University, Canada  
 XVI. Multimedia Applications and Processing  
 Multimedia, computer vision, graphics, and machine learning have become ubiquitous in modern information systems, creating new challenges for detection, recognition, indexing, access, search, retrieval, automated understanding, and processing, resulting in many applications based on image and signal processing, machine learning and various multimedia technologies. Recent advances in pervasive computers, networks, telecommunications, and information technology, along with the proliferation of multimedia mobile devices, have stimulated the rapid development of intelligent applications. These key technologies, using virtual reality, augmented reality, and computational intelligence, are creating a multimedia revolution that significantly impacts a broad spectrum of consumer, business, healthcare, educational and governmental domains. Advancements in AI resulted in the rapid growth of both methods and applications of machine learning approaches in computer vision, image processing, and analysis. Further advances in parallel computing, in the first decade of the 21st century, combined with development of deep neural networks, became a real game-changer in machine vision. This Thematic Track covered a range of AI-based theories, methods, algorithms, technologies, and systems for diversified and heterogeneous digital multimedia, imaging, computer graphics and machine learning areas. Moreover, it provided an opportunity for researchers and professionals to discuss present and future challenges and potential collaboration for future progress in these fields.  
 Thematic Track organizers:  
 + Iwanowski, Marcin, Warsaw University of Technology, Poland  
 + Kwaśnicka, Halina, Wrocław University of Science and Technology, Poland  
 + Śluzek, Andrzej, Khalifa University, United Arab Emirates  
 + Stanescu, Liana, University of Craiova, Romania  
 XVII. Practical Aspects of and Solutions for Software Engineering  
 This Thematic Track was a follow-up to the KKIO series of software engineering conferences, organized, since 1999, under the auspices of the Polish Information Processing Society. The track was focused on emerging challenges and solutions for software engineering industry. A particular interest was related to validation and demonstration of practical applications of the proposed approaches. The track gathered contributions concerned with practical aspects of software engineering, relevant to the IT industry (including challenges and needs), research ideas and solutions aimed at addressing such aspects, and became a place to establish the cooperation between scientific and industrial partners.  
 Thematic Track organizers:  
 + Jarzębowicz, Aleksander, Gdańsk University of Technology, Poland  
 + Przybyłek, Adam, Gdańsk University of Technology, Poland  
 + Staroń, Mirosław, University of Gothenburg, Sweden  
 XVIII. Recent Advances in Information Technology  
 The aim of this Thematic Track was to provide a platform for exchange of ideas between early-stage researchers, in computer science and intelligence systems, Ph.D. students in particular. Furthermore, it provided all participants an opportunity to get feedback on their studies from experienced members of the AI and IT research communities. In fact, this track – as in previous years – played the role of so-called Doctoral Symposium, a well-established tradition of the FedCSIS conference series. Here, special care was taken to provide support and mentoring for young researchers and to facilitate frutiful discussion and exchange of ideas.  
 Thematic Track organizers:  
 + Dedinec, Aleksandra, Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University, North Macedonia  
 + Gil, David, Computer Technology Department, University of Alicante, Spain  
 + Kowalski, Piotr, Systems Research Institute, Polish Academy of Sciences and AGH University of Science and Technology, Poland  
 + Łukasik, Szymon, Systems Research Institute, Polish Academy of Sciences and AGH University of Science and Technology, Poland  
 XIX. Rough Sets: Theory and Applications  
 This Thematic Track discussed research related to the state-of-the-art and future perspectives of rough sets, considered from both a theoretical standpoint and real-world applications. Rough set theory is a versatile mathematical framework that has proven successful in AI, knowledge representation, approximate reasoning, data mining, machine learning, and pattern recognition, among other areas. The track was devoted to all the mentioned areas, with an additional emphasis on problems of modeling AI processes using rough set-based techniques. The track provided an opportunity for interdisciplinary exchange and collaboration among scientists from diverse backgrounds, including mathematics, computer science, statistics, physics, engineering, and social sciences. Moreover, it allowed staying up-to-date with the state-of-the-art in rough set theory and its applications, and to discuss future research directions and opportunities. Last but not least, the track was synchronized with Rough Set School which provided a more fundamental background for the theory and applications of rough sets. Thematic Track organizers:  
 + Artiemjew, Piotr, University of Warmia and Mazury in Olsztyn, Poland  
 + Chelly Dagdia, Zaineb, UVSQ, France  
 + Mani, A., Indian Statistical Institute, India  
 XX. Scalable Computing  
 The world of large-scale computing continuously evolves. The most recent addition to the mix comes from numerous data streams that materialize from exploding number of cheap sensors installed “everywhere”, on the one hand, and ability to capture and study events with systematically increasing granularity, on the other. To address the needs for scaling computational and storage infrastructures, concepts like: edge, fog and dew computing emerged. Novel issues, involved in “pushing computing away from the center”, did not replace open questions that existed in the context of grid and cloud computing. Rather, they added new dimensions of complexity and resulted in the need of addressing scalability across more and more complex ecosystems consisting of individual sensors and micro-computers (e.g. Raspberry PI based systems) as well as supercomputers available within the Cloud (e.g. Cray computers and/or machines for large ML model training, facilitated – for instance – within the MS Azure Cloud). Addressing research questions that arise in individual “parts” as well as across the ecosystem viewed from a holistic perspective, with scalability as the main focus, was the goal of this Thematic Track.  
 Thematic Track organizers:  
 + Gepner, Paweł, Warsaw University of Technology, Poland  
 + Gusev, Marjan, University Ss. Cyril and Methodius, Macedonia  
 + Petcu, Dana, West University of Timisoara, Romania  
 + Ristov, Sashko, University of Innsbruck, Austria  
 + Stencel, Krzysztof, University of Warsaw, Poland  
 Hide Preface to Thematic Tracks    
 Thematic Tracks Regular Papers  
 Psychological Safety, Leadership and Non-Technical Debt in Large Scale Agile Software Development | 8595 | Psychological Safety, Leadership, Non-Technical Debt, Agile, large-scale, Software development | Muhammad Ovais Ahmad, | pages 327–334. | KKIO 
  Comparative Analysis of Word Embedding and Machine Learning Techniques for Classification of Software Developer Communications on Gitter | 6950 | Functional Requirements, Non-Functional Requirements, Deep Learning, Data Imbalance Methods, Feature Selection, Classification Techniques, Word Embedding. | Tumu Akshar, Lov Kumar, Dr. Yogita, Lalita Bhanu Murthy, | pages 335–346. | SEW 
  Dual-Path Image Reconstruction: Bridging Vision Transformer and Perceptual Compressive Sensing Networks | 978 | Deep learning, Perception, | Zakaria Bairi, Kadda Beghdad Bey, Olfa Ben-Ahmed, Abdenour Amamra, Abbas Bradai, | pages 347–354. | MMAP 
  On combining image features and word embeddings for image captioning | 997 | image captioning, neural image feature extractors, | Mateusz Bartosiewicz, Marcin Iwanowski, Martika Wiszniewska, Karolina Frączak, Paweł Leśnowolski, | pages 355–365. | MMAP 
  IoT and Edge Computing using virtualized low-resource integer Machine Learning with support for CNN, ANN, and Decision Trees | 7745 | Virtualization, Virtual Machines, Tiny ML, Sensor Networks, Microservices, Low-power Systems, Vector Operations | Stefan Bosse, | pages 367–376. | IoT 
  Impact of processor frequency scaling on performance and energy consumption for WZ factorization on multicore architecture | 6213 | processor frequency scaling, performance, energy, WZ factorization | Beata Bylina, Jarosław Bylina, Monika Piekarz, | pages 377–383. | CANA 
  Simulating Large-Scale Topographic Terrain Features with Reservoirs and Flowing Water | 2137 | procedural generation, terrain simulation, | Łukasz Błaszczyk, Michalina Mizura, Aleksander Płocharski, Joanna Porter-Sobieraj, | pages 385–392. | MMAP 
  Applying Knowledge Distillation to Improve Weed Mapping With Drones | 960 | Computer Vision, Knowledge Distillation, | Giovanna Castellano, Pasquale De Marinis, Gennaro Vessio, | pages 393–400. | AgriAI 
  Mutual Learning Algorithm for Kidney Cyst, Kidney Tumor and Kidney Stone Diagnosis | 378 | Mutual learning, Teacher-student network, CNN, Model distillation, Kidney Disease, Kidney Cyst, Kidney Tumor, Kidney Stone | Sabrina Chowdhury, Snehasis Mukhopadhyay, Kumpati S. Narendra, | pages 401–410. | DSH 
  A Graph Matching Algorithm to extend Wise Systems with Semantic | 4672 | knowledge-based systems, graph matching, | Abdelhafid Dahhani, Ilham Alloui, Sébastien Monnet, Flavien Vernier, | pages 411–420. | KAM 
  Modelling and Solving the Precedence-Constrained Minimum-Cost Arborescence Problem with Waiting-Times | 6191 | Combinatorial Optimization, Arborescences, Precedence-Constraints | Mauro Dell'Amico, Jafar Jamal, Roberto Montemanni, | pages 421–430. | WCO 
  Optimum Large Sensor Data Filtering, Networking and Computing | 5436 | data acquisition, parallel processing, | Maciej Drozdowski, Joanna Berlińska, Thomas Robertazzi, | pages 431–440. | WSC 
  Resilient s-ACD for Asynchronous Collaborative Solutions of Systems of Linear Equations | 8932 | Asynchronous Methods, Iterative Methods, Numerical Methods, Linear Solver, Collaborative Autonomy, Edge Computing | Lucas Erlandson, Zachary Atkins, Alyson Fox, Christopher Vogl, Agnieszka Miedlar, Colin Ponce, | pages 441–450. | WSC 
  Risk-Based Continuous Quality Control for Software in Legal Metrology | 6171 | automatic quality control, functional identification, risk assessment, legal metrology | Marko Esche, Levin Ho, Martin Nischwitz, Reinhard Meyer, | pages 451–461. | KKIO 
  Classifying Industrial Sectors from German Textual Data with a Domain Adapted Transformer | 6694 | Classification, BERT, Domain Adapted Transformer, computational social sciences, Industrial Sectors | Richard Fechner, Jens Dörpinghaus, Anja Firll, | pages 463–470. | CNLPS 
  Towards Enhancing Open Innovation Efficiency: A Method for Ontological Integration of BPMN and EMMO | 8906 | Open innovation, Elementary Multiperspective Material Ontology, Business Process Modeling and Notations, EMMO, BPMN, Ontology, Ontology integration | Christophe Feltus, Damien Nicolas, Carlos Kavka, Djamel Khadraoui, Salim Belouttar, Natalia Konchakova, Heinz A. Preisig, Peter Klein, | pages 471–479. | KAM 
  Compiler Support for Parallel Evaluation of C++ Constant Expressions | 4268 | compilation, static analysis, | Andrew Gozillon, Hossein Haeri, James Riordan, Paul Keir, | pages 481–490. | WAPL 
  Explainability in RIONA Algorithm Combining Rule Induction and Instance-Based Learning | 4139 | classification, supervised learning, | Grzegorz Góra, Andrzej Skowron, Arkadiusz Wojna, | pages 491–502. | RSTA 
  Estimation of absolute distance and height of people based on monocular view and deep neural networks for edge devices operating in the visible and thermal spectra | 3560 | absolute distance estimation, absolute height estimation, | Jan Gąsienica-Józkowy, Bogusław Cyganek, Mateusz Knapik, Szymon Głogowski, Łukasz Przebinda, | pages 503–511. | MMAP 
  The reception of holidays in social networks: A case study on Twitter | 6718 | social network analysis, Twitter analysis, digital theology, data clustering, practical theology, Jewish-Christian studies, religious and cultural studies | Bettina K. Hakius, | pages 513–522. | AI 
  Is Homomorphic Encryption Feasible for Smart Mobility? | 695 | Smart Mobility, Privacy, Homomorphic Encryption | Anika Hannemann, Erik Buchmann, | pages 523–532. | NEMESIS 
  Efficient exact A* algorithm for the single plant Hydro Unit Commitment problem | 5158 | dynamic programming, Hydro Unit Commitment, | Alexandre Heintzmann, Christian Artigues, Pascale Bendotti, Sandra Ulrich Ngueveu, Cécile Rottner, | pages 533–543. | WCO 
  Clustering Corticosteroids Responsiveness in Sepsis Patients using Game-Theoretic Rough Sets | 9521 | Game-Theoretic Rough Sets, Missing values, Clustering corticosteroid responsiveness, Application, Sepsis patients | Rahma Hellali, Zaineb Chelly Dagdia, Karine Zeitouni, | pages 545–556. | RSTA 
  Tenure and Background of CIOs in Germany: Influencing Factors and International Comparison | 5836 | CIO, Chief Information Officer, | Patrick Hillebrand, Markus Westner, | pages 557–566. | ISM 
  A reusability-oriented use-case model specification language | 5469 | requirement specification, metamodel, | Bogumiła Hnatkowska, Piotr Zabawa, | pages 567–576. | KKIO 
  AI-based Maize and Weeds detection on the edge with CornWeed Dataset | 2125 | CornWeed dataset, Maize weed detection, | Naeem Iqbal, Christoph Manss, Christian Scholz, Daniel Koenig, Matthias Igelbrink, Arno Ruckelshausen, | pages 577–584. | AgriAI 
  BIGOS - Benchmark Intended Grouping of Open Speech Corpora for Polish Automatic Speech Recognition | 1609 | automatic speech recognition, asr, | Michał Junczyk, | pages 585–590. | CNLPS 
  MLP-COMET-based decision model re-identification for continuous decision-making in the complex network environment | 5438 | MCDA, MCDM, | Bartłomiej Kizielewicz, Jakub Więckowski, Jarosław Jankowski, | pages 591–602. | ISM 
  List Of Pareto Optimal Solutions of a Biobjective Shortest Path Problem | 3718 | bicriterion optimization, Pareto optimal solutions, | Lasko Laskov, Marin Marinov, | pages 603–613. | WCO 
  Comparative Analysis of Exact, Heuristic and Metaheuristic Algorithms for Flexible Assembly Scheduling | 2715 | flexible assembly scheduling, mathematical programming, | Octavian Maghiar, Teodora Selea, Adrian Copie, Flavia Micota, Mircea Marin, | pages 615–625. | WCO 
  Current Trends in Automated Test Case Generation | 9829 | software testing, test case generation, test data generation, papers survey | Tomas Potuzak, Richard Lipka, | pages 627–636. | SEW 
  Analysis of a GPT-3 chatbot with respect to its input in a sales dialogue | 3513 | GPT-3 chatbot, sales dialogue, | Julian Premm, Hagen Peukert, Dennis Rössel, Mareike Silber, | pages 637–647. | ISM 
  Standards-based Cyber Threat Intelligence sharing using private Blockchains | 6880 | Blockchain, Cyber Threat Intelligence, Cyber Defense, TAXII | Kimon-Antonios Provatas, Ioannis Tzannetos, Vassilios Vescoukis, | pages 649–656. | NEMESIS 
  Open Vocabulary Keyword Spotting with Small-Footprint ASR-based Architecture and Language Models | 8594 | keyword spotting, open vocabulary keyword spotting, query-by-text, automatic speech recognition, language model | Mikołaj Pudo, Mateusz Wosik, Artur Janicki, | pages 657–666. | CNLPS 
  Algorithmic Handling of Time Expanded Networks | 6717 | Network Flows, Routing, Scheduling, Combinatorial Optimization, Integer Linear Programming | Alain Quilliot, Jose-Luis Figueroa, Hélène Toussaint, | pages 667–676. | WCO 
  Factors for Effective Communication of IT Costs and IT Business Value | 7224 | Effective Communication, Perception, Success Factors, IT Costs, IT Business Value, Business-IT Alignment, COBIT | Constanze Riedinger, Melanie Huber, Niculin Prinz, | pages 677–687. | ISM 
  An Enhancement of Reinforcement Learning by Scheduling with Learning Effects | 4564 | Scheduling, Learning effect, | Radosław Rudek, | pages 689–697. | CANA 
  Multi-queue service for task scheduling based on data availability | 8957 | multi-queue, task scheduling, distributed systems, large-scale computing, grid computing | Kamil Rybiński, Michał Śmiałek, | pages 699–709. | KKIO 
  Semi-persistent services for IoT networks using RESTful approach | 287 | address-free networking, zero-configuration networking, P2P broadcasting networks, BLE mesh, ad-hoc networks, RESTful approach | Jarogniew Rykowski, | pages 711–720. | IoT 
  Exception Handling in Programmable Controllers with Denotational Model | 5651 | semantic model, programmable controllers, | Jan Sadolewski, Bartosz Trybus, | pages 721–730. | CN 
  An Innovative Drastic Metric for Ranking Similarity in Decision-Making Problems | 6502 | a true metric, new distance metric, decision-making, distance of rankings | Wojciech Sałabun, Andrii Shekhovtsov, | pages 731–738. | ISM 
  Classifying Speech Acts in Political Communication: A Transformer-based Approach with Weak Supervision and Active Learning | 3485 | Speech Act Classification, Political Communication, | Klaus Schmidt, Andreas Niekler, Cathleen Kantner, Manuel Burghardt, | pages 739–748. | AI 
  Investigating the Effect of Partial and Real-Time Feedback in INMAP Code-To-Architecture Mapping | 5070 | Software Architecture Conformance, Automated Source Code Mapping, | Zipani Tom Sinkala, Sebastian Herold, | pages 749–758. | SEW 
  Hashtag Discernability - Competitiveness Study of Graph Spectral and Other Clustering Methods | 2398 | clustering, graph spectral clustering, | Bartłomiej Starosta, Mieczysław Kłopotek, Slawomir T. Wierzchon, Dariusz Czerski, | pages 759–767. | CNLPS 
  An Experimental Framework for Secure and Reliable Data Streams Distribution in Federated IoT Environments | 3882 | Internet of Things, Blockchain, | Jakub Sychowiec, Zbigniew Zielinski, | pages 769–780. | IoT 
  On the Applicability of the Pareto Principle to Source-Code Growth in Open Source Projects | 5221 | software evolution, the Pareto principle, | Korneliusz Szymański, Mirosław Ochodek, | pages 781–789. | KKIO 
  Scheduling Jobs to Minimize a Convex Function of Resource Usage | 4164 | scheduling, load balancing, | Evelin Szögi, Tamas Kis, | pages 791–799. | WCO 
  Target search with an allocation of search effort to overlapping cones of observation | 7181 | Moving Target search, Dynamic Programming, FAB algorithm, Overlapping Observation Cones | Hugo Vaillaud, Claire Hanen, Emmanuel Hyon, Cyrille Enderli, | pages 801–811. | WCO 
  Exploring the Prevalence of Anti-patterns in the Application of Scrum in Software Development Organizations | 9562 | Scrum, Agile, Anti-patterns | Michał Wróbel, Dorota Przała, Paweł Weichbroth, | pages 813–822. | KKIO 
  Analysis of the Impact of Data Augmentation on the Performance of Deep Learning Models in Multispectral Food Authenticity Identification | 3643 | food safety, deep learning, | Yaru Zhang, Arif Yilmaz, Mirela Popa, Christopher Brewster, | pages 823–832. | AgriAI 
  Filtering Decision Rules Driven by Sequential Forward and Backward Selection of Attributes: An Illustrative Example in Stylometric Domain | 7295 | selection of attributes, decision rules, ranking of attributes | Beata Zielosko, Urszula Stańczyk, Kamil Jabloński, | pages 833–842. | RSTA 
  Automatic Colorization of Digital Movies using Decolorization Models and SSIM Index | 3017 | monochrome movies, re-colorization, | Andrzej Śluzek, Marcin Dudziński, Tomasz Świsłocki, | pages 843–853. | MMAP 
  Thematic Tracks Short Papers  
 IoT for the Maritime Industry: Challenges and Emerging Applications | 3625 | Internet of things, maritime industry, | Sheraz Aslam, Herodotos Herodotou, Eduardo Garro, Alvaro Martinez Romero, Maria Angeles Burgos, Alessandro Cassera, George Papas, Petros Dias, Michalis Michaelides, | pages 855–858. | IoT 
  Binary Classification of Agricultural Crops Using Sentinel Satellite Data and Machine Learning Techniques | 1703 | Crop Classification, AgriAI, | Paolo Bertellini, Gianluca D'Addese, Giorgia Franchini, Simone Parisi, Carmelo Scribano, Daniele Zanirato, Marko Bertogna, | pages 859–864. | AgriAI 
  Experiments on software error prediction using Decision Tree and Random Forest algorithms | 363 | error prediction, decision tree, random forest, PROMISE repository | Ilona Bluemke, Paweł Borsukiewicz, | pages 865–869. | SEW 
  Diagnosing Machine Learning Problems in Federated Learning Systems: A Case Study | 722 | Federated Learning, System Monitoring, ML Diagnosis, Exploding Gradients, Machine Learning, Topology | Karolina Bogacka, Anastasiya Danilenka, Katarzyna Wasielewska-Michniewska, | pages 871–876. | DS 
  Use of traffic sampling in anomaly detection for high-throughput network links | 6381 | computer network, anomaly detection, ISP, network traffic sampling, cybersecurity | Marek Bolanowski, Andrzej Paszkiewicz, Hubert Mazur, | pages 877–882. | CN 
  L1-Norm Principal Component Analysis Using Quaternion Rotations | 3368 | L1-norm, PCA, | Adam Borowicz, | pages 883–888. | WCO 
  Efficient Deep Learning Approach for Olive Disease Classification | 4794 | Convolutional Neural Networks, EfficientNet, | Antonio Bruno, Davide Moroni, Massimo Martinelli, | pages 889–894. | AgriAI 
  The scalability in terms of the time and the energy for several matrix factorizations on a multicore machine | 3506 | scalability, energy, | Beata Bylina, Monika Piekarz, | pages 895–900. | CANA 
  Selection of floating photovoltaic system considering strong sustainability paradigm using SSP-COPRAS method | 492 | Floating photovoltaic systems selection, Multi-criteria decision making, SSP-COPRAS, Strong sustainability paradigm | Aleksandra Bączkiewicz, Jarosław Wątróbski, | pages 901–905. | ISM 
  Urban scene semantic segmentation using the U-Net model | 3686 | image segmentation, semantic segmentation, | Marcin Ciecholewski, | pages 907–912. | MMAP 
  The Effects of Native Language on Requirements Quality | 9537 | requirements, native langauge, quality of requirements, natural language, errors | Fayona Cowperthwaite, Jennifer Horkoff, Sylwia Kopczyńska, | pages 913–917. | KKIO 
  One-shot federated learning with self-adversarial data | 1102 | Federated learning, One-shot learning, | Anastasiya Danilenka, Karolina Bogacka, Katarzyna Wasielewska-Michniewska, | pages 919–924. | DS 
  Mitigating the effects of non-IID data in federated learning with a self-adversarial balancing method | 6549 | federated learning, non-IID data, performance, adversarial federated learning | Anastasiya Danilenka, | pages 925–930. | DS 
  Real-time Communication Model for IoT Systems | 8513 | realtime routing, tasks scheduling, Internet of Things, communication protocols, realtime system | Stanisław Deniziak, Mirosław Płaza, Łukasz Arcab, | pages 931–936. | IoT 
  Review of Automated Code Refactoring of C# Programs | 7277 | code refactoring, unit testing, code quality, code and test maintenance, C# | Anna Derezinska, Dawid Sygocki, | pages 937–941. | KKIO 
  Employee Technostress in South Africa’s Hybrid Workplaces: Causes and Coping Mechanisms | 2907 | technostress, hybrid workplaces, | Shelley Dowrie, Jean-Paul Van Belle, Marita Turpin, | pages 943–947. | ISM 
  Improving Domain-Specific Retrieval by NLI Fine-Tuning | 7569 | natural language inference, multilingual large language models, contrastive fine-tuning, information retrieval | Roman Dusek, Aleksander Wawer, Christopher Galias, Lidia Wojciechowska, | pages 949–953. | CNLPS 
  Ant Colony Optimization for Workforce Planning with Hybridization | 9586 | Workforce Planning, Ant Colony Optimization, Metaheuristics, Hybrid Method, Local Search | Stefka Fidanova, Maria Ganzha, | pages 955–959. | WCO 
  Future and Backward Exploration of XR Environments | 2375 | Exploration, Semantic Web, | Jakub Flotyński, Paweł Sobociński, Michał Śliwicki, Mikołaj Maik, | pages 961–965. | MMAP 
  Improving the Performance of Multiscene Marketing Video Content through its Dynamics Adjustments | 7106 | video message, efficiency, dynamics of a video message, eyetracking, marketing | Kacper Fornalczyk, Kamil Bortko, Aneta Disterheft, Jarosław Jankowski, | pages 967–972. | ISM 
  Performance assessment of OpenMP constructs and benchmarks using modern compilers and multi-core CPUs | 7822 | benchmarking OpenMP constructs, parallel programming, multi-core CPU, performance investigation, benchmarks | Bartłomiej Gawrych, Pawel Czarnul, | pages 973–978. | WSC 
  A short note on computing permutations | 5568 | algorithms, recursion, | Paweł Gburzyński, Janusz Zalewski, | pages 979–982. | SEW 
  Association Rule Mining for Requirement Elicitation Techniques in IT Projects | 4831 | associations rules mining, requirements elicitation, | Denys Gobov, Nikolai Sokolovskiy, | pages 983–987. | KKIO 
  Potentials and Challenges of Gamification in Recruiting | 4012 | Gamification, Recruiting, | Ralf Haerting, Maren Gerst, Jasmin Zerrer, | pages 989–994. | MECBE 
  Recognition of Weeds in Cornfields | 2610 | weed recognition, corn field, | Gábor Hartyányi, Laszlo Czuni, | pages 995–999. | AgriAI 
  Price-Shaped Optimal Water Reflow in Prosumer Energy Cascade Hydro Plants | 6642 | hydro plants, green energy, optimal control, networked systems, time-delay systems | Przemysław Ignaciuk, Michał Morawski, | pages 1001–1005. | CN 
  Semi-Active Control of a Shear Building based on Reinforcement Learning: Robustness to measurement noise and model error | 8946 | structural control, semi-active control, reinforcement learning, tuned mass damper | Aleksandra Jedlińska, Dominik Pisarski, Grzegorz Mikułowski, Bartłomiej Błachowski, Łukasz Jankowski, | pages 1007–1010. | SEW 
  Gender-aware speaker's emotion recognition based on 1-D and 2-D features | 4485 | emotion recognition, gender recognition, | Włodzimierz Kasprzak, Mateusz Hryciów, | pages 1011–1015. | MMAP 
  Detecting type of hearing loss with different AI classification methods: a performance review | 3083 | hearing loss, classification, | Michał Kassjański, Marcin Kulawiak, Tomasz Przewoźny, Dmitry Tretiakow, Jagoda Kuryłowicz, Andrzej Molisz, Krzysztof Koźmiński, Aleksandra Kwaśniewska, Paulina Mierzwińska-Dolny, Miłosz Grono, | pages 1017–1022. | DS 
  Dynamic SITCOM: an innovative approach to re-identify social network evaluation models | 539 | Complex networks, SITCOM, MCDA, MCDM, Centrality measures, Re-identification, Similarity | Bartłomiej Kizielewicz, Jarosław Jankowski, | pages 1023–1027. | ISM 
  IoTrust - a HW/SW framework supporting security core baseline features for IoT | 6946 | IoT, cybersecurity, SoC, TEE, HWRoT | Mateusz Korona, Bartosz Zabołotny, Fryderyk Kozioł, Mateusz Biernacki, Radosław Giermakowski, Paweł Rurka, Marta Chmiel, Mariusz Rawski, | pages 1029–1034. | NEMESIS 
  On Gower Similarity Coefficient and Missing Values | 3575 | Gower similarity coefficient, mixed-type attributes, | Marzena Kryszkiewicz, | pages 1035–1040. | RSTA 
  Mechanism for detecting cause-and-effect relationships in court judgments | 4827 | natural language processing, machine learning, | Łukasz Kurant, | pages 1041–1046. | CNLPS 
  Expectation-Maximization Algorithms for Gaussian Mixture Models Using Linear Algebra Libraries on Parallel Shared-Memory Systems | 9859 | Gaussian mixture models, EM algorithm, parallel algorithms, OpenMP, BLAS | Wojciech Kwedlo, | pages 1047–1052. | WSC 
  Performance Analysis of a 3D Elliptic Solver on Intel Xeon Computer System | 5683 | parallel algorithm, PCG method, | Ivan Lirkov, Marcin Paprzycki, Maria Ganzha, | pages 1053–1058. | CANA 
  Controllability for English-Ukrainian Machine Translation by Using Style Transfer Techniques | 895 | Machine Translation, Controllability, NLG, Style Transfer | Daniil Maksymenko, Nataliia Saichyshyna, Marcin Paprzycki, Maria Ganzha, Oleksii Turuta, Mirela Alhasani, | pages 1059–1068. | CNLPS 
  EpiDoc Data Matching for Federated Information Retrieval in the Humanities | 1515 | federated information retrieval, EpiDoc, | Sylvia Melzer, Meike Klettke, Franziska Weise, Kaja Harter-Uibopuu, Ralf Möller, | pages 1069–1074. | AI 
  VICRA: Variance-Invariance-Covariance Regularization for Attack Prediction | 1151 | Self-supervised learning, Deep Learning, | Aditya Srinivas Menon, Gouri Nair, | pages 1075–1080. | NEMESIS 
  Segmentation Methods Evaluation on Grapevine Leaf Diseases | 7053 | vine disease detection, remote sensing, deep learning | Szilard Molnar, Levente Tamas, | pages 1081–1085. | AgriAI 
  Automatic speaker's age classification in the Common Voice database | 2483 | speaker classification, Common Voice database, | Adam Nowakowski, Włodzimierz Kasprzak, | pages 1087–1091. | MMAP 
  Sensitivity Study of a Large-scale Air Pollution Model on the Bulgarian Petascale Supercomputer Discoverer | 5063 | sensitivity analysis, air pollution, | Tzvetan Ostromsky, Ivan Dimov, Rayna Georgieva, Venelin Todorov, | pages 1093–1100. | WCO 
  Inscrutability versus Privacy and Automation versus Labor in Human-Centered AI: Approaching Ethical Paradoxes and Directions for Research | 7504 | Critical Theory, ethical paradox, inscrutability of AI technology, privacy violation, labor substitution | Hagen Peukert, | pages 1101–1105. | AI 
  New measures of algorithms quality for permutation flow-shop scheduling problem | 7072 | Permutation flow-shop scheduling problem, Makespan, ART.NEH, ARID | Radosław Puka, Iwona Skalna, Tomasz Derlecki, | pages 1107–1111. | WCO 
  PSE for Analysis of 3D Tomographic Images in Materials Science | 669 | Tomographic Images, Problem Solving Environment (PSE), Materials Science, GPUs | Paulo Quaresma, Pedro Medeiros, Adriano Lopes, Alexandre Velhinho | pages 1113–1117. | MMAP 
  Path Length-Driven Hypergraph Partitioning: An Integer Programming Approach | 592 | Hypergraph partitioning, Critical path, multi-level scheme | Julien Rodriguez, Francois Galea, François Pellegrini, Lilia Zaourar, | pages 1119–1123. | WCO 
  Laundry Cluster Management Using Cloud | 2510 | cloud computing, washing machines, | Mateusz Salach, Bartosz Trybus, Bartosz Pawłowicz, Marcin Hubacz, | pages 1125–1129. | CN 
  Text embeddings and clustering for characterizing online communities on Reddit | 6275 | data mining, natural language processing, Reddit, clustering, text embedding, social media, online social networks | Jan Sawicki, | pages 1131–1136. | DS 
  Runge-Kutta Method and WSM6 Microphysics for Weather Prediction on Hybrid Parallel Platform | 7199 | Runge-Kutta Method, WSM6 microphysics, Hybrid Parallel Algorithms, Multi-GPU Algorithms, High performance Computing | Hércules C. Silva, Marco A. Stefanes, Vinícius Capistrano, | pages 1137–1141. | WSC 
  Incident Detection with Pruned Residual Multilayer Perceptron Networks | 6021 | IoT, Cybersecurity, Intrusion Detection System, Residual Neural Networks | Mohamad Soubra, Marek Kisiel-Dorohinicki, Marcin Kurdziel, Marek Zachara, | pages 1143–1148. | NEMESIS 
  Optimizing Machine Translation for Virtual Assistants: Multi-Variant Generation with VerbNet and Conditional Beam Search | 8601 | machine translation, intelligent virtual assistants, natural language understanding | Marcin Sowański, Artur Janicki, | pages 1149–1154. | DS 
  Performance of Portable Sparse Matrix-Vector Product Implemented Using OpenACC | 9640 | sparse matrices, storage formats, matrix-vector multiplication, OpenACC, performance | Kinga Stec, Przemyslaw Stpiczynski, | pages 1155–1160. | CANA 
  Using graph solutions to identify "troll farms" and fake news propagation channels | 2738 | fake news, MIB, | Patryk Sulej, Krzysztof Hryniów, | pages 1161–1166. | NEMESIS 
  A Stochastic Optimization Technique for UNI-DEM framework | 8893 | Stochastic optimization methods, Monte Carlo lattice approach, Sensitivity analysis, Air pollution modelling | Venelin Todorov, Slavi Georgiev, Ivan Dimov, Tzvetan Ostromsky, | pages 1167–1172. | WCO 
  Extremal algebraic graphs, quadratic multivariate public keys and temporal rules | 1191 | Multivariate Cryptography, Extremal Graph theory, | Vasyl Ustimenko, Aneta Wroblewska, | pages 1173–1178. | NEMESIS 
  On Extremal Algebraic Graphs and implementations of new cubic Multivariate Public Keys | 7763 | Multivariate Cryptography, Public Keys, Multivariate quadratic rules, Graph based Cryptography | Vasyl Ustimenko, Tymoteusz Chojecki, Michal Klisowski, | pages 1179–1184. | NEMESIS 
  Comparing Performance of Machine Learning Libraries across Computing Platforms | 3594 | Machine Learning, Embedded Systems, | Pedro Vicente, Pedro M. Santos, Barikisu Asulba, Nuno Martins, Joana Sousa, Luís Almeida, | pages 1185–1189. | DE 
  Deep Neural Networks application for Cup-to-Disc ratio estimation in eye fundus images | 944 | Deep neural network, Image preprocessing, | Sandra Virbukaitė, Jolita Bernatavičienė, | pages 1191–1195. | MMAP 
  On some concept lattice of social choice functions | 3892 | formal concept analysis, knowledge modeling, | Piotr Wasilewski, Janusz Kacprzyk, Sławomir Zadrożny, | pages 1197–1203. | RSTA 
  Postquantum symmetric cryptography inspired by neural networks | 9901 | private-key cryptography, postquantum cryptography, neural networks | Wojciech Węgrzynek, Paweł Topa, | pages 1205–1210. | NEMESIS 
  Adding Linguistic Information to Transformer Models Improves Biomedical Event Detection? | 2076 | Biomedical Event Extraction, Event Detection, | Laura Zanella, Yannick Toussaint, | pages 1211–1216. | CNLPS 
  Sensitivity analysis of the criteria weights used in selected MCDA methods in the multi-criteria assessment of banking services in Poland in 2022 | 3745 | assessment of banking websites, multi-criteria methods, | Marek Zborowski, Witold Chmielarz, | pages 1217–1222. | MECBE 
  Let's estimate all parameters as probabilities: Precise estimation using Chebyshev's inequality, Bernoulli distribution, and Monte Carlo simulations | 1144 | estimate as a probability, Monte Carlo simulation, | Lubomír Štěpánek, Filip Habarta, Ivana Malá, Luboš Marek, | pages 1223–1227. | CANA 
  A lower bound for proportion of visibility polygon's surface to entire polygon's surface: Estimated by Art Gallery Problem and proven that cannot be greatly improved | 4335 | visibility polygon, visibility region, | Lubomír Štěpánek, Filip Habarta, Ivana Malá, Luboš Marek, | pages 1229–1233. | WCO 
  Social Media, Topic Modeling and Sentiment Analysis in Municipal Decision Support | 1479 | smart cities, topic modeling, | Miloš Švaňa, | pages 1235–1239. | KAM 
  Competitions  
 PolEval  
 Preface to PolEval   
 PolEval  is an annual NLP challenge organized since 2017. The choice of the name of the challenge was deliberate: as most research concentrates on the most popular languages (especially English), the aim of PolEval was to promote work on processing Polish. By focusing on Polish, it actively promotes the creation of new resources in this language, facilitates further research and contributes to creating new and improved methods and models for Polish.  
 The goal of PolEval is thus to:  
 develop established procedures for evaluating systems solving a wide range of tasks in NLP, 
  create annotated datasets that can be used for training and evaluation of systems, 
  objectively compare systems performing various tasks in the field of natural language processing, 
  bring researchers from the scientific and business communities closer together and exchanging knowledge between them, 
  facilitate popularization of NLP issues in the context of the Polish language. 
  To achieve these goals, PolEval proposes a well-formulated task framework in which the scope, input data, expected output data, evaluation methods training and test data are prepared by the organizers. This way the challenge aims to be a platform for objective comparison of methods, models and systems for processing Polish.  
 Hide Preface to PolEval    
 PolEval 2022/23 Challenge Tasks and Results | 5627 | poleval, shared task, | Łukasz Kobyliński, Maciej Ogrodniczuk, Piotr Rybak, Piotr Przybyła, Piotr Pęzik, Agnieszka Mikołajczyk, Wojciech Janowski, Michał Marcińczuk, Aleksander Smywiński-Pohl, | pages 1243–1250. | CNLPS_PolEval 
  Punctuation Prediction for Polish Texts using Transformers | 1633 | poleval, punctuation prediction, | Jakub Pokrywka, | pages 1251–1254. | CNLPS_PolEval 
  Abbreviation Disambiguation in Polish Press News Using Encoder-Decoder Models | 839 | poleval, abbreviation disambiguation, | Krzysztof Wróbel, Jakub Karbowski, Paweł Lewkowicz, | pages 1255–1264. | CNLPS_PolEval 
  Passage Retrieval of Polish Texts Using OKAPI BM25 and an Ensemble of Cross Encoders | 9253 | poleval, passage retrieval, question answering | Jakub Pokrywka, | pages 1265–1269. | CNLPS_PolEval 
  Hybrid retrievers with generative re-rankers | 8119 | poleval, passage retrieval, question answering | Marek Kozłowski, | pages 1271–1276. | CNLPS_PolEval 
  Multi-index Retrieve and Rerank with Sequence-to-Sequence Model | 3900 | poleval, passage retrieval, | Konrad Wojtasik, | pages 1277–1279. | CNLPS_PolEval 
  Passage Retrieval in question answering systems in Polish language | 586 | passage retrieval, information retrieval, | Anna Pacanowska, | pages 1281–1286. | CNLPS_PolEval 
  Cybersecurity Threat Detection in the Behavior of IoT Devices  
 Preface to Cybersecurity Threat Detection in the Behavior of IoT Devices   
 Cybersecurity  Threat Detection in the Behavior of IoT Devices was the 9th competition organized in association with the FedCSIS conference series at KnowledgePit.ai. The goal was to detect attacks on IoT devices on the basis of data provided by Efigo company, describing the changing behavior of devices, and known moments of cyberattack attempts. The data set was generated as a part of a SPINET project aiming at improving the cybersecurity of IoT device networks.  
 The increasing significance of many IoT device applications motivates scientists to develop techniques for cyber safety improvement in many ways. In our case, based on the changing device behavior, it was expected that the profile of processes running on the device should change during the attack attempts.  
 The competition data was collected in a simulated environment - IoT devices were emulated in a separated network, where attacking servers were also plugged in. The scenario of attacks was known, so it was possible to tag the behavioral data as “normal” and “unusual”. Based on that information participants tried to develop classification models to predict whether the device is being attacked or not.  
 The top four competitor groups were invited to submit a paper describing their solutions to our special event at the FedCSIS 2023 conference. These papers are included in this chapter of the conference proceedings and are preceded by a paper describing in detail the competition, authored by the organizers. The most of presented approaches were based on gradient-boosting algorithms. That is not surprising - such models play an essential role in different fields of application. However, they are not so easy to interpret which may cause difficulties in better understanding the nature of IoT devices' behavior change during cyberattacks.  
 Andrzej Janusz   
 Marcin Michalak   
 Hide Preface to Cybersecurity Threat Detection in the Behavior of IoT Devices    
 Cybersecurity Threat Detection in the Behavior of IoT Devices: Analysis of Data Mining Competition Results | 3089 | Keywords—data science competitions, KnowledgePit.ai platform, | Michał Czerwiński, Marcin Michalak, Piotr Biczyk, Błażej Adamczyk, Daniel Iwanicki, Iwona Kostorz, Maksym Brzęczek, Andrzej Janusz, Marek Hermansa, Łukasz Wawrowski, Artur Kozłowski, | pages 1289–1293. | FedCSIS 
  Tackling Variable-length Sequences with High-cardinality Features in Cyber-attack Detection | 2385 | Internet of Things, Cybersecurity, | Chang Lin, | pages 1295–1299. | FedCSIS 
  Beating Gradient Boosting: Target-Guided Binning for Massively Scalable Classification in Real-Time | 7166 | gradient boosting, feature selection, predictive binning, cybersecurity | Dymitr Ruta, Ming Liu, Ling Cen, | pages 1301–1306. | FedCSIS 
  Spotting Cyber Breaches in IoT Devices | 7136 | cybersecurity, data mining competition, LightGBM | Sławomir Pioroński, Tomasz Górecki, | pages 1307–1310. | FedCSIS 
  Gradient boosting models for cybersecurity threat detection with aggregated time series features | 4457 | Cybersecurity threat detection, Gradient Boosting Trees, | Ming Liu, Ling Cen, Dymitr Ruta, | pages 1311–1315. | FedCSIS 
  Center for Artificial Intelligence Challenge on Conversational AI Correctness  
 Preface to Center for Artificial Intelligence Challenge on Conversational AI Correctness   
 Center  Center for Artificial Intelligence Challenge on Conversational AI Correctness was organized as part of the 1st Symposium on Challenges for Natural Language Processing. The goal of this competition was to develop Natural Language Understanding models that are robust against speech recognition errors.  
 Regardless of near-human accuracy of Automatic Speech Recognition in general-purpose transcription tasks, speech recognition errors can significantly deteriorate the performance of a Natural Language Understanding model that follows the speech-to-text module in a virtual assistant. The problem is even more apparent when an ASR system from an external vendor is used as an integral part of a conversational system without any further adaptation. The contestants were expected to develop Natural Language Understanding models that maintain satisfactory performance despite the presence of ASR errors in the input.  
 The data for the competition consist of natural language utterances along with semantic frames that represent the commands targeted at a virtual assistant. The approach used to prepare the data for the challenge was meant to promote models robust to various types of errors in the input, making it impossible to solve the task by simply learning a shallow mapping from incorrectly recognized words to the correct ones. It reflects real-world scenarios where the NLU system is presented with inputs that exhibit various disturbances due to changes in the ASR model, acoustic conditions, speaker variation, and other causes.  
 This chapter includes the paper discussing the objectives, evaluation rules and results of the competition, authored by the organizers followed by the detailed description of the leading solution contributed by the winners of the challenge.  
 Hide Preface to Center for Artificial Intelligence Challenge on Conversational AI Correctness    
 Center for Artificial Intelligence Challenge on Conversational AI Correctness | 6058 | natural language understanding, automatic speech recognition, spoken dialogue systems, conversational AI | Marek Kubis, Paweł Skórzewski, Marcin Sowański, Tomasz Ziętkiewicz, | pages 1319–1324. | CNLPS_PolEval 
  Boosting conversational AI correctness by accounting for ASR errors using a sequence to sequence model | 9627 | CAICCAIC challenge, Conversational AI, Spoken Dialogue Systems | Szymon Jadczak, Rafał Jaworski, | pages 1325–1328. | CNLPS_PolEval 
  Temporal Image Caption Retrieval Competition  
 Preface to Temporal Image Caption Retrieval Competition   
 Temporal  Image Caption Retrieval Competition was organized as part of the 1st Symposium on Challenges for Natural Language Processing. The goal of the competition was, given a picture from a newspaper and the newspaper's publication daily date, to retrieve a picture caption from a given caption set.  
 Multimodal models, especially combining vision and text, are gaining great recognition. One such multimodal challenge is Text-Image retrieval, which is to retrieve an image for a text query or retrieve a text for a given image. In this challenge, we introduce a task in the Text-Image retrieval setup, additionally extending the modalities with temporal data.  
 Language models rarely utilize any input information except for text. E.g additional data could be a text domain, document timestamp, website URL, or other metadata information. However, models trained solely on text data may be limited in usage. Additional temporal information is useful when factual knowledge is required, but the facts change over time.  
 The presented task is based on the Chronicling America [ Lee, B. C. G., Mears, J., Jakeway, E., Ferriter, M., Adams, C., Yarasavage, N., … & Weld, D. S.  (2020). The Newspaper Navigator Dataset: Extracting Headlines and Visual Content from 16 Million Historic Newspaper Pages in Chronicling America.  In Proceedings of the 29th ACM International Conference on Information & Knowledge Management (CIKM '20). Association for Computing Machinery, New York, NY, USA, 3055–3062.  ] and Challenging America [ Pokrywka, J., Gralinski, F., Jassem, K., Kaczmarek, K., Jurkiewicz, K., & Wierzchoń, P.  (2022, July). Challenging America: Modeling language in longer time scales.  In Findings of the Association for Computational Linguistics: NAACL 2022 ( pp. 737-749  ).] projects. Chronicling America is an open database of over 16 million pages of digitized historic American newspapers covering 274 years. Challenging America is a set of temporal challenges built from the Chronicling America dataset.  
 This chapter includes the paper discussing the objectives, evaluation rules and results of the competition, authored by the organizers followed by the detailed description of the leading solution contributed by the winners of the challenge.  
 Hide Preface to Cybersecurity Threat Detection in the Behavior of IoT Devices    
 Temporal Image Caption Retrieval Competition – Description and Results | 7280 | shared task, diachronic linguistics, challenging america | Jakub Pokrywka, Piotr Wierzchoń, Kornel Weryszko, Krzysztof Jassem, | pages 1331–1336. | CNLPS_PolEval 
  Multimodal Neural Networks in the Problem of Captioning Images in Newspapers | 4192 | TICRC, CNLPS, | Patryk Kaszuba, | pages 1337–1340. | CNLPS_PolEval 
    
 TeXnical Editor: Aleksander Denisiuk   
  E-mail: denisiuk@matman.uwm.edu.pl   
  Phone/fax: +48-89-5246089

94. FUN_0 conference:
Black Friday 2024: 50 Ways to Save on Online Learning    
 View      
 Close    
  
   Class Central     Courses  Class Central   
     
 Rankings 
  Collections 
   
 Subjects   
 View all    
 Computer Science 
  Health & Medicine 
  Mathematics 
  Business 
  Humanities 
  Engineering 
  Science 
  Education & Teaching 
  Social Sciences 
  Art & Design 
  Data Science 
  Programming 
  Personal Development 
  Information Security (InfoSec) 
  View all Subjects   
 Universities 
  The Report 
   
 Courses from 1000+ universities   
   
   Rankings   

 Best Courses   
   
 Best of All Time 
  Best of the Year 2022 
  Best of the Year 2021 
   
 Most Popular Courses   
   
 Most Popular of All Time 
  Most Popular of the Year 2024 
  Most Popular of the Year 2023 

   Collections   

   Computer Science   
   
 Artificial Intelligence 
  Algorithms and Data Structures 
  Internet of Things 
  Information Technology 
  Computer Networking 
  Machine Learning 
  DevOps 
  Deep Learning 
  Cryptography 
  Quantum Computing 
  Human-Computer Interaction (HCI) 
  Distributed Systems 
  Blockchain Development 
  Operating Systems 
  Computer Graphics 
  Automata Theory 
  Compilers 
  SCADA 
  Mainframe 
  Digital Image Processing 
  View all Computer Science 

   Health & Medicine   
   
 Nutrition & Wellness 
  Disease & Disorders 
  Public Health 
  Health Care 
  Nursing 
  Anatomy 
  Veterinary Science 
  Continuing Medical Education (CME) 
  Blood Pressure 
  Wellbeing 
  Women's Health 
  Hygiene 
  Healthcare Innovation 
  Music Therapy 
  Holistic Health 
  Ayurveda 
  Herbalism 
  Massage Therapy 
  View all Health & Medicine 

   Mathematics   
   
 Statistics & Probability 
  Foundations of Mathematics 
  Calculus 
  Discrete Mathematics 
  Trigonometry 
  Geometry 
  Algebra 
  Precalculus 
  Number Theory 
  Combinatorics 
  Mathematical logic 
  Linear Programming 
  Graph Theory 
  Set Theory 
  Group Theory 
  Differential Equations 
  Polynomials 
  Integration 
  Mathematical Analysis 
  Mathematical Thinking 
  View all Mathematics 

   Business   
   
 Management & Leadership 
  Finance 
  Entrepreneurship 
  Marketing 
  Strategic Management 
  Industry Specific 
  Business Intelligence 
  Accounting 
  Human Resources 
  Project Management 
  Sales 
  Design Thinking 
  Business Software 
  Customer Service 
  Nonprofit Management 
  Innovation 
  Operations Management 
  Corporate Governance 
  Business Plan 
  Business Proposal 
  View all Business 

   Humanities   
   
 History 
  Literature 
  Language Learning 
  Grammar & Writing 
  Philosophy 
  Religion 
  ESL 
  Culture 
  Sports 
  Journalism 
  Ethics 
  Linguistics 
  Food 
  Library Science 
  Reading 
  Crisis Management 
  Games 
  Emergency Management 
  Performing Arts 
  Religious Studies 
  View all Humanities 

   Engineering   
   
 Electrical Engineering 
  Mechanical Engineering 
  Civil Engineering 
  Robotics 
  Nanotechnology 
  GIS 
  Textiles 
  Manufacturing 
  BIM 
  CAD 
  Chemical Engineering 
  Energy Systems 
  Aerospace Engineering 
  Finite Element Analysis 
  Geotechnical Engineering 
  Reliability Engineering 
  Petroleum Engineering 
  Control Theory 
  Environmental Engineering 
  Energy Conversion 
  View all Engineering 

   Science   
   
 Chemistry 
  Physics 
  Environmental Science 
  Astronomy 
  Biology 
  Agriculture 
  Materials Science 
  Earth Science 
  Applied Science 
  Forensic Science 
  Meteorology 
  Horology 
  Paleontology 
  Fire Science 
  Sensory Science 
  Ergonomics 
  Physical Sciences 
  Complex Systems 
  Scientific Method 
  Medicine 
  View all Science 

   Education & Teaching   
   
 K12 
  Higher Education 
  STEM 
  Teacher Professional Development 
  Course Development 
  Online Education 
  Pedagogy 
  Social-emotional Learning (SEL) 
  Instructional Design 
  Homeschooling 
  Special Education 
  Adult Education 
  Course Design 
  Online Learning 
  Educational Technology 
  Curriculum Development 
  Next Generation Science Standards 
  Student-Centered Learning 
  Student Engagement 
  Classroom Management 
  View all Education & Teaching 

   Social Sciences   
   
 Sociology 
  Economics 
  Psychology 
  Anthropology 
  Political Science 
  Law 
  Urban Planning 
  Human Rights 
  Sustainability 
  Governance 
  Archaeology 
  Social Work 
  Early Childhood Development 
  Structural Equation Modeling 
  Cultural Studies 
  Research Methods 
  Community Engagement 
  Philanthropy 
  Behavioral Science 
  Media Studies 
  View all Social Sciences 

   Art & Design   
   
 Music 
  Digital Media 
  Visual Arts 
  Design & Creativity 
  Art Therapy 
  Art Composition 
  Character Design 
  Fashion Design 
  Inspiration 
  Golden Ratio 
  Pattern Design 
  Geometric Patterns 
  Copic Markers 
  Jewelry Design 
  Botanical Drawing 
  Animal Illustration 
  Anime Drawing 
  Observational Drawing 
  Clay Modeling 
  View all Art & Design 

   Data Science   
   
 Bioinformatics 
  Big Data 
  Data Mining 
  Data Analysis 
  Data Visualization 
  Jupyter Notebooks 
  Process Mining 
  Stata 
  Text Mining 
  Social Network Analysis 
  Computational Analysis 
  Data Collection 
  Information Retrieval 
  Data Processing 
  Data Wrangling 
  Data Extraction 
  Data Manipulation 
  Monte Carlo Simulation 
  Network Analysis 
  Data Preparation 
  View all Data Science 

   Programming   
   
 Mobile Development 
  Web Development 
  Databases 
  Game Development 
  Programming Languages 
  Software Development 
  Cloud Computing 
  Domain-Specific Languages (DSL) 
  Hardware Description Languages (HDL) 
  Aspect-oriented programming 
  Object-oriented programming 
  Visual Programming 
  Competitive Programming 
  Database Programming 
  Generic Programming 
  Programming Language Development 
  Leetcode 
  GNU Toolchain 
  View all Programming 

   Personal Development   
   
 Communication Skills 
  Career Development 
  Self Improvement 
  Presentation Skills 
  Resilience 
  Self-Control 
  Creativity 
  Gratitude 
  Growth Mindset 
  Self-Assessment 
  Survival Skills 
  Sleep Improvement 
  Career Planning 
  Empowerment 
  Generosity 
  Personal Growth 
  Courage 
  Humility 
  Social Skills 
  Dog Training 
  View all Personal Development 

   Information Security (InfoSec)   
   
 Cybersecurity 
  Network Security 
  Ethical Hacking 
  Digital Forensics 
  Reverse Engineering 
  Penetration Testing 
  Malware Analysis 
  DevSecOps 
  OSINT (Open Source Intelligence) 
  Threat Intelligence 
  Red Team 
  Blue Team 
  View all Information Security (InfoSec) 

 The Report    Coursera Announces Layoffs, Stock Plunges Despite $100M Milestone    
 Two years after its first major layoff round, Coursera announces another, impacting 10% of its workforce.  
 Dhawal Shah  Oct 25, 2024    
   
 Latest  
 10 Best Chess Courses for 2024 
  Writing as Enchantment: Inside Alan Moore’s BBC Maestro Course 
  7 Best Biology Courses for 2024 
  Learn Something New: 100 Most Popular Courses For December 
  Black Friday 2024: 50+ Online Learning Deals 

 Visit The Report     

 600 Free Google Certifications  
  Trending 
    
 Most common   
 English 
  javascript 
  harvard 
    
 Popular subjects   
 Web Development  
 13,821 courses 
  Data Analysis  
 8,881 courses 
  Cybersecurity  
 16,944 courses 
    
 Popular courses   
 Fractals and Scaling  
 Santa Fe Institute 
  Mechanics of Materials I: Fundamentals of Stress & Strain and Axial Loading  
 Georgia Institute of Technology 
  Learn Like a Pro: Science-Based Tools to Become Better at Anything  
 edX 

      Organize and share your learning with Class Central Lists.  
 View our Lists Showcase   
 Sign up    

 Log in  or  Sign up    
     Log in 
  Sign up 

       0 Reviews     
 Share    
   
 Start learning     

 Class Central is learner-supported. When you buy through links on our site, we may earn an affiliate commission.  

 Conference Talks 
  NDC Conferences 
      
 Computer Science 
  Algorithms 
   
  Computer Science 
  Data Structures 
   
  Computer Science 
  Algorithms 
  Graph Algorithms 
   
  Computer Science 
  Algorithms 
  Greedy Algorithms 
   
  Computer Science 
  Algorithms 
  Dynamic programming 
   
  Programming 
  Competitive Programming 

 Fun with Algorithms  
 NDC Conferences  via YouTube  Help    
       0  reviews      

  Add to list 
  Mark complete 
  Write review 
   
 Start learning    Write review    
  Affiliate notice     

 About 
  Related 
  Reviews 

 Details  
    
  Play Course Trailer    

 Start learning      
 Provider | YouTube  Help 
  Pricing | Conference Talk 
  Languages | English 
  Duration & workload | 57 minutes 
  Sessions | On-Demand 
  Share 

 Found in  
    
 NDC Conferences Courses 
  Algorithms Courses 
  Data Structures Courses 
  Graph Algorithms Courses 
  Greedy Algorithms Courses 
  Dynamic programming Courses 
  Competitive Programming Courses 

 Overview  
    
  Save Big on Coursera Plus. 7,000+ courses at $160 off  . Limited Time Only!    
 Grab it    
   
 Explore the fascinating world of algorithms and data structures in this engaging 57-minute conference talk from NDC London 2023. Dive into a programming language-agnostic journey through problem-solving techniques, covering graph algorithms, dynamic programming, greedy algorithms, and various data structures. Learn how to build solutions from first principles and combine algorithms to tackle increasingly complex challenges, from easy to medium to hard LeetCode or Advent of Code-style problems. Discover how algorithm puzzles and competitive programming can reignite your passion for coding and enhance your problem-solving skills in your day-to-day work. Gain valuable insights into the foundational aspects of computing that underpin everything from CRUD APIs to highly optimized data processing, and understand how this knowledge can improve your approach to difficult problems and optimization strategies.   

 Syllabus  
    
 Fun with Algorithms - Tess Ferrandez-Norlander - NDC London 2023  

 Taught by  
 NDC Conferences  

 Related Courses  
    
 Algorithms in Python – Full Course for Beginners 
  50 days of LeetCode in python: Algorithms coding interview 
  Mastering Coding Interviews & Competitions 
  Algorithmic Design and Techniques  
  3.7 
  Algorithmic Toolbox  
  3.6 
  Greedy Algorithms Tutorial – Solve Coding Challenges 

 Reviews  

            Select rating  
   
 Start your review of Fun with Algorithms   

 Start learning      

 Home    Conference Talks 
  NDC Conferences 

 Browse by subject  Computer Science 
  Psychology 
  Cybersecurity 
  Health 
  Law 
  Accounting 
  Web Development 
    
 Browse by provider  Coursera 
  edX 
  FutureLearn 
  Udacity 
  Noble Desktop 
  Udemy 
  freeCodeCamp 
    
 Browse by university  Harvard 
  Stanford 
  Georgia Tech 
  University of Michigan 
  Purdue University 
  Duke University 
  IIT Madras 

 Browse by institution  Google 
  Microsoft 
  IBM 
  Amazon 
  Linux Foundation 
  British Council 
  Salesforce 
    
 Rankings  Best Online Courses of All Time 
  Best Online Courses of the Year 
  Most Popular Courses of All Time 
  Most Popular Courses of the Year 
  250 Top FREE Coursera Courses of All Time 
  100 Top FREE edX Courses of All Time 
  250 Top Udemy Courses of All Time 

 The Report  by Class Central  RSS Feed  The "New Normal" that Wasn't 
  DDoS Attack on Class Central 
  500+ Online Degrees in India 
  Harvard's CS50 Free Certificate Guide 
  How Open University Works 
    
 Free Certificates & Courses  300+ Free Google Certificates 
  9000 Free Courses from Tech Giants 
  1800+ Free Coursera Courses 
  Ivy League Online Courses 
  180 Free Writing Online Courses 

 About Class Central  Class Central aggregates courses from many providers to help you find the best courses on almost any subject, wherever they exist.  
 Facebook 
  Twitter 
  LinkedIn 
  YouTube 
  Bluesky 

 Class Central © 2011-2024 Privacy Policy   
 About Us 
  Join Us 
  Help Center 
  Contact Us 

 Share  
  
 Facebook 
  Twitter 
  Bluesky 
  Email 
  Copy link 
    
 Never Stop Learning.  
 Get personalized course recommendations, track subjects and courses with reminders, and more.  
 Sign up for free

95. COG_0 conference:
home 
  attend 
  program 
  competitions 
  organization 
  sponsoring 
   
   Menu    
 home 
  attend 
  program 
  competitions 
  organization 
  sponsoring 

 The annual IEEE Conference on Games (IEEE CoG)  seeks to be the premier venue for technical, scientific, and engineering work on video games, board  games, and other types of games. Games offer a fantastic domain for  computational creativity, game design, technology, education, social sciences  and, undoubtedly, artificial and computational intelligence. IEEE CoG is a venue  to discuss recent advances and explore future directions.   
 IEEE CoG 2023 will take place at Northeastern University  , which is located in Boston in the United States, from August 21st to 24th  .  
 Contact:  ieeecog2023@gmail.com  

 Important Deadlines (all Anytime on Earth – AoE)  :  
  Competitions and tutorial  proposal: 27th February 2023   
  Submission of full technical papers (required: title, abstract, authors)  : 17th March 2023    
  Edit full technical paper submissions (paper, supplementary material)  : 24th March 2023    
  Notification of acceptance of full technical papers  : 9th May 2023   
  Submission of auxiliary  (competition, vision, short paper, and demo) papers  : 19th May 2023    
  Submission of the camera-ready version of full technical papers  : 28th May 2023   
  Notification of acceptance of auxiliary papers  : 17th June 2023   
  Games industry presentation  proposals: 19th June 2023    
  Journal paper presentation  proposals: 19th June 2023    
  Academic presentation  proposals :  19th June 2023    
  Notification of acceptance of presentations  : 26th June 2023   
  Submission of the camera-ready version of auxiliary papers  : 7th July 2023   
  Early bird (and author) registration  : 21st July 2023    

 Industry Day Program      

 Full Program      

 Call for Papers      

 Remote Policy    
  In discussion with members of the community, IEEE CoG 2023 will be primarily an in-person conference. However, the organization acknowledges that for a wide variety of reasons not all members can physically attend the conference and that traveling may simply be impossible. Therefore, the conference will provide the possibility for remote presentation (prerecorded but live streamed) for remote authors. At least one remote author must register for the conference by the payment of one regular registration (IEEE Member or Non-Member). After registration, make an official request for remote presentation using this form: https://forms.gle/TM9iJ96zf1LBVjHw8   

 Code of Conduct    
  IEEE CoG 2023 follows IEEE’s nondisrimination policy  , which prohibits discrimination, harassment, and bullying against any person for any reason (e.g., age, race, political affiliation), and IEEE’s Code of Ethics  , which commits members to the highest ethical and professional conduct. The organization further commits to providing a harassment-free, accessible, and pleasant conference experience where every participant feels welcome and included. Participants can contact any member of the Organization  in confidence. They can also make use of IEEE’s Ethics Reporting Line  .   

 sponsors  

 become a sponsor  

 click here      

 previous IEEE CoGs  

 2019 
  2020 
  2021 
  2022 

 navigation  

 home 
  attend 
  program 
  competitions 
  organization 
  sponsoring 

 Twitter       

 © 2023 All rights reserved​

96. COG_1 conference:
home 
  attend 
  program 
  competitions 
  organization 
  sponsoring 
   
   Menu    
 home 
  attend 
  program 
  competitions 
  organization 
  sponsoring 

 competitions  

 bot bowl V  

     more info  
    
 Title:  Bot Bowl V  
  Organizers:  Mattias Bermell, Modl.ai  
  Niels Justesen, Ph.D., Modl.ai  
  Website:  https://github.com/njustesen/botbowl   
 Description + Evaluation Criteria:  
   Bot Bowl is an AI competition using the Bot Bowl framework (previously known as FFAI). The Bot Bowl framework simulates the board game Blood Bowl by Games Workshop and offers APIs for scripted bots, search-based, and ML algorithms in Python. It’s also possible to use another programming language while there are no existing APIs for that. Blood Bowl is a major challenge for artificial agents due to its complexity and lack of rewards. This also means that we don’t have any basic baseline agents that are able to score points in this game! We do, however, provide tutorials on how to develop scripted, search-based, or ML bots.  
 The competition will have one track using the traditional board size of 26×15  
  squares with 11 players on each side. We will, like last year, restrict the game to  
  only feature a prefixed Human roster (i.e. no Orcs, Elves, etc.). The format will be a round-robin tournament where each bot plays 10 matches against each other and the tournament winner will be determined based on the following point system: 3 points for winning, 1 point for a draw, 0 points for a loss. In case of a tie, the bot with the highest number of touchdowns, and then inflicted casualties would win. In the future, when state of the art bots reliably beat humans in this setting, we plan to introduce more races and player abilities to the competition thus increasing the branching factor and introducing more of the long-term strategic elements that the game is known for.  
  Bot Bowl has been run four times in the past with an average of five bots  
  participating in each tournament. Bot Bowl III, saw the rise of a competitive  
  machine learning bot that used imitation and reinforcement learning. Last yearʼs competition, Bot Bowl IV, saw a mix of AI techniques including MCTS,  
  scripts and neural networks. In the end it was a purely scripted bot that won the competition. This year we plan to introduce an even faster forward model to the framework hopefully resulting in stronger search based bots. We are also setting up a master thesis proposal to investigate how imitation  
  learning from human replays can be used.  
 Tracks:  Single track with traditional board size of 26×15 squares with 11 players on each side  
  Video:  in progress  

 tales of tribute AI competition  

     more info  
    
 Title:  Tales of Tribute AI Competition  
 Organizers:  
   Jakub Kowalski, University of Wrocław  
  Dominik Budzki, University of Wrocław  
  Damian Kowalik, University of Wrocław  
  Katarzyna Polak, University of Wrocław  
  Radosław Miernik, University of Wrocław  
 Website:  https://github.com/ScriptsOfTribute   
 Description + Evaluation Criteria:  
   The deckbuilding card game Tales of Tribute is a special activity recently added to the massively popular multiplayer online role-playing video game The Elder Scrolls Online. Although the game remains small by CCG standards (about 120 cards and only a few keywords), it is interesting and challenging for humans, with a significant potential for being a good AI testbed.   
 The players start with the same base cards and build their decks during the game by buying cards from a shared resource pool called the Tavern (a concept similar to Dominion). Tales of Tributes encourages strategic long-term planning – to ensure the deck we build contains enough strong cards and is not clustered with weak ones. In the meantime, because of a huge randomness factor influencing, e.g., which cards occur in the Tavern, it is usually hard to stick with a pre-made plan – so it also requires considerable adaptiveness.   
 Tales of Tribute AI Competition aims to fill the void after the Hearthstone AI Competition while being significantly more challenging than a toy problem covered by Legends of Code and Magic and the Strategy Card Game AI Competition.   
 The competition will be run using ScriptsOfTribute, an open reimplementation of the original game in the .Net framework designed especially for this event. It features the game manager that allows running AI agents implemented as C# classes against each other and a graphical user interface that support human vs. AI games.   
 The competition’s winners will be decided upon the global winrate in all vs. all tournament, conducted on a large number of mirror matches using the same seeds. Deadline (August 7th).   
 Tracks:  Single track  
  Video:  https://youtu.be/3FxBlZ40l6o   

 the 2nd DareFightingICE competition  

     more info  
    
 Title:  The 2nd DareFightingICE Competition  
 Organizers:  
   Chollakorn Nimpattanavong, Graduate School of Information Science and Engineering,  Ritsumeikan University   
 Ibrahim Khan, Graduate School of Information Science and Engineering, Ritsumeikan  University   
 Van Thai Nguyen, Graduate School of Information Science and Engineering,Ritsumeikan  University   
 Junzhang Chen, College of Information Science and Engineering, Ritsumeikan University   
 Liyong Tao, College of Information Science and Engineering, Ritsumeikan University   
 Hidetoshi Gaya, College of Information Science and Engineering, Ritsumeikan University   
 Ruck Thawonmas, College of Information Science and Engineering, Ritsumeikan University   
 Website:  https://tinyurl.com/DareFightingICE   
 Description + Evaluation Criteria:  
   Are you aware of any sound design (a set of sound effects combined with the source code that implements their timing-control algorithm) in video games that considers visually impaired players? Enhanced with a better sound design than its predecessor FightingICE, DareFightingICE is a fighting game platform for creating a sound design for such players. As in the first competition at CoG 2022, this year, there are also two tracks. The first track is an AI competition, and the second is a sound-design competition.  
 Submissions  — of an AI capable of operating with only audio input information or/and a sound design for visually impaired players — are welcome.  
 The AI track utilizes this year’s default sound design of DareFightingICE. There are two leagues: Standard and Speedrunning. Standard League considers the winner of a round as the one with the hit point (HP) above zero when its opponent’s HP has reached zero. In Speedrunning League, the league winner is the AI with the shortest average time to beat our sample MCTS AI that has access to delayed game states and a sample deep-learning AI whose input is only audio data. This track’s winner is decided, considering both leagues’ results based on the 2018 Formula-1 scoring system.  
 In the sound design track, the winning sound design is the one that has not only the highest sum of the scores from blindfolded human test players (scores here include both relative game scores compared when playing without being blindfolded and subjective scores assessing sound aesthetic) but also the highest performance from the sample deep-learning AI fighting against the sample MCTS AI when the former is trained using the sound design of interest.  
 The winning AI — if trainable — and the winning sound design will be used in the sound design track and the AI track in the next competition, respectively.  
 Submission deadlines   
  Midterm deadline: May 24, 2023 (23:59 JST)  
  Final deadline: July 29, 2023 (23:59 JST)(no extension!!)  
   
 Tracks:  
   (1) AI Track: This track seeks submissions for the strongest blind fighting game AI.  
  (2) Sound Design Track: This track seeks submissions for the best fighting game sound design.  
 Video:  https://youtu.be/IojUrlXibvk   

 the Dota 2 5v5 AI competition  

     more info  
    
 Title  :  The Dota 2 5v5 AI Competition   
 Organizers:   
   José Font, Department of Computer Science and Media Technology, Malmö University (MAU)   
 Alberto Álvarez, Department of Computer Science and Media Technology, Malmö University (MAU)   
 Website:   https://games.mau.se/research/the-dota2-5v5-ai-competition/    
 Description:   
   The Dota 2 5v5 AI Competition challenges participants to code a bot that competes against (and wins!) other player bots in standard Dota 2 matches. The competition runs on the original Dota 2 game, thanks to the Dota 2 5v5 Framework, that lets you develop, deploy, and run your own python program that controls the 5 heroes in any Dota 2 team: Radiant or Dire. Your bot will face other participantsʼ bots in standard 5v5 matches. You can freely choose 5 among all the available heroes for your team. Depending on the number of entries, we would arrange either an elimination or a round-robin tournament. The winner will be the bot with most wins and, in case of tie, the one that beats its opponents faster. The framework saves the time elapsed from the match start to the Ancientʼs destruction event, which determines the end of a match.   
 Tracks:   One   
 Video:   
   There is a short video (with subtitles) and detailed instructions in the above competition website, as well as results from 2021.   

 6th annual GDMC - AI settlement generation competition in minecraft  

     more info  
    
 Title:   6th annual GDMC – AI Settlement Generation Competition in Minecraft   
 Organizers:   
   Christoph Salge, University of Hertfordshire, UK  
 Michael Cerny Green, NYU, US Rodrigo Canaan, Cal Poly State University, US  
 Christian Guckelsberger, Aalto University, Finland & QMUL, UK Jean-Baptiste Hervé, University of Hertfordshire, UK  
 Julian Togelius, NYU, US  
 Website:  http://gendesignmc.engineering.nyu.edu/    
 Wiki:  https://gendesignmc.wikidot.com/start   
 Social Media:   
   Discord: http://discord.gg/ueaxuXj  Twitter: @gendesignMC  
 Description:   
   The GDMC competition is about writing an algorithm that can produce an “interestingʼʼ settlement for a previously unseen Minecraft map. It was designed to provide an AI competition focussed on computational creativity, co-creativity  and adaptive, as well as holistic PCG. Competitors submit their algorithm, in one of two formats (both available via GitHub, see webpage), and the organizers then apply the algorithm to three, previously unseen Minecraft maps. The resulting maps and settlements are then sent out to a panel of expert and public judges, who score each algorithm in four categories: adaptivity, functionality, evocative narrative and aesthetics.   
 This is the 6th iteration for the competition. We had 11, 21, 11, 7 and 4 submissions in previous years. Last yearʼs winner was the team from Leiden University. We switched to two new frameworks this year, one being developed by our active community and the other one being a more modern map editor for Minecraft. We have an active and helpful community, with over 300 discord members, and GDMC being used in classes in at least 5 universities internationally. We have also been covered in traditional media, such as MIT Tech review  1  , several online videos and podcasts (see videos), and have been invited to the Microsoft Research Summit on Game AI. Several papers have been published both about the competition, and by our participants about their entries. The are numerous master and bachelor theses written in this framework now. We run one main competition, with an optional bonus challenge for chronicle generation, addressing the challenge of grounded computational storytelling.  
   https://www.technologyreview.com/2020/09/22/1008675/ai-planners-minecraft urban-design-healthier-happier-cities/    
 Video:   
   There are about 25 introductory, framework-tutorial, showcase and media coverage videos about GDMC at this point. Here is a small selection:   
 General Introductory Video:  https://youtu.be/opvVnpyiMmA   
 Framework introduction, by community member D. Churchill:  https://youtu.be/e1ydZA4qfSs    
 Last yearʼs winner presentation:  https://youtu.be/uYUIZUGPNX8   
  Coverage in AI and Game YouTube show:   
  https://youtu.be/_hP3RPFfSAI   
 Bonus Information:   
   Our website contains the following information, for the public:   
 An online form to submit the entries. 
  Detailed rules for the competition, including submission instructions. • The results of the previous three years, including code, generated settlement, competition  maps and scores. 
  A detailed explanation of the scoring criteria, including the actual instructions given to our  judges. 
  A list of examples of good Minecraft settlements. 
  Links to our other communication platforms: Discord, Twitter and our Wiki. • Links to a code repository containing example code for both submission options: 
  Submission of an Amulet Script – a Minecraft editor that allows for custom filters 
  Submission based on building Forge based http framework, that allows for real-time interaction with the running Minecraft world. The framework opens an http connection and there are Python and C example implementations to get started. 
  Links to related publications. 
  Timelines for the 6th round of GDMC, 2023:   
 February 2023: Announcement of the new Round. 
  15 of June, 2023: Submission Deadline. 
  15 of August, 2023: Deadline for Evaluation by Judges. 
  August, 2021: Announcement of Results at COG 2022 and online. 

 geometry friends collaborative game AI competition  

     more info  
    
 Title:  Geometry Friends Collaborative Game AI Competition   
 Organizers:   
   Rui Prada, Francisco S. Melo, Inês Batina e Inês Lobo INESC-ID and Instituto Superior Técnico, Universidade de Lisboa   
 Website:  https://geometryfriends.gaips.inesc-id.pt/     
 https://gaips.inesc-id.pt/geometryfriends/     
 Description:   
   The goal of the competition is to build AI agents for a 2-player collaborative physics-based puzzle platformer game (Geometry Friends). The agents control, each, a different character (circle or rectangle) with distinct characteristics. Their goal is to collaborate in order to collect a set of diamonds in a set of levels as fast as possible. The game presents problems of combined task and motion planning and promotes collaboration at different levels. Participants can tackle  cooperative levels with the full complexity of the problem or single- player levels for dealing with task and motion planning without the complexity of collaboration.   
 The winner is the submission that achieves a higher overall score after running 10 different levels. The score of each level depends on the performance of the task regarding the number of collectibles caught and the time the agents take to solve the level.   
 Tracks:  
   The competition has 3 tracks: Cooperative, Single Player Circle, Single Player Rectangle   
 Video:   
   A video is provided in the guides section of the website.  
   https://geometryfriends.gaips.inesc-id.pt/guides/     

 IEEE StarCraft AI competition  

     more info  
    
 Title:   IEEE StarCraft AI Competition   
 Organizers:   
   Jaeyoung Moon  
   Isaac Han  
   KyungJoong Kim  
   
   Website:   https://cilab.gist.ac.kr/sc_competition    
 Description + Evaluation Criteria:   
   The IEEE CoG StarCraft competitions have made remarkable progress in advancing the creation and evolution of new StarCraft bots. Participants have employed various strategies to enhance the bots, leading to the enrichment of game AI and methodologies. Furthermore, recent developments in game AI, particularly through the application of deep learning and reinforcement learning, have also contributed to the advancement of StarCraft AIs. Nevertheless, developing AI for the game remains a formidable challenge, given the need to effectively manage a vast number of units and buildings while considering resource management and high-level tactics. The competition’s primary goal is to stimulate the growth of real-time strategy (RTS) game AI and overcome complex issues such as uncertainty, unit management, and the game’s real-time nature.   
 The winner of the competition will be determined through a round-robin tournament, with as many rounds as possible conducted before the deadline for the announcement of the winners. If it is estimated that there is insufficient time to complete another round or insufficient time to prepare before announcing the winners, the tournament will be concluded at the end of a full round.   
 Tracks:  Single track: 1 vs. 1 full game   
 Video:   https://youtu.be/6tr-RDd8L3Q    

 microRTS Competition  

     more info  
    
 Title:  MicroRTS Competition   
 Organizers:   
   Rubens Moraes and Levi Lelis   
 Website:   https://sites.google.com/site/micrortsaicompetition    
 Description:   
   Several AI competitions organized around RTS games have been organized in the past (such as the ORTS competitions, and the StarCraft AI competitions: AIIDE, CIG, SSCAI), which has spurred a new wave of research into RTS AI. However, as it has been reported numerous times, developing bots for RTS games such as StarCraft involves a large amount of engineering, which often relegates the research aspects of the competition to a second plane. The microRTS competition has been created to motivate research in the basic research questions underlying the development of AI for RTS games while minimizing the amount of engineering required to participate. Also, a key difference with respect to the StarCraft competition is that the AIs have access to a “forward model” (i.e., a simulator), with which they can simulate the effect of actions or plans, thus allowing for planning and game-tree search techniques to be developed easily. Although we acknowledge that planning in domains for which the agent does not have a forward model is an important problem, this is left out of this competition, in order to focus on other core RTS problems. The winner of the competition will be determined with a round robin tournament where each agent plays all the other agents (and a few agents the organizers will add to the pool) in a set of maps. A victory counts as 1.0, a draw as 0.5, and a defeat as 0.0. The agent with the highest score in the round robin tournament will be determined as the winner of the competition.   
 Track:  Classic, which focuses on the problem of large state spaces and branching factors by making the game fully observable. The game will be configured to be deterministic.   
 Video:  Videos of competition are available in the website:  https://sites.google.com/site/micrortsaicompetition/getting-started?authuser=0    

 CoG-2023 multi-agent google research football competition  

     more info  
    
 Title:   CoG-2023 Multi-Agent Google Research Football Competition   
 Organizers:   
   Haifeng Zhang, Institute of Automation, Chinese Academy of Sciences, China   
 Yahui Cui, Institute of Automation, Chinese Academy of Sciences  
 China Yan Song, Institute of Automation, Chinese Academy of Sciences, China  
 Website:   http://www.jidiai.cn/cog_2022/     
 Description:   
   The competition will be named CoG-2023 Multi-Agent Google Research Football Competition as it plans to use the multi-agent scenarios of the Google Research Football (GRF) simulators [1] as the testbed. The GRF simulator bears great similarity to well-known football games like FIFA and REAL Football, vividly modelling the dynamics of the ball and player movement as well as their interaction such as passing, shooting, etc. The competition focuses on the full game scenario built on GRF simulator where two teams of players compete for goals on the pitch (as shown in Fig. 1).  The competition will be held on Jidi platform which offers online evaluation of submitted policies on various simulated environments and holds Kaggle-like  customized competitions. Regarding the scale of the game, the GRF competition has two tracks as two separate contests, one easy track using the 5vs5 multi agent full-game scenario and one hard track using the 11vs11 multi-agent full game scenario.   
 On these scenarios, the duration of the game is 3000 discrete time-steps corresponding to 90 minutes in a real football match. The observation for each player contains information of both the teammates and the opponents, as well as the state of the ball. Based on the provided information, each individual player can either move or make specific actions such as ball-passing or ball-shooting. The goal of each team is to control all of its players (5 or 11), organize team offense and defense and win the game by scoring more than the other team. Expectedly, a strong participant is required to demonstrate sophisticated football skills and counter various opponentsʼ tactics in such complex competitive tasks.   
 Previous GRF Competitions:   
   GRF has already been chosen previously as a testbed for AI competitions. For instance, the Single-Agent RL (SARL) Google Research Football 2020 Kaggle Competition [2] was held by the famous Manchester City F.C., attracting over 1,000 team participation on the single-agent 11v11 full-game scenario. In this task, one side of the team only needs to control the single designated player and all of its teammates are controlled by the built-in AI. In year 2022, Jidi held the MARL CoG 2022 GRF tracks [3] on multi-agent RL (MARL) settings (5v5 and 11v11 full-game scenarios) with an increase in the number of controllable players.  This was more difficult than the single-agent settings and had attracted over 100 team participation (see Fig.2).   
 Jidi plans to continue the competition on GRF in year 2023 after discovering interesting tactics from MARL CoG 2022 GRF tracks. On the 5v5 track particularly, many top participants have learned a high-pass glitch existing in the goal-keeperʼs built-in logic and taken advantage of such loopholes to form an extremely strong tactics. On the 11v11 track, some collaborative behavior between players have emerged and a game clip can be found in [4]. To further encourage multi-agent learning research, we will hold two tracks on 5v5 and 11v11 full-game scenarios respectively:   
 5vs5 track:  http://www.jidiai.cn/env_detail?envid=71  ; 
  11vs11 track:  http://www.jidiai.cn/env_detail?envid=34; 
  Evaluation Details:   
   Each team of the competition consists of 1-3 members and each track is scheduled for two warm-up rounds and two main rounds. Only the results of the main rounds are added up to give the final scores and the team with the highest score wins the track. Both the warm-up and the main rounds adopt the Swiss Round double competition system [5] and the ranking of each team is determined through (4  ⌈  logN  ⌉+1  ) rounds of matches (N is the number of teams).  The double competition system means that the two submissions will be evaluated under the same environment random seeds for two rounds and switching sides when each round finishes. The initial score for each team is at 1000 and are updated through ELO algorithm.   
 Tracks:  To further encourage multi-agent learning research, we will hold two tracks on 5v5 and 11v11 full-game scenarios respectively:   
 5vs5 track:  http://www.jidiai.cn/env_detail?envid=71   ; 
  11vs11 track:  http://www.jidiai.cn/env_detail?envid=34; 

 VGC AI competition  

     more info  
    
 Title:  VGC AI Competition   
 Organizers:  Simão Reis   
 Website:   https://gitlab.com/DracoStriker/pokemon-vgc-engine/-/wikis/home    
 Description:   Can AI beat other opponents in Pokémon battle games?   
 The VGC AI Competition aims to emulate the Esports scenario of human video game championships of Pokémon with AI agents, including the game balance  
 aspect. Player agents must master Pokémon battling and team building, with only information about past team choices. Balancing agents must adapt the Pokémon attributes to motivate more variety of choices by pre-set player agents.   
 Tentative submission deadline: 30th June 2023  
 Tracks:  The competition is organized in three tracks:   
 In the Battle Track, battle agents must be able to pilot any given team. The winner is determined by the outcome of battles structured as a tree championship. 
  The Championship Track focuses on the team-building aspect of the VGCs. Player agents (battle+team-building duo) must be able to adapt to the meta by assembling the best teams to counter the teams they predict they will be facing. The winner is determined by the final ELO ranking after many epochs of competition. 
  In the Meta-Game Balance Track, a balancing agent has to maintain a Pokémon roster. Entries will be evaluated in parallel by accumulated points over temporal checkpoints, accumulating the output of a fitness function that measures the diversity of the meta by a pre-set team-building agents. 

 the 1st ChatGPT4PCG competition: character-like level generation for science birds competition  

     more info  
    
 Title:  The 1st ChatGPT4PCG Competition: Character-like Level Generation for Science Birds  
 Organizers:   
  1. Pittawat Taveekitworachai, Graduate School of Information Science and Engineering, Ritsumeikan University  
  2. Febri Abdullah, Graduate School of Information Science and Engineering, Ritsumeikan University  
  3. Mury F. Dewantoro, Graduate School of Information Science and Engineering, Ritsumeikan University  
  4. Ruck Thawonmas, College of Information Science and Engineering, Ritsumeikan University  
  5. Julian Togelius, NYU Tandon School of Engineering, New York University  
  6. Jochen Renz, School of Computing, The Australian National University  
 Website:   
  https://chatgpt4pcg.github.io/   
 Description of the Competition:  
   The 1st ChatGPT4PCG Competition challenges participants to utilize the state-of-the-art natural language processing tool, ChatGPT, to generate visually appealing and structurally sound levels for Science Birds, an Angry Birds clone created for research purposes.  
   
  As a participant, your goal is to create a prompt that instructs ChatGPT to generate a level in Science Birds that resembles an English capital letter while ensuring that the level is stable and able to withstand gravity. You are encouraged to use various prompt engineering techniques to develop the most effective prompt possible.  
   
  To participate, you must submit your prompt according to our guidelines. We will then generate a number of samples, each of which will undergo rigorous testing for stability and similarity. Stability will be evaluated by loading the level in Science Birds and ensuring that there is no movement for a duration of 10 seconds. The similarity of each generated level to its corresponding English character will be determined using an open-source Vision Transformer (ViT)-based classifier model. The stability testing system and the instructions to use the classifier model, as well as all the relevant tools, will be provided.  
   
  This competition offers a unique opportunity for the best prompt engineers from around the world to showcase their creativity and skills. Join us in this exciting challenge to push the boundaries of prompt engineering and procedural content generation!  
 Track:  NA  
  Video:  https://youtu.be/9AJhqIkDbxs   
  Contact Email address:  chatgpt4pcg@gmail.com   
 Submission deadline:   
  Midterm: 19 May 2023 (23:59 JST)  
  Final: 21 July 2023 (23:59 JST)  
 Other Information:   
  Keywords: ChatGPT, prompt engineering, procedural content generation, level generation, conversational agent, large language model, Angry Birds, Science Birds  
  Programming languages: N/A. However, having general programming knowledge can be useful.  
  Complexity: Low-Medium  
  Competitive: New Competition  
  Barrier of entry: Low  

 sponsors  

 become a sponsor  

 click here      

 previous IEEE CoGs  

 2019 
  2020 
  2021 
  2022 

 navigation  

 home 
  attend 
  program 
  competitions 
  organization 
  sponsoring 

 Twitter       

 © 2023 All rights reserved​

97. FUN_1 conference:
DROPS 
  Series | LIPIcs – Leibniz International Proceedings in Informatics 
  OASIcs – Open Access Series in Informatics 
  Dagstuhl Follow-Ups 
  Schloss Dagstuhl Jahresbericht 
   Discontinued Series 
  Journals | DARTS – Dagstuhl Artifacts Series 
  Dagstuhl Reports 
  Dagstuhl Manifestos 
  LITES – Leibniz Transactions on Embedded Systems 
  TGDK – Transactions on Graph Data and Knowledge 
  Conferences | AFT 
  AIB 
  AofA 
  APPROX 
  ATMOS 
  CALCO 
  CCC 
  CONCUR 
  COSIT 
  CP 
  CPM 
  CSL 
  DISC 
  DITAM 
  DNA 
  ECOOP 
  ECRTS 
  ESA 
  FAB 
  FMBC 
   FORC 
  FSCD 
  FSTTCS 
  FUN 
  GD 
  GIScience 
  ICALP 
  ICDT 
  ICPEC 
  IPEC 
  iPMVM 
  ISAAC 
  ITC 
  ITCS 
  ITP 
  LDK 
  MFCS 
  Microservices 
  NG-RES 
  OPODIS 
   PARMA 
  RANDOM 
  SAND 
  SAT 
  SEA 
  SLATE 
  SNAPL 
  SoCG 
  STACS 
  SWAT 
  TIME 
  Tokenomics 
  TQC 
  TYPES 
  WABI 
  WCET 
  Artifacts | Supplementary Materials (Software, Datasets, ...) 
  dblp Artifacts 
   DARTS (Evaluated Artifacts) 
        
  Metadata Export | Metadata Export 
  OAI Interface 

  Volume    Export XML 
  Export ACM-XML 
  Export DOAJ-XML 
  Export Schema.org 
  Export HTML 

  LIPIcs, Volume 291  
 12th International Conference on Fun with Algorithms (FUN 2024)  
   
  Part of: | Series: | Leibniz International Proceedings in Informatics (LIPIcs) | Part of: | Conference: | International Conference on Fun with Algorithms (FUN) 

 Event  
 FUN 2024, June 4-8, 2024, Island of La Maddalena, Sardinia, Italy   
 Editors  
  Andrei Z. Broder          
 Google 
    
  Tami Tamir          
 Reichman University, Herzliya, Israel 

 Publication Details  
 published at: 2024-05-29 
  Publisher: Schloss Dagstuhl – Leibniz-Zentrum für Informatik 
  ISBN: 978-3-95977-314-0 
  DBLP: | db/conf/fun/fun2024 

  Access Numbers  
 Detailed Access Statistics available here 
  Total Document Accesses (updated on a weekly basis): | 0   PDF Downloads   0   Metadata Views 

 Documents   
 No documents found matching your filter selection.   
  Document   
 Complete Volume   
 DOI: 10.4230/LIPIcs.FUN.2024    

 LIPIcs, Volume 291, FUN 2024, Complete Volume   
 Authors:  Andrei Z. Broder and Tami Tamir  
  Abstract    
 LIPIcs, Volume 291, FUN 2024, Complete Volume   

  Cite as    
 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 1-570, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @Proceedings{broder_et_al:LIPIcs.FUN.2024 title = {{LIPIcs, Volume 291, FUN 2024, Complete Volume}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {1--570}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024}, URN = {urn:nbn:de:0030-drops-199079}, doi = {10.4230/LIPIcs.FUN.2024}, annote = {Keywords: LIPIcs, Volume 291, FUN 2024, Complete Volume} }  @Proceedings{broder_et_al:LIPIcs.FUN.2024 title = {{LIPIcs, Volume 291, FUN 2024, Complete Volume}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {1--570}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024}, URN = {urn:nbn:de:0030-drops-199079}, doi = {10.4230/LIPIcs.FUN.2024}, annote = {Keywords: LIPIcs, Volume 291, FUN 2024, Complete Volume} }    

  Document   
 Front Matter   
 DOI: 10.4230/LIPIcs.FUN.2024.0    

 Front Matter, Table of Contents, Preface, Conference Organization   
 Authors:  Andrei Z. Broder and Tami Tamir  
  Abstract    
 Front Matter, Table of Contents, Preface, Conference Organization   

  Cite as    
 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 0:i-0:xvi, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{broder_et_al:LIPIcs.FUN.2024.0 author = {Broder, Andrei Z. and Tamir, Tami}, title = {{Front Matter, Table of Contents, Preface, Conference Organization}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {0:i--0:xvi}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.0}, URN = {urn:nbn:de:0030-drops-199080}, doi = {10.4230/LIPIcs.FUN.2024.0}, annote = {Keywords: Front Matter, Table of Contents, Preface, Conference Organization} }  @InProceedings{broder_et_al:LIPIcs.FUN.2024.0 author = {Broder, Andrei Z. and Tamir, Tami}, title = {{Front Matter, Table of Contents, Preface, Conference Organization}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {0:i--0:xvi}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.0}, URN = {urn:nbn:de:0030-drops-199080}, doi = {10.4230/LIPIcs.FUN.2024.0}, annote = {Keywords: Front Matter, Table of Contents, Preface, Conference Organization} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.1    

 Baba Is Universal   
 Authors:  Zachary Abel and Della Hendrickson  
  Abstract    
 We consider the computational complexity of constant-area levels of games which allow an unlimited number of objects in a fixed region. We discuss how to prove that such games are RE-hard (and in particular undecidable) and capable of universal computation, even on constant-area levels. We use the puzzle game Baba is You as a case study, showing that 8×17 levels are capable of universal computation by constructing a particular small universal counter machine within Baba is You.   

  Cite as    
 Zachary Abel and Della Hendrickson. Baba Is Universal. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 1:1-1:15, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{abel_et_al:LIPIcs.FUN.2024.1 author = {Abel, Zachary and Hendrickson, Della}, title = {{Baba Is Universal}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {1:1--1:15}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.1}, URN = {urn:nbn:de:0030-drops-199093}, doi = {10.4230/LIPIcs.FUN.2024.1}, annote = {Keywords: Undecidability, Baba is You, RE-hardness, counter machines, universal computation} }  @InProceedings{abel_et_al:LIPIcs.FUN.2024.1 author = {Abel, Zachary and Hendrickson, Della}, title = {{Baba Is Universal}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {1:1--1:15}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.1}, URN = {urn:nbn:de:0030-drops-199093}, doi = {10.4230/LIPIcs.FUN.2024.1}, annote = {Keywords: Undecidability, Baba is You, RE-hardness, counter machines, universal computation} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.2    

 Poset Positional Games   
 Authors:  Guillaume Bagan, Eric Duchêne, Florian Galliot, Valentin Gledel, Mirjana Mikalački, Nacim Oijid, Aline Parreau, and Miloš Stojaković  
  Abstract    
 We propose a generalization of positional games, supplementing them with a restriction on the order in which the elements of the board are allowed to be claimed. We introduce poset positional games, which are positional games with an additional structure - a poset on the elements of the board. Throughout the game play, based on this poset and the set of the board elements that are claimed up to that point, we reduce the set of available moves for the player whose turn it is - an element of the board can only be claimed if all the smaller elements in the poset are already claimed. We proceed to analyze these games in more detail, with a prime focus on the most studied convention, the Maker-Breaker games. First we build a general framework around poset positional games. Then, we perform a comprehensive study of the complexity of determining the game outcome, conditioned on the structure of the family of winning sets on the one side and the structure of the poset on the other.   

  Cite as    
 Guillaume Bagan, Eric Duchêne, Florian Galliot, Valentin Gledel, Mirjana Mikalački, Nacim Oijid, Aline Parreau, and Miloš Stojaković. Poset Positional Games. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 2:1-2:12, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{bagan_et_al:LIPIcs.FUN.2024.2 author = {Bagan, Guillaume and Duch\^{e}ne, Eric and Galliot, Florian and Gledel, Valentin and Mikala\v{c}ki, Mirjana and Oijid, Nacim and Parreau, Aline and Stojakovi\'{c}, Milo\v{s}}, title = {{Poset Positional Games}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {2:1--2:12}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.2}, URN = {urn:nbn:de:0030-drops-199100}, doi = {10.4230/LIPIcs.FUN.2024.2}, annote = {Keywords: Positional games, Maker-Breaker games, Game complexity, Poset, Connect 4} }  @InProceedings{bagan_et_al:LIPIcs.FUN.2024.2 author = {Bagan, Guillaume and Duch\^{e}ne, Eric and Galliot, Florian and Gledel, Valentin and Mikala\v{c}ki, Mirjana and Oijid, Nacim and Parreau, Aline and Stojakovi\'{c}, Milo\v{s}}, title = {{Poset Positional Games}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {2:1--2:12}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.2}, URN = {urn:nbn:de:0030-drops-199100}, doi = {10.4230/LIPIcs.FUN.2024.2}, annote = {Keywords: Positional games, Maker-Breaker games, Game complexity, Poset, Connect 4} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.3    

 Snake in Optimal Space and Time   
 Authors:  Philip Bille, Martín Farach-Colton, Inge Li Gørtz, and Ivor van der Hoog  
  Abstract    
 We revisit the classic game of Snake and ask the basic data structural question: how many bits does it take to represent the state of a snake game so that it can be updated in constant time? Our main result is a data structure that uses optimal space (within constant factors). To achieve our results, we introduce several interesting data structural techniques, including a decomposition technique for the problem, a tabulation scheme for encoding small subproblems, and a dynamic memory allocation scheme.   

  Cite as    
 Philip Bille, Martín Farach-Colton, Inge Li Gørtz, and Ivor van der Hoog. Snake in Optimal Space and Time. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 3:1-3:15, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{bille_et_al:LIPIcs.FUN.2024.3 author = {Bille, Philip and Farach-Colton, Mart{\'\i}n and G{\o}rtz, Inge Li and van der Hoog, Ivor}, title = {{Snake in Optimal Space and Time}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {3:1--3:15}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.3}, URN = {urn:nbn:de:0030-drops-199118}, doi = {10.4230/LIPIcs.FUN.2024.3}, annote = {Keywords: Data structure, Snake, Nokia, String Algorithms} }  @InProceedings{bille_et_al:LIPIcs.FUN.2024.3 author = {Bille, Philip and Farach-Colton, Mart{\'\i}n and G{\o}rtz, Inge Li and van der Hoog, Ivor}, title = {{Snake in Optimal Space and Time}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {3:1--3:15}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.3}, URN = {urn:nbn:de:0030-drops-199118}, doi = {10.4230/LIPIcs.FUN.2024.3}, annote = {Keywords: Data structure, Snake, Nokia, String Algorithms} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.4    

 Uniform-Budget Solo Chess with Only Rooks or Only Knights Is Hard   
 Authors:  Davide Bilò, Luca Di Donato, Luciano Gualà, and Stefano Leucci  
  Abstract    
 We study the Solo-Chess problem which has been introduced in [Aravind et al., FUN 2022]. This is a single-player variant of chess in which the player must clear all but one piece from the board via a sequence captures while ensuring that the number of captures performed by each piece does not exceed the piece’s budget. The time complexity of finding a winning sequence of captures has already been pinpointed for several combination of piece types and initial budgets. We contribute to a better understanding of the computational landscape of Solo-Chess by closing two problems left open in [Aravind et al., FUN 2022]. Namely, we show that Solo-Chess is hard even when all pieces are restricted to be only rooks with budget exactly 2, or only knights with budget exactly 11.   

  Cite as    
 Davide Bilò, Luca Di Donato, Luciano Gualà, and Stefano Leucci. Uniform-Budget Solo Chess with Only Rooks or Only Knights Is Hard. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 4:1-4:19, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{bilo_et_al:LIPIcs.FUN.2024.4 author = {Bil\`{o}, Davide and Di Donato, Luca and Gual\`{a}, Luciano and Leucci, Stefano}, title = {{Uniform-Budget Solo Chess with Only Rooks or Only Knights Is Hard}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {4:1--4:19}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.4}, URN = {urn:nbn:de:0030-drops-199121}, doi = {10.4230/LIPIcs.FUN.2024.4}, annote = {Keywords: solo chess, puzzle games, board games, NP-completeness} }  @InProceedings{bilo_et_al:LIPIcs.FUN.2024.4 author = {Bil\`{o}, Davide and Di Donato, Luca and Gual\`{a}, Luciano and Leucci, Stefano}, title = {{Uniform-Budget Solo Chess with Only Rooks or Only Knights Is Hard}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {4:1--4:19}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.4}, URN = {urn:nbn:de:0030-drops-199121}, doi = {10.4230/LIPIcs.FUN.2024.4}, annote = {Keywords: solo chess, puzzle games, board games, NP-completeness} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.5    

 Swapping Mixed-Up Beers to Keep Them Cool   
 Authors:  Davide Bilò, Maurizio Fiusco, Luciano Gualà, and Stefano Leucci  
  Abstract    
 There was a mix-up in Escher’s bar and n customers sitting at the same table have each received a beer ordered by somebody else in the party. The drinks can be rearranged by swapping them in pairs, but the eccentric table shape only allows drinks to be exchanged between people sitting on opposite sides of the table. We study the problem of finding the minimum number of swaps needed so that each customer receives its desired beer before it gets warm. Formally, we consider the Colored Token Swapping problem on complete bipartite graphs. This problem is known to be solvable in polynomial time when all ordered drinks are different [Yamanaka et al., FUN 2014], but no results are known for the more general case in which multiple people in the party can order the same beer. We prove that Colored Token Swapping on complete bipartite graphs is NP-hard and that it is fixed-parameter tractable when parameterized by the number of distinct types of beer served by the bar.   

  Cite as    
 Davide Bilò, Maurizio Fiusco, Luciano Gualà, and Stefano Leucci. Swapping Mixed-Up Beers to Keep Them Cool. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 5:1-5:18, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{bilo_et_al:LIPIcs.FUN.2024.5 author = {Bil\`{o}, Davide and Fiusco, Maurizio and Gual\`{a}, Luciano and Leucci, Stefano}, title = {{Swapping Mixed-Up Beers to Keep Them Cool}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {5:1--5:18}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.5}, URN = {urn:nbn:de:0030-drops-199132}, doi = {10.4230/LIPIcs.FUN.2024.5}, annote = {Keywords: Colored Token Swapping, Complete Bipartite Graphs, Labeled Token Swapping, FPT Algorithms, NP-Hardness} }  @InProceedings{bilo_et_al:LIPIcs.FUN.2024.5 author = {Bil\`{o}, Davide and Fiusco, Maurizio and Gual\`{a}, Luciano and Leucci, Stefano}, title = {{Swapping Mixed-Up Beers to Keep Them Cool}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {5:1--5:18}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.5}, URN = {urn:nbn:de:0030-drops-199132}, doi = {10.4230/LIPIcs.FUN.2024.5}, annote = {Keywords: Colored Token Swapping, Complete Bipartite Graphs, Labeled Token Swapping, FPT Algorithms, NP-Hardness} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.6    

 Bottom-Up Rebalancing Binary Search Trees by Flipping a Coin   
 Authors:  Gerth Stølting Brodal  
  Abstract    
 Rebalancing schemes for dynamic binary search trees are numerous in the literature, where the goal is to maintain trees of low height, either in the worst-case or expected sense. In this paper we study randomized rebalancing schemes for sequences of n insertions into an initially empty binary search tree, under the assumption that a tree only stores the elements and the tree structure without any additional balance information. Seidel (2009) presented a top-down randomized insertion algorithm, where insertions take expected O(lg² n) time, and the resulting trees have the same distribution as inserting a uniform random permutation into a binary search tree without rebalancing. Seidel states as an open problem if a similar result can be achieved with bottom-up insertions. In this paper we fail to answer this question. We consider two simple canonical randomized bottom-up insertion algorithms on binary search trees, assuming that an insertion is given the position where to insert the next element. The subsequent rebalancing is performed bottom-up in expected O(1) time, uses expected O(1) random bits, performs at most two rotations, and the rotations appear with geometrically decreasing probability in the distance from the leaf. For some insertion sequences the expected depth of each node is proved to be O(lg n). On the negative side, we prove for both algorithms that there exist simple insertion sequences where the expected depth is Ω(n), i.e., the studied rebalancing schemes are not competitive with (most) other rebalancing schemes in the literature.   

  Cite as    
 Gerth Stølting Brodal. Bottom-Up Rebalancing Binary Search Trees by Flipping a Coin. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 6:1-6:15, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{brodal:LIPIcs.FUN.2024.6 author = {Brodal, Gerth St{\o}lting}, title = {{Bottom-Up Rebalancing Binary Search Trees by Flipping a Coin}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {6:1--6:15}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.6}, URN = {urn:nbn:de:0030-drops-199143}, doi = {10.4230/LIPIcs.FUN.2024.6}, annote = {Keywords: Binary search tree, insertions, random rebalancing} }  @InProceedings{brodal:LIPIcs.FUN.2024.6 author = {Brodal, Gerth St{\o}lting}, title = {{Bottom-Up Rebalancing Binary Search Trees by Flipping a Coin}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {6:1--6:15}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.6}, URN = {urn:nbn:de:0030-drops-199143}, doi = {10.4230/LIPIcs.FUN.2024.6}, annote = {Keywords: Binary search tree, insertions, random rebalancing} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.7    

 Physical Ring Signature   
 Authors:  Xavier Bultel  
  Abstract    
 Ring signatures allow members of a group (called ring) to sign a message anonymously within the group, which is chosen ad hoc at the time of signing (the members do not need to have interacted before). In this paper, we propose a physical version of ring signatures. Our signature is based on one-out-of-many signatures, a method used in many real cryptographic ring signatures. It consists of boxes containing coins locked with padlocks that can only be opened by a particular group member. To sign a message, a group member shakes the boxes of the other members of the group so that the coins are in a random state ("heads" or "tails", corresponding to bits 0 and 1), and opens their box to arrange the coins so that the exclusive "or" of the coins corresponds to the bits of the message they wish to sign. We present a prototype that can be used with coins, or with dice for messages encoded in larger (non-binary) alphabets. We suggest that this system can be used to explain ring signatures to the general public in a fun way. Finally, we propose a semi-formal analysis of the security of our signature based on real cryptographic security proofs.   

  Cite as    
 Xavier Bultel. Physical Ring Signature. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 7:1-7:18, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{bultel:LIPIcs.FUN.2024.7 author = {Bultel, Xavier}, title = {{Physical Ring Signature}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {7:1--7:18}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.7}, URN = {urn:nbn:de:0030-drops-199154}, doi = {10.4230/LIPIcs.FUN.2024.7}, annote = {Keywords: Physical Cryptography, Ring Signature, Anonymity} }  @InProceedings{bultel:LIPIcs.FUN.2024.7 author = {Bultel, Xavier}, title = {{Physical Ring Signature}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {7:1--7:18}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.7}, URN = {urn:nbn:de:0030-drops-199154}, doi = {10.4230/LIPIcs.FUN.2024.7}, annote = {Keywords: Physical Cryptography, Ring Signature, Anonymity} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.8    

 A Tractability Gap Beyond Nim-Sums: It’s Hard to Tell Whether a Bunch of Superstars Are Losers   
 Authors:  Kyle Burke, Matthew Ferland, Svenja Huntemann, and Shanghua Teng  
  Abstract    
 In this paper, we address a natural question at the intersection of combinatorial game theory and computational complexity: "Can a sum of simple tepid games in canonical form be intractable?" To resolve this fundamental question, we consider superstars, positions first introduced in Winning Ways where all options are nimbers. Extending Morris' classic result with hot games to tepid games, we prove that disjunctive sums of superstars are intractable to solve. This is striking as sums of nimbers can be computed in linear time. Our analyses also lead to a family of elegant board games with intriguing complexity, for which we present web-playable versions of the rulesets described within.   

  Cite as    
 Kyle Burke, Matthew Ferland, Svenja Huntemann, and Shanghua Teng. A Tractability Gap Beyond Nim-Sums: It’s Hard to Tell Whether a Bunch of Superstars Are Losers. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 8:1-8:14, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{burke_et_al:LIPIcs.FUN.2024.8 author = {Burke, Kyle and Ferland, Matthew and Huntemann, Svenja and Teng, Shanghua}, title = {{A Tractability Gap Beyond Nim-Sums: It’s Hard to Tell Whether a Bunch of Superstars Are Losers}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {8:1--8:14}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.8}, URN = {urn:nbn:de:0030-drops-199168}, doi = {10.4230/LIPIcs.FUN.2024.8}, annote = {Keywords: Combinatorial Game Theory, NP-hardness, Superstars} }  @InProceedings{burke_et_al:LIPIcs.FUN.2024.8 author = {Burke, Kyle and Ferland, Matthew and Huntemann, Svenja and Teng, Shanghua}, title = {{A Tractability Gap Beyond Nim-Sums: It’s Hard to Tell Whether a Bunch of Superstars Are Losers}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {8:1--8:14}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.8}, URN = {urn:nbn:de:0030-drops-199168}, doi = {10.4230/LIPIcs.FUN.2024.8}, annote = {Keywords: Combinatorial Game Theory, NP-hardness, Superstars} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.9    

 The Steady-States of Splitter Networks   
 Authors:  Basile Couëtoux, Bastien Gastaldi, and Guyslain Naves  
  Abstract    
 We introduce splitter networks, which abstract the behavior of conveyor belts found in the video game Factorio. Based on this definition, we show how to compute the steady-state of a splitter network. Then, leveraging insights from the players community, we provide multiple designs of splitter networks capable of load-balancing among several conveyor belts, and prove that any load-balancing network on n belts must have Ω(n log n) nodes. Incidentally, we establish connections between splitter networks and various concepts including flow algorithms, flows with equality constraints, Markov chains and the Knuth-Yao theorem about sampling over rational distributions using a fair coin.   

  Cite as    
 Basile Couëtoux, Bastien Gastaldi, and Guyslain Naves. The Steady-States of Splitter Networks. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 9:1-9:14, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{couetoux_et_al:LIPIcs.FUN.2024.9 author = {Cou\"{e}toux, Basile and Gastaldi, Bastien and Naves, Guyslain}, title = {{The Steady-States of Splitter Networks}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {9:1--9:14}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.9}, URN = {urn:nbn:de:0030-drops-199174}, doi = {10.4230/LIPIcs.FUN.2024.9}, annote = {Keywords: Factorio, splitter networks, flow, balancer, steady-state} }  @InProceedings{couetoux_et_al:LIPIcs.FUN.2024.9 author = {Cou\"{e}toux, Basile and Gastaldi, Bastien and Naves, Guyslain}, title = {{The Steady-States of Splitter Networks}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {9:1--9:14}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.9}, URN = {urn:nbn:de:0030-drops-199174}, doi = {10.4230/LIPIcs.FUN.2024.9}, annote = {Keywords: Factorio, splitter networks, flow, balancer, steady-state} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.10    

 How Did They Design This Game? Swish: Complexity and Unplayable Positions   
 Authors:  Antoine Dailly, Pascal Lafourcade, and Gaël Marcadet  
  Abstract    
 Swish is a competitive pattern recognition card-based game, in which players are trying to find a valid cards superposition from a set of cards, called a "swish". By the nature of the game, one may expect to easily recover the logic of the Swish’s designers. However, no justification appears to explain the number of cards, of duplicates, but also under which circumstances no player can find a swish. In this work, we formally investigate Swish. In the commercial version of the game, we observe that there exist large sets of cards with no swish, and find a construction to generate large sets of cards without swish. More importantly, in the general case with larger cards, we prove that Swish is NP-complete.   

  Cite as    
 Antoine Dailly, Pascal Lafourcade, and Gaël Marcadet. How Did They Design This Game? Swish: Complexity and Unplayable Positions. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 10:1-10:19, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{dailly_et_al:LIPIcs.FUN.2024.10 author = {Dailly, Antoine and Lafourcade, Pascal and Marcadet, Ga\"{e}l}, title = {{How Did They Design This Game? Swish: Complexity and Unplayable Positions}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {10:1--10:19}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.10}, URN = {urn:nbn:de:0030-drops-199185}, doi = {10.4230/LIPIcs.FUN.2024.10}, annote = {Keywords: Game, Complexity, Algorithms} }  @InProceedings{dailly_et_al:LIPIcs.FUN.2024.10 author = {Dailly, Antoine and Lafourcade, Pascal and Marcadet, Ga\"{e}l}, title = {{How Did They Design This Game? Swish: Complexity and Unplayable Positions}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {10:1--10:19}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.10}, URN = {urn:nbn:de:0030-drops-199185}, doi = {10.4230/LIPIcs.FUN.2024.10}, annote = {Keywords: Game, Complexity, Algorithms} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.11    

 Hamiltonian Paths and Cycles in NP-Complete Puzzles   
 Authors:  Marnix Deurloo, Mitchell Donkers, Mieke Maarse, Benjamin G. Rin, and Karen Schutte  
  Abstract    
 We show that several pen-and-paper puzzles are NP-complete by giving polynomial-time reductions from the Hamiltonian path and Hamiltonian cycle problems on grid graphs with maximum degree 3. The puzzles include Dotchi Loop, Chains, Linesweeper, Arukone{}₃ (also called Numberlink₃), and Araf. In addition, we show that this type of proof can still be used to prove the NP-completeness of Dotchi Loop even when the available puzzle instances are heavily restricted. Together, these results suggest that this approach holds promise in general for finding NP-completeness proofs of many pen-and-paper puzzles.   

  Cite as    
 Marnix Deurloo, Mitchell Donkers, Mieke Maarse, Benjamin G. Rin, and Karen Schutte. Hamiltonian Paths and Cycles in NP-Complete Puzzles. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 11:1-11:25, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{deurloo_et_al:LIPIcs.FUN.2024.11 author = {Deurloo, Marnix and Donkers, Mitchell and Maarse, Mieke and Rin, Benjamin G. and Schutte, Karen}, title = {{Hamiltonian Paths and Cycles in NP-Complete Puzzles}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {11:1--11:25}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.11}, URN = {urn:nbn:de:0030-drops-199199}, doi = {10.4230/LIPIcs.FUN.2024.11}, annote = {Keywords: Hamiltonicity, NP-completeness, complexity theory, pen-and-paper puzzles} }  @InProceedings{deurloo_et_al:LIPIcs.FUN.2024.11 author = {Deurloo, Marnix and Donkers, Mitchell and Maarse, Mieke and Rin, Benjamin G. and Schutte, Karen}, title = {{Hamiltonian Paths and Cycles in NP-Complete Puzzles}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {11:1--11:25}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.11}, URN = {urn:nbn:de:0030-drops-199199}, doi = {10.4230/LIPIcs.FUN.2024.11}, annote = {Keywords: Hamiltonicity, NP-completeness, complexity theory, pen-and-paper puzzles} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.12    

 Card-Based Cryptography Meets Differential Privacy   
 Authors:  Reo Eriguchi, Kazumasa Shinagawa, and Takao Murakami  
  Abstract    
 Card-based cryptography studies the problem of implementing cryptographic algorithms in a visual way using physical cards to demonstrate their security properties for those who are unfamiliar with cryptography. In this paper, we initiate the study of card-based implementations of differentially private mechanisms, which are a standard privacy-enhancing technique to publish statistics of databases while protecting the privacy of any particular individual. We start with giving the definition of differential privacy of card-based protocols. As a feasibility result, we present three kinds of protocols using standard binary cards for computing the sum of parties' binary inputs, f(x₁,…,x_n) = ∑ⁿ_{i=1} x_i for x_i ∈ {0,1}, under differential privacy. Our first protocol follows the framework of output perturbation, which provides differential privacy by adding noise to exact aggregation results. The protocol needs only two shuffles, and the overheads in the number of cards and the error bound are independent of the number n of parties. Our second and third protocols are based on Randomized Response, which adds noise to each input before aggregation. Compared to the first protocol, they improve the overheads in the number of cards and the error bound in terms of differential privacy parameters at the cost of incurring a multiplicative factor of n. To address a technical challenge of generating non-uniform noise using a finite number of cards, we propose a novel differentially private mechanism based on the hypergeometric distribution, which we believe may be of independent interest beyond applications to card-based cryptography.   

  Cite as    
 Reo Eriguchi, Kazumasa Shinagawa, and Takao Murakami. Card-Based Cryptography Meets Differential Privacy. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 12:1-12:20, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{eriguchi_et_al:LIPIcs.FUN.2024.12 author = {Eriguchi, Reo and Shinagawa, Kazumasa and Murakami, Takao}, title = {{Card-Based Cryptography Meets Differential Privacy}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {12:1--12:20}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.12}, URN = {urn:nbn:de:0030-drops-199206}, doi = {10.4230/LIPIcs.FUN.2024.12}, annote = {Keywords: Card-based cryptography, Differential privacy, Secure computation} }  @InProceedings{eriguchi_et_al:LIPIcs.FUN.2024.12 author = {Eriguchi, Reo and Shinagawa, Kazumasa and Murakami, Takao}, title = {{Card-Based Cryptography Meets Differential Privacy}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {12:1--12:20}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.12}, URN = {urn:nbn:de:0030-drops-199206}, doi = {10.4230/LIPIcs.FUN.2024.12}, annote = {Keywords: Card-based cryptography, Differential privacy, Secure computation} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.13    

 The Great Textual Hoax: Boosting Sampled String Matching with Fake Samples   
 Authors:  Simone Faro, Francesco Pio Marino, Andrea Moschetto, Arianna Pavone, and Antonio Scardace  
  Abstract    
 Sampled String Matching is presented as an efficient solution to the string matching problem, aiming to tackle the space constraints of indexed string matching while purportedly reducing search times for online solutions. Despite the problem’s inception dating back to 1991, practical solutions have only recently emerged. These purportedly accelerate online searches by up to 35 times compared to conventional methods, achieved through a partial index occupying a mere 5% of the text size. This paper delves into the intricacies of one of the latest and most effective text sampling techniques, character distance sampling, which revolves around sampling distances between characters of a selected alphabet within the text. Specifically, we introduce fake samples while remaining honest! In other words, the study reveals that, interestingly, strategically introducing fake samples within the sampled sequence slashes the required index space by almost half, just avoid compromising the algorithm’s correctness. Additionally, since efficiency is everything, this approach, in turn, purportedly enhances the algorithm’s efficiency under specific conditions.   

  Cite as    
 Simone Faro, Francesco Pio Marino, Andrea Moschetto, Arianna Pavone, and Antonio Scardace. The Great Textual Hoax: Boosting Sampled String Matching with Fake Samples. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 13:1-13:17, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{faro_et_al:LIPIcs.FUN.2024.13 author = {Faro, Simone and Marino, Francesco Pio and Moschetto, Andrea and Pavone, Arianna and Scardace, Antonio}, title = {{The Great Textual Hoax: Boosting Sampled String Matching with Fake Samples}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {13:1--13:17}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.13}, URN = {urn:nbn:de:0030-drops-199211}, doi = {10.4230/LIPIcs.FUN.2024.13}, annote = {Keywords: string matching, sampling} }  @InProceedings{faro_et_al:LIPIcs.FUN.2024.13 author = {Faro, Simone and Marino, Francesco Pio and Moschetto, Andrea and Pavone, Arianna and Scardace, Antonio}, title = {{The Great Textual Hoax: Boosting Sampled String Matching with Fake Samples}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {13:1--13:17}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.13}, URN = {urn:nbn:de:0030-drops-199211}, doi = {10.4230/LIPIcs.FUN.2024.13}, annote = {Keywords: string matching, sampling} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.14    

 PackIt!: Gamified Rectangle Packing   
 Authors:  Thomas Garrison, Marijn J. H. Heule, and Bernardo Subercaseaux  
  Abstract    
 We present and analyze PackIt!, a turn-based game consisting of packing rectangles on an n × n grid. PackIt! can be easily played on paper, either as a competitive two-player game or in solitaire fashion. On the t-th turn, a rectangle of area t or t+1 must be placed in the grid. In the two-player format of PackIt! whichever player places a rectangle last wins, whereas the goal in the solitaire variant is to perfectly pack the n × n grid. We analyze necessary conditions for the existence of a perfect packing over n × n, then present an automated reasoning approach that allows finding perfect games of PackIt! up to n = 50 which includes a novel SAT-encoding technique of independent interest, and conclude by proving an NP-hardness result.   

  Cite as    
 Thomas Garrison, Marijn J. H. Heule, and Bernardo Subercaseaux. PackIt!: Gamified Rectangle Packing. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 14:1-14:19, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{garrison_et_al:LIPIcs.FUN.2024.14 author = {Garrison, Thomas and Heule, Marijn J. H. and Subercaseaux, Bernardo}, title = {{PackIt!: Gamified Rectangle Packing}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {14:1--14:19}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.14}, URN = {urn:nbn:de:0030-drops-199226}, doi = {10.4230/LIPIcs.FUN.2024.14}, annote = {Keywords: PackIt!, rectangle packing, SAT, NP-hardness} }  @InProceedings{garrison_et_al:LIPIcs.FUN.2024.14 author = {Garrison, Thomas and Heule, Marijn J. H. and Subercaseaux, Bernardo}, title = {{PackIt!: Gamified Rectangle Packing}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {14:1--14:19}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.14}, URN = {urn:nbn:de:0030-drops-199226}, doi = {10.4230/LIPIcs.FUN.2024.14}, annote = {Keywords: PackIt!, rectangle packing, SAT, NP-hardness} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.15    

 Polyamorous Scheduling   
 Authors:  Leszek Gąsieniec, Benjamin Smith, and Sebastian Wild  
  Abstract    
 Finding schedules for pairwise meetings between the members of a complex social group without creating interpersonal conflict is challenging, especially when different relationships have different needs. We formally define and study the underlying optimisation problem: Polyamorous Scheduling. In Polyamorous Scheduling, we are given an edge-weighted graph and try to find a periodic schedule of matchings in this graph such that the maximal weighted waiting time between consecutive occurrences of the same edge is minimised. We show that the problem is NP-hard and that there is no efficient approximation algorithm with a better ratio than 4/3 unless P = NP. On the positive side, we obtain an O(log n)-approximation algorithm; indeed, an O(log Δ)-approximation for Δ the maximum degree, i.e., the largest number of relationships of any individual. We also define a generalisation of density from the Pinwheel Scheduling Problem, "poly density", and ask whether there exists a poly-density threshold similar to the 5/6-density threshold for Pinwheel Scheduling [Kawamura, STOC 2024]. Polyamorous Scheduling is a natural generalisation of Pinwheel Scheduling with respect to its optimisation variant, Bamboo Garden Trimming. Our work contributes the first nontrivial hardness-of-approximation reduction for any periodic scheduling problem, and opens up numerous avenues for further study of Polyamorous Scheduling.   

  Cite as    
 Leszek Gąsieniec, Benjamin Smith, and Sebastian Wild. Polyamorous Scheduling. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 15:1-15:18, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{gasieniec_et_al:LIPIcs.FUN.2024.15 author = {G\k{a}sieniec, Leszek and Smith, Benjamin and Wild, Sebastian}, title = {{Polyamorous Scheduling}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {15:1--15:18}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.15}, URN = {urn:nbn:de:0030-drops-199234}, doi = {10.4230/LIPIcs.FUN.2024.15}, annote = {Keywords: Periodic scheduling, Pinwheel scheduling, Edge-coloring, Chromatic index, Approximation algorithms, Hardness of approximation} }  @InProceedings{gasieniec_et_al:LIPIcs.FUN.2024.15 author = {G\k{a}sieniec, Leszek and Smith, Benjamin and Wild, Sebastian}, title = {{Polyamorous Scheduling}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {15:1--15:18}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.15}, URN = {urn:nbn:de:0030-drops-199234}, doi = {10.4230/LIPIcs.FUN.2024.15}, annote = {Keywords: Periodic scheduling, Pinwheel scheduling, Edge-coloring, Chromatic index, Approximation algorithms, Hardness of approximation} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.16    

 Tetris Is Not Competitive   
 Authors:  Matthias Gehnen and Luca Venier  
  Abstract    
 In the video game Tetris, a player has to decide how to place pieces on a board that are revealed by the game one after another. We show that the missing information about the upcoming pieces is indeed crucial to a player’s success. We present a construction for piece sequences that force (online) players without or with a finite preview of upcoming pieces to lose while (offline) players who know the entire piece sequence can clear the board and continue to play. From a competitive analysis perspective, it follows that there cannot be any c-competitive online algorithm for various optimization goals in the context of playing Tetris. Furthermore, we improve existing results by providing a construction for piece sequences which force every player to lose for every possible board size with at least two columns. With this construction, we are also able to show that an instance with just 435 pieces is sufficient to force every player to lose on a standard-size board with ten columns and twenty rows.   

  Cite as    
 Matthias Gehnen and Luca Venier. Tetris Is Not Competitive. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 16:1-16:16, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{gehnen_et_al:LIPIcs.FUN.2024.16 author = {Gehnen, Matthias and Venier, Luca}, title = {{Tetris Is Not Competitive}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {16:1--16:16}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.16}, URN = {urn:nbn:de:0030-drops-199242}, doi = {10.4230/LIPIcs.FUN.2024.16}, annote = {Keywords: Online Algorithms, Tetris} }  @InProceedings{gehnen_et_al:LIPIcs.FUN.2024.16 author = {Gehnen, Matthias and Venier, Luca}, title = {{Tetris Is Not Competitive}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {16:1--16:16}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.16}, URN = {urn:nbn:de:0030-drops-199242}, doi = {10.4230/LIPIcs.FUN.2024.16}, annote = {Keywords: Online Algorithms, Tetris} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.17    

 Computational Complexity of Matching Match Puzzle   
 Authors:  Yuki Iburi and Ryuhei Uehara  
  Abstract    
 Various forms of graph coloring problems have been studied over the years in the society of graph theory. Recently, some original puzzles are popularized in Japanese 100-yen shops, and one of them can be formalized as a graph coloring problem in a natural way. However, this natural graph coloring problem has not been investigated in the context of the graph theory. In this paper, we investigate this puzzle as a graph coloring problem. We first prove that this graph coloring problem is NP-complete even when the graph is restricted to a path or a spider. In these cases, diameter of the graphs seems to play an important role for its difficulty. We then show that the problem can be solved in polynomial time when the graph is restricted to some graph classes of constant diameter.   

  Cite as    
 Yuki Iburi and Ryuhei Uehara. Computational Complexity of Matching Match Puzzle. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 17:1-17:10, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{iburi_et_al:LIPIcs.FUN.2024.17 author = {Iburi, Yuki and Uehara, Ryuhei}, title = {{Computational Complexity of Matching Match Puzzle}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {17:1--17:10}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.17}, URN = {urn:nbn:de:0030-drops-199251}, doi = {10.4230/LIPIcs.FUN.2024.17}, annote = {Keywords: Graph coloring, Matching Match puzzle, NP-complete, polynomial-time solvable} }  @InProceedings{iburi_et_al:LIPIcs.FUN.2024.17 author = {Iburi, Yuki and Uehara, Ryuhei}, title = {{Computational Complexity of Matching Match Puzzle}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {17:1--17:10}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.17}, URN = {urn:nbn:de:0030-drops-199251}, doi = {10.4230/LIPIcs.FUN.2024.17}, annote = {Keywords: Graph coloring, Matching Match puzzle, NP-complete, polynomial-time solvable} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.18    

 Advanced Spikes `n' Stuff: An NP-Hard Puzzle Game in Which All Tutorials Are Efficiently Solvable   
 Authors:  Christian Ikenmeyer and Dylan Khangure  
  Abstract    
 We adjust Alan Hazelden’s 2017 polynomial time solvable puzzle game Spikes `n' Stuff: We obtain the NP-complete puzzle game Advanced Spikes `n' Stuff with 3 trap types so that each strict subset of the traps results in a polynomial time solvable puzzle game. We think of this as a "hard game in which all tutorial levels are easy". The polynomial time algorithms for solving the tutorial games turn out to be quite different to each other. While numerous papers analyze the complexity of games and which game objects make a game NP-hard, our paper is the first to study a game where the NP-hardness can only be achieved by a combination of all game objects, assuming P differs from NP.   

  Cite as    
 Christian Ikenmeyer and Dylan Khangure. Advanced Spikes `n' Stuff: An NP-Hard Puzzle Game in Which All Tutorials Are Efficiently Solvable. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 18:1-18:13, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{ikenmeyer_et_al:LIPIcs.FUN.2024.18 author = {Ikenmeyer, Christian and Khangure, Dylan}, title = {{Advanced Spikes `n' Stuff: An NP-Hard Puzzle Game in Which All Tutorials Are Efficiently Solvable}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {18:1--18:13}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.18}, URN = {urn:nbn:de:0030-drops-199265}, doi = {10.4230/LIPIcs.FUN.2024.18}, annote = {Keywords: computational complexity, P vs NP, motion planning, games} }  @InProceedings{ikenmeyer_et_al:LIPIcs.FUN.2024.18 author = {Ikenmeyer, Christian and Khangure, Dylan}, title = {{Advanced Spikes `n' Stuff: An NP-Hard Puzzle Game in Which All Tutorials Are Efficiently Solvable}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {18:1--18:13}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.18}, URN = {urn:nbn:de:0030-drops-199265}, doi = {10.4230/LIPIcs.FUN.2024.18}, annote = {Keywords: computational complexity, P vs NP, motion planning, games} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.19    

 Anarchy in the APSP: Algorithm and Hardness for Incorrect Implementation of Floyd-Warshall   
 Authors:  Jaehyun Koo  
  Abstract    
 The celebrated Floyd-Warshall algorithm efficiently computes the all-pairs shortest path, and its simplicity made it a staple in computer science classes. Frequently, students discover a variant of this Floyd-Warshall algorithm by mixing up the loop order, ending up with the incorrect APSP matrix. This paper considers a computational problem of computing this incorrect APSP matrix. We will propose efficient algorithms for this problem and prove that this incorrect variant is APSP-complete.   

  Cite as    
 Jaehyun Koo. Anarchy in the APSP: Algorithm and Hardness for Incorrect Implementation of Floyd-Warshall. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 19:1-19:11, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{koo:LIPIcs.FUN.2024.19 author = {Koo, Jaehyun}, title = {{Anarchy in the APSP: Algorithm and Hardness for Incorrect Implementation of Floyd-Warshall}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {19:1--19:11}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.19}, URN = {urn:nbn:de:0030-drops-199270}, doi = {10.4230/LIPIcs.FUN.2024.19}, annote = {Keywords: fine-grained complexity, recreational algorithms} }  @InProceedings{koo:LIPIcs.FUN.2024.19 author = {Koo, Jaehyun}, title = {{Anarchy in the APSP: Algorithm and Hardness for Incorrect Implementation of Floyd-Warshall}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {19:1--19:11}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.19}, URN = {urn:nbn:de:0030-drops-199270}, doi = {10.4230/LIPIcs.FUN.2024.19}, annote = {Keywords: fine-grained complexity, recreational algorithms} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.20    

 Variations on the Tournament Problem   
 Authors:  Fabrizio Luccio, Linda Pagli, and Nicola Santoro  
  Abstract    
 In 1883, Lewis Carrol wrote a newspaper article to criticize how the second best player was determined in a tennis tournament, and to suggest how such a task could be done correctly. This article has been taken by Donald Knuth as the inspiration for efficiently determining the smallest t elements of a totally ordered set of size n using k-comparisons. In the ensuing research, optimal algorithms for some low values of k and t have been established, by Knuth and Aigner; for k = 2 and t ≤ 3, a few new bounds have been established for special values of n. Surprisingly, very little else is known on this problem, in spite of its illustrious pedigree and its relationship to other classical problems (e.g., selection and sorting with k-sorters). Enticed by the undeniable beauty of the problem, and the obvious promise of fun, we have joined the investigative quest. The purpose of this paper is to share some new results obtained so far. We are glad to report advances in two directions.   

  Cite as    
 Fabrizio Luccio, Linda Pagli, and Nicola Santoro. Variations on the Tournament Problem. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 20:1-20:11, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{luccio_et_al:LIPIcs.FUN.2024.20 author = {Luccio, Fabrizio and Pagli, Linda and Santoro, Nicola}, title = {{Variations on the Tournament Problem}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {20:1--20:11}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.20}, URN = {urn:nbn:de:0030-drops-199280}, doi = {10.4230/LIPIcs.FUN.2024.20}, annote = {Keywords: algorithms, parallel algorithms, tournament, selection, ranking} }  @InProceedings{luccio_et_al:LIPIcs.FUN.2024.20 author = {Luccio, Fabrizio and Pagli, Linda and Santoro, Nicola}, title = {{Variations on the Tournament Problem}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {20:1--20:11}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.20}, URN = {urn:nbn:de:0030-drops-199280}, doi = {10.4230/LIPIcs.FUN.2024.20}, annote = {Keywords: algorithms, parallel algorithms, tournament, selection, ranking} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.21    

 PSPACE-Hard 2D Super Mario Games: Thirteen Doors   
 Authors:  MIT Hardness Group, Hayashi Ani, Erik D. Demaine, Holden Hall, and Matias Korman  
  Abstract    
 We prove PSPACE-hardness for fifteen games in the Super Mario Bros. 2D platforming video game series. Previously, only the original Super Mario Bros. was known to be PSPACE-hard (FUN 2016), though several of the games we study were known to be NP-hard (FUN 2014). Our reductions build door gadgets with open, close, and traverse traversals, in each case using mechanics unique to the game. While some of our door constructions are similar to those from FUN 2016, those for Super Mario Bros. 2, Super Mario Land 2, Super Mario World 2, and the New Super Mario Bros. series are quite different; notably, the Super Mario Bros. 2 door is extremely difficult. Doors remain elusive for just two 2D Mario games (Super Mario Land and Super Mario Run); we prove that these games are at least NP-hard.   

  Cite as    
 MIT Hardness Group, Hayashi Ani, Erik D. Demaine, Holden Hall, and Matias Korman. PSPACE-Hard 2D Super Mario Games: Thirteen Doors. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 21:1-21:19, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{mithardnessgroup_et_al:LIPIcs.FUN.2024.21 author = {MIT Hardness Group and Ani, Hayashi and Demaine, Erik D. and Hall, Holden and Korman, Matias}, title = {{PSPACE-Hard 2D Super Mario Games: Thirteen Doors}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {21:1--21:19}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.21}, URN = {urn:nbn:de:0030-drops-199295}, doi = {10.4230/LIPIcs.FUN.2024.21}, annote = {Keywords: video games, computational complexity, PSPACE} }  @InProceedings{mithardnessgroup_et_al:LIPIcs.FUN.2024.21 author = {MIT Hardness Group and Ani, Hayashi and Demaine, Erik D. and Hall, Holden and Korman, Matias}, title = {{PSPACE-Hard 2D Super Mario Games: Thirteen Doors}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {21:1--21:19}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.21}, URN = {urn:nbn:de:0030-drops-199295}, doi = {10.4230/LIPIcs.FUN.2024.21}, annote = {Keywords: video games, computational complexity, PSPACE} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.22    

 You Can't Solve These Super Mario Bros. Levels: Undecidable Mario Games   
 Authors:  MIT Hardness Group, Hayashi Ani, Erik D. Demaine, Holden Hall, Ricardo Ruiz, and Naveen Venkat  
  Abstract    
 We prove RE-completeness (and thus undecidability) of several 2D games in the Super Mario Bros. platform video game series: the New Super Mario Bros. series (original, Wii, U, and 2), and both Super Mario Maker games in all five game styles (Super Mario Bros. 1 and 3, Super Mario World, New Super Mario Bros. U, and Super Mario 3D World). These results hold even when we restrict to constant-size levels and screens, but they do require generalizing to allow arbitrarily many enemies at each location and onscreen, as well as allowing for exponentially large (or no) timer. In our Super Mario Maker reductions, we work within the standard screen size and use the property that the game engine remembers offscreen objects that are global because they are supported by "global ground". To prove these Mario results, we build a new theory of counter gadgets in the motion-planning-through-gadgets framework, and provide a suite of simple gadgets for which reachability is RE-complete.   

  Cite as    
 MIT Hardness Group, Hayashi Ani, Erik D. Demaine, Holden Hall, Ricardo Ruiz, and Naveen Venkat. You Can't Solve These Super Mario Bros. Levels: Undecidable Mario Games. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 22:1-22:20, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{mithardnessgroup_et_al:LIPIcs.FUN.2024.22 author = {MIT Hardness Group and Ani, Hayashi and Demaine, Erik D. and Hall, Holden and Ruiz, Ricardo and Venkat, Naveen}, title = {{You Can't Solve These Super Mario Bros. Levels: Undecidable Mario Games}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {22:1--22:20}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.22}, URN = {urn:nbn:de:0030-drops-199302}, doi = {10.4230/LIPIcs.FUN.2024.22}, annote = {Keywords: video games, computational complexity, undecidability} }  @InProceedings{mithardnessgroup_et_al:LIPIcs.FUN.2024.22 author = {MIT Hardness Group and Ani, Hayashi and Demaine, Erik D. and Hall, Holden and Ruiz, Ricardo and Venkat, Naveen}, title = {{You Can't Solve These Super Mario Bros. Levels: Undecidable Mario Games}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {22:1--22:20}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.22}, URN = {urn:nbn:de:0030-drops-199302}, doi = {10.4230/LIPIcs.FUN.2024.22}, annote = {Keywords: video games, computational complexity, undecidability} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.23    

 ASP-Completeness of Hamiltonicity in Grid Graphs, with Applications to Loop Puzzles   
 Authors:  MIT Hardness Group, Josh Brunner, Lily Chung, Erik D. Demaine, Della Hendrickson, and Andy Tockman  
  Abstract    
 We prove that Hamiltonicity in maximum-degree-3 grid graphs (directed or undirected) is ASP-complete, i.e., it has a parsimonious reduction from every NP search problem (including a polynomial-time bijection between solutions). As a consequence, given k Hamiltonian cycles, it is NP-complete to find another; and counting Hamiltonian cycles is #P-complete. If we require the grid graph’s vertices to form a full m × n rectangle, then we show that Hamiltonicity remains ASP-complete if the edges are directed or if we allow removing some edges (whereas including all undirected edges is known to be easy). These results enable us to develop a stronger "T-metacell" framework for proving ASP-completeness of rectangular puzzles, which requires building just a single gadget representing a degree-3 grid-graph vertex. We apply this general theory to prove ASP-completeness of 37 pencil-and-paper puzzles where the goal is to draw a loop subject to given constraints: Slalom, Onsen-meguri, Mejilink, Detour, Tapa-Like Loop, Kouchoku, Icelom; Masyu, Yajilin, Nagareru, Castle Wall, Moon or Sun, Country Road, Geradeweg, Maxi Loop, Mid-loop, Balance Loop, Simple Loop, Haisu, Reflect Link, Linesweeper; Vertex/Touch Slitherlink, Dotchi-Loop, Ovotovata, Building Walk, Rail Pool, Disorderly Loop, Ant Mill, Koburin, Mukkonn Enn, Rassi Silai, (Crossing) Ichimaga, Tapa, Canal View, and Aqre. The last 13 of these puzzles were not even known to be NP-hard. Along the way, we prove ASP-completeness of some simple forms of Tree-Residue Vertex-Breaking (TRVB), including planar multigraphs with degree-6 breakable vertices, or with degree-4 breakable and degree-1 unbreakable vertices.   

  Cite as    
 MIT Hardness Group, Josh Brunner, Lily Chung, Erik D. Demaine, Della Hendrickson, and Andy Tockman. ASP-Completeness of Hamiltonicity in Grid Graphs, with Applications to Loop Puzzles. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 23:1-23:20, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{mithardnessgroup_et_al:LIPIcs.FUN.2024.23 author = {MIT Hardness Group and Brunner, Josh and Chung, Lily and Demaine, Erik D. and Hendrickson, Della and Tockman, Andy}, title = {{ASP-Completeness of Hamiltonicity in Grid Graphs, with Applications to Loop Puzzles}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {23:1--23:20}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.23}, URN = {urn:nbn:de:0030-drops-199314}, doi = {10.4230/LIPIcs.FUN.2024.23}, annote = {Keywords: pencil-and-paper puzzles, computational complexity, parsimony} }  @InProceedings{mithardnessgroup_et_al:LIPIcs.FUN.2024.23 author = {MIT Hardness Group and Brunner, Josh and Chung, Lily and Demaine, Erik D. and Hendrickson, Della and Tockman, Andy}, title = {{ASP-Completeness of Hamiltonicity in Grid Graphs, with Applications to Loop Puzzles}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {23:1--23:20}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.23}, URN = {urn:nbn:de:0030-drops-199314}, doi = {10.4230/LIPIcs.FUN.2024.23}, annote = {Keywords: pencil-and-paper puzzles, computational complexity, parsimony} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.24    

 Tetris with Few Piece Types   
 Authors:  MIT Hardness Group, Erik D. Demaine, Holden Hall, and Jeffery Li  
  Abstract    
 We prove NP-hardness and #P-hardness of Tetris clearing (clearing an initial board using a given sequence of pieces) with the Super Rotation System (SRS), even when the pieces are limited to any two of the seven Tetris piece types. This result is the first advance on a question posed twenty years ago: which piece sets are easy vs. hard? All previous Tetris NP-hardness proofs used five of the seven piece types. We also prove ASP-completeness of Tetris clearing, using three piece types, as well as versions of 3-Partition and Numerical 3-Dimensional Matching where all input integers are distinct. Finally, we prove NP-hardness of Tetris survival and clearing under the "hard drops only" and "20G" modes, using two piece types, improving on a previous "hard drops only" result that used five piece types.   

  Cite as    
 MIT Hardness Group, Erik D. Demaine, Holden Hall, and Jeffery Li. Tetris with Few Piece Types. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 24:1-24:18, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{mithardnessgroup_et_al:LIPIcs.FUN.2024.24 author = {MIT Hardness Group and Demaine, Erik D. and Hall, Holden and Li, Jeffery}, title = {{Tetris with Few Piece Types}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {24:1--24:18}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.24}, URN = {urn:nbn:de:0030-drops-199322}, doi = {10.4230/LIPIcs.FUN.2024.24}, annote = {Keywords: complexity, hardness, video games, counting} }  @InProceedings{mithardnessgroup_et_al:LIPIcs.FUN.2024.24 author = {MIT Hardness Group and Demaine, Erik D. and Hall, Holden and Li, Jeffery}, title = {{Tetris with Few Piece Types}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {24:1--24:18}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.24}, URN = {urn:nbn:de:0030-drops-199322}, doi = {10.4230/LIPIcs.FUN.2024.24}, annote = {Keywords: complexity, hardness, video games, counting} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.25    

 Complexity of Planar Graph Orientation Consistency, Promise-Inference, and Uniqueness, with Applications to Minesweeper Variants   
 Authors:  MIT Hardness Group, Della Hendrickson, and Andy Tockman  
  Abstract    
 We study three problems related to the computational complexity of the popular game Minesweeper. The first is consistency: given a set of clues, is there any arrangement of mines that satisfies it? This problem has been known to be NP-complete since 2000 [Kaye, 2000], but our framework proves it as a side effect. The second is inference: given a set of clues, is there any cell that the player can prove is safe? The coNP-completeness of this problem has been in the literature since 2011 [Scott et al., 2011], but we discovered a flaw that we believe is present in all published results, and we provide a fixed proof. Finally, the third is solvability: given the full state of a Minesweeper game, can the player win the game by safely clicking all non-mine cells? This problem has not yet been studied, and we prove that it is coNP-complete.   

  Cite as    
 MIT Hardness Group, Della Hendrickson, and Andy Tockman. Complexity of Planar Graph Orientation Consistency, Promise-Inference, and Uniqueness, with Applications to Minesweeper Variants. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 25:1-25:20, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{mithardnessgroup_et_al:LIPIcs.FUN.2024.25 author = {MIT Hardness Group and Hendrickson, Della and Tockman, Andy}, title = {{Complexity of Planar Graph Orientation Consistency, Promise-Inference, and Uniqueness, with Applications to Minesweeper Variants}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {25:1--25:20}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.25}, URN = {urn:nbn:de:0030-drops-199335}, doi = {10.4230/LIPIcs.FUN.2024.25}, annote = {Keywords: NP, coNP, hardness, minesweeper, solvability, gadgets, simulation} }  @InProceedings{mithardnessgroup_et_al:LIPIcs.FUN.2024.25 author = {MIT Hardness Group and Hendrickson, Della and Tockman, Andy}, title = {{Complexity of Planar Graph Orientation Consistency, Promise-Inference, and Uniqueness, with Applications to Minesweeper Variants}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {25:1--25:20}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.25}, URN = {urn:nbn:de:0030-drops-199335}, doi = {10.4230/LIPIcs.FUN.2024.25}, annote = {Keywords: NP, coNP, hardness, minesweeper, solvability, gadgets, simulation} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.26    

 Coordinating "7 Billion Humans" Is Hard   
 Authors:  Alessandro Panconesi, Pietro Maria Posta, and Mirko Giacchini  
  Abstract    
 In the video game "7 Billion Humans", the player is requested to direct a group of workers to various destinations by writing a program that is executed simultaneously on each worker. While the game is quite rich and, indeed, it is considered one of the best games for beginners to learn the basics of programming, we show that even extremely simple versions are already NP-Hard or PSPACE-Hard.   

  Cite as    
 Alessandro Panconesi, Pietro Maria Posta, and Mirko Giacchini. Coordinating "7 Billion Humans" Is Hard. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 26:1-26:16, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{panconesi_et_al:LIPIcs.FUN.2024.26 author = {Panconesi, Alessandro and Posta, Pietro Maria and Giacchini, Mirko}, title = {{Coordinating "7 Billion Humans" Is Hard}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {26:1--26:16}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.26}, URN = {urn:nbn:de:0030-drops-199342}, doi = {10.4230/LIPIcs.FUN.2024.26}, annote = {Keywords: video games, computational complexity, NP, PSPACE} }  @InProceedings{panconesi_et_al:LIPIcs.FUN.2024.26 author = {Panconesi, Alessandro and Posta, Pietro Maria and Giacchini, Mirko}, title = {{Coordinating "7 Billion Humans" Is Hard}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {26:1--26:16}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.26}, URN = {urn:nbn:de:0030-drops-199342}, doi = {10.4230/LIPIcs.FUN.2024.26}, annote = {Keywords: video games, computational complexity, NP, PSPACE} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.27    

 Arimaa Is PSPACE-Hard   
 Authors:  Benjamin G. Rin and Atze Schipper  
  Abstract    
 Arimaa is a strategy board game developed in 2003 by Omar Syed, designed to be hard for AI to win because of its large branching factor. In this paper, its theoretical complexity is considered. We prove that Arimaa (suitably generalized to an n × n board) is PSPACE-hard. This result is found by reducing a known PSPACE-hard variant of Generalized Geography to a variant of Arimaa that we call Arimaa^′, which in turn is then reduced to (n × n) Arimaa. Since the game is easily seen to be solvable in exponential time, it follows that its complexity lies somewhere between being PSPACE-complete and EXPTIME-complete.   

  Cite as    
 Benjamin G. Rin and Atze Schipper. Arimaa Is PSPACE-Hard. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 27:1-27:24, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{rin_et_al:LIPIcs.FUN.2024.27 author = {Rin, Benjamin G. and Schipper, Atze}, title = {{Arimaa Is PSPACE-Hard}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {27:1--27:24}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.27}, URN = {urn:nbn:de:0030-drops-199359}, doi = {10.4230/LIPIcs.FUN.2024.27}, annote = {Keywords: Arimaa, complexity theory, PSPACE-hardness, board games, Generalized Geography} }  @InProceedings{rin_et_al:LIPIcs.FUN.2024.27 author = {Rin, Benjamin G. and Schipper, Atze}, title = {{Arimaa Is PSPACE-Hard}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {27:1--27:24}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.27}, URN = {urn:nbn:de:0030-drops-199359}, doi = {10.4230/LIPIcs.FUN.2024.27}, annote = {Keywords: Arimaa, complexity theory, PSPACE-hardness, board games, Generalized Geography} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.28    

 No Tiling of the 70 × 70 Square with Consecutive Squares   
 Authors:  Jiří Sgall, János Balogh, József Békési, György Dósa, Lars Magnus Hvattum, and Zsolt Tuza  
  Abstract    
 The total area of the 24 squares of sizes 1,2,…,24 is equal to the area of the 70× 70 square. Can this equation be demonstrated by a tiling of the 70× 70 square with the 24 squares of sizes 1,2,…,24? The answer is "NO", no such tiling exists. This has been demonstrated by computer search. However, until now, no proof without use of computer was given. We fill this gap and give a complete combinatorial proof.   

  Cite as    
 Jiří Sgall, János Balogh, József Békési, György Dósa, Lars Magnus Hvattum, and Zsolt Tuza. No Tiling of the 70 × 70 Square with Consecutive Squares. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 28:1-28:16, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{sgall_et_al:LIPIcs.FUN.2024.28 author = {Sgall, Ji\v{r}{\'\i} and Balogh, J\'{a}nos and B\'{e}k\'{e}si, J\'{o}zsef and D\'{o}sa, Gy\"{o}rgy and Hvattum, Lars Magnus and Tuza, Zsolt}, title = {{No Tiling of the 70 × 70 Square with Consecutive Squares}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {28:1--28:16}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.28}, URN = {urn:nbn:de:0030-drops-199362}, doi = {10.4230/LIPIcs.FUN.2024.28}, annote = {Keywords: square packing, Gardner’s problem, combinatorial proof} }  @InProceedings{sgall_et_al:LIPIcs.FUN.2024.28 author = {Sgall, Ji\v{r}{\'\i} and Balogh, J\'{a}nos and B\'{e}k\'{e}si, J\'{o}zsef and D\'{o}sa, Gy\"{o}rgy and Hvattum, Lars Magnus and Tuza, Zsolt}, title = {{No Tiling of the 70 × 70 Square with Consecutive Squares}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {28:1--28:16}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.28}, URN = {urn:nbn:de:0030-drops-199362}, doi = {10.4230/LIPIcs.FUN.2024.28}, annote = {Keywords: square packing, Gardner’s problem, combinatorial proof} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.29    

 Achieving the Highest Possible Elo Rating   
 Authors:  Rikhav Shah  
  Abstract    
 Elo rating systems measure the approximate skill of each competitor in a game or sport. A competitor’s rating increases when they win and decreases when they lose. Increasing one’s rating can be difficult work; one must hone their skills and consistently beat the competition. Alternatively, with enough money you can rig the outcome of games to boost your rating. This paper poses a natural question for Elo rating systems: say you manage to get together n people (including yourself) and acquire enough money to rig k games. How high can you get your rating, asymptotically in k? In this setting, the people you gathered aren't very interested in the game, and will only play if you pay them to. This paper resolves the question for n = 2 up to constant additive error, and provides close upper and lower bounds for all other n, including for n growing arbitrarily with k. There is a phase transition at n = k^{1/3}: there is a huge increase in the highest possible Elo rating from n = 2 to n = k^{1/3}, but (depending on the particular Elo system used) little-to-no increase for any higher n. Past the transition point n > k^{1/3}, the highest possible Elo is at least Θ(k^{1/3}). The corresponding upper bound depends on the particular system used, but for the standard Elo system, is Θ(k^{1/3}log(k)^{1/3}).   

  Cite as    
 Rikhav Shah. Achieving the Highest Possible Elo Rating. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 29:1-29:21, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{shah:LIPIcs.FUN.2024.29 author = {Shah, Rikhav}, title = {{Achieving the Highest Possible Elo Rating}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {29:1--29:21}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.29}, URN = {urn:nbn:de:0030-drops-199376}, doi = {10.4230/LIPIcs.FUN.2024.29}, annote = {Keywords: Elo, rating system, monotonic invariant, Euler’s method, mass movement} }  @InProceedings{shah:LIPIcs.FUN.2024.29 author = {Shah, Rikhav}, title = {{Achieving the Highest Possible Elo Rating}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {29:1--29:21}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.29}, URN = {urn:nbn:de:0030-drops-199376}, doi = {10.4230/LIPIcs.FUN.2024.29}, annote = {Keywords: Elo, rating system, monotonic invariant, Euler’s method, mass movement} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.30    

 How to Covertly and Uniformly Scramble the 15 Puzzle and Rubik’s Cube   
 Authors:  Kazumasa Shinagawa, Kazuki Kanai, Kengo Miyamoto, and Koji Nuida  
  Abstract    
 A combination puzzle is a puzzle consisting of a set of pieces that can be rearranged into various combinations, such as the 15 Puzzle and Rubik’s Cube. Suppose a speedsolving competition for a combination puzzle is to be held. To make the competition fair, we need to generate an instance (i.e., a state having a solution) that is chosen uniformly at random and unknown to anyone. We call this problem a secure random instance generation of the puzzle. In this paper, we construct secure random instance generation protocols for the 15 Puzzle and for Rubik’s Cube. Our method is based on uniform cyclic group factorizations for finite groups, which is recently introduced by the same authors, applied to permutation groups for the puzzle instances. Specifically, our protocols require 19 shuffles for the 15 Puzzle and 43 shuffles for Rubik’s Cube.   

  Cite as    
 Kazumasa Shinagawa, Kazuki Kanai, Kengo Miyamoto, and Koji Nuida. How to Covertly and Uniformly Scramble the 15 Puzzle and Rubik’s Cube. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 30:1-30:15, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{shinagawa_et_al:LIPIcs.FUN.2024.30 author = {Shinagawa, Kazumasa and Kanai, Kazuki and Miyamoto, Kengo and Nuida, Koji}, title = {{How to Covertly and Uniformly Scramble the 15 Puzzle and Rubik’s Cube}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {30:1--30:15}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.30}, URN = {urn:nbn:de:0030-drops-199385}, doi = {10.4230/LIPIcs.FUN.2024.30}, annote = {Keywords: Card-based cryptography, Uniform cyclic group factorization, Secure random instance generation, The 15 Puzzle, Rubik’s Cube} }  @InProceedings{shinagawa_et_al:LIPIcs.FUN.2024.30 author = {Shinagawa, Kazumasa and Kanai, Kazuki and Miyamoto, Kengo and Nuida, Koji}, title = {{How to Covertly and Uniformly Scramble the 15 Puzzle and Rubik’s Cube}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {30:1--30:15}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.30}, URN = {urn:nbn:de:0030-drops-199385}, doi = {10.4230/LIPIcs.FUN.2024.30}, annote = {Keywords: Card-based cryptography, Uniform cyclic group factorization, Secure random instance generation, The 15 Puzzle, Rubik’s Cube} }    

  Document   
 DOI: 10.4230/LIPIcs.FUN.2024.31    

 A Programming Language Embedded in Magic: The Gathering   
 Authors:  Howe Choong Yin and Alex Churchill  
  Abstract    
 Previous work demonstrated that the trading card game Magic: The Gathering is Turing complete, by embedding a universal Turing machine inside the game. However, this is extremely hard to program, and known programs are extremely inefficient. We demonstrate techniques for disabling Magic cards except when certain conditions are met, and use them to build a microcontroller with a versatile programming language embedded within a Magic game state. We remove all choices made by players, forcing all player moves except when a program instruction asks a player for input. This demonstrates Magic to be at least as complex as any two-player perfect knowledge game, which we demonstrate by supplying sample programs for Nim and the Collatz conjecture embedded in Magic. As with previous work, our result applies to how real Magic is played, and can be achieved using a tournament-legal deck; but the execution is far faster than previous constructions, generally one cycle of game turns per program instruction.   

  Cite as    
 Howe Choong Yin and Alex Churchill. A Programming Language Embedded in Magic: The Gathering. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 31:1-31:19, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{yin_et_al:LIPIcs.FUN.2024.31 author = {Yin, Howe Choong and Churchill, Alex}, title = {{A Programming Language Embedded in Magic: The Gathering}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {31:1--31:19}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.31}, URN = {urn:nbn:de:0030-drops-199391}, doi = {10.4230/LIPIcs.FUN.2024.31}, annote = {Keywords: Programming, computability theory, Magic: the Gathering, two-player games, tabletop games} }  @InProceedings{yin_et_al:LIPIcs.FUN.2024.31 author = {Yin, Howe Choong and Churchill, Alex}, title = {{A Programming Language Embedded in Magic: The Gathering}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {31:1--31:19}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.31}, URN = {urn:nbn:de:0030-drops-199391}, doi = {10.4230/LIPIcs.FUN.2024.31}, annote = {Keywords: Programming, computability theory, Magic: the Gathering, two-player games, tabletop games} }    

  Document   
 Salon des Refusés   
 DOI: 10.4230/LIPIcs.FUN.2024.32    

 Eating Ice-Cream with a Colander   
 Authors:  Kien Huynh and Valentin Polishchuk  
  Abstract    
 k-order α-hull is a generalization of both k-hull and α-shape (which are generalizations of convex hull); since its introduction in a 2014 IPL paper (which also established its combinatorial properties and gave efficient algorithms to compute it), it was used in a variety of applications (as witnessed by 38 citations in Google Scholar) ranging from computer graphics to hydrology to seismology. The subject must have been so rich and complex that it took more than a year to review the submission at IPL (which was chosen as the venue "Devoted to the Rapid Publication"), as may be witnessed by the timeline in the paper header. Nonetheless it was not rich enough to warrant publication at SODA 2009 and WADS 2009 (the reviews saying it is not yet ready for the prime time - cited from memory) nor in FUN 2010 to which the paper was submitted under the title "Eating Ice-Cream with Colander"   

  Cite as    
 Kien Huynh and Valentin Polishchuk. Eating Ice-Cream with a Colander. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 32:1-32:4, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{huynh_et_al:LIPIcs.FUN.2024.32 author = {Huynh, Kien and Polishchuk, Valentin}, title = {{Eating Ice-Cream with a Colander}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {32:1--32:4}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.32}, URN = {urn:nbn:de:0030-drops-199408}, doi = {10.4230/LIPIcs.FUN.2024.32}, annote = {Keywords: computational geometry, alpha-shape, k-hull, robust shape reconstruction} }  @InProceedings{huynh_et_al:LIPIcs.FUN.2024.32 author = {Huynh, Kien and Polishchuk, Valentin}, title = {{Eating Ice-Cream with a Colander}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {32:1--32:4}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.32}, URN = {urn:nbn:de:0030-drops-199408}, doi = {10.4230/LIPIcs.FUN.2024.32}, annote = {Keywords: computational geometry, alpha-shape, k-hull, robust shape reconstruction} }    

  Document   
 Salon des Refusés   
 DOI: 10.4230/LIPIcs.FUN.2024.33    

 Retrospective: Avoiding the Disk Bottleneck in the Data Domain Deduplication File System   
 Authors:  Kai Li  
  Abstract    
 The paper titled "Avoiding the Disk Bottleneck in the Data Domain Deduplication File System" [Zhu et al., 2008] describes several fundamental ideas behind the file system that drives Data Domain’s deduplication storage products. Initially submitted to the 2007 ACM SIGOPS Symposium on Operating System Principles (SOSP), the paper was rejected by its program committee. It was subsequently submitted and accepted for publication at the USENIX Conference on File And Storage Technologies (FAST) in 2008. Twelve years later, it was honored with the USENIX Test-of-Time Award. This retrospective explores the paper’s historical significance and impact, analyzes the reasons behind its initial rejection, and suggests methods to enhance the paper review process in the academic community.   

  Cite as    
 Kai Li. Retrospective: Avoiding the Disk Bottleneck in the Data Domain Deduplication File System. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 33:1-33:4, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{li:LIPIcs.FUN.2024.33 author = {Li, Kai}, title = {{Retrospective: Avoiding the Disk Bottleneck in the Data Domain Deduplication File System}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {33:1--33:4}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.33}, URN = {urn:nbn:de:0030-drops-199417}, doi = {10.4230/LIPIcs.FUN.2024.33}, annote = {Keywords: Deduplication, file systems, compression} }  @InProceedings{li:LIPIcs.FUN.2024.33 author = {Li, Kai}, title = {{Retrospective: Avoiding the Disk Bottleneck in the Data Domain Deduplication File System}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {33:1--33:4}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.33}, URN = {urn:nbn:de:0030-drops-199417}, doi = {10.4230/LIPIcs.FUN.2024.33}, annote = {Keywords: Deduplication, file systems, compression} }    

  Document   
 Salon des Refusés   
 DOI: 10.4230/LIPIcs.FUN.2024.34    

 Short Programs for Functions on Curves: A STOC Rejection   
 Authors:  Victor S. Miller  
  Abstract    
 In 1986 I submitted a note "Short Programs for functions on curves" to the STOC conference. It was rejected. Since it seemed to be a paper that would only be interesting to a very small group of people, I didn't try to publish it, but instead circulated it among people who, I thought, would be interested in it. However, about 11 years later I was contacted by Dan Boneh, to whom I had given a copy a few years previously, who said that the algorithm in my paper had important applications. Since then it has become a core algorithm in the field of "Pairing Based Cryptography".   

  Cite as    
 Victor S. Miller. Short Programs for Functions on Curves: A STOC Rejection. In 12th International Conference on Fun with Algorithms (FUN 2024). Leibniz International Proceedings in Informatics (LIPIcs), Volume 291, pp. 34:1-34:4, Schloss Dagstuhl – Leibniz-Zentrum für Informatik (2024)  
   Copy BibTex To Clipboard    
   
  @InProceedings{miller:LIPIcs.FUN.2024.34 author = {Miller, Victor S.}, title = {{Short Programs for Functions on Curves: A STOC Rejection}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {34:1--34:4}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.34}, URN = {urn:nbn:de:0030-drops-199427}, doi = {10.4230/LIPIcs.FUN.2024.34}, annote = {Keywords: Elliptic Curves, Finite Fields, Weil Pairing, Straight Line Program} }  @InProceedings{miller:LIPIcs.FUN.2024.34 author = {Miller, Victor S.}, title = {{Short Programs for Functions on Curves: A STOC Rejection}}, booktitle = {12th International Conference on Fun with Algorithms (FUN 2024)}, pages = {34:1--34:4}, series = {Leibniz International Proceedings in Informatics (LIPIcs)}, ISBN = {978-3-95977-314-0}, ISSN = {1868-8969}, year = {2024}, volume = {291}, editor = {Broder, Andrei Z. and Tamir, Tami}, publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik}, address = {Dagstuhl, Germany}, URL = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.FUN.2024.34}, URN = {urn:nbn:de:0030-drops-199427}, doi = {10.4230/LIPIcs.FUN.2024.34}, annote = {Keywords: Elliptic Curves, Finite Fields, Weil Pairing, Straight Line Program} }    

 Filters  

 Authors 
   Show All  Collapse 
  Show All 
  A 
  Abel, Zachary 
  Ani, Hayashi 
  B 
  Bagan, Guillaume 
  Balogh, János 
  Békési, József 
  Bille, Philip 
  Bilò, Davide 
  Brodal, Gerth Stølting 
  Broder, Andrei Z. 
  Brunner, Josh 
  Bultel, Xavier 
  Burke, Kyle 
  C 
  Chung, Lily 
  Churchill, Alex 
  Couëtoux, Basile 
  D 
  Dailly, Antoine 
  Demaine, Erik D. 
  Deurloo, Marnix 
  Di Donato, Luca 
  Donkers, Mitchell 
  Dósa, György 
  Duchêne, Eric 
  E 
  Eriguchi, Reo 
  F 
  Farach-Colton, Martín 
  Faro, Simone 
  Ferland, Matthew 
  Fiusco, Maurizio 
  G 
  Galliot, Florian 
  Garrison, Thomas 
  Gąsieniec, Leszek 
  Gastaldi, Bastien 
  Gehnen, Matthias 
  Giacchini, Mirko 
  Gledel, Valentin 
  Gørtz, Inge Li 
  Gualà, Luciano 
  H 
  Hall, Holden 
  Hendrickson, Della 
  Heule, Marijn J. H. 
  Huntemann, Svenja 
  Huynh, Kien 
  Hvattum, Lars Magnus 
  I 
  Iburi, Yuki 
  Ikenmeyer, Christian 
  K 
  Kanai, Kazuki 
  Khangure, Dylan 
  Koo, Jaehyun 
  Korman, Matias 
  L 
  Lafourcade, Pascal 
  Leucci, Stefano 
  Li, Jeffery 
  Li, Kai 
  Luccio, Fabrizio 
  M 
  Maarse, Mieke 
  Marcadet, Gaël 
  Marino, Francesco Pio 
  Mikalački, Mirjana 
  Miller, Victor S. 
  MIT Hardness Group 
  Miyamoto, Kengo 
  Moschetto, Andrea 
  Murakami, Takao 
  N 
  Naves, Guyslain 
  Nuida, Koji 
  O 
  Oijid, Nacim 
  P 
  Pagli, Linda 
  Panconesi, Alessandro 
  Parreau, Aline 
  Pavone, Arianna 
  Polishchuk, Valentin 
  Posta, Pietro Maria 
  R 
  Rin, Benjamin G. 
  Ruiz, Ricardo 
  S 
  Santoro, Nicola 
  Scardace, Antonio 
  Schipper, Atze 
  Schutte, Karen 
  Sgall, Jiří 
  Shah, Rikhav 
  Shinagawa, Kazumasa 
  Smith, Benjamin 
  Stojaković, Miloš 
  Subercaseaux, Bernardo 
  T 
  Tamir, Tami 
  Teng, Shanghua 
  Tockman, Andy 
  Tuza, Zsolt 
  U 
  Uehara, Ryuhei 
  V 
  van der Hoog, Ivor 
  Venier, Luca 
  Venkat, Naveen 
  W 
  Wild, Sebastian 
  Y 
  Yin, Howe Choong 

  Subjects 
   Show All  Collapse 
  Show All 
  Computing methodologies 
  Computing methodologies → Number theory algorithms 
  Computing methodologies → Parallel algorithms 
  Hardware 
  Hardware → Communication hardware, interfaces and storage 
  Information systems 
  Information systems → Information retrieval 
  Mathematics of computing 
  Mathematics of computing → Combinatorial algorithms 
  Mathematics of computing → Combinatoric problems 
  Mathematics of computing → Combinatorics 
  Mathematics of computing → Discrete mathematics 
  Mathematics of computing → Graph algorithms 
  Mathematics of computing → Network flows 
  Security and privacy 
  Security and privacy → Information-theoretic techniques 
  Security and privacy → Public key (asymmetric) techniques 
  Security and privacy → Public key encryption 
  Theory of computation 
  Theory of computation → Algorithmic game theory 
  Theory of computation → Backtracking 
  Theory of computation → Complexity classes 
  Theory of computation → Computational geometry 
  Theory of computation → Data structures design and analysis 
  Theory of computation → Design and analysis of algorithms 
  Theory of computation → Discrete optimization 
  Theory of computation → Fixed parameter tractability 
  Theory of computation → Network flows 
  Theory of computation → Online algorithms 
  Theory of computation → Pattern matching 
  Theory of computation → Problems, reductions and completeness 
  Theory of computation → Random walks and Markov chains 
  Theory of computation → Representations of games and their complexity 
  Theory of computation → Scheduling algorithms 
  Theory of computation → Shortest paths 

  Questions / Remarks / Feedback   X  Feedback for Dagstuhl Publishing  
     
  Send    
   
  Thanks for your feedback!  
 Feedback submitted   
 OK    
  Could not send message  
 Please try again later or send an E-mail    
 OK    
   About DROPS  
 Schloss Dagstuhl - Leibniz Center for Informatics has been operating the Dagstuhl Research Online Publication Server (short: DROPS) since 2004. DROPS enables publication of the latest research findings in a fast, uncomplicated manner, in addition to providing unimpeded, open access to them. All the requisite metadata on each publication is administered in accordance with general guidelines pertaining to online publications (cf. Dublin Core). This enables the online publications to be authorized for citation and made accessible to a wide readership on a permanent basis. Access is free of charge for readers following the open access idea which fosters unimpeded access to scientific publications.  
 More about DROPS 
    
 Instructions for Authors  
 Dagstuhl Series   
  LIPIcs 
  OASIcs 
  Dagstuhl Follow-Ups 
    
 Dagstuhl Journals   
  DARTS – Dagstuhl Artifacts Series 
  Dagstuhl Reports 
  Dagstuhl Manifestos 
  LITES 
  TGDK – Transactions on Graph Data and Knowledge 

 Instructions for Editors  
 Dagstuhl Series   
  LIPIcs 
  OASIcs 
  Dagstuhl Follow-Ups 
    
 Dagstuhl Journals   
  DARTS – Dagstuhl Artifacts Series 
  Dagstuhl Reports 
  Dagstuhl Manifestos 
  LITES 
  TGDK – Transactions on Graph Data and Knowledge 

 © 2023-2024 Schloss Dagstuhl – LZI GmbH  About DROPS  Imprint  Privacy  Contact

98. FUN_2 conference:
Science Direct                  Journals & Books 
   
 ScienceDirect help 

 !  There was a problem providing the content you requested  
 Please contact us via our support center  for more information and provide the details below.  
 Reference Number: 8ea888986a71e6b2  
 IP Address: 14.237.32.203  
 User Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0  
 Timestamp: 2024-11-30 05:45:24 UTC  
   
 ::CLOUDFLARE_ERROR_1000S_BOX::   

 Elsevier             About ScienceDirect    Shopping cart    Contact and support    Terms and conditions    Privacy policy    
 We use cookies to help provide and enhance our service and tailor content and ads. By continuing you agree to the use of cookies   .  
 Copyright © 2020 Elsevier B.V. or its licensors or contributors. ScienceDirect ® is a registered trademark of Elsevier B.V.  
   
 RELX Group

99. CISS_0 conference:
The requested URL was rejected. Please consult with your administrator.  
   
  Your support ID is: < 8203162004118104310>  
   
  [Go Back]

100. COG_2 conference:
Socialist Republic of Vietnam    Choose your Country/Region  

 Asia   
   
  China    
  India    
  Japan    
  South Korea    
   
  Malaysia    
  Taiwan, China    
  United Arab Emirates    
  Indonesia    
   
  Hong Kong, China    
  Singapore    
  Thailand    
  Turkey    

 America   
   
  United States    
  Canada    
  Brazil    
  Argentina    
   
  Mexico    
  Colombia    
  Chile    
  Peru    
   
  Guatemala    

 Europe   
   
  Italy    
  United Kingdom    
  France    
  Germany    
   
  Spain    
  Portugal    
  Austria    
  Poland    
   
  Greece    
  Russian Federation    
  Czech Republic    
  Switzerland    
   
  Netherlands    
  Sweden    
  Romania    
  Hungary    
   
  Belgium    
  Ukraine    
  Ireland    
  Croatia    
   
  Finland    
  Denmark    
  Cyprus    
  Serbia    
   
  Slovakia    
  Norway    
  Bulgaria    
  Iceland    

 Oceania   
   
  Australia    
  New Zealand    
  Fiji    

 Africa   
   
  South Africa    
  Tunisia    
  Morocco    
  Egypt    

 Product | Software 
  Webinar 
  Video conference 
  Virtual conference 
  Institution Edition 
  Discover | Subject category 
  Conference in Socialist Republic of Vietnam 
  Contribution library 
  Browse by venue 
  Services 
         
 Create an event  Lecture    
   
 Meeting/Workshop/Tutorials    
   
 Conference    

 Log in  Sign up    

 2023 IEEE Conference on Games (CoG)  
   
 Aug. 21 - 24, 2023  
 Interdisciplinary Science and Engineering Complex (ISEC), 805 Columbus Ave, , , , Boston, MA, USA, 02120, ;, Boston · Egypt  
   
 Conference  Virtual Conference    
  0  Views   
  0  Comments   
 Favorite    
  Share    

 Introduction  
   
 AboutComputing and Processing; Robotics and Control Systems  
  Keywords:Games,Serious Games,Game Development,Game Technology,Computer Games,Casual Games,Console Games,Immersive Games,Intelligent Agents,Computational and artificial intelligence,Game Design,Multi-agent system,  
  Scope:The annual IEEE Conference on Games (IEEE CoG) brings together leading researchers and practitioners from academia and industry in the field of games to discuss recent advances and explore future directions. It covers all topics in the field of games, from game design to game intelligence and game theory, including scientific, technical, engineering and societal aspects.  
  Sponsor Type:1  

 Call for paper  

 Submit Comment  

 Verify Code     Change Another   Submit    

 All Comments  

 Submission Template  
 ×    
  Paper Template  
  Paper Template  

 Home 
  Program 
  Timetable 
  Abstract List 
  Photo 
  Review 
  Management 
    
 Important Date  
   
 Conference Date | Aug 21  
 2023  
  to  Aug 24  
 2023 
  Aug 24  2023 | Registration deadline 

 Sponsored By  
   
 IEEE Computational Intelligence Society   
   
 Contact Information  
   
 li******@sustech.edu.cn 
  Login to view full info    

 Contact Information  
 ×    

 OK    

 About Us  |  News  |  Blog  |  Feedback  |  Disclaimer  |  Privacy Policy  |  Terms of Service  |  Cancellation Policy  |  Contact   
 Copyright © 2013-2021 Aconf.org  - One-stop solutions for academic events   
 鄂ICP备09016152号-4

