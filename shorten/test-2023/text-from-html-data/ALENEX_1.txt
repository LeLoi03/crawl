 Proceedings  
 Proceedings Series | Algorithm Engineering & Experiments (ALENEX) 
  Algorithmic Principles of Computer Systems-APOCS 
  Analytic Algorithmics and Combinatorics (ANALCO) 
  Email 
 Home  Proceedings  2023 Proceedings of the Symposium on Algorithm Engineering and Experiments (ALENEX)   
 Description | The aim of ALENEX is to provide a forum for the presentation of original research in the design, implementation, and experimental evaluation of algorithms and data structures. Typical results include an extensive experimental analysis of nontrivial algorithmic results, ideally bridging the gap between theory and practice. ALENEX papers also address methodological issues and standards in the experimental evaluation of algorithms and data structures. Relevant areas of applied algorithmic research include but are not limited to databases; geometry; graphs and networks, including web applications; operations research; combinatorial aspects of scientific computing; and computational problems in the natural sciences or engineering. ALENEX also regularly welcomes papers that address algorithms and data structures for advanced models of computing, including memory hierarchies and parallel computing, ranging from instruction parallelism over multicore computing to high-performance and cloud computing. 
 CHAPTERS  
 Abstract 
  PDF 
  Abstract   Given a directed graph G  ( V  , A  ), the DIRECTED FEEDBACK VERTEX SET (DFVS) problem asks for the smallest sized subset of V  whose removal makes G  acyclic. The problem is NP-complete and efficient constant-factor approximation algorithms are ruled out under UGC. Attempting to get an exact DFVS in practice usually involves the application of reduction rules that decrease the instance size without compromising the optimal solution. If the reduced graph gets sufficiently small, the respective instance can then be solved to optimality e.g. by a branching algorithm. However, one might need to resort to heuristics in the end in case the reduced instance is still huge. In this paper, we propose novel reduction rules for DFVS with a special focus on lossy rules. Here, the idea is that an optimal solution on the reduced graph combined with the information gained in the reduction process provides an α-approximation for the original instance. We present several rules that ensure small α, and discuss how to combine and engineer them. We also propose a taxonomy to study general types of lossy rules. In an extensive experimental analysis, we evaluate the impact of exact and lossy rules on the running time, the size of the reduced instance, and the solution quality. It turns out that the lossy rules are indeed very effective and that it is often possible to solve instances by using reduction rules only.  
  Full Access    
  Abstract   Preferential attachment lies at the heart of many network models aiming to replicate features of real world networks. To simulate the attachment process, conduct statistical tests, or obtain input data for benchmarks, efficient algorithms are required that are capable of generating large graphs according to these models.  
 Existing graph generators are optimized for the most simple model, where new nodes that arrive in the network are connected to earlier nodes with a probability P  ( h  ) ∝ d  that depends linearly on the degree d  of the earlier node h  . Yet, some networks are better explained by a more general attachment probability P  ( h  ) ∝ f  ( d  ) for some function f  : ℕ → ℝ. Here, the polynomial case f  ( d  ) = d  α  where α ∈ ℝ >0  is of particular interest.  
 In this paper, we present efficient algorithms that generate graphs according to the more general models. We first design a simple yet optimal sequential algorithm for the polynomial model. We then parallelize the algorithm by identifying batches of independent samples and obtain a near-optimal speedup when adding many nodes. In addition, we present an I/O-efficient algorithm that can even be used for the fully general model. To showcase the efficiency and scalability of our algorithms, we conduct an experimental study and compare their performance to existing solutions.  
 Abstract 
  PDF 
  Abstract   This paper introduces Search-optimized Packed Memory Arrays  (SPMAs), a collection of data structures based on Packed Memory Arrays (PMAs) that address suboptimal search via cache-optimized search layouts. Traditionally, PMAs and B-trees have tradeoffs between searches/inserts and scans: B-trees were faster for searches and inserts, while PMAs were faster for scans.  
 Our empirical evaluation shows that SPMAs overcome this tradeoff for unsorted input distributions: on average, SPMAs are faster than B+-trees (a variant of B-trees optimized for scans) on all major operations. We generated datasets and search/insert workloads from the Yahoo! Cloud Serving Benchmark (YCSB) and found that SPMAs are about 2× faster than B+-trees regardless of the ratio of searches to inserts. On uniform random inputs, SPMAs are on average between 1.3× −2.3× faster than B+-trees on all operations. Finally, we vary the amount of sortedness in the inputs to stress the worst-case insert distribution in the PMA. We find that the worst-case B+-tree insertion throughput is about 1.5× faster than the worst-case PMA insertion throughput. However, the worst-case input for the PMA is sorted and highly unlikely to appear naturally in practice. The SPMAs maintain higher insertion throughput than the B+-tree when the input is up to 25% sorted.  
 Abstract 
  PDF 
  Abstract   A Perfect Hash Function (PHF) is a hash function that has no collisions on a given input set. PHFs can be used for space efficient storage of data in an array, or for determining a compact representative of each object in the set. In this paper, we present the PHF construction algorithm SicHash - Small Irregular Cuckoo Tables for Perfect Hashing. At its core, SicHash uses a known technique: it places objects in a cuckoo hash table and then stores the final hash function choice of each object in a retrieval data structure. We combine the idea with irregular cuckoo hashing, where different objects can have a different number of hash functions. Additionally, we use many small tables that we overload beyond their asymptotic maximum load factor. The most space efficient competitors often use brute force methods to determine the PHFs. SicHash provides a more direct construction algorithm that only rarely needs to re-compute parts. Our implementation improves the state of the art in terms of space usage versus construction time for a wide range of configurations. For some configurations, SicHash is up to 4.3 times faster than the next best competitor. At the same time, it provides very fast queries.  
  Full Access    
