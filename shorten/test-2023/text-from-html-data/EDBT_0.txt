EDBT    
 Organization 
  Test of Time 
 Local Web site   
 Notice that from 2022 on, the EDBT Conference switched to 3 submission/publication cycles for its papers. Details can be found below.  
 Back to top    
 Welcome to the Web site of the EDBT Association (edbt.org)   
 The Association  
 The EDBT Association has close relationships with other organizations in the database field, including ACM SIGMOD  , IEEE TC on Data Engineering  , VLDB Endowment  , and the ICDT Council  .  
 Conference Proceedings  
 All EDBT Proceedings are listed in the Computer Science Bibliography at dblp.org  .  
 Back to top    
 Organization of the EDBT Association   
 The EDBT Association invites as members the key officers of EDBT Conferences and Summer Schools, for a duration of 5 years.  
 The EDBT Association has an Executive Board (EB), elected by the members. The EB membership term is 4 years. The Association is represented by its President, who is elected by the EB.  
 The current Executive Board members are:  
 In Memoriam  
 2022  
 Joachim W. Schmidt  was a founding member of the EDBT Association and long term member of the Executive Board. He has always given valuable advice for further developping the format, the scientific quality, and the attractiveness of our Conferences and Summer Schools. For many of us, he has been a true friend. Joachim passed away in May 2022. We are missing him.  
 Back to top    
 New Publication Schedule of EDBT Conferences 2022 ff.    
 3 Submit/Review Cycles  
 12 Month Resubmission Ban  
 EDBT, like other conferences in our field with multiple submit/review cycles, follows a "12 month resubmission ban" model for rejected and withdrawn papers in each of its track formats:  
 EDBT conferences typically have tracks with short and long paper formats. Resubmission of work is not allowed to any track of EDBT if the work - or any work with substantial overlap with the submitted paper and with the same or overlapping sets of authors - was previously rejected from a track of EDBT in the same paper format, within 12 months. A paper withdrawn by the authors after a revision decision will be considered as rejected and the 12-month resubmission ban applies to such papers as well.  
 Back to top    
 Decision:  the PC chair appoints a small committee (3 persons max) for the selection of some papers candidates for the award. The EDBT executive board will make the final decision based on this list.  
 Back to top    
 2024, March 25-28 | Paestum, Italy | OpenProceedings (EDBT) 
  LIPIcs (ICDT) | Qiong Luo, Letizia Tanca | Anastasia Ailamaki, Sihem Amer-Yahia, H.V. Jagadish, Georgia Koutrika, Sudeepa Roy 
 2023, March 28-31 | Ioannina, Greece | OpenProceedings (EDBT) 
  LIPIcs (ICDT) | Sourav S. Bhowmick, Katja Hose | Leonid Libkin, Jayant Haritsa, Juliana Freire, Gonzalo Navarro, Anil Goel 
 2022, March 29-April 01 | Edinburgh, UK | OpenProceedings (EDBT) 
  LIPIcs (ICDT) | Julia Stoyanovich, Jens Teubner | Peter Boncz, Seung-won Hwang, Marcelo Arenas, Hung Ngo, Moshe Y. Vardi, Nofar Carmeli 
  OpenProceedings (ICDT) 
  ACM DL (EDBT) 
  ACM DL (ICDT) 
  ACM DL (Workshops) | Norman Paton | Daniel Abadi, Jan van den Bussche, C. Mohan, Luc Segoufin 
  OpenProceedings (ICDT) 
  ACM DL (EDBT) 
  ACM DL (ICDT) 
  ACM DL (Workshops) | Elke Rundensteiner | Michael Carey, Wenfei Fan, Erich Graedel, Alon Halevy |  
  OpenProceedings (ICDT) 
  ACM DL (EDBT) 
  ACM DL (ICDT) | Anastasia Ailamaki | Susan B. Davidson, Dan Suciu, Jeff Ullman, Gerhard Weikum 
  OpenProceedings (ICDT) 
  ACM DL (EDBT) 
  ACM DL (ICDT) 
  ACM DL (Workshops) | Ioana Manolescu | Amol Deshpande, Val Tannen, Pierre Fraigniaud, Ian Horrocks 
  OpenProceedings (ICDT) 
  ACM DL (EDBT) 
  ACM DL (ICDT) 
  ACM DL (Workshops) | Martin Kersten | Victor Vianu, Umeshwar Dayal, Georg Gottlob 
  Posteingang@uni-konstanz.de   
 Verantwortlich im Sinne der §§ 6 TDG, 10 MdStV:   
  As a content provider ("Inhaltsanbieter") according to § 8 Teledienstgesetz University of Konstanz is responsible for own contents ("eigene Informationen") hold ready for utilisation. Even though all contents are carefully reviewed and constantly updated no guarantee can be provided for completeness, accuracy and ultimate up-to-dateness. University of Konstanz is therefore not liable for damages in connection with the usage of these contents. Cross-references ("links") to contents of other providers have to become differentiated from own contents ("eigene Inhalte"). Even if University of Konstanz should arrange through this access for the usage of these contents according to § 9 Tele-dienstgesetz, no responsibility will be taken for this external content ( "fremden Inhalt"). Links are references to dynamic internet appearances of third parties. University of Konstanz has reviewed the content in respect to liabilities according to civil and criminal law at the first time link-up. However University of Konstanz is not obliged to constantly review these in respect to changes which could cause a new liability. In case University of Konstanz should notice that a specific offer to which a link was provided will cause a liability according to civil oder criminal law the link will become canceled.  
 Close    
  A Condensation Approach to Privacy Preserving Data Mining   
 The paper addresses the topic of privacy-preserving data mining and proposes a framework for anonymization in contrast to perturbation approaches that introduce noise. The approach advocated in this paper takes into consideration the correlated nature of multi-dimensional data and also that is not problem-specific, i.e., the framework is generic and many mining operations can be formulated and solved given the same framework.  
 The paper is seminal and covers a topic which has not lost relevance today. It constitutes a prime example of how far a simple idea (in this case condensation: reduce a group of records to a number of carefully selected statistical properties of that group) can carry a whole line of original research. Condensation comes with a naturally built-in "privacy dial" (namely the group size) and is practical (easily implemented, maintainable under updates). It established general techniques that have been taken up by many people in the area and outside the area. The results in this paper can be (and have been) generalized in many ways as they tackled a more general problem of grouping, aggregation, and sampling.  
 A number of follow-up papers  by the same authors, quite clearly demonstrate that the proposed condensation approach has interesting aspects:  
  Geo-Relational Algebra: A Model and Query Language for Geometric Database Systems   
 The paper addresses the user’s conceptual model of a database system for geometric data. It proposes to extend relational database management systems by integrating geometry at all levels: At the conceptual level, relational algebra is extended to include geometric data types and operators. At the implementation level, the wealth of algorithms and data structures for geometric problems developed in the past decade in the field of Computational Geometry is exploited. The paper starts from a view of relational algebra as a many-sorted algebra which allows to easily embed geometric data types and operators. A concrete algebra for two-dimensional applications is developed. It can be used as a highly expressive retrieval and data manipulation language for geometric as well as standard data. Also, geo-relational database systems and their implementation strategy are discussed.  
 The committee members unanimously agreed that this paper clearly stands out in terms of relevance, impact, and influence in databases. Of all the papers considered, this is the one that had had the most and longest lasting impact with results that are still relevant today and whose influence can be traced to many real systems and a significant amount of follow up work.  
 The paper pioneered an important application area well before it became mainstream and did it in a systematic and clean way that has been very influential in both research and practice. Modern commercial systems all support geographic data types that are nowadays used in a wide range of applications and use cases (maps locations based services, geographic information systems, mobility etc.).  
 The selection committee also appreciated very much the cleanliness completeness, insights, formalism, and systematic treatment of the problem as well as the approach followed by the author in selecting and solving a research problem.  
 Close    
  Bridging Physical and Virtual Worlds: Complex Event Processing for RFID Data Streams   
 The paper proposes an event-oriented approach to the processing of RFID data which makes it possible to automate the translation of RFID based application semantics through complex event detection. In particular, it demonstrates the ability to process complex events by capturing temporal constraints in an algebra. The resulting declarative event-based approach is shown to simplify RFID data processing and is shown to be scalable. The paper pioneers declarative event-based RFID processing. The simplicity and expressiveness of the proposed framework are admirable. For example, the framework makes it possible to express object tracking on historical data as well as to formulate real-time monitoring.  
 This industry track paper reports on an analysis of mobile telecoms data, with a view to predicting which customers will leave. The analysis involves commercial mobile telephony data, in which nodes are customers and edges represent calls. The hypothesis tested is that it is possible to predict who will leave a network based on earlier departures among their connections. The main technique investigated is the use of spreading activation, to predict the heat of nodes based on the heat of connected notes. It is shown how the approach based on connections is more effective than classification techniques based on other properties of the nodes. As a result, the paper provides early and compelling experience on the combination an important real problem (churn in mobile telecom networks) with a powerful technique (social ties) and applies it on large real data (telecom operator network over 4 months). The approach has influenced many subsequent studies, for the same problem, but also for analyses involving different types of network and different hypotheses. Social network analysis continues as an important and active area ten years later, and this paper continues to be widely cited.  
 The committee members agreed that this paper clearly stands out in terms of methodology, impact, and influ- ence. It has catalyzed and enabled substantial follow-up research and has demonstrated its high relevance to industry.  
 Abstract:   
 Ten years later, Shore-MT work has concluded, although the system still serves as a research platform in the space. Meanwhile, research on transaction processing scalability continues to mature, the move to main- memory transaction processing and their higher TPS increased the need for scalable storage managers, while the popular open-source systems, such as MySQL and PostgreSQL, significantly improved their scalability. In particular, a significant amount of research and industrial developments in the ten years since the Shore-MT paper focused on improving the scalability of individual components of a storage manager, such as latches, the logging subsystem and access methods. This research was partly carried out by our research group as follow- on work, but other research groups and database vendors have made important contributions as well. Another significant amount of effort has focused on scalable concurrency control protocols, again both within and outside our research group. The knowledge that we have gained from building Shore-MT has been invaluable in maintaining scalability in this new, multi-dimensional ecosystem.  
 Abstract:   
  Implementations of map-reduce are being used to perform many operations on very large data. We examine strategies for joining several relations in the map-reduce environment. Our new approach begins by identifying the "map-key," the set of attributes that identify the Reduce process to which a Map process must send a particular tuple. Each attribute of the map-key gets a "share," which is the number of buckets into which its values are hashed, to form a component of the identifier of a Reduce process. Relations have their tuples replicated in limited fashion, the degree of replication depending on the shares for those map-key attributes that are missing from their schema. We study the problem of optimizing the shares, given a fixed number of Reduce processes. An algorithm for detecting and fixing problems where an attribute is "mistakenly" included in the map-key is given. Then, we consider two important special cases: chain joins and star joins. In each case we are able to determine the map-key and determine the shares that yield the least replication. While the method we propose is not always superior to the conventional way of using map-reduce to implement joins, there are some important cases involving large-scale data where our method wins, including: (1) analytic queries in which a very large fact table is joined with smaller dimension tables, and (2) queries involving paths through graphs with high out-degree, such as the Web or a social network.  
 This paper presented optimization strategies for executing multi-way joins in a map-reduce environment. It focused on large-scale data and provided algorithms to choose the number of map-keys and shares in order to minimize the communication cost among the map and reduce processes. The committee members agreed that this paper clearly pioneered the field of join processing in map-reduce environments. It has triggered substantial follow-up research and impact on big data processing in parallel and distributed architectures.  
 Abstract:   
  GPS devices allow recording the movement track of the moving object they are attached to. This data typically consists of a stream of spatio-temporal (x,y,t) points. For application purposes the stream is transformed into finite subsequences called trajectories. Existing knowledge extraction algorithms defined for trajectories mainly assume a specific context (e.g. vehicle movements) or analyze specific parts of a trajectory (e.g. stops), in association with data from chosen geographic sources (e.g. points-of-interest, road networks). We investigate a more comprehensive semantic annotation framework that allows enriching trajectories with any kind of semantic data provided by multiple 3rd party sources.  
  This paper presents SeMiTri - the framework that enables annotating trajectories for any kind of moving objects. Doing so, the application can benefit from a "semantic trajectory" representation of the physical movement. The framework and its algorithms have been designed to work on trajectories with varying data quality and different structures, with the objective of covering abstraction requirements of a wide range of applications. Performance of SeMiTri has been evaluated using many GPS datasets from multiple sources - including both fast moving objects (e.g. cars, trucks) and people's trajectories (e.g. with smartphones). These two kinds of experiments are reported in this paper.  
 The EDBT 2022 Test of Time Award committee was formed by Bill Howe, University of Washington, USA Julia Stoyanovich, New York University, USA Jens Teubner, TU Dortmund, Germany Xiaofang Zhou, Hong Kong University of Science and Technology, Hong Kong.  
 Abstract:   
  In data mining applications and spatial and multimedia databases, a useful tool is the kNN join, which is to produce the k nearest neighbors (NN), from a dataset S, of every point in a dataset R. Since it involves both the join and the NN search, performing kNN joins efficiently is a challenging task. Meanwhile, applications continue to witness a quick (exponential in some cases) increase in the amount of data to be processed. A popular model nowadays for large-scale data processing is the shared-nothing cluster on a number of commodity machines using MapReduce [6]. Hence, how to execute kNN joins efficiently on large data that are stored in a MapReduce cluster is an intriguing problem that meets many practical needs. This work proposes novel (exact and approximate) algorithms in MapReduce to perform efficient parallel kNN joins on large data. We demonstrate our ideas using Hadoop. Extensive experiments in large real and syn- thetic datasets, with tens or hundreds of millions of records in both R and S and up to 30 dimensions, have demonstrated the efficiency, effectiveness, and scalability of our methods.  
 Close    
 x   Test of Time Award 2023  
 The EDBT 2023 Test of Time Award committee was formed by Sihem Amer-Yahia Alon Halevy Divesh Srivastava.  
 Abstract:   
  We introduce HIL, a high-level scripting language for entity resolution and integration. HIL aims at providing the core logic for complex data processing flows that aggregate facts from large collections of structured or unstructured data into clean, unified entities. Such flows typically include many stages of processing that start from the outcome of information extraction and continue with entity resolution, mapping and fusion. A HIL program captures the overall integration flow through a combination of SQL-like rules that link, map, fuse and aggregate entities. A salient feature of HIL is the use of logical indexes in its data model to facilitate the modular construction and aggregation of complex entities. Another feature is the presence of a flexible, open type system that allows HIL to handle input data that is irregular, sparse or partially known. As a result, HIL can accurately express complex integration tasks while still being high-level and focused on the logical entities (rather than the physical operations). Compilation algorithms translate the HIL specification into efficient run-time queries that can execute in parallel on Hadoop. We show how our framework is applied to real-world integration of entities in the financial domain, based on public filings archived by the U.S. Securities and Exchange Commission (SEC). Furthermore, we apply HIL on a larger-scale scenario that performs fusion of data from hundreds of millions of Twitter messages into tens of millions of structured entities  
 The EDBT 2024 Test of Time Award committee was formed by Minos Garofalakis Davide Martinenghi Baihua Zheng.  
 Abstract:   
  A key problem in many graph-based applications is the need to know, given a directed graph G and two vertices u, v ∈ G whether there is a path between u and v, i. e., if u reaches v. This problem is particularly challenging in the case of very large real-world graphs. A common approach is the pre- processing of the graphs, in order to produce an efficient index structure, which allows fast access to the reachability information of the vertices. However, the majority of existing methods can not handle very large graphs. We propose in this paper, a novel indexing method called FELINE (Fast rEfined onLINE search), which is inspired by Dominance Graph Drawing. FELINE creates an index from the graph representation in a two-dimensional plane, which provides reachability information in constant time for a significant portion of queries. Experiments demonstrate the efficiency of FELINE compared to state-of-the-art approaches  
