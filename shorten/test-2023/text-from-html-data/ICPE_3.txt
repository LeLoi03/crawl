ICPE '23 Companion: Companion of the 2023 ACM/SPEC International Conference on Performance Engineering  
  Full Citation in the ACM Digital Library    
 SESSION: Emerging Research Track  
 Incremental Change Detection Method For Data Center Power Efficiency Metrics (Work In Progress Paper)   
 Jana Backhus 
  Yasutaka Kono 
 Design-time Performability Evaluation of Runtime Adaptation Strategies (Work In Progress Paper)   
 Martina Rapp 
  Max Scheerer 
  Ralf Reussner 
  Performability is the classic metric for performance evaluation of static systems in case of failures. Compared to static systems, Self-Adaptive Systems (SASs) are inherently more complex due to their constantly changing nature. Thus software architects are facing more complex design decisions which are preferably evaluated at design-time. Model-Based Quality Analysis (MBQA) provides valuable support by putting software architects in a position to take well-founded design decisions about software system quality attributes over the whole development phase of a system. We claim that combining methods from MBQA and established performability concepts support software architects in this decision making process to design effective fault-tolerant adaptation strategies. Our contribution is a model-based approach to evaluate performability-oriented adaptation strategies of SAS at design-time. We demonstrate the applicability of our approach by a proof-of-concept.  
 Event-based Simulation for Transient Systems with Capture Replay to Predict Self-Adaptive Systems (Work in Progress Paper)   
 Sarah Stieß 
  Stefan Höppner 
  Steffen Becker 
  Matthias Tichy 
  Cloud-native systems are dynamic in nature as they always have to react to changes in the environment, e.g., how users utilize the system. Self-adaptive cloud-native systems manage those changes by predicting how future environmental changes will impact the system's service level objectives and how the system can subsequently reconfigure to ensure that the service level objectives stay fulfilled. The farther the predictions look into the future, the higher the chance that good reconfigurations can be identified and applied. However, this requires efficient exploration of potential future system states, particularly exploring alternative futures resulting from alternative system reconfiguration. We present in this paper an extension to the Slingshot simulator for Palladio component models to efficiently explore the future state space induced by environmental changes and reconfigurations. The extension creates snapshots of simulation states and reloads them to explore alternatives. We show that Slingshot's event-based publish-subscribe architecture enables us to extend the simulator easily and without changes to the simulator itself.  
 Transparent Trace Annotation for Performance Debugging in Microservice-oriented Systems (Work In Progress Paper)   
 Adel Belkhiri 
  Ahmad Shahnejat Bushehri 
  Gabriela Nicolescu 
  Microservices is a cloud-native architecture in which a single application is implemented as a collection of small, independent, and loosely-coupled services. This architecture is gaining popularity in the industry as it promises to make applications more scalable and easier to develop and deploy. Nonetheless, adopting this architecture in practice has raised many concerns, particularly regarding the difficulty of diagnosing performance bugs and explaining abnormal software behaviour. Fortunately, many tools based on distributed tracing were proposed to achieve observability in microservice-oriented systems and address these concerns (e.g., Jaeger). Distributed tracing is a method for tracking user requests as they flow between services. While these tools can identify slow services and detect latency-related problems, they mostly fail to pinpoint the root causes of these issues.  
 This paper presents a new approach for enacting cross-layer tracing of microservice-based applications. It also proposes a framework for annotating traces generated by most distributed tracing tools with relevant tracing data and metrics collected from the kernel. The information added to the traces aims at helping the practitioner get a clear insight into the operations of the application executing user requests. The framework we present is notably efficient in diagnosing the causes of long tail latencies. Unlike other solutions, our approach for annotating traces is completely transparent as it does not require the modification of the application, the tracer, or the operating system. Furthermore, our evaluation shows that this approach incurs low overhead costs.  
 Visualizing Runtime Evolution Paths in a Multidimensional Space (Work In Progress Paper)   
 Hagen Tarner 
  Fabian Beck 
  Runtime data of software systems is often of multivariate nature, describing different aspects of performance among other characteristics, and evolves along different versions or changes depending on the execution context. This poses a challenge for visualizations, which are typically only two- or three-dimensional. Using dimensionality reduction, we project the multivariate runtime data to 2D and visualize the result in a scatter plot. To show changes over time, we apply the projection to multiple timestamps and connect temporally adjacent points to form trajectories. This allows for cluster and outlier detection, analysis of co-evolution, and finding temporal patterns. While projected temporal trajectories have been applied to other domains before, we use it to visualize software evolution and execution context changes as evolution paths. We experiment with and report results of two application examples: (I) the runtime evolution along different versions of components from the Apache Commons project, and (II) a benchmark suite from scientific visualization comparing different rendering techniques along camera paths.  
 Enhancing the Configuration Tuning Pipeline of Large-Scale Distributed Applications Using Large Language Models (Idea Paper)   
 Gagan Somashekar 
  Rajat Kumar 
  The performance of distributed applications implemented using microservice architecture depends heavily on the configuration of various parameters, which are hard to tune due to large configuration search space and inter-dependence of parameters. While the information in product manuals and technical documents guides the tuning process, manual collection of meta-data for all application parameters is laborious and not scalable. Prior works have largely overlooked the automated use of product manuals, technical documents and source code for extracting such meta-data. In the current work, we propose using large language models for automated meta-data extraction and enhancing the configuration tuning pipeline. We further ideate on building an in-house knowledge system using experimental data to learn important parameters in configuration tuning using historical data on parameter dependence, workload statistics, performance metrics and resource utilization. We expect productionizing the proposed system will reduce the total time and experimental iterations required for configuration tuning in new applications, saving an organization both developer time and money.  
 A Case of Multi-Resource Fairness for Serverless Workflows (Work In Progress Paper)   
 Amit Samanta 
  Ryan Stutsman 
 Our assertion is that beyond the glaring issues like cold start costs, a more fundamental shift is needed in how serverless function invocations are provisioned and scheduled in order to support these more demanding applications. Specifically, we propose a platform that leverages the observability and predictability of serverless functions to enforce multi-resource fairness. We explain why we believe interference across a spectrum of resources (CPU, network, and storage) contributes to lower resource utilization and poor response times for latency-sensitive and high-fanout serverless application patterns. Finally, we propose a new distributed and hierarchical function scheduling architecture that combines lessons from multi-resource fair scheduling, hierarchical scheduling, batch-analytics resource scheduling, and statistics to create an approach that we believe will enable tighter SLAs on serverless platforms than has been possible in the past.  
 Challenges and Future Directions in Efficiency Benchmarking (Vision Paper)   
 Maximilian Meissner 
  Klaus-Dieter Lange 
  Samuel Kounev 
 As the IT landscape experiences radical transformations, efficiency benchmarks need to be updated accordingly to generate results relevant to government regulators, manufacturers, and customers. In this paper, we outline current challenges efficiency benchmark developers are tackling and highlight recent technological developments the next generation of efficiency benchmarks should take into account.  
 A Reference Architecture for Datacenter Scheduler Programming Abstractions: Design and Experiments (Work In Progress Paper)   
 Aratz Manterola Lasa 
  Sacheendra Talluri 
  Sneh Patel 
  Naser Ezzati-Jivan 
  Developers often use microbenchmarking tools to evaluate the performance of a Java program. These tools run a small section of code multiple times and measure its performance. However, this process can be problematic as Java execution is traditionally divided into two stages: a warmup stage where the JVM's JIT compiler optimizes frequently used code and a steady stage where performance is stable. Measuring performance before reaching the steady stage can provide an inaccurate representation of the program's efficiency. The challenge comes from determining when a program should be considered as in a steady state. In this paper, we propose that call stack sampling data should be considered when conducting steady state performance evaluations. By analyzing this data, we can generate call graphs for individual microbenchmark executions. Our proposed method of using call stack sampling data and visualizing call graphs intuitively empowers developers to effectively distinguish between warmup and steady state executions. Additionally, by utilizing machine learning classification techniques this method can automate the steady state detection, working towards a more accurate and efficient performance evaluation process.  
 A Study of Java Microbenchmark Tail Latencies   
  Lukas Iffländer 
  Samuel Kounev 
  This paper compares the performance of R, Python, and Rust in the context of data processing tasks. A real-world data processing task in the form of an aggregation of benchmark measurement results was implemented in each language, and their execution times were measured. The results indicate that while all languages can perform the tasks effectively, there are significant differences in performance. Even the same code showed significant runtime differences depending on the interpreter used for execution. Rust and Python were the most efficient, with R requiring much longer execution times. Additionally, the paper discusses the potential implications of these findings for data scientists and developers when choosing a language for data processing projects.  
 Analysing Static Source Code Features to Determine a Correlation to Steady State Performance in Java Microbenchmarks   
  Beatrice Ombuki-Berman 
  Naser Ezzati-Jivan 
  The practice of microbenchmarking is very important for observing the performance of code. As such, observing the states and anomalies experienced by the program during a benchmark is equally important. This paper attempts to evaluate the effectiveness of the matrix profile method when applied to analyse JMH benchmarks in time series format, to determine if it is a viable alternative to proven methods. We observe that, when using the matrix profile method, there is a statistically significant difference between the results of the analysis on steady state and non-steady state benchmarks. By comparing results of the matrix profile method and the proven changepoint analysis method, we are able to prove a stronger correlation between the two when the benchmark tested is non-steady state versus that of steady state.  
 Software Mining -- Investigating Correlation between Source Code Features and Michrobenchmark's Steady State   
 Towards Evaluation/Mitigation Risk of Systemic Failures in a Recoverable Network with Redistributed Elastic Load   
 Vladimir Marbukh 
  While systemic failure/overload in recoverable networks with load redistribution is a common phenomenon, current ability to evaluate and moreover mitigate the corresponding systemic risk is vastly insufficient due to complexity of the problem and relying on oversimplified models. The proposed in this paper framework for systemic risk evaluation relies on approximate dimension reduction at the onset of systemic failure. Assuming a general failure/recovery microscopic model, the macro-level system dynamics is approximated by a 2-state Markov process alternating between systemically operational and failed states.  
 Challenges and Possible Approaches for Sustainable Digital Twinning   
 Paulo Roberto Farah 
  Silvia Regina Vergilio 
  In this paper, we present PerfoRT, a tool to ease software performance regression measurement of Java systems. Its main characteristics include: minimal configuration to ease automation and hide complexity to the end user; a broad scope of performance metrics including system, process, JVM, and tracing; and presentation of the results from a developer's perspective. We show some of its features in a usage example using Apache Commons BCEL project.  
 SESSION: Tutorials  
 SESSION: First Workshop on Artificial Intelligence for Performance Modeling, Prediction, and Control (AIPerf 2023)  
 ICPE'23 AIPerf Workshop Chairs' Welcome   
 Emilio Incerto 
  Marin Litoiu 
  Riccardo Pinciroli 
  We are pleased to welcome you to the 2023 ACM Workshop on Artificial Intelligence for Performance Modeling, Prediction, and Control - AIPerf'23.  
 In its first edition, AIPerf intends to foster the usage of AI (such as probabilistic methods, machine learning, and deep learning) to control, model, and predict the performance of computer systems. The relevance of these topics reflects current and future trends toward exploiting AI-based approaches to deal with complex, large, and interconnected systems. Despite AI and ML being widely adopted techniques to investigate several mainstream domains, their usage for performance modeling and evaluation is still limited, and their benefit to the performance engineering field remains unclear. AIPerf proposes a meeting venue to promote the dissemination of research works that use or study AI techniques for quantitative analysis of modern ICT systems and to engage academics and practitioners of this field. The workshop focuses on presenting experiences and results of applying AI/ML-based techniques to performance-related problems, as well as sharing performance datasets and benchmarks with the community to facilitate the development of new and more accurate learning procedures.  
 Putting together AIPerf'23 was a team effort. We first thank the authors for providing the content of the program. We are grateful to the program committee and the senior program committee, who worked very hard to review papers and provide authors' feedback. Finally, We thank the ICPE23 organizers for sponsoring AIPerf in its community.  
  Germán Moltó 
  Miguel Caballer 
  This paper proposes an auto-profiling tool for OSCAR, an open-source platform able to support serverless computing in cloud and edge environments. The tool, named OSCAR-P, is designed to automatically test a specified application workflow on different hardware and node combinations, obtaining relevant information on the execution time of the individual components. It then uses the collected data to build performance models using machine learning, making it possible to predict the performance of the application on unseen configurations. The preliminary evaluation of the performance models accuracy is promising, showing a mean absolute percentage error for extrapolation lower than 10%.  
 Towards Novel Statistical Methods for Anomaly Detection in Industrial Processes   
  Daniele Licari 
  Andrea Vandin 
  This paper presents a novel methodology based on first principles of statistics and statistical learning for anomaly detection in industrial processes and IoT environments. We present a 5-level analytical pipeline that cleans, smooths, and eliminates redundancies from the data, and identifies outliers as well as the features that contribute most to these anomalies. We show how smoothing can make our methodology less sensitive to short-lived anomalies that might be, e.g., due to sensor noise. We validate the methodology on a dataset freely available in the literature. Our results show that we can identify all anomalies in the considered dataset, with the ability of controlling the amount of false positives. This work is the result of a research project co-funded by the Tuscany Region and a company leader in the paper and nonwovens sector. Although the methodology was developed for this domain, we consider here a dataset from a different industrial sector. This shows that our methodology can be generalized to other contexts with similar constraints on limited resources, interpretability, time, and budget.  
 SESSION: First FastContinuum Workshop (Fast Continuum 2023)  
 ICPE'23 Fast Continuum Workshop Chairs' Welcome   
 Danilo Ardagna 
  Elisabetta Di Nitto 
  Lorenzo Blasi 
  Francesc Lordan 
  It is our great pleasure to welcome you to the first FastContinuum Workshop held on April 16th 2023. The goal of the workshop is to foster discussion and collaboration among researchers from cloud/edge/fog computing and performance analysis communities, to share the relevant topics and results of the current approaches proposed by industry and academia. FastContinuum solicited full papers as well as demo and short papers including reports about research activities not mature enough for a full paper as well as new ideas and vision papers.  
 The final program includes four full papers and three short ones. They cover some of the most interesting areas of computing continua, from FaaS development and acceleration to the management of heterogeneous datasets to the development of Infrastructure as Code and the automation of deployment through the computing continuum. DevSecOps is also brought to the attendees' attention as one of the crucial ingredients for proper management of the continuum.  
 The workshop keynote, given by Samuel Kunev, investigates further the area of serverless computing properly positioning the multiple aspects and approaches developed in this area and highlighting the main challenges related to the performance of these approaches. The keynote is held in collaboration with the eleventh International Workshop on Load Testing and Benchmarking of Software Systems (LTB 2023).  
 On the Acceleration of FaaS Using Remote GPU Virtualization   
  Javier Prades 
  Federico Silla 
  Serverless computing and, in particular, Function as a Service (FaaS) has introduced novel computational approaches with its highly-elastic capabilities, per-millisecond billing and scale-to-zero capacities, thus being of interest for the computing continuum. Services such as AWS Lambda allow efficient execution of event-driven short-lived bursty applications, even if there are limitations in terms of the amount of memory and the lack of GPU support for accelerated execution. To this aim, this paper analyses the suitability of including GPU support in AWS Lambda through the rCUDA middleware, which provides CUDA applications with remote GPU execution capabilities. A reference architecture for data-driven accelerated processing is introduced, based on elastic queues and event-driven object storage systems to manage resource contention and GPU scheduling. The benefits and limitations are assessed through a use case of sequence alignment. The results indicate that, for certain scenarios, the usage of remote GPUs in AWS Lambda represents a viable approach to reduce the execution time.  
 A Pattern-based Function and Workflow Visual Environment for FaaS Development across the Continuum   
  Alessandro Mamelli 
  Teta Stamati 
  The ability to split applications across different locations in the continuum (edge/cloud) creates needs for application break down into smaller and more distributed chunks. In this realm the Function as a Service approach appears as a significant enabler in this process. The paper presents a visual function and workflow development environment for complex FaaS (Apache OpenwhisK) applications. The environment offers a library of pattern based and reusable nodes and flows while mitigating function orchestration limitations in the domain. Generation of the deployable artefacts, i.e. the functions, is performed through embedded DevOps pipelines. A range of annotations are available for dictating diverse options including QoS needs, function or data locality requirements, function affinity considerations etc. These are propagated to the deployment and operation stacks for supporting the cloud/edge interplay. The mechanism is evaluated functionally through creating, registering and executing functions and orchestrating workflows, adapting typical parallelization patterns and an edge data collection process.  
 Heterogeneous Datasets for Federated Survival Analysis Simulation   
  André Martin 
  Matteo Matteucci 
  Survival analysis studies time-modeling techniques for an event of interest occurring for a population. Survival analysis found widespread applications in healthcare, engineering, and social sciences. However, the data needed to train survival models are often distributed, incomplete, censored, and confidential. In this context, federated learning can be exploited to tremendously improve the quality of the models trained on distributed data while preserving user privacy. However, federated survival analysis is still in its early development, and there is no common benchmarking dataset to test federated survival models. This work provides a novel technique for constructing realistic heterogeneous datasets by starting from existing non-federated datasets in a reproducible way. Specifically, we propose two dataset-splitting algorithms based on the Dirichlet distribution to assign each data sample to a carefully chosen client: quantity-skewed splitting and label-skewed splitting. Furthermore, these algorithms allow for obtaining different levels of heterogeneity by changing a single hyperparameter. Finally, numerical experiments provide a quantitative evaluation of the heterogeneity level using log-rank tests and a qualitative analysis of the generated splits. The implementation of the proposed methods is publicly available in favor of reproducibility and to encourage common practices to simulate federated environments for survival analysis.  
 Continuum: Automate Infrastructure Deployment and Benchmarking in the Compute Continuum   
  Laurentiu Niculut 
  Debora Benedetto 
  The infrastructure-as-code (IaC) is an approach for automating the deployment, maintenance, and monitoring of environments for online services and applications that developers usually do manually. The benefit is not only reducing the time and effort but also the operational costs. This paper aims at describing our experience in applying IaC in cloud-native applications, mainly discussing the key challenges towards modeling and generating IaC faced in the ongoing project Programming Trustworthy Infrastructure-As-Code in a Secure Framework (PIACERE). The concluding insights could spur the wider adoption of IaC by software developers.  
 IEM: A Unified Lifecycle Orchestrator for Multilingual IaC Deployments   
  Tomaz Martincic 
  Dejan Stepec 
  Security represents one of the crucial concerns when it comes to DevOps methodology-empowered software development and service delivery process. Considering the adoption of Infrastructure as Code (IaC), even minor flaws could potentially cause fatal consequences, especially in sensitive domains such as healthcare and maritime applications. However, most of the existing solutions tackle either Static Application Security Testing (SAST) or run-time behavior analysis distinctly. In this paper, we propose a) IaC Scan Runner, an open-source solution developed in Python for inspecting a variety of state-of-the-art IaC languages in application design time and b) the run time anomaly detection tool called LOMOS. Both tools work in synergy and provide a valuable contribution to a DevSecOps tool set. The proposed approach is demonstrated and their results will be demonstrated on various case studies showcasing the capabilities of static analysis tool IaC Scan Runner combined with LOMOS - log analysis artificial intelligence-enabled framework.  
 SESSION: First Workshop on Serverless, Extreme-Scale, and Sustainable Graph Processing Systems (GraphSys 2023)  
 ICPE'23 GraphSys Workshop Chairs Introduction (Welcome)   
 Alexandru Iosup 
  Radu Prodan 
  It is our great pleasure to welcome you to the 2023 ACM/SPEC Workshop on Serverless, Extreme-Scale, and Sustainable Graph Processing Systems. This is the first such workshop, aiming to facilitate the exchange of ideas and expertise in the broad field of high-performance large-scale graph processing.  
 Graphs or linked data are crucial to innovation, competition, and prosperity and establish a strategic investment in technical processing and ecosystem enablers. Graphs are universal abstractions that capture, combine, model, analyze, and process knowledge about real and digital worlds into actionable insights through item representation and interconnectedness. For societally relevant problems, graphs are extreme data that require further technological innovations to meet the needs of the European data economy. Digital graphs help pursue the United Nations Sustainable Development Goals (UN SDG) by enabling better value chains, products, and services for more profitable or green investments in the financial sector and deriving trustworthy insight for creating sustainable communities. All science, engineering, industry, economy, and society-at-large domains can leverage graph data for unique analysis and insight, but only if graph processing becomes easy to use, fast, scalable, and sustainable.  
  Peter Haase 
  Wolfgang Schell 
  Knowledge Graphs and semantic technologies allow scientists and domain experts to model complex relations between data in a logically structured and machine readable format. metaphactory is a platform that enables users to build these kinds of semantic graphs easily and efficiently. metaphactory uses standards such as RDF in combination with OWL, SKOS, SHACL, and others to provide a flexible endpoint to interact with graphs of varying complexity and expressivity. As part of the Graph-Massivizer project, metaphactory is supporting integration and infrastructure consolidation for components developed in the project. Part of this work is to develop a toolkit which metaphactory uses to process very large graphs without sacrificing sustainability. In this paper we describe in detail the metaphactory platform and how it supports large-scale graph processing in the Graph-Massivizer project, as well as outlining the current efforts within the project and how they aim to increase capabilities in the present to support future work.  
 Towards Sustainable Serverless Processing of Massive Graphs on the Computing Continuum   
  Reza Farahani 
  Radu Prodan 
  Serverless computing offers an affordable and easy way to code lightweight functions that can be invoked based on some events to perform simple tasks. For more complicated processing, multiple serverless functions can be orchestrated as a directed acyclic graph to form a serverless workflow, so-called function choreography (FC). Although most famous cloud providers offer FC management systems such as AWS Step Functions, and there are also several open-source FC management systems (e.g., Apache OpenWhisk), their primary focus is on describing the control flow and data flow between serverless functions in the FC. Moreover, the existing FC management systems rarely consider the processed data, which is commonly represented in a graph format. In this paper, we review the capabilities of the existing FC management systems in supporting graph processing applications. We also raise two key research questions related to large-scale graph processing using serverless computing in federated Function-as-a-Service (FaaS). As part of the Graph-Massivizer project, funded by the Horizon Europe research and innovation program, we will research and develop (prototype) solutions that will address these challenges.  
 Boosting the Impact of Extreme and Sustainable Graph Processing for Urgent Societal Challenges in Europe Graph-Massivizer: A Horizon Europe Project   
  Andrea Borghesi 
  Andrea Bartolini 
  In this paper, we explore the use of Graph Neural Networks (GNNs) for anomaly anticipation in high performance computing (HPC) systems. We propose a GNN-based approach that leverages the structure of the HPC system (particularly, the physical proximity of the compute nodes) to facilitate anomaly anticipation. We frame the task of forecasting the availability of the compute nodes as a supervised prediction problem; the GNN predicts the probability that a compute node will fail within a fixed-length future window.  
 We empirically demonstrate the viability of the GNN-based approach by conducting experiments on the production Tier-0 super-computer hosted at CINECA datacenter facilities, the largest Italian provider of HPC. The results are extremely promising, showing both anomaly detection capabilities on par with other techniques from the literature (with a special focus on those tested on real, production data) and, more significantly, strong results in terms of anomaly prediction.  
  Joze Rozanec 
  Marko Grobelnik 
  This paper describes how we envision classifying events into the United Nations Sustainable Development Goals (SDGs) by utilizing machine learning techniques on global news data. We propose extracting data from a media intelligence platform using an ontology and a classifier to assign each event to its corresponding SDG. To minimize the labeling effort, a few-shot classification approach is employed. Additionally, a labeling tool is developed to facilitate event analysis and assign labels accurately. We envision this approach could be used for analyzing media events at a large scale and track progress towards the SDGs.  
 AI, What Does the Future Hold for Us? Automating Strategic Foresight   
  Gregor Leban 
  Marko Grobelnik 
  There is an increasing awareness that strategic foresight is much needed to guide efficient policy-making. The growing digitalization implies a rising amount of digital evidence of many aspects of society (e.g., science, economy, and politics). Artificial intelligence can process massive amounts of data and extract meaningful information. Furthermore, a knowledge graph can be developed to capture significant aspects of reality, and machine learning models can be used to identify patterns and derive insights. This paper describes how we envision artificial intelligence could be used to create and deliver strategic foresight automatically.  
 Extreme and Sustainable Graph Processing for Green Finance Investment and Trading   
 In this work, we present the Graph-Optimizer tool. Graph-Optimizer uses optimised BGOs and composition rules to capture and model the workload. It combines the workload model with hardware and infrastructure models, predicting performance and energy consumption. Combined with design space exploration, such predictions select codesigned workload implementations to fit a requested performance objective and guarantee their performance bounds during execution.  
 SESSION: Sixth Workshop on Hot Topics in Cloud Computing Performance (HotCloudPerf 2023)  
 HotCloudPerf'23 Workshop Chairs' Welcome   
 Klervie Toczé 
  Nikolas Herbst 
  Alexandru Iosup 
  It is our great pleasure to welcome you to the 2023 edition of the Workshop on Hot Topics in Cloud Computing Performance - HotCloudPerf 2023.  
 Cloud computing is emerging as one of the most profound changes in the way we build and use IT. The use of global services in public clouds is increasing, and the lucrative and rapidly growing global cloud market already supports over 1 million IT-related jobs. However, it is currently challenging to make the IT services offered by public and private clouds performant (in an extended sense) and efficient. Emerging architectures, techniques, and real-world systems include interactions with the computing continuum, serverless operation, everything as a service, complex workflows, auto-scaling and -tiering, etc. It is unclear to which extent traditional performance engineering, software engineering, and system design and analysis tools can help with understanding and engineering these emerging technologies. The community needs practical tools and powerful methods to address hot topics in cloud computing performance.  
 Responding to this need, the HotCloudPerf workshop proposes a meeting venue for academics and practitioners, from experts to trainees, in the field of cloud computing performance. The workshop aims to engage this community and to lead to the development of new methodological aspects for gaining a deeper understanding not only of cloud performance, but also of cloud operation and behavior, through diverse quantitative evaluation tools, including benchmarks, metrics, and workload generators. The workshop focuses on novel cloud properties such as elasticity, performance isolation, dependability, and other non-functional system properties, in addition to classical performance-related metrics such as response time, throughput, scalability, and efficiency.  
  Markus Zilch 
  Steffen Becker 
  Cloud-native applications force increasingly powerful and complex autoscalers to guarantee the applications' quality of service. For software engineers with operational tasks understanding the autoscalers' behavior and applying appropriate reconfigurations is challenging due to their internal mechanisms, inherent distribution, and decentralized decision-making. Hence, engineers seek appropriate explanations. However, engineers' expectations on feedback and explanations of autoscalers are unclear. In this paper, through a workshop with a representative sample of engineers responsible for operating an autoscaler, we elicit requirements for explainability in autoscaling. Based on the requirements, we propose an evaluation scheme for evaluating explainability as a non-functional property of the autoscaling process and guide software engineers in choosing the best-fitting autoscaler for their scenario. The evaluation scheme is based on a Goal Question Metric approach and contains three goals, nine questions to assess explainability, and metrics to answer these questions. The evaluation scheme should help engineers choose a suitable and explainable autoscaler or guide them in building their own.  
 Enhancing Trace Visualizations for Microservices Performance Analysis   
 Jessica Leone 
  Luca Traini 
  Performance analysis of microservices can be a challenging task, as a typical request to these systems involves multiple Remote Procedure Calls (RPC) spanning across independent services and machines. Practitioners primarily rely on distributed tracing tools to closely monitor microservices performance. These tools enable practitioners to trace, collect, and visualize RPC workflows and associated events in the context of individual end-to-end requests. While effective for analyzing individual end-to-end requests, current distributed tracing visualizations often fall short in providing a comprehensive understanding of the system's overall performance. To address this limitation, we propose a novel visualization approach that enables aggregate performance analysis of multiple end-to-end requests. Our approach builds on a previously developed technique for comparing structural differences of request pairs and extends it for aggregate performance analysis of sets of requests. This paper presents our proposal and discusses our preliminary ongoing progress in developing this innovative approach.  
 Performance Experiences From Running An E-health Inference Process As FaaS Across Diverse Clusters   
 George Kousiouris 
  Aristodemos Pnevmatikakis 
  In this paper we report our experiences from the migration of an AI model inference process, used in the context of an E-health platform to the Function as a Service model. To that direction, a performance analysis is applied, across three available Cloud or Edge FaaS clusters based on the open source Apache Openwhisk FaaS platform. The aim is to highlight differences in performance based on the characteristics of each cluster, the request rates and the parameters of Openwhisk. The conclusions can be applied for understanding the expected behavior of the inference function in each of these clusters as well as the effect of the Openwhisk execution model. Key observations and findings are reported on aspects such as function execution duration, function sizing, wait time in the system, network latency and concurrent container overheads for different load rates. These can be used to detect in a black box manner capabilities of unknown clusters, guide or fine-tune performance models as well as private cloud FaaS deployment setup.  
 Can My WiFi Handle the Metaverse? A Performance Evaluation Of Meta's Flagship Virtual Reality Hardware   
 SESSION: Eleventh International Workshop on Load Testing and Benchmarking of Software Systems (LTB 2023)  
 LTB'23 Workshop Chairs' Welcome   
 Alexander Podelko 
  Daniel Seybold 
  Database management systems~(DBMS) are crucial architectural components of any modern distributed software system. Yet, ensuring a smooth, high-performant operation of a DBMS is a black art that requires tweaking many knobs and is heavily dependent on the experienced workload. Misconfigurations at production systems have an heavy impact on the overall delivered service quality and hence, should be avoided at all costs. Replaying production workload on test and staging systems to estimate the ideal configuration are a valid approach. Yet, this requires traces from the production systems.  
 While many DBMS's have built-in support to capture such traces these have a non-negligible impact on performance. eBPF is a Linux kernel feature claiming to enable low-overhead observability and application tracing. In this paper, we evaluate different eBPF-based approaches to DBMS workload tracing for PostgreSQL and MySQL. The results show that using eBPF causes lower overhead than the built-in mechanisms. Hence, eBPF can be a viable baseline for building a generic tracing framework. Yet, our current results also show that additional optimisation and fine-tuning is needed to further lower the performance overhead.  
 Verifying Transient Behavior Specifications in Chaos Engineering Using Metric Temporal Logic and Property Specification Patterns   
 SESSION: First Practically FAIR Workshop (PFAIR 2023)  
 ICPE'23 PFAIR Workshop Chairs Introduction   
 Jay Lofstead 
  Paula Olaya 
  It is our great pleasure to welcome you to the 2023 ACM Practically FAIR - PFAIR 2023. This workshop builds upon the popular FAIR data principles to investigate and share best practices for adopting FAIR principles in practice. The FAIR proposal only covers some computing and science domains while leaving many unconsidered and also does not prescribe how to achieve the standards in the ideal. As researchers and practitioners begin to meet these standards, we, as a community, need to agree upon what constitutes meeting the principles and how it can be validated. We had a call for research and experience papers and received one submission that met our peer review standards and will fill out our program with a keynote as well as a panel and open discussion.  
 FAIR Enabling Re-Use of Data-Intensive Workflows and Scientific Reproducibility   
 Line C. Pouchard 
  Scientific computing communities often run their experiments using complex data- and compute-intensive workflows that utilize high performance computing (HPC), distributed clusters and specialized architectures targeting machine learning and artificial intelligence. FAIR principles for data and software can be useful enablers for the reproducibility of performance (a key HPC metric) and that of scientific results (a crucial tenet of the scientific method) that are based in part on re-use, the R of FAIR principles. FAIR principles are under-used by HPC and data-intensive communities who have been slow to adopt them. This is due in part to the complexity of workflow life cycles, the numerous workflow management systems, the lack of integration of FAIR within existing technologies, and the specificity of managed systems that include rapidly evolving architectures and software stacks, and execution models that require resource managers and batch schedulers. Numerous challenges emerge for scientists attempting to publish FAIR datasets and software for the purpose of re-use and reproducibility, e.g. what data to publish and where due to sizes, how to "FAIRify" data subsetting, at what level of granularity to attribute persistent identifiers to software, what is the minimal amount of metadata needed to guarantee a certain level of reproducibility, what does reproducible AI actually mean? This talk will focus on such challenges and illustrate the negative impact of not applying FAIR on the reproducibility of experiments. We will introduce the notion of FAIR Digital Objects and present RECUP, a framework for data and metadata services for high performance workflows that proposes micro-solutions for adapting FAIR principles to HPC.  
 Automatic FAIR Provenance Collection and Visualization for Time Series   
  Horacio Gonzalez-Velez 
  Adriana E. Chis 
  Provenance provides data lineage and history of different transformations applied to a dataset. A complete trace of data provenance can enable the reanalysis, reproducibility, and reusability of features, which are essential for validating results and extending them in many projects. Open time series datasets are readily accessible and discoverable, but their full reproducibility and reusability require clear metadata provenance. This paper introduces an assessment of provenance variables using an algorithm for collecting FAIR (Findable, Accessible, Interoperable, Reusable) characteristics in open time series and generating an associated provenance graph. We have evaluated the FAIRness of provenance traces by automatically mapping their properties to a provenance data model graph for a case study employing open time series from weather stations. Our approach arguably enables researchers to analyse time series datasets with similar characteristics, prompting new research questions, insights, and investigations. As a result, this approach has the potential to promote reusability and reproducibility, which are critical factors in scientific research.  
 SESSION: Fourth Workshop on Education and Practice of Performance Engineering (WEPPE 2023)  
 WEPPE'23 Workshop Chairs' Welcome   
 Alberto Avritzer 
  Matteo Camilli 
  It is our great pleasure to welcome you to the 4th International Workshop on Education and Practice of Performance Engineering - WEPPE 2023. The goal of the Workshop on Education and Practice of Performance Engineering is to bring together University researchers and Industry Performance Engineers to share education and practice experiences. This year's symposium continues its tradition of being a forum for performance engineering educators. We are interested in creating opportunities to share valuable experience between researchers that are actively teaching performance engineering and Performance Engineers that are applying Performance Engineering techniques in industry.  
 Performance Engineering Practices for Modern Industrial Applications at ABB Research   
 Heiko Koziolek 
  ABB is developing a vast range of software services for process automation applications used in chemical production facilities, power plants, and container ships. High responsiveness and resource efficiency is important in this domain both for real-time embedded systems and distributed containerized systems, but performance engineering can be challenging due to system complexity and application domain heterogeneity. This talk provides experiences and lessons learned from several selected case studies on performance engineering. It illustrates testing performance of OPC UA pub/sub communication, clustered MQTT brokers for edge computing, software container online updates, and lightweight Kubernetes frameworks while highlighting the applied practices and tools. The talk reports on challenges in workload modeling, performance testing, and performance modeling.  
 Quantitative Analysis of Software Designs: Teaching Design and Experiences   
 Alireza Hakamian 
  Steffen Becker 
  Context. The Software Quality and Architecture group (SQA) at the University of Stuttgart offers the Quantitative Analysis of Software Designs (QASD) course for master students. The goal is to give students the necessary skill to evaluate architecture alternatives of software systems quantitatively. The course offers a combination of required theoretical skills, such as applying stochastic processes and practical exercises using suitable tools. The challenge is providing teaching materials that balance necessary theoretical knowledge and appropriate tooling that can be used in practice. As a solution, the course is designed so that one-third is about the formalisms behind quantitative analysis, including stochastic processes and queuing theory. One-third is modeling languages, such as queuing networks, UML, and UML profiles, including MARTE. The other one-third uses tooling to model and analyze example systems. During Corona, we provided students with an e-learning module with pre-recorded videos, online quizzes at the end of every chapter, and a virtual machine that pre-installed all the required tooling for the exercise sheets. Final-remarks. In the past two years, students' feedback was often positive regarding the balance between theory and tooling. However, it has to be emphasized that the number of students participating in the course has always been no more than ten. Hence, the student feedback has not been collected by the universities' survey.  
 Early Progress on Enhancing Existing Software Engineering Courses to Cultivate Performance Awareness   
 Theory and Practice in Performance Evaluation Courses: The Challenge of Online Teaching   
 Andrea Marin 
  This paper reports the experience gained over several years of teaching the course entitled Software performance and scalability at the University Ca' Foscari of Venice. The course is taken by perspective computer scientists and is taught at the master's level. It covers the topics of modeling and assessment of the performance properties of software systems.  
 In this paper, we will also devote attention to the challenge of online teaching due to the pandemic conditions.  
 Finally, we propose some auspices for the community to collect material for structured courses on performance and reliability evaluation topics.  
 Anna-Lena Roth 
  Tim Süß 
  Performance analysis tools are frequently used to support the development of parallel MPI applications. They facilitate the detection of errors, bottlenecks, or inefficiencies but differ substantially in their instrumentation, measurement, and type of feedback. Especially, tools that provide visual feedback are helpful for educational purposes. They provide a visual abstraction of program behavior, supporting learners to identify and understand performance issues and write more efficient code. However, existing professional tools for performance analysis are very complex, and their use in beginner courses can be very demanding. Foremost, their instrumentation and measurement require deep knowledge and take a long time. Immediate, as well as straightforward feedback, is essential to motivate learners. This paper provides an extensive overview of performance analysis tools for parallel MPI applications, which experienced developers broadly use today. It also gives an overview of existing educational tools for parallel programming with MPI and shows their shortcomings compared to professional tools. Using tools for performance analysis of MPI programs in educational scenarios can promote the understanding of program behavior in large HPC systems and support learning parallel programming. At the same time, the complexity of the programs and the lack of infrastructure in educational institutions are barriers. These aspects will be considered and discussed in detail.  
 SESSION: Eighth Workshop on Challenges in Performance Methods for Software Development (WOSP-C 2023)  
 8th Workshop on Challenges in Performance Methods for Software Development: WOSP-C'23 Chairs' Welcome   
 Daniele Di Pompeo 
  Michele Tucci 
  It is our great pleasure to welcome you to the 8th Workshop on Challenges in Performance Methods for Software Development - WOSP-C 2023. This year's workshop continues its tradition of being the forum for the discussion of emerging or unaddressed challenges in software and performance, including challenges in developing software to be performant, concurrent programming issues, performance and architecture, performance measurement, cloud performance, and testing. Its purpose is to open new avenues for research on methods to address continuously emerging performance challenges. The software world is changing, and new challenges are to be expected.  
 We also encourage attendees to attend the keynote and talk presentations. These valuable and insightful talks can and will guide us to a better understanding of the future: Non-Volatile Hardware Transactional Memory: Advancements, Challenges, and Future Directions, Paolo Romano (who is currently at IST, Lisbon University & INESC-ID)  
 Putting together WOSP-C'23 was a team effort. We first thank the authors for providing the content of the program. We are grateful to the program committee, who worked very hard in reviewing papers and providing feedback for authors. Finally, we thank the hosting organization or university, our sponsor, ACM SIGs.  
 Non-Volatile Hardware Transactional Memory: Challenges, Advancements, and Future Directions   
 Paolo Romano 
  Transactional memory (TM) has emerged as a powerful paradigm to simplify concurrent programming. Nowadays, hardware-based TM (HTM) implementations are available in several mainstream CPUs (e.g., by ARM, Intel and IBM). Due to their hardware nature, HTM implementations spare the cost of software instrumentation and can efficiently detect conflicts by extending existing cache- coherency protocols. However, their cache-centric approach also imposes a number of limitations that impact how effectively such systems can be used in practice.  
 This talk investigates the challenges that arise when leveraging existing HTM systems in conjunction with another recent disrup- tive hardware technology, namely Non-Volatile Memory (NVM). NVM, such as Intel Optane DC, provide much higher density than existing DRAM, while attaining competitive performance and pre- serving DRAM's byte addressability. However, the cache-centric approach adopted by existing HTM implementations raises a crucial problem when these are used in conjunction with NVM: since CPU caches are volatile, existing HTM fail to guarantee that data updated by committed transactions are atomically persisted to NVM.  
 I will overview how this problem has been so far tackled in the literature, with a focus on solutions that do not assume ad-hoc hard- ware mechanisms not provided by current HTM implementations, but that rather rely on hardware-software co-design techniques to ensure consistency on unmodified existing HTM systems. I will conclude by presenting ongoing research directions that depart from state of the art approaches in a twofold way: i) they assume the availability of durable caches, i.e., systems equipped with addi- tional power sources that ensure that cache contents can be safely persisted to NVM upon crashes; ii) they assume a weaker isolation levels at the TM level, namely Snapshot Isolation, which despite being more relaxed than the reference consistency model for TM systems (e.g., opacity), can still ensure correct execution of a wide range of applications while enabling new optimizations to boost the efficiency HTM applications operating on NVM.  
 Heuristic Derivation of a Fluid Model from a Layered Queueing Network   
 Murray Woodside 
  Fluid approximations are useful for representing transient behaviour of queueing systems. For layered queues a fluid model has previously been derived indirectly via transformation first to a PEPA model, or via recursive neural networks. This paper presents a derivation directly from the layered queueing mechanisms, starting from a transformation to a context-sensitive layered form. The accuracy of predictions, compared to transient simulations and steady-state solutions, is evaluated and appears to be useful.  
 dqualizer: Domain-Centric Runtime Quality Analysis of Business-Critical Application Systems   
