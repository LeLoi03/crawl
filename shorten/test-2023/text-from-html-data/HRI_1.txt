Please ensure Javascript is enabled for purposes of website accessibility  Skip to content    
 Authors  Full Papers  Alt.HRI  Workshops and Tutorials  Late Breaking Reports  Student Design Competition  Videos and Demos    
 Submission  Submission Themes  Additional Information for Authors  Guides for Anonymizing Submissions    
 Attending  Registration  Health and Safety  Venue and Accommodation  Visitor Information  Visting Stockholm  Reception  Transportation  Visa Support Letter  Student Volunteer Program  Fee Waiver Program    
 Program  Awards  Schedule  Online Schedule  LBR Program  Proceedings  Keynote Speakers  Workshops  Pioneers Workshop    
 About  Organizers  Past HRI Conferences    
 Press    
 Contents  
 HRI ’23: Proceedings of the 2023 ACM/IEEE International Conference on Human-Robot Interaction   
 ACM Digital Library    HRI ’23: Companion of the 2023 ACM/IEEE International Conference on Human-Robot Interaction   
 ACM Digital Library     
  HRI ’23: Proceedings of the 2023 ACM/IEEE International Conference on Human-Robot Interaction  
 SESSION: Keynote Talks  
 Chieko Asakawa 
  Robotic technology has long been seen as a potential mobility aid for the visually impaired and the latest advancements in sensing and artificial intelligence have made it a reality. Before starting the project we researched the capabilities of and user interactions with guide dogs. We discovered that the rich haptic interaction with the “handle” allows users to comfortably follow a guide dog.  
 We then began designing a navigation robot with a handle that is small and slim enough to be followed in a similar body posture. Our goal was to make the robot natural and seamless in an urban environment leading us to the concept of the AI Suitcase a suitcase-shaped robot. In this presentation after reviewing the capabilities of a guide dog we will explain the concept design and implementation of the AI Suitcase and interaction techniques with the robot. We will also discuss the challenges of implementing such new robotic technologies in the real world including technical challenges infrastructure challenges business models and social acceptance.  
 Robots in Real Life: Putting HRI to Work   
 Andrea Thomaz 
  This talk will be focused on the unique challenges in deploying a mobile manipulation robot into an environment where the robot is working closely with people on a daily basis. Diligent Robotics’ first product Moxi, is a mobile manipulation service robot that is at work in hospitals today assisting nurses and other front line staff with materials management tasks. This talk will dive into the computational complexity of developing a mobile manipulator with social intelligence. Dr. Thomaz will focus on how human-robot interaction theories and algorithms translate into the real-world and the impact on functionality and perception of robots that perform delivery tasks in a busy human environment. The talk will include many examples and data from the field, with commentary and discussion around both the expected and unexpected hard problems in building robots operating 24/7 as reliable teammates.  
  Soyon Kim 
  Laurel D. Riek 
  Many robot-delivered health interventions aim to support people longitudinally at home to complement or replace in-clinic treatments. However there is little guidance on how robots can support collaborative goal setting (CGS). CGS is the process in which a person works with a clinician to set and modify their goals for care; it can improve treatment adherence and efficacy. However for home-deployed robots clinicians will have limited availability to help set and modify goals over time which necessitates that robots support CGS on their own. In this work we explore how robots can facilitate CGS in the context of our robot CARMEN (Cognitively Assistive Robot for Motivation and Neurorehabilitation), which delivers neurorehabilitation to people with mild cognitive impairment (PwMCI). We co-designed robot behaviors for supporting CGS with clinical neuropsychologists and PwMCI and prototyped them on CARMEN. We present feedback on how PwMCI envision these behaviors supporting goal progress and motivation during an intervention. We report insights on how to support this process with home-deployed robots and propose a framework to support HRI researchers interested in exploring this both in the context of cognitively assistive robots and beyond. This work supports designing and implementing CGS on robots which will ultimately extend the efficacy of robot-delivered health interventions.  
 Expanded Situational Awareness Without Vision: A Novel Haptic Interface for Use in Fully Autonomous Vehicles   
  Stuart Reeves 
  Sean Rintel 
  Mobile Robotic Telepresence (MRP) systems afford remote communication with an embodied physicality and autonomous mobility which is thought to be useful for creating a sense of presence in hybrid activities. In this paper drawing on phenomenology we interviewed seven long term users of MRP to understand the lived experience of participating in hybrid spaces through a telepresence robot. The users’ accounts show how the capabilities of the robot impact interactions, and how telepresence differs from in-person presence. Whilst not feeling as if they were really there, users felt present when they were being able to participate in local action and be treated as present. They also report standing out and being subject to behaviour amounting to ‘ othering’. We argue that these experiences point to a need for future work on telepresence to focus on giving remote users the means to exercise autonomy in ways that enable them to participate — to be ‘ in on the action’ — rather than in ways that simply simulate being in-person.  
 Feminist Human-Robot Interaction: Disentangling Power Principles and Practice for Better More Ethical HRI   
 Katie Winkle 
  Donald McMillan 
  Ericka Johnson 
  Iolanda Leite 
  Human-Robot Interaction (HRI) is inherently a human-centric field of technology. The role of feminist theories in related fields (e.g. Human-Computer Interaction, Data Science) are taken as a starting point to present a vision for Feminist HRI which can support better more ethical HRI practice everyday as well as a more activist research and design stance. We first define feminist design for an HRI audience and use a set of feminist principles from neighboring fields to examine existent HRI literature showing the progress that has been made already alongside some additional potential ways forward. Following this we identify a set of reflexive questions to be posed throughout the HRI design research and development pipeline encouraging a sensitivity to power and to individuals’ goals and values. Importantly, we do not look to present a definitive, fixed notion of Feminist HRI, but rather demonstrate the ways in which bringing feminist principles to our field can lead to better, more ethical HRI, and to discuss how we, the HRI community, might do this in practice.  
 Implications of AI Bias in HRI: Risks (and Opportunities) when Interacting with a Biased Robot   
 Tom Hitron 
  Noa Morag Yaar 
  Hadas Erel 
  Social robotic behavior is commonly designed using AI algorithms which are trained on human behavioral data. This training process may result in robotic behaviors that echo human biases and stereotypes. In this work we evaluated whether an interaction with a biased robotic object can increase participants’ stereotypical thinking. In the study, a gender-biased robot moderated debates between two participants (man and woman) in three conditions: (1) The robot’ s behavior matched gender stereotypes (Pro-Man); (2) The robot’s behavior countered gender stereotypes (Pro-Woman); (3) The robot’ s behavior did not reflect gender stereotypes and did not counter them (No-Preference). Quantitative and qualitative measures indicated that the interaction with the robot in the Pro-Man condition increased participants’ stereotypical thinking. In the No-Preference condition, stereotypical thinking was also observed but to a lesser extent. In contrast when the robot displayed counter-biased behavior in the Pro-Woman condition, stereotypical thinking was eliminated. Our findings suggest that HRI designers must be conscious of AI algorithmic biases, as interactions with biased robots can reinforce implicit stereotypical thinking and exacerbate existing biases in society. On the other hand, counter-biased robotic behavior can be leveraged to support present efforts to address the negative impact of stereotypical thinking.  
 SESSION: Human-robot Communication  
  We present a new typology for classifying signals from robots when they communicate with humans. For inspiration we use ethology the study of animal behaviour and previous efforts from literature as guides in defining the typology. The typology is based on communicative signals that consist of five properties: the origin where the signal comes from the deliberateness of the signal the signal’s reference, the genuineness of the signal, and its clarity (i.e., how implicit or explicit it is). Using the accompanying worksheet, the typology is straightforward to use to examine communicative signals from previous human-robot interactions and provides guidance for designers to use the typology when designing new robot behaviours.  
 Hmm You Seem Confused ! Tracking Interlocutor Confusion for Situated Task-Oriented HRI   
 Na Li 
  Robert Ross 
  Our research seeks to develop a long-lasting and high-quality engagement between the user and the social robot which in turn requires a more sophisticated alignment of the user and the system than is currently commonly available. Close monitoring of interlocutors’ states, and we argue their confusion state in particular, and adjusting dialogue policies based on this state of confusion is needed for successful joint activity. In this paper, we present an initial study of human-robot conversation scenarios using a Pepper robot to investigate the confusion states of users. A Wizard-of-Oz (WoZ) HRI experiment is illustrated in detail with stimuli strategies to trigger confused states from interlocutors. For the collected data, we estimated emotions, head pose, and eye gaze, and these features were analysed against the silence duration time of the speech data and the post-study self-reported confusion states that are reported by participants. Our analysis found a significant relationship between confusion states and most of these features. We see these results as being particularly significant for multimodal situated dialogues for human-robot interaction and beyond.  
 Crossing Reality: Comparing Physical and Virtual Robot Deixis   
  Amia Castro 
  Tom Williams 
  Augmented Reality (AR) technologies present an exciting new medium for human-robot interactions enabling new opportunities for both implicit and explicit human-robot communication. For example these technologies enable physically-limited robots to execute non-verbal interaction patterns such as deictic gestures despite lacking the physical morphology necessary to do so. However a wealth of HRI research has demonstrated real benefits to physical embodiment (compared to, e.g., virtual robots on screens), suggesting AR augmentation of virtual robot parts could face challenges. In this work we present empirical evidence comparing the use of virtual (AR) and physical arms to perform deictic gestures that identify virtual or physical referents. Our subjective and objective results demonstrate the success of mixed reality deictic gestures in overcoming these potential limitations and their successful use regardless of differences in physicality between gesture and referent. These results help to motivate the further deployment of mixed reality robotic systems and provide nuanced insight into the role of mixed-reality technologies in HRI contexts.  
 The Effect of Simple Emotional Gesturing in a Socially Assistive Robot on Child’s Engagement at a Group Vaccination Day   
 Hannah R. M. Pelikan 
  Malte F. Jung 
  Horns and sirens are important tools for communicating on the road which are still understudied in autonomous vehicles. While HRI has explored different ways in which robots could sound we focus on the range of actions that a single sound can accomplish in interaction. In a Research through Design study involving autonomous shuttle buses in public transport we explored sound design with the help of voice-overs to video recordings of the buses on the road and Wizard-of-Oz tests in live traffic. The buses are slowed down by (unnecessary) braking in response to people getting close. We found that prolonged jingles draw attention to the bus and invite interaction while repeated short beeps and bell sounds can instruct the movement of others away from the bus. We highlight the importance of designing sound in sequential interaction and describe a new method for embedding video interaction analysis in the design process.  
 Coffee Tea Robots?: The Performative Staging of Service Robots in ‘Robot Cafes’ in Japan   
  Herve Poirier 
  Cecile Boulard 
  This paper examines the advantages and disadvantages of combining Human-Like and Machine-Like behaviors for a robot taking a shared elevator with a bystander as part of an office delivery service scenario. We present findings of an in-person wizard-of-oz experiment that builds on and implements behavior policies developed in a previous study. In this experiment we found that the combination of Machine-Like and Human-Like behaviors was perceived as better than Human-Like behaviors alone. We discuss possible reasons and point to key capabilities that a socially competent robot should have to achieve better Human-Like behaviors in order to seamlessly negotiate a social encounter with bystanders in a shared elevator or similar scenario. We found that establishing and maintaining a shared transactional space is one of these key requirements.  
 Studying Mind Perception in Social Robotics Implicitly: The Need for Validation and Norming   
  Cengiz Acarturk 
  Burcu A. Urgen 
  The recent shift towards incorporating implicit measurements into the mind perception studies in social robotics has come along with its promises and challenges. The implicit tasks can go beyond the limited scope of the explicit tasks and increase the robustness of empirical investigations in human-robot interaction (HRI). However designing valid and reliable implicit tasks requires norming and validating all stimuli to ensure no confounding factors interfere with the experimental manipulations. We conducted a lexical norming study to systematically explore the concepts suitable for an implicit task that measures mind perception induced by social robots. Two-hundred seventy-four participants rated an expanded and strictly selected list of forty mental capacities in two categories: Agency and Experience and in two levels of capacities: High and Low. We used the partitioning around medoids algorithm as an objective way of revealing the clusters. We discussed the different clustering solutions in light of the previous findings. We consulted on frequency-based natural language processing (NLP) on the answers to the open-ended questions. The NLP analyses verified the significance of clear instructions and the presence of some common conceptualizations across dimensions. We proposed a systematic approach that encourages validation and norming studies which will further improve the reliability and reproducibility of HRI studies.  
 Your Way Or My Way: Improving Human-Robot Co-Navigation Through Robot Intent and Pedestrian Prediction Visualisations   
  As mobile robots enter shared urban spaces operating in close proximity to people this raises new challenges in terms of how these robots communicate with passers-by. Following an iterative process involving expert focus groups (n=8), we designed an augmented reality concept that visualises the robot’s navigation intent and the pedestrian’ s predicted path. To understand the impact of path visualisations on trust sense of agency user experience and robot understandability we conducted a virtual reality evaluation (n=20). We compared visualising both robot intent and pedestrian path prediction against just visualising robot intent and a baseline without augmentation. The presence of path visualisations resulted in a significant improvement of trust. Triangulation of quantitative and qualitative results further highlights the impact of pedestrian path prediction visualisation on robot understandability as it allows for exploratory interaction.  
 On Using Social Signals to Enable Flexible Error-Aware HRI   
 Maia Stiber 
  Russell H. Taylor 
  Ayse Kucukyilmaz 
  Cagatay Basdogan 
  This paper proposes a machine learning (ML) approach to detect and resolve motion conflicts that occur between a human and a proactive robot during the execution of a physically collaborative task. We train a random forest classifier to distinguish between harmonious and conflicting human-robot interaction behaviors during object co-manipulation. Kinesthetic information generated through the teamwork is used to describe the interactive quality of collaboration. As such we demonstrate that features derived from haptic (force/torque) data are sufficient to classify if the human and the robot harmoniously manipulate the object or they face a conflict. A conflict resolution strategy is implemented to get the robotic partner to proactively contribute to the task via online trajectory planning whenever interactive motion patterns are harmonious and to follow the human lead when a conflict is detected. An admittance controller regulates the physical interaction between the human and the robot during the task. This enables the robot to follow the human passively when there is a conflict. An artificial potential field is used to proactively control the robot motion when partners work in harmony. An experimental study is designed to create scenarios involving harmonious and conflicting interactions during collaborative manipulation of an object and to create a dataset to train and test the random forest classifier. The results of the study show that ML can successfully detect conflicts and the proposed conflict resolution mechanism reduces human force and effort significantly compared to the case of a passive robot that always follows the human partner and a proactive robot that cannot resolve conflicts.  
 Crafting with a Robot Assistant: Use Social Cues to Inform Adaptive Handovers in Human-Robot Collaboration   
 “What If It Is Wrong”: Effects of Power Dynamics and Trust Repair Strategy on Trust and Compliance in HRI   
 Ulas Berk Karli 
  Shiye Cao 
  Minja Axelsson 
  Hatice Gunes 
  The World Health Organization recommends that employers take action to protect and promote mental well-being at work. However the extent to which these recommended practices can be implemented in the workplace is limited by the lack of resources and personnel availability. Robots have been shown to have great potential for promoting mental well-being and the gradual adoption of such assistive technology may allow employers to overcome the aforementioned resource barriers. This paper presents the first study that investigates the deployment and use of two different forms of robotic well-being coaches in the workplace in collaboration with a tech company whose employees (26 coachees) interacted with either a QTrobot (QT) or a Misty robot (M). We endowed the robots with a coaching personality to deliver positive psychology exercises over four weeks (one exercise per week). Our results show that the robot form significantly impacts coachees’ perceptions of the robotic coach in the workplace. Coachees perceived the robotic coach in M more positively than in QT (both in terms of behaviour appropriateness and perceived personality), and they felt more connection with the robotic coach in M. Our study provides valuable insights for robotic well-being coach design and deployment, and contributes to the vision of taking robotic coaches into the real world.  
 A Drone Teacher: Designing Physical Human-Drone Interactions for Movement Instruction   
  Maria Jose Pinto Bernal 
  Tony Belpaeme 
  The perception of audiovisual speech plays an important role in infants’ first language acquisition and continues to be important for language understanding beyond infancy. Beyond that, the perception of speech and congruent lip motion supports language understanding for adults, and it has been suggested that second language learning benefits from audiovisual speech, as it helps learners distinguish speech sounds in the target language. In this paper, we study whether congruent audiovisual speech on a robot facilitates the learning of Japanese pronunciation. 27 native-Dutch speaking participants were trained in Japanese pronunciation by a social robot. The robot demonstrated 30 Japanese words of varying complexity using either congruent audiovisual speech, incongruent visual speech, or computer-generated audiovisual speech. Participants were asked to imitate the robot’ s pronunciation recordings of which were rated by native Japanese speakers. Against expectation the results showed that congruent audiovisual speech resulted in lower pronunciation performance than low-fidelity or incongruent speech. We show that our learners being native Dutch speakers are only very weakly sensitive to audiovisual Japanese speech which possibly explains why learning performance does not seem to benefit from audiovisual speech.  
 I Learn Better Alone !: Collaborative and Individual Word Learning With a Child and Adult Robot   
  Service robots have increasingly been investigated in retailing. Previous studies mainly focused on the effectiveness of recommendation with regard to a single robot and whether and how the use of two robots combined can achieve better performance remain unclear. In this study we address this by exploring the combination power of two service robots for product recommendation in a bakery. We placed one robot inside the store for product recommendation and the other robot outside to promote the inside robot. Particularly we are interested in the effects of the outside robot on the inside robot’s performance in product recommendation. Our results indicate that using the outside robot to promote the inside robot achieved more purchases over using the inside robot alone. Particularly, we discovered that the outside robot increased the attention of customers toward the inside robot; hence, more customers checked and purchased the products. Based on the findings, we discuss the important points for the effective use of service robots.  
 Hey?: ! What did you think about that Robot? Groups Polarize Users’ Acceptance and Trust of Food Delivery Robots   
 Jennifer E. Martinez 
  Dawn VanLeeuwen 
  Argiro Vatakis 
  Heiko Hamann 
  Many large-scale multi-robot systems require human input during operation in different applications. To still minimize the human effort interaction is intermittent or restricted to a subset of robots. Despite this reduced demand for human interaction the mental load and stress can be challenging for the human operator. A specific effect of human-swarm interaction may be a hypothesized change of subjective time perception in the human operator. In a series of simple human-swarm interaction experiments with robot swarms of up to 15 physical robots we study whether human operators have altered time perception due to the number of controlled robots or robot speeds. Using data gathered by questionnaires we found that increased swarm size shrinks perceived time and decreased robot speeds expand the perceived time. We introduce the concept of subjective time perception to human-swarm interaction. Future research will enable swarm systems to autonomously modulate subjective timing to ease the job of human operators.  
 SESSION: Robots for Health and Well-being  
  Tariq Iqbal 
  Brenda Roberts 
  Informal caregivers are the main source of dementia care. Considering the importance of both family caregivers and persons living with dementia (PwDs), this paper explores how these two parties go through their dementia journey and how they envision robots to support them. We adopt a person-centered care approach which views these couples as reciprocal carepartners rather than as care-givers and care-receivers. We conducted a community-based participatory research study with a dementia advocacy organization to imagine how robots can support these dementia dyads. The contribution of this paper is threefold: First we introduce a person-centered care approach and show how this new approach reveals the issues of PwDs and carepartners (CPs) as partners and citizens. For example PwDs’ main challenges were not dementia symptoms but the concomitant stigma such as fears of being considered abnormal. This issue has rarely been discussed in HRI. Second, we suggest slow communication as an important robot design feature. When robots can wait for PwDs to proceed with information without judging PwDs’ relatively slow response PwDs feel respected and less stigmatized. Third we address the importance of paying attention to disagreements between PwDs and CPs about robot design preferences. Considering the interdependency of the two parties robot design processes should allow the two to negotiate.  
 A Robotic Companion for Psychological Well-being: A Long-term Investigation of Companionship and Therapeutic Alliance   
  Sue Min Cho 
  Chien-Ming Huang 
  Lack of physical activity has severe negative health consequences for older adults and limits their ability to live independently. Robots have been proposed to help engage older adults in physical activity (PA), albeit with limited success. There is a lack of robust understanding of older adults’ needs and wants from robots designed to engage them in PA. In this paper, we report on the findings of a co-design process where older adults, physical therapy experts, and engineers designed robots to promote PA in older adults. We found a variety of motivators for and barriers against PA in older adults; we, then, conceptualized a broad spectrum of possible robotic support and found that robots can play various roles to help older adults engage in PA. This exploratory study elucidated several overarching themes and emphasized the need for personalization and adaptability. This work highlights key design features that researchers and engineers should consider when developing robots to engage older adults in PA, and underscores the importance of involving various stakeholders in the design and development of assistive robots.  
 Evaluating and Personalizing User-Perceived Quality of Text-to-Speech Voices for Delivering Mindfulness Meditation with Different Physical Embodiments   
  Enkelejda Kasneci 
  Andreas Zell 
  For successful deployment of robots in multifaceted situations an understanding of the robot for its environment is indispensable. With advancing performance of state-of-the-art object detectors the capability of robots to detect objects within their interaction domain is also enhancing. However it binds the robot to a few trained classes and prevents it from adapting to unfamiliar surroundings beyond predefined scenarios. In such scenarios humans could assist robots amidst the overwhelming number of interaction entities and impart the requisite expertise by acting as teachers. We propose a novel pipeline that effectively harnesses human gaze and augmented reality in a human-robot collaboration context to teach a robot novel objects in its surrounding environment. By intertwining gaze (to guide the robot’s attention to an object of interest) with augmented reality (to convey the respective class information) we enable the robot to quickly acquire a significant amount of automatically labeled training data on its own. Training in a transfer learning fashion, we demonstrate the robot’ s capability to detect recently learned objects and evaluate the influence of different machine learning models and learning procedures as well as the amount of training data involved. Our multimodal approach proves to be an efficient and natural way to teach the robot novel objects based on a few instances and allows it to detect classes for which no training dataset is available. In addition, we make our dataset publicly available to the research community, which consists of RGB and depth data, intrinsic and extrinsic camera parameters, along with regions of interest.  
 People Dynamically Update Trust When Interactively Teaching Robots   
  Daniel Rakita 
  Bilge Mutlu 
  Robots designed to interact with people in collaborative or social scenarios must move in ways that are consistent with the robot’s task and communication goals. However, combining these goals in a naïve manner can result in mutually exclusive solutions, or infeasible or problematic states and actions. In this paper, we present Lively, a framework which supports configurable, real-time, task-based and communicative or socially-expressive motion for collaborative and social robotics across multiple levels of programmatic accessibility. Lively supports a wide range of control methods (i.e. position, orientation, and joint-space goals), and balances them with complex procedural behaviors for natural, lifelike motion that are effective in collaborative and social contexts. We discuss the design of three levels of programmatic accessibility of Lively, including a graphical user interface for visual design called LivelyStudio, the core library Lively for full access to its capabilities for developers, and an extensible architecture for greater customizability and capability.  
 Nudging or Waiting?: Automatically Synthesized Robot Strategies for Evacuating Noncompliant Users in an Emergency Situation   
  Hadas Kress-Gazit 
  Guy Hoffman 
  Robots have the potential to assist in emergency evacuation tasks, but it is not clear how robots should behave to evacuate people who are not fully compliant, perhaps due to panic or other priorities in an emergency. In this paper, we compare two robot strategies: an actively nudging robot that initiates evacuation and pulls toward the exit and a passively waiting robot that stays around users and waits for instruction. Both strategies were automatically synthesized from a description of the desired behavior. We conduct a within participant study (=20) in a simulated environment to compare the evacuation effectiveness between the two robot strategies. Our results indicate an advantage of the nudging robot for effective evacuation when being exposed to the evacuation scenario for the first time. The waiting robot results in lower efficiency, higher mental load, and more physical conflicts. However, participants like the waiting robots equally or slightly more when they repeat the evacuation scenario and are more familiar with the situation. Our qualitative analysis of the participants’ feedback suggests several design implications for future emergency evacuation robots.  
  HRI ’23: Companion of the 2023 ACM/IEEE International Conference on Human-Robot Interaction  
 SESSION: alt.HRI  
 The Eye of the Robot Beholder: Ethical Risks of Representation, Recognition, and Reasoning over Identity Characteristics in Human-Robot Interaction   
 Tom Williams 
  Significant segments of the HRI literature rely on or promote the ability to reason about human identity characteristics, including age, gender, and cultural background. However, attempting to handle identity characteristics raises a number of critical ethical concerns, especially given the spatiotemporal dynamics of these characteristics. In this paper I question whether human identity characteristics can and should be represented, recognized, or reasoned about by robots, with special attention paid to the construct of race due to its relative lack of consideration within the HRI community. As I will argue, while there are a number of well-warranted reasons why HRI researchers might want to enable robotic consideration of identity characteristics, these reasons are outweighed by a number of key ontological, perceptual, and deployment-oriented concerns. This argument raises troubling questions as to whether robots should even be able to understand or generate descriptions of people, and how they would do so while avoiding these ethical concerns. Finally, I conclude with a discussion of what this means for the HRI community, in terms of both algorithm and robot design, and speculate as to possible paths forward.  
 How Did We Miss This?: A Case Study on Unintended Biases in Robot Social Behavior   
  Jesse de Pagter 
  Astrid Weiss 
  In this paper, we reflect on the disciplinary foundations and dominant practices in the field of Human-Robot Interaction (HRI) from the perspective of our own experience of working interdisciplinarily and drawing on colleagues’ ongoing work that transcends disciplinary boundaries. As a part of this reflection, we explore possibilities for the field’s theoretical and methodological expansion, which we contend is needed, given the rapid expansion of robotic technologies in the real world settings. We argue the field of science and technology studies (STS) can be a valuable collaborator and contributor in the process of negotiating disciplinary boundaries of HRI and advancing the field beyond common narratives of technological solutionism and determinism. We frame STS as a field with a strong tradition of studying social and political embeddedness of science and technology, and how these are co-constitutive and co-emergent. STS also investigates the roles and responsibility different actors share in this process. To further explore how the interfacing between STS and HRI can be enacted, we sketch out three modes of interdisciplinary collaboration we call i) Borrowing, ii) Poking and iii) Entangling. We argue that each of these modes comes with advantages, disadvantages and challenges. In the conclusion, we engage the notions of “thinking with care” and disciplinary reflexivity, as an invitation to fellow scholars to consider which disciplinary assumptions are brought to the table when enacting different modes of interfacing between HRI and STS, and how these are entangled with the goals and (desired) outcomes of research practices.  
 Nature-Robot Interaction   
 Pedro Reynolds-Cuéllar 
  Andrés F. Salazar-Gómez 
  Up until now, Human-Robot Interaction (HRI) has been largely defined by the influences both humans and robots exert on each other across various interaction modes. Robots follow human purpose and serve goals determined by humans with various degrees of agency. Humans act, respond, and adapt to robot behaviors while simultaneously advancing technology to increase robot’s affordances. Abstracted by this dyad, HRI has left out the material background making this exchange possible: Nature. The current planetary crisis forces us to reconsider the importance of contextualizing HRI within a larger picture, and invites us to ask ourselves how this relationship can be better served by considering Nature as the driving agent in this binary relationship. In response to this reflection, we present a first attempt of a speculative paradigm in HRI: Nature-Robot Interaction. We discuss ethical and design underpinnings of this approach to HRI, introduce initial guiding principles, as well as examples of potential affordances, embodiments and interactions. While we begin in the realm of the speculative and recognize the infancy of our proposal, we invite the HRI community to it as a serious design principle moving forward.  
 Creative AI for HRI Design Explorations   
 Marius Hoggenmueller 
  Maria Luce Lupetti 
  Willem van der Maden 
  Kazjon Grace 
  Design fixation, a phenomenon describing designers’ adherence to pre-existing ideas or concepts that constrain design outcomes, is particularly prevalent in human-robot interaction (HRI), for example, due to collectively held and stabilised imaginations of what a robot should look like or behave. In this paper, we explore the contribution of creative AI tools to overcome design fixation and enhance creative processes in HRI design. In a four weeks long design exploration, we used generative text-to-image models to ideate and visualise robotic artefacts and robot sociotechnical imaginaries. We exchanged results along with reflections through a digital postcard format. We demonstrate the usefulness of our approach to imagining novel robot concepts, surfacing existing assumptions and robot stereotypes, and situating robotic artefacts in context. We discuss the contribution to designerly HRI practices and conclude with lessons learnt for using creative AI tools as an emerging design practice in HRI research and beyond.  
 Dancing with the Nonhuman: A Feminist, Embodied, Material Inquiry into the Making of Human-Robot Relationships   
  Hyunchul Kim 
  Jeongmi Lee 
  Nowadays, telepresence systems based on the Extended Reality (XR) system are actively developed and used for remote collaboration due to COVID-19. Still, several issues, such as limited traversable space in Virtual Reality (VR) and require all participants to wear head-mounted display (HMD), stop these systems from being used in our daily life. On the other hand, telepresence robots have been used in various fields before the pandemic. However, these robots also have a limitation in that the current form is incapable of delivering non-verbal expressions, which is essential for social interaction. Therefore, we present a Holobot, a telepresence robot based on the XR system. A remote user connects to the Holobot through VR HMDs, and the Holobot augments a virtual avatar that projects users’ facial and gesture expressions. We developed a prototype and conducted a simple field test in the exhibition to receive feedback. VR participants enjoyed exploring remote spaces and interacting with each other through Holobot. Furthermore, remote space participants mentioned that a 1:1 scale avatar helped to build co-presence with the VR user. Based on these insights, we think Holobot could provide design guideline for future telepresence robot. For further approach we plan to improve our prototype and conduct user test for structured evaluation of our system.  
 The NarRobot Plugin – Connecting the Social Robot Reeti to the Unity Game Engine   
  Sophia Maier 
  Birgit Lugrin 
  The integration of robots as storytellers, game masters or embodied characters into games is a novel technique for game design yet restricted to human-robot interaction (HRI) research. To facilitate the usage of robots, a plugin for a common game engine is needed. NarRobot was developed to provide an easy to use interface and seamless integration of the social robot Reeti into the Unity engine without using third-party materials. Further, it includes an intuitive pose editor. Targeting both HRI research and game development the plugin allows researchers to focus on their actual research instead of fiddling with back-end functionality. It also simplifies the entry into programming robots for games. In this contribution, our plugin is presented alongside with a proof of concept and three use cases focusing on interactivity combination with other services, and multi-platform usage: interactive storytelling, integration into a smart room, and a mobile app for a robotic hotel employee.  
 “Nice to meet you!”: Expressing Emotions with Movement Gestures and Textual Content in Automatic Handwriting Robots   
  Yaxuan Mao 
  Ray LC 
  Text-writing robots have been used in assistive writing and drawing applications. However, robots do not convey emotional tones in the writing process due to the lack of behaviors humans typically adopt. To examine how people interpret designed robotic expressions of emotion through both movements and textual output, we used a pen-plotting robot to generate texts by performing human-like behaviors like stop-and-go, speed, and pressure variation. We examined how people convey emotion in the writing process by observing how they wrote in different emotional contexts. We then mapped these human expressions during writing to the handwriting robot and measured how well other participants understood the robot’s affective expression. We found that textual output was the strongest determinant of participants’ ability to perceive the robot’s emotions whereas parameters of gestural movements of the robots like speed, fluency, pressure, size, and acceleration could be useful for understanding the context of the writing expression.  
 Towards Designing Companion Robots with the End in Mind   
 Waki Kamino 
  This paper presents an early-stage idea of using ‘robot death’ as an integral component of human-robot interaction design for companion robots. Reviewing previous discussions around the deaths of companion robots in real-life and popular culture contexts, and analyzing the lifelike design of current companion robots in the market, the paper explores the potential advantages of designing companion robots and human-robot interaction with their ‘death’ in mind.  
 A Multimodal Teach-in Approach to the Pick-and-Place Problem in Human-Robot Collaboration   
  Tim Schwartz 
  Michael Feld 
  Teaching robotic systems how to carry out a task in a collaborative environment still presents a challenge. This is because replicating natural human-to-human interaction requires the availability of interaction modalities that allow conveying complex information. Speech, gestures, gaze-based interactions as well as directly guiding a robotic system count towards such modalities that yield the potential to enable smooth multimodal human-robot interaction. This paper presents a conceptual approach for multimodally teaching a robotic system how to pick-and-place an object, one of the fundamental tasks not only in robotics, but in everyday life. By establishing task and dialogue model separately, we aim to split robot/task logic from interaction logic and to achieve modality independence for the teaching interaction. Finally, we elaborate on an experimental implementation of our models for multimodally teaching a UR-10 robot arm how to pick-and-place an object.  
 Robotic Coaches Delivering Group Mindfulness Practice at a Public Cafe   
  Micol Spitale 
  Hatice Gunes 
  Group meditation is known to keep people motivated and committed over longer periods of time, as compared to individual practice. Robotic coaching is a promising avenue for engaging people in group meditation and mindfulness exercises. However, the deployment of robotic coaches to deliver group mindfulness sessions in real-world settings is very scarce. We present the first steps in deploying a robotic mindfulness coach at a public cafe, where participants could join robot-led meditation sessions in a group setting. We conducted two studies with two robotic coaches: the toy-like Misty II robot for 4 weeks (n = 4), and the child-like QTrobot for 3 weeks (n = 3). This paper presents an exploratory qualitative analysis of the data collected via group discussions after the sessions, and researcher observations during the sessions. Additionally, we discuss the lessons learned and future work related to deploying a robotic coach in a real-world group setting.  
 TEAM3 Challenge: Tasks for Multi-Human and Multi-Robot Collaboration with Voice and Gestures   
  Bradon Thymes 
  Joseph P. Salisbury 
  Intuitive human-robot collaboration requires adaptive modalities for humans and robots to communicate and learn from each other. For diverse teams of humans and robots to naturally collaborate on novel tasks, robots must be able to model roles for themselves and other team members, anticipate how team members may perceive their actions, and communicate back to team members to continuously promote inclusive team cohesion toward achieving a shared goal. Here, we describe a set of tasks for studying mixed multi-human and multi-robot teams with heterogenous roles to achieve joint goals through both voice and gestural interactions. Based around the cooperative game TEAM3, we specify a series of dyadic and triadic human-robot collaboration tasks that require both verbal and nonverbal communication to effectively accomplish. Task materials are inexpensive and provide methods for studying a diverse set of challenges associated with human-robot communication, learning, and perspective-taking.  
 Exploring Human-Drone Collaboration Through Contact Improvisation   
  Shuya Lu 
  Ray L C 
  Current video conferencing technology allows participants to communicate virtually over distance, but users lack the sense of presence due to the absence of physical cues for interaction. We proposes the design of Gesture-Bot, a DIY telepresence robot that performs pan-and-tilt gestures in the presence of a receiver during video chat. It is command via the web by a remote sender. We conducted a workshop to design and evaluate pan-and-tilt movements with 26 participants in two separate communication scenarios to examine the flow of communication in physical-interactions-assisted remote chat. According to the data collected from the questionnaire and the post-experiment interview, the Gesture-Bot system has shown its potential in assisting remote communications while aspects such as the outlook, the method of controlling the robot, the set of gestures are to be improved in the future.  
 A Methodological Approach to Facilitate the Design of Flexible and Efficient Multi-Application Systems for HRC   
 Omar Elsarha 
  Debora Clever 
  Human-robot collaboration (HRC) can bring immense benefits in terms of working conditions and flexibility in industrial environments. Efficiency benefits can only be realized if validated risk reduction measures ensure human safety. One idea to increase the overall throughput of a robot is to increase the number of possible tasks and the number of potential safety reactions that a robot system can perform. Activating a validated safety configuration based on the environmental status in a safety-rated manner allows for deciding the most efficient task within an assessed setup. This paper proposes a new methodology exploiting this potential with a dual-layer finite state machine. The concept and its potential benefits are showcased using a simplified simulation example.  
 Towards Robot Learning from Spoken Language   
  Daniel Sidobre 
  Rachid Alami 
  In this paper, we present a coordinated and reactive human-aware motion planner for performing a handover task by an autonomous aerial manipulator (AAM). We present a method to determine the final state of the AAM for a handover task based on the current state of the human and the surrounding obstacles. We consider the visual field of the human and the effort to turn the head and see the AAM as well as the discomfort caused to the human. We apply these social constraints together with the kinematic constraints of the AAM to determine its coordinated motion along the trajectory.  
 Who to Teach a Robot to Facilitate Multi-party Social Interactions?   
 Jouh Yeong Chew 
  Keisuke Nakamura 
  One salient function of social robots is to play the role of facilitator to enhance the harmony state of multi-party social interactions so that every human participant is encouraged and motivated to engage actively. However, it is challenging to handcraft the behavior of social robots to achieve this objective. One promising approach is for the robot to learn from human teachers. This paper reports the findings of an empirical test to determine the optimal experiment condition for a robot to learn verbal and nonverbal strategies to facilitate a multi-party interaction. First, the modified L8 Orthogonal Array (OA) is used to design a fractional factorial experiment condition using factors like the type of human facilitator, group size and stimulus type. The response of OA is the harmony state explicitly defined using the speech turn-taking between speakers and represented using metrics extracted from the first order Markov transition matrix. Analyses of Main Effects and ANOVA suggest the type of human facilitator and group size are significant factors affecting the harmony state. Therefore, we propose the optimal experiment condition to train a facilitator robot using high school teachers as human teachers and group size larger than four participants.  
 Human Workload Evaluation of Drone Swarm Formation Control using Virtual Reality Interface   
  Andrey Kiselev 
  Amy Loutfi 
  Failures are natural and unavoidable events in any form of interaction, especially in human-robot interactions (HRI). Throughout the literature, the definition and classification of failures are diverse depending on the source and application domain. However, the tolerance to the aftereffect of these failures is low in teleoperation due to its unstructured application domains. One such type of failure is called human induced interaction failure. This is an interesting and often overlooked failure type, due to the perspective that robots are designed always to obey the instructions given by the human operators. Regardless of the degree of automation that the robot is equipped with. But what if the instructions provided are faulty dangerous, or misleading. This paper addresses the above mentioned research gap. It introduces a framework based on the concept of Intelligent Disobedience (ID), derived from guide dog training methods, to manage human induced interaction failures in teleoperation scenarios.  
 HighLight: Towards an Ambient Robotic Table as a Social Enabler   
  We take initial steps into prototyping an expressive robotic table that can serve as a social mediator. The work is constructed through a rapid prototyping process consisting of five workshop-based phases with five interaction design participants. We report on the various prototyping techniques that led to the generated concept of an expressive robotic table. Our design process explores how expressive motion cues such as respiratory movements can be leveraged to mediate social interactions between people in cold outdoor environments. We conclude by discussing the implications of the different prototyping methods applied and the envisioned future directions of the work within the scope of expressive robotics.  
 Social Robotics meets Sociolinguistics: Investigating Accent Bias and Social Context in HRI   
 Mary Ellen Foster 
  Jane Stuart-Smith 
  Elin A. Björling 
  Self-disclosure to a social robot is a mental health intervention that can decrease stress for adolescents. Online digital robots provide the potential to scale this intervention especially in COVID-19 social distancing situations. However, self-disclosure interactions with digital social robots remain relatively unexplored.  
 We conducted two online self-disclosure studies with adolescents (13-19 years old): our Active Listening Study compared experiences sharing positive, negative, and neutral feelings with a social robot, while our Journaling Study explored differences in sharing stressors by speaking with and without a social robot and by writing. We found that positive prompt tone improved mood while neutral prompt decreased stress, and less negative attitudes toward robots correlate with more qualitatively positive experiences with robot interactions. We also found robot disclosure interactions hold promising potential as a preferred method of self-disclosure over solo speaking, moderated by negative attitudes toward robots. This paper outlines limitations and future work from these studies.  
 A Controllable and Repeatable Method to Study Perceptual and Motor Adaptation in Human-Robot Interaction   
  Mark-Robin Giolando 
  Julie A. Adams 
  Underwater environments present numerous challenges for marine robots, such as noisy perception, constrained communication, and uncertainty due to wave motion. Human-in-the-loop systems can improve the efficiency and success rate of underwater grasping; however, collecting information in such unstructured environments and accurately presenting it to the operator remains a challenging task. Decision Support Systems (DSSs) can intelligently process and convey information to the operators to facilitate informed decision making. A DSS for autonomous underwater grasping provides visualization capabilities and tools to interact with the available information. Successful initial DSS-assisted underwater grasping was conducted using a six degrees of freedom robotic arm and a depth camera mounted on a mechanical testbed.  
 Trust Estimation for Autonomous Vehicles by Measuring Pedestrian Behavior in VR   
  Francesco Rea 
  Alessandra Sciutti 
  Belonging to a group is a natural need for human beings. Being left out and rejected represents a negative event, which can cause discomfort and stress to the excluded person and other members. Social robots have been shown to have the potential to be optimal tools for studying influence in group interactions, providing valuable insights into how human group dynamics can be modeled, replicated, and leveraged. In this work, we aim to study the effect of being excluded by a social robot in a teenagers-robot interaction. We propose a conversational turn-taking game, inspired by the Cyberball paradigm and rooted in social exclusion mechanisms to explore how the humanoid robot iCub can affect group dynamics by excluding one of the group members. Preliminary results show that the included player tries to re-engage with the one excluded by the robot. We interpret this dynamic as an included player’s tentative to compensate for the exclusion and reestablish a balance, in line with findings in human-human interaction research. Furthermore, the paradigm we developed seems a suitable tool for researching social influence in different Human-Robot Interaction contexts.  
 Can a Robot’s Hand Bias Human Attention?   
 Vali Lalioti 
  Iulia A. Ionescu 
  As robots are starting to inhabit more intimate social spheres, their functionality and acceptance in a fundamentally social environment greatly depend on them being tolerated by humans. One factor contributing to successfully accomplishing tasks in a collaborative manner is how robots’ actions and motions are interpreted by the people around them. Our broader research seeks to explore this gap aiming to design movement that is expressive, culturally dependent and contextually sensitive. A country that is at the forefront of this, in terms of social robots and their acceptance in society, is Japan. Therefore, as the first phases of this broader research, we present a new process, including a design toolkit, an open brief and a participatory structure. We discuss the resulting robot morphologies and participant feedback from a workshop in Japan, and conclude by discussing limitations and further research in designing robots with expressive movement contextually sensitive within an HRI-for-all paradigm.  
 How to Train Your Guide Dog: Wayfinding and Safe Navigation with Human-Robot Modeling   
 James M. Berzuk 
  James E. Young 
  When engaging with a social robot, people form expectations about the robot that may not align with its real behaviour and abilities. This gap is known as expectation discrepancy, and can confuse and disappoint users. We are developing a framework that can be used to understand and compare instances of expectation discrepancy between robots by considering the sources of those expectations. In doing so, we aim to provide a structure and unified vocabulary that can be used to support description and comparison of robot designs and the expectations users form of them. We have begun by examining theoretical work on expectations in interactions between people, and are working to synthesize this into an initial foundation. We will then refine this into a final social robot expectation framework by conducting a survey of expectation formation and discrepancy in existing social robots and projects.  
 Designing and Prototyping Drones for Emotional Support   
  Irene Di Giulio 
  Oya Celiktutan 
  Humans tend to use various nonverbal signals to communicate their messages to their interaction partners. Previous studies utilised this channel as an essential clue to develop automatic approaches for understanding modelling and synthesizing individual behaviours in human-human interaction and human-robot interaction settings. On the other hand, in small-group interactions, an essential aspect of communication is the dynamic exchange of social signals among interlocutors. This paper introduces LISI-HHI – Learning to Imitate Social Human-Human Interaction, a dataset of dyadic human inter- actions recorded in a wide range of communication scenarios. The dataset contains multiple modalities simultaneously captured by high-accuracy sensors including motion capture, RGB-D cameras, eye trackers, and microphones. LISI-HHI is designed to be a benchmark for HRI and multimodal learning research for modelling intra- and interpersonal nonverbal signals in social interaction contexts and investigating how to transfer such models to social robots.  
 What You See Is (not) What You Get: A VR Framework for Correcting Robot Errors   
  Patric Jensfelt 
  Andre Pereira 
  Many solutions tailored for intuitive visualization or teleoperation of virtual, augmented and mixed (VAM) reality systems are not robust to robot failures, such as the inability to detect and recognize objects in the environment or planning unsafe trajectories. In this paper, we present a novel virtual reality (VR) framework where users can (i) recognize when the robot has failed to detect a real- world object, (ii) correct the error in VR, (iii) modify proposed object trajectories and, (iv) implement behaviors on a real-world robot. Finally we propose a user study aimed at testing the efficacy of our framework. Project materials can be found in the OSF repository.  
 The Impact of Robot’s Body Language on Customer Experience: An Analysis in a Cafe Setting   
  Shintaro Okazaki 
  Oya Celiktutan 
  Nonverbal communication plays a crucial role in human-robot interaction (HRI) and have been widely used for robots in service environments. While few studies have addressed the understanding customer’s acceptance of robots under many different interaction conditions, the impact of robots’ nonverbal interaction modalities (i.e., a combination of body language, voice, and touch) on customers’ experience has not been investigated truly. To this end, in this paper, we introduce an HRI framework that aims to assist customers in their food and beverage choices in a real-world cafe setting. With this framework, the contribution of this paper are two folds. We introduce a time-synchronised multisensory HRI dataset comprising the interactions between a social robot and customers in a real-world environment. We conduct a user study to evaluate the configuration of multimodal HRI framework, particularly nonverbal gestures, and its contribution to customers’ interaction experience in this specific marketing setting.  
  Oriana Ferrari 
  Emilia Barakova 
  There is a growing interest in implementing robotics applications for children in healthcare to provide companionship, comfort, education, and therapy. Parental expectations regarding robotics for young children play a critical role in influencing its development and acceptance. However, parental expectations are widely overlooked in HRI. Therefore, a better understanding of what parents of young children expect the robot to do in health-related interactions with robots is needed. To achieve this, we adopted the Technology-Specific Expectation Scale (TSES) [2] and added three more dimensions (i.e., assistive role, social-emotional, and playful distraction) to gauge users’ expectations of robots in healthcare, resulting in TSES-R. This paper reports the development and reliability analysis of TSES-R. Furthermore, this paper presents the preliminary results collected from using the TSES-R with a sample of 31 families, which showcases how these outcomes could be helpful for future related studies.  
 A Social Robot for Explaining Medical Tests and Procedures: An Exploratory Study in the Wild   
 The Warehouse Robot Interaction Sim: An Open-Source HRI Research Platform   
 Connor Esterwood 
  Lionel Peter Robert 
  The use of physical robots in real-world laboratories for the study of human-robot interaction is not without limitations and logistical challenges. In response, a wide range of studies have begun using virtual representations of robots. However, very few of these platforms are openly available to the HRI community. This limits reproducibility and the ability of the community to leverage existing resources for their own research. In response, this paper presents The Warehouse Robot Interaction Sim. The Warehouse Robot Interaction Sim is an open-source immersive virtual platform developed in the Unreal Engine with the goal of conducting research on trust repair in HRI. This paper summarizes the overall structure of the platform, how it can be modified, and briefly discuss how this platform has been leveraged for research. In doing so we hope to encourage other researchers in HRI to consider leveraging this platform for their own research questions and study designs.  
 Formative Usability Evaluation of WiGlove – A Home-based Rehabilitation Device for Hand and Wrist Therapy after Stroke   
  Luke Jai Wood 
  Farshid Amirabdollahian 
  WiGlove is a passive dynamic orthosis aimed at home-based post-stroke rehabilitation of the hand and wrist. This paper highlights results from WiGlove’s formative evaluation as the first step towards its deployment. In this study, twenty healthy participants evaluated the usability and safety of the WiGlove compared to its predecessor, the state-of-the-art SCRIPT Passive Orthosis (SPO). In this within-subject experiment, they performed various tasks such as donning/doffing, adjusting the tension, grasping, etc., with both gloves and rated them using a Likert scale-based questionnaire. The results showed improvements in several aspects of usability and safety. This study provides preliminary evidence of WiGlove’s fitness for the next assessment with its intended users, people recovering from stroke with sustained hand and wrist impairment.  
 Robotic Interventions for Learning (ROB-I-LEARN): Examining Social Robotics for Learning Disabilities through Business Model Canvas   
  K. Sivakumar 
  John R. McIntyre 
  This ROB-I-LEARN research utilizes a versatile framework (e.g., Business Model Canvas or BMC) for robot design and curriculum development aimed at students diagnosed with autism spectrum disorder (ASD). Robotic interventions / human-robot interaction (HRI) field experiments with high school students were conducted as a recommendation or an outcome of the BMC framework and customer discovery interviews. These curriculum-related robotic interventions / interactive scenarios were designed to improve cognitive rehabilitation targeting students with ASD in high schools, thus enabling a higher quality learning environment that corresponds with students’ learning requirements to prepare them for future learning and workforce environments.  
 Enhancing Human-robot Collaboration by Exploring Intuitive Augmented Reality Design Representations   
 Chrisantus Eze 
  Christopher Crick 
  As the use of Augmented Reality (AR) to enhance interactions between human agents and robotic systems in a work environment continues to grow, robots must communicate their intents in informative yet straightforward ways. This improves the human agent’s feeling of trust and safety in the work environment while also reducing task completion time. To this end, we discuss a set of guidelines for the systematic design of AR interfaces for Human-Robot Interaction (HRI) systems. Furthermore, we develop design frameworks that would ride on these guidelines and serve as a base for researchers seeking to explore this direction further. We develop a series of designs for visually representing the robot’s planned path and reactions, which we evaluate by conducting a user survey involving 14 participants. Subjects were given different design representations to review and rate based on their intuitiveness and informativeness. The collated results showed that our design representations significantly improved the participants’ ease of understanding the robot’s intents over the baselines for the robot’s proposed navigation path, planned arm trajectory, and reactions.  
 “Who’s that?”: Identity Self-Perception and Projection in the Use of Telepresence Robots in Hybrid Classrooms   
  Hannah Li 
  Selma Sabanovic 
  Robotic Telepresence (RT) is a promising medium for students who are unable to attend in-person classes. It enables remote students to be present in the classroom and interact with their classmates and instructors. However, it can be limiting to their identity self-perception and projection, which may have repercussions on the social dynamics and inclusion within the classroom. We present preliminary findings of a qualitative analysis of 12 observations and interviews with RT attendees. We examine RT design and use aspects that either supported identity self-perception and projection or limited it. Finally, we present telepresence robots design and use recommendations for the classroom context.  
 Will It Yield: Expectations on Automated Shuttle Bus Interactions With Pedestrians and Bicyclists   
 Ji-Yeong Oh 
  Casey C. Bennett 
  This paper describes a user experience comparison study to explore whether a user’s ‘cultural background’ affects their interaction with in-home pet robots designed for health purposes, e.g. socially-assistive robots (SARs). 11 Koreans and 10 Americans were interviewed after interacting in their own homes with a SAR. Statistical analyses and TF-IDF keyword analyses were conducted to detect significant differences between groups in terms of code co-occurrences. Results showed that American participants were more likely to focus on the interactive experience itself, whereas Korean participants focused more on critiquing technical aspects of the technology. Such differences suggest that Koreans tend to treat robotic pets as “tools”, while Americans view the robotic pet through the lens of their past experience raising real-life pets. We discuss implications of this for human-robot interaction (HRI) regarding SARs may be dependent on users’ cultural characteristics e.g. necessitating customized content that takes into account culturally-specific modes of use.  
 Development of a Wearable Robot that Moves on the User’s Arm to Provide Calming Interactions   
 Koji Kimura 
  Fumihide Tanaka 
  Wearable robots can maintain constant physical contact with the user and support its daily life. However since most wearable robots are fixed on the user’s body, the user has to be constantly aware of their presence. Sometimes this can impose a burden on the user and prevents them from wearing the robot daily. One solution to this problem is for the robot to move around the user’s body. When the user does not interact with the robot, it can move to an unobtrusive position and attract less attention from the user. This research aims to actualize such a wearable robot. In addition, by introducing flexible rubber joints, we aim for creating calming interactions with the user wearing the robot. This short paper reports the development of our initial prototypes.  
 Designing a Robot which Touches the User’s Head with Intra-Hug Gestures   
  Hidenobu Sumioka 
  Masahiro Shiomi 
  There are a lot of positive benefits of hugging, and several studies have applied its application in human-robot interaction. However, due to the limitation of a robot performance, these robots only touched the human’s back. In this study, we developed a hug robot, named “Moffuly-II.” This robot can hug not only with intra-hug gestures, but also touch the user’s back or head. This paper describes the robot system and the user’s impression of hug with the robot.  
 A Persuasive Robot that Alleviates Endogenous Smartphone-related Interruption   
  Ruhan Wang 
  Yijie Guo 
  The endogenous interruptions of smartphones have impacted people’s everyday life in many aspects, especially in the study and work scene under a lamp. To mitigate this, we make a robot that could persuade you intrinsically by augmenting the lamp on your desk with specific posture and light. This paper will present our design considerations and the first prototype to show the possibility of alleviating people’s endogenous interruptions through robots.  
 Buzzo or Eureka — Robot that Makes Remote Participants Feel More Presence in Hybrid Discussions   
  Yijie Guo 
  Haipeng Mi 
  Teleconferencing technology has been widely used in the context of the covid-19 pandemic. However, local and remote participants always have a poorer experience of hybrid discussion for various reasons in the leaderless group discussions with mixed online and offline members. In this paper, this phenomenon is explored through an early pilot study. We found problems with the lack of presence of remote participants in hybrid discussion sessions, as well as unclear information about the status of members. To solve such problems, we’ve designed a social robot called SNOTBOX. The bot indicates the participation status (marginalized or not) of the remote participant using “Buzzo” and the remote participant’s desire to be heard through a “Eureka”. We used both representations to attract the attention of local participants as a way to enhance the presence of remote participants in the conference. SNOTBOX is easy to produce and allows for DIY customization, and also supports multi-participant online discussions.  
 Designing and Evaluating Interactive Tools for a Robot Hand Collection   
  Kosuke Wakabayashi 
  Yuki Nishida 
  There have been discussions on using robots to provide suggestions for decision making in mixed jury-systems. Hence, it is vital to investigate the influence of system interventions on decision making. This study focused on how such suggestions from a robot and an expert human influenced the decision making of a sentence in a court judgment task. We hypothesized that the sequential pattern of presentation of suggestions by an AI system installed in a robot and a human expert would influence decision making performance. In a large-scale online experiment, we investigated several factors, such as the (a) adviser type (AI(Robot) or Human), (b) sequential order (AI to Human, Human to AI), and (c) length of the sentence (3 or 7 years) that would influence decision making. The results showed that when presented with a human expert’s suggestion, after an AI decision, participants were more biased towards the human’s suggestion. Moreover, participants’ decisions were influenced by the length of the suggestion, especially when presented with heavy lengths (seven years). This provides new implications on the factors that may influence decision making using robots as tools in a mixed jury-system and contributes to the notion of using robots in courts.  
 PLATYPUS: An Environment for End-User Development of Robot-Assisted Physical Training   
 Jose Pablo De la Rosa Gutierrez 
  Anders Stengaard Sørensen 
  When robots are used for physical therapy, programming becomes too important to be left to programmers. Developing programs for training robots is time-consuming and requires expertise within multiple engineering domains, combined with physical training, therapy, and human interaction competencies. In this paper, we present Platypus: an end-user development environment that encompasses the design and execution of custom activities for robot-assisted physical training. The current version ships a set of plugins for Eclipse’s IDE and uses a block-based visual language to specify the robot’s behaviors at a high abstraction level, which are translated into the low-level code specifications followed by the robot. As a use case, we present its implementation on RoboTrainer, a modular, rope-based pulling device for training at home. While user tests suggest that the platform has the potential to reduce the technical obstacles for building custom training scenarios, informational and design learning barriers were revealed during the tests.  
 Towards HRI of Everyday Life: Human Lived Experiences with Social Robots   
 Karolina Zawieska 
  Jessica Sorenson 
  As the HRI field evolves, the way we understand, and study human-robot interaction also inevitably changes. We argue here that there has been a gradual shift in HRI research from investigating a concept of human-robot ‘interaction’ towards that of ‘experience’. This includes User Experience (UX) approaches in the first place but also those perspectives that begin to go beyond mere usability and optimization toward meaningful social interactions and social experiences. This paper addresses the shift in question from a sociological perspective and proposes to bring it even further to include a systematic study of human ‘lived experiences’ taking place in the community contexts. The ultimate goal is to facilitate theoretical and methodological developments needed to systematically address and pursue research on the ‘HRI of Everyday Life’.  
 The Peg-Turning Dilemma: An Experimental Framework for Measuring Altruistic Behaviour Towards Robots   
  Aryaman Pandya 
  Paul Schmitt 
  With the advent of autonomous vehicles (AVs) on public roads, the frequency of interactions between these AVs and pedestrians will increase. One example of such an interaction is at unsignalized crosswalks, where pedestrians and vehicles must negotiate for the right of way. Studies show that these interactions often use social communication channels. This paper addresses how AVs can fill this communication gap, focusing on the impact of pedestrian self-identifiability. Using VR, we designed two novel awareness-conveying behaviors, and a control condition with no awareness behavior. We then conducted a within-subjects VR study with 19 participants in which they traversed a crosswalk in front of a driverless vehicle in each experimental condition and rated their experience across seven probes. Results indicated that an awareness-conveying behavior significantly increased pedestrians’ sense of safety and that increases in self-identifiability further improved pedestrians’ experience without resulting in a heightened sense of surveillance from the vehicle.  
 Save Baby Whale! A Pet Robot as a Medication Reminder for Children with Asthma   
  Zhiyao Ma 
  Yijie Guo 
  Asthma is one of the most common chronic diseases in children, but adherence to asthma medications is very low, which can lead to poor or even dangerous outcomes. To solve this problem, we came up with a baby whale pet robot that needs to be taken care of by children. In this paper, we present the design of our first prototype to explore whether a pet robot could help improve medication adherence in children with asthma.  
 The Impact of Speech and Movement on the Interaction with a Mobile Hand Disinfection Robot   
  Leon Bodenhagen 
  Oskar Palinko 
  Hand disinfection is an important tool in the line of defense against infectious diseases. Hand sanitizer dispensers are usually passive devices sitting at entrances of buildings and other frequented locations. In this study we explore the usefulness of an interactive mobile hand sanitizer robot, more specifically, the research is focused on finding the most significant attention-grabbing modality for the robot to motivate people to disinfect their hands. Through an in -the-wild Wizard-of-Oz experiment and a short questionnaire each of the four usage modalities was tested in the entrance hall of a university. The results show that movement had the most significant impact, compared to sound and nothing at all, yet due to the robot’s design the participants expected it to talk to them.  
 “Feeling Unseen”: Exploring the Impact of Adaptive Social Robots on User’s Social Agency During Learning   
 Pooja Malvi 
  Hee Rin Lee 
  The increasing number of public AI-art generation tools has allowed people, including children, to be creative and bring their ideas to life. However, these AI systems could be misused by children and expose them to age-inappropriate images. In this paper, we explore how social robots could guide children as an embodied element of the AI art generation system. To investigate this topic, we examined how children conceptualize AI observed how they use an AI-art generation system called DALL-E 2, and conducted co-design workshops to develop a social robot prototype, Cat-E. The Cat-E aims to help children generate AI art in a regulated, safe but creative way by providing prompts and leading them to generate more ethical and morally sound AI art. This study reveals that children perceive a robot as an embodied element of AI and consider it to be a reliable and unbiased source of information. We propose that social robots can play a role of a friendly guide that enables children creatively but safely utilize AI systems.  
 Improving a Robot’s Turn-Taking Behavior in Dynamic Multiparty Interactions   
 Maike Paetzel-Prüsmann 
  James Kennedy 
  In this paper, we describe ongoing work to develop a robust and natural turn-taking behavior for a social agent to engage a dynamically changing group in a conversation. We specifically focus on discussing likely interaction scenarios for a social robot and how appropriate conversational behavior could unfold in each situation. Preliminary findings from annotations of more than 9,000 dialogue samples from a related domain are used to help judge the importance of different interaction scenarios. We conclude by outlining important general considerations for designing more robust dialogue systems as well as highlight next steps we are taking in developing our character’s turn-taking behavior.  
 Attention-guiding Takeover Requests for Situation Awareness in Semi-autonomous Driving   
  Jialong Li 
  Kenji Tei 
  In semi-autonomous driving (SAE Level-3), the automated driving system allows drivers to focus on their non-driving-related tasks for the majority of the journey. However, when the system faces situations beyond its operational design domain, the drivers need to manually control the vehicle responding to the takeover request (TOR). Many efforts have been made in previous studies to find a more effective method to initiate the TOR. In this paper, we propose to improve drivers’ takeover performance by utilizing attention-guiding techniques when delivering the TOR. A preliminary experiment (N=19) indicates that our method reduced drivers’ collision rate and mental workload.  
 What Does It Mean to Anthropomorphize Robots?: Food For Thought for HRI Research   
 Samia Cornelius Bhatti 
  Lionel Peter Robert 
  Anthropomorphism is a well-used but vague concept that demands further understanding and clarification to be effectively used in HRI research. Although most HRI research defines and uses anthropomorphism as a human-like attribution process, there is lack of distinction between its deployment in design versus its manifestation in user response. Furthermore, researchers need to separate mindless from mindful anthropomorphism and find ways to theorize and measure each. Researchers also need to consider the dynamic and contextual nature of anthropomorphism to generate relevant findings for research as well as practice.  
 Presenting Human-Robot Relative Hand Position using a Multi-Step Vibrotactile Stimulus for Handover Task   
  Anahita Etemad 
  Hiroyuki Umemuro 
  This paper investigated the influence of a social robot which discloses a backstory of its experiences on the development of trust in human-robot interaction with respect to the nature of backstories. We compared three cases of backstories, a happy backstory, a sorrowful backstory and no backstory told by the robot during interaction with participants. The results indicated that the robot disclosing a happy backstory provided the participants with higher impression of trustworthiness in general and affective trust compared to the robot telling no backstory. However, the robot with sorrowful backstory was not evaluated to lead to higher trustworthiness than the robot with no backstory. Furthermore, the happy backstory condition scored higher than the sorrowful backstory condition in general, affective and cognitive trust. Thus, participants rated a happy backstory tied to positive self-disclosed emotion, to be significantly more influential in human-robot trust.  
 ‘Sorry’ Says the Robot: The Tendency to Anthropomorphize and Technology Affinity Affect Trust in Repair Strategies after Error   
  Matteo Laffranchi 
  Lorenzo de Michieli 
  Robotic rehabilitation devices are showing strong potential for intensive, task-oriented, and personalized motor training. Integrating Mixed Reality (MR) technology and tangible objects in these systems allow the creation of attractive, stimulating, and personalized hybrid environments. Using a gamification approach MR-based robotic training can increase patients’ motivation, engagement, and experience. This paper presents the development of two Mixed Reality-based exergames to perform bimanual exercises assisted by a shoulder rehabilitation exoskeleton and using tangible objects. The system design was completed by adopting a user-centered iterative process. The system evaluates task performance and cost function metrics from the kinematic analysis of the hands’ movement. A preliminary evaluation of the system is presented, which shows the correct operation of the system and the fact that it stimulates the desired upper limb movements.  
 Bridging the Gap: Using a Game-based Approach to Raise Lay People’s Awareness About Care Robots   
 Pradip Pramanick 
  Chayan Sarkar 
  The prolificacy of human-robot interaction not only depends on a robot’s ability to understand the intent and content of the human utterance but also gets impacted by the automatic speech recognition (ASR) system. Modern ASR can provide highly accurate (grammatically and syntactically) translation. Yet, the general purpose ASR often misses out on the semantics of the translation by incorrect word prediction due to open-vocabulary modeling. ASR inaccuracy can have significant repercussions as this can lead to a completely different action by the robot in the real world. Can any prior knowledge be helpful in such a scenario? In this work, we explore how prior knowledge can be utilized in ASR decoding. Using our experiments, we demonstrate how our system can significantly improve ASR translation for robotic task instruction.  
 Let’s Roll Together: Children Helping a Robot Play a Dice Game   
 Emily Timmerman 
  Mike E.U. Ligthart 
  Play is an important part of children’s lives and playing with social robots could provide powerful interventions, for example in education. However, child-robot play is often restricted by the technical limitations of the robot. Tools like Bluetooth-connected dice could circumvent some of these limitations, but technical limitations can also be resolved in a social way. In this paper, we explore children playing a dice game with a Nao robot. The Nao robot cannot pick up the dice. We compared two modes of helping: rolling for the robot and handing the dice to the robot. The results show that children prefer handing the dice to the robot. They feel the robot is more involved when it physically participates. Children who feel the robot is more involved, enjoy the game more. Finally, we found evidence that helping the robot might even be preferred over the robot not needing any help.  
 Sawarimōto: A Vision and Touch Sensor-based Method for Automatic or Tele-operated Android-to-human Face Touch   
  Takashi Minato 
  Hiroshi Ishiguro 
  Although robot-to-human touch experiments have been performed, they have all used direct tele-operation with a remote controller, pre-programmed hand motions, or tracked the human with wearable trackers. This report introduces a project that aims to visually track and touch a person’s face with a humanoid android using a single RGB-D camera for 3D pose estimation. There are three major components: 3D pose estimation, a touch sensor for the android’s hand, and a controller that combines the pose and sensor information to direct the android’s actions. The pose estimation is working and released under as open-source. A touch sensor glove has been built and we have begun work on creating an under-skin version. Finally, we have tested android face-touch control. These tests showed many hurdles that will need to be overcome, but also how convincing the experience already is for the potential of this technology to elicit strong emotional responses.  
 Exploring Mothers’ Perspectives on Socially Assistive Robots in Peripartum Depression Screening   
  Isabel García Velázquez 
  Ginevra Castellano 
  Peripartum Depression (PPD) affects 8-15 percent of new mothers in Sweden every year; a majority of PPD cases go undetected, and only a small percentage receives adequate care. Social Assistive Robots (SARs) bring great potential for healthcare applications. Using SARs in healthcare tasks, for example PPD Screening, could reduce healthcare professionals’ strain, by supporting them, without replacing them, in key roles. However, studies that investigate the possibility to utilize SARs in PPD screening are scarce. In this paper, we present an interview study with ten mothers with prior experience of PPD in relation to their pregnancy. The contributions from this work are twofold. First, we elicited participants’ opinions and attitudes towards utilizing SARs in PPD screening. Second, we explored participants’ expressed needs in PPD screening. From the participants’ statements, we discovered potential scenarios which could address future patients’ needs. These insights could be used as a foundation for the development of SARs in PPD screening and other mental healthcare applications, thus helping address PPD in women.  
 Chaos to Control: Human Assisted Scene Inspection   
  We are working towards a mixed reality-based human-robot collaboration interface using gaze and gesture as methods of communicating intent in a search and rescue scenario to optimize the operation. The lack of mature algorithms and control schemes for autonomous systems makes it still difficult for them to operate safely in high-risk environments. We are approaching the problem through symbiosis while utilizing humans’ intuition of the environment and robots’ capability to travel through unknown environments for optimal performance in a given time.  
 The Effect of Gender on Perceived Anthropomorphism and Intentional Acceptance of a Storytelling Robot   
 Daan Robben 
  Eriko Fukuda 
  Mirjam De Haas 
  Gender and anthropomorphism play a substantial role in how social robots are perceived. In child-robot interaction, children’s perception of the robot can be influenced by individual factors, such as the robot’s gender. The purpose of this study is to examine how gender congruity affects the way children perceive social storytelling robots. Furthermore, the relationships among gender congruity, anthropomorphism, and intentional acceptance were investigated. Sixty-four children interacted with a storytelling robot. The results indicated that children did not humanize the robot to a higher degree if the robot’s gender matched with the children’s gender. Moreover, children who anthropomorphised the robot to a higher degree found the robot more sociable and had higher intentions of using the robot repeatedly. The findings of this studies contrast with previous scientific work, and indicate more research should be conducted to find out which factors play a vital role in the humanization and gendering of robots.  
 Hey Robot, Can You Help Me Feel Less Lonely?: An Explorative Study to Examine the Potential of Using Social Robots to Alleviate Loneliness in Young Adults   
  Cindy L. Bethel 
  Selma Sabanovic 
  The use of socially assistive robots is able to alleviate some depression symptoms, according to existing research. However, due to comorbidities that often accompany depression and the unique experiences of each individual, it is necessary to get a better understanding of how SARs should be personalized. Through 10 hourlong workshops with 10 individuals living with depression, we explored the customization of a zoomorphic SAR for adults with depression. By using the SAR Therabot? as a base platform, participants designed their own unique covering for the robot, and discussed desired robot behaviors and privacy concerns around data collection. Though the physical designs of the robots varied greatly, participants expressed common themes regarding their preference for a soft touchable exterior, comfort with sharing data with their therapists, and interest in the robot producing more realistic sounds and movements, among other design features.  
 Development of a University Guidance and Information Robot   
 Amar Halilovic 
  Felix Lindner 
  With the rise in the number of robots in our daily lives, human-robot encounters will become more frequent. To improve human-robot interaction (HRI), people will require explanations of robots’ actions, especially if they do something unexpected. Our focus is on robot navigation, where we explain why robots make specific navigational choices. Building on methods from the area of Explainable Artificial Intelligence (XAI), we employ a semantic map and techniques from the area of Qualitative Spatial Reasoning (QSR) to enrich visual explanations with knowledge-level spatial information. We outline how a robot can generate visual and textual explanations simultaneously and test our approach in simulation.  
 Study of Telerobot Personalization for Children: Exploring Qualitative Coding of Artwork   
  Siena Saltzen 
  Sanjay S. Joshi 
  Social telepresence robots (i.e., telerobots) are used for social and learning experiences by children. However, most (if not all) commercially available telerobot bodies were designed for adults in corporate or healthcare settings. Due to an adult-focused market, telerobot design has typically not considered important factors such as age and physical aspect in the design of robot bodies. To better understand how peer interactants can facilitate the identities of remote children through personalization of robot bodies, we conducted an exploratory study to evaluate collaborative robot personalization. In this study, child participants (N=28) attended an interactive lesson on robots in our society. After the lesson, participants interacted with two telerobots for personalization activities and a robot fashion show. Finally, participants completed an artwork activity on robot design. Initial findings from this study will inform our continued work on telepresence robots for virtual inclusion and improved educational experiences of remote children and their peers.  
 Collaboration with Highly Automated Vehicles via Voice Interaction and Augmented Reality: A VR-Based Study   
  Lina Orrell 
  Hanna Rönntoft 
  In future confined industrial contexts (hubs), highly automated vehicles and human operators may work in shared spaces and collaborate on joint tasks. This will probably generate a demand for new user interfaces between humans and machines that need to be designed to facilitate high levels of safety and efficiency as well as a positive user experience (UX). The present work investigates the potential of using a combination of voice interaction (VI) and visual augmented reality (AR) to support collaboration between automated vehicles and humans manually operating a machine. A concept using VI and AR for a loading scenario in a logistic center was created and evaluated using a VR headset to provide an immersive experience. A user study with 18 forklift drivers was conducted. Our study shows that the concept generated high scores in terms of usability and UX which indicates a promising potential to use VI and AR to facilitate interaction between human machine operators and unmanned highly automated vehicles when performing collaborative tasks. Our study also implies a need to explore the design and implementation of more complex and social VI for users in logistic centers.  
 Robot Theory of Mind with Reverse Psychology   
  Marta Romeo 
  Angelo Cangelosi 
  Theory of mind (ToM) corresponds to the human ability to infer other people’s desires, beliefs, and intentions. Acquisition of ToM skills is crucial to obtain a natural interaction between robots and humans. A core component of ToM is the ability to attribute false beliefs. In this paper, a collaborative robot tries to assist a human partner who plays a trust-based card game against another human. The robot infers its partner’s trust in the robot’s decision system via reinforcement learning. Robot ToM refers to the ability to implicitly anticipate the human collaborator’s strategy and inject the prediction into its optimal decision model for a better team performance. In our experiments, the robot learns when its human partner does not trust the robot and consequently gives recommendations in its optimal policy to ensure the effectiveness of team performance. The interesting finding is that the optimal robotic policy attempts to use reverse psychology on its human collaborator when trust is low. This finding will provide guidance for the study of a trustworthy robot decision model with a human partner in the loop.  
 Human Gesture Recognition with a Flow-based Model for Human Robot Interaction   
  Cecilia Ovesdotter Alm 
  Jamison Heard 
  With the development of industry 4.0, more collaborative robots are being implemented in manufacturing environments. Hence, research in human-robot interaction (HRI) and human-cobot interaction (HCI) is gaining traction. However, the design of how cobots interact with humans has typically focused on the general able-bodied population, and these interactions are sometimes ineffective for specific groups of users. This study’s goal is to identify interactive differences between hearing and deaf and hard of hearing individuals when interacting with cobots. Understanding these differences may promote inclusiveness by detecting ineffective interactions, reasoning why an interaction failed, and adapting the framework’s interaction strategy appropriately.  
 Transparent Value Alignment   
 Lindsay Sanneman 
  Julie Shah 
  As robots become increasingly prevalent in our communities, aligning the values motivating their behavior with human values is critical. However, it is often difficult or impossible for humans, both expert and non-expert, to enumerate values comprehensively, accurately, and in forms that are readily usable for robot planning. Misspecification can lead to undesired, inefficient, or even dangerous behavior. In the value alignment problem, humans and robots work together to optimize human objectives, which are often represented as reward functions and which the robot can infer by observing human actions. In existing alignment approaches, no explicit feedback about this inference process is provided to the human. In this paper, we introduce an exploratory framework to address this problem, which we call Transparent Value Alignment (TVA). TVA suggests that techniques from explainable AI (XAI) be explicitly applied to provide humans with information about the robot’s beliefs throughout learning, enabling efficient and effective human feedback.  
 Children’s Fundamental Rights in Human-Robot Interaction Research: A Systematic Review   
  Nicolás Rodríguez 
  Alberto Sanfeliu 
  In Human-Robot Collaboration (HRC) tasks, the classical Perception-Action cycle can not fully explain the collaborative behaviour of the human-robot pair until it is extended to Perception-Intention-Action (PIA) cycle, giving to the human’s intention a key role at the same level of the robot’s perception and not as a subblock of this. Although part of the human’s intention can be perceived or inferred by the other agent, this is prone to misunderstandings so the true intention has to be explicitly informed in some cases to fulfill the task. Here, we explore both types of intention and we combine them with the robot’s perception through the concept of Situation Awareness (SA). We validate the PIA cycle and its acceptance by the user with a preliminary experiment in an object transportation task showing that its usage can increase trust in the robot.  
 Practical Development of a Robot to Assist Cognitive Reconstruction in Psychiatric Day Care   
  Hirokazu Kato 
  Masahiro Shiomi 
  One of the important roles of social robots is to support mental health through conversations with people. In this study, we focused on the column method to support cognitive restructuring, which is also used as one of the programs in psychiatric day care, and to help patients think flexibly and understand their own characteristics. To develop a robot that assists psychiatric day care patients in organizing their thoughts about their worries and goals through conversation, we designed the robot’s conversation content based on the column method and implemented its autonomous conversation function. This paper reports on the preliminary experiments conducted to evaluate and improve the effectiveness of this prototype system in an actual psychiatric day care setting, and on the comments from participants in the experiments and day care staff.  
 Comparison of Attitudes Towards Robots of Different Population Samples in Norway   
 Marten Bloch 
  Alexandra Fernandes 
  Acceptance of robots is known to be directly influenced by perceptions and attitudes potential users have of them. Particularly, negative attitudes can prevent that the implementations of robots unlock their full potential and ultimately fail if negative attitudes are not addressed. We employed the popular Negative Attitude Towards Robots Scale (NARS) across four different studies to assess how different populations in Norway perceive robots. All four included exposure to at least a robot. However, the setup of each individual study was different from the others. We summarized the results across study and made comparisons between the different samples. We also analyzed the effect of gender and age on attitude towards robots as measured by the NARS. The results indicate that there are significant differences between samples and that females score significantly higher than males, thus having a less favorable opinion of robots and potentially avoiding interaction with them. We touch upon possible explanations and implications of our results and highlight the need for more research into this topic.  
 Who’s in Charge?: Using Personalization vs. Customization Distinction to Inform HRI Research on Adaptation to Users   
 Dimitri LACROIX 
  Ricarda Wullenkord 
  Friederike Eyssel 
  This paper presents a conceptual approach regarding robot-to-user adaptation, with a focus on the psychological effects of this adaptation process during human-robot interaction (HRI). This approach emphasizes the pertinent role of users in shaping adaptation processes. First, a literature review revealed perceived personal relevance as the central determinant of successful robot-to-user adaptation. Second, we distinguish two main types of adaptations which depend on the extent to which a user is involved: Personalization and customization. We then illustrate effects of personalization vs. customization on potential end users. In particular, anthropomorphism and psychological ownership should be taken into account in prospective research. Finally, we propose to interpret personalization and customization as two opposites of a continuum to guide future empirical research about robot adaptation, before suggesting some leads for future research about the psychological effects of adaptation processes in HRI.  
 Evaluating Kinect, OpenPose and BlazePose for Human Body Movement Analysis on a Low Back Pain Physical Rehabilitation Dataset   
  Sao Mai Nguyen 
  Adriana Tapus 
  Analyzing human motion is an active research area, with various applications. In this work, we focus on human motion analysis in the context of physical rehabilitation using a robot coach system. Computer-aided assessment of physical rehabilitation entails evaluation of patient performance in completing prescribed rehabilitation exercises, based on processing movement data captured with a sensory system, such as RGB and RGB-D cameras. As 2D and 3D human pose estimation from RGB images had made impressive improvements, we aim to compare the assessment of physical rehabilitation exercises using movement data obtained from both RGB-D camera (Microsoft Kinect) and estimation from RGB videos (OpenPose and BlazePose algorithms). A Gaussian Mixture Model (GMM) is employed from position (and orientation) features, with performance metrics defined based on the log-likelihood values from GMM. The evaluation is performed on a medical database of clinical patients carrying out low back-pain rehabilitation exercises, previously coached by robot Poppy.  
 Towards a Wave Approach for Value Sensitive Design in Social Robotics   
  Vivienne Jia Zhong 
  Friederike Eyssel 
  Even though a broad range of social robots are currently available on the market, social robots are not yet an integral part of companies, healthcare providers, or public institutions. This might be due to the fact that the prevalent developer perspective immanently focuses on technological advancements, whereas a human-centered view remains underrepresented. In this paper, we argue that a human-centered perspective which integrates values and beliefs of relevant technology stakeholders needs to complement existing approaches to social robot design. Therefore, we propose to apply value sensitive design (VSD) to improve the process of social robot development and design. Even though VSD has become popular in recent years and it represents an established approach to foster innovative technologies, it has not yet been widely applied in the context of social robotics. Concretely, in this paper we will outline the added value of using VSD for social robots and we will explain how to utilize this methodology to enrich research and practice in social robotics.  
 Comparing How Soft Robotic Tentacles and an Equivalent Traditional Robot are Described   
  Chrystopher L. Nehaniv 
  Kerstin Dautenhahn 
  Persons with Dementia face the issue of a deteriorating memory. As assistive robots are being increasingly adapted as a helper to persons with dementia, this paper presents an additional feature to such robots. Assistive robots that might assist with different tasks in users’ households can also be utilized to track salient objects to quickly find them in case they are misplaced. This paper presents an episodic memory system that can enable a robot to recognize salient objects and track them while moving in and out of the environment. We also demonstrate how to develop access to the robot’s memory in an easy-to-understand way using a graphical user interface (GUI). The proposed system is integrated with a Fetch mobile manipulator robot to track, store and visualize various household objects in an environment. Results from a system evaluation study are encouraging and the system will be further investigated in future co-design and user studies.  
 Social Robots to Encourage Play for Children with Disabilities: Learning Perceived Requirements and Barriers from Family Units   
  Antonio Andriella 
  Paul Pridham 
  In this paper, we present a proposed format for reporting human studies in Human-Robot Interaction (HRI). We call for details which are often overlooked or left out of research papers due to space constraints, and propose a standardized format to contain those details in paper appendices. Providing a formalized study reporting method will promote an increase in replicability and reproducibility of HRI studies and encourage meta-analysis and review, ultimately increasing the generalizability and validity of HRI research. Our draft is the first step towards these goals, and we welcome feedback from the HRI community on the included topics.  
 Rube-Goldberg Machines, Transparent Technology, and the Morally Competent Robot   
 Terran Mott 
  Tom Williams 
  Social robots of the future will need to perceive, reason about, and respond appropriately to ethically sensitive situations. At the same time, policymakers and researchers alike are advocating for increased transparency and explainability in robotics-design principles that help users build accurate mental models and calibrate trust. In this short paper, we consider how Rube Goldberg machines might offer a strong analogy on which to build transparent user interfaces for the intricate, but knowable inner workings of a cognitive architecture’s moral reasoning. We present a discussion of these related concepts, a rationale for the suitability of this analogy, and early designs for an initial prototype visualization.  
 TIP: A Trust Inference and Propagation Model in Multi-Human Multi-Robot Teams   
  Armaghan Moemeni 
  Praminda Caleb-Solly 
  Robot teleoperation is being explored in a number of application areas, where combining human adaptive intelligence and high precision of robots can provide access to dangerous or inaccessible places, or augment human dexterity. Using virtual reality (VR) is one way to enable robot teleoperation, where additional information can be augmented in the display to make the remote control easier. In this paper, we present a robot teleoperation system, developed and deployed on a JAKA Minicobo robotic arm, to compare the user experience and performance for three different control methods. These include a VR controller, VR gestures and a traditional graphical user interface (GUI). Each study participant was asked to conduct the experiment twice using all three methods, during which the time, the total spatial distance of the robot end-effector movement, and the frequency of errors in a teleoperation task were recorded for quantitative analysis. All participants were also asked to complete a questionnaire based on the NASA task load index. The results show that overall the VR gestures method enables users to complete the task faster than the VR controller, and using the traditional GUI is generally slower. While the quantitative results do not show statistically significant differences, both of the VR methods place greater perceived physical and mental demands on the users, in comparison to the GUI, although when asked which method they preferred, only three of the sixteen participants preferred the VR gestures method. Given that a number of applications use VR, this study indicates that if the task is not time critical, then a traditional GUI might be more suitable for reducing perceived mental and physical load, and controller-free VR interaction might not always be desirable.  
 A Persuasive Hand Sanitizer Robot in the Wild: The Effect of Persuasive Speech on the Use of a Hand Sanitizer Robot   
  Kerstin Fischer 
  Oskar Palinko 
  In this paper, we report on field tests of a hand sanitizer robot, which tracks people’s movements using gaze and which uses several different persuasive utterances when people are approaching. Our results show that adding speech made people significantly more aware of the opportunity of using hand sanitizer, but that people do not use the hand sanitizer more often than with eye gaze only. Furthermore, the different utterances themselves did not lead to significant differences in attention or use, in spite of their effectiveness in other situations.  
 More Than a Number: A Multi-dimensional Framework For Automatically Assessing Human Teleoperation Skill   
  Ginevra Castellano 
  Katie Winkle 
  Human-robot interaction has the power to influence human norms and culture. While there is potential benefit in using this power to create positive social change, so too is there risk in merely reinforcing existing social biases which uphold systems of oppression. As the most salient forms of oppression arise along lines of social identity, it stands to reason that we must take utmost care in leveraging human-like identity cues when designing social robots and other agentic embodiments. Yet, the understanding of how to do this is not well-developed. Towards forming an ethics of robot identity, we begin by surveying the state of thought on the topic in human-robot interaction. We do this by conducting a structured review of HRI conference proceedings analyzed from a feminist, intersectional perspective. Our initial findings suggest that existing literature has not fully engaged with intersectionality, embodies an alarming pathologization of neurodivergence, and almost wholly neglects the examination of race.  
 M-OAT Shared Meta-Model Framework for Effective Collaborative Human-Autonomy Teaming   
 Baijun Xie 
  Chung Hyuk Park 
  Social play is essential in human interactions, increasing social bonding, mitigating stress, and relieving anxiety. With advancements in robotics, social robots can employ this role to assist in human-robot interaction scenarios for clinical and healthcare purposes. However, robotic intelligence still needs further development to match the wide spectrum of social behaviors and contexts in human interactions. In this paper we present our robotic intelligence framework with a mutual learning paradigm in which we apply deep learning based on emotion recognition and behavior perception, through which the robot learns human movements and contexts through the interactive game of charades. Furthermore, we designed a gesture-based social game to provide a more empathetic and engaging social robot for the user. We also created a custom behavior database containing contextual behaviors for the proposed social games. A pilot study was conducted with participants ranging in age from 12 to 19 for a preliminary evaluation.  
 The Influence of a Robot Recommender System on Impulse Buying Tendency   
  Kamila Zhumakhanova 
  Anara Sandygulova 
  Drones are continually entering our daily lives by being used in a number of different applications. This creates a natural demand for better interaction ways between humans and drones. One of the possible applications that would benefit from improved interaction is the inspection of smoking in prohibited areas. We propose our own gesture of drone flight that we believe would deliver the message “not to smoke” better than the ready-made built-in gesture. To this end, we conducted a within-subject experiment involving 19 participants, where we evaluated the gestures on a drone operated through the Wizard-of-Oz interaction design. The results demonstrate that the proposed gesture was better at conveying the message compared to the built-in gesture.  
 Design of Child-robot Interactions for Comfort and Distraction from Post-operative Pain and Distress   
  As a step towards designing a home robot to support older adults’ ikigai (meaning in life), we interviewed the family members who provide care for them. After conducting interviews with ten family caregivers in Japan we found that older adults’ physical health is a major concern to both caregivers and older adults. However concerns over loneliness were not prioritized by caregivers, though they did perceive older adults’ worries around this issue. Additionally, caregivers saw a number of ways a social robot could be designed to address this, as well as its ability to go beyond loneliness in promoting more fulfilling lives among older adults. Finally, we conclude that an ikigai robot may be designed to support both the ikigai of older adults and (indirectly) their family caregivers.  
 Lying About Lying: Examining Trust Repair Strategies After Robot Deception in a High-Stakes HRI Scenario   
 Kantwon Rogers 
  Reiden John Allen Webber 
  Robin Helmert 
  Anna-Lisa Vollmer 
  Since robots can facilitate our everyday life by assisting us in basic tasks, they are continuously integrated into our life. However, for a robot to establish itself, a user must accept and trust its doing. As the saying goes, you don’t trust things you don’t understand. Therefore, the base hypothesis of this paper is that providing technical transparency for users can increase understanding of the robot architecture and its behaviors as well as trust and acceptance towards it. In this work, we aim to improve a robot’s understanding trust, and acceptance by displaying transparent visualizations of its intention and perception in augmented reality. We conducted a user study where robot navigation with certain interruptions was demonstrated to two groups. The first group did not have AR visualizations displayed during the first demonstration; in the second demonstration, the visualizations were shown. The second group had the visualizations displayed throughout only one demonstration. Results showed that understanding increased with AR visualizations when prior knowledge had been gained in previous demonstrations.  
 CHIBO: A Pneumatic Robot that Provides Real-time Intervention for Parent-child Feeding Behavior   
  Parents may inadvertently promote excess weight gain in childhood by using inappropriate child-feeding behaviors. This study presents the design of a home robot in a parent-child feeding scenario. Designed for parents who have difficulty quantifying the amount of food their children, it helps them quantify calorie intake through pneumatic feedback and gives real-time feedback and intervention by recognizing feeding behaviors. It aims to create a more intuitive link between scientific quantification standards and actual eating scenarios by a pneumatic device in the form of a peripheral interaction. Based on our current prototype development, we have sought to explore the effectiveness of peripheral interactions with physical robotic interventions in user behavior.  
 SESSION: HRI Pioneers  
 Enabling Human-like Language-Capable Robots Through Working Memory Modeling   
 Rafael Sousa Silva 
 Socially Assistive Robotics for Anxiety Reduction   
 Kayla Matheus 
  Prior work in HRI for domains such as exercise, rehabilitation, and autism has shown how socially assistive robots (SARs) can successfully support behavioral practices. Applying these insights to mental health is an opportunity to support a large and growing population that is actively struggling. My research investigates utilizing SARs for supporting the therapeutic behavior of deep breathing for anxiety reduction. My prior work to date has focused on the design affordances required for an anxious population through the development of a new, haptically-based robot, Ommie. Future work explores how SARs for anxiety-reducing behaviors can maximize long-term, in-the-wild use through haptic interactions, perception technologies, and personalized motivational mechanisms.  
 Aligning Robot Behaviors with Human Intents by Exposing Learned Behaviors and Resolving Misspecifications   
 Investigating the Potential of Life-like Haptic Cues for Socially Assistive Care Robots   
 Jacqueline Borgstedt 
  Physical touch (e.g., hugging, holding hands, petting an animal) plays a fundamental role in the provision of socio-emotional support. Touch-based interactions should thus be considered for socially assistive robots designed to provide similar support. However, the haptic properties of currently existing robots are limited. While research has shown possibilities of integrating life-like haptic cues (e.g., thermal, vibrotactile pressure cues) into robotic interfaces, current understanding of user experiences with life-like haptic cues delivered by a robot, and their potential to regulate user affect, is insufficient. The current and proposed works investigate whether integrating life-like haptic cues into Human-Robot Interaction (HRI) can enhance the socio-emotional support provided by socially assistive robots and improve the relationships with, and perceptions of such robots. The findings of this work will provide insights into user experiences of touching a socially assistive robot and their perceptions of life-like haptic cues. The contributions will provide concrete design suggestions on how haptic cues can be integrated into interfaces of socially assistive robots to enhance users’ well-being during stress-inducing situations  
 Measuring Trust in Children’s Speech: Towards Responsible Robot-Supported Information Search   
  Children use conversational agents, such as Alexa or Siri, to search for information, but also tend to trust these agents which might influence their information assessment. It is challenging for children to assess the veracity of information retrieved from the internet and social media, possibly more so when they trust a voice agent excessively. In this project, I propose to design child-robot interactions to empower children to have a critical attitude by implementing real-time trust monitoring and robot behavioural interventions in cases of high trust. First, we need to be able to measure children’s level of trust in the robot real-time during the interaction, to reason about when excessive trust may be occurring. Second, we need to study what behavioural interventions by the robot foster critical attitudes toward the provided information. By adapting the robot’s behavior when excessive trust occurs, I aim to contribute to more responsible interactions between children and robots.  
 Designing Robotic Camera Systems to Enable Synchronous Remote Collaboration   
 Pragathi Praveena 
  Michael Gleicher 
  Bilge Mutlu 
  Collaborative robots have the potential to be intelligent, embodied agents that can contribute to remote human collaboration. We explore this paradigm through the design of robot-mounted camera systems for remote assistance. In this extended abstract, we discuss our iterative design process to develop interaction techniques that leverage shared control-based methods to distribute camera control between the agentic robot and human collaborators.  
 Robot Sound-In-Interaction   
 Hannah R. M. Pelikan 
  Sound is an important interaction modality in human interaction, which robot design is only starting to tap into. Drawing on insights about how human sounds support coordination of bodily activities, this work focuses on how robots can communicate through sound in concrete interactions in the wild. My work contributes a focus on how users make sense of sound in everyday interaction, promotes re-consideration of what HRI is designing for and stimulates the development of new HRI design methods.  
 Social Network Engagement during Human-robot Interaction: An Extended Abstract on a Fundamental Novel Field within Human-robot Interaction   
 Erin Hedlund-Botti 
  Matthew C. Gombolay 
  As the world’s population is aging and there are growing shortages of caregivers, research into assistive robots is increasingly important. Due to differing needs and preferences, which may change over time end-users will need to be able to communicate their preferences to a robot. Learning from Demonstration (LfD) is one method that enables non-expert users to program robots. While a powerful tool, prior research in LfD has made assumptions that break down in real-world scenarios. In this work, we investigate how to learn from suboptimal and heterogeneous demonstrators, how users react to failure with LfD, and the feasibility of LfD with a target population of older adults.  
 Resolving References in Natural Language Explanation Requests about Robot Behavior in HRI   
 Florian Schröder 
  Sonja Stange 
  Stefan Kopp 
  In HRI, users have been shown to request explanations when their interpretation of autonomous robot behavior fails. These requests can refer to the behavior either by open questions or with attributes of the behavior. The presented work aims to resolve these references in explanation requests by developing an episodic memory with a graph database that stores and queries representations of the internal execution. The reference resolution is done by the detection of temporal adverb and verb constraints in the syntactical dependency tree of utterances, the execution of a query in the episodic memory, and the scoring of the resulting entries to find the referred behavior. The explanation generation process of the original model is adapted to the new approach and can contain additional information such as detected constraints, a failed execution state, and the distinction between running and completed executions.  
 Longitudinal Proactive Robot Assistance   
 Perceived Appropriateness: A Novel View for Remediating Perceived Inappropriate Robot Navigation Behaviors   
 Yunzhong Zhou 
  Robots navigating in social environments inevitably exhibit behavior perceived as inappropriate by people which they will repeat unless they are aware of them; hindering their social acceptance. This highlights the importance of robots detecting and adapting to the perceived appropriateness of their behavior, in line with what we found in a systematic literature review. Therefore, we have conducted experiments (both outdoor and indoor) to understand the perceived appropriateness of robot social navigation behavior, based on which we collected a dataset and developed a machine learning model for detecting such perceived appropriateness. To investigate the usefulness of such information and inspire robot adaptive navigation behavior design, we will further conduct a WoZ study to understand how trained human operators adapt robot behavior to people’s feedback. In all, this work will enable robots to better remediate their inappropriate behavior, thus improving their social acceptance.  
 Social Robots to Encourage Play for Children with Physical Disabilities: Learning from Family Units   
  Johan Michalove 
  Jessie Wong 
  Toasting bread is a seemingly mundane task that people perform on a daily basis, whether in a private kitchen area or in a communal dining space. This paper presents a robotic toaster, or “toaster bot”, that is designed with animated movements to enhance the toast-making experience by not only assisting in completing the task itself but also by acting as a playful entity with whom users may interact. Furthermore, we aim to explore different roles and behaviors for the robotic toaster and how they are understood by the users.  
 Internet of Robotic Cat Toys to Deepen Bond and Elevate Mood   
 Isla Xi Han 
  Sarah Witzman 
  Pets provide important mental support for human beings. Recent advancements in robotics and HRI have led to research and commercial products providing smart solutions to enrich indoor pets’ lives. However, most of these products focus on satisfying pets’ basic needs, such as feeding and litter cleaning, rather than their mental well-being. In this paper, we present the internet of robotic cat toys, where a group of robotic agents connects to play with our furry friends. Through three iterations, we demonstrate an affordable and flexible design of clip-on robotic agents to transform a static household into an interactive wonderland for pets.  
 Making Music More Inclusive with Hospiano   
  Mengyu Chen 
  Hanyang Hu 
  Endogenous smartphone interruptions have changed many aspects of people’s daily lives, particularly in the study and work environment. We create a robot that could persuade you inherently by enhancing the desk lamp with posture changes and facial expression of gaze, which is affordable on both cost and interaction. This paper presents our design considerations and the first prototype to show the possibility of alleviating people’s endogenous interruptions through persuasive robots.  
 Pet Whale Robot Reminds Asthmatic Children of Medication   
  Yuyang Qi 
  Yao Lu 
  Children who are left behind have more mental problems than their urban peers because they have fewer instant emotional interactions with their parents. In order to solve this, we propose a pair of wearable soft robots that strengthen their emotional bond by enhancing instant nonverbal interactions. This paper details the design and creation of our initial pair of prototypes.  
 Mosu Buddy: Mourning Support Robot   
  Hanhui Yang 
  Yahan Xie 
  Inappropriate child-feeding behaviors are one of the causes of childhood obesity or stomach problems. Children from 1 to 5 years old don’t know how much they should eat and parents may not know whether their children are full or not. Therefore, we designed a robot in a parent-child feeding scenario that visualizes children’s daily diet through changes in its form. It aims to establish a more intuitive connection between scientific quantitative standards and actual feeding scenarios in the form of peripheral interaction. Thus solving the problem of real-time feedback in feeding.  
 LEIDUSS: An Interactive Social Robot Table for ADHD Children for Reading   
  Byounghern Kim 
  Hui Sung Lee 
  It is difficult for humans to express their pain confidently. Generally, communication between patients and caregivers is important, but there are difficulties of interaction with existing methods. We propose an assistive robot, ALH-E, that consists of squeezable input device and wriggling output device for pain communication. The patients can log their pain by squeezing, and the output device can express the patient’s pain intensity through dynamic wriggling movements. Human-robot interaction with ALH-E can be an assistive communication of pain between the patients and caregivers in the insufficient environment. This paper presents our development of the device and new interaction.  
 Smart Transformer Health Monitoring System   
 Ali Ahmed 
  Dependency on electricity is currently at an all-time high with power distribution being a key element. Currently, the maintenance and monitoring methodologies especially in Pakistan revolve around taking on-field samples (DGA) which is overall primitive and prone to human error. This research paper presents a smart device that can monitor transformer’s health using AI and relay that health score to a remote dashboard through the Internet of Things (IoT). The device uses a combination of single board computer, embedded systems, and communication protocols and is designed to detect and diagnose any issues with the transformer and alert the user in real time. The results of this research show that the device is an effective and reliable tool for extrusive monitoring of health of transformer.  
 BeeBot: A Robot that Help Children Manage Their Blood Glucose in a Friendly Way   
  Manuel Aranda 
  Diego Zegarra 
  Injury burns are traumatic events, especially for children. The use of combined pharmacological and non-pharmacological strategies in hospitals favor emotional experiences. However, in Latin American hospitals which have low budgets, it is not possible to hire therapeutic support personnel, such as clowns, due to the lack of available human resources. RoPi is a social robot created to assist hospitalized children’s emotional support through its multicolor interchangeable pieces and its interactive functions.  
 An Affordable MathBot: Let’s play!   
  Zhilong Zhao 
  Houze Li 
  We’ve designed a social robot called SNOTBOX. The bot indicates the participation status (marginalized or not) of the remote participant using “Buzzo” and the remote participant’s desire to be heard through a “Eureka”. We used both representations to attract the attention of local participants as a way to enhance the presence of remote participants in the conference. SNOTBOX is low cost, easy to manufacture and supports diy participants’ personalities, as well as being able to support multiple participants in online discussions.  
 Arpi, a Social Robot for Children with Epilepsy   
 Lucía Gabriela Sarmiento Calderón 
  Leonardo Fabio Gómez Hormaza 
  Arpi is a social robot designed to keep children with tonic-clonic epilepsy company and help the families to take care of them. Arpi monitors the child’s mood and empathically interacts with him through movements and sounds. When a seizure begins, it alerts the parents and monitors the time to assess whether it is necessary to seek professional help. Additionally, it is low cost and can be used in any environment, making it accessible to children in low-income countries , who, due to a lack of a good diagnosis and treatment experience physical and emotional difficulties in their daily lives.  
 Cogui: Interactive Social Robot for Autism Spectrum Disorder Children: A Wonderful Partner for ASD Children   
  Mark-Robin Giolando 
  Julie A. Adams 
  Underwater environments present numerous challenges for marine robots, such as noisy perception, constrained communication, and uncertainty due to wave motion. Collecting and accurately presenting information to the operator in such unstructured environments is a challenging task. A Decision Support System for autonomous underwater grasping provides visualization capabilities and tools to interact with the available information. Successful operator selected, autonomous underwater grasping trials were conducted using a six degrees of freedom robotic arm and a depth camera.  
 ReRun: Enabling Multi-Perspective Analysis of Driving Interaction in VR   
  Avi Parush 
  Wendy Ju 
  Rerun is a software system to support post-facto analysis in simulation research. In this submission, we show it working inside a multiplayer driving simulator. Rerun is built in Unity 3D and captures the virtual behavior of participants and their interactions with virtual objects. These recorded behaviors can then be played back from any perspective in the virtual space. This is useful in multi-agent interaction studies because researchers can sift through scenarios carefully from each participant’s perspective or even from an outside observer’s perspective. This enables a fine-grained understanding of implicit and explicit signaling between participants and other human or AI-controlled agents.  
 Stretch to the Client; Re-imagining Interfaces   
 Kay N. Wojtowicz 
  Maria E. Cabrera 
  This paper presents the efforts made towards the creation of a client interface to be used with Hello-Robot Stretch. The goal is to create an interface that is accessible to allow for the best user experience. This interface enables users to control Stretch with basic commands through several modalities. To make this interface accessible, a simple and clear web interface was crafted so users of differing abilities can successfully interact with Stretch. A voice activated option was also added to further increase the range of possible interactions.  
 Mosu Buddy: Mourning Support Robot   
  Julia Rosén 
  Maurice Lamb 
  Recent advances in large scale language models have significantly changed the landscape of automatic dialogue systems and chatbots. We believe that these models also have a great potential for changing the way we interact with robots. Here, we present the first integration of the OpenAI GPT-3 language model for the Aldebaran Pepper and Nao robots. The present work transforms the text-based API of GPT-3 into an open verbal dialogue with the robots. The system will be presented live during the HRI2023 conference and the source code of this integration is shared with the hope that it will serve the community in designing and evaluating new dialogue systems for robots.  
 Open-source Natural Language Processing on the PAL Robotics ARI Social Robot   
 SESSION: Workshops  
 Workshop YOUR Study Design 2023!: Participatory Critique and Refinement of Participants’ Studies   
 Mayumi Mohan 
  Anouk Neerincx 
  Patricia Alves-Oliveira 
  Naomi T. Fitter 
  A well-designed and evaluated study plays an essential role in highlighting the impact and contribution of a research idea. However, novice Human-Robot Interaction (HRI) researchers often lack the experience and know-how to devise an effective study. This workshop aims to provide a platform for those doing research in HRI, and related fields to obtain expert feedback on their study design before running a user study. The workshop invites a 2-4 page long contribution from participants outlining an upcoming user study focusing on the methods section and planned analyses. Participants will take part in two separate mentoring sessions led by different mentors. The workshop is interactive in nature and will also include mentor-led discussion sessions on topics relevant to study design such as hypothesis design and analysis, and human-centered study design.  
 The Imperfectly Relatable Robot: An Interdisciplinary Workshop on the Role of Failure in HRI   
 Katherine Harrison 
  Giulia Perugia 
  Ana Paiva 
  Amy Loutfi 
  Focusing on failure to improve human-robot interactions represents a novel approach that calls into question human expectations of robots, as well as posing ethical and methodological challenges to researchers. Fictional representations of robots (still for many non-expert users the primary source of expectations and assumptions about robots) often emphasize the ways in which robots surpass/perfect humans, rather than portraying them as fallible. Thus, to encounter robots that come too close, drop items or stop suddenly starts to close the gap between fiction and reality. These kinds of failures – if mitigated by explanation or recovery procedures – have the potential to make the robot a little more relatable and human-like. However studying failures in human-robot interaction requires producing potentially difficult or uncomfortable interactions in which robots failing to behave as expected may seem counterintuitive and unethical. In this space, interdisciplinary conversations are the key to untangling the multiple challenges and bringing themes of power and context into view. In this workshop, we invite researchers from across the disciplines to an interactive, interdisciplinary discussion around failure in social robotics. Topics for discussion include (but are not limited to) methodological and ethical challenges around studying failure in HRI, epistemological gaps in defining and understanding failure in HRI, sociocultural expectations around failure and users’ responses.  
 Social Robots Personalisation: At the Crossroads between Engineering and Humanities (CONCATENATE)   
  Angelo Cangelosi 
  Gordon Cheng 
  Nowadays, robots are expected to interact more physically, cognitively, and socially with people. They should adapt to unpredictable contexts alongside individuals with various behaviours. For this reason personalisation is a valuable attribute for social robots as it allows them to act according to a specific user’s needs and preferences and achieve natural and transparent robot behaviours for humans. If correctly implemented, personalisation could also be the key to the large-scale adoption of social robotics. However achieving personalisation is arduous as it requires us to expand the boundaries of robotics by taking advantage of the expertise of various domains. Indeed, personalised robots need to analyse and model user interactions while considering their involvement in the adaptative process. It also requires us to address ethical and socio-cultural aspects of personalised HRI to achieve inclusive and diverse interaction and avoid deception and misplaced trust when interacting with the users. At the same time, policymakers need to ensure regulations in view of possible short-term and long-term adaptive HRI. This workshop aims to raise an interdisciplinary discussion on personalisation in robotics. It aims at bringing researchers from different fields together to propose guidelines for personalisation while addressing the following questions: how to define it – how to achieve it – and how it should be guided to fit legal and ethical requirements.  
 Human-Robot Conversational Interaction (HRCI)   
  Nima Zargham 
  Minha Lee 
  Conversation is one of the primary methods of interaction between humans and robots. It provides a natural way of communication with the robot, thereby reducing the obstacles that can be faced through other interfaces (e.g., text or touch) that may cause difficulties to certain populations, such as the elderly or those with disabilities, promoting inclusivity in Human-Robot Interaction (HRI). Work in HRI has contributed significantly to the design, understanding and evaluation of human-robot conversational interactions. Concurrently, the Conversational User Interfaces (CUI) community has developed with similar aims, though with a wider focus on conversational interactions across a range of devices and platforms. This workshop aims to bring together the CUI and HRI communities through a one-day workshop to outline key shared opportunities and challenges in developing conversational interactions with robots, resulting in collaborative publications targeted at the CUI 2023 provocations track.  
 CRITTER: Child-Robot Interaction and Interdisciplinary Research   
  Natalia Calvo-Barajas 
  Simone M. de Droog 
  Several recent works in human-robot-interaction (HRI) have begun to highlight the importance of the replication crisis and open science practices for our field. Yet, suggestions and recommendations tailored to child-robot-interaction (CRI) research, which poses it’s own additional set of challenges, remain limited. There is also an increased need within both HRI and CRI for inter and cross-disciplinary collaborations, where input from multiple different domains can contribute to better research outcomes. Consequently, this workshop aims to facilitate discussions between researchers from diverse disciplines within CRI. The workshop will open with a panel discussion between CRI researchers from different disciplines, followed by 3-minute flash talks of the accepted submissions. The second half of the workshop will consist of breakout group discussions, where both senior and junior academics from different disciplines can share their experiences of conducting CRI research. Through this workshop we hope to create a common ground for addressing shared challenges in CRI, as well as identify a set of possible solutions going forward.  
 Lifelong Learning and Personalization in Long-Term Human-Robot Interaction (LEAP-HRI): Adaptivity for All   
 Bahar Irfan 
  Aditi Ramachandran 
  Mariacarla Staffa 
  Hatice Gunes 
  Adaptation and personalization are critical elements when modeling robot behaviors toward users in real-world settings. Multiple aspects of the user need to be taken into consideration in order to personalize the interaction, such as their personality, emotional state, intentions, and actions. While this information can be obtained a priori through self-assessment questionnaires or in real-time during the interaction through user profiling, behaviors and preferences can evolve in long-term interactions. Thus, gradually learning new concepts or skills (i.e., “lifelong learning”) both for the users and the environment is crucial to adapt to new situations and personalize interactions with the aim of maintaining their interest and engagement. In addition, adapting to individual differences autonomously through lifelong learning allows for inclusive interactions with all users with varying capabilities and backgrounds. The third edition of the “Lifelong Learning and Personalization in Long-Term Human-Robot Interaction (LEAP-HRI)” workshop aims to gather and present interdisciplinary insights from a variety of fields, such as education, rehabilitation, elderly care service and companion robots, for lifelong robot learning and adaptation to users, context, environment, and activities in long-term interactions. The workshop aims to promote a common ground among the relevant scientific communities through invited talks and in-depth discussions via paper presentations, break-out groups, and a scientific debate. In line with the HRI 2023 conference theme, “HRI for all”, our workshop theme is “adaptivity for all” to encourage HRI theories, methods, designs, and studies for lifelong learning personalization, and adaptation that aims to promote inclusion and diversity in HRI.  
 Variable Autonomy for Human-Robot Teaming (VAT)   
  Arzu Guneysu 
  Wafa Johal 
  This year’s conference theme “HRI for all” not just raises the importance of reflecting on how to promote inclusion for every type of user but also calls for careful consideration of the different layers of people potentially impacted by such systems. In educational setups, for instance, the users to be considered first and foremost are the learners. However, teachers, school directors, therapists and parents also form a more secondary layer of users in this ecosystem. The 7th edition of R4L focuses on the issues that HRI experiments in educational environments may cause to stakeholders and how we could improve on bringing the stakeholders’ point of view into the loop. This goal is expected to be achieved in a very practical and dynamic way by the means of: (i) lightening talks from the participants; (ii) two discussion panels with special guests: One with active researchers from academia and industry about their experience and point of view regarding the inclusion of stakeholders; another panel with teacher, school directors, and parents that are/were involved in HRI experiments and will share their viewpoint; (iii) semi-structured group discussions and hands-on activities with participants and panellists to evaluate and propose guidelines for good practices regarding how to promote the inclusion of stakeholders, especially teachers, in educational HRI activities. By acquiring the viewpoint from the experimenters and stakeholders and analysing them in the same workshop, we expect to identify current gaps, propose practical solutions to bridge these gaps, and capitalise on existing synergies with the collective intelligence of the two communities.  
 Virtual Augmented, and Mixed Reality for Human-Robot Interaction (VAM-HRI)   
 Maciej Wozniak 
  Christine T. Chang 
  Kim Baraka 
  Sonia Chernova 
  Service robots will be co-located with human users in an unstructured human-centered environment and will benefit from understanding the user’s daily activities, preferences, and needs towards fully assisting them. This workshop aims to explore how abstract semantic knowledge of the user’s environment can be used as a context in understanding and grounding information regarding the user’s instructions, preferences, habits, and needs. While object semantics have primarily been investigated for robotics in the perception and manipulation domain, recent works have shown the benefits of semantic modeling in a Human-Robot Interaction (HRI) context toward understanding and assisting human users. This workshop focuses on semantic information that can be useful in generalizing and interpreting user instructions, modeling user activities, anticipating user needs and making the internal reasoning processes of a robot more interpretable to a user. Therefore, the workshop builds on topics from prior workshops such as Learning in HRI, behavior adaptation for assistance, and learning from humans and aims at facilitating cross-pollination across these domains through a common thread of utilizing abstract semantics of the physical world towards robot autonomy in assistive applications. We envision the workshop to touch on research areas such as unobtrusive learning from observations, preference learning, continual learning, enhancing the transparency of autonomous robot behavior, and user adaptation. The workshop aims to gather researchers working on these areas and provide fruitful discussions towards autonomous assistive robots that can learn and ground scene semantics for enhancing HRI.  
 Workshop on Test Methods and Metrics for Accessible HRI   
 Jeremy Marvel 
  Shelly Bagchi 
  Emmanuel Senft 
  Yue Wang 
  As robots become more ubiquitous in our modern world, the expectation that humans and robots will interact physically, conceptually, and emotionally in everyday life necessitates the development of validated technologies that are safe, secure, and effective. Regardless, robotics is still considered by many as being inaccessible, even as their availability increases. In alignment with the 2023 HRI Conference’s theme of ?HRI for all,” this fifth installment of the Workshop on Test Methods and Metrics for Effective HRI is focused on addressing this accessibility disparity. Specifically, this year’s workshop presents and addresses issues regarding 1) human factors for diverse populations, 2) accessibility of standards and specifications, and 3) enabling equal and equitable access to research results & data. The goal of this workshop is to enable increased accessibility to HRI research and resources by addressing the metrology that is used to verify and validate HRI performance.  
 2nd Workshop on Human-Interactive Robot Learning (HIRL)   
  Berk Calli 
  Aaron Dollar 
  Recent rapid progress in HRI research makes it more crucial than ever to have systematic development and benchmarking methodologies to assess and compare different algorithms and strategies. Indeed, the lack of such methodologies results in inefficiencies and sometimes stagnation, since new methods cannot be effectively compared to prior work and the research gaps become challenging to identify. Moreover, lacking an active and effective mechanism to disseminate and utilize the available datasets and benchmarking protocols significantly reduces their impact and utility. A unified effort in the development, utilization, and dissemination of open-source assets amongst a governed community of users can advance these domains substantially; for HRI this is particularly needed in the curation and generation of datasets for benchmarking. This workshop will take a step towards removing the roadblocks to the development and assessment of HRI by reviewing, discussing and laying the groundwork for an open-source ecosystem at the intersection of HRI and robot manipulation. The workshop will play a crucial role for identifying the preconditions and requirements to develop an open-source ecosystem that provides open-source assets for HRI benchmarking and comparison, aiming to determine the needs and wants of HRI researchers. Invited speakers include those who have contributed to the development of open-source assets in HRI and robot manipulation and discussion topics will include issues related to the usage of open-source assets and the benefits of forming of an open-source ecosystem.  
 Symbiotic Society with Avatars (SSA): Beyond Space and Time   
  Yukiko Nakano 
  Hiroshi Ishiguro 
  Avatar robots can help people extend their physical, cognitive, and perceptual capabilities, allowing people to exceed time and space constraints. In that sense, avatar robots can greatly influence people’s lives. However, we have many challenges to be addressed in various scenarios such as avatar-human interaction operator-avatar interaction, avatar-avatar interaction, ethical and legal issues, technical challenges, and so on. It is indispensable to discuss what the necessary research and technologies are to realize avatars that are well accepted in society while envisioning a future symbiotic society in which people communicate with other people and their avatars. In our previous workshop “Symbiotic Society with Avatars: Social Acceptance Ethics, and Technologies (SSA)” we focused on the ethical aspect of avatars. In this workshop, our aim is to provide an opportunity for researchers from different backgrounds including social robotics, teleoperation and mixed reality to come together and discuss the advances and values in a symbiotic society with avatars.  
 Inclusive HRI II: Equity and Diversity in Design, Application, Methods, and Community   
 Ana Tanevska 
  Shruti Chandra 
  Katie Seaborn 
  Katie Winkle 
  Diversity, equality, and inclusion (DEI) are critical factors that need to be considered when developing AI and robotic technologies for people. The lack of such considerations exacerbates and can also perpetuate existing forms of discrimination and biases in society for years to come. Although concerns have already been voiced around the globe, there is an urgent need to take action within the human-robot interaction (HRI) community. This workshop contributes to filling the gap by providing a platform in which to share experiences and research insights on identifying, addressing, and integrating DEI considerations in HRI. With respect to last year, this year the workshop will further engage participants on the problem of sampling biases through hands-on co-design activities for mitigating inequity and exclusion within the field of HRI.  
 Perspectives on Moral Agency in Human-Robot Interaction   
