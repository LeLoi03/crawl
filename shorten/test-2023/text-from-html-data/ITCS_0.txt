  ISAAC 
  ITC 
  ITCS 
  ITP 
  LDK 
 14th Innovations in Theoretical Computer Science Conference (ITCS 2023)  
  Part of: | Series: | Leibniz International Proceedings in Informatics (LIPIcs) | Part of: | Conference: | Innovations in Theoretical Computer Science Conference (ITCS) 
 Event  
 ITCS 2023, January 10-13, 2023, MIT, Cambridge, Massachusetts, USA   
 Editor  
 Yael Tauman Kalai          
 Publication Details  
 published at: 2023-02-01 
  Publisher: Schloss Dagstuhl ‚Äì Leibniz-Zentrum f√ºr Informatik 
 Authors:  Moshe Babaioff, Nicole Immorlica, Yingkai Li, and Brendan Lucier  
  Abstract    
 A prevalent assumption in auction theory is that the auctioneer has full control over the market and that the allocation she dictates is final. In practice, however, agents might be able to resell acquired items in an aftermarket. A prominent example is the market for carbon emission allowances. These allowances are commonly allocated by the government using uniform-price auctions, and firms can typically trade these allowances among themselves in an aftermarket that may not be fully under the auctioneer‚Äôs control. While the uniform-price auction is approximately efficient in isolation, we show that speculation and resale in aftermarkets might result in a significant welfare loss. Motivated by this issue, we consider three approaches, each ensuring high equilibrium welfare in the combined market. The first approach is to adopt smooth auctions such as discriminatory auctions. This approach is robust to correlated valuations and to participants acquiring information about others' types. However, discriminatory auctions have several downsides, notably that of charging bidders different prices for identical items, resulting in fairness concerns that make the format unpopular. Two other approaches we suggest are either using posted-pricing mechanisms, or using uniform-price auctions with anonymous reserves. We show that when using balanced prices, both these approaches ensure high equilibrium welfare in the combined market. The latter also inherits many of the benefits from uniform-price auctions such as price discovery, and can be introduced with a minor modification to auctions currently in use to sell carbon emission allowances.   
  Cite as    
 Authors:  Ulrich Bauer, Abhishek Rathod, and Meirav Zehavi  
  Abstract    
 Cut problems form one of the most fundamental classes of problems in algorithmic graph theory. In this paper, we initiate the algorithmic study of a high-dimensional cut problem. The problem we study, namely, Homological Hitting Set (HHS), is defined as follows: Given a nontrivial r-cycle z in a simplicial complex, find a set ùíÆ of r-dimensional simplices of minimum cardinality so that ùíÆ meets every cycle homologous to z. Our first result is that HHS admits a polynomial-time solution on triangulations of closed surfaces. Interestingly, the minimal solution is given in terms of the cocycles of the surface. Next, we provide an example of a 2-complex for which the (unique) minimal hitting set is not a cocycle. Furthermore, for general complexes, we show that HHS is W[1]-hard with respect to the solution size p. In contrast, on the positive side, we show that HHS admits an FPT algorithm with respect to p+Œî, where Œî is the maximum degree of the Hasse graph of the complex ùñ™.   
  Cite as    
 Authors:  Paul Beame and Sajin Koroth  
  Abstract    
 Query-to-communication lifting theorems, which connect the query complexity of a Boolean function to the communication complexity of an associated "lifted" function obtained by composing the function with many copies of another function known as a gadget, have been instrumental in resolving many open questions in computational complexity. A number of important complexity questions could be resolved if we could make substantial improvements in the input size required for lifting with the Index function, which is a universal gadget for lifting, from its current near-linear size down to polylogarithmic in the number of inputs N of the original function or, ideally, constant. The near-linear size bound was recently shown by Lovett, Meka, Mertz, Pitassi and Zhang [Shachar Lovett et al., 2022] using a recent breakthrough improvement on the Sunflower Lemma to show that a certain graph associated with an Index function of that size is a disperser. They also stated a conjecture about the Index function that is essential for further improvements in the size required for lifting with Index using current techniques. In this paper we prove the following; - The conjecture of Lovett et al. is false when the size of the Index gadget is less than logarithmic in N. - The same limitation applies to the Inner-Product function. More precisely, the Inner-Product function, which is known to satisfy the disperser property at size O(log N), also does not have this property when its size is less than log N. - Notwithstanding the above, we prove a lifting theorem that applies to Index gadgets of any size at least 4 and yields lower bounds for a restricted class of communication protocols in which one of the players is limited to sending parities of its inputs. - Using a modification of the same idea with improved lifting parameters we derive a strong lifting theorem from decision tree size to parity decision tree size. We use this, in turn, to derive a general lifting theorem in proof complexity from tree-resolution size to tree-like Res(‚äï) refutation size, which yields many new exponential lower bounds on such proofs.   
  Cite as    
 Authors:  Greg Bodwin, Michael Dinitz, and Yasamin Nazari  
  Abstract    
 A t-emulator of a graph G is a graph H that approximates its pairwise shortest path distances up to multiplicative t error. We study fault tolerant t-emulators, under the model recently introduced by Bodwin, Dinitz, and Nazari [ITCS 2022] for vertex failures. In this paper we consider the version for edge failures, and show that they exhibit surprisingly different behavior. In particular, our main result is that, for (2k-1)-emulators with k odd, we can tolerate a polynomial number of edge faults for free. For example: for any n-node input graph, we construct a 5-emulator (k = 3) on O(n^{4/3}) edges that is robust to f = O(n^{2/9}) edge faults. It is well known that Œ©(n^{4/3}) edges are necessary even if the 5-emulator does not need to tolerate any faults. Thus we pay no extra cost in the size to gain this fault tolerance. We leave open the precise range of free fault tolerance for odd k, and whether a similar phenomenon can be proved for even k.   
  Cite as    
 Authors:  Mark Braverman and Dor Minzer  
  Abstract    
 A regular graph G = (V,E) is an (Œµ,Œ≥) small-set expander if for any set of vertices of fractional size at most Œµ, at least Œ≥ of the edges that are adjacent to it go outside. In this paper, we give a unified approach to several known complexity-theoretic results on small-set expanders. In particular, we show: 1) Max-Cut: we show that if a regular graph G = (V,E) is an (Œµ,Œ≥) small-set expander that contains a cut of fractional size at least 1-Œ¥, then one can find in G a cut of fractional size at least 1-O(Œ¥/(ŒµŒ≥‚Å∂)) in polynomial time. 2) Improved spectral partitioning, Cheeger‚Äôs inequality and the parallel repetition theorem over small-set expanders. The general form of each one of these results involves square-root loss that comes from certain rounding procedure, and we show how this can be avoided over small set expanders. Our main idea is to project a high dimensional vector solution into a low-dimensional space while roughly maintaining ùìÅ‚ÇÇ¬≤ distances, and then perform a pre-processing step using low-dimensional geometry and the properties of ùìÅ‚ÇÇ¬≤ distances over it. This pre-processing leverages the small-set expansion property of the graph to transform a vector valued solution to a different vector valued solution with additional structural properties, which give rise to more efficient integral-solution rounding schemes.   
  Cite as    
 Authors:  Sam Buss, Noah Fleming, and Russell Impagliazzo  
  Abstract    
 Connections between proof complexity and circuit complexity have become major tools for obtaining lower bounds in both areas. These connections - which take the form of interpolation theorems and query-to-communication lifting theorems - translate efficient proofs into small circuits, and vice versa, allowing tools from one area to be applied to the other. Recently, the theory of TFNP has emerged as a unifying framework underlying these connections. For many of the proof systems which admit such a connection there is a TFNP problem which characterizes it: the class of problems which are reducible to this TFNP problem via query-efficient reductions is equivalent to the tautologies that can be efficiently proven in the system. Through this, proof complexity has become a major tool for proving separations in black-box TFNP. Similarly, for certain monotone circuit models, the class of functions that it can compute efficiently is equivalent to what can be reduced to a certain TFNP problem in a communication-efficient manner. When a TFNP problem has both a proof and circuit characterization, one can prove an interpolation theorem. Conversely, many lifting theorems can be viewed as relating the communication and query reductions to TFNP problems. This is exciting, as it suggests that TFNP provides a roadmap for the development of further interpolation theorems and lifting theorems. In this paper we begin to develop a more systematic understanding of when these connections to TFNP occur. We give exact conditions under which a proof system or circuit model admits a characterization by a TFNP problem. We show: - Every well-behaved proof system which can prove its own soundness (a reflection principle) is characterized by a TFNP problem. Conversely, every TFNP problem gives rise to a well-behaved proof system which proves its own soundness. - Every well-behaved monotone circuit model which admits a universal family of functions is characterized by a TFNP problem. Conversely, every TFNP problem gives rise to a well-behaved monotone circuit model with a universal problem. As an example, we provide a TFNP characterization of the Polynomial Calculus, answering a question from [Mika G√∂√∂s et al., 2022], and show that it can prove its own soundness.   
  Cite as    
 Authors:  Julia Chuzhoy, Mina Dalirrooyfard, Vadim Grinberg, and Zihan Tan  
  Abstract    
 We propose a new conjecture on hardness of 2-CSP‚Äôs, and show that new hardness of approximation results for Densest k-Subgraph and several other problems, including a graph partitioning problem, and a variation of the Graph Crossing Number problem, follow from this conjecture. The conjecture can be viewed as occupying a middle ground between the d-to-1 conjecture, and hardness results for 2-CSP‚Äôs that can be obtained via standard techniques, such as Parallel Repetition combined with standard 2-prover protocols for the 3SAT problem. We hope that this work will motivate further exploration of hardness of 2-CSP‚Äôs in the regimes arising from the conjecture. We believe that a positive resolution of the conjecture will provide a good starting point for other hardness of approximation proofs. Another contribution of our work is proving that the problems that we consider are roughly equivalent from the approximation perspective. Some of these problems arose in previous work, from which it appeared that they may be related to each other. We formalize this relationship in this work.   
  Cite as    
 Authors:  Natalia Dobrokhotova-Maikova, Alexander Kozachinskiy, and Vladimir Podolskii  
  Abstract    
 In this paper, we address sorting networks that are constructed from comparators of arity k > 2. I.e., in our setting the arity of the comparators - or, in other words, the number of inputs that can be sorted at the unit cost - is a parameter. We study its relationship with two other parameters - n, the number of inputs, and d, the depth. This model received considerable attention. Partly, its motivation is to better understand the structure of sorting networks. In particular, sorting networks with large arity are related to recursive constructions of ordinary sorting networks. Additionally, studies of this model have natural correspondence with a recent line of work on constructing circuits for majority functions from majority gates of lower fan-in. Motivated by these questions, we initiate the studies of lower bounds for constant-depth sorting networks. More precisely, we consider sorting networks of constant depth d and estimate the minimal k for which there is such a network with comparators of arity k. We prove tight lower bounds for d ‚â§ 4. More precisely, for depths d = 1,2 we observe that k = n. For d = 3 we show that k = ‚åàn/2‚åâ. As our main result, we show that for d = 4 the minimal arity becomes sublinear: k = Œò(n^{2/3}). This contrasts with the case of majority circuits, in which k = O(n^{2/3}) is achievable already for depth d = 3. To prove these results, we develop a new combinatorial technique based on the notion of access to cells of a sorting network.   
  Cite as    
 Authors:  Klim Efremenko, Gillat Kol, Dmitry Paramonov, and Raghuvansh R. Saxena  
  Abstract    
 Much of today‚Äôs communication is carried out over large wireless systems with different input-output behaviors. In this work, we compare the power of central abstractions of wireless communication through the general notion of boolean symmetric f-channels: In every round of the f-channel, each of its n parties decides to either broadcast or not, and the channel outputs f(m), where m is the number of broadcasting parties. Our first result is that the well studied beeping channel, where f is the threshold-1 function, is not stronger than any other f-channel. To this end, we design a protocol over the f-channel and prove that any protocol that simulates it over the beeping channel blows up the round complexity by a factor of Œ©(log n). Our lower bound technique may be of independent interest, as it essentially generalizes the popular fooling set technique by exploiting a "local" relaxation of combinatorial rectangles. Curiously, while this result shows the limitations of a noiseless channel, namely, the beeping channel, we are able to use it to show the limitations of the noisy version of many other channels. This includes the extensively studied single-hop radio network model with collisions-as-silence (CAS), which is equivalent to the f-channel with f(m) = 1 iff m = 1. In particular, our second and main result, obtained from the first, shows that converting CAS protocols to noise resilient ones may incur a large performance overhead, i.e., no constant rate interactive code exists. To this end, we design a CAS protocol and prove that any protocol that simulates it over the noisy CAS model with correlated stochastic noise, blows up the round complexity by a factor of Œ©(log n). We mention that the Œ©(log n) overhead in both our results is tight.   
  Cite as    
 Authors:  Antoine El-Hayek, Monika Henzinger, and Stefan Schmid  
  Abstract    
 Data dissemination is a fundamental task in distributed computing. This paper studies broadcast problems in various innovative models where the communication network connecting n processes is dynamic (e.g., due to mobility or failures) and controlled by an adversary. In the first model, the processes transitively communicate their ids in synchronous rounds along a rooted tree given in each round by the adversary whose goal is to maximize the number of rounds until at least one id is known by all processes. Previous research has shown a ‚åà(3n-1)/2‚åâ-2 lower bound and an O(nlog log n) upper bound. We show the first linear upper bound for this problem, namely ‚åà(1+‚àö2) n-1‚åâ ‚âà 2.4n. We extend these results to the setting where the adversary gives in each round k-disjoint forests and their goal is to maximize the number of rounds until there is a set of k ids such that each process knows of at least one of them. We give a ‚åà3(n-k)/2‚åâ-1 lower bound and a (œÄ¬≤+6)/6 n+1 ‚âà 2.6n upper bound for this problem. Finally, we study the setting where the adversary gives in each round a directed graph with k roots and their goal is to maximize the number of rounds until there exist k ids that are known by all processes. We give a ‚åà3(n-3k)/2‚åâ+2 lower bound and a ‚åà(1+‚àö2)n‚åâ+k-1 ‚âà 2.4n+k upper bound for this problem. For the two latter problems no upper or lower bounds were previously known.   
  Cite as    
 Authors:  Arnold Filtser, Michael Kapralov, and Mikhail Makarov  
  Abstract    
 In this paper we initiate the study of expander decompositions of a graph G = (V, E) in the streaming model of computation. The goal is to find a partitioning ùíû of vertices V such that the subgraphs of G induced by the clusters C ‚àà ùíû are good expanders, while the number of intercluster edges is small. Expander decompositions are classically constructed by a recursively applying balanced sparse cuts to the input graph. In this paper we give the first implementation of such a recursive sparsest cut process using small space in the dynamic streaming model. Our main algorithmic tool is a new type of cut sparsifier that we refer to as a power cut sparsifier - it preserves cuts in any given vertex induced subgraph (or, any cluster in a fixed partition of V) to within a (Œ¥, Œµ)-multiplicative/additive error with high probability. The power cut sparsifier uses OÃÉ(n/ŒµŒ¥) space and edges, which we show is asymptotically tight up to polylogarithmic factors in n for constant Œ¥.   
  Cite as    
 Authors:  Roy Gotlib and Tali Kaufman  
  Abstract    
 One of the key components in PCP constructions are agreement tests. In agreement test the tester is given access to subsets of fixed size of some set, each equipped with an assignment. The tester is then tasked with testing whether these local assignments agree with some global assignment over the entire set. One natural generalization of this concept is the case where, instead of a single assignment to each local view, the tester is given access to l different assignments for every subset. The tester is then tasked with testing whether there exist l global functions that agree with all of the assignments of all of the local views. In this work we present sufficient condition for a set system to exhibit this generalized definition of list agreement expansion. This is, to our knowledge, the first work to consider this natural generalization of agreement testing. Despite initially appearing very similar to agreement expansion in definition, proving that a set system exhibits list agreement expansion seem to require a different set of techniques. This is due to the fact that the natural extension of agreement testing (i.e. that there exists a pairing of the lists such that each pair agrees with each other) does not suffice when testing for list agreement as list agreement crucially relies on a global structure. It follows that if a local assignments satisfy list agreement they must not only agree locally but also exhibit some additional structure. In order to test for the existence of this additional structure we use the connection between covering spaces of a high dimensional complex and its coboundaries. Specifically, we use this connection as a form of "decoupling". Moreover, we show that any set system that exhibits list agreement expansion also supports direct sum testing. This is the first scheme for direct sum testing that works regardless of the parity of the sizes of the local sets. Prior to our work the schemes for direct sum testing were based on the parity of the sizes of the local tests.   
  Cite as    
 Authors:  Varun Gupta, Ravishankar Krishnaswamy, Sai Sandeep, and Janani Sundaresan  
  Abstract    
 In this paper we study two fully-dynamic multi-dimensional vector load balancing problems with recourse. The adversary presents a stream of n job insertions and deletions, where each job j is a vector in ‚Ñù^d_{‚â• 0}. In the vector scheduling problem, the algorithm must maintain an assignment of the active jobs to m identical machines to minimize the makespan (maximum load on any dimension on any machine). In the vector bin packing problem, the algorithm must maintain an assignment of active jobs into a number of bins of unit capacity in all dimensions, to minimize the number of bins currently used. In both problems, the goal is to maintain solutions that are competitive against the optimal solution for the active set of jobs, at every time instant. The algorithm is allowed to change the assignment from time to time, with the secondary objective of minimizing the amortized recourse, which is the average cardinality of the change of the assignment per update to the instance. For the vector scheduling problem, we present two simple algorithms. The first is a randomized algorithm with an O(1) amortized recourse and an O(log d/log log d) competitive ratio against oblivious adversaries. The second algorithm is a deterministic algorithm that is competitive against adaptive adversaries but with a slightly higher competitive ratio of O(log d) and a per-job recourse guarantee bounded by OÃÉ(log n + log d log OPT). We also prove a sharper instance-dependent recourse guarantee for the deterministic algorithm. For the vector bin packing problem, we make the so-called small jobs assumption that the size of all jobs in all the coordinates is O(1/log d) and present a simple O(1)-competitive algorithm with O(log n) recourse against oblivious adversaries. For both problems, the main challenge is to determine when and how to migrate jobs to maintain competitive solutions. Our central idea is that for each job, we make these decisions based only on the active set of jobs that are "earlier" than this job in some ordering ‚â∫ of the jobs.   
  Cite as    
 Authors:  Prahladh Harsha, Daniel Mitropolsky, and Alon Rosen  
  Abstract    
 A problem is downward self-reducible if it can be solved efficiently given an oracle that returns solutions for strictly smaller instances. In the decisional landscape, downward self-reducibility is well studied and it is known that all downward self-reducible problems are in PSPACE. In this paper, we initiate the study of downward self-reducible search problems which are guaranteed to have a solution - that is, the downward self-reducible problems in TFNP. We show that most natural PLS-complete problems are downward self-reducible and any downward self-reducible problem in TFNP is contained in PLS. Furthermore, if the downward self-reducible problem is in TFUP (i.e. it has a unique solution), then it is actually contained in UEOPL, a subclass of CLS. This implies that if integer factoring is downward self-reducible then it is in fact in UEOPL, suggesting that no efficient factoring algorithm exists using the factorization of smaller numbers.   
  Cite as    
 Authors:  William He and Benjamin Rossman  
  Abstract    
 We study the formula complexity of the word problem Word_{S_n,k} : {0,1}^{kn¬≤} ‚Üí {0,1}: given n-by-n permutation matrices M‚ÇÅ,‚Ä¶ ,M_k, compute the (1,1)-entry of the matrix product M‚ÇÅ‚ãØ M_k. An important feature of this function is that it is invariant under action of S_n^{k-1} given by (œÄ‚ÇÅ,‚Ä¶ ,œÄ_{k-1})(M‚ÇÅ,‚Ä¶ ,M_k) = (M‚ÇÅœÄ‚ÇÅ^{-1},œÄ‚ÇÅM‚ÇÇœÄ‚ÇÇ^{-1},‚Ä¶ ,œÄ_{k-2}M_{k-1}œÄ_{k-1}^{-1},œÄ_{k-1}M_k). This symmetry is also exhibited in the smallest known unbounded fan-in {and,or,not}-formulas for Word_{S_n,k}, which have size n^O(log k). In this paper we prove a matching n^{Œ©(log k)} lower bound for S_n^{k-1}-invariant formulas computing Word_{S_n,k}. This result is motivated by the fact that a similar lower bound for unrestricted (non-invariant) formulas would separate complexity classes NC¬π and Logspace. Our more general main theorem gives a nearly tight n^d(k^{1/d}-1) lower bound on the G^{k-1}-invariant depth-d {maj,and,or,not}-formula size of Word_{G,k} for any finite simple group G whose minimum permutation representation has degree n. We also give nearly tight lower bounds on the G^{k-1}-invariant depth-d {and,or,not}-formula size in the case where G is an abelian group.   
  Cite as    
 Authors:  Yael Hitron, Merav Parter, and Eylon Yogev  
  Abstract    
 We present a new algorithmic framework for distributed network optimization in the presence of eavesdropper adversaries, also known as passive wiretappers. In this setting, the adversary is listening to the traffic exchanged over a fixed set of edges in the graph, trying to extract information on the private input and output of the vertices. A distributed algorithm is denoted as f-secure, if it guarantees that the adversary learns nothing on the input and output for the vertices, provided that it controls at most f graph edges. Recent work has presented general simulation results for f-secure algorithms, with a round overhead of D^Œò(f), where D is the diameter of the graph. In this paper, we present a completely different white-box, and yet quite general, approach for obtaining f-secure algorithms for fundamental network optimization tasks. Specifically, for n-vertex D-diameter graphs with (unweighted) edge-connectivity Œ©(f), there are f-secure congest algorithms for computing MST, partwise aggregation, and (1+Œµ) (weighted) minimum cut approximation, within OÃÉ(D+f ‚àön) congest rounds, hence nearly tight for f = OÃÉ(1). Our algorithms are based on designing a secure algorithmic-toolkit that leverages the special structure of congest algorithms for global optimization graph problems. One of these tools is a general secure compiler that simulates light-weight distributed algorithms in a congestion-sensitive manner. We believe that these tools set the ground for designing additional secure solutions in the congest model and beyond.   
  Cite as    
 Authors:  Uri Meir, Rotem Oshman, Ofer Shayevitz, and Yuval Volkov  
  Abstract    
 In recent years there has been great interest in networks of passive, computationally-weak nodes, whose interactions are controlled by the outside environment; examples include population protocols, chemical reactions networks (CRNs), DNA computing, and more. Such networks are usually studied under one of two extreme regimes: the schedule of interactions is either assumed to be adversarial, or it is assumed to be chosen uniformly at random. In this paper we study an intermediate regime, where the interaction at each step is chosen from some not-necessarily-uniform distribution: we introduce the definition of a (p,Œµ)-scheduler, where the distribution that the scheduler chooses at every round can be arbitrary, but it must have ùìÅ_p-distance at most Œµ from the uniform distribution. We ask how far from uniform we can get before the dynamics of the model break down. For simplicity, we focus on the 3-majority dynamics, a type of chemical reaction network where the nodes of the network interact in triplets. Each node initially has an opinion of either ùñ∑ or ùñ∏, and when a triplet of nodes interact, all three nodes change their opinion to the majority of their three opinions. It is known that under a uniformly random scheduler, if we have an initial gap of Œ©(‚àö{n log n}) in favor of one value, then w.h.p. all nodes converge to the majority value within O(n log n) steps. For the 3-majority dynamics, we prove that among all non-uniform schedulers with a given ùìÅ_1- or ùìÅ_‚àû-distance to the uniform scheduler, the worst case is a scheduler that creates a partition in the network, disconnecting some nodes from the rest: under any (p,Œµ)-close scheduler, if the scheduler‚Äôs distance from uniform only suffices to disconnect a set of size at most S nodes and we start from a configuration with a gap of Œ©(S+‚àö{n log n}) in favor of one value, then we are guaranteed that all but O(S) nodes will convert to the majority value. We also show that creating a partition is not necessary to cause the system to converge to the wrong value, or to fail to converge at all. We believe that our work can serve as a first step towards understanding the resilience of chemical reaction networks and population protocols under non-uniform schedulers.   
  Cite as    
 Authors:  Tomoyuki Morimae and Takashi Yamakawa  
  Abstract    
 Assume that Alice can do only classical probabilistic polynomial-time computing while Bob can do quantum polynomial-time computing. Alice and Bob communicate over only classical channels, and finally Bob gets a state |x‚ÇÄ‚ü©+|x‚ÇÅ‚ü© with some bit strings x‚ÇÄ and x‚ÇÅ. Is it possible that Alice can know {x‚ÇÄ,x‚ÇÅ} but Bob cannot? Such a task, called remote state preparations, is indeed possible under some complexity assumptions, and is bases of many quantum cryptographic primitives such as proofs of quantumness, (classical-client) blind quantum computing, (classical) verifications of quantum computing, and quantum money. A typical technique to realize remote state preparations is to use 2-to-1 trapdoor collision resistant hash functions: Alice sends a 2-to-1 trapdoor collision resistant hash function f to Bob, and Bob evaluates it coherently, i.e., Bob generates ‚àë_x|x‚ü©|f(x)‚ü©. Bob measures the second register to get the measurement result y, and sends y to Alice. Bob‚Äôs post-measurement state is |x‚ÇÄ‚ü©+|x‚ÇÅ‚ü©, where f(x‚ÇÄ) = f(x‚ÇÅ) = y. With the trapdoor, Alice can learn {x‚ÇÄ,x‚ÇÅ} from y, but due to the collision resistance, Bob cannot. This Alice‚Äôs advantage can be leveraged to realize the quantum cryptographic primitives listed above. It seems that the collision resistance is essential here. In this paper, surprisingly, we show that the collision resistance is not necessary for a restricted case: we show that (non-verifiable) remote state preparations of |x‚ÇÄ‚ü©+|x‚ÇÅ‚ü© secure against classical probabilistic polynomial-time Bob can be constructed from classically-secure (full-domain) trapdoor permutations. Trapdoor permutations are not likely to imply the collision resistance, because black-box reductions from collision-resistant hash functions to trapdoor permutations are known to be impossible. As an application of our result, we construct proofs of quantumness from classically-secure (full-domain) trapdoor permutations.   
  Cite as    
  TGDK ‚Äì Transactions on Graph Data and Knowledge 
 ¬© 2023-2024 Schloss Dagstuhl ‚Äì LZI GmbH  Imprint  Privacy  Contact