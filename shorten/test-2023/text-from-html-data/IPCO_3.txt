 This book constitutes the refereed proceedings of the 24th International Conference on Artificial Intelligence in Educat  
 Author / Uploaded 
  Alberto Del Pia 
  Volker Kaibel 
  From Approximate to Exact Integer Programming  
  1 Introduction  
  1.1 Contributions of This Paper  
  1.2 Related Work  
  2 Preliminaries  
  1.1 Group-Constrained Problems and Proof Strategy for Theorem 1  
  1.2 Further Related Work  
  1.3 Structure of the Paper  
  2 GCTUF with Transposed Network Constraint Matrices  
  3 Overview of Our Techniques Leading to Theorem 3  
  5 The Subspace of Linearizable Instances  
  References  
  Author Index   
 Citation preview   
  Alberto Del Pia ¬∑ Volker Kaibel (Eds.)  
  Integer Programming and Combinatorial Optimization 24th International Conference, IPCO 2023 Madison, WI, USA, June 21‚Äì23, 2023 Proceedings  
  Lecture Notes in Computer Science Founding Editors Gerhard Goos Juris Hartmanis  
  Alberto Del Pia ¬∑ Volker Kaibel Editors  
  Integer Programming and Combinatorial Optimization 24th International Conference, IPCO 2023 Madison, WI, USA, June 21‚Äì23, 2023 Proceedings  
  Editors Alberto Del Pia University of Wisconsin-Madison Madison, WI, USA  
  Preface  
  the Office of Naval Research, FICO, Google, Gurobi Optimization, and The Optimization Firm. March 2023  
  Alberto Del Pia Volker Kaibel  
  A. Basu et al.  
  A point in S((f, C), Œµ) will be called an Œµ-approximate solution and points in C ‚à© dom(f ) ‚à© (Zn √ó Rd ) will be called feasible solutions. We say that x1 , . . . , xn are the integer-valued decision variables or simply the integer variables of the problem, and y1 , . . . , yd are called the continuous variables. The notion of information complexity (a.k.a oracle complexity or analytical complexity) goes back to foundational work by Nemirovski and Yudin [8] on convex optimization (without integer variables) and is based on the following. An algorithm for reporting an Œµ-approximate solution to an instance (f, C) must be ‚Äúgiven‚Äù the instance somehow. Allowing only instances with explicit, algebraic descriptions (e.g., the case of linear programming) can be restrictive. To work with more general, nonlinear instances, the algorithm is allowed to make queries to an oracle to collect information about the instance. The standard oracle that has been studied over the past several decades is the so-called Ô¨Årst-order oracle, which consists of two parts: i) a separation oracle that receives a point z ‚àà Rn+d and reports ‚ÄúYES‚Äù if z ‚àà C and otherwise reports a separating hyperplane for z and C, ii) a subgradient oracle that receives a point z ‚àà Rn+d and reports f (z) and a subgradient for f at z. The goal is to design a query strategy that can report an Œµ-approximate solution after making the smallest number of queries. Tight lower and upper bounds (diÔ¨Äering by only a small constant factor) on the number of queries were obtained by Nemirovski and Yudin in their seminal work  case with no integer variables); roughly speaking, the bound is  [8] (the Œò d log 1Œµ . These insights were extended to the mixed-integer setting in [2,3, 9], with the best known lower and upper bounds stated in [2]. Observe that the response to any separation/subgradient query is a vector in Rn+d . Thus, each query reveals at least n+d bits of information about the instance. A more careful accounting that measures the ‚Äúamount of information‚Äù accrued would track the total number of bits obtained as opposed to just the total number of oracle queries made. A natural question, posed in [2], is whether the bounds from the classical analysis would change if one uses this new measure of the total number of bits, as opposed to the number  of queries. The intuition, roughly, is that one should need a factor (n + d) log 1Œµ larger than   the number of Ô¨Årst-order queries, because one should need to probe at least log 1Œµ bits in n+d coordinates to recover the full subgradient/separating hyperplane (up to desired approximations). We attempt to make some progress on this question in this paper. The above discussion suggests that one should consider oracles that return a desired bit of a desired coordinate of the separating hyperplane vector or subgradient. However, one can imagine making other binary queries on the instance; for example, one can pick a direction and ask for the sign of the inner product of the subgradient and this direction. In fact, one can consider more general binary queries that have nothing to do with subgradients/separating hyperplanes. If one allows all possible binary queries, i.e., one can use any function from the space of instances to {0, 1} as a query, then one can simply ask for the appropriate bits of the true minimizer and in O((n + d) log(1/Œµ)) queries, one can get an Œµ-approximate solution. A matching lower bound follows from a fairly straightforward counting argument. Thus, allowing for all possible binary queries gives the same information complexity bound as the original Nemirovski-Yudin bound  
  Information Complexity of Mixed-Integer Convex Optimization  
  3  
  with subgradient queries in the n = 0 (no integer variables) case, but is an exponential improvement when n ‚â• 1 (see [2] and the discussion below). What this shows is that the bounds on information complexity can be quite diÔ¨Äerent under diÔ¨Äerent oracles. With all possible binary queries, while each query reveals only a single bit of information, the queries themselves are a much richer class and this compensates to give the same bound in the continuous case and exponentially better bounds in the presence of integer variables. Thus, to get a better understanding of this trade-oÔ¨Ä, we restrict to queries that still extract information from the subgradient or separating hyperplane at a point, and are thus ‚Äúlocal‚Äù in a sense. (In,d,R,œÅ,M is the set of instances we focus on throughout the paper, see DeÔ¨Ånition 2 for a formal deÔ¨Ånition.) Definition 1. An oracle using Ô¨Årst-order information consists of two parts: 1. For every z ‚àà [‚àíR, R]n+d , there exist two maps gzsep : In,d,R,œÅ,M ‚Üí Rn+d and gzsub : In,d,R,œÅ,M ‚Üí R √ó Rn+d such that for all (f, C) ‚àà In,d,R,œÅ,M the following properties hold. (a) C ‚äÜ {z ‚àà Rn+d : gzsep (C), z < gzsep (C), z } if z ‚àà C and gzsep (C) = 0 if z ‚àà C. In other words, gzsub (f ) returns a (normal vector to a) separating hyperplane if z ‚àà C. We will assume that a nonzero response gzsep (C) has norm 1, since scalings do not change the separation property. (b) gzsub (f ) ‚àà {f (z)} √ó ‚àÇf (z), where ‚àÇf (z) denotes the subdiÔ¨Äerential (the set of all subgradients) of f at z. In other words, gzsub (f ) returns the function value and a subgradient for f at z. If f (z) = +‚àû, gzsub (f ) returns a separating hyperplane for z and the domain of f .1 Such maps will be called Ô¨Årst-order maps. A collection of Ô¨Årst-order maps, one for every z, is called a (complete) Ô¨Årst-order chart and will be denoted by G. 2. There are two sets of functions Hsep and Hsub with domains Rn+d and R √ó Rn+d respectively. We will use the notation H = Hsep ‚à™ Hsub . H will be called the collection of permissible queries of the oracle. The algorithm, at any iteration, can choose a point z and a function h ‚àà H  and it receives the response h(gzsep (f)) or h(gzsub (C)), depending on whether sep sub   or h ‚àà H , where (f , C) is the unknown instance. h‚ààH In particular, when Hsep and Hsub consist only of the identity function, we recover a standard Ô¨Årst-order oracle. We will also study the cases where Hsep and Hsub consist of functions that map a vector to a particular bit of a particular coordinate, or the sign of the inner product with a particular direction, or the set of all possible binary functions. In the last case, the oracle will be called the general binary oracle based on G.  
  1  
  Our Results  
  It is not hard to see that if we consider all possible instances of (1), then any adaptive query strategy has inÔ¨Ånite information complexity because a Ô¨Ånite number of queries cannot distinguish between all possible instances. Thus, bounds on the information complexity must be based on appropriate parameterizations of the problem. We will focus on the following standard parameterization. Definition 2. In,d,R,œÅ,M is the set of all instances of (1) such that (i) C ‚à© dom(f ) is contained in the box {z ‚àà Rn √ó Rd : z‚àû ‚â§ R}. ÀÜ ‚àà Rd (ii) If (x , y ) is an optimal solution of the instance, then there exists y  ÀÜ ‚àû ‚â§ œÅ} ‚äÜ C. In other words, there is a ‚Äústrictly satisfying {(x , y) : y ‚àí y ÀÜ ) in the same Ô¨Åber as the optimum (x , y ). feasible‚Äù point (x , y (iii) f is Lipschitz continuous with respect to the  ¬∑ ‚àû -norm with Lipschitz constant M on {x} √ó [‚àíR, R]d for all x ‚àà [‚àíR, R]n ‚à© Zn , where we use the convention that if f is identically +‚àû on {x}√ó[‚àíR, R]d , then any M works on this Ô¨Åber. In other words, for any (x, y), (x, y ) ‚àà (Zn √óRd )‚à©[‚àíR, R]n+d with y ‚àíy ‚àû ‚â§ R, |f (x, y)‚àíf (x, y )| ‚â§ M y ‚àíy ‚àû with the convention that ‚àû ‚àí ‚àû = 0. We obtain the following results in this paper. Results for n ‚â• 1 (allowing integer variables). 1. In the classical setting where Hsep and Hsub consist only of the identity function (i.e. each query receives the entire subgradient/separating hyperplane), we improve the best known lower bound (from [2]) on the number of queries needed for the general mixed-integer case. In particular, we show that one   MR n queries, improving upon the previous needs at least Œ© 2 d log min{œÅ,1}Œµ    R bound of Œ© 2n d log œÅ . We mention here that the Ô¨Årst lower bound on information complexity with integer constrained variables was established in [3], for a speciÔ¨Åc class of algorithms/query strategies called cutting-plane schemes. The lower bounds stated here (and in [2]) do not make any assumptions on the algorithms/query strategies.    MR n for the classical setting is com2. This lower bound of Œ© 2 d log min{œÅ,1}Œµ    MR in the litplemented by an upper bound of O 2n d(n + d) log min{œÅ,1}Œµ erature. This was Ô¨Årst obtained in [9]; see [2] for a self-contained exposition. As mentioned before, we expect the information complexity in the setting of binary  oracles using Ô¨Årst-order information to be at most a factor MR larger than the classical setting. We rigorously prove (n + d) log min{œÅ,1}Œµ this, under the additional assumption that the Ô¨Åber containing the optimal solution contains a point that is œÅ-deep inside the feasible region C, i.e., a ball of radius œÅ centered at this point is contained in the set C. Note that this is a stronger assumption compared to item (ii) in the deÔ¨Ånition of In,d,R,œÅ,M .  
  Information Complexity of Mixed-Integer Convex Optimization  
  Discussion and Future Avenues  
  The concept of information complexity in continuous convex optimization and its study go back several decades, and it is considered a fundamental question in convex optimization. In comparison, much less work on information complexity has been carried out in the presence of integer constrained variables. Nevertheless, we believe there are important and challenging questions that come up in that domain that are worth studying. Further, even within the context of continuous convex optimization, the notion of information complexity has almost exclusively focused on the number of Ô¨Årst-order queries. As we hope to illustrate with the results of this paper, considering other kinds of oracles lead to very interesting questions at the intersection of mathematical optimization and information theory. In particular, the study of binary oracles promises to give a more reÔ¨Åned understanding of the fundamental question ‚ÄúHow much information about an optimization instance do we need to be able to solve it with provable guarantees?‚Äù. For instance, establishing any superlinear (in the dimension) lower bound for the continuous problem with binary oracles, like the one in Theorem 3, seems to be nontrivial. In fact, the results from [6], on which Theorem 3 is based, were considered a breakthrough in establishing superlinear lower bounds on space complexity of convex optimization. Even so, the right bound is conjectured to be quadratic in the dimension (see Theorem 4) and our Theorem 3 is far from that at this point. We thus view the results of this paper as expanding our understanding of information complexity of optimization in two diÔ¨Äerent dimensions: what role does the presence of integer variables play and what role does the nature of the oracle play (with or without integer variables)? For integer variables, our Ô¨Årst result brings the lower bound closer to the best  
  8  
  A. Basu et al.  
  known upper bound on information complexity based on the classical subgradient oracle. The remaining gap is now simply a factor linear in the dimension. A conjecture in convex geometry Ô¨Årst articulated in [9, Conjecture 4.1.20] and elaborated upon in [2,3] would resolve this and would show that the right upper bound is essentially equal to the lower bound we prove in this paper. Therefore, we have reasons to believe that the right bound is the one we obtain in this paper. Beyond this, we believe the following additional conjectures to be good catalysts for future research, especially in regard to understanding the interplay of integer variables and other oracles. Conjecture 1. Given an oracle (G, H) based on Ô¨Årst-order information, suppose there is a family of instances that establishes a lower bound (d, R, œÅ, M, G, H) for the n = 0 (continuous) case. Then there exists a family of instances that establishes a lower bound of 2n ¬∑ (d, R, œÅ, M, G, H) for the n ‚â• 1 case, i.e., the general mixed-integer case. Conjecture 2. If there exists a query strategy with worst case information complexity u(n, d, R, œÅ, M, G) under the standard Ô¨Årst-order oracle based on a complete Ô¨Årst-order chart G, then there existsa query strategy with  worst case infor under the general mation complexity u(n, d, R, œÅ, M, G) ¬∑ O (n + d) log MœÅŒµR binary oracle based G. Both of the above results, if true, would be useful ‚Äútransfer‚Äù theorems: the Ô¨Årst one for lower bounds, the second one for upper bounds. Conjecture 1 takes a lower bound result for the continuous problem and lifts it to the general mixedinteger case with a factor of 2n . This would be a general tool that can then give Theorem 1 as a special case and also give a mixed-integer version of Theorem 3 as a corollary. Further, if future research on the information complexity of continuous convex optimization results in better/diÔ¨Äerent lower bounds, these would immediately imply new lower bounds for the mixed-integer case as well. For instance, we believe the following conjecture to be true for the continuous convex optimization problem. Conjecture 3. There exists a complete Ô¨Årst-order chart G such that the general 2    . binary oracle based on G has information complexity Œ© d2 log MœÅŒµR Another version of Conjecture 3 is also stated in the language of ‚Äúmemoryconstrained‚Äù algorithms (see Sect. 2.2 below) in [6,11]. Conjecture 2 can be used to take upper bound results proved in the standard Ô¨Årst-order oracle setting and get upper bound results in the general binary oracle setting. For instance, if the upper bound for the general mixed-integer problem is improved by resolving the convex geometry conjecture mentioned above (and we believe the lower bound is correct and the upper bound is indeed loose), then this would also give better upper bounds for the general binary oracle setting.  
  Information Complexity of Mixed-Integer Convex Optimization  
  Proof of Theorem 3  
  We need to introduce the idea of information memory of any query strategy/algorithm. Definition 4. A Ô¨Årst-order query strategy with information memory comprises three functions: 1. œÜquery : {0, 1}‚àó ‚Üí [‚àíR, R]n √ó [‚àíR, R]d . n d ‚àó ‚àó 2. œÜsep update : (R √ó R ) √ó {0, 1} ‚Üí {0, 1} . sub n d ‚àó 3. œÜupdate : (R √ó (R √ó R )) √ó {0, 1} ‚Üí {0, 1}‚àó . Given access to a (complete) Ô¨Årst-order chart G, the query strategy maintains an information memory, which is a Ô¨Ånite length binary string in {0, 1}‚àó , initialized as the empty string. At every iteration k = 1, 2, . . ., the query œÜquery (rk‚àí1 ) andupdates its memory using either strategy computes zk :=    sep sep sep  sub   is the gz (C), rk‚àí1 or rk = œÜ gz (f ), rk‚àí1 , where (f, C) rk = œÜ update  
  k  
  Zuse Institute Berlin, Berlin, Germany {bestuzheva,gleixner}@zib.de 2 HTW Berlin, Berlin, Germany Gurobi GmbH, Frankfurt am Main, Germany [email protected]   
  Abstract. The reformulation-linearization technique (RLT) is a prominent approach to constructing tight linear relaxations of non-convex continuous and mixed-integer optimization problems. The goal of this paper is to extend the applicability and improve the performance of RLT for bilinear product relations. First, a method for detecting bilinear product relations implicitly contained in mixed-integer linear programs is developed based on analyzing linear constraints with binary variables, thus enabling the application of bilinear RLT to a new class of problems. Our second contribution addresses the high computational cost of RLT cut separation, which presents one of the major diÔ¨Éculties in applying RLT eÔ¨Éciently in practice. We propose a new RLT cutting plane separation algorithm which identiÔ¨Åes combinations of linear constraints and bound factors that are expected to yield an inequality that is violated by the current relaxation solution. A detailed computational study based on implementations in two solvers evaluates the performance impact of the proposed methods. Keywords: Reformulation-linearization technique ¬∑ Bilinear products ¬∑ Cutting planes ¬∑ Mixed-integer programming  
  1  
  15  
  relaxations can be constructed, which were shown to converge to the convex hull representation of MILPs and mixed-integer polynomial problems where continuous variables appear linearly [18‚Äì20]. RLT has been shown to provide strong relaxations [21,23], but this comes at the cost of excessive numbers of cuts. To address this, Sherali and Tuncbilek [25] proposed a technique to add a subset of RLT cuts, depending on signs of coefÔ¨Åcients of monomial terms in the original constraints and the RLT constraints. Furthermore, the reduced RLT technique [12‚Äì14,22] yields equivalent representations with fewer nonlinear terms for polynomial problems containing linear equality constraints. We focus on RLT for bilinear products, which is of particular interest due to the numerous applications whose models involve nonconvex quadratic nonlinearities [3,5,7‚Äì9,17]. Even in the bilinear case, large numbers of factors to be multiplied and of RLT cuts that are generated as a result remain an issue that can lead to considerable slowdowns, both due to the cost of cut separation and the large sizes of resulting LP relaxations. The Ô¨Årst contribution of this paper is a new approach to applying RLT to MILPs. Unlike the approaches that only introduce multilinear relations via multiplication [18,19], this approach detects and enforces bilinear relations that are already implicitly present in the model. A bilinear product relation where one multiplier is a binary variable and the other multiplier is a variable with Ô¨Ånite bounds can be equivalently written as two linear constraints. We identify such pairs of linear constraints that implicitly encode a bilinear product relation, then utilize this relation in the generation of RLT cuts. The second contribution of this paper addresses the major bottleneck for applying RLT successfully in practice, which stems from prohibitive costs of separating RLT cuts, by proposing an eÔ¨Écient separation algorithm. This algorithm considers the signs of bilinear relation violations in a current LP relaxation solution and the signs of coeÔ¨Écients in linear constraints in order to ignore combinations of factors that will not produce a violated inequality. Furthermore, we propose a technique which projects the linear constraints onto a reduced space and constructs RLT cuts based on the resulting much smaller system. The rest of the paper is organized as follows. In Sect. 2, RLT for bilinear products is explained. In Sect. 3, we describe the technique for deriving bilinear product relations from MILP constraints. Section 4 presents the new cut separation algorithm, and computational results are presented in Sect. 5.  
  2  
  17  
  The key step is the replacing of products xk xj with the variables wkj . When a bilinear product relation xk xj ƒ≥ wkj does not hold for the current relaxation solution, this substitution may lead to an increase in the violation of the inequality, thus possibly producing a cut that is violated by the relaxation solution. n In the case that we have a linear equation constraint k‚Äú1 a1k xk ‚Äú b1 and all nonlinear terms can be replaced using equality relations, then RLT produces an n the equation constraint is treated as two inequalities nequation cut. Otherwise, a x ƒè b and 1 k‚Äú1 1k k k‚Äú1 a1k xk ƒõ b1 to produce inequality cuts.  
  3  
  (8)  
  The ith nonlinear term is ari xi xj , where ari ‚Äú ari when multiplying by (xj ¬¥ xj ) and ari ‚Äú ¬¥ari when multiplying by (xj ¬¥ xj ). Following the procedure described in Sect. 2, RLT may replace the product xi xj with wij . The product can also be replaced with a linear expression, but this does not change the reasoning, and we will only use wij in this section. ‚àó ‚Ä∞ x‚àói x‚àój , then such a replacement will change the violation of (8). The If wij terms whose replacement will increase the violation are of interest, that is, the terms where: ‚àó . ari x‚àói x‚àój ƒè ari wij This determines the choice of bound factors to multiply with: ‚àó x‚àói x‚àój ƒÉ wij ‚áí  
  multiply by (xj ¬¥ xj ) if ari ƒÖ 0, multiply by (xj ¬¥ xj ) if ari ƒÉ 0,  
  kPJ 2  
  the only nonlinear terms are xj xk with k P J 1 , and therefore, no substitution xi xk ‚Üí wik is performed for k P J 2 . If the McCormick inequalities for xi , xk and ‚àó for k P J 2 , and checking the violation of a projected wik hold, then x‚àói x‚àók ‚Äú wik RLT cut is equivalent to checking the violation of a full RLT cut. Depending on the solver, McCormick inequalities may not be satisÔ¨Åed at ‚àó for some k P J 2 , but these vio(x‚àó , w‚àó ). Thus, it is possible that x‚àói x‚àók ‚Ä∞ wik lations will not contribute to the violation of the projected RLT cut. In this case, projection Ô¨Åltering has an additional eÔ¨Äect: for violated bilinear products involving variables whose values in x‚àó are at bound, the violation of the product will be disregarded when checking the violation of RLT cuts. Thus, adding McCormick cuts will be prioritized over adding RLT cuts.  
  5  
  Projection Ô¨Åltering has a minor impact on performance. When comparing the runs where projection Ô¨Åltering is disabled and enabled, the relative diÔ¨Äerence in time and nodes does not exceed 1% on both MILP and MINLP instances, except for aÔ¨Äected MILP instances where projection Ô¨Åltering decreases the number of nodes by 4%. This is possibly occurring due to the eÔ¨Äect of prioritizing McCormick inequalities to RLT cuts when enforcing derived product relations. The number of solved instances remains almost unchanged, with one less instance being solved on both MILP and MINLP test sets when projection Ô¨Åltering is enabled.  
  26  
  Introduction  
  Many important problems in theoretical computer science are fundamentally search problems. The objective of these problems is to Ô¨Ånd a certain solution from the search space. In this paper we analyze a search problem that we call explorable heap selection. The problem is related to the famous branch-andbound algorithm and was originally proposed by Karp, Widgerson and Saks [13] to model node selection for branch-and-bound with low space-complexity. Furthermore, as we will explain later, the problem remains practically relevant to branch-and-bound even in the full space setting.  
  S. Borst et al.  
  The explorable heap selection problem1 is an online graph exploration problem for an agent on a rooted (possibly inÔ¨Ånite) binary tree. The nodes of the tree are labeled by distinct real numbers (the key values) that increase along every path starting from the root. The tree can thus be thought of as a min-heap. Starting at the root, the agent‚Äôs objective is to select the nth smallest value in the tree while minimizing the distance traveled, where each edge of the tree has unit travel cost. The key value of a node is only revealed when the agent visits it, and the problem thus has an online nature. When the agent learns the key value of a node, it still does not know the rank of this value. A simple selection strategy is to use the best-Ô¨Årst rule, which repeatedly explores the unexplored node whose parent has the smallest key value. While this rule is optimal in terms of the number of nodes that it explores, namely Œò(n), the distance traveled by the agent can be far from optimal. In the worstcase, an agent using this rule will need to travel a distance of Œò(n2 ) to Ô¨Ånd the nth smallest value. A simple bad example for this rule is to consider a rooted tree consisting of two paths (which one can extend to a binary tree), where the two paths are consecutively labeled by all positive even and odd integers respectively. Improving on the best-Ô¨Årst strategy, Karp, Saksand Wigderson [13]  gave a randomized algorithm with expected cost n¬∑exp(O( log(n))) using O( log(n)) working space. They also showed how to make the algorithm deterministic using O(log(n)2.5 ) space. In this work, our main contribution is an improved randomized algorithm with expected cost O(n log(n)3 ) using O(log(n)) space. Given the Œ©(n) lower bound, our travel cost is optimal up to logarithmic factors. Furthermore we show that any algorithm for explorable heap selection that only uses s units of memory, must take at least n ¬∑ logs (n) time in expectation. An interesting open problem is the question whether a superlinear lower bound also holds without any restriction on the memory usage. To clarify the memory model, it is assumed that any key value and O(log n) bit integer can be stored using O(1) space. We also assume that maintaining the current position in the tree does not take up memory. Furthermore, we assume that key value comparisons and moving across an edge of the tree require O(1) time. Under these assumptions, the running times of the above algorithms are in fact proportional to their travel cost. Throughout the paper, we will thus use travel cost and running time interchangeably. Motivation. The motivation to look at this problem comes from the branchand-bound algorithm. This is a well-known algorithm that can be used for solving many types of problems. In particular, it is often used to solve integer linear programs (ILP), which are of the form arg min{c x : x ‚àà Zn , Ax ‚â§ b}. In that setting, branch-and-bound works by Ô¨Årst solving the linear programming (LP) relaxation, which does not have integrality constraints. The value of the solution to the relaxation forms a lower bound on the objective value of the original problem. Moreover, if this solution only has integral components, it is also optimal for the original problem. Otherwise, the algorithm chooses a ÀÜi is not integral. It then creates two component xi for which the solution value x xi  or xi ‚â• ÀÜ xi . This new subproblems, by either adding the constraint xi ‚â§ ÀÜ 1  
  [13] did not name the problem, so we have given a descriptive name here.  
  at a vertex v ‚àà V and may decide to move to either the left child, the right child or the parent of v (if it exists, i.e. if v is not the root of the tree). Each traversal of an edge costs one unit of time, and the complexity of an algorithm for this problem is thus measured by the total traveled distance in the binary tree. The algorithm is also allowed to store values in memory. For a node v ‚àà V , also per abuse of notation written v ‚àà T , we denote by T (v) the subtree of T rooted at v. For a tree T and a value L ‚àà R, we deÔ¨Åne the subtree TL := {v ‚àà T | val(v) ‚â§ L}. We denote the nth smallest value in T by SELECTT (n). This is the quantity that we are interested in Ô¨Ånding algorithmically. We say that a value V ‚àà R is good for a tree T if V ‚â§ SELECTT (n) and bad otherwise. Similarly, we call a node v ‚àà T good if val(v) ‚â§ SELECTT (n) and bad otherwise. We use [k] to refer to the set {1, . . . , k}. When we write log(n), we assume the base of the logarithm to be 2. We will often instruct the agent to move to an already discovered good vertex v ‚àà V . The way this is done algorithmically is by saving val(v) in memory and starting a depth Ô¨Årst search at the root, turning back every time a value strictly bigger than val(v) is encountered until Ô¨Ånally Ô¨Ånding val(v). This takes at most O(n) time, since we assume v to be a good node. If we instruct the agent to go back to the root from a certain vertex v ‚àà V , this is simply done by traveling back in the tree, choosing to go to the parent of the current node at each step. In later sections, we will often say that a subroutine takes a subtree T (v) as input. This implicitly means that we in fact pass it val(v) as input, make the agent travel to v ‚àà T using the previously described procedure, call the subroutine from that position in the tree, and travel back to the original position at the end of the execution. Because the subroutine knows the value val(v) of the root of T (v) , it can ensure it never leaves the subtree T (v) , thus making it possible to recurse on a subtree as if it were a rooted tree by itself. We will sometimes want to pick a value uniformly at random from a set of values {V1 , . . . , Vk } of unknown size that arrives in a streaming fashion, for instance when we traverse a part of the tree T by doing a depth Ô¨Årst search. That is, we see the value Vi at the ith time step, but do not longer have access to it in memory once we move on to Vi+1 . This can be done by generating random values {X1 , . . . , Xk } where, at the ith time step, Xi = Vi with probability 1/i, and Xi = Xi‚àí1 otherwise. It is easy to check that Xk is a uniformly distributed sample from {V1 , . . . , Vk }.  
  3  
  Sparse Approximation over the Cube Sabrina Bruckmeier1(B) , Christoph Hunkenschr¬® oder2 , and Robert Weismantel1 1 ETH Z¬® urich, Z¬® urich, Switzerland {sabrina.bruckmeier,robert.weismantel}@ifor.math.ethz.ch 2 TU Berlin, Berlin, Germany [email protected]   
  Abstract. This paper presents an analysis of the NP-hard minimization problem min{b ‚àí Ax2 : x ‚àà [0, 1]n , |supp(x)| ‚â§ œÉ}, where supp(x) := of investigation {i ‚àà [n] : xi = 0} and œÉ is a positive integer. The object  is a natural relaxation where we replace |supp(x)| ‚â§ œÉ by i xi ‚â§ œÉ. Our analysis includes a probabilistic view on when the relaxation is exact. We also consider the problem from a deterministic point of view and provide a bound on the distance between the images of optimal solutions of the original problem and its relaxation under A. This leads to an algorithm for generic matrices A ‚àà Zm√ón and achieves a polynomial running time provided that m and A‚àû are Ô¨Åxed. Keywords: Sparse Approximation Recovery  
  1  
  Introduction and Literature Review  
  Due to the recent development of machine learning, data science and signal processing, more and more data is generated, but only a part of it might be necessary in order to already make predictions in a suÔ¨Éciently good manner. Therefore, the question arises to best approximate a signal b by linear combinations of no   more than œÉ vectors Ai from a suitable dictionary A = A1 , . . . , An ‚àà Rm√ón : min Ax ‚àí b2 subject to x0 ‚â§ œÉ,  
  (1)  
  Preliminaries  
  Let A ‚àà Zm√ón and b ‚àà Zm . Moreover, let supp(x) denote the support of x, i.e. supp(x) := {i ‚àà [n] : xi = 0} and set x0 := |supp(x)|. For the rest of the paper, x denotes an optimal solution for (P0 ) for a given integer œÉ ‚àà Z‚â•1 . A natural convex relaxation of (P0 ) is given by min Ax ‚àí b2 subject to x ‚àà [0, 1]n and x1 ‚â§ œÉ. x  
  (P1 )  
  An optimal solution to (P1 ) will be denoted by x ÀÜ throughout the paper. When m = 1, there exists an optimal solution x ÀÜ for (P1 ) that has at most one fractional variable (see Lemma 4). This solution is also feasible for (P0 ), and hence optimal. The idea of our approach is to establish a proximity result for AÀÜ x and Ax respectively, that we can exploit algorithmically. This proximity bound depends on m which comes as no surprise, given that the problem is NP-hard even for  
  Sparse Approximation Over the Cube  
  In the second to last equality we used that the normal cones Cv tile the space Rm . ‚àö Let Œº > 0 be a constant s.t. Q ‚äÜ ŒºB, e.g. Œº = œÉ mA‚àû . We have the containment Q + ŒªB ‚äÜ ŒºB + ŒªB = (Œº + Œª)B that allows us to estimate vol(Q + ŒªB) ‚â§ (Œª + Œº)m vol(B). The probability that b is sampled in one of the normal cones is therefore  m Œª Œªm vol(ŒªB) ‚àö ‚â• ‚â• . vol(Q + ŒªB) (Œª + Œº)m Œª + œÉ mA‚àû  ‚àö Let us brieÔ¨Çy comment on the probability quantity œÅ := (Œª/(Œª + œÉ mA‚àû ))m . If we choose Œª = 2m3/2 œÉA‚àû in Theorem 6, then œÅ ‚â• 1/2, as one can verify with Bernoulli‚Äôs inequality. Figure 1 depicts the geometry underlying the proof of Theorem 6. The vector b1 is sampled from the dotted area and hence, an optimal solution of (P1 ) may use 2 fractional entries, and thus have support œÉ + 1. On the other hand, the vector b2 is sampled from the dashed area, which leads to the solution of (P1 ) corresponding to a vertex of Q. In the second case (P1 ) has an integral solution, which automatically solves (P0 ).  
  Fig. 1. The sampling of the vector b from Q + ŒªB  
  i‚ààF  
  Since x ÀÜi ‚àà (0, 1) for all i ‚àà F, there exists Œµ > 0 such that both points x ÀÜ + Œµy x + Œµy ‚àí x ÀÜ) = and x ÀÜ ‚àí Œµy are feasible for (P1 ). By Lemma 7, we must have v  A(ÀÜ x + y) ‚àà H.  v  AŒµy ‚â§ 0 and ‚àív  AŒµy ‚â§ 0, resulting in v  Ay = 0. Thus, A(ÀÜ With these results we are now able to show a proximity result (Theorem 2) between AÀÜ x and Ax . Here, ÀÜ x denotes the vector x ÀÜ rounded down componentwise. Proof (Theorem 2). Given an optimal solution x ÀÜ of (P1 ), let F = {i ‚àà [n] : generality, we may assume that |F| ‚â§ m and x ÀÜi ‚àà (0, 1)}. Without loss of  ÀÜi , and construct a feasible solution y for (P0 ) F = {1, 2, . . . , |F|}. Let k := i‚ààF x from x ÀÜ as follows: ‚éß 1, 1 ‚â§ i ‚â§ k ‚é™ ‚é™ ‚é™ ‚é®k ‚àí k, i = k yi := ‚é™ 0, k + 1 ‚â§ i ‚â§ |F| ‚é™ ‚é™ ‚é© x ÀÜi , i‚àà / F. The point y satisÔ¨Åes 0 ‚â§ yi ‚â§ 1 for all i ‚àà [n] and y0 = ÀÜ x1  ‚â§ œÉ. Since   yi = x ÀÜi , (3) i‚ààF  
  i‚ààF  
  (P1 )  
  The results of Sects. 4 and 5 extend to this generalization in a straight-forward manner. For the algorithm it implies that the number of arithmetic operations increases by an additional factor of um ‚àû . The reason is the core of our approach: The proximity bound between optimal solutions for (P0 ) and (P1 ) respectively, increases by this factor. The proximity bound must however depend on u‚àû as the following example shows: Let n and u be even, non-negative integers. Set A := 1, œÉ := n2 and b = u2 1 where 1 denotes the all-ones vector. It can easily be checked that x ÀÜ = u2 1 is  optimal for (P1 ) while u , i ‚àà [œÉ]  xi = 2 0, i ‚àà [n] \ [œÉ] is optimal for (P0 ). This shows that any approach aiming for a logarithmic dependency on u‚àû requires techniques that are diÔ¨Äerent from the ideas presented in this paper. Acknowledgements. The second and third author acknowledge support by the Einstein Foundation Berlin.  
  Combinatorial Optimization, RWTH Aachen University, Aachen, Germany {buesing,gersing}@combi.rwth-aachen.de 2 Discrete Optimization, RWTH Aachen University, Aachen, Germany [email protected]   
  Abstract. Robust combinatorial optimization with budget uncertainty is one of the most popular approaches for integrating uncertainty in optimization problems. The existence of a compact reformulation for (mixed-integer) linear programs and positive complexity results give the impression that these problems are relatively easy to solve. However, the practical performance of the reformulation is actually quite poor when solving robust integer problems due to its weak linear relaxation. To overcome the problems arising from the weak formulation, we propose a procedure to derive new classes of valid inequalities for robust binary optimization problems. For this, we recycle valid inequalities of the underlying deterministic problem such that the additional variables from the robust formulation are incorporated. The valid inequalities to be recycled may either be readily available model constraints or actual cutting planes, where we can benefit from decades of research on valid inequalities for classical optimization problems. We first demonstrate the strength of the inequalities theoretically, by proving that recycling yields a facet-defining inequality in surprisingly many cases, even if the original valid inequality was not facetdefining. Afterwards, we show in a computational study that using recycled inequalities leads to a significant improvement of the computation time when solving robust optimization problems. Keywords: Robust Optimization ¬∑ Combinatorial Optimization Integer Programming ¬∑ Polyhedral Combinatorics  
  1  
  MILP solvers [7]. In this context, we propose a new class of valid inequalities for robust combinatorial optimization problems that are easy to compute and can lead to a signiÔ¨Åcant reduction of the computation time. Without uncertainties, the socalled nominal combinatorial optimization n problem NOM is deÔ¨Åned as min{ i‚àà[n] ci xi |Ax ‚â§ b, x ‚àà {0, 1} }, with c ‚àà Rn , A ‚àà Rm√ón , and b ‚àà Rm . Here, [n] = {1, . . . , n}. In the case of uncertainty in the objective, the coeÔ¨Écients ci are replaced by uncertain coeÔ¨Écients ci from an interval [ci , ci + cÀÜi ]. We say that ci can deviate from its nominal value ci by up to the deviation cÀÜi . Since the worst-case, in which all coeÔ¨Écients ci deviate to ci + cÀÜi , is unlikely, Bertsimas and Sim [6] deÔ¨Åne an uncertainty budget Œì ‚àà [0, n] and only consider scenarios where at most Œì  coeÔ¨Écients ci deviate to ci + cÀÜi and one coeÔ¨Écient may deviate to ci + (Œì ‚àí Œì ) cÀÜi . The robust counterpart, in which we optimize against the worst-case, can be stated as     ci xi + max cÀÜi xi (Œì ‚àí Œì ) cÀÜt xt + min i‚àà[n]  
  S‚à™{t}‚äÜ[n]: |S|‚â§Œì ,t‚ààS / n  
  .  
  Unfortunately, the formulation P ROB is quite weak, often leading to much higher computation times for solving ROB compared to NOM. In fact, the relative integrality gap of the formulation P ROB may be arbitrarily large, even if the integrality gap of the corresponding nominal problem is zero. This is shown in the following example from [7]. Example the easy problem of  selecting the cheapest of n elements  1. Consider  n . The integrality gap is zero for all c x | x = 1, x ‚àà {0, 1} min i‚àà[n] i i i‚àà[n] i n c ‚àà R . However, if we consider an instance of the uncertain counterpart ROB with c ‚â° 0, cÀÜ ‚â° 1, and Œì = 1  
   ‚é´ ‚éß  
  ‚é™ ‚é™ ‚é© ‚é≠  
  x ‚àà [0, 1]n , p ‚àà Rn‚â•0 , z ‚àà R‚â•0 This bilinear formulation strengthens the robustness constraints pi + z ‚â• cÀÜi xi by multiplying z with xi , which is valid due to xi ‚àà {0, 1}. While the bilinearity is rather hindering for practical purposes, P BIL is theoretically very strong. In fact, there exists no polyhedral formulation P for ROB with P  P BIL . Contribution. In this paper, we use the bilinear formulation P BIL as a foundation for the new class of recycled inequalities. To obtain these, we combine the strength of the bilinear inequalities with the structural properties provided by inequalities for the nominal problem NOM. By doing so, we can use inequalities for NOM  
  Recycling Inequalities for Robust Combinatorial Optimization  
  i‚àà[n]  
  whichis a valid inequality for C due to œÄ ‚â• 0. Now, since z ‚â• 0 holds, we  
  have i‚àà[n] œÄi xi z ‚â§ œÄ0 z, which proves the statement.  As we reuse the valid inequality i‚àà[n] œÄi xi ‚â§ œÄ0 to strengthen the formula tion P ROB , we call (1) the recycled inequality of i‚àà[n] œÄi xi ‚â§ œÄ0 . In accordance  with the requirements of Theorem 1, we call i‚àà[n] œÄi xi ‚â§ œÄ0 recyclable if it is valid for C NOM and œÄ ‚â• 0. Note that we could also derive the concept of recycled inequalities on the basis of the even stronger bilinear inequalities xi (pi + z) ‚â• cÀÜi xi , resulting from multiplying both pi and z with xi . However, after  summing the bilinear inequalities with factors œÄi , this would yield the term i‚àà[n] œÄi xi pi , which we can only  estimate against i‚àà[n] œÄi pi , yielding the same result as above. To get a better understanding for recycled inequalities, let us recognize how they compare to the bilinear inequalities over the course of their construction. First, note that the sum of the bilinear inequalities is weaker than the bilinear inequalities themselves. Hence, when separating a recycled inequality to cut-oÔ¨Ä a fractional solution (Àú x, pÀú, zÀú) ‚àà P NOM , the inequality to be recycled should only xi zÀú ‚â• cÀÜi x Àúi support indices i ‚àà [n] with œÄi > 0 for which the bilinear inequality pÀúi +Àú is violated  or tight. A second potential weakening occurs  when applying the estimation i‚àà[n] œÄi xi z ‚â§ œÄ0 z. This implies that recycling i‚àà[n] œÄi xi ‚â§ œÄ0 is especially interesting if it is binding for x Àú.  Revisit Example 1, where we can recycle the valid inequality i‚àà[n] xi ‚â§ 1  implied by the constraint i‚àà[n] xi = 1. The corresponding recycled inequality    z + i‚àà[n] pi ‚â• i‚àà[n] xi yields z + i‚àà[n] pi ‚â• 1, and thus the optimal objective value of the linear relaxation is now equal to the optimal integer objective value. This intuitively highlights the strength of the recycled inequalities in the case where both properties, a binding recyclable valid inequality and the violation of supported bilinear inequalities, coincide. ROB  
      Lemma 1. We have dim C ROB = dim C NOM + n + 1. Proof. For a polytope P ‚äÜ Rn , the number n ‚àí dim (P ) equals the maximumnumber of linearly independent equations that are met by all x ‚àà P . Let i‚àà[n] (œâi xi + œân+i pi ) + œâ2n+1 z = œâ0 be an equation that is satisÔ¨Åed by all be raised arbitrarily and C ROB = ‚àÖ, we have (x, p, z) ‚àà C ROB . Since p and z can  œân+1 = ¬∑ ¬∑ ¬∑ = œâ2n+1 = 0 and thus i‚àà[n] œâi xi = œâ0 . Hence, the equations that are met by all (x, p, z) ‚àà C ROB are exactly the equations that are met by all x ‚àà C NOM , which implies        dim C ROB = 2n + 1 ‚àí n ‚àí dim C NOM = dim C NOM + n + 1.  
  Knowing the dimension of C ROB , we are now able to study  facet-deÔ¨Åning recycled inequalities. For this, we only consider inequalities i‚àà[n] œÄi xi ‚â§ œÄ0 consisting of variables with uncertain objective coeÔ¨Écients, i.e., we have œÄi = 0 for all i ‚àà [n] with cÀÜi = 0. We call inequalities with this property uncertaintyexclusive inequalities. Note that these are the only interesting inequalities for recycling, because we can always drop variables xi with cÀÜi = 0. This strengthens the corresponding recycled inequality by removing œÄi pi from the left-hand side, while the right-hand side doesn‚Äôt change due to œÄi cÀÜi xi = 0. The following theorem characterizes exactly under which conditions recyclable, uncertaintyexclusive inequalities i‚àà[n] œÄi x ‚â§ œÄ0 yield facet-deÔ¨Åning recycled inequalities,  
      
  based on the face F (œÄ) = x ‚àà C NOM i‚àà[n] œÄi x = œÄ0 . The statement may seem very technical at Ô¨Årst glance, but we will see afterwards that it is quite powerful and has some surprising implications.  Theorem 2. Let i‚àà[n] œÄi xi ‚â§ œÄ0 be a recyclable, uncertainty-exclusive inequality and ej ‚àà Rn+1 be the unit-vector for j ‚àà S = {i ‚àà [n]|œÄi = 0}. Then the recyROB exist vectors cled inequality (1) is facet-defining for if and  only  j C  if there  n‚àí|S|   1 n‚àí|S|  
  Àú1 , 1 , . . . , x ‚äÜ F (œÄ) such that e j ‚àà S ‚à™ x Àú Àú , 1 are x Àú ,...,x linearly independent. Proof. First, note that the face of the recycled inequality is not equal to C ROB , since p and z can be raised arbitrarily.    Thus, it is facet-deÔ¨Åning if and only if there exist dim C ROB = dim C NOM + n + 1 aÔ¨Énely independent vectors (x, p, z) ‚àà C ROB that satisfy it with equality.   Regardless of œÄ, there are dim C NOM + 1 + |S|   aÔ¨Énely independent NOM ROB ) ‚äÜ (x, p, z) ‚àà C satisfying (1) with equality. For this, let x0 , . . . , xdim(C  j  NOM j C be aÔ¨Énely   NOM independent. j We choose x , cÀÜ  x , 0 for each j ‚àà 0, . . . , dim C , where cÀÜ  x refers to the component-wise multiplication,     i.e., cÀÜ  xj i = cÀÜi xji . By deÔ¨Ånition, xj , cÀÜ  xj , 0 is within C ROB and satisÔ¨Åes   (1) with equality. Additionally, we choose x0 , cÀÜ  x0 + ej , 0 for each j ‚àà S. Here, ej ‚àà Rn with some abuse of notation. Again, this vector is within C ROB and satisÔ¨Åes (1) with equality due to œÄj = 0.  
    to1 the  ones above  j independent n‚àí|S|  
  Àú , 1 , . . . , x Àú , 1 are linearly independent. To show and e j ‚àà S ‚à™  x this, one subtracts x0 , cÀÜ  x0 , 0 from all other vectors, yielding vectors that are linearly independent if and only if the desired aÔ¨Éne independency holds. Writing the vectors in a matrix and performing basic column and row transformations implies the result. We omit this step here  j due to space limitations. Àúi , we also have With zÀúj > 0 and œÄi pÀúji = œÄi cÀÜi ‚àí zÀúj x     œÄi pÀúji = œÄi cÀÜi x Àúji ‚áî œÄ0 zÀúj = œÄi zÀúj x Àúji ‚áî œÄ0 = œÄi x Àúji , œÄ0 zÀúj + i‚àà[n]  
  i‚àà[n]  
    space x ‚àà C NOM xi = 0 for all œÄi = 0 .  
  Note that the additional requirements on C NOM imply that the restricted solutionspace is of dimension n ‚àí |S|, which guarantees that we Ô¨Ånd appropriate  Àún‚àí|S| . vectors x Àú1 , . . . , x One now might raise the question whether inequalities recycled from dominated inequalities are actually of practical interest or whether they do not really matter due to the special structure of the objective function. The following example demonstrates that it can be beneÔ¨Åcial to weaken an inequality before it is recycled. Example 2. Consider the robust problem   
  ‚éß  
   constraint xv + xw ‚â§ 1 with v‚ààQ xv ‚â§ 1 for a clique Q ‚äÜ V with {v, w} ‚äÜ Q. This clique formulation has a much tighter linear relaxation compared to the previous edge formulation, and thus reduces the contribution of the nominal problem to the integrality gap. Indeed, Table 1 shows that separating recycled clique inequalities reduces the integrality gap by more than one half when using the clique formulation. Apart from this observation, the clique formulation is not of practical interest, as the solver performs better on the edge formulation. Using the edge formulation, we are able to solve 2 more instances when recycling clique inequalities, but observe an increase of the computation time. This seems to be due to some interference with Gurobi‚Äôs own cutting planes. When disabling Gurobi‚Äôs cutting planes, recycling is much better than using the default formulation. In fact, disabling Gurobi‚Äôs cuts and using recycled clique inequalities is the overall best performing approach, solving the most instances in the least amount of computation time. This is true for both nominal formulations and indicates that, given a careful implementation, recycling clique inequalities yields a signiÔ¨Åcant speedup compared to the robust default formulation. 4.2  
  Robust Bipartite Matching  
  ‚é™ ‚é™ E ‚é≠ ‚é© E  
  x ‚àà {0, 1} , p ‚àà R‚â•0 , z ‚àà R‚â•0 on a bipartite graph with nodes V and edges E. In contrast to the independent set problem, for which the standard nominal formulation is quite weak, we have P NOM = C NOM for the bipartite matching problem [8]. That is, the integrality gap of the robust counterpart is only due to the robust substructure, which allows us to test the strength of recycled inequalities to their limit. We randomly generate instances by Ô¨Årst dividing  n  a given set  of nodes V = [n]  n  and W = + 1, . . . , n . Afterwards, we into two partitions U = 2 2  
  Recycling Inequalities for Robust Combinatorial Optimization  
  J. Cardinal and R. Steiner  
  the computational hypotheses. While making this statement, it is important to point out that here (and throughout this paper) we always measure the number of non-degenerate steps during an execution of a pivot rule for the simplex algorithm, and not the natural alternative, which would be the number of all steps (including both degenerate and non-degenerate steps). A degenerate step in a simplex algorithm here means a step that changes the basis of active variables, but not the value of the current feasible solution. 1.2  
  Pivot Rules for Circuit-Augmentation Algorithms  
  Note that in the two problems, the input graph is guaranteed to be Hamiltonian, yet it remains hard to explicitly construct a directed cycle of some guaranteed length. Characterising the approximability of the longest cycle problem in undirected graphs is a longstanding open question [3,22]. The second ingredient of our proof is the following lemma, perhaps of independent interest, that bounds the increase in length of a longest directed cycle after a number of cycle Ô¨Çips in a digraph. Lemma 3. Let G be an undirected graph, and let C1 , . . . , Ct be a sequence of (not necessarily distinct) cycles in G. Let D0 , D1 , . . . , Dt be a sequence of orientations of G such that for each i ‚àà [t] the cycle Ci is directed in Di‚àí1 and such that Di is obtained from Di‚àí1 by Ô¨Çipping Ci . There exists a polynomial-time algorithm that, given as input a number , the orientations D0 , . . . , Dt and a directed cycle C in Dt of length |C| > t+1 , computes a directed cycle in D0 of length at least . The bound of Lemma 3 can be shown to be essentially tight. We refer to the full version of this paper for an explicit description of a directed graph whose maximum directed cycle is of length , but after a sequence of at most t cycle Ô¨Çips, it contains a directed cycle of length at least (/2)t+1 . 2.2  
  Reduction  
  Proof of Lemma 3  
  Proof (Lemma 3). Let the orientations D0 , D1 , . . . , Dt of G be given as input, together with a directed cycle C in Dt and a number  ‚àà N such that |C| > t+1 . Our algorithm starts by computing the sequence of cycles C1 , . . . , Ct by determining for each i ‚àà [t] the set of edges with diÔ¨Äerent orientation in Di‚àí1 and Di . Next we compute in polynomial time the subgraph H of G which is the union of the cycles C1 , . . . , Ct in G. We in particular compute a list of the vertex sets of its connected components, which we call Z1 , . . . , Zc for some number c ‚â• 1. We need the following fact, proved in the full version: Claim ‚ú¢ (). For each r ‚àà [c] the induced subdigraph D0 [Zr ] of D0 is strongly connected. Let (x0 , x1 , . . . , xk‚àí1 , xk = x0 ) be the cyclic list of vertices on the directed cycle C in Dt , with edges oriented from xi to xi+1 for all i ‚àà [k ‚àí 1]. By assumption on the input, we have k = |C| > t+1 . We Ô¨Årst check if C is vertex-disjoint from H, in which case we may return C, which is then also a directed cycle in D0 of length k > t+1 ‚â• , as desired. Otherwise, C intersects some of the components of H. We then for each vertex xi ‚àà V (C) compute a label lab(xi ) ‚àà [c + 1], deÔ¨Åned as lab(xi ) := r if xi ‚àà Zr lies in the r-th component of H, and lab(xi ) := c + 1 if xi is not a vertex of H. We next compute an auxiliary weighted directed multigraph M on the vertex set [c] as follows: For every maximal subsequence of C, of length at least  
  Inapproximability of Shortest Paths on Perfect Matching Polytopes  
  Fig. 4. Construction of the auxiliary directed multigraph M in the proof of Lemma 3. The cycle C is shown on the left, together with the connected components of H that it intersects. The resulting weighted directed multigraph M is shown on the right.  
  Furthermore, by deÔ¨Ånition every vertex in M has the same number of incoming and outgoing arcs. Hence, we may compute in polynomial time an edgedisjoint decomposition of M into directed cycles (including possible loops) in M . Let W1 , . . . , Wp for some p ‚àà N be the list of edge-disjoint directed cycles in this decomposition of M . We now create, for each Wi , a directed cycle Ki in D0 of length |Ki | ‚â• weight(Wi ), where weight(Wi ) is the total arc weight of Wi , as follows: Let (l0 , l1 , . . . , ls = l0 ) be the cyclic vertex-sequence of Wi . For each arc (lj , lj+1 ) in Wi , we consider the corresponding subsequence P (lj , lj+1 ) of C which starts in Zlj , ends in Zlj+1 , and all whose internal vertices are not contained in H. We note that since arcs outside H have the same orientation in D0 and Dt , the subsequence P (lj , lj+1 ) is a directed path or a directed cycle also in D0 which starts in Zlj and ends in Zlj+1 . We Ô¨Årst check whether there exists an index j such that P (lj , lj+1 ) is a directed cycle. In this case, necessarily Wi is a loop (i.e. s = 0) and lj = lj+1 = l0 . We thus may simply put Ki := P (lj , lj+1 ), with weight(Wi ) = |Ki | satisÔ¨Åed by deÔ¨Ånition of the weights in M . Otherwise, each of the P (lj , lj+1 ) is a directed path in D0 . We now make use of Claim ‚ú¢, which tells us that D0 [Zlj ] is strongly connected for every j = 0, 1, . . . , s ‚àí 1. We may therefore compute in polynomial time for each j = 0, 1, . . . , s‚àí1 a directed path Qj in D0 [Zlj ] (possibly consisting of a single vertex) which connects the endpoint of P (lj‚àí1 , lj ) to the starting point of P (lj , lj+1 ) (index-addition modulo s). Crucially, note that any two directed paths in the collection {P (lj , lj+1 ), Qj |j = 0, 1, . . . , s‚àí1} are vertex-disjoint except for shared common endpoints. We now compute the directed cycle Ki in D0 , which is the union of the directed paths P (lj , lj+1 ) and the directed paths Qj for j = 0, . . . , s ‚àí 1. It is clear that its length |Ki | is lower-bounded by the sum of the  
  (4)  
  where max{ a , d } = 1. Whether S gets mapped to S h or S g depends on whether the quadratic deÔ¨Åning S is homogeneous or not. Thus, one of the goals of this paper will be: using C as maximal S h - and S g -free sets of [16], to Ô¨Ånd a monoid M such that C is S h + M - or S g + M -free and, subsequently, strengthen the corresponding intersection cut. Monoidal strengthening is also related to lifting [3,9‚Äì11]. A nice property of œà is that it is subadditive2 . This implies that with œà we obtain sequence independent lifting, i.e. we can apply the strengthening to all integer variables at the same time. However, the monoidal lifting function œà is, in general, just one possible way of lifting. We can deÔ¨Åne the best possible coeÔ¨Écient that a particular integer variable can achieve, with the so-called lifting function œÄ [4,10].   1 ‚àí œÜ(s) : f + s + œÉr ‚àà S, œÉ ‚àà Z‚â•1 . (5) œÄ(r) = sup œÉ In general, œÄ is not subadditive so we do not have sequence independent lifting with it [4]. When it is subadditive, we say that there is unique lifting, because œÄ dominates any other lifting. For the case S = Zn ‚à© P it is well understood when we have unique lifting [3]. Our Ô¨Ånal goal is to show that in our setting there is unique lifting; more speciÔ¨Åcally, we show that choosing œÜ to be a minimal representation 3 of C ‚àí f , we have that œÄ = œà. Contributions. Our main contributions are: (1) we show that the monoidal strengthening framework does not produce any strengthening when S is deÔ¨Åned using a homogeneous quadratic; (2) in the non-homogeneous case, we show a family of cases where monoidal strengthening can be applied and an explicit monoid construction based on a maximal S g -free set of [16] which can be used for this strengthening; (3) we show an explicit formula for how to eÔ¨Éciently 1 2 3  
  With a slight abuse of notation, we refer to a non-convex set C ‚àí M as S-free whenever the convex set C ‚àí m is S-free for every m ‚àà M . A function œà is subadditive if œà(x + y) ‚â§ œà(x) + œà(y). This means that if œÅ is such that C = {s ‚àà Rp : œÅ(s ‚àí f ) ‚â§ 1} then œÅ(s) ‚â• œÜ(s).  
  Monoidal Strengthening in the Homogeneous Case  
  In this section, we analyze the case of S h and show that the monoidal strengthening framework does not produce any improvements when the cuts are created using maximal S h -free sets. The main reason behind this fact is that S h is a cone, and consequently every maximal S h -free set is a convex cone [6, Corollary 3]4 ; we show below why this is not a good setting for monoidal strengthening. In fact, the results in this section apply to a generic closed cone S and are stated with respect to such set. As mentioned before, for a given S-free set C, we are interested in Ô¨Ånding a monoid M such that C ‚àí M is S-free. The following result shows that in this case C ‚àí M = M . We remark that cone(¬∑) is the cone generated by a set, which may not be convex. Theorem 2. Let S, C ‚äÜ Rn where S is a closed cone and C is a convex maximal S-free set. Let M ‚äÜ Rn be a monoid such that C ‚àíM is S-free, then C ‚àíM = C. In particular, this implies that the cut obtained from monoidal strengthening would be the same as the standard intersection cut obtained through C. Proof (sketch). Since M is a monoid, 0 ‚àà M and thus C ‚äÜ C ‚àí M . It can be shown that cl cone(M ) is a convex cone such that C ‚àí cl cone(M ) is S-free. Note that C ‚àí cl cone(M ) is convex, and thus the maximality of C implies that C ‚àí cl cone(M ) ‚äÜ C. Since C ‚àí M ‚äÜ C ‚àí cl cone(M ), we conclude C ‚àí M = C. This last result shows that in the presence of a maximal S-free set C, there is not much to be gained from the monoidal strengthening framework when S is a cone. This negative property, nonetheless, can be reinterpreted as a way of detecting ‚Äúnon-maximality‚Äù of an S-free set: if one could Ô¨Ånd a monoid M such that C ‚àí M is S-free and C ‚àí M = C, then C is not maximal. We formalize this in the next result.  
  4  
  1 (Œª, Œ≤) + dT Œ≤  
  Maximality of the resulting set is shown using the exposing points above and, for relaxed inequalities, a diverging sequence in S g that approaches the inequality indeÔ¨Ånitely (an exposing sequence). This is due to the fact that these relaxed inequalities may have never intersect S g . In our current monoid construction, we require that all inequalities to have exposing points. This requirement translates to aT Œª + dT Œ≤ < 0 for all Œ≤ with  
  Œ≤ = 1. This, in turn, reduces to d < ‚àíaT Œª. Note that this condition implies that C = CŒª ‚à© H is maximal S g -free with respect to H [16]. Additionally, this implies that we can assume a = max{ a , d } = 1. We believe that when these assumptions are not fulÔ¨Ålled, monoidal strengthening cannot be applied. Proving this conjecture is part of future work. 3.2  
  (viT b)2 Œ∏i  
  We note that we also need to compute the cut coeÔ¨Écient œÜ(r), but this can also be done eÔ¨Éciently as shown in [8]. The expressions on the previous proposition may not provide too much insight themselves, as they are accumulating a series of transformations to bring S to S g . However, we believe their value relies in that, given an eigenvalue decomposition for a general quadratic inequality, one can simply plug-in the desired parameters and obtain a univariate quadratic that yields the strengthened coeÔ¨Écients of an intersection cut.  
  5  
  (1)  
  where A ‚àà Zm√ón , b ‚àà Zm and c ‚àà Zn , see, e.g. [16,27,30]. Lenstra [23] has shown that integer programming can be solved in polynomial time, if the number of variables 2 is fixed. A careful analysis of his algorithm yields a running time of 2O(n ) times a polynomial in the binary encoding length of the input of the integer program. Kannan [19] has improved this to n O(n) , where, from now on we ignore the extra factor that depends polynomially on the input length. The current best algorithm is the one of Dadush [10] with a running time of 2O(n) ¬∑ n n . The question whether there exists a singly exponential time, i.e., a 2O(n) -algorithm for integer programming is one of the most prominent open problems in the area of algorithms and complexity. Integer programming can be described in the following more general form. Here, a convex body is synonymous for a full-dimensional compact and convex set. Integer Programming (IP) Given a convex body K ‚äÜ Rn , find an integer solution x ‚àó ‚àà K ‚à© Zn or assert that K ‚à© Zn = . The convex body K must be well described in the sense that there is access to a separation oracle, see [16]. Furthermore, one assumes that K contains a ball of radius r > 0 and that it is contained in some ball of radius R. In this setting, the current best running times hold as well. The additional polynomial factor in the input encoding length becomes a polynomial factor in log(R/r ) and the dimension n. Central to this paper is Approximate integer programming which is as follows. Approximate Integer Programming (Approx-IP) Given a convex body K ‚äÜ Rn , let c ‚àà Rn be its center of gravity. Either find an integer vector x ‚àó ‚àà (2 ¬∑ (K ‚àí c) + c) ‚à© Zn , or assert that K ‚à© Zn = . The convex body 2 ¬∑ (K ‚àí c) + c is K scaled by a factor of 2 from its center of gravity. The algorithm of Dadush [11] solves approximate integer programming in singly exponential time 2O(n) . Despite its clear relation to exact integer programming, there is no reduction from exact to approximate known so far. Our guiding question is the following: Can approximate integer programming be used to solve the exact version of (specific) integer programming problems? 1.1 Contributions of This Paper We present two different algorithms to reduce the exact integer programming problem (IP) to the approximate version (A PPROX -IP).  
  D. Dadush et al.  
  Moreover, given X as input, the points u 1 , . . . , u k can be found in time polynomial in |X |, k and n. Proof. Let  = min{|X |, n + 1}. The claim is true whenever k ‚â§  since then we may simply pick an arbitrary point in X . Hence from now on we assume k > . By Carath√©odory‚Äôs theorem, there exists a convex combination of zero, using    elements of X . We write 0 = i =1 Œªi v i where v i ‚ààX , Œªi ‚â• 0 for i ‚àà [] and i =1 Œªi = 1.  Consider the numbers L i = (k ‚àí )Œªi + 1. Clearly, i =1 L i = k. This implies that there  exists an integer vector Œº ‚àà N with Œº ‚â• (k ‚àí )Œª and i =1 Œºi = k. It remains to show that we have 1   Œºi v i ‚â§ /k. k i =1 K  
  In fact, one has       Œºi v i = (Œºi ‚àí (k ‚àí )Œªi ) v i + (k ‚àí ) Œªi v i    
  =0  
  For the moreover part, note that the coefficients Œª1 , . . . , Œª are the extreme points of a linear program which can be found in polynomial time. Finally, the linear system  Œº ‚â• (k ‚àí )Œª, i =1 Œºi = k has a totally unimodular constraint matrix and the right hand side is integral, hence any extreme point solution is integral as well, see e.g. [31]. Lemma 10. For any integer  ‚â• 5(n + 1), the convex combination Œº computed in line  (10) satisfies x‚ààX Œºx x ‚àà K . Proof. We may translate the sets X and K so that c = 0 without affecting the claim. Recall that z ‚àà conv(X ). By Carath√©odory‚Äôs Theorem there are v 1 , . . . , v m ‚àà X with m ‚â§ n + 1 so that z ‚àà conv{v 1 , . . . , v m } and so 0 ‚àà conv{v 1 ‚àí z, . . . , v m ‚àí z}. We have v i ‚àà 3K by Lemma 3 and ‚àíz ‚àà 14 E ‚äÜ 14 K as well as z ‚àà 14 K . Hence v i ‚àí zK ‚â§ v i K +‚àí zK ‚â§ m Zm 13 ‚â•0 4 . We apply Lemma 9 and obtain a convex combination Œº ‚àà  with  i =1 Œºi (v i ‚àí m z) 13 K ‚â§  . Then 4  
    m m 13 m 1 + ‚â§1 Œºi v i ‚â§ Œºi (v i ‚àí z) + zK ‚â§  
  (4)  
  in the same claimed running time. We apply the result of Frank and Tardos (Theorem 6) and replace c, Œ≥, A, b by integer-valued objects of bounded ¬∑‚àû -norm so that the feasible region of (4) remains the same. Hence we may indeed assume that c ‚àà Zn , 3 2 Œ≥ ‚àà Z, A ‚àà Zm√ón and b ‚àà Zm with c‚àû , |Œ≥|, A‚àû , b‚àû ‚â§ 2O(n ) ¬∑ ŒîO(n ) . Any feasible solution x to (4) has a slack bounded by Œ≥‚àí‚å©c, x‚å™ ‚â§ |Œ≥|+c‚àû ¬∑n ¬∑Œî ‚â§ N where we may 3 2 choose N := 2O(n ) ŒîO(n ) . Similarly b i ‚àí A i x ‚â§ N for all i ‚àà [n]. We can then introduce slack variables y ‚àà Z‚â•0 and z ‚àà Zm ‚â•0 and consider the system ‚å©c, x‚å™ + y = Œ≥, Ax + z = b, 0 ‚â§ x ‚â§ u, 0 ‚â§ y ‚â§ N , 0 ‚â§ z j ‚â§ N ‚àÄ j ‚àà [m], (x, y, z) ‚àà Zn+1+m  
  (5)  
  D. Dadush et al.  
  to capture a large diversity of settings. However, its general intractability makes it challenging to derive a general algorithmic theory, and hence the focus has been to consider meaningful special cases. The main theoretical result in this area has been the algorithm by Lenstra [10], and the improvement by Kannan [7], which show that integer programs are tractable as long as the dimension is constant. In recent years, a surge of interest appeared regarding eÔ¨Écient algorithms for integer programs under other assumptions. More recently, the seminal work by Eisenbrand and Weismantel [4] for integer programs with a constant number of constraints and bounded matrix coeÔ¨Écients sparked a new trend of improved algorithms and lower bounds; see, e.g., [2,6,9]. In this paper, we study a new general framework that encompasses and further extends many of the settings found in the literature. Consider the problem of optimizing a low dimensional objective function over a high dimensional space Zn . Formally, the problem is deÔ¨Åned as min cT x + g(W x) i ‚â§ xi ‚â§ ui  
  for all i ‚àà {1, 2, . . . , n},  
  W , which reduces the dimension of the problem to n = (2Œî + 1)m . Notice that the linear part of the objective may not remain linear, but it does remain convex. Thus, we can apply Lenstra-Kannan to solve the problem in the claimed running time. This indicates that the problem is tractable for small values of Œî and m. Our main result is an algorithm that avoids the double exponential running time. Theorem 1. For any function g, problem (1) can be solved in time 2  
  nm ¬∑ (mŒî)O(m ) ¬∑ Q , where Q is the query time of the oracle for (2). In particular, for a convex function g, the term Q can be replaced by input O(1) . We notice that in this theorem the bound of Q for the convex case follows by using the Lenstra-Kannan algorithm to solve the small dimensional subproblem (2). In this case, the mO(m) factor in the running time of the Lenstra-Kannan 2 algorithm can be omitted as it is upper bounded by (mŒî)O(m ) . Regarding the nm term, as we explain below, it can be made lower order in interesting concrete settings. We also remark that a term of the form Œîm cannot be avoided due to reductions from integer linear programming (see Sect. 1.1) and lower bounds for that problem [6]. 1.1  
  Applications  
  D. Dadush et al.  
  The reduction to Theorem 1 is as follows: we Ô¨Årst abandon the restriction of x ‚àà {0, 1}n in favor of the general bounded integer variables. Then, since any two variables with the same column in the projection matrix W can be merged to one (by adapting the box-constraints), we may assume without loss of generality that n ‚â§ (2Œî + 1)m . One of the main motivations in the work by Hunkenschr¬® oder et al. [5] is to solve certain types of regression problems. For example, they examine an integer compressed sensing problem, where one receives a small number m of linear measurements of a high dimensional integral signal x‚àó ‚àà {0, 1}n which one would like to (approximately) reconstruct. The received measurements are of the form b = W x‚àó , where W ‚àà Zm√ón is an unknown matrix with coeÔ¨Écients of size at most Œî. As an approximation to x‚àó , they compute the minimizer of min{ b ‚àí W x 2 : x ‚àà {0, 1}n }, under the assumption that one can only access W indirectly via gradient and function evaluation queries to f (x) = b ‚àí W x 2 . As we will explain later, in the compressed sensing and related settings, one can essentially avoid any overhead from not knowing W . While we focus above on the case where W is known, using orthogonal techniques, we can also improve the running times in the unknown W setting by modifying the Hunkenschr¬® oder et al. framework. We defer further discussion of their framework and our related improvements to Sect. 4. Mixed-Integer Linear Programming. Eisenbrand and Weismantel [4] studied the complexity of integer programs of the form min cT x s.t. Ax = b, i ‚â§ xi ‚â§ ui x ‚àà Zn .  
  (4) for all i ‚àà {1, . . . , n},  
  The related results for more restrictive cases in [4] and [5] are based on proximity: the continuous relaxation of the problem, where the integer requirement is omitted, is solved and if one can show that the solution for the relaxation and the actual solution diÔ¨Äer only slightly, then this can be exploited in reducing the search space. The precise proximity theorem in [4] is as follows. Theorem 2 (Eisenbrand and Weismantel [4]). Let z be an optimal vertex solution to the linear program   max cT x : Ax = b and i ‚â§ xi ‚â§ ui for all i , where A ‚àà Zm√ón has entries of size at most Œî. If there exists an integer solution, then there is also an optimal integer solution x‚àó with  
  x‚àó ‚àí z 1 ‚â§ m(2mŒî + 1)m . Hunkenschr¬® oder et al. [5] consider the optimal solution to the continuous relaxation of (3). In the special cases of separable convex and strict convex functions they show that a similar proximity holds, which is a crucial ingredient in their algorithm. Already for general convex functions, however, the proximity bound can be very large, as shown in an example in [5]. This forms a serious obstacle towards our main result. We manage to circumvent this and still rely on proximity by applying it in a diÔ¨Äerent way. Consider for sake of illustration that we were able to determine the value of b‚àó = W x‚àó , where x‚àó is the optimal solution of (1). Then it would be easy to recover x‚àó (solving our problem) by applying the integer linear programming algorithm by Eisenbrand and Weismantel [4]. The algorithm works by computing the continuous solution z to W x = b‚àó and then using that z ‚àí x‚àó 1 is bounded by Theorem 2. Indeed, this bound still holds in our case when Ô¨Åxing b‚àó . However, it is not clear how to compute or guess b‚àó , nor how to compute z without knowing b‚àó . Let us now consider the case that the domain of each variable is Z‚â•0 , which is slightly simpler than the bounded case. Here we may assume that z has only m non-zero components, which we can guess from nm candidates. We still do not know b‚àó or z, but we trivially know z on the n ‚àí m zero components. Intuitively, this is enough to apply proximity to recover x‚àó on the zero components of z. Moreover, recovering x‚àó on the non-zero components of z is only an mdimensional problem, where we can apply the oracle problem (2).  
  (7)  
  In fact, the nm term here can be omitted, since one may assume without loss of generality that no two columns of W are equal and therefore n ‚â§ (2Œî + 1)m .  
  Optimizing Low Dimensional Functions  
  Conclusion and Open Questions  
  In this paper we have demonstrated that the task of optimizing low dimensional functions over a projection as introduced by Hunkenschr¬® oder et al. [5] remains tractable even in much more general settings than originally considered. This creates a bridge also to other lines of work in integer optimization, such as integer programs with few constraints [4]. Our main result leaves open a few questions about the complexity of algorithms for problem (1) or the central case of g being a convex function. As mentioned before, one cannot hope to avoid a term of Œîm in the running time because of known conditional lower bounds. The necessity of the nm term or the m2 exponent, however, appears less clear. The algorithm for integer programming by Eisenbrand and Weismantel [4], a special case of our setting (see applications), does not require the nm term and in many cases we can avoid it as well by merging duplicate columns of W . It would be nice if this term could be removed in general, or at least in the convex case. Related to the m2 exponent, there is already a notorious question arising from [4]. There, Eisenbrand and Weismantel gave an improved algorithm with exponent O(m) instead of O(m2 ) for the case that there are no upper variable bounds, but with bounds they require O(m2 ). It remains unclear whether this is necessary. In our case even without upper bounds our algorithm need the exponent O(m2 ). In fact, this exponent arises in several places: when guessing the support (assuming n ‚âà Œîm ) and when guessing the projection of the tight variables b(T ) .  
  London School of Economics and Political Science, London, UK [email protected]  2 Carnegie Mellon University, Pittsburgh, PA, USA [email protected]  , {moseleyb,rbz}@andrew.cmu.edu 3 University of Bremen, Bremen, Germany [email protected]   
  Abstract. The conÔ¨Åguration balancing problem with stochastic requests generalizes well-studied resource allocation problems such as load balancing and virtual circuit routing. There are given m resources and n requests; each request has multiple possible configurations, each of which increases the load of each resource by some amount. The goal is to select one conÔ¨Åguration for each request to minimize the makespan: the load of the most-loaded resource. In the stochastic setting, the amount by which a conÔ¨Åguration increases the resource load is uncertain until the conÔ¨Åguration is chosen, but we are given a probability distribution. We develop both oÔ¨Ñine and online algorithms for conÔ¨Åguration balancing with stochastic requests. When the requests are known oÔ¨Ñine, we give a non-adaptive policy for conÔ¨Åguration balancing with stochastic requests that O( logloglogmm )-approximates the optimal adaptive policy, which matches a known lower bound for the special case of load balancing on identical machines. When requests arrive online in a list, we give a non-adaptive policy that is O(log m) competitive. Again, this result is asymptotically tight due to information-theoretic lower bounds for special cases (e.g., for load balancing on unrelated machines). Finally, we show how to leverage adaptivity in the special case of load balancing on related machines to obtain a constant-factor approximation oÔ¨Ñine and an O(log log m)-approximation online. A crucial technical ingredient in all of our results is a new structural characterization of the optimal adaptive policy that allows us to limit the correlations between its decisions. Keywords: stochastic scheduling  
  1  
  F. Eberle et al.  
  must choose one conÔ¨Åguration cj ‚àà [qj ] per request, which adds xj (cj ) to the load vector on the resources. The goal is to minimize the makespan, i.e., the load of the most-loaded resource. ConÔ¨Åguration balancing captures many natural resource allocation problems where requests compete for a Ô¨Ånite pool of resources and the task is to Ô¨Ånd a ‚Äúfair‚Äù allocation in which no resource is over-burdened. Two well-studied problems of this form arise in scheduling and routing. (i) In load balancing a.k.a. makespan minimization, there are m (unrelated) machines and n jobs. Scheduling job j on machine i increases the load of i by pij ‚â• 0. The goal is to schedule each job on some machine to minimize the makespan, i.e., the load of the most-loaded machine. (ii) In virtual circuit routing or congestion minimization, there is a directed graph G = (V, E) on m edges with edge capacities ce > 0 for e ‚àà E, and n requests, each request consisting of a source-sink pair (sj , tj ) in G and a demand dj ‚â• 0. The goal is to route each request j from sj to tj via some directed path, increasing the load/congestion of each edge e on the path by dj/ce , while the objective is to minimize the load of the most-loaded edge. ConÔ¨Åguration balancing captures both problems by taking the m resources to be the m machines or edges, respectively; each conÔ¨Åguration now corresponds to assigning a job to some machine or routing a request along some path. Typically, job sizes or request demands are not known exactly when solving resource allocation problems in practice. This motivates the study of algorithms under uncertainty, where an algorithm must make decisions given only partial/uncertain information about the input. Uncertainty can be modeled in diÔ¨Äerent ways. In exceptional cases, a non-clairvoyant algorithm that has no knowledge about the loads of requests may perform surprisingly well; an example is Graham‚Äôs greedy list scheduling for load balancing on identical machines [15]. In general, a non-clairvoyant algorithm cannot perform well. Hence, we consider a stochastic model, where the unknown input follows some known distribution but the actual realization is a priori unknown. Such a model is natural when there is historical data available from which such distributions can be deduced. In the conÔ¨Åguration balancing with stochastic requests problem, we assume that each conÔ¨Åguration c of request j is a random vector Xj (c) with known distribution Dj (c) supported on Rm ‚â•0 such that the Xj (c)‚Äôs are independent across diÔ¨Äerent requests j. The actual realized vector of a conÔ¨Åguration c of request j is only observed after irrevocably selecting this particular conÔ¨Åguration for request objective is to minimize the expected maximum load  j. The n (makespan) E maxi j=1 Xij (cj ) , where cj is the conÔ¨Åguration chosen for request j. We assume that we have oracle access to the Dj (c)‚Äôs; in particular we assume that in constant time, we can compute any needed statistic of the distribution Dj (c). Further, we distinguish whether there is an additional dimension of uncertainty or not, namely the knowledge about the request set. In the oÔ¨Ñine setting, the set of requests and the distributions of the conÔ¨Ågurations of each request are known up-front, and they can be selected and assigned to the resources irre-  
  ConÔ¨Åguration Balancing for Stochastic Requests  
  vocably in any order. In the online setting, requests are not known in advance and they are revealed one-by-one (online-list model). The algorithm learns the stochastic information on conÔ¨Ågurations of a request upon its arrival, and must select one of them without knowledge of future arrivals. After a conÔ¨Åguration is chosen irrevocably, the next request arrives. In general, we allow an algorithm to base the next decision on knowledge about the realized vectors of all previously selected request conÔ¨Ågurations. We call such policies adaptive. Conversely, a non-adaptive policy is one that Ô¨Åxes the particular conÔ¨Åguration chosen for a request without using any knowledge of the realized conÔ¨Åguration vectors. The goal of this paper is to investigate the power of adaptive and nonadaptive policies for online and oÔ¨Ñine conÔ¨Åguration balancing with stochastic requests. We quantify the performance of an algorithm by bounding the worst-case ratio of the achieved expected makespan and the minimal expected makespan achieved by an optimal oÔ¨Ñine adaptive policy. We say that an algorithm Alg Œ±-approximates an algorithm Alg‚Äô if, for any input instance, the expected makespan of Alg is at most a factor Œ± larger than the expected makespan of Alg‚Äô; we refer to Œ± also as approximation ratio. For online algorithms, the term competitive ratio refers to their approximation ratio. 1.1  
  Our Results  
  Technical Overview  
  We illustrate the main idea behind our non-adaptive policies, which compare to the optimal oÔ¨Ñine adaptive policy. Throughout this paper, we let Opt denote the optimal adaptive policy as well as its makespan. As in many other stochastic optimization problems, our goal is to give a good deterministic proxy for the makespan of a policy. Then, our algorithm will optimize over this deterministic proxy to obtain a good solution. First, we observe that if all conÔ¨Ågurations were bounded with respect to E[Opt] in every entry, then selecting conÔ¨Ågurations such   that each resource has expected load O(E[Opt]) gives the desired O logloglogmm approximation by standard concentration inequalities for independent sums with bounded increments. Thus, in this case the expected load on each resource is a good proxy. However, in general, we have no upper bound on Xij (c), so we cannot argue as above. We turn these unbounded random variables (RVs) into bounded ones in a standard way by splitting each request into truncated and exceptional parts. DeÔ¨Ånition 1 (Truncated and Exceptional Parts). Fix œÑ ‚â• 0 as threshold. For a RV X, its truncated part (w.r.t. threshold œÑ ) is X T := X ¬∑ 1X 0 is the truncationthresh old. There are m jobs: a stochastic one with processing time Xj ‚àº œÑ ¬∑Ber œÑ1 and 1 m ‚àí 1 deterministic jobs with processing time Xj ‚â° m . The optimal adaptive policy Ô¨Årst schedules the stochastic job on the fast machine. If its realized size is 0, then it schedules all deterministic jobs on the fast machine as well. Otherwise the realized size is œÑ and it schedules deterministic job on each slow machine,   one 1 + ¬∑ implying E[Opt] = 1 ‚àí œÑ1 m‚àí1 m  However, the total expected œÑ EœÑ = Œò(1).  ¬∑ 1j‚Üíi = œÑ1 (mœÑ ) = m, where j ‚Üí i exceptional load (w.r.t. œÑ ) is i,j E Xij denotes that job j is assigned to machine i, i.e., conÔ¨Åguration i is chosen for j. In the example, the optimal adaptive policy accrues a lot of exceptional load, but this does not have a large eÔ¨Äect on the makespan. Concretely, (1) can be loose by a Œ©(m)-factor for adaptive policies. Thus, it seems that the total exceptional load is a bad proxy in terms of lower-bounding Opt. However, we show that, by comparing our algorithm to a near-optimal adaptive policy rather than the optimal one, the total exceptional load becomes a good proxy in the following sense. This is the main technical contribution of our work, and it underlies all of our algorithmic techniques. Theorem 5. For conÔ¨Åguration balancing with stochastic requests, there exists an adaptive policy with expected maximum load and total expected exceptional load at most 2 ¬∑ E[Opt] with respect to any truncation threshold   œÑ ‚â• 2 ¬∑ E[Opt]. Further, any conÔ¨Åguration c selected by this policy satisÔ¨Åes E maxi Xi (c) ‚â§ œÑ . The proof of the above relies on carefully modifying the ‚Äúdecision tree‚Äù representing the optimal adaptive policy; see [14] for proof. In light of Theorem 5, the deterministic proxies we consider are the expected truncated load on each resource and the total expected exceptional load. All of our algorithms then proceed by ensuring that both quantities are bounded with respect to E[Opt]. In the oÔ¨Ñine case, we round a natural assignment-type linear program (LP), and in the online case, we use a potential-function argument. All of these algorithms actually output non-adaptive policies. For the special case of related-machines load balancing, we also compute a non-adaptive assignment but instead of following it exactly, we deviate using adaptivity and give improved solutions. 1.3  
  Related Work  
  Online Setting  
  We now consider online conÔ¨Åguration balancing where n stochastic requests arrive online one-by-one, and for each request, one conÔ¨Åguration has to be irrevocably selected before the next request appears. We present a non-adaptive online algorithm that achieves a competitive ratio of O(log m), which is best possible due to the lower bound of Œ©(log m) [5]. By a standard guess-and-double scheme, we may assume that we have a good guess of E[Opt]. We omit the proof, which is analogous to its virtual-circuitrouting counterpart in [3]. Lemma 4. Given an instance of online conÔ¨Åguration balancing with stochastic requests, suppose there exists an online algorithm that, given parameter Œª > 0, never creates an expected makespan more than Œ± ¬∑ Œª, possibly terminating before handling all requests. Further, if the algorithm terminates prematurely, then it certiÔ¨Åes that E[Opt] > Œª. Then, there exists an O(Œ±)-competitive algorithm for online conÔ¨Åguration balancing with stochastic requests. Further, the resulting algorithm preserves non-adaptivity. We will build on the same technical tools as in the oÔ¨Ñine case. In particular, we wish to compute a non-adaptive assignment online with small expected truncated load on each resource and small total expected exceptional load. To achieve this, we generalize the greedy potential function approach of [3]. Our two new ingredients are to treat the exceptional parts of a request‚Äôs conÔ¨Åguration as a  
  ConÔ¨Åguration Balancing for Stochastic Requests  
  S. Fujishige et al.  
  a variety of Ô¨Årst order methods. This feature also yields a signiÔ¨Åcant advantage in our computational experiments. Overview of the Algorithm. A key concept in our algorithm is the centroid mapping, deÔ¨Åned as follows. For disjoint subsets I0 , I1 ‚äÜ N , we let L(I0 , I1 ) denote the aÔ¨Éne subspace of RN where x(i) = 0 for i ‚àà I0 and x(i) = u(i) for i ‚àà I1 . For x ‚àà B(u), let I0 (x) and I1 (x) denote the subsets of coordinates i with x(i) = 0 and x(i) = u(i), respectively. A centroid mapping Œ® : B(u) ‚Üí RN is a mapping with the property that Œ® (x) ‚àà arg miny { 12 Ay ‚àí b2 | y ‚àà L(I0 (x), I1 (x))}. This mapping may not be unique, since the columns of A corresponding to {i ‚àà N | 0 < x(i) < u(i)} = N \ (I0 (x) ‚à™ I1 (x)) may not be independent: the optimal centroid set is itself an aÔ¨Éne subspace. The point x ‚àà B(u) is stable if Œ® (x) = x. Stable points can be seen as the analogues of corral solutions in Wolfe‚Äôs algorithm. Every major cycle starts with an update step and ends with a stable point. The update step could be any Ô¨Årst-order step satisfying some natural requirements, such as variants of Frank‚ÄìWolfe, projected gradient, or Wolfe updates. As long as the current iterate is not optimal, this update strictly improves the objective. Finite convergence follows by the fact that there can be at most 3n stable points. After the update step, we start a sequence of minor cycles. From the current iterate x ‚àà B(u), we move to Œ® (x) in case Œ® (x) ‚àà B(u), or to the intersection of the boundary of B(u) and the line segment [x, Œ® (x)] otherwise. The minor cycles Ô¨Ånish once x = Œ® (x) is a stable point. The objective 12 Ax ‚àí b2 is decreasing in every minor cycle, and at least one new coordinate i ‚àà N is set to 0 or to u(i). Thus, the number of minor cycles in any major cycle is at most n. One can use various centroid mappings, with only a mild requirement on Œ® (see Sect. 2.2). We present a poly(n, Œ∫) convergence analysis in the uncapacitated case for projected gradient and Wolfe updates. We expect that similar arguments extend to the capacitated case. The proof has two key ingredients. First, we show linear convergence of the Ô¨Årst-order update steps (Theorem 3). Such a bound follows already from [16]; we present a simple self-contained proof exploiting properties of stable points and the uncapacitated setting. The second step of the analysis shows that in every poly(n, Œ∫) iterations, we can identify a new variable that will never become zero in subsequent iterations (Theorem 2). The proof relies on proximity arguments: we show that for any iterate x and any subsequent iterate x , the distance x ‚àí x  can be upper bounded in terms of n, Œ∫, and the optimality gap at x. In Sect. 5, we present preliminary computational experiments using randomly generated problem instances of various sizes. We compare the performance of diÔ¨Äerent variants of our algorithm to standard gradient methods. The algorithm performs much better with projected gradient updates than with Wolfe updates. We compare an ‚Äòoblivious‚Äô centroid mapping and one that chooses Œ® (x) as the a nearest point to x in the centroid set in the ‚Äòlocal norm‚Äô (see Sect. 2.2). The latter one appears to be signiÔ¨Åcantly better. For choices of parameters n ‚â• 2m, our method with projected gradient updates and local norm mapping outperforms  
  An Update-and-Stabilize Framework for the Minimum-Norm-Point Problem  
  k=1  
  where  ‚â§ n and h1 , h2 , . . . , h ‚àà F(W ) are elementary vectors that conform to v. A fundamental result on elementary vectors asserts that for every subspace W ‚äÜ RN , every v ‚àà W admits a conformal circuit decomposition, see e.g. [12,20]. Note that there may be multiple conformal circuit decompositions of a vector. Given A ‚àà RM √óN , we deÔ¨Åne the extended subspace XA ‚äÇ RN ‚äïM as XA := ker(A | ‚àíIM ). Hence, for every v ‚àà RN , (v, Av) ‚àà XA . For v ‚àà RN , the generalized  path-circuit decomposition of v with respect to A is a decomposition v = k=1 hk , where  ‚â§ n, and for each 1 ‚â§ k ‚â§ , (hk , Ahk ) ‚àà RN ‚äïM is an elementary vector in XA that conforms to (v, Av). Moreover, hk is an inner vector in the decomposition if Ahk = 0 and an outer vector otherwise. We say that v ‚àà RN is cycle-free with respect to A, if all generalized pathcircuit decompositions of v contain outer vectors only. The following lemma will play a key role in analyzing our algorithms.  
  An Update-and-Stabilize Framework for the Minimum-Norm-Point Problem  
  Optimal Solutions and Proximity  
  We deÔ¨Åne the set Z(A, u) := {Ax | x ‚àà B(u)} . Thus, Problem (P) is to Ô¨Ånd the point in Z(A, u) that is nearest to b with respect to the Euclidean norm. We note that if the upper bounds u are Ô¨Ånite, Z(A, u) is called a zonotope. Throughout, we let p‚àó denote the optimum value of (P). Note that whereas the optimal solution x‚àó may not be unique, the vector b‚àó := Ax‚àó is unique by strong convexity; we have p‚àó = 12 b ‚àí b‚àó 2 . We use Œ∑(x) := 12 Ax ‚àí b2 ‚àí p‚àó to denote the optimality gap for x ‚àà B(u). The point x ‚àà B(u) is an Œµapproximate solution if Œ∑(x) ‚â§ Œµ. For a point x ‚àà B(u), let I0 (x) := {i ‚àà N : x(i) = 0}, I1 (x) := {i ‚àà N : x(i) = u(i)}, and J(x) := N \ (I0 (x) ‚à™ I1 (x)). The gradient of the objective 1 2 2 Ax ‚àí b in (P) can be written as g x := A (Ax ‚àí b) . We recall the Ô¨Årst order optimality conditions: x ‚àà B(u) is an optimal solution to (P) if and only if g x (i) = 0 for all i ‚àà J(x), g x (i) ‚â• 0 for all i ‚àà I0 (x), and g x (i) ‚â§ 0 for all i ‚àà I1 (x). Using Lemma 1, we can show: Lemma 2. For any x ‚àà B(u), there exists an optimal solution x‚àó to (P) such that x ‚àí x‚àó ‚àû ‚â§ Œ∫(XA )Ax ‚àí b‚àó 1 , and hence, x ‚àí x‚àó 2 ‚â§ nŒ∫(XA )Ax ‚àí b‚àó 2 .  
  (1)  
  However, this mapping has some undesirable properties. For example, we may have an iterate x that is already in C(I0 (x), I1 (x)), but Œ® (x) = x. Instead, we aim for centroid mappings that move the current point ‚Äòas little as possible‚Äô. The centroid mapping Œ® is called cycle-free, if the vector Œ® (x) ‚àí x is cycle-free w.r.t. A for every x ‚àà B(u). √óN be a positive diagonal matrix. Lemma 3. For every x ‚àà B(u), let D(x) ‚àà RN >0 Then, the following Œ® (x) deÔ¨Ånes a cycle-free centroid mapping:  
  Œ® (x) := arg min{D(x)(y ‚àí x) | y ‚àà C(I0 (x), I1 (x))} .  
  We need one more auxiliary lemma. Lemma 11. Consider an uncapacitated instance of (P), and let x ‚â• 0 be a stable point. Let x ÀÜ ‚â• 0 such that for each i ‚àà N , either x ÀÜ(i) = x(i), or x ÀÜ(i) = x ‚àí Ax2 . 0 < x(i). Then, AÀÜ x ‚àí b2 = Ax ‚àí b2 + AÀÜ For the threshold Œò as in Lemma 10 and for any x ‚â• 0, let us deÔ¨Åne    J  (x) := i | x(i) > Œò Œ∑(x) . The following is immediate from Lemma 10. Lemma 12. Consider an uncapacitated instance of (P). Let x ‚â• 0 be an iterate of Algorithm 1 using projected gradient updates, and x ‚â• 0 be any later iterate. Then, J  (x) ‚äÜ J(x ). Proof (Proof of Theorem 2). At any point of the algorithm, let J  denote the Consider a stable iterate x union of the sets J  (x) for all iterations thus far.  at the beginning of any major cycle, and let Œµ := Œ∑(x)/4nŒòA. Theorem 3 (XA )A2 log(n + for projected gradient updates guarantees that within O(n2 Œ∫2  Œ∫(XA ))) major cycles we arrive at an iterate x such that Œ∑(x ) < Œµ. The bound is O(n3 Œ∫2 (XA )A2 log(n + Œ∫(XA ))) for Wolfe updates. We note that log(n + Œ∫(XA ) + A) = O(log(n + Œ∫(XA ))) according to Remark 1. We show that (3) J  (x ) ‚à© I0 (x) = ‚àÖ. From here, we can conclude that J  was extended between iterates x and x . This may happen at most n times, and so we get the claimed bounds on the number of major cycles. The bound on the minor cycles for projected gradient updates follows since every major cycle contains at most n minor cycles. For Wolfe updates, it follows since every major cycle adds on one component to J(x) whereas every minor cycle removes at least one. Hence, the total number of minor cycles is at most m plus the total number of major cycles. For a contradiction, assume that (3) does not hold. Thus, for every i ‚àà I0 (x), ÀÜ ‚àà RN as x ÀÜ(i) := 0 if i ‚àà I0 (x), and we have x (i) ‚â§ ŒòŒµ. Let us deÔ¨Åne x  By the above assumption, ÀÜ x ‚àí x ‚àû ‚â§ ŒòŒµ, and x ÀÜ(i) := x (i) if i ‚àà J(x). ‚àö  x ‚àí b2 = therefore AÀÜ x ‚àí Ax  ‚â§ nŒòAŒµ. From Lemma 11, we can bound AÀÜ  2  2 ‚àó 2 2 2 x ‚àí Ax  ‚â§ 2p + (nŒò A + 2)Œµ . Recall that since x is a Ax ‚àí b + AÀÜ ÀÜ is a feasible stable solution, Ax‚àíb = min {Ay ‚àí b : y ‚àà L(I0 (x), ‚àÖ)}. Since x solution to this program, it follows that AÀÜ x ‚àí b2 ‚â• Ax ‚àí b2 . We get that x ‚àí b2 ‚àí 2p‚àó ‚â§ (nŒò2 A2 + 2)Œµ2 , in contradiction 2Œ∑(x) = Ax ‚àí b2 ‚àí 2p‚àó ‚â§ AÀÜ with the choice of Œµ.  
  5  
  Acknowledgments. The third author would like to thank Richard Cole, Daniel Dadush, Christoph Hertrich, Bento Natura, and Yixin Tao for discussions on Ô¨Årst order methods and circuit imbalances.  
  (called the M -vertex-stabilizer problem) is also eÔ¨Éciently solvable. The authors of [15] showed that both results generalize to weighted graphs. This paper focuses on Capacitated NBG, introduced by Bateni et al [2] as a generalization of NBG, to capture the more realistic scenario where players are allowed to enter in more than one deal. This generalization can be modeled by allowing for vertex capacities c ‚àà ZV‚â•0 . The notion of a matching is therefore generalized to a c-matching, where each vertex v ‚àà V is matched with at most cv vertices. In this case, the value of a maximum-weight c-matching of a graph G is denoted as ŒΩ c (G), and the standard LP relaxation is given by    c  xuv ‚â§ cv ‚àÄv ‚àà V, 0 ‚â§ x ‚â§ 1 . (2) ŒΩf (G) := max w x : u:uv‚ààE  
  An outcome to the NBG is associated with a c-matching M and a vector a ‚àà R2E ‚â•0 that satisÔ¨Åes auv + avu = wuv if uv ‚àà M , and auv = avu = 0 otherwise. The concepts of outside option and stable outcome can be deÔ¨Åned similarly as in the unit-capacity case, see [2]. The authors of [2] proved that the LP characterization of stable solutions generalize, i.e., there exist a stable outcome for the capacitated NBG on G if and only if ŒΩ c (G) = ŒΩfc (G) (i.e., G is stable). Farczadi et al [9] show that some other important properties of NBG extend to this capacitated generalization, such as the possibility to eÔ¨Éciently compute a so-called balanced solution (we refer to [9] for details). The goal of this paper is to investigate whether the other two signiÔ¨Åcant features of NBG mentioned before generalize to the capacitated setting. Namely: (i) Can one still eÔ¨Éciently stabilize instances via vertex-removal operations? (ii) Does the equivalence between existence of stable allocations for capacitated CMG and existence of stable solutions for capacitated NBG still hold? Our Results. In this paper we provide an answer to the above questions. We investigate the M -vertex-stabilizer problem and the vertex-stabilizer problem in the capacitated setting in Sects. 3 and 4, respectively. While for unit-capacity graphs both problems are eÔ¨Éciently solvable, we show that adding capacities makes the complexity status of the vertex-stabilizer problem diverge. In particular, we prove that the vertex-stabilizer problem is NP-complete, and no n1‚àíŒµ -approximation is possible, for any Œµ > 0, unless P=NP. Note that a trivial n-approximation algorithm can be easily developed. In contrast, we show that the M -vertex-stabilizer problem is still polynomialtime solvable in the capacitated setting. Our results here extend those of [15] for unit-capacity graphs, and builds upon an auxiliary construction of [9]. Finally, in Sect. 5 we show that the equivalence between stability of a graph, existence of a stable allocation for CMG and existence of a stable outcome for NBG does not extend in the capacitated setting. In particular, we provide an unstable graph which does attain a stable allocation for the capacitated CMG.1 1  
  It is stated in [8] (Theorem 2.3.9) that a stable allocation for capacitated CMG exists iÔ¨Ä G is stable, but our example shows this statement is not correct.  
  Preliminaries and Notation  
  Problem DeÔ¨Ånition. A set S ‚äÜ V is called a vertex-stabilizer if G \ S is stable, where G \ S is the subgraph induced by the vertices V \ S. We say that a vertex-stabilizer S preserves a matching M of G if M is a matching in G \ S. We now formally deÔ¨Åne the stabilization problems considered in this paper. Vertex-stabilizer Problem: given G = (V, E) with edge weights w ‚àà RE ‚â•0 and vertex capacities c ‚àà ZV‚â•0 , Ô¨Ånd a vertex-stabilizer of minimum cardinality. M -vertex-stabilizer Problem: given G = (V, E) with edge weights w ‚àà RE ‚â•0 , V vertex capacities c ‚àà Z‚â•0 , and a maximum-weight c-matching M , Ô¨Ånd a vertexstabilizer of minimum cardinality among the ones preserving M . An instance of the vertex-stabilizer problem will be denoted as (G, w, c). An instance of the M -vertex-stabilizer problem will be denoted as [(G, w, c), M ]. We say that an instance is stable if G is stable. Without loss of generality, we can assume that cv is bounded by the degree of v ‚àà V . Notation. For a vertex v, we let Œ¥(v) be the set of edges of G incident into it, we let N (v) be the set of its neighbours, and N + (v) = N (v) ‚à™ {v}. For F ‚äÜ E, we denote by dF v the degree of v in G with respect to the edges in F . We deÔ¨Åne w(F ) := e‚ààF we . Given a c-matching M , we say that v ‚àà V is exposed if = 0, and covered if dM for feasible solutions x dM v v > 0. We also use these terms  of (2), called fractional c-matchings, e.g., v is exposed if e‚ààŒ¥(v) xe = 0. We let n := |V |, and  denote the symmetric diÔ¨Äerence operator. We denote a (uv-)walk W by listing its edges and endpoints sequentially, i.e., by W = (u; e1 , . . . , ek ; v). We deÔ¨Åne its inverse as W ‚àí1 = (v; ek , . . . , e1 ; u). Note that a path is a walk in which edges do not repeat, and internal vertices do not repeat. A cycle is a path which starts and ends at the same vertex. If we refer to the edge set of a walk W , we just write W . Note that this can be a multi-set. Duality and Augmenting Structures. The dual of (2) is given by   œÑfc (G) := min c y + 1 z : yu + yv + zuv ‚â• wuv ‚àÄuv ‚àà E, y ‚â• 0, z ‚â• 0 .  
  (3)  
  (5)  
  Definition 5. An M -bi-cycle C ‚à™ P ‚à™ D consists of two M -blossoms C and D with bases u and v, respectively, and an M -alternating path P = (u; e1 , . . . , ek ; v) such that (P, D, P ‚àí1 , C) is M -alternating. The bi-cycle is M -augmenting if w(C \ M ) + 2w(P \ M ) + w(D \ M ) > w(C ‚à© M ) + 2w(P ‚à© M ) + w(D ‚à© M ). (6) Note that, in the last two deÔ¨Ånitions, it may happen that P has no edges. Auxiliary Construction. We will use a construction given in [9], to transform an M -vertex-stabilizer instance [(G, w, c), M ] into another one ([(G , w , 1), M  ]) deÔ¨Åned on an auxiliary graph with unit capacities. Construction: [(G, w, c), M ] ‚Üí [(G , w , 1), M  ] 1. For each v ‚àà V , create the set Cv = {v1 , . . . , vcv } of cv copies of v, add Cv to V (G ), and initialize J(v) = {1, . . . , cv }. 2. For each uv ‚àà M , add a single edge ui vj to both E(G ) and M  with edgeweight wuv , where i ‚àà J(u) and j ‚àà J(v) are chosen arbitrarily. Remove i and j from J(u) and J(v), respectively. 3. For each edge uv ‚àà E \ M , add an edge ui vj to E(G ) with edge-weight wuv , for all ui ‚àà Cu and vj ‚àà Cv . See Fig. 1 for an example. In this Ô¨Ågure it is easy to see that the matching M  in G is not maximum, even though M is maximum in G.2 Remark 2. If [(G, w, c), M ] has auxiliary [(G , w , 1), M  ], and X ‚äÜ V is any set of vertices which avoids M , then (G \ X) = G \ X  , where X  = ‚à™v‚ààX Cv . We deÔ¨Åne a map Œ∑ to go back from the auxiliary graph G to the original graph G. SpeciÔ¨Åcally, if ui ‚àà V (G ) ‚à© Cu for some u ‚àà V , then Œ∑(ui ) := u, and if ui vj ‚àà E(G ) such that ui ‚àà Cu , vj ‚àà Cv for some u, v ‚àà V , then Œ∑(ui vj ) := uv. This extends in the obvious way to paths, cycles, walks, and so on. We will need the following theorem. 2  
  It was stated in [9, corollary 1] that M is maximum if and only if M  is maximum, but this example shows this to be false.  
  M. Gerstbrein et al.  
  the given matching is not maximum, is not guaranteed to Ô¨Ånd an optimal solution, but only a 2-approximate one (see Theorem 12 in [15]). In addition, since the auxiliary construction splits a vertex into multiple ones, we may even get infeasible solutions. As a concrete example of this, the algorithm of [15] applied to the instance of Fig. 1b will include b2 in its proposed solution. Mapping this solution to our capacitated instance would imply to remove b, which is clearly not allowed as b is M -covered. To overtake this issue, we do not apply the algorithm of [15] as a black-box, but use parts of it (highlighted in Lemma 1) in a careful way. In particular, we use it to compute a sequence of feasible augmenting walks in G . We actually show that the walks in G which might create the issue described before when mapped backed to G, are the walks in which at least one edge of G is traversed more than once in opposite directions, and that have two distinct endpoints. When this happens, we prove that we can modify the walk and get one where the endpoints coincide, which will still be feasible and augmenting. In this latter case, we can then either correctly identify a vertex to remove (the unique endpoint), or determine that the instance cannot be stabilized. A More Detailed Description. We start by deÔ¨Åning the operation of traceback, which we will use to modify the feasible augmenting walks, when needed. Definition 6. Given [(G, w, c), M ] and an M -alternating walk P = (u; e1 , . . . , ek ; v) which repeats an edge in opposite directions, let t be the least index such that et = es for some s < t, and es and et are traversed in opposite directions by P . Then the u-traceback and v-traceback of P are deÔ¨Åned as the walks tb(P, u) = (e1 , . . . , et , es‚àí1 , es‚àí2 , . . . , e1 ) and tb(P, v) = (ek , ek‚àí1 . . . , es , et+1 , et+2 , . . . , ek ). The next lemma explains how to use the traceback operation. Due to space constraint, the proof is deferred to the full version of this extended abstract [10]. Lemma 3. Given [(G, w, c), M ] and auxiliary [(G , w , 1), M  ], let P  = (ui ; e1 , . . . , ek ; vj ) be a proper M  -augmenting path such that both ui and vj are M  exposed and Œ∑(ui ) = Œ∑(vj ). Then tb(Œ∑(P  ), Œ∑(ui )) and tb(Œ∑(P  ), Œ∑(vj )) are welldeÔ¨Åned, feasible M -alternating walks, and at least one of them is M -augmenting. Proof (Proof of Theorem 3). Let [(G, w, c), M ] be the input for the M -vertexstabilizer problem, with auxiliary [(G , w , 1), M  ]. Algorithm 1 iteratively considers an M  -exposed vertex ui , and computes a feasible M  -augmenting walk U starting at ui , if one exists. Lemma 2 implies that Œ∑(U ) is a feasible M augmenting walk in G. Theorem 2 implies that we need to remove at least one vertex of the walk Œ∑(U ) to stabilize the graph. Note that every vertex a = ui , vj of U is M  -covered, and hence, Œ∑(a) is M -covered. Therefore, the only vertices we can potentially remove are Œ∑(ui ) or Œ∑(vj ). Hence, if both Œ∑(ui ) and Œ∑(vj ) are M -covered, the graph cannot be stabilized and Algorithm 1 checks this in line 9. If only one among Œ∑(ui ) and Œ∑(vj ) is M -covered, then necessarily we have to remove the M -exposed vertex among the two. Algorithm 1 checks this in  
  Stabilization of Capacitated Matching Games  
  NP-hard, but admits a 2-approximation algorithm (we mentioned this in the strategy overview), which is best possible assuming Unique Game Conjecture. With a minor modiÔ¨Åcation of Algorithm 1, we can generalize this result to the capacitated setting. We state here the result, and refer to the full version of this extended abstract paper for details [10]. Theorem 4. Given a weighted, capacitated graph G = (V, E) and a c-matching M , the problem of computing a minimum-cardinality S ‚äÜ V such that G \ S is stable, and M is a maximum-weight c-matching in G \ S, admits an eÔ¨Écient 2-approximation algorithm.  
  4  
  O. Hanguir et al.  
  The next lemma shows that for 2 ‚â§ k ‚â§ m, the (k ‚àí 1)-dimensional faces of P are either (k ‚àí 1)-simplices of T , or (k ‚àí 2)-faces of T that were adjoined to the south pole. Lemma 5. For 2 ‚â§ k ‚â§ m, we have fk‚àí1 (P ) = gk‚àí1 (T ) + fk‚àí2 (T ). The previous lemma implies that gk‚àí1 (T ) = fk‚àí1 (P ) ‚àí fk‚àí2 (T ). Since P has n + 1 points, we know from the upper bound theorem that fk‚àí1 (P ) ‚â§ fk‚àí1 (C(n + 1, m)). Therefore, gk‚àí1 (T ) ‚â§ fk‚àí1 (C(n + 1, m)) ‚àí fk‚àí2 (T ), and all we need is a lower bound on fk‚àí2 (T ). The following lemma uses the lower bound theorem (Theorem 1.1, [10]) to establish a lower bound on fk‚àí2 (T ). The lower bound theorem presents a lower bound on the number of faces in every dimension among all polytopes of dimension d over p points, for d ‚â• 2 and p ‚â• 2. m Lemma 6. For 2 ‚â§ k ‚â§ m, we have gk‚àí1 (T ) ‚â§ fk‚àí1 (C(n + 1, m)) ‚àí k‚àí1 . See the full version of the paper to see how these lemmas come together to prove Theorem 1.  
  5  
  General Lower Bound (Proof of Theorem 2)  
  Throughout this section, we Ô¨Åx positive integers n > m ‚â• 4, and explicitly present designs (A, c) that have the number of k-loadouts promised in Theorem 2 for all k ‚â§ m. For m = 2 and m = 3, the exactly optimal designs are presented in the full version. All of the designs constructed in this paper will satisfy the property that A has linearly independent rows, hence we assume in the rest of this section that A is a full row rank matrix. 5.1  
  Construction Based on Moment Curve  
  Conclusion  
  We study the novel problem of diversity maximization. This problem can be motivated by the video game design context where designing for diversity is one of its core design philosophies. We model this diversity optimization problem as a parametric linear programming problem where we are interested in the diversity of supports of optimal solutions. Using this model, we establish upper bounds and construct designs that match this upper bound asymptotically. To our knowledge, this is the Ô¨Årst paper to systematically study the question of ‚Äúdiversity maximization‚Äù as we have deÔ¨Åned it here. The goal here is ‚Äúdiverse-in diverse-out‚Äù, if two players have right-hand resource vectors, they will optimally play diÔ¨Äerent strategies. We believe there could be other applications for ‚Äúdiverse-in diverse-out‚Äù optimization problems. Consider, for example, a diet problem where a variety of ingredients are used in the making of meals, depending on diÔ¨Äerent availability in resources. We leave this exploration for future work. There are also natural extensions to our model and analysis that could be pursued. For instance, we have studied the linear programming version of the problem. An obvious next step is the integer linear setting, which also arises naturally in the design of games. Just as in our analysis of the linear program, a deep understanding of the parametric nature of the integer optimization problems is necessary to proceed in the integer setting. [16] introduce a theory of reduced Gr¬® obner bases of toric ideals that play a role analogous to triangulations of cones. Another compelling extension would involve mixed -integer decision sets. This will require a deep appreciation of parametric mixed-integer linear programming, a topic that remains of keen interest in the integer programming community (see, for instance, [5,6]). Finally, another direction is to consider multiple objectives for the player. In our setting, we have assumed a single meaningful objective for the player, such as maximizing the damage of a loadout of weapons.  
  London School of Economics and Political Science, London, UK [email protected]  2 ETH Zurich, Zurich, Switzerland [email protected]   
  Abstract. This paper studies the expressive power of artiÔ¨Åcial neural networks with rectiÔ¨Åed linear units. In order to study them as a model of real-valued computation, we introduce the concept of Max-AÔ¨Éne Arithmetic Programs and show equivalence between them and neural networks concerning natural complexity measures. We then use this result to show that two fundamental combinatorial optimization problems can be solved with polynomial-size neural networks. First, we show that for any undirected graph with n nodes, there is a neural network (with Ô¨Åxed weights and biases) of size O(n3 ) that takes the edge weights as input and computes the value of a minimum spanning tree of the graph. Second, we show that for any directed graph with n nodes and m arcs, there is a neural network of size O(m2 n2 ) that takes the arc capacities as input and computes a maximum Ô¨Çow. Our results imply that these two problems can be solved with strongly polynomial time algorithms that solely uses aÔ¨Éne transformations and maxima computations, but no comparison-based branchings. Keywords: Neural Network Expressivity ¬∑ Strongly Polynomial Algorithms ¬∑ Minimum Spanning Tree Problem ¬∑ Maximum Flow Problem  
  1  
  Our Main Results  
  In order to make it easier to think about NNs in an algorithmic way, we introduce the pseudo-code language Max-AÔ¨Éne Arithmetic Programs (MAAPs). We show that MAAPs and NNs are equivalent (up to constant factors) concerning three basic complexity measures corresponding to depth, width, and overall size of NNs. Hence, MAAPs serve as a convenient tool for constructing NNs with bounded size and could be useful for further research about NN expressivity beyond the scope of this paper. We use this result to prove our two main theorems. The Ô¨Årst one shows that computing the value of a minimum spanning tree has polynomial complexity on NNs. The proof is based on a result from subtraction-free circuit complexity [17]. Theorem 1. For a Ô¨Åxed graph with n vertices, there exists an NN of depth O(n log n), width O(n2 ), and size O(n3 ) that correctly maps a vector of edge weights to the value of a minimum spanning tree. The second result shows that computing a maximum Ô¨Çow has polynomial complexity on NNs. Since all classical algorithms involve conditional branchings based on the comparison of real numbers, the proof involves the development of a new strongly polynomial maximum Ô¨Çow algorithm which avoids such branchings. While, in terms of standard running times, the algorithm is deÔ¨Ånitely not competitive with algorithms that exploit comparison-based branchings, it is of independent interest with respect to the structural understanding of Ô¨Çow problems. Theorem 2. Let G = (V, E) be a Ô¨Åxed directed graph with s, t ‚àà V , |V | = n, and |E| = m. There exists an NN of depth and size O(m2 n2 ) and width O(1) that correctly maps a vector of arc capacities to a vector of Ô¨Çow values in a maximum s-t-Ô¨Çow. Let us point out that in case of minimum spanning trees, the NN computes only the objective value, while for maximum Ô¨Çows, the NN computes the actual solution. There is a structural reason for this diÔ¨Äerence: Due to their continuous nature, ReLU NNs cannot compute a discrete solution vector, like an indicator vector of the optimal spanning tree, because inÔ¨Ånitesimal changes of the edge weights would lead to jumps in the output. For the Maximum Flow Problem, however, the optimal Ô¨Çow itself does indeed have a continuous dependence on the arc capacities. 1.2  
  Discussion of the Results  
  Before presenting our result in more detail, we discuss the signiÔ¨Åcance and limitations of our results from various perspectives. Due to space constraints, we refer to the full version for a more detailed discussion. Learning Theory. A standard approach to create a machine learning model usually contains the following two steps. The Ô¨Årst step is to Ô¨Åx a particular  
  Poly-Size ReLU Neural Networks for Maximum Flow Computation  
  Algorithms and Proof Overview  
  In this section we provide an intuitive overview of how we prove our results. The detailed proofs are deferred to the full version due to space constraints. Max-AÔ¨Éne Arithmetic Programs. For the purpose of algorithmic investigations of ReLU NNs, we introduce the pseudo-code language Max-AÔ¨Éne Arithmetic Programs (MAAPs). A MAAP operates on real-valued variables. The only operations allowed in a MAAP are computing maxima and aÔ¨Éne transformations of variables as well as parallel and sequential for loops with a Ô¨Åxed 2 number of iterations. In particular, no if branchings are allowed. With a MAAP A, we associate three complexity measures d(A), w(A), and s(A), which can easily be calculated from a MAAP‚Äôs description. The intuition behind these measures is that they correspond (up to constant factors) to the depth, width, and size of an NN computing the same function as the MAAP does. We formalize this intuition by proving the following proposition, which is similar to the transformation of circuits into straight-line programs in Boolean or arithmetic circuit complexity. Proposition 3. For a function f : Rn ‚Üí Rm the following is true. (i) If f can be computed by a MAAP A, then it can also be computed by an NN with depth d(A) + 1, width w(A), and size s(A). (ii) If f can be computed by an NN with depth d + 1, width w, and size s, then it can also be computed by a MAAP A with d(A) = d, w(A) = 2w, and s(A) = 4s. The proof of the proposition works by providing explicit constructions to convert a MAAP into an NN (part (i)), and vice versa (part (ii)) while taking care that the diÔ¨Äerent complexity measures translate respectively. The takeaway from this exercise is that for proving that NNs of a certain size can compute certain functions, it is suÔ¨Écient to develop an algorithm in the 2  
  In this context, Ô¨Åxed means that the number of iterations cannot depend on the speciÔ¨Åc instance. It can still depend on the size of the instance (e.g., the size of the graph in case of the two CO problems considered in this paper).  
  C. Hertrich and L. Sering  
  Algorithm 1: MSTn : Compute the value of a minimum spanning tree for the complete graph on n ‚â• 3 vertices. Input: Edge weights (xij )1‚â§i 0. However, we cannot recover the shortest s-t path with capacity ak,s . Therefore, in general, Ô¨Çow will not be sent along a single path and the value of the Ô¨Çow output by FindAugmentingFlowk might be strictly less than ak,s . After computing the ai,v values, FindAugmentingFlowk greedily pushes Ô¨Çow from s towards t, using a lexicographic selection rule to pick the next arc to push Ô¨Çow on (line 12 to 22). On the high level, this is similar to the preÔ¨Çow-push algorithm, but using the ai,v values that encode the shortest path distance information implicitly. This may leave some nodes with excess Ô¨Çow; a Ô¨Ånal cleanup phase (line 23 to 29) is needed to send the remaining Ô¨Çow back to the source s. An example for the FindAugmentingFlowk -subroutine is given in Fig. 3. We emphasize again that, although the description of the subroutine in the example in Fig. 3 seems to rely heavily on the distance of a node to t, this information is calculated and used only in an implicit way via the precomputed ai,v values. This way, we are able to implement the subroutine without the usage of comparisonbased branchings. The proof of correctness for our algorithm consists of two main steps. The Ô¨Årst step is the analysis of the subroutine. This involves carefully showing that the returned Ô¨Çow indeed satisÔ¨Åes Ô¨Çow conservation, is feasible with respect to the residual capacities, uses only arcs that lie on a s-t-path of length exactly k in the  
  Poly-Size ReLU Neural Networks for Maximum Flow Computation  
  S‚äÜE  
  Equivalently, fÀÜ(x) is the upper part of the convex hull of the graph of f ; we call it the concave extension following terminology of discrete convex analysis [20]. Agrawal, Ding, Saberi and Ye [2] introduced the correlation gap as the worst case ratio F (x) CG(f ) := min . (3) x‚àà[0,1]E fÀÜ(x) It bounds the maximum loss incurred in the expected value of f by ignoring correlations. This quantity plays a fundamental role in stochastic optimization [2, 22], mechanism design [7,18,28], prophet inequalities [11,15,24], and a variety of submodular optimization problems [3,12]. The focus of this paper is on weighted matroid rank functions. For a matroid M = (E, I) and a weight vector w ‚àà RE + , the corresponding weighted matroid rank function is given by rw (S) := max {w(T ) : T ‚äÜ S, T ‚àà I} . It is monotone nondecreasing and submodular. Recall that a function f : 2E ‚Üí R is monotone if f (X) ‚â§ f (Y ) for all X ‚äÜ Y ‚äÜ E, and submodular if f (X) + f (Y ) ‚â• f (X ‚à© Y ) + f (X ‚à™ Y ) for all X, Y ‚äÜ E. The correlation gap of a weighted matroid rank function has been identiÔ¨Åed as the performance guarantee in a range of approximation algorithms and mechanism design settings: Monotone Submodular Maximization. Calinescu et al. [8] considered the problem m of maximizing a sum of weighted matroid rank functions i=1 fi subject to a matroid constraint. Using an LP relaxation and pipage rounding [1], they gave a (1 ‚àí 1/e)-approximation algorithm. This was extended by Shioura [26] to the problem of maximizing a sum of monotone M  -concave functions [19]. In [9], a (1 ‚àí 1/e)-approximation algorithm was obtained for maximizing an arbitrary monotone submodular function subject to a matroid constraint. A fundamental special case of this model is the maximum coverage problem. Given m subsets Ei ‚äÜ E, the corresponding coverage function is deÔ¨Åned as this is a special case of maximizing f (S) = |{i ‚àà [m] : Ei ‚à© S = ‚àÖ}|. Note that  m a sum of matroid rank functions: f (S) = i=1 ri (S) where ri (S) is the rank function of a rank-1 uniform matroid with support Ei . Even for maximization under a cardinality constraint, there is no better than (1 ‚àí 1/e)-approximation for this problem unless P = N P (see Feige [16]). Recently, tight approximations have been established for the special case when the function values fi (S) are determined by the cardinality of the set S.  
  On the Correlation Gap of Matroids  
  Fig. 1. Our correlation gap bound as a function of the rank œÅ and girth Œ≥ separately.  
  The rank and girth have meaningful interpretations in the aforementioned applications. For instance, the problem of maximizing a sum of weighted consider m matroid rank functions i=1 fi under a matroid constraint (E, J ). For every i ‚àà [m], let Mi be the matroid of fi . In game-theoretic contexts, each fi usually represents the utility function of agent i. Thus, our goal is to select a bundle of items S ‚àà J which maximizes the total welfare. If Mi has girth Œ≥ and rank œÅ, this means that agent i is interested in Œ≥ ‚àí1 ‚â§ k ‚â§ œÅ items with positive weights. The special case œÅ = Œ≥ ‚àí 1 (uniform matroids) has already found applications in list decoding [6] and approval voting [14]. On the other hand, for sequential posted-price mechanisms, if the underlying matroid M has girth Œ≥ and rank œÅ, this means that the seller can service Œ≥ ‚àí 1 ‚â§ k ‚â§ œÅ agents simultaneously. To the best of our knowledge, our results give the Ô¨Årst improvement over the (1 ‚àí 1/e) bound on the correlation gap of general matroids. We hope that our paper will motivate further studies into more reÔ¨Åned correlation gap bounds, exploring the dependence on further matroid parameters, as well as obtaining tight bounds for special matroid classes. 1.1  
  Our Techniques  
  E. Husiƒá et al.  
  P. This implies that rÀÜw (x) = w x for any weights w ‚àà RE + . Moreover, we deduce that x(E) is integral. To prove Theorem 1, we Ô¨Åx a matroid M and derive a contradiction for a nonuniform weighting. More precisely, we consider a weighting w ‚àà RE + and a point rw (x‚àó ) < CG(r). By the above, we x‚àó ‚àà [0, 1]E which give a smaller ratio Rw (x‚àó )/ÀÜ rw (x‚àó ) = Rw (x‚àó )/w x‚àó . We pick w such that can use the simpler form Rw (x‚àó )/ÀÜ it has the smallest number of diÔ¨Äerent values. If the number of distinct values is at least 2, then we derive a contradiction by showing that a better solution can be obtained by increasing the weights in a carefully chosen value class until they coincide with the next smallest value. The greedy maximization property of matroids is essential for this argument. Uniform Matroids. Before outlining our proof of Theorem 2, let us revisit the correlation gap of uniform matroids. Let M = (E, I) be a uniform matroid on n elements with rank œÅ = r(E). If œÅ = 1, then it is easy to verify that the symmetric point x = (1/n) ¬∑ 1 realizes the correlation gap 1 ‚àí 1/e. Since x lies in the independent set polytope, we have rÀÜ(x) = 1 x = 1. If one samples each i ‚àà E with probability 1/n, the probability of selecting at least one element is R(x) = 1 ‚àí (1 ‚àí 1/n)n . Thus, CG(r) = 1 ‚àí (1 ‚àí 1/n)n , which converges to 1 ‚àí 1/e as n ‚Üí ‚àû. More generally, for œÅ ‚â• 1, Yan [28] showed that the symmetric point x = (œÅ/n) ¬∑ 1 similarly realizes the correlation gap 1 ‚àí e‚àíœÅ œÅœÅ /œÅ!. Poisson Clock Analysis. To obtain the (1 ‚àí 1/e) lower bound on the correlation gap of a monotone submodular function, Calinescu et al. [8] introduced an elegant probabilistic analysis. Instead of sampling each i ‚àà E with probability xi , they consider n independent Poisson clocks of rate xi that are active during the time interval [0, 1]. Every clock may send at most one signal from a Poisson process. Let Q(t) be the set of elements whose signal was sent between time 0 and t; the output is Q(1). It is easy to see that E[f (Q(1))] ‚â§ F (x). In [8], they show that the derivative of E[f (Q(t))] can be lower bounded as f ‚àó (x) ‚àí E[f (Q(t))] for every t ‚àà [0, 1], where   ‚àó fS (i)xi (4) f (x) := min f (S) + S‚äÜE  
  i‚ààE  
  is an extension of f such that f ‚àó ‚â• fÀÜ. The bound E[f (Q(1))] ‚â• (1 ‚àí 1/e)f ‚àó (x) is obtained by solving a diÔ¨Äerential inequality. Thus, F (x) ‚â• E[f (Q(1))] ‚â• (1 ‚àí 1/e)f ‚àó (x) ‚â• (1 ‚àí 1/e)fÀÜ(x) follows. A Two Stage Approach. If f is a matroid rank function, then f ‚àó = fÀÜ (see Theorem 3). Still, the factor (1 ‚àí 1/e) in the analysis of [8] cannot be improved: for an integer x ‚àà P, we lose a factor (1‚àí1/e) due to E[f (Q(1))] = (1‚àí1/e)F (x), even though the extensions coincide: F (x) = fÀÜ(x). Our analysis in Sect. 4 proceeds in two stages. Let M = (E, I) be a matroid with rank œÅ and girth Œ≥. The basic idea is that up to sets of size Œ≥ ‚àí 1, our  
  On the Correlation Gap of Matroids  
  matroid ‚Äòlooks like‚Äô a uniform matroid. Since the correlation gap of uniform matroids is well-understood, we Ô¨Årst extract a uniform matroid of rank Œ≥ ‚àí 1 from our matroid, and then analyze the contribution from the remaining part separately. More precisely, we decompose the rank function as r = g + h, where g(S) = min{|S|, } is the rank function of a uniform matroid of rank  = Œ≥ ‚àí 1. Note that the residual function h := f ‚àí g is not submodular in general, as h(S) = 0 for all |S| ‚â§ . We will lower bound the multilinear extensions G(x) and H(x) separately. As g is the rank function of a uniform matroid, similarly as above we can derive a tight lower bound on G in terms of its rank  = Œ≥ ‚àí 1. Bounding H(x) is based on a Poisson clock analysis as in [8], but is signiÔ¨Åcantly more involved. Due to the monotonicity of h, directly applying the result in [8] would yield E[h(Q(1)] ‚â• (1 ‚àí 1/e)h‚àó (x). However, h‚àó (x) = 0 whenever M is loopless ( ‚â• 1), as h(‚àÖ) = 0 and h({i}) = 0 for all i ‚àà E. So, the argument of [8] directly only leads to the trivial E[h(Q(1))] ‚â• 0. Nevertheless, one can still show that, conditioned on the event |Q(t)| ‚â• , the derivative of E[H(Q(t))] is at least r‚àó (x) ‚àí  ‚àí E[H(Q(t))]. Let T ‚â• 0 be the earliest time such that |Q(T )| ‚â• , which we call the activation time of Q. Then, solving a diÔ¨Äerential inequality produces E[h(Q(1))|T = t] ‚â• (1 ‚àí e‚àí(1‚àít) )(r‚àó (x) ‚àí ) for all t ‚â§ 1. To lower bound E[h(Q(1))], it is left to take the expectation over all possible 1 ¬Ø activation times T ‚àà [0, 1]. Let h(x) = (r‚àó (x) ‚àí ) 0 Pr[T = t](1 ‚àí e‚àí(1‚àít) )dt ¬Ø be the resulting expression. We prove that h(x) is concave in each direction ei ‚àí ej for i, j ‚àà E. This allows us to round x to an integer x ‚àà [0, 1]E such ¬Ø  ) ‚â§ h(x); ¬Ø recall that x(E) ‚àà Z by Theorem 4. that x (E) = x(E) and h(x ¬Ø After substantial simpliÔ¨Åcation of h(x ), we arrive at the formula in Theorem 2, except that œÅ is replaced by x(E). So, the rounding procedure eÔ¨Äectively shifts the dependency of the lower bound from the value of x to the value of x(E). Since x(E) ‚â§ œÅ by Theorem 4, the Ô¨Ånal step is to prove that the formula in Theorem 2 is monotone decreasing in œÅ.  
  2  
  Locating the Correlation Gap  
  In this section, given a weighted matroid rank function rw , we locate a point x‚àó ‚àà [0, 1]E on which the correlation gap CG(rw ) is realized, and derive some structural properties. Using this, we prove Theorem 1, i.e., the smallest correlation gap over all possible weightings is attained by uniform weights. We start with a more convenient characterization of the concave extension of rw . Lemma 2. Let M = (E, I) be a matroid with rank function r and weights E w ‚àà RE ÀÜw (x) = max{w y : y ‚àà P(r), y ‚â§ x}. + . For any x ‚àà [0, 1] , we have r Next, we show that x‚àó can be chosen to lie in the independent set polytope P(r); and that supp(x‚àó ) is a tight set w.r.t. x‚àó , meaning x‚àó (E) = r(supp(x‚àó )). Theorem 4. Let M = (E, I) be a matroid with rank function r. For any weights ‚àó ‚àó w ‚àà RE rw (x‚àó ) + \ {0}, there exists a point x ‚àà P(r) such that CG(rw ) = Rw (x )/ÀÜ ‚àó ‚àó and x (E) = r(supp(x )). Proof (of Theorem 1). For the purpose of contradiction, suppose that there exist ‚àó E such that Rw (x‚àó )/ÀÜ rw (x‚àó ) < CG(r). weights w ‚àà RE + and a point x ‚àà [0, 1] ‚àó According to Theorem 4, we may assume that x ‚àà P(r). Thus, rÀÜw (x‚àó ) = w x‚àó by Lemma 2. Let w1 > w2 > ¬∑ ¬∑ ¬∑ > wk ‚â• 0 denote the distinct values of w. For each i ‚àà [k], let Ei ‚äÜ E denote the set of elements with weight wi . Clearly, k ‚â• 2, as rw (x‚àó ) = w1 R(x‚àó )/(w1 x‚àó (E)) = R(x‚àó )/x‚àó (E) ‚â• CG(r). Let otherwise Rw (x‚àó )/ÀÜ us pick a counterexample with k minimal. First, we claim that wk > 0. Indeed, if the smallest weight is wk = 0, then Rw (x‚àó ) and rÀÜw (x‚àó ) remain unchanged after setting we ‚Üê w1 and x‚àóe ‚Üê 0 for all e ‚àà Ek ; this contradicts the minimal choice of k.  
  On the Correlation Gap of Matroids  
  Lower Bounding H(x‚àó )  
  Our analysis of H(x‚àó ) uses the Poisson clock setup of Calinescu et al. [8], which incrementally builds a set Q(1) as follows. Each element i ‚àà E is assigned a Poisson clock of rate x‚àói . We start all the clocks simultaneously at time t = 0, and begin with the initial set Q(0) = ‚àÖ. For t ‚àà [0, 1], if the clock on an element i rings at time t, then we add i to our current set Q(t). We stop at time t = 1. ‚àó Clearly, Pr(i ‚àà Q(1)) = 1 ‚àí e‚àíxi ‚â§ x‚àói for all i ‚àà E. Since h is monotone, ‚àó Proposition 1 yields H(x‚àó ) ‚â• H(1 ‚àí e‚àíx ) = E[h(Q(1))], where equality is due to independence of the Poisson clocks. So, it suÔ¨Éces to lower bound E[h(Q(1))]. Let t ‚àà [0, 1) and consider an inÔ¨Ånitesimally small interval [t, t + dt]. For each i ‚àà E, the probability of adding i during this interval is Pr(Poi(x‚àói dt) ‚â• 1) = x‚àói dt + O(dt2 ). Note that the probability of adding two or more elements is also O(dt2 ). Since dt is very small, we can eÔ¨Äectively neglect all O(dt2 ) terms. Definition 2. We say that Q is activated at time T if |Q(t)| <  for all t < T and |Q(t)| ‚â•  for all t ‚â• T . We call T the activation time of Q. Let S ‚äÜ E where |S| ‚â•  and let t ‚â• t ‚â• 0. Conditioning on the events Q(t) = S and T = t , the expected increase of h(Q(t)) (up to O(dt2 ) terms) is  rS (i)x‚àói dt ‚â• (Œª ‚àí  ‚àí h(S))dt, E[h(Q(t + dt)) ‚àí h(Q(t))|Q(t) = S ‚àß T = t ] = i‚ààE  
  On the Correlation Gap of Matroids  
  where the inequality is due to   h(S) + rS (i)x‚àói = r(S) ‚àí  + rS (i)x‚àói ‚â• r‚àó (x‚àó ) ‚àí  = rÀÜ(x‚àó ) ‚àí  = Œª ‚àí . i‚ààE  
  i‚ààE  
  The inequality follows from the deÔ¨Ånition of r‚àó in (4), the second equality is by Theorem 3, while the third equality is due to Lemma 2 because x‚àó ‚àà P(r). Dividing by dt and taking expectation over S, we obtain for all t ‚â• t ‚â• 0, 1 E[h(Q(t + dt)) ‚àí h(Q(t))|T = t ] ‚â• Œª ‚àí  ‚àí E[h(Q(t))|T = t ]. dt  
  (7)  
  Putting Everything Together  
  We are Ô¨Ånally ready to lower bound the correlation gap of the matroid rank function r. Recall that we assumed Œª >  in the previous subsection. Combining the lower bounds (6) and (12) gives us CG(r) =  
     ‚àí1 Œª G(x‚àó ) + H(x‚àó ) 1 e‚àíŒª  Œªi i + = 1 ‚àí ( ‚àí i) (e ‚àí 1) ‚àí . (13) i 1 x‚àó e Œª i=0 i!  
  Lemma 2. Let G = (V, E) be a k-regular k-edge-connected graph. Suppose either |V | = 3 or G has at least one proper min cut, and every proper min cut is crossed by some other proper min cut. Then, k is even and G forms a cycle, with k/2 parallel edges between each adjacent pair of vertices. We now deÔ¨Åne our class of instances. Definition 2 (Cycle cut instance). We say a graph G is a cycle cut instance if every non-singleton tight set S can be written as the union of two tight sets A, B = S. As mentioned in the introduction this condition captures the two known integrality gap examples of the subtour LP. We now show an equivalent deÔ¨Ånition of cycle cut instances after giving some deÔ¨Ånitions. First, Ô¨Åx an arbitrary root vertex r ‚àà V , and for all cuts we consider we will take the side which does not contain r. Definition 3 (Critical cuts). A critical cut is any tight set S ‚äÜ V {r} which does not cross any other tight set. Definition 4 (Hierarchy of critical cuts, H). Let H ‚äÜ 2V r be the set of all critical cuts. The hierarchy naturally gives rise to a parent-child relationship between sets as follows: Definition 5 (Child, parent, E ‚Üí (S)). Let S ‚àà H such that |S| ‚â• 2. Call the maximal sets C ‚àà H for which C ‚äÇ S the children of S, and call S their parent. Finally, deÔ¨Åne E ‚Üí (S) to be the set of edges with endpoints in two diÔ¨Äerent children of S. Definition 6 (Cycle cut, degree cut). Let S ‚àà H with |S| ‚â• 2. Then we call S a cycle cut if when G  S and all of the children of S are contracted, the resulting graph forms a cycle of length at least three with two parallel edges between each adjacent node. Otherwise, we call it a degree cut. While this deÔ¨Ånition of a cycle cut may sound specialized, due to Lemma 2, cycle cuts arise very naturally from collections of crossing min cuts. Lemma 3. If G is a cycle cut instance, then for any choice of r, H is composed only of cycle cuts (and singletons). One can also show that if for some choice of r, H is composed only of cycle cuts, then G is a cycle cut instance. Thus, in the remainder of the paper, we assume H is a collection of cycle cuts. Given S ‚àà H, let a0 = G  S and let a1 , . . . , ak be its children in H (which are either vertices or cycle cuts). By Lemma 2 a0 , . . . , ak can be arranged into a cycle such that two edges go between each adjacent vertex. WLOG let a1 , . . . , ak be in counterclockwise order starting from a0 . We call a1 the leftmost child of S and ak the rightmost child.  
  B. Jin et al.  
  Fig. 7. In our illustrations of the patterns entering a given cycle cut, any edge that is not present may either be unused or doubled. Therefore, all four of the given edge conÔ¨Ågurations are represented by the upper left most state, S1 .  
  and suppose (q1 , q2 , q3 , q4 ) is the resulting distribution after one transition of a Markov chain. What this means is that for each child of C, the distribution of patterns entering it will be either (q1 , q2 , q3 , q4 ) or (q2 , q1 , q3 , q4 ) depending on if the child is straight or twisted, respectively (see DeÔ¨Ånition 9 and Fig. 3). In particular, it can be shown that if (q1 , q2 , q3 , q4 ) is the distribution induced on a child which is a straight cycle cut, then (q2 , q1 , q3 , q4 ) would be the distribution induced on a child which is a twisted cycle cut. Thus, it is suÔ¨Écient to check that: i) the distributions induced on straight children lie in the feasible region and ii) if (q1 , q2 , q3 , q4 ) is a distribution induced on straight children, then (q2 , q1 , q3 , q4 ) is also in the feasible region. This corresponds to the set of distributions induced on the children being symmetric under this transformation.2  
  Sensitivity of Mechanisms  
  In this section, we study by how much the allocations for a Ô¨Åxed player may change under a slight modiÔ¨Åcation of the reported type. These changes are measured in the following two ways. For two localallocations a, b ‚àà {0, 1}m , let the cardinality distance be dc (a, b) := |a|1 ‚àí |b|1 , and let the Hamming distance be dh (a, b) := |a ‚àí b|1 , where | ¬∑ |1 is the 1-norm. Note that the cardinality distance is a pseudometric. Let f be an one-player allocation function, we deÔ¨Åne the cardinality sensitivity of f as    Œºc (f ) = max dc (a, b)  a, b ‚àà F for some F ‚àà I(f ) . The Hamming sensitivity Œºh (f ) arises in the same way, with dh instead of dc . Intuitively, the cardinality sensitivity Œºc (f ) is the maximal amount such that any slight change in the type of the player does not cause her allocated bundle to change its cardinality by more than Œºc (f ). Let Œ¶m be the set of truthful allocation functions for one player and m items. We are now interested in computing the values Mc (m) := minf ‚ààŒ¶m Œºc (f ) and Mh (m) := minf ‚ààŒ¶m Œºh (f ). Our strategy to compute these values is as follows. From Theorem 5 we know that the indiÔ¨Äerence complexes of allocation functions f ‚àà Œ¶m are in bijection with the regular subdivisions of [0, 1]m . So we need to identify those subdivisions, for which the maximal distance between any two vertices of one of its cells is minimized. In this way, we can compute Mc (m) exactly, and we give bounds for Mh (m). Proposition 11. The minimal cardinality sensitivity of DSIC one-player mechanisms is Mc (m) = 1. Proof. We Ô¨Årst slice the unit cube into the polytopes    m   m  Pk = x ‚àà [0, 1]  k ‚àí 1 ‚â§ xi ‚â§ k , k = 1, . . . , m .  i=1  
  The polytopes P1 , . . . , Pm form the maximal cells of a polytopal subdivision S m 2 of [0, 1]m . That subdivision is regular with height function Œª(x) = ‚àí ( i=1 xi ) . This proves the claim, as for each Pk , the diÔ¨Äerence in the coordinate sums of two of its vertices diÔ¨Äer by at most one.    
  Lx Proof sketch. Due to Lemma 3, it only remains to bound œÅL := supx‚ààRL xx  A . B Lx As described above, we can express œÅL as the largest eigenvalue of the matrix ZL , whose principal submatrix TL‚àí1 ‚àöis a tridiagonal Toeplitz matrix. This has ‚àí2/(b‚àí1) on the main diagonal and b/(b‚àí1) on both adjacent diagonals. We show value as the largest eigenthat the largest eigenvalue of ZL converges to the same ‚àö ‚àö ‚àí2 œÄ L‚Üí‚àû ‚àí2 + 2b‚àí1b ¬∑ cos L ‚àí‚àí‚àí‚àí‚Üí b‚àí1 + 2b‚àí1b . value of TL‚àí1 , which has the closed form b‚àí1 3/2   Therefore, we obtain by Lemma 3 that Db is 1 + 2b b‚àí1 -competitive. This ratio is minimized for b = 3, yielding the desired bound. For the tightness part, we deÔ¨Åne the vector xL ‚àà RL ‚â•0 by  
  ‚àí1  
  A. R. Karlin et al.  
  (1) The Ô¨Årst is that the vector m (whose cost upper bounds the cost of the minimum cost matching on the odd vertices of the tree) can be written as the (weighted) sum of indicators of events that depend on the sampled tree T , and each of these events happens only when a constant number of (not necessarily disjoint) sets of edges have certain parities or certain sizes. (2) The second is that the probability of any such event can be deterministically computed in polynomial time by evaluating the generating polynomial of all spanning trees at certain points in CE , see Lemma 10. Structure of the Paper. After reviewing some preliminaries, in Sect. 3 we review the matrix tree theorem and show (as a warmup) how to compute the probability two (not necessarily disjoint) sets of edges both have an even number of edges in the sampled tree. In Sect. 4, we then give a complete description and proof of a deterministic algorithm for the special ‚Äúdegree cut‚Äù case of TSP. Unlike the subsequent sections of the paper, Sect. 4 is self-contained and thus directed towards readers looking for more high-level intuition or those not familiar with [KKO21,KKO22]. In Sect. 5 we show (2) from above and give the deterministic algorithm in the general case. The remainder of the paper then involves proving (1) for the general deÔ¨Ånition of m from [KKO21,KKO22].  
  2 2.1  
  General Case  
  The matching vector m in the general case, [KKO22, Thm 6.1], can be written as s + s‚àó + 12 x where s, s‚àó are functions of the tree T ‚àº ŒºŒª and some independent Bernoullis B. Roughly speaking, the (slack) vector s‚àó : E ‚Üí R‚â•0 takes care of matching constraints for near minimum cuts that are crossed and the (slack) vector s : E ‚Üí R takes care of the constraints corresponding to cuts which are not crossed. Most importantly, the guarantee is that for a Ô¨Åxed tree T the expectation of c(s) + c(s‚àó ) + 12 c(x) over the Bernoullis is at least c(M ) where M is the minimum cost matching on the odd vertices of T . Furthermore, E [c(s) + c(s‚àó )] ‚â§ ‚àíc(x) which is the necessary bound to begin applying the method of conditional expectation in Algorithm 3. Remark 3. The deÔ¨Ånitions of s and s‚àó , the proof that E [c(s) + c(s‚àó )] ‚â§ ‚àíc(x), and the proof that x/2 + E [s + s‚àó | T ] is in the O(T )-join polyhedron come from [KKO21,KKO22]. Here, we will review how to construct the random slack vectors s, s‚àó for a given spanning tree T and then explain how to eÔ¨Éciently compute E [c(s) + c(s‚àó ) | Set] deterministically for any Set ‚àà Tpartial . Unfortunately, a reader who has not read [KKO21,KKO22] may not be able to understand the motivation behind the details of the construction of s, s‚àó . However, ?? and ?? are self-contained in the sense that a reader should be able to verify that E [c(s) + c(s‚àó ) | Set] can be computed eÔ¨Éciently and deterministically. Our theorem boils down to showing the following two lemmas: Lemma 9. For any Set ‚àà Tpartial , there is a polynomial time deterministic algorithm that computes: (1) ET ‚àºŒºŒª [c(s‚àó ) | Set] (shown in Ec(s‚àó ) (e, Set)) (2) ET ‚àºŒºŒª [c(s) | Set] (shown in Ec(s) (e, Set))  
  i=1  
  where the last equality uses that œâi is the mi ‚Äôth root of unity. The RHS is exactly equal to the probability that (Ei )S ‚â° œÉi mod mi for all i. Remark 4. When we apply this lemma in this paper, we will always let k be a constant and mi ‚â§ |V | for all i. Thus, it will always use a polynomial number of calls to an oracle evaluating the generating polynomial of a spanning tree distribution ŒºŒª . By Theorem 3, for any z ‚àà C|E| : gŒºŒª ({ze }e‚ààE ) =  
   1 det( Œªe ze Le + 11T /n), n e‚ààE  
  Relaxations with Primal Degeneracy  
  Up to now, we have made the convenient assumption that the relaxation P t is a simple polyhedron. More generally, there always exists a basis cone C t , such that a cut valid for P t is valid for C t . With Example 5, we illustrate the complication if Œ± ¬Ø T x ‚â• Œ≤¬Ø is supporting at a primal degenerate point of P t : a basis for that point needs to be chosen carefully, as the inequality may not be valid for some basis cones. It can be computationally involved to Ô¨Ånd a valid basis in these situations, which prevents a direct application of our approach relying on simple polyhedra. The purpose of this example is to highlight a crucial obstacle to a complete correspondence between PRLP and CGLP solutions, but we do not further investigate the nondegenerate case in this paper. Example 5. Figure 1 shows a polyhedron P , deÔ¨Åned as the feasible solutions to ‚àí(13/8)x1 ‚àí (1/4)x2 ‚àí x3 ‚â• ‚àí15/8 (1/2)x1 + x2 ‚â• 1/2 (1/2)x1 ‚àí x3 ‚â• ‚àí3/4 (1/2)x1 ‚àí x2 ‚â• ‚àí1/2 x2 ‚â• 0.  
  (c1) (c2) (c3) (c4) (c5)  
  Optimal General Factor Problem and Jump System Intersection Yusuke Kobayashi(B) Kyoto University, Kyoto, Japan [email protected]   
  Abstract. In the optimal general factor problem, given a graph G = (V, E) and a set B(v) ‚äÜ Z of integers for each v ‚àà V , we seek for an edge subset F of maximum cardinality subject to dF (v) ‚àà B(v) for v ‚àà V , where dF (v) denotes the number of edges in F incident to v. A recent crucial work by Dudycz and Paluch shows that this problem can be solved in polynomial time if each B(v) has no gap of length more than one. While their algorithm is very simple, its correctness proof is quite complicated. In this paper, we formulate the optimal general factor problem as the jump system intersection, and reveal when the algorithm by Dudycz and Paluch can be applied to this abstract form of the problem. By using this abstraction, we give another correctness proof of the algorithm, which is simpler than the original one. We also extend our result to the valuated case.  
  1 1.1  
  Jump System Intersection  
  In this paper, we introduce an abstract form of the optimal general factor problem by using the concept of jump systems introduced by Bouchet and Cunningham [2] (see also [9,17]). Let V be a Ô¨Ånite set. For x, y ‚àà ZV , we say that s ‚àà ZV is an (x, y)-step if s1 = 1 and (x + s) ‚àí y1 = x ‚àí y1 ‚àí 1. A non-empty subset J ‚äÜ ZV is called a jump system if it satisÔ¨Åes the following property: (JUMP) For any x, y ‚àà J and for any (x, y)-step s, either x + s ‚àà J or there exists an (x + s, y)-step t such that x + s + t ‚àà J. Typical examples of jump systems include matroids, delta-matroids, integral polymatroids (or submodular systems [7]), and degree sequences of subgraphs.  
  Optimal General Factor Problem and Jump System Intersection  
  Our Contribution: Jump System with SBO Property  
  A natural question is why the optimal general factor problem can be solved eÔ¨Éciently, while the general setting of Jump System Intersection is hard. In this paper, we answer this question by revealing the properties of J that are essential in the argument in [5]. For a positive integer , we denote {1, 2, . . . , } by []. For x, y ‚àà ZV , we say that a multiset {p1 , . . . , p } of vectors is a 2-step decomposition ofy ‚àí x if pi ‚àà ZV and pi 1 = 2 for each i ‚àà [], y ‚àí x1 = 2, and y ‚àí x = i‚àà[] pi . A non-empty subset J ‚äÜ ZV is called a jump system with SBO property1 if it satisÔ¨Åes the following property: (SBO-JUMP) For any x, y ‚àà J, there exists a 2-step decomposition {p1 , . . . , p } of y ‚àí x such that x + i‚ààI pi ‚àà J for any I ‚äÜ []. We can see that (SBO-JUMP) implies (JUMP). To see this, for given x, y ‚àà J, suppose that there exist vectors p1 , . . . , p ‚àà ZV satisfying the conditions in (SBO-JUMP). Then, for any (x, y)-step s, there exists an (x + s, y)-step t such that s + t = pi for some i ‚àà [], and hence x + s + t = x + pi ‚àà J. Therefore, if J is a jump system with SBO property, then it is a jump system such that v‚ààV x(v) has the same parity for any x ‚àà J, which is called a constant parity jump system. See [21] for a characterization of constant parity jump systems. We now give a few examples of jump systems with SBO property. 1  
  SBO stands for strongly base orderable (see Example 1).  
  The subproblem in (C3) is to Ô¨Ånd a maximum (a, b)-parity factor, which can be solved in polynomial time. Our proof for Theorem 1 is based on the argument of Dudycz and Paluch [5]. While their algorithm is very simple, the correctness proof is quite complicated. In particular, an involved case analysis is required to prove a key lemma [5, Lemma 2]. Our technical contribution in this paper is to give a new simpler proof of this lemma in a slightly diÔ¨Äerent form (Lemma 1). In our proof, we use several properties that are peculiar to our problem formulation (see Sect. 4.1), which is an advantage of introducing the abstract form of the optimal general factor problem. We also show that a scaling technique used in [5] is not required in the algorithm, which is another contribution of this paper. We also introduce a quantitative extension of (SBO-JUMP), and extend Theorem 1 to a valuated variant of Jump System Intersection; see Theorem 2. 1.4  
  Organization  
  The rest of this paper is organized as follows. Some preliminaries are given in Sect. 2. In Sect. 3, we describe our algorithm and prove its correctness by using a key technical lemma (Lemma 1). A proof of Lemma 1 is given in Sect. 4, where properties shown in Sect. 4.1 play important roles to simplify the argument. In Sect. 5, we extend our results to the valuated case and show that a polynomial-time algorithm for the weighted general factor problem is derived from our results. Proofs of theorems/lemmas marked with () are omitted due to the page limitation and given in the full version [10].  
  2  
  Preliminaries  
  Let V be a Ô¨Ånite set. For v ‚àà V , let œáv ‚àà ZV denote the characteristic vector of v, that is, œáv (v) = 1 and œáv (u) = 0 for u ‚àà V \ {v}. For each v ‚àà V , we are given a non-empty Ô¨Ånite set B(v) ‚äÜ Z that has no gap of length more than one, i.e., B(v) is a one-dimensional jump system. Throughout this paper, let B ‚äÜ ZV be the direct product of B(v)‚Äôs, i.e., B := {x ‚àà ZV | x(v) ‚àà B(v) for any v ‚àà V }. For x ‚àà ZV , we denote min B ‚â§ x ‚â§ max B if min B(v) ‚â§ x(v) ‚â§ max B(v) for every v ‚àà V . For x ‚àà ZV , we deÔ¨Åne q(x) = |{v ‚àà V | x(v) ‚àà B(v)}|. Note that, if min B ‚â§ x ‚â§ max B, then q(x) := miny‚ààB x ‚àí y1 , because each B(v) has no gap of length greater than one. Recall that a parity interval is a subset of Z that is of the form {Œ±, Œ± + 2, . . . , Œ≤ ‚àí 2, Œ≤}. For v ‚àà V , we see that B(v) is uniquely partitioned into inclusionwise maximal parity intervals (see Fig. 1), which we call maximal parity intervals of B(v). For Œ±, Œ≤ ‚àà Z with min B(v) ‚â§ Œ± ‚â§ Œ≤ ‚â§ max B(v), we deÔ¨Åne distB(v) (Œ±, Œ≤) as the number of maximal parity intervals of B(v) intersecting [Œ±, Œ≤] minus one. In other words, distB(v) (Œ±, Œ≤) is the number of pairs of consecutive integers in B(v) ‚à© [Œ±, Œ≤]. We also deÔ¨Åne  
  Algorithm and Correctness  
  Our algorithm for Jump System Intersection is basically the same as [5]. We Ô¨Årst initialize the vector x := x0 , where x0 is as in Condition (C1) in Theorem 1. In each iteration, we compute a vector x ‚àà J ‚à© B maximizing c x subject to distB (x, x ) ‚â§ 2. If c x = c x, then the algorithm terminates by returning x. Otherwise, we replace x with x and repeat the procedure. See Algorithm 1 for a pseudocode of the algorithm. In the correctness proof, we use the following key lemma, whose proof is given in Sect. 4. Note again that giving a simpler proof for this lemma is a technical contribution of this paper. Lemma 1. Let x, y ‚àà B be vectors with distB (x, y) = 4, let {p1 , . . . , p } be a 2-step decomposition of y ‚àí x,  and let wi ‚àà R for i ‚àà []. Then, there exists a set I ‚äÜ [] such that z := x + i‚ààI pi is contained in B, distB (x, z) = 2, and   i‚ààI wi ‚â• min{0, i‚àà[] wi }.  
  Optimal General Factor Problem and Jump System Intersection  
  Input: J, B, c, and x0 . Output: x ‚àà J ‚à© B maximizing c x. x ‚Üê x0 ; while true do Find a vector x ‚àà J ‚à© B maximizing c x subject to distB (x, x ) ‚â§ 2; if c x = c x then return x x ‚Üê x ;  
  Remark 1. In Lemma 1, the roles of x and y are symmetric by changing the signs of pi and wi , because I¬Ø := [] \ I satisÔ¨Åes the following:   ‚Äì x + i‚ààI pi = y + i‚ààI¬Ø(‚àípi ), ‚Äì  distB (x, z) = 2 ‚áê‚áí  z) = 2,and     distB (y, ‚áê‚áí ‚Äì w ‚â• min 0, w i i i‚ààI i‚àà[] i‚ààI¬Ø(‚àíwi ) ‚â• min 0, i‚àà[] (‚àíwi ) .  Let w ‚àà R be the vector consisting of wi ‚Äôs, and denote w(I) := i‚ààI wi for I ‚äÜ []. We next show the following lemma. Note that almost the same result is shown for degree sequences in [5, Lemma 1]. Lemma 2. Let k be a positive integer. Let x, y ‚àà B be vectors with distB (x, y) = 2k and let {p1 , . . . , p } be a 2-step decomposition of y ‚àíx. Then,  there exist index sets ‚àÖ = I0  I1  I2  ¬∑ ¬∑ ¬∑  Ik = [] such that zj := x + i‚ààIj pi is contained in B and distB (zj‚àí1 , zj ) = 2 for j ‚àà [k]. Proof. It suÔ¨Éces to construct I1 ‚äÜ [] satisfying the conditions, because I2 , I3 , . . . , Ik‚àí1 can be constructed in this order in the same way. By changing the direction of axes if necessary, we may assume that x(v) ‚â§ y(v) for every v ‚àà V . Then, each pi is equal to œáa + œáb for some a, b ‚àà V (possibly a = b). For z ‚àà ZV , we denote œÜ(z) := (distB (x, z), q(z)) ‚àà Z2‚â•0 . In order to construct I1 , we start with I := I0 = ‚àÖ and add an element one by one to I. During  the procedure, we keep œÜ(z) ‚àà {(0, 0), (0, 2), (1, 1), (2, 0)}, where z := x + i‚ààI pi . Note that œÜ(z) = (0, 0) when I is initialized to I0 . If œÜ(z) = (2, 0), then I1 := I clearly satisÔ¨Åes the conditions. Otherwise, it holds that œÜ(z) ‚àà {(0, 0), (0, 2), (1, 1)}. In this case, we show that there exists an index i ‚àà [] \ I such that œÜ(z + pi ) ‚àà {(0, 0), (0, 2), (1, 1), (2, 0)} by the following case analysis. ‚Äì Suppose that œÜ(z) = (0, 0). Let i be an arbitrary index in [] \ I. Then, pi = œáa + œáb for some a, b ‚àà V (possibly a = b). We see that œÜ(z + œáa ) ‚àà {(0, 1), (1, 0)}, and hence œÜ(z + pi ) = œÜ(z + œáa + œáb ) ‚àà {(0, 0), (0, 2), (1, 1), (2, 0)}. ‚Äì Suppose that œÜ(z) = (0, 2). Then, z + œáa + œáb ‚àà B for some distinct a, b ‚àà V such that z(a) < y(a) and z(b) < y(b). Let i be an index in [] \ I such that pi = œáa + œác for some c ‚àà V (possibly c = a or c = b). Then, we see that œÜ(z +œáa ) = (0, 1), and hence œÜ(z +pi ) = œÜ(z +œáa +œác ) ‚àà {(0, 0), (0, 2), (1, 1)}.  
  (c x‚àó ‚àí c x)|I1 | .   
  We also see that c x ‚â• c z1 , because z1 ‚àà J ‚à© B and distB (x, z1 ) ‚â§ 2. By ‚àó 1 combining these inequalities with |I1 | ‚â• 1 and  = x ‚àíx , we obtain c x ‚àí 2 2   ‚àó    c x ‚â• x‚àó ‚àíx 1 (c x ‚àí c x). This implies that the global optimality is guaranteed by the local optimality. Corollary 1. In an instance of Jump System Intersection with (C2), a feasible solution x ‚àà J ‚à© B maximizes c x if and only if c x ‚â• c x for any x ‚àà J ‚à© B with distB (x, x ) ‚â§ 2. We are now ready to prove the correctness of Algorithm 1. Proof (Proof of Theorem 1). We Ô¨Årst show that each iteration of Algorithm 1 runs in polynomial time. For x, x ‚àà B with distB (x, x ) ‚â§ 2, we see that x(v) and x (v) are contained in the same maximal parity interval of B(v) for any v ‚àà V except at most two elements. Thus, for x ‚àà B, {x ‚àà B | distB (x, x ) ‚â§ 2} can be partitioned into O(n2 ) sets, each of which is a direct product of parity intervals. Therefore, we can Ô¨Ånd a vector x ‚àà J ‚à© B maximizing c x subject to distB (x, x ) ‚â§ 2 by using the oracle in Condition (C3), O(n2 ) times. We next evaluate the number of iterations inthe algorithm. Let OPT be the optimal value of the problem and let Bsize := v‚ààV |B(v)|. Since J is a jump system with SBO property by Condition (C2), we can apply Lemma 3. By this lemma, if x is replaced with x in line 6 of Algorithm 1, then  
  2 1 OPT ‚àí c x ‚â§ 1 ‚àí ‚àó (OPT ‚àí c x) ‚â§ 1 ‚àí (OPT ‚àí c x), x ‚àí x1 Bsize 1 that is, the gap to the optimal value decreases by a factor of at most 1 ‚àí Bsize .  Therefore, by repeating this procedure O(Bsize log(OPT‚àíc x0 )) times, the algorithm terminates and returns an optimal solution. This shows that Algorithm 1 solves Jump System Intersection in polynomial time.    
  Y. Kobayashi  
  minimize the number of diÔ¨Äerent (pi , wi ) pairs. Such (x, y, (pi )i‚àà[] , w) is called a minimal counterexample. DeÔ¨Åne U ‚äÜ V as U := {v ‚àà V | distB(v) (x(v), y(v)) ‚â• 1}. By changing the direction of axes if necessary, we may assume that x(v) ‚â§ y(v) for every v ‚àà V . Then, each pi is equal to œáa +œáb for some a, b ‚àà V (possibly a = b). We show some properties of the minimal counterexample. Our argument becomes simpler with the aid of these properties. Lemma 4. For any i ‚àà [], pi = œáa + œáb for some a, b ‚àà U (possibly a = b). Consequently, x(v) = y(v) for all v ‚àà V \ U . Proof. Assume to the contrary that there exists i ‚àà [] such that pi = œáa + œác for some a ‚àà V and for some c ‚àà V \ U . Suppose that a = c, i.e., pi = 2œác . We consider a new instance by removing pi and replacing y with y ‚àí 2œác ‚àà B. By the minimality of the counterexample, the obtained instance has a solution I ‚äÜ [] \ {i}, which implies that w(I) ‚â• 0 or w(I) ‚â• w([] \ {i}). Then, I  := I is a solution of the original instance in the former case and I  := I ‚à™ {i} is a solution of the original instance in the latter case, which is a contradiction. Suppose next that a = c. Since distB(c) (x(c), y(c)) = 0 and x(c), y(c) ‚àà B(c), we see that x(c) and y(c) have the same parity. Thus, there exists i ‚àà [] \ {i} such that pi = œáb + œác for some b ‚àà V \ {c}. We merge pi and pi as follows: replace pi and pi with a new vector pi := œáa + œáb whose weight is wi + wi , and replace y with y ‚àí 2œác ‚àà B. By the minimality of the counterexample, the obtained instance has a solution I ‚äÜ ([] \ {i, i }) ‚à™ {i }. Then, we see that the set (I \ {i }) ‚à™ {i, i } if i ‚àà I,  I := I otherwise is a solution of the original instance, which is a contradiction.  
     
  Part of Case Analysis: |U | = 3  
  In this extended abstract, we only consider the case when |U | = 3. Let U = {v1 , v2 , v3 } such that distB(v1 ) (x(v1 ), y(v1 )) = distB(v2 ) (x(v2 ), y(v2 )) = 1 and distB(v3 ) (x(v3 ), y(v3 )) = 2. By Lemmas 4 and 5, for any i ‚àà [], either pi = œáa +œáb for some distinct a, b ‚àà U or pi = 2œáv3 . Since distB (x, z + )+distB (y, z + ) = 4, by changing the roles of x and y if necessary (see Remark 1), we may assume that distB (x, z + ) ‚â§ 2.2 Furthermore, since x ‚àí z + 1 is even, we see that distB (x, z + ) + q(z + ) is even. Therefore, the pair œÜ(z + ) := (distB (x, z + ), q(z + )) is one of the following: (0, 0), (0, 2), (1, 1), (1, 3), (2, 0), and (2, 2), where we note that q(z + ) ‚â§ |U | = 3. We derive a contradiction by considering each case separately. Case 1: œÜ(z + ) = (0, 0), (0, 2), (1, 1), or (2, 0). By Lemma 7, there exists an index set I ‚äÜ [] with I + ‚äÜ I such that  z := x + i‚ààI pi is contained in B and distB (x, z) = 2. Since wi ‚â§ 0 for each i ‚àà [] \ I, we obtain w(I) ‚â• w([]), and hence I is a solution of Lemma 1. This is a contradiction. Case 2: œÜ(z + ) = (1, 3). In this case, z + (v) ‚àà B(v) for v ‚àà U . Since z + (v1 ) = y(v1 ), there exists i ‚àà []\I + such that pi = œáv1 +œáu for some u ‚àà {v2 , v3 }. Since œÜ(z + +pi ) = (1, 1), + by Lemma  7, there exists an index set I ‚äÜ [] with I ‚à™ {i} ‚äÜ I such that z := x + j‚ààI pj is contained in B and distB (x, z) = 2. We see that such I is a solution of Lemma 1 in the same way as Case 1, which is a contradiction. 2  
   If we change the roles of x and y, then I ‚àí := {i ‚àà [] | wi < 0} and z ‚àí := y‚àí i‚ààI ‚àí pi + + + play the roles of I and z , respectively. We see that if distB (x, z ) ‚â• 3, then distB (y, z ‚àí ) ‚â§ distB (y, z + ) = 4 ‚àí distB (x, z + ) ‚â§ 1.  
  Y. Kobayashi  
  Case 3: œÜ(z + ) = (2, 2). Since q(z + ) = 2 and |U | = 3, at least one of z + (v1 ) ‚àà B(v1 ) and z + (v2 ) ‚àà B(v2 ) holds. By changing the roles of v1 and v2 if necessary, we may assume that z + (v1 ) ‚àà B(v1 ). Let v ‚àó ‚àà {v2 , v3 } be the other element such that z + (v ‚àó ) ‚àà B(v ‚àó ). Since z + (v1 ) = x(v1 ), there exists i1 ‚àà I + such that pi1 = œáv1 + œáu for some u ‚àà {v2 , v3 }. Similarly, since z + (v1 ) = y(v1 ), there exists i2 ‚àà [] \ I + such that pi2 = œáv1 + œáu for some u ‚àà {v2 , v3 }. By Observation 1, either pi1 = œáv1 + œáv‚àó or pi2 = œáv1 + œáv‚àó holds (Fig. 3). If pi1 = œáv1 + œáv‚àó , then I := I + \ {i1 } is a solution, because w(I) ‚â• 0, which is a contradiction; see Fig. 3 (left two). If pi2 = œáv1 + œáv‚àó , then I := I + ‚à™ {i2 } is a solution, because w(I) ‚â• w([]), which is a contradiction; see Fig. 3 (right two).  
  Fig. 3. Possible situations in Case 3. A blue edge (u, v) corresponds to an element i ‚àà [] \ I + with pi = œáu + œáv , a red dashed edge (u, v) corresponds to an element i ‚àà I + with pi = œáu + œáv , and a vertex v ‚àà V in a rectangle satisÔ¨Åes that z + (v) ‚àà B(v). (Color Ô¨Ågure online)  
  Extension to Valuated Problem  
  In this section, we consider a valuated version of Jump System Intersection. Valuated Jump System Intersection Input. A function f : J ‚Üí Z on a jump system J ‚äÜ ZV and a Ô¨Ånite onedimensional jump system B(v) ‚äÜ Z for each v ‚àà V . Problem. Find a vector x ‚àà J ‚à© B maximizing f (x), where B ‚äÜ ZV is the direct product of B(v)‚Äôs. Note that f and J may be given in an implicit way, e.g., by an oracle. To simplify the notation, we extend the domain of f to ZV by setting f (x) = ‚àí‚àû for x ‚àà ZV \ J. The following property is a quantitative extension of (SBO-JUMP). (SBO-M-JUMP) For any x, y ‚àà J, there exist real values  g1 , . . . , g and a2-step such that f (x+ i‚ààI pi ) ‚â• f (x)+ i‚ààI gi decomposition {p1 , . . . , p } of y ‚àíx for any I ‚äÜ [] and f (y) = f (x) + i‚àà[] gi . Note that we use ‚ÄúM‚Äù in the name of the exchange axiom, because it deÔ¨Ånes a subclass of M-concave functions on constant parity jump systems [21]; see Remark 2 below. We can see that if f satisÔ¨Åes (SBO-M-JUMP), then its eÔ¨Äective domain J := {x ‚àà ZV | f (x) > ‚àí‚àû} satisÔ¨Åes (SBO-JUMP). By using (SBO-MJUMP), we generalize Theorem 1 as follows.  
  Optimal General Factor Problem and Jump System Intersection  
  Motivation  
  A natural application for feasible decompositions in the setting described above lies in network security games; see, e.g., [1‚Äì3,8,16,17] for various examples and applications of network security games. In fact, such a game was also the motivation of Dahan, Amin, and Jaillet [3], who originally introduced the decomposition setting described above. We will discuss their game in detail in Sect. 5. Here, we describe a simpler yet relevant problem as an illustrative example. Consider the following game played on a set system (E, P), where each element e ‚àà E is equipped with a usage cost ce ‚â• 0 and an inspection cost de ‚â• 0. A defender D determines a random subset S of elements from E to inspect at  cost e‚ààS de (e.g., a set of links of a network at which passing traÔ¨Éc is monitored). She anticipates that an attacker A is planning to carry out an illegal action, where A chooses a set in P ‚àà P (e.g., a route in the network  along which he smuggles contraband), for which he will receive utility U1 ‚àí e‚ààP ce for some constant U1 > 0. However, if P intersects with the random set S of elements inspected by D, then A is discovered while carrying out his illegal action, reducing his utility by a penalty U2 ‚â• U1 . The attacker also has the option to not carry out any attack, resulting in utility 0. Thus, A will  refrain from using P ‚àà P if the probability that S ‚à© P = ‚àÖ exceeds œÄP := (U1 ‚àí e‚ààP ce )/U2 . A natural goal for D is to discourage A from attempting any attack at all, while keeping the incurred inspection cost as small as possible. Note that the randomized  that achieve this goal correspond exactly to vectors x that strategies minimize S‚äÜE e‚ààS de xS subject to constraints (2) to (4). Unfortunately, the corresponding LP has both an exponential number of variables and an exponential number of constraints in the size of the ground set E. However, assume that we can establish the following three properties for our set system: (i) condition () is suÔ¨Écient for the feasibility of marginals, (ii) we can eÔ¨Éciently compute the corresponding feasible decompositions, and  Œ≥ . Then (i)allows us (iii) given Œ≥ ‚àà RE e + , we can eÔ¨Éciently solve minP ‚ààP e‚ààP to formulate D‚Äôs problem in terms of the marginals, i.e., minœÅ‚àà[0,1]E e‚ààE de œÅe subject to constraints (), (iii) allows us to separate the linear constraints () and obtain optimal marginals œÅ, and (ii) allows us to turn these marginals into a distribution corresponding to an optimal inspection strategy for the defender D. In this paper, we will establish all three conditions for a generic type of set systems called abstract networks.  
  [e, P ] := {p ‚àà P : e P p} (e, P ) := {p ‚àà P : e ‚â∫P p}  
  For any path P ‚àà P, we further denote the minimal and maximal element of P with respect to P by sP and tP , respectively. Throughout the paper, proofs of results marked with () can be found in the full version [13].  
  2  
  Special Case: Directed Graphs. Consider the case where P is the set of simple s-t-paths in a digraph D = (V, A) and E = V ‚à™ A. For v ‚àà V , let Psv denote the set of simple s-v-paths in D. If we are given explicit access to D (rather than accessing P via a membership oracle), we can compute feasible decompositions as follows. Without loss of generality, we can assume that for any v ‚àà V and Q ‚àà Psv there is Q ‚àà Pst with Q ‚äÜ Q .2 Then Œ±v = minQ‚ààPsv f ‚ààQ\{v} Œºf +œÅf  for v ‚àà V and Œ±a = minQ‚ààPsv f ‚ààQ Œºf + œÅf for a = (v, w) ‚àà A. Hence, the vector Œ± corresponds to shortest-path distances in D with respect to œÅ + Œº (with costs on both arcs and nodes). Both Œ± and the corresponding feasible decomposition of œÅ can be computed by a single run of Dijkstra‚Äôs [4] algorithm. Computing feasible decompositions in the general case of arbitrary abstract networks is more involved. We show how this can be achieved in Sect. 3. Proof of Theorem 1. We show that x as constructed in Theorem 1 is a feasible decomposition. Note that  x fulÔ¨Ålls (3) and (4) by construction. Note further that x fulÔ¨Ålls (1) because S‚äÜE:e‚ààS xS = Pr [e ‚àà SœÑ ] = Pr [Œ±e ‚â§ œÑ < Œ±e + œÅe ] = œÅe for all e ‚àà E, where the second identity follows from 0 ‚â§ Œ±e ‚â§ 1 ‚àí œÅe . It remains to prove that x fulÔ¨Ålls (2). The following lemma will be helpful in this endeavour. Lemma 2. Given (E, P), œÅ, Œº, and Œ± as described in Theorem 1, the following two conditions are fulÔ¨Ålled for every P ‚àà P: 1. Œ±tP + ŒºtP + œÅtP ‚â• 1 and 2. for every e ‚àà P \ {tP } there is e ‚àà (e, P ) with Œ±e ‚â§ Œ±e + Œºe + œÅe . Proof. We Ô¨Årst show statement 1. By contradiction assume Œ±tP + ŒºtP + œÅtP < 1. Let Q ‚àà P with tP ‚àà Q and f ‚àà(Q,tP ) Œºf + œÅf = Œ±tP and let R := Q √ótP P .  Note  tP ] and hence e‚ààR Œºe + œÅe ‚â§ Œ±tP + ŒºtP + œÅtP < 1, implying  that R ‚äÜ [Q, e‚ààR œÅe < 1 ‚àí e‚ààR Œºe , a contradiction to (). We now turn to statement 2. If Œ±e ‚â• 1 ‚àí Œºe ‚àí œÅe , then the statement follows with e = tP because Œ±tP‚â§ 1 ‚â§ Œ±e + Œºe + œÅe . Thus assume Œ±e < 1 ‚àí Œºe ‚àí œÅe and let Q ‚àà P with Œ±e = f ‚àà(Q,e) Œºf + œÅf . Let R := Q √óe P . By () we observe  that f ‚ààR Œºf + œÅf ‚â• 1 > Œ±e + Œºe + œÅe , which implies R \ [Q, e] = ‚àÖ because Œº, œÅ ‚â• 0. Thus, let e ‚àà R \ [Q, e] be minimal with respect to ‚â∫R . Observe that R \ [Q, e] ‚äÜ (e, P ) and hence e ‚àà (e, P ). The statement then follows from   Œ±e ‚â§ f ‚àà(R,e ) Œºf + œÅf ‚â§ f ‚àà[Q,e] Œºf + œÅf = Œ±e + Œºe + œÅe , where the second inequality is due to the fact that (R, e ) ‚äÜ [Q, e] by choice of  e and the fact that Œº, œÅ ‚â• 0. With the help of Lemma 2, we can prove that x fulÔ¨Ålls (2) as follows. Let P ‚àà P. For e ‚àà P deÔ¨Åne  Œºf . œÜ(e) := Pr [SœÑ ‚à© [P, e] = ‚àÖ ‚àß œÑ ‚â§ Œ±e + œÅe ] + f ‚àà[P,e] 2  
  This can be ensured by introducing arcs (v, t) with Œº(v,t) = 1 and œÅ(v,t) = 0 for all v ‚àà V \ {t}. Note that this does not change the set of feasible decompositions of œÅ.  
  Other Set Systems  
  The results in this paper lead to the question whether suÔ¨Éciency of () and computability of feasible decompositions can be established for other set systems, beyond abstract networks. We give negative answers for several natural candidates of such systems and point out interesting questions for future research. SuÔ¨Éciency of () (). There are simple counterexamples for the suÔ¨Éciency of () in the following cases, even when assuming that œÄ ‚â° 1: when P is the set of bases of a matroid; when P is the set of perfect matchings in a bipartite graph; when P is the set of si -ti -paths in a digraph with multiple terminal pairs (si , ti ). An interesting question in this context is whether we can describe the systems for which () is suÔ¨Écient by means of forbidden substructures. Approximately Feasible Decompositions (). Given the non-existence result mentioned above, one may be interested in Ô¨Ånding decompositions that satisfy the requirements at least approximately. We say a decomposition x of marginals œÅ is Œ≤-approximately feasible, for Œ≤ ‚àà [0, 1], if it fulÔ¨Ålls (1), (3), (4)  and S‚äÜE:S‚à©P =‚àÖ xS ‚â• Œ≤ ¬∑ œÄP for all P ‚àà P. Indeed, if marginals œÅ fulÔ¨Åll () for requirements œÄ, a (1 ‚àí 1/e)-approximately feasible decomposition always exists: Simply include each element e ‚àà E in the random set independently with probability œÅe . An interesting question for future research is whether better guarantees may be achieved for some classes of systems. Computing Feasible Decompositions and Optimization (). For a given instance, we may also be interested in Ô¨Ånding a decomposition of the given marginals that is Œ≤-approximately feasible for the largest possible value of Œ≤. Note that this also includes the case of Ô¨Ånding a feasible decomposition if it exists (resulting in Œ≤ = 1). Unfortunately, this latter problem is NP-complete, even in quite restricted cases, as evidenced by the theorem below. However, note that this hardness result still leaves room for approximating the best possible Œ≤. Theorem 9 (). The following decision problem is NP-complete: Given a set system (E, P) with |P | = 3 for all P ‚àà P and marginals œÅ ‚àà [0, 1]E , is there a feasible decomposition of œÅ for (E, P) and requirement vector œÄ ‚â° 1? Acknowledgements. The author thanks three anonymous reviewers for numerous helpful suggestions that improved the manuscript. This work has been supported by the special research fund of KU Leuven (project C14/22/026).  
  N. Megow and J. Schl√∂ter  
  as well as its value by using a minimal number of queries. It can be seen as an integer linear program (ILP) with uncertainty in the coeÔ¨Écients of the objective function:  m min j=1 xj Ii ‚ààSj wi m (1) s.t. j=1 xj = 1 ‚àà {0, 1} ‚àÄj ‚àà {1, . . . , m}. xj Since the wi ‚Äôs are uncertain, we might have to execute queries to determine an optimal solution to (1). We refer to this problem as MinSet under uncertainty. In this paper, we consider the stochastic problem variant, where all values wi are drawn independently at random from their intervals Ii according to unknown distributions di . As there are instances that cannot be solved without querying the entire input, we analyze an algorithm ALG in terms of its competitive ratio: for the set of problem instances J , it is deÔ¨Åned as maxJ‚ààJ E[ALG(J)]/E[OPT(J)], where ALG(J) is the number of queries needed by ALG to solve instance J, and OPT(J) is the minimum number of queries necessary to solve the instance. MinSet is a fundamental problem and of intrinsic importance within the Ô¨Åeld of explorable uncertainty. The majority of existing works considers the adversarial setting, where query outcomes are not stochastic but returned in a worst-case manner. Selection type problems have been studied in the adversarial setting and constant (matching) upper and lower bounds are known, e.g., for selecting the minimum [19], the k-th smallest element [13,19], a minimum spanning tree [10,12,18,23], sorting [17] and geometric problems [5]. However, these problems essentially boil down to comparing single uncertainty intervals and identifying the minimum of two unknown values. Once we have to compare two (even disjoint) sets and the corresponding sums of unknown values, no deterministic algorithm can have a better adversarial competitive ratio than n, the number of uncertainty intervals. This has been shown by Erlebach et al. [11] for MinSet, and it implies strong adversarial lower bounds for classical combinatorial problems, such as, knapsack and matchings [25], as well as solving ILPs with uncertainty in the cost coeÔ¨Écients as in (1) [25]. As a main result, we provide substantially better algorithms for MinSet under stochastic uncertainty. This is a key step for breaching adversarial lower bounds for a wide range of problems. For the stochastic setting, the only related results we are aware of concern sorting [6] and the problem of Ô¨Ånding the minimum in each set of a given collection of sets [2]. Asking for the sum of unknown values is substantially diÔ¨Äerent. The Covering Point of View. Our key observation is that we can view MinSet as a covering problem with uncertainty in the constraints. To see this, we focus on the structure of the uncertainty intervals and how a query aÔ¨Äects it. We assume that each interval Ii ‚àà I is either open (non-trivial ) or trivial, i.e., Ii = (Li , Ui ) or Ii = {wi }; a standard technical assumption in explorable uncertainty. In the latter case, Li = Ui = wi . We call Li and Ui lower  and upper limit. For a set S ‚àà S,  we deÔ¨Åne the initial lower limit LS = Ii ‚ààS Li and initial upper limit US = Ii ‚ààS Ui . Clearly, w(S) ‚àà (LS , US ). As the intervals (LS , US ) of the sets S ‚àà S can overlap, we might have to execute queries to determine the set of minimum value. A query to an interval  
  Set Selection Under Explorable Stochastic Uncertainty  
  Ii reveals the precise value wi and, thus, replaces both, Li and Ui , with wi . In a sense, a query to an Ii ‚àà S reduces the range (LS , US ) in which w(S) might lie by increasing LS by wi ‚àí Li and decreasing US by Ui ‚àí wi . Let LS (Q) and US (Q) denote the limits of set S after querying a set of intervals Q ‚äÜ I. For a MinSet instance (I, S), let w‚àó = minS‚ààS w(S) be the initially uncertain minimum set value. To solve the problem, we have to adaptively query a set of intervals Q until US ‚àó (Q) = LS ‚àó (Q) = w‚àó holds for some S ‚àó ‚àà S and LS (Q) ‚â• w‚àó holds for all S ‚àà S. Only then, we know for sure that w‚àó is indeed the minimum set value and that S ‚àó achieves this value. The following ILP with ai = wi ‚àí Li for all Ii ‚àà I and bS = w‚àó ‚àí LS for all S ‚àà S formulates this problem:  min Ii ‚ààI xi s.t. (MinSetIP) Ii ‚ààS xi ¬∑ ai ‚â• bS ‚àÄS ‚àà S xi ‚àà {0, 1} ‚àÄIi ‚àà I Observe that this ILP is a special case of the multiset multicover problem (see, e.g., [26]). If ai = wi ‚àí Li = 1 for all Ii ‚àà I and bS = w‚àó ‚àí LS = 1 for all S ‚àà S, then the problem is exactly the classical SetCover problem with I corresponding to the SetCover sets and S corresponding to the SetCover elements. The optimal solution to (MinSetIP) is the optimal query set for the corresponding MinSet instance. Under uncertainty however, the coeÔ¨Écients ai = wi ‚àí Li and right-hand sides bS = w‚àó ‚àí LS are unknown. We only know that ai ‚àà (Li ‚àí Li , Ui ‚àí Li ) = (0, Ui ‚àí Li ) as ai = (wi ‚àí Li ) and wi ‚àà (Li , Ui ). In a sense, to solve MinSet under uncertainty, we have to solve (MinSetIP) with uncertainty in the coeÔ¨Écients and irrevocable decisions. For the rest of the paper, we interpret MinSet under uncertainty in exactly that way: We have to solve (MinSetIP) without knowing the coeÔ¨Écients in the constraints. Whenever we irrevocably add an interval Ii to our solution (i.e., set xi to 1), the information on the coeÔ¨Écients (in form of wi ) is revealed. Our goal is to add elements to our solution until it becomes feasible for (MinSetIP), and to minimize the number of added elements. In this interpretation, the terms ‚Äúquerying an element‚Äù and ‚Äúadding it to the solution‚Äù are interchangeable, and we use them as such. Our main contribution is an algorithmic framework that exploits techniques for classical covering problems and adapts them to handle uncertainty in the coeÔ¨Écients ai and the right-hand sides bS . This framework allows us to obtain improved results for MinSet under uncertainty and other covering problems. Our Results. We design a polynomial-time algorithm for MinSet under stochastic uncertainty with competitive ratio O( œÑ1 ¬∑ log2 m), where m is the number of sets (number of constraints in (MinSetIP)) and parameter œÑ characterizes how ‚Äúbalanced‚Äù the distributions of values within the given intervals are. More precisely, œÑ = minIi ‚ààI œÑi and œÑi is the probability that wi is larger than the center of Ii (e.g., for uniform distributions œÑ = 12 ). This is the Ô¨Årst stochastic result in explorable uncertainty concerning the sum of unknown values and it builds on new methods that shall be useful for solving more general problems in this  
  Œ≤‚ààI  
  where the Ô¨Årst equality follow from Œ≤ ‚àà Dm and Œì (Œ≤) ‚àà Dn . Due to the nonexpansiveness of Œì , every summand is non-negative. Since the sum is 0, every   summand must be 0. As ŒªŒ≤ > 0, we conclude that Œì (Œ≤) Œì (Œ≤) = Œ≤  Œ≤.  
  (6)  
  where Œì ‚àà Dn will be chosen in Claim 1 so that Œì (Œ≤) Œì = 0. Using this property, the inclusion Œ≤ ‚àà Dm and Œì , Œì (Œ≤) ‚àà Dn , we see that (xt , yt ) ‚àà Q. Consider a bounded sequence of inequalities Œ≥ t x ‚àí Œ±t y ‚â• 0, where t ‚àà N, that are satisÔ¨Åed by points in CŒì and such that 0 ‚â• Œ≥ t xt ‚àí Œ±t yt . By the Farkas Lemma, there exist numbers ŒªŒ≤,t ‚â• 0 for each Œ≤ ‚àà I such that  (Œ≥ t , Œ±t ) = Œ≤‚ààI ŒªŒ≤,t (Œì (Œ≤), Œ≤). (7) After normalizing (Œ≥ t , Œ±t ), we may assume (Œ≥ t , Œ±t ) = (Œì (Œ≤), Œ≤) for all t. Furthermore, according to Carath¬¥eodory‚Äôs theorem we may assume that for each t the set {(Œì (Œ≤), Œ≤) : ŒªŒ≤,t > 0} is linearly independent. Consequently, there exists œÑ > 0 such that ŒªŒ≤,t ‚â§ œÑ for each Œ≤ ‚àà I and t ‚àà N. In order to demonstrate that ((xt , yt ))‚àû t=1 is an exposing sequence, we prove  limt‚Üí‚àû Œ≤‚ààI ŒªŒ≤,t (Œì (Œ≤), Œ≤) = (Œì (Œ≤), Œ≤). To this end, it suÔ¨Éces to prove limt‚Üí‚àû ŒªŒ≤,t = 0 for each Œ≤ ‚àà I \ {Œ≤}. We will choose Œì so that this condition is met. Note that ‚àö    0 ‚â• Œ≥ t xt ‚àíŒ±t yt = Œ≤‚ààI ŒªŒ≤,t (Œì (Œ≤) Œì (Œ≤)‚àíŒ≤  Œ≤)+ 2t+1 Œì  Œì (Œ≤)‚àí 1t Œ≤  Œ≤ . t Multiplying through by t, we have   ‚àö  0 ‚â• Œ≤‚ààI ŒªŒ≤,t t(Œì (Œ≤) Œì (Œ≤) ‚àí Œ≤  Œ≤) + 2t + 1 Œì  Œì (Œ≤) ‚àí Œ≤  Œ≤ .  
  (8)  
  = Œì (Œ≤)2 = 1.  
  Using the isometry with Œ≤ and each Œ≤ ‚àà H, we then have      Œ≤ =  Œ≤ Œ≤‚ààH Œ≤ Œ≤ Œ≤ = Œ≤‚ààH Œ≤ Œì (Œ≤) Œì (Œ≤) = Œì (Œ≤) Œì (Œ≤) = 1.   Œ≤| ‚â§ Œ≤Œ≤  Thus, we have equality in the Cauchy-Schwarz inequality |Œ≤ ‚â§ 1,  1   so Œ≤ = Œ≤ . Thus, (Œì (Œ≤), Œ≤) = Œ≤‚ààH Œ≤ (Œì (Œ≤), Œ≤) contradicting that Œì (Œ≤) x ‚àí Œ≤  y ‚â• 0 deÔ¨Ånes a facet of CŒì . Choose Œì ‚àà Dn according to Claim 1. For each t ‚àà N, we have   ‚àö ŒªŒ≤,t t(Œì (Œ≤) Œì (Œ≤) ‚àí Œ≤  Œ≤) + 2t + 1 Œì  Œì (Œ≤) ‚àí Œ≤  Œ≤ = ‚àíŒªŒ≤,t ‚â• ‚àíœÑ. Together with (8), this implies   ‚àö  0 ‚â• ‚àíœÑ + Œ≤‚ààI\{Œ≤} ŒªŒ≤,t t(Œì (Œ≤) Œì (Œ≤) ‚àí Œ≤  Œ≤) + 2t + 1 Œì  Œì (Œ≤) ‚àí Œ≤  Œ≤ . (9) For Œ≤ ‚àà I \ {Œ≤}, if ŒªŒ≤,t does not go to 0 as t tends to ‚àû, then Claim 1 implies that the righthand side of (9) will go to ‚àû, which is a contradiction. Hence, (7) tends to (Œì (Œ≤), Œ≤) as t tends to ‚àû.   Remark 2. As we mentioned in Section 1.1, we conjecture that Theorem 3 is generalizable to a set CŒì that is not necessarily a polyhedron. With this in mind, a natural question is how reliant on polyhedrality the proof of this section is. Various points of the proof can be adapted to handle a non-polyhedral case: for example, a similar expression to (7) can be obtained for an inÔ¨Ånite I. However, one the key steps that heavily uses Ô¨Åniteness is the construction of Œì using a strict separating hyperplane in Case 1 of Claim 1. It is not clear if such Œì exists in a general case, and the proof may need a diÔ¨Äerent approach.  
  Institute of Engineering Sciences, Universidad de O‚ÄôHiggins, Rancagua, Chile [email protected]  Sauder School of Business, University of British Columbia, Vancouver, BC, Canada [email protected]  3 Energy Systems and Infrastructure Analysis Division, Argonne National Laboratory, Lemont, IL, USA [email protected]   
  Abstract. A branch-and-bound (BB) tree certiÔ¨Åes a dual bound on the value of an integer program. In this work, we introduce the tree compression problem (TCP): Given a BB tree T that certiÔ¨Åes a dual bound, can we obtain a smaller tree with the same (or stronger) bound by either (1) applying a diÔ¨Äerent disjunction at some node in T or (2) removing leaves from T ? We believe such post-hoc analysis of BB trees may assist in identifying helpful general disjunctions in BB algorithms. We initiate our study by considering computational complexity and limitations of TCP. We then conduct experiments to evaluate the compressibility of realistic branch-and-bound trees generated by commonly-used branching strategies, using both an exact and a heuristic compression algorithm.  
  1  
  the only allowed directions are typically {e1 , . . . , en }, in which case we say the algorithm uses variable disjunctions. However, many results explore the beneÔ¨Åt of additional directions: various subsets of {‚àí1, 0, 1}n are explored in [25,27,30]; directions derived from mixed integer Gomory cuts are explored in [9,19]; directions derived using basis reduction techniques are explored in [1,26]; Mahajan and Ralphs [23] solve a subproblem to Ô¨Ånd a disjunction that closes the duality gap by a certain amount. The largest set of directions is the set Zn , in which case the algorithm uses general disjunctions. Although a larger set of allowable directions provides more Ô¨Çexibility, it has been repeatedly veriÔ¨Åed that searching through this set during the execution of the algorithm can be computationally expensive [15,23]. The work in this paper is motivated by a diÔ¨Äerent approach to identify meaningful directions. Given a tree T produced using some set of allowable directions D ‚äÜ Zn , we ask if T can be ‚Äúcompressed‚Äù into a smaller tree with the same (or stronger) dual bound by using a potentially larger set of directions D ‚äá D, and a limited set of transformations. This post-hoc compression analysis is more restricted and allows one to use a global view of the tree to identify potentially meaningful branching directions, as opposed to the dynamic approach. We believe this compression question may help produce small trees to be used as better certiÔ¨Åcates [7] or as training data for learn-to-branch strategies. Related Work. To the best of our knowledge, this is the Ô¨Årst piece of work to study the tree compression problem. A related question is the minimum size of a BB tree certifying optimality or infeasibility of (1); we use some of these results in our own work. Chv¬¥ atal [8] and Jeroslow [18] gives examples of IPs that require a BB tree whose size is exponential in the number of variables n when only variable directions D = {e1 , . . . , en } are used to generate disjunctions. There are examples where an exponential lower bound in n cannot be avoided even with general disjunctions [10,11]. Basu et al. [3] consider the set Ds of directions whose support is at most s; they prove that if s ‚àà O(1), then a BB tree proving infeasibility of Jeroslow‚Äôs instance has exponential in n many nodes [3]. For an interesting perspective on provable upper bounds, Dey et al. [12] relate the size of BB trees generated using full strong branching and variable disjunctions to the additive integrality gap for certain classes of instances like vertex cover. For complexity results, Pfetsch et al. [16] show that is it NP-hard to Ô¨Ånd the smallest BB tree generated using only variable disjunctions. Mahajan and Ralphs [24] show that it is NP-complete to decide whether there is a general disjunction proving infeasibility at the root node. They also provide a MIP that can be solved at a node in a BB tree to yield a disjunction maximizing the dual bound improvement. The tree compression problem is a post-hoc analysis of a BB tree. A similar kind of analysis is done in backdoor branching, where one explores a tree T to Ô¨Ånd small paths from the root to the optimal solution with the ultimate aim to identify good branching decisions to make next time the algorithm is run on a similar IP [14,20]. The major diÔ¨Äerence between backdoor branching and the compression question is that the former only considers Ô¨Ånding a path  
  Compression Algorithms  
  In this section we introduce two compression algorithms and later evaluate their performance. Let T be a BB tree and c ‚àà Qn . For both algorithms, the general approach we follow is: (1) Traverse T starting from the root. We may skip leaves, since these are not compressible; (2) If the minimum of x ‚Üí c x over Q(v) is greater than or equal to d(T, c) then we apply drop(T, v); (3) Otherwise, we search for (œÄ, œÄ0 ) ‚àà Zn √ó Z such that T  = replace(T, v, œÄ, œÄ0 ) satisÔ¨Åes d(T, c) ‚â• d(T  , c). In the following, we provide two methods for Step (3), which is the bottleneck of the procedure. 4.1  
  An Exact Method  
  A Heuristic Method  
  Many heuristic methods for Ô¨Ånding good branching directions have been proposed in the literature (e.g. [9,16,19,27]) and can be readily used for tree compression. Here, we adapt a procedure in Owen and Mehrota [27] that iteratively improves variable directions by changing one coeÔ¨Écient at a time. To outline the method, assume we have solved the LP relaxation at a node v. The Ô¨Årst step is to Ô¨Ånd the best variable direction œÄ ‚àà {e1 , . . . , en }. Suppose œÄ  x ‚â§ œÄ0 is the side of the disjunction with the smallest optimal value. We add this constraint to the node LP and re-solve it to obtain a fractional solution x. For each fractional component xi , we then evaluate the branching directions œÄ + ei and œÄ ‚àí ei . If one of these directions yields a better dual bound than œÄ, then we replace œÄ by it and repeat the procedure until œÄ can no longer be improved. At the end, if the bound provided by œÄ is better than the tree bound, we apply replace(T, v, œÄ, œÄ0 ). Unlike the previous exact method, this iterative method provides no guarantees that a suitable disjunction will be found, even if it exists, and therefore may not achieve the best compression. However, it is typically much faster.  
  G. MuÀú noz et al.  
  hence being y a decision-dependent uncertainty parameter. The leader endows the set Y (x) with a probability distribution Œ≤x which models how the leader believes that the possible responses of the follower are distributed. Note that the classical optimistic and pessimistic approaches of bilevel programming are included in this setting, under quite mild assumptions (see [29]). Uncertainty in the data of the lower-level has been considered by Claus for linear bilevel programming from a variational perspective considering risk measures (see the survey [6] by Burtscheidt, and the references therein, and the recent works [7,8]). In [19], Ivanov considered the cost function of the follower as a bilinear form Ax + Œæ(œâ), y. Recently, in [5], Buchheim, Henke and Irmai considered a bilevel version of the continuous knapsack problem with uncertainty on the follower‚Äôs objective. In this work, we consider a linear bilevel programming problem where the lower-level objective is uncertain for the leader but follows a prior known distribution (as the particular case studied in [5]). We study the problem from a Bayesian approach perspective [29], and by means of the so-called chamber complex of a polytope (see Sect. 4), which subdivides the space of the leader‚Äôs decisions in a meaningful way. The idea of using the chamber complex to understand geometrical properties of optimization problems under uncertainty is not new, but it is recent. To the best of our knowledge, the Ô¨Årst work that does this is [14] (see also [13]), on which multistage stochastic linear optimization is studied. However, the techniques there cannot be extended to Stackelberg games. Due to space constraints, we do not provide all details in this extended abstract. We refer the reader to our full-length preprint [27]. 1.1  
  Problem Formulation and Contributions  
  (4)  
  It will be assumed throughout the paper that D is full dimensional. We do not lose generality since it is always possible to embed D into Rdim(D) . We will also assume that D is compact, i.e. it is a polytope. Finally, by moving the leader‚Äôs constraints to the follower‚Äôs problem, we assume without losing any generality that   (5) X = x ‚àà Rnx : ‚àÉy ‚àà Rny such that Ax + By ‚â§ b . In the latter assumption about X we are simply stating that the lower-level problem is feasible for any feasible choice of x and restricting ‚Äòunilaterally‚Äô the x coordinate in D which does not change the lower-level problem. We deÔ¨Åne the ambient space Y for the follower‚Äôs decision vector as   Y = y ‚àà Rny : ‚àÉx ‚àà Rnx such that Ax + By ‚â§ b . (6) Note that, since D is full-dimensional and compact in Rnx √ó Rny , both X and Y are full-dimensional (in Rnx and Rny , respectively) and compact as well. We  
  Geometrical Structure of Vertex-Supported Beliefs  
  Here, we recall the deÔ¨Ånition of a chamber complex, frequently used in some Ô¨Åelds of mathematics, like computational geometry (see, e.g., [9]). Definition 1 (Chamber complex). Let D ‚äÇ Rnx √ó Rny be a polyhedron as described in (4). For each x ‚àà X = œÄ(D), we deÔ¨Åne the chamber of x as   œÄ(F ) : F ‚àà F (D), x ‚àà œÄ(F ) . (13) œÉ(x) = The chamber complex, is then given by the (Ô¨Ånite) collection of chambers, i.e., C (D) = {œÉ(x) : x ‚àà X}. For a more comprehensive exposition of the chamber complex C (D) and their many interesting properties, we refer the reader to [9,13,14,27] and references therein. The next proposition shows that to compute a chamber it is enough to consider faces of D with dimensions up to nx instead of the collection of all faces. Proposition 3 ([27]). For any x ‚àà X, one has that œÉ(x) = {œÄ(F ) : F ‚àà F , x ‚àà œÄ(F ), dim(F ) ‚â§ nx }. While the previous result narrows the class of faces that are needed to compute a chamber, we may still need faces of drastically diÔ¨Äerent dimensions. The next example illustrates this phenomenon. Example 1. Consider the polytope D := {(x, y) ‚àà R2 √ó R : |x1 | ‚â§ y ‚â§ 1 ‚àí |x2 |}, whose vertices are (0, ¬±1, 0) and (¬±1, 0, 1). Clearly, (0, 0) and (1, 0) are minimal chambers, however, (0, 0) is not a projection of a vertex of D, while (1, 0) cannot be obtained using only projections of facets. It is well-known (see, e.g., [14]) that the family {ri(K) : K ‚àà C(D)} is a partition of X. With this in mind, we introduce the following deÔ¨Ånition. Definition 2. A function f : X ‚Üí R is said to be piecewise linear over the chamber complex C (D) if there exists a sequence of pairs {(dK , aK ) : K ‚àà C (D)} ‚äÇ Rnx √ó R such that  f (x) = (dK , x + aK )1ri(K) (x), ‚àÄx ‚àà X. (14) K‚ààC (D)  
  Exploiting the Polyhedral Geometry of Stochastic Linear  
  Enumeration Algorithm  
  Corollary 1 gives us a natural strategy to solve problem (18): It is enough to compute the chamber vertices V (D) and evaluate the corresponding objective function Œ∏ at each one of them. In this section we provide an enumeration algorithm to compute V (D) by sequentially solving mixed-integer programming problems which are formulated using F‚â§nx := {F ‚àà F : dim(F ) ‚â§ nx }, as shown in Proposition 3. We remind the reader that, due to the discussion in Example 1, we may need faces of diÔ¨Äerent dimensions to compute V (D). This is why we rely on the full set F‚â§nx . Remark 1. Computing V (D) is at least as hard as computing all vertices of a polytope. Indeed, given an arbitrary (full-dimensional) polytope P ‚äÜ Rn , one may consider D = P √ó [0, 1]. The vertices of P correspond exactly to V (D). To the best of our knowledge, the complexity of Ô¨Ånding all vertices of a polytope P is currently unknown; however, for a polyhedron P (not necessarily bounded), it is known that it is NP-complete to decide, given a subset of vertices of P , if there is a new vertex of P to add to the collection [20]. Therefore, we can expect that computing V (D) will be computationally expensive. For x ‚àà X, let us deÔ¨Åne the label of x as the set (x) := {F ‚àà F‚â§nx : x ‚àà œÄ(F )}. Endowing the set of all (Ô¨Ånitely many) labels with the order of the inclusion, one can show (see [27]) that x ‚àà V (D) ‚áê‚áí (x) is a maximal label.  
  (19)  
  tially: note in Table 1 that in all but the bottom two entries1 , Algorithm 1 used all available faces. This is because the algorithm heavily relies on maximal labels, which is important in our procedure to not repeat chambers when enumerating. 1  
  The last two entries of Table 1 correspond to cases where F‚â§nx was not fully computed due to the time limit.  
  about them in an online fashion? Our paper provides answers to these questions, through the lens of contention resolution schemes. Contention resolution schemes aim to solve the following problem: Given a family of feasible sets F ‚äÇ 2E and a random set R sampled from a distribution on 2E , how can we choose a feasible subset I ‚äÜ R, I ‚àà F, so that each element from R is picked with some guaranteed conditional probability: Pr[e ‚àà I | e ‚àà R] ‚â• c for some Ô¨Åxed c > 0 and all e ‚àà E? We call such a scheme c-balanced. This condition is a kind of fairness constraint, ensuring every element e has a reasonable chance of making it into I. In this paper, we think about E as the set of edges in a graph, and F as the set of matchings of the graph. The constant c is the conditional probability with which we can ensure an edge ends up in the matching I we pick, given it appears in R. A natural assumption on the random set R is that it comes from a product distribution with marginal probabilities xe such that x is in a polytope corresponding to the family F (either the exact convex hull, or a suitable relaxation, depending on the application), i.e., roughly speaking, R on average, is in F. For matchings on graphs, this corresponds to an assumption that each edge e appears in R independently with probability xe , and the vector (xe )e‚ààE belongs to the matching polytope, i.e, is a fractional matching. The formal notion of contention resolution was Ô¨Årst investigated as a tool for randomized rounding. In this setting, we have an optimization problem subject to a constraint, and x represents a fractional solution to a relaxation of the problem. Contention resolution is one of the phases of a randomized rounding approach to converting this fractional solution into an integral solution: First we generate a random set R, by sampling each element e independently with probability xe , and then we select a subset of R which satisÔ¨Åes the desired constraint. The Ô¨Çexibility of the approach enables its wide applicability in combinatorial optimization. This approach was introduced by Feige [2], who developed a contention resolution scheme (CRS) for matchings on the restricted class of star graphs, in the context of an application to combinatorial auctions. CRSs were then investigated more systematically in [4] in the context of submodular optimization. In particular, an optimal (1 ‚àí 1/e)-balanced CRS was identiÔ¨Åed in [4] for the case where F forms a matroid. The 1 ‚àí 1/e factor is optimal even for F = {I : |I| ‚â§ 1}. For applications in submodular optimization, it turns out that an additional property of monotonicity is often useful: A CRS is called monotone, if for every element e, the probability that e is selected from a set R is non-increasing as a function on the sets R containing e. This property is generally needed for the analysis of randomized rounding with a submodular objective function [4]. However, for some applications it is not necessary that a CRS is monotone; in particular it was not needed in Feige‚Äôs original application in [2], and it is also unnecessary for a related application that we present in the full version of this paper.  
  Our Techniques  
  Our Theorem 1 follows from an improved and simpliÔ¨Åed analysis of Karp and Sipser‚Äôs algorithm [1] for constructing matchings by adding random edges adjacent to leaves. While we utilize many of the ideas from Karp and Sipser‚Äôs paper, our analysis of the algorithm is an improvement in several ways: ‚Äì We obtain a contention resolution scheme, while Karp and Sipser only compute the expected size of the maximum matching. This yields the somewhat surprising conclusion that Karp and Sipser‚Äôs algorithm works just as well for weighted matchings as it does for unweighted matchings. ‚Äì We avoid Karp and Sipser‚Äôs (technically complicated) use of the so-called diÔ¨Äerential equation method. We also avoid the use of generating functions, another method used recently to calculate the expected size of the maximum matching in random graphs [5]. ‚Äì We obtain results for any random graph R(x) constructed from a fractional matching satisfying x‚àû ‚â§ , unlike Karp and Sipser who only consider the Erdos-Renyi random graph Gn,c/n . Many previous results require that there be some kind of symmetry in the random graph to obtain bounds on the size of the matching. We stress that we do not need to make any such assumption on R(x). We do need to assume that x‚àû ‚â§ . This assumption is useful because it ensures that the neighbourhood of any particular edge looks like a random tree. A closely related assumption (‚Äúlocal weak convergence‚Äù) has been considered previously in the literature. This assumption, together with recursive distributional equations, is used to formalize various statistical mechanical heuristics regarding matchings in random graphs. Most related to our work is the work of Bordenave, Lelarge, and Salez [3]. Once again, the advantage of our method is that we obtain a CRS (as opposed to computing the expected size of the maximum matching) and we avoid the use of technically complicated tools. These improvements come at a cost‚Äìwe assume that the average degree of each vertex is less than or equal to 1. The theoretical and practical signiÔ¨Åcance of this case, and the importance of contention resolution schemes, make this trade-oÔ¨Ä a good choice. Our Theorem 2 requires several new techniques, although the basic idea can be traced back to Karp and Sipser as well: When deciding which edge incident  
  Towards an Optimal Contention Resolution Scheme for Matchings  
  An Optimal CRS When x‚àû ‚Üí 0 The Karp-Sipser Algorithm  
  The Karp-Sipser algorithm is a method to select a matching in a graph. Given a graph G, the algorithm deletes all the degree 0 vertices, selects a random degree 1 vertex (if one exists), and adds the edge adjacent to it to the matching. Then, it deletes all the edges adjacent to the edge just added to the matching, and recurses on the newly obtained graph G . Note that unlike in the paper of Karp and Sipser, we do not use a two stage process to generate the matching. An attractive feature of the Karp-Sipser algorithm is that it doesn‚Äôt ‚Äúmake any mistakes‚Äù. This is because for any vertex v of degree 1 in a graph G, G has a maximum matching in which v is matched. If an edge is deleted by the algorithm at some stage, we will say that it disappears. We also say that a vertex is added to the matching if an edge adjacent to it is added to the matching. Before we discuss the analysis of the algorithm, we take a brief detour. 2.2  
  Random Trees  
  M. N¬® agele et al.  
  and interest in identifying special classes of polynomial-time solvable IPs while remaining as general as possible. One of the best-known such classes are IPs with a constraint matrix that is totally unimodular (TU), i.e., the determinant of any of its square submatrices is within {‚àí1, 0, 1}. A long-standing open conjecture in the Ô¨Åeld is whether this result can be generalized to Œî-modular constraint matrices for constant Œî. Here, we say that a matrix A ‚àà Zk√ón is Œî-modular if it has full column rank and all n √ó n submatrices have determinants in {‚àíŒî, . . . , Œî}.1 For brevity, we call an IP with Œî-modular constraint matrix a Œî-modular IP. We recap the above-mentioned conjecture below. Unfortunately, we do not know its precise origin; it may be considered folklore in the Ô¨Åeld. Conjecture 1. For constant Œî ‚àà Z‚â•0 , Œî-modular IPs can be solved in polynomial time. First progress on Conjecture 1 was made by Artmann, Weismantel, and Zenklusen [3], who showed that it holds for Œî = 2 (the bimodular case). Fiorini, Joret, Weltge, and Yuditsky [11] show that the conjecture is true for an arbitrary constant Œî under the extra condition that the constraint matrix has at most two non-zero entries per row or column. Through a non-trivial extension of the techniques in [3], it was shown by N¬® agele, Santiago, and Zenklusen [24] that there is a randomized algorithm to check feasibility of an IP with a strictly 3-modular constraint matrix in polynomial time. Here, a matrix A ‚àà Zk√ón is called strictly Œî-modular if it has full column rank and all its n √ó n submatrices have determinants in {‚àíŒî, 0, Œî}. As a key ingredient, all these prior approaches solve certain combinatorial optimization problems with congruency constraints. This is not surprising, as even strictly Œî-modular IPs include the following class of MCCTU problems:2 Multi-Congruency-Constrained TU Problem (MCCTU): Let T ‚àà Zk√ón be TU, b ‚àà Zk , c ‚àà Rk , m ‚àà Zq>0 , Œ≥i ‚àà Zn for i ‚àà [q], r ‚àà Zq . Solve min{c x : T x ‚â§ b, Œ≥i x ‚â° ri  
  (mod ‚àó)mi ‚àÄi ‚àà [q], x ‚àà Zn } .  
  Group-Constrained Problems and Proof Strategy for Theorem 1  
  To show Theorem 1, we exploit its close connection to MCCTU. Capturing the congruency constraints of an MCCTU problem through an abelian group constraint, we attain the following group-constrained TU feasibility problem. Group-Constrained TU Feasibility (GCTUF): Let T ‚àà Rk√ón be a TU matrix, let b ‚àà Zk , let (G, +) be a Ô¨Ånite abelian group, and let Œ≥ ‚àà Gn and r ‚àà G. The task is to show infeasibility or Ô¨Ånd a solution of the system T x ‚â§ b, Œ≥  x = r, x ‚àà Zn . Here, the scalar product Œ≥  x denotes the linear combination of the group elements Œ≥1 , . . . , Œ≥n with multiplicities x1 , . . . , xn in G. Group constraints generalize congruency constraints, which are obtained in the special case where G is cyclic. More generally, by the fundamental theorem of Ô¨Ånite abelian groups, a Ô¨Ånite abelian group G is, up to isomorphism, a direct product of cyclic groups. Hence, a group constraint can be interpreted as a set of congruency constraints and vice versa. Thus, GCTUF and MCCTU feasibility are two views on the same problem. We stick to GCTUF mostly for convenience of notation. Moreover, the GCTUF setting also allows for an elegant use of group-related results later on. One may assume that the group is given through its multiplication table (the Cayley table). In fact, the precise group representation is not of great importance to us. Concretely, for constant Œî, strictly Œî-modular IP feasibility problems reduce to GCTUF problems with a constant size group. Many of our polynomial-time algorithmic results can even be extended to settings where the group size is not part of the input, and access to group operations is provided through an oracle. By Lemma 1 and the aforementioned equivalent viewpoint of multiple congruency constraints and a group constraint, in order to prove Theorem 1, it is enough for us to show the equivalent statement below. Theorem 2. There exists a strongly polynomial time randomized algorithm for GCTUF problems with a group of cardinality at most 4. On a high level, we follow a well-known strategy for TU-related problems by employing Seymour‚Äôs decomposition [31] to decompose the problem into problems on simpler, more structured TU matrices. (See, e.g., [1,3,9,24].) Roughly speaking, a TU matrix is either very structured‚Äîin which case we call it a base block ‚Äîor can be decomposed into smaller TU matrices through a small set of well-deÔ¨Åned operations. (See the discussion following Theorem 7.) The use of Seymour‚Äôs decomposition typically comes with two main challenges, namely (i) solving the base block cases, and (ii) propagating solutions of the base block cases back through the decomposition eÔ¨Éciently to solve the original problem. First, we show that this propagation can be done eÔ¨Éciently for our problem. Theorem 3. Let G be an abelian group of size at most 4. Given an oracle for solving base block GCTUF problems with group G, we can solve GCTUF problems with group G in strongly polynomial time with strongly polynomially many calls to the oracle.  
  Advances on Strictly Œî-Modular IPs  
  1.3  
  Structure of the Paper  
  In Sect. 2, we prove Theorem 4. Section 3 illustrates our approach and new contributions towards Theorem 3 on a more technical level, and explains the main new ingredients of our proof. Due to space constraints, some proofs are deferred to a long version of this paper, including the proof of Lemma 1.  
  2  
  M. N¬® agele et al.  
  from using larger depths, as GCTUF become harder with increasing depth.) This œÄB (Œ±, Œ≤))| = min{d + allows us to compute a set œÄ ¬ØB (Œ±, Œ≤) ‚äÜ œÄB (Œ±, Œ≤) of size |¬Ø ¬ØB (Œ±, Œ≤) = ‚àÖ and, as long as |¬Ø œÄB (Œ±, Œ≤)| < 1, œÄB (Œ±, Œ≤)}. Indeed, we can start with œÄ min{d + 1, œÄB (Œ±, Œ≤)}, we solve an RB -GCTUF B-problem (i.e., we look for a BœÄB (Œ±, Œ≤) being a set of size problem solution xB with Œ≥  xB ‚àà RB ) with RB = G\¬Ø at least |G| ‚àí d. If RB ‚à© œÄB (Œ±, Œ≤) = ‚àÖ, then we Ô¨Ånd an element in RB ‚à© œÄB (Œ±, Œ≤) that can be added to œÄ ¬ØB (Œ±, Œ≤) and we repeat; otherwise, RB ‚à© œÄB (Œ±, Œ≤) = ‚àÖ and we know that we computed œÄ ¬ØB (Œ±, Œ≤) = œÄB (Œ±, Œ≤). To the contrary, note that the A-problem may be almost as big as the original GCTUF problem (possibly with just two fewer columns). Hence, here we cannot aÔ¨Äord (runtime-wise) a similar computation as for the B-problem. However, we can aÔ¨Äord to solve multiple RA -GCTUF A-problems of smaller depth, i.e., |RA | > |R|, because the runtime decreases signiÔ¨Åcantly with decreasing depth. By using the same approach as in the B-problem, but with sets RA of size |RA | ‚â• œÄA (Œ±, Œ≤)| = min{d, œÄA (Œ±, Œ≤)}. |R|+1, we obtain a set œÄ ¬ØA (Œ±, Œ≤) ‚äÜ œÄA (Œ±, Œ≤) of size |¬Ø Let us next take a closer look at patterns. Fix some (Œ±, Œ≤) ‚àà Œ† and let A 1 i , . . . , rA } for some A ‚â• 1 and pairwise diÔ¨Äerent rA ‚àà G, and œÄA (Œ±, Œ≤) = {rA  1  i i A let xA , . . . , xA be corresponding solutions of the A-problem with Œ≥A xA = rA . i i DeÔ¨Åne B , rB , and xB analogously. Observe that if A ‚â§ d and B ‚â§ d + 1, we have œÄ ¬ØX (Œ±, Œ≤) = œÄX (Œ±, Œ≤) for both X ‚àà {A, B}. Hence, we can compute j i + rB ‚àà R for some all feasible group elements and check explicitly whether rA i ‚àà [A ] and j ‚àà [B ], i.e., whether a solution exists. If B ‚â• d + 1, we can (independently of A ) even show that there always exists a feasible solution, and we can also Ô¨Ånd one: Indeed, we can compute d + 1 solutions xi := (x1A , xiB ) 1 i + rB ‚àà G, at least one of which must satisfy with pairwise diÔ¨Äerent sums rA 1 i + rB ‚àà R. If A ‚â• d and B ‚â• 2, we can argue similarly: We show that among rA ¬ØB (Œ±, Œ≤) (which we can any d elements of œÄ ¬ØA (Œ±, Œ≤), and any two elements of œÄ j j i i , rB with rA + rB ‚àà R. Note that while for groups compute), there is a pair rA of prime order this can be shown via the Cauchy-Davenport theorem, the above result does not hold in general. We show, however, that as long as R is not a union of cosets in G, we can recover the implication (cf. Section 3.1 for why this assumption is legit). Lemma 3. Let G be a finite abelian group, and let R ‚äÜ G be such that R = R + H for any non-trivial subgroup H of G. Then, for any subsets X, Y ‚äÜ G with |X| = |G| ‚àí |R| and |Y | ‚â• 2, we have (X + Y ) ‚à© R = ‚àÖ. Proof. Let b1 , b2 ‚àà Y with b1 = b2 , and set h = b1 ‚àíb2 . Assume (X + Y )‚à©R = ‚àÖ. Then |X| = |G| ‚àí |R| implies |X + Y | = |X|. Thus, X + b1 = X + b2 and hence X = X + h. Iterating gives X = X + h, where h denotes the subgroup generated by h. As R = G \ (X + b1 ), we get R = R + h, a contradiction.  
  The following observation summarizes the above discussion. If |¬Ø Observation 1 Let (Œ±, Œ≤) ‚àà Œ†. œÄA (Œ±, Œ≤)| ‚â§ d ‚àí 1 or |¬Ø œÄB (Œ±, Œ≤)| ‚â• 2, we can immediately determine whether a feasible solution to the original R-GCTUF problem exists for such (Œ±, Œ≤), and if so, obtain one by combining solutions com¬ØB . puted for the A- and B-subproblem when determining œÄ ¬ØA and œÄ  
  Thus, the only case in which we cannot immediately check whether a feasible solution exists for some (Œ±, Œ≤), is when B = 1 and A ‚â• d + 1 (which imply œÄB (Œ±, Œ≤)| = 1). This is the only case where we may have |¬Ø œÄA (Œ±, Œ≤)| = d and |¬Ø œÄA (Œ±, Œ≤) + œÄ ¬ØB (Œ±, Œ≤)) ‚à© R = ‚àÖ, in which case (œÄA (Œ±, Œ≤) + œÄB (Œ±, Œ≤)) ‚à© R = ‚àÖ but (¬Ø we say that (Œ±, Œ≤) contains a hidden solution. 3.3  
  Handling Patterns  
  an interior pair if (Œ±, Œ≤)+ Definition 1. Let D be as in (5). We call (Œ±, Œ≤) ‚àà Œ† v ‚àà Œ† for all v ‚àà D, a border pair if (Œ±, Œ≤) ¬± v ‚àà Œ† for exactly two v ‚àà D, and a vertex pair if it is not an interior or border pair. Note that for a border pair (Œ±, Œ≤), due to symmeŒ≤ try, the two directions v ‚àà D with (Œ±, Œ≤) ¬± v ‚àà Œ† will always be antiparallel, i.e., v and ‚àív for some x x v ‚àà D. To continue, the four types of patterns we b i x distinguish are the following: (I) |œÄB (Œ±, Œ≤)| = 1 for or this is not the case, and (II) Œ† has x b x all (Œ±, Œ≤) ‚àà Œ†, Œ± an interior pair, or (III) Œ† has no interior but border pairs, or (IV) Œ† has only vertex pairs. We sketch how to proceed for each of the types and present the Fig. 3. A pattern shape detailed discussion in the long version. with an interior, border, and vertex pairs (marked i,  
  Patterns of type I . In a type I pattern, techniques b, and w, respectively). of [24] enable reducing the problem to a new GCTUF problem with same G and |R|, and at least one variable less, thus allowing to make progress.  
  J. Poremba and F. B. Shepherd  
  gives a characterization of when the Ô¨Çow-cut gap is 1 for pairs (G, H) where G is series-parallel. They prove there are inÔ¨Ånitely many minimal ‚Äúbad‚Äù topologies called the odd spindles. These generalize the graph of Fig. 1 by replacing the ‚Äúdemand triangle‚Äù by a ‚Äúdemand odd cycle‚Äù. We are not aware of an algorithm for recognizing this property for series-parallel topologies. Of course, when |E(H)| = 2, Hu‚Äôs Theorem gives us a very simple polynomial time recognition algorithm for undirected cut-suÔ¨Éciency. Given such a topology (G, H), it always outputs YES! We consider the directed analogue of this question and prove the following contrasting result. Theorem 1. It is NP-hard to determine whether a directed multiÔ¨Çow topology (G, H) is cut-suÔ¨Écient, even if H is a 2-cycle. In general, there is much less work for directed cut-suÔ¨Éciency. One beautiful result is a theorem of Nagamochi and Ibaraki [24] which shows that any cutsuÔ¨Écient directed topology (G, H) is also ‚Äúintegrally cut-suÔ¨Écient‚Äù. In other words, if all the capacities and demands are integral, then the cut condition is suÔ¨Écient to guarantee an integral routing. Theorem 1 relies on an understanding of the forbidden minors in directed 2-commodity topologies, much along the lines of the undirected series-parallel characterization of Chakrabarti et al. [4]. There are a number of diÔ¨Éculties we face with this approach. Most signiÔ¨Åcantly, directed cut-suÔ¨Éciency does not enjoy the same minor-closed property as the undirected setting. The key issue is that contracting an edge e in the directed setting may not correspond to deÔ¨Åning its capacity to +‚àû. This is because it may create entirely new paths for Ô¨Çows to use. This requires us to develop a theory of ‚Äúrelevant minors‚Äù. Namely, a minor (G , H  ) is relevant if the cut condition in the minor is directly connected to the cut condition in (G, H) with an appropriate setting of edge weights in (G, H). The technical results we need are developed in Sect. 3. We partition the class of 2-commodity topologies into one of three types. H is said to have roundtrip demands if E(H) = {(s, t), (t, s)} for distinct nodes s, t ‚àà V , it has 2-path demands if E(H) = {(s, t), (t, r)} where s, t, r are distinct nodes, and it has 2-matching demands if E(H) = {(s1 , t1 ), (s2 , t2 )} for distinct nodes s1 , s2 , t1 , t2 . There is also the case where H has a single common head or common tail, but these are always cut-suÔ¨Écient by a simple reduction from the Max-Flow Min-Cut Theorem. Using the notion of relevant minors, we Ô¨Ånd that the two topologies from Fig. 2a-2b, are the only minimal forbidden relevant minors for roundtrip and 2-path topologies. More precisely we have the following. Theorem 2. A directed multiÔ¨Çow topology with roundtrip demands is cutsuÔ¨Écient if and only if it does not contain the bad dual triangles (Fig. 2a) as a relevant minor. Theorem 3. A directed multiÔ¨Çow topology with 2-path demands is cut-suÔ¨Écient if and only if it does not contain the bad triangle (Fig. 2b) or the bad dual triangles (Fig. 2a) as a relevant minor.  
  Cut-SuÔ¨Écient Directed 2-Commodity Multiow Topologies  
  Fig. 2. The minimal bad roundtrip and 2-path demand topologies. With unit capacities and demands, each satisÔ¨Åes the cut condition but is not feasible.  
  These results imply that, in the case of roundtrip and 2-path demands, the minimal non-cut-suÔ¨Écient directed topologies are certiÔ¨Åed as such by multiÔ¨Çow instances with 0,1 data (i.e., demands and capacities are 0, 1-valued). Ultimately, this implies that any non-cut-suÔ¨Écient topology in these classes is certiÔ¨Åed by 0,1 demand values and 0,1,+‚àû capacity values. This 2 property need not always hold; Fig. 3 is an undirected example where the cut condition is suÔ¨Écient for unit demand weights but not when one of the demand edges has weight 2. We conjecture - see Sect. 6 - that this 0,1 property is true for all directed Fig. 3. An undirected topology where 2-commodity topologies. If true, this the cut condition is suÔ¨Écient for unit would give a complete characterization demands, but not in general. of 2-commodity cut-suÔ¨Éciency using a result in [27], which establishes that the non-cut-suÔ¨Écient topologies certiÔ¨Åed by 0, 1 demands are characterized via the minors in Fig. 2b and 2a. We achieve Theorems 2 and 3 by showing that, for roundtrip and 2-path demands, if G contains two paths for its diÔ¨Äerent commodities that share an edge, then we Ô¨Ånd either the bad dual triangles or the bad triangle as a relevant minor. This argument also yields the following characterization of cut-suÔ¨Éciency, which is in a convenient form to prove Theorem 1. Theorem 4. Suppose (G, H) is a directed multiÔ¨Çow topology with roundtrip or 2-path demands, say (s, t) and (t, r) where r may equal s. The topology is cutsuÔ¨Écient if and only if every st-path is arc-disjoint from every tr-path in G. 1.1  
  Other Related Work  
  own identity beyond their incident nodes. Contractions may change the ends of non-contracted edges, but those edges themselves still exist. For notational convenience we still write edges in terms of incident nodes, such as e = (w, v). A minor of an undirected or directed multiÔ¨Çow topology (G, H) is obtained by a sequence of edge deletions from G and H, and contractions of edges in G. Contracting e ‚àà E(G) identiÔ¨Åes its ends in both G and H, and we denote this topology (G, H)/e. For a multiÔ¨Çow topology (G, H), we say weights (u, d) are cut-deceptive if (G, H, u, d) satisÔ¨Åes the cut condition but is not feasible. Hence, a topology is cut-suÔ¨Écient if and only if it does not have any cut-deceptive weights. For undirected multiÔ¨Çow topologies, the family of cut-suÔ¨Écient topologies is closed under taking minors. In particular, if a minor (G , H  ) has cut-deceptive weights (u, d), then those weights can be extended to cut-deceptive weights (uext , dext ) for (G, H) as follows. Definition 1 (Extension of Weights). Let (G , H  ) be a minor of an undirected or directed multiÔ¨Çow topology (G, H). Let (u, d) be weights for (G , H  ). We deÔ¨Åne the extension1 of (u, d) to be the weights (uext , dext ) of (G, H) where: ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì  
  3  
  a full characterization of safety, in this paper, we rely on a suÔ¨Écient condition for a set of edges to be safe. SpeciÔ¨Åcally, we show that if contracting an edge set does not create new terminal connectivity, then it is safe. We formalize this notion as follows. Definition 3 (Entry/Exit Points, Entry-Exit Connected). Let (G, H) be a directed multiÔ¨Çow topology. Let F ‚äÜ E(G) be weakly connected. ‚Äì We denote by Entry(F ) the set of nodes x ‚àà V (F ) such that there exists an sx-path in G ‚àí F for some s ‚àà tails(H). We call these entry points of F . ‚Äì We denote by Exit(F ) the set of nodes y ‚àà V (F ) such that there exists a yt-path in G ‚àí F for some t ‚àà heads(H). We call these exit points of F . We say F is entry-exit connected if G[F ] contains an xy-path for every x ‚àà Entry(F ) and y ‚àà Exit(F ). To prove such sets are safe, we recast the cut condition from discussing density of cuts to discussing paths connecting terminals. We call this new form the path cut condition. In essence, the cut condition in (G, H, u, d) is equivalent to the existence of, for every F ‚äÜ E(H), d(F ) many arc-disjoint tails(F )‚àíheads(F ) paths (i.e., paths between tails(F ) and heads(F )) in Gu . Definition 4 (Weakly Feasible Routing). Let F ‚äÜ E(H) be a demand subset of directed multiÔ¨Çow instance (G, H, u, d). A weakly feasible routing of F is a set PF of d(F ) arc-disjoint tails(F ) ‚àí heads(F ) paths in Gu . Furthermore, the weakly feasible routing is fair or marginal-satisfying if both:   ‚Äì exactly d Œ¥F+ (s) paths in PF start at s for every s ‚àà tails(F ), and  ‚àí  ‚Äì exactly d Œ¥F (t) paths in PF end at t for every t ‚àà heads(F ). On a technical note, this deÔ¨Ånition is problematic if tails(F ) ‚à© heads(F ) = ‚àÖ. Fortunately, in such a case no cut contains the entirety of F . It is a degenerate case that ultimately can be excluded from the path cut condition2 . Now, we deÔ¨Åne the path cut condition. In fact, we deÔ¨Åne two versions. Each is useful in diÔ¨Äerent circumstances, and both are equivalent to the cut condition. Definition 5 (Path Cut Condition). Let (G, H, u, d) be a directed multiÔ¨Çow instance. The (fair) path cut condition is the property that, for every F ‚äÜ E(H) where tails(F ) ‚à© heads(F ) = ‚àÖ, there exists a (fair) weakly feasible routing of F . Theorem 5. Let (G, H, u, d) be a directed multiÔ¨Çow instance. The cut condition, the path cut condition, and the fair path cut condition are equivalent. The path cut condition gives a convenient way to prove that it is safe to contract entry-exit connected edge sets. 2  
  An equally valid alternative would be to allow a weakly feasible routing of F to pack inÔ¨Ånitely many copies of the length-zero path on a node in tails(F ) ‚à© heads(F ).  
  J. Poremba and F. B. Shepherd  
  Theorem 6. Let (G, H) be a directed multiÔ¨Çow topology. If a weakly connected edge set F ‚äÜ E(G) is entry-exit connected, then F is safe. Proof. Let (G , H  ) = (G, H)/F . Let vF be the identiÔ¨Åed node for F in (G , H  ). Let (u, d) be weights for (G , H  ) that satisfy the path cut condition. We prove that (G, H, uext , dext ) satisÔ¨Åes the path cut condition by showing that for each J ‚äÜ E(H) with tailsH (J) ‚à© headsH (J) = ‚àÖ, there is a weakly feasible routing of J in (G, H, uext , dext ). Let k = d(J) = dext (J). For each x ‚àà Entry(F ) and y ‚àà Exit(F ), let Fx,y be an xy path in G[F ] (which exist, since F is entry-exit connected). Note that in Guext , there are inÔ¨Ånitely many copies of each Fx,y , since uext (e) = +‚àû for all e ‚àà F . For each x and y, select k of them, say Fx,y,1 , . . . , Fx,y,k . Recall that, per our convention on minors, the edges of J still exist in H  . However, the ends of edges may change. We split into two cases. In the Ô¨Årst case, suppose there exists v ‚àà tailsH  (J) ‚à© headsH  (J). Since tailsH (J) ‚à© headsH (J) = ‚àÖ, but the intersection is non-empty after contracting F into vF , it must be that v = vF . Then there exist s ‚àà tailsH (J) and t ‚àà headsH (J) such that s, t ‚àà V (G[F ]). Note that s ‚àà Entry(F ) and t ‚àà Exit(F ). Then taking Fs,t,i for i = 1, . . . , k gives a weakly feasible routing of F . In the second case, suppose that tailsH  (J) ‚à© headsH  (J) = ‚àÖ. Then, the path cut condition of (G , H  , u, d) implies that there is a set P  of k arc-disjoint tailsH  (J) ‚àí headsH  (J) paths in Gu . We map each of the paths P1 , . . . , Pk in P  to a tailsH (J)‚àíheadsH (J) path in Guext . Each Pi ‚àà P  is a path from some s ‚àà tailsH  (J) to some t ‚àà headsH  (J). If Pi avoids vF , then s ‚àà tailsH (J) and t ‚àà headsH (J), and we map Pi to itself. If Pi uses vF , then in Guext its edges form two paths: a path Xi from some sÀÜ ‚àà tailsH (J) to some x ‚àà Entry(F ), and a path Yi from some y ‚àà Exit(F ) to some tÀÜ ‚àà headsH (J) (either path may have length zero). Joining Xi and Yi with Fx,y,i yields a tailsH (J) ‚àí headsH (J) path. We map Pi to this path. In this way, each Pi ‚àà P  maps to a tailsH (J) ‚àí headsH (J) path in Guext that uses only the edges of Pi and edges in some Fx,y,i . Then the image of P  under this mapping is a set of k arc-disjoint tailsH (J) ‚àí headsH (J) paths in Guext , as desired. There are several special cases of entry-exit connected sets that lead to quick ways to justify safety. Definition 6. A subdivision of directed multiÔ¨Çow topology (G, H) is obtained by a sequence of the following operation: select an edge e ‚àà E(G), and replace it with a path of length at least one. Corollary 1. Let (G, H) be a directed multiÔ¨Çow topology. 1. 2. 3. 4.  
  If F ‚äÜ E(G) is strongly connected, then F is safe. ‚àí If e = (a, b) ‚àà E(G) with deg+ G (a) = 1 and degH (a) = 0, then e is safe. ‚àí + If e = (a, b) ‚àà E(G) with degG (b) = 1 and degH (b) = 0, then e is safe. If (G, H) is a subdivision of (G , H  ), then (G , H  ) is a relevant minor of (G, H).  
  Items 1 and 4 are used to prove Theorem 2, and Item 3 is additionally used to prove Theorem 3, though the proof for the latter is omitted in this paper since it is very similar to the former. We note that these theorems do not require the full generality of this entry-exit connected machinery, and Corollary 1 can be proven in an ad-hoc fashion without appealing to Theorem 6. However it shows that the cases of Corollary 1 are diÔ¨Äerent expressions of the same general connectivity property. More importantly, the entry-exit machinery is general in the sense of not being restricted to a two demand setting. Moreover, the general form of entry-exit connected sets is used in [27] for studying safe contractions when there are 2-matching demands. We expect it to be useful in investigating characterizations of cut-suÔ¨Éciency for more general H.  
  4  
  Opposingly Ordered Paths  
  The cut condition implies the existence of certain paths in Gu . From there, infeasibility implies particular interactions of these paths, which we use to prove the existence of the desired relevant minor. To that end, we use the following terminology to describe interactions between paths. Definition 7 (Overlap Segments, Bridges). Let P and Q be paths in a directed graph that share at least one node. ‚Äì An overlap segment is a maximal common subpath of P and Q. It is trivial if it is one node. It is terminal if it contains the start or end of either path. ‚Äì A P -bridge of Q is a maximal subpath B of P that has at least one edge and shares no edges or internal nodes of B with Q. In the above, note that P can be written as an alternating sequence of P bridges of Q and the overlap segments of P and Q. When we say that we are listing objects, such as overlap segments, nodes, or edges, in P -order, we mean we list them by their order of occurrence when following the (directed) path P . Paths can intersect numerous times in varied conÔ¨Ågurations, so it may not be obvious how to proceed looking for a particular minor. To manage this complexity, we reduce to the case where the overlap segments follow a special pattern. Definition 8 (Opposingly Ordered). Let P and Q be paths in a directed graph that share at least one node. We say that P and Q are opposingly ordered if the P -order of their overlap segments is the reverse of the Q-order.  
  Characterization for Roundtrip and Two-Path Demands  
  We now have the tools to prove our characterizations. We begin with roundtrip demands. Lemma 2. Let (G, H) be a directed multiÔ¨Çow topology with roundtrip demands between s and t. Suppose G contains an st-path P and a ts-path Q that are not arc-disjoint. Then (G, H) contains the bad dual triangles (Fig. 2a) as a relevant minor. Proof. Consider a counterexample that minimizes |E(P )|+|E(Q)|. By Lemma 1, we may assume P and Q are opposingly ordered, otherwise we replace Q with Q‚àó . Note that s and t themselves are trivial terminal overlap segments. Since P and Q share an edge, there is a non-trivial overlap segment J ‚àó . Note that J ‚àó is not terminal. We claim J ‚àó is the only non-terminal overlap segment. Suppose there are at least two, for the sake of contradiction. Let JP be the Ô¨Årst non-terminal overlap segment in P -order (last in Q-order), and let JQ be the Ô¨Årst in Q-order (last in P -order). At least one of these two is not J ‚àó . Without loss of generality, suppose JP = J ‚àó . Say JP starts at w and ends at v. Let C be the cycle obtained by starting at s, following the Ô¨Årst (in P -order) P -bridge of Q to w, following JP from w to v, then following the last (in Q-order) Q-bridge of P from v to s. Consider the topology (G , H  ) = (G, H)/C, which has roundtrip demands. Since directed cycles are strongly connected, this contraction is safe by Corollary 1. Additionally, P  = P/(P ‚à© C) and Q = Q/(Q ‚à© C) are paths for the two commodities. Moreover, they have a non-trivial overlap segment, namely J ‚àó . By minimality, we obtain the desired relevant minor in (G , H  ), and hence in (G, H), a contradiction. So, there is exactly one non-terminal overlap segment J ‚àó , and it is nontrivial. Let w‚àó and v ‚àó be the Ô¨Årst and last nodes of J ‚àó , respectively (in either P -order or Q-order, both are the same for nodes of an overlap segment). The only other overlap segments are the terminal ones, s and t themselves. There are thus exactly two P -bridges of Q, connecting s to w‚àó and v ‚àó to t, respectively. Similarly there are exactly two Q-bridges of P , connecting t to w‚àó and v ‚àó to s, respectively. Then, the topology (P ‚à™ Q, H) is exactly a subdivision of the bad dual triangles. By Corollary 1, the bad dual triangles is a relevant minor of (P ‚à™ Q, H) and hence also of (G, H). Lemma 2 implies that if (G, H) has roundtrip demands and does not contain the bad dual triangles as a relevant minor, then every st-path in G is arc-disjoint  
  Cut-SuÔ¨Écient Directed 2-Commodity Multiow Topologies  
  NP-Hardness of Recognizing Cut-SuÔ¨Éciency  
  The proofs of Theorems 2 and 3 can be adapted to give a polynomial time algorithm. Given (G, H) with roundtrip or 2-path demands, and weights (u, d) that satisfy the cut condition, the algorithm outputs either a feasible integer routing for (G, H, u, d) or one of the two forbidden relevant minors. The algorithm does not however determine whether (G, H) is cut-suÔ¨Écient, since particular (u, d) may be feasible despite (G, H) not being cut-suÔ¨Écient in general. We show that determining if a directed multiÔ¨Çow topology (G, H) is cut-suÔ¨Écient (the CutSufficient decision problem) is NP-hard, even if we restrict to roundtrip demands (the CutSufficientRT decision problem). We reduce from an NP-hard decision problem we call UsefulEdge. Given a directed graph G, distinct nodes s, t ‚àà V (G), and an edge e ‚àà E(G), it asks whether there exists a (simple directed) st-path in G that uses the edge e. The directed 2-node-disjoint path problem, proved by Fortune et al. [9] to be NPhard, can be reduced to UsefulEdge. Theorem 1 is implied by the following. Theorem 7. There is a polynomial time reduction from the UsefulEdge problem to the CutSufficientRT problem. Proof. Given an input (G, s, t, e = (w, v)) for UsefulEdge, we construct a multiÔ¨Çow topology (G , H  ) with roundtrip demands. We obtain G from G as follows: 1. Subdivide e into e1 = (w, w ), e2 = (w , v  ), e3 = (v  , v), where w , v  are new nodes and w, v maintain their other incident edges. 2. Add two new nodes s , t , and edges (s , s), (t, t ), (t , w ), and (v  , s ). Finally, deÔ¨Åne H  = (V (G ), {(s , t ), (t , s )}). We claim that (G , H  ) is not cutsuÔ¨Écient if and only if there is an st-path in G that uses e, which proves the result. DeÔ¨Åne Q to be the path (t , w ), (w , v  ), (v  , s ). For the ‚Äúonly if‚Äù direction, suppose that (G , H  ) is not cut-suÔ¨Écient. Then by Theorem 4, G has some s t -path P  that shares an edge with some t s -path. The only t s -path is Q , and the only possible shared edge is e2 = (w , v  ),  
  Towards a Complete 2-Commodity Characterization  
  For two commodities, the only remaining case is 2-matching demands. We conjecture that the bad dual triangles and the bad triangle are the only forbidden relevant minors for this case. Conjecture 1. A directed multiÔ¨Çow topology with 2-matching demands (and hence, two demands in general) is cut-suÔ¨Écient if and only if it does not contain the bad triangle or the bad dual triangles as a relevant minor. In [27], the following is proved. Proposition 3. If directed multiÔ¨Çow topology (G, H) has 2-matching demands and (integer) cut-deceptive weights (u, d) where d(e) = 1 for all e ‚àà E(H), then it contains either the bad triangle or the bad dual triangles as a relevant minor. The argument considers more intricate interactions of paths arising from the fair path cut condition. It also requires general entry-exit connected contractions, rather than the specialized cases of Corollary 1. For roundtrip and 2-path demands, there is a clear reduction to the case of unit weight demands: if there is a cut-deceptive weighting (u, d), then by taking any paths P and Q for the two commodities that share an edge, Lemmas 2 and 3 show there is a cut-deceptive weighting for (P ‚à™ Q, H) where the demands are unit. This observation is encapsulated in Theorem 4. However, we do not have so strong a result for 2-matching demands. It is not enough to just take paths for the two commodities that share an edge, as this may not even satisfy the cut condition.  
  Theorem 1. There is a constant-competitive algorithm for RA-MSP with only the cardinality of the matroid known upfront. Moreover, our result holds in the more general adversarial order with a sample setting, where we are allowed to sample a random constant fraction of the elements and all remaining (non-sampled) elements arrive in adversarial order. As mentioned, when the matroid is fully known upfront, an O(1)-competitive algorithm was known for RA-MSP even when the arrival order of all elements is adversarial [15]. Interestingly, for this setting it is known that, without knowing the matroid upfront, no constant-competitive algorithm exists. More precisely, a lower bound on the competitiveness of Œ©(|N |/log log|N |) was shown in [15]. Organization of the Paper. We start in Sect. 2 with a brief discussion on the role of (matroid) densities in the context of random assignment models, as our algorithm heavily relies on densities. Decomposing the matroid into parts of diÔ¨Äerent densities has been central in prior advances on RA-MSP. However, this crucially relies on knowing the matroid upfront. We work with a rank-density curve, introduced in Sect. 3.1, which is also unknown upfront; however, we show that it can be learned approximately (in a well-deÔ¨Åned sense) by observing a random constant fraction of the elements. Section 3 provides an outline of our approach based on rank-density curves and presents the main ingredients which allow us to derive Theorem 1. Sect. 4 showcases the main technical tool that allows us to approximate the rank-density curve from a sample set. Finally, Sect. 5 discusses our main algorithmic contribution and a sketch of its analysis. We emphasize that we predominantly focus on providing a simple algorithm and analysis, refraining from optimizing the competitive ratio of our procedure at the cost of complicating the presentation. Moreover, due to space constraints, some proofs are deferred to the long version of this paper. We assume that all matroids are loopless, i.e., every element is independent by itself. This is without loss of generality, as loops can simply be ignored in matroid secretary problems.  
  2  
  Outline of Our Approach  
  As discussed, prior approaches [15,16] for RA-MSP heavily rely on knowing the matroid upfront, as they need to construct its principal sequence upfront. A natural approach would be to observe a sample set S ‚äÜ N containing a constant fraction of all elements and then try to mimic the existing approaches using the principal sequence of M|S , the matroid M restricted to the elements in S. A main hurdle lies in how to analyze such a procedure as the principal sequence of M|S can diÔ¨Äer signiÔ¨Åcantly from the one of M. In particular, one can construct matroids where the density of some parts is likely to be underestimated by a super-constant factor. Moreover, generally M|S may have many diÔ¨Äerent densities not present in M (e.g., when M is uniformly dense). We overcome these issues by not dealing with principal sequences directly, but rather using what we call the rank-density curve of a matroid, which captures certain key parameters of the principal sequence. As we show, rank-density curves have three useful properties: (i) They provide a natural way to derive a quantity that both relates to the oÔ¨Ñine optimum and can be easily compared against to bound the competitiveness of our procedure. (ii) They can be learned approximately by observing an O(1)-fraction of N . (iii) Approximate rank-density curves can be used algorithmically to protect denser areas from sparser ones without having to know the matroid upfront. Section 3.1 introduces rank-density curves and shows how they conveniently allow for deriving a quantity that compares against the oÔ¨Ñine optimum. Section 3.2 then discusses our results on approximately learning rank-density curves and how this can be exploited algorithmically. 3.1  
  Rank-Density Curves  
  RA-MSP Subinstances. We will often work with minors of the matroid that is originally given in our RA-MSP instance, and apply certain results to such minors instead of the original matroid. To avoid confusion, we Ô¨Åx throughout the paper one RA-MSP instance with matroid Morig = (Norig , Iorig ) and unknown but (adversarially) Ô¨Åxed weights w : Norig ‚Üí R‚â•0 , and our goal is to design an O(1)-competitive algorithm for this instance. The weights w of the original instance are the only weights we consider, even when working with RA-MSP subinstances on minors of Morig , as their elements also obtain their weights uniformly at random from w. In particular, the function F as deÔ¨Åned in (3) is always deÔ¨Åned with respect to the original weights w. Many of our statements hold not just for minors of M but any matroid with weights uniformly drawn from w. For simplicity, we typically also state these results for minors of M. For a matroid M = (N, I) with |N | ‚â§ |Norig |, we denote by (M, w) the RA-MSP instance on the matroid M obtained by assigning a uniformly random subset of |N | weights among the weights w uniformly at random to the elements in N . Our subinstances will be of this type (with M being a minor of Morig ). Even though there may be more weights than elements, such instances (M, w) can indeed be interpreted as RA-MSP instances, as they correspond to the adversary Ô¨Årst choosing uniformly at random a subset of |N | weights among the weights in w, which then get assigned uniformly at random to the elements. 3.2  
  Proof Plan for Theorem 1 via Rank-Density Curves  
  We now expand on how one can learn an approximation œÅÀú of the rank-density curve œÅMorig and how this can be exploited algorithmically to return an independent set of expected weight Œ©(F (œÅMorig )), which by Lemma 1 implies O(1)competitiveness of the procedure. To this end, we start by formalizing the notion of an approximate rank-density curve, which relies on the notion of downshift. Definition 2. Let œÅ : R>0 ‚Üí R‚â•0 be a non-increasing function and let Œ±, Œ≤ ‚àà R‚â•1 . The (Œ±, Œ≤)-downshift œÅ : R>0 ‚Üí R‚â•0 of œÅ is deÔ¨Åned via an auxiliary function œÜ : R>0 ‚Üí R‚â•0 as follows:  œÅ(Œ±)  ‚àÄt ‚àà (0, 1], 1 if œÜ(t) ‚àà (0, 1), Œ≤ œÜ(t) := œÅ(Œ±¬∑t) œÅ (t) := œÜ(t) otherwise . ‚àÄt > 1; Œ≤ Moreover, a function œÅÀú : R>0 ‚Üí R‚â•0 is called an (Œ±, Œ≤)-approximation of œÅ if it is non-increasing and œÅ ‚â§ œÅÀú ‚â§ œÅ, where œÅ is the (Œ±, Œ≤)-downshift of œÅ. The reason we round up values in (0, 1) in the above deÔ¨Ånition of downshift, is that while we deÔ¨Åne the latter for a more general type of curves, throughout the paper we mainly use it with rank-density curves, and density values are always at least one. One issue when working with an (O(1), O(1))-approximation œÅÀú of œÅ is that F (Àú œÅ) may be more than a constant factor smaller than F (œÅ) and we thus cannot compare against F (Àú œÅ) to obtain an O(1)-competitive procedure. However, as the  
  R. Santiago et al.  
  The second main ingredient in the proof of Theorem 2 is the following result. Due to space constraints, we defer its proof to the long version. Theorem 6. Let M = (N, I) be a matroid minor of Morig , and let r and œÅM denote the rank function and rank-density curve of M, respectively. Given an (Œ±, Œ≤)-approximate curve œÅÀú of œÅM with Œ± ‚àà R‚â•24 and Œ≤ ‚àà Z‚â•3 , there is a procedure ALG(Àú œÅ, Œ±, Œ≤) returning rank-density curves œÅ, œÅ1 , œÅ2 , œÅ3 , œÅ4 such that: 2 2 (i) œÅ is an (Œ± , Œ≤ )-approximation of œÅM . (ii) i‚àà[4] F (œÅi ) ‚â• F (œÅ). (iii) For each i ‚àà [4], œÅi satisÔ¨Åes the following properties: Let {Œºj }j‚àà[] be the densities of œÅi , then all the Œºj are powers of Œ≤ ‚â• 3, and r(D(N, Œºj+1 )) ‚â• Œ±r(D(N, Œºj/Œ≤ )) ‚â• 24r(D(N, Œºj/Œ≤ )) for j ‚àà [ ‚àí 1]. Moreover, œÅi ‚â§ œÅM .  
  1 1 r(N )Œ∑(1) ‚â• r(N m )Œ∑(Œªm ), 2e 2e  
  where the Ô¨Årst inequality holds by Lemma 4 with h = 1 and s = r(N ) ‚â• 1, as any basis of M is an independent set of rank r(N ), and the second inequality holds because r(N ) ‚â• r(N m ) and Œªm = 1. The desired lower bound on the expected weight of the set returned by the algorithm now follows by combining the above results with the respective probabilities that each branch is executed. To sum up, we discuss that our main result (i.e., Theorem 1) still holds in the more general adversarial order with a sample setting, where we are allowed to sample a set S ‚äÜ N containing every element of N independently with probability 1/2, and the remaining (non-sampled) elements arrive in adversarial order. In order to see this, Ô¨Årst note that the only place in the proof of Theorem 5 where we use that the non-sampled elements (i.e., N \ S) arrive in random order, is to argue that when running the classical secretary algorithm in branch (ii) we obtain an expected weight of at least wmax/e. Indeed, branches (i) and (iii) rely on running the procedure from Lemma 4, whose guarantees hold in the case where the elements arrive in adversarial order. However, note that running the classical secretary procedure in the above adversarial order with a sample setting outputs an element with expected weight of at least wmax/4. Indeed, the probability of selecting wmax in the latter setting is at least the probability of the event that wmax is not sampled and the second largest weight is; which occurs with probability 1/4. Thus, Theorem 5 holds (up to possibly a slightly worse constant) in the adversarial order with a sample setting. Next, observe that this implies that Theorem 2 also holds in the above setting (again, up to possibly a slightly worse constant). This follows because its proof relies on combining the procedures from Theorems 5 and 6, and the latter is completely oblivious to the arrival order of the elements. Finally, note that the proof of Theorem 1 uses the procedure from Theorem 5 and the classical secretary algorithm. Because (as discussed above) both of these algorithms have very similar guarantees in the adversarial order with a sample setting to the ones shown in this paper for random order, the claim follows.  
  O(1)-Competitive Random Assignment MSP Without Knowing the Matroid  
  A Combinatorial Algorithm for BKP  
  In this section we describe our exact solution method for BKP. At a high level, the algorithm is essentially just standard depth-Ô¨Årst branch-and-bound. Our strong lower bound, deÔ¨Åned later in Sect. 3, is essential for reducing the search space. To begin formalizing this, we Ô¨Årst deÔ¨Åne the notion of a subproblem. Definition 1. A subproblem (X, i) consists of some i ‚àà {1, . . . , n + 1} and set of items X ‚äÜ {1, . . . i ‚àí 1} such that X ‚àà U. Note that this deÔ¨Ånition depends on the ordering of the items, which throughout the paper we assume to be such that wp1L ‚â• wp2L ‚â• ¬∑ ¬∑ ¬∑ ‚â• wpnL with ties broken by n 1 2 placing items with larger pi Ô¨Årst. These subproblems will form the nodes of the branch-and-bound tree; (‚àÖ, 1) is the root node, and for every X ‚àà U, (X, n+1) is a leaf. Every non-leaf subproblem (X, i) has the child (X, i+1), which represents omitting item i from the upper-level solution. Non-leaf subproblems (X, i) with X ‚à™ {i} ‚àà U have an additional child (X ‚à™ {i}, i + 1) which represents including item i in the upper-level solution. The algorithm simply starts at the root and traverses the subproblems in a depth-Ô¨Årst manner, preferring the child (X ‚à™ {i}, i + 1) if it exists because it is more likely to lead to a good solution. Every time the search reaches a leaf (X, n + 1), we solve the knapsack problem max{p(Y ) : Y ‚àà L(X)} to get a feasible solution, and updating the incumbent if appropriate. 2.1  
  The Bound Test  
  N. Weninger and R. Fukasawa  
  power to react to that choice. SpeciÔ¨Åcally, the upper level choice of whether to take item i can depend on how much capacity the lower level has used on items {1, . . . , i ‚àí 1}. Evidently, this is not permitted by the deÔ¨Ånition of BKP, which dictates that the upper level solution is completely decided prior to choosing the lower level solution. However, our experiments show that this actually gives the upper level an extremely small amount of additional power in practice. The lower bound œâ may also be interpreted as a relaxation from a 2-round game to a 2n-round game. This may seem to be making the problem more diÔ¨Écult, but each round is greatly simpliÔ¨Åed, so the problem becomes easier to solve. This 2n-round game is as follows. In round 2i ‚àí 1, the leader (the upper level player) decides whether to include the item i. In round 2i, the follower (the lower level player) responds to the leader‚Äôs decision: if item i is still available, then the follower decides whether to include item i. The score of the game is simply the total proÔ¨Åt of all items chosen by the follower. It is straightforward to see that the minimax value of this game (i.e., the score given that both players follow an optimal strategy) is equal to œâ(1, C U , C L ). We now show formally that œâ(1, C U , C L ) lower bounds the optimal objective value of BKP. To this end we deÔ¨Åne œâX , a modiÔ¨Åed version of œâ where instead of the minimization in the case where cU ‚â• 0, cL ‚â• 0 and i ‚â§ n, the choice is made depending on whether i ‚àà X for some given set X. œâX (i, cU , cL ) is equal to œâg in the Ô¨Årst three cases, but replaces the last two cases with: œâX (i, cU , cL ) = ‚éß if cU ‚â• 0, cL ‚â• 0, i ‚â§ n and i ‚àà X, œâ (i + 1, cU ‚àí wiU , cL ) ‚é™ ‚é® X œâX (i + 1, cU , cL ‚àí wiL ) + pi , ‚é™ / X. if cU ‚â• 0, cL ‚â• 0, i ‚â§ n and i ‚àà ‚é©max œâX (i + 1, cU , cL ) With this simple modiÔ¨Åcation, we claim that œâX (1, C U , C L ) = max{p(Y ) : Y ‚àà L(X)} (and similarly for other i, cU , and cL ). To formalize this, we show that œâX and K (as deÔ¨Åned in Sect. 2.1) are equivalent in the following sense. Lemma 5. For all 1 ‚â§ i ‚â§ n, X ‚äÜ {i, . . . , n}, cU ‚â• wU (X) and cL ‚â• 0, œâX (i, cU , cL ) = K(X ‚à™ {1, . . . , i ‚àí 1}, cL ). Proof. Given that cU ‚â• wU (X), the case cU < 0 can not occur in the expansion of œâX (i, cU , cL ), so œâX (i, cU , cL ) = œâX (i, ‚àû, cL ). Consider the 0-1 knapsack problem with proÔ¨Åts p and weights w formed by taking p = p and w = wL except with pj = wj = 0 for items j ‚àà X. We can then simplify the deÔ¨Ånition of œâX (i, ‚àû, cL ) by using p and w to eÔ¨Äectively skip items in X: ‚éß ‚àí‚àû if cL < 0, ‚é™ ‚é™ ‚é™ ‚é™ ‚é®0 if cL ‚â• 0 and i > n, œâX (i, ‚àû, cL ) = L   ‚é™ ‚é™ ‚é™max œâX (i + 1, ‚àû, c ‚àí wi ) + pi , ‚é™ if cL ‚â• 0 and i ‚â§ n. ‚é© œâX (i + 1, ‚àû, cL )  
  A Fast Combinatorial Algorithm for BKP  
  N. Weninger and R. Fukasawa  
  Note that in particular, this implies that œâ(1, C U , C L ) ‚â§ minX‚ààU K(X, C L ) = minX‚ààU maxY ‚ààL(X) p(Y ), i.e., œâ(1, C U , C L ) is a lower bound for BKP. We end this section with a simple observation. The approach we derived for our problem was based on obtaining good feasible solutions to the lower problem. Now, if the lower problem is already NP-hard, one may ask how useful can an approximate solution to the lower level be. For this, we consider a very generic problem: (1) z ‚àó := min max c(x, y) x‚ààU y‚ààL(x)  
  For each x ‚àà U, assume there exists y ‚àà L(x) that maximizes the inner problem. Let y ‚àó (x) be such a maximizer of c(x, y) for y ‚àà L(x). The following lemma then shows that if we can solve the problem with an approximate lower level, instead of an exact one, we get an approximate solution to (1). Lemma 6. Suppose we have a function f (x) such that for all x ‚àà U: ‚Äì f (x) ‚àà L(x), and ‚Äì c(x, f (x)) ‚â§ c(x, y ‚àó (x)) ‚â§ Œ±c(x, f (x)), for some Œ± ‚â• 1. x, y ‚àó (Àú x)) ‚â§ Œ±z ‚àó . Let x Àú ‚àà arg min c(x, f (x)). Then c(Àú x‚ààU  
  Proof. Let (x‚àó , y ‚àó (x‚àó )) be the optimal solution to (1). Then 1  
  c(Àú x, y ‚àó (Àú x)) ‚â§ c(Àú x, f (Àú x)) ‚â§ c(x‚àó , f (x‚àó )) ‚â§ c(x‚àó , y ‚àó (x‚àó )) = z ‚àó . Œ± While this does not immediately give an approximation algorithm for the problem, we believe it may be useful to simplify some Œ£p2 -hard bilevel interdiction problems and, for that reason, we include this lemma in this work. Note that an analogous result can be also derived for a max ‚àí min problem.  
  4  
  Conclusion  
  We presented a new combinatorial algorithm for solving BKP that is on average 4.5 times better, and achieves up to 3 orders of magnitude improvement in runtime over the performance of the previous state-of-the-art algorithm, DCS. The only disadvantage of our algorithm that we identiÔ¨Åed in computational testing is the high memory usage. Because of this, if memory is limited and time is not a concern, it may be a better idea to use DCS. However, if there is any correlation between the lower-level weights and proÔ¨Åts, DCS is unlikely to solve the instance in any reasonable amount of time, so it is preferable to use our algorithm on a machine with a large amount of memory, and/or to use additional implementation tricks to reduce the memory usage. For future work, it would be of interest to investigate whether our lower bound can be strengthened further (say, to an O(1)-approximation). We expect that it would be straightforward to generalize this work to the multidimensional variant of BKP (i.e., where there are multiple knapsack constrains at each level), although the issues with high memory usage would likely become worse in this setting. It may also be straightforward to apply this technique to covering interdiction problems. Beyond this, we suspect that a similar lower bound and search algorithm can be used to eÔ¨Éciently solve a variety of interdiction problems.  
  The Static Algorithm  
  We assume that the algorithm is given as input some Ô¨Åxed 0 < Œµ < 1. Notation For sake of notation let N (u) = {v ‚àà V | uv ‚àà E} be the set of neighbors of u ‚àà U in G, and similarly for N (v) for v ‚àà V . Preprocessing of the Weights. Let wmax > 0 be the maximum weight edge of E. For our static auction algorithm we may ignore any edge uv ‚àà E of weight less than Œµ ¬∑ wmax /n as w(M ‚àó ) ‚â• wmax as taking n of these small weight edges would not even contribute Œµ ¬∑ w(M ‚àó ) to the matching. Thus, we only consider edges of weight at least Œµ ¬∑ wmax /n, which allows us to rescale all edge weights by dividing them by Œµ ¬∑ wmax /n. As a result we can assume (by slight abuse of notation) in the following that the minimum edge weight is 1 and the largest edge weight wmax equals n/Œµ . Furthermore, since we only care about approximations, we will also round down all edge weights to the nearest power of (1 + Œµ) for some Œµ < Œµ /2 and, again by slight abuse of notation, we will use w to denote these edge weights. Formally to round, we deÔ¨Åne iLog(x) = log1+Œµ (x) and Round(x) = (1 + Œµ)iLog(x) . Let kmax = iLog(wmax ) = iLog(n/Œµ) = O(Œµ‚àí1 log(n/Œµ)). Let kmin be the smallest integer such that (1 + Œµ)‚àíkmin ‚â§ Œµ. Observe that as log(1 + Œµ) ‚â§ Œµ for 0 ‚â§ Œµ ‚â§ 1 it holds that kmin ‚â•  
  log(Œµ‚àí1 ) ‚â• Œµ‚àí1 log(Œµ‚àí1 ). log(1 + Œµ)  
  D. W. Zheng and M. Henzinger  
  Algorithm. The algorithm Ô¨Årst builds for every v ‚àà V a list Qv of pairs (i, uv) for each edge uv and each value i with ‚àíkmin ‚â§ i ‚â§ juv = iLog(wuv ) and then sorts Qv by decreasing value of i. After, it calls the function MatchR(v) on every v ‚àà V . The function MatchR(v) matches v to the item that maximizes its utility and updates price according to our multiplicative update rule. While matching v, another vertex v  originally matched to v may become unmatched. If this happens, MatchR(v  ) is called immediately after MatchR(v). Algorithm 2.1: MultiplicativeAuction(G = (U ‚à™ V, E)) M ‚Üê ‚àÖ. yu ‚Üê 0 for all u ‚àà U . jv ‚Üê kmax for all v ‚àà V Qv ‚Üê ‚àÖ for all v ‚àà V . For v ‚àà V :  
  # This is only used in the analysis  
  D. W. Zheng and M. Henzinger  
  Approximation Factor. We will show the approximation factor of the matching M found by the algorithm by primal dual analysis. We remark that it is possible to show this result purely combinatorially as well which we include in Appendix A, as it may be of independent interest. We will show that this M and a vector y satisfy the complementary slackness condition up to a 1 ¬± Œµ factor, which implies the approximation guarantee. This was proved by Duan and Pettie [8] (the original lemma was for general matchings, we have specialized it here to bipartite matchings). Lemma 1 (Lemma 2.3 of [8]). Let M be a matching and let y be an assignment of the dual variables. Suppose y is a valid solution to the LP in the following approximate sense: For all uv ‚àà E, yu + yv ‚â• (1 ‚àí Œµ0 ) ¬∑ w(uv) and for all e ‚àà M , yu + yv ‚â§  (1 + Œµ1 ) ¬∑ w(uv). If the y-values of all unmatched vertices are zero, then M is a (1 + Œµ1 )‚àí1 (1 ‚àí Œµ0 ) -approximate maximum weight matching. This lemma is enough for us to prove the approximation factor of our algorithm. Lemma 2. MultiplicativeAuction(G = (U ‚à™ V, E)) outputs a (1 ‚àí Œµ )approximate maximum weight matching of the bipartite graph G. Proof. Let Œµ > 0 be a parameter depending on Œµ that we will choose later. We begin by choosing an assignment of the dual variables yu for u ‚àà U and yv for v ‚àà V . Let all yu ‚Äôs be those obtained by the algorithm for u ‚àà U . For v ‚àà V , let yv = 0 if v is not matched in M and yv = util(uv) = w(uv) ‚àí yu if v is matched to u in M . By Invariant 3 all unmatched vertices u ‚àà U have yu = 0. Observe that for uv ‚àà M we have yu + yv = util(uv). It remains to show that for uv ‚àà M we have that yu + yv ‚â• (1 ‚àí Œµ0 )w(uv) for some Œµ0 > 0. First we consider if v is unmatched, so yv = 0. Since v is unmatched, by Invariant 4 then for all u ‚àà N (v), we must have util(uv) < (1 + Œµ)‚àíkmin ‚â§ Œµ. Since we rescaled weights so that w(uv) ‚â• 1, we know that util(uv) < Œµ ‚â§ Œµ ¬∑ w(uv). Furthermore, observe that as yu = w(uv) ‚àí util(uv) by deÔ¨Ånition of utility, it follows that: yu + yv = yu = w(uv) ‚àí util(uv) > (1 ‚àí Œµ)w(uv).  
  (1)  
  Author Index  
  A Achterberg, Tobias  
  Author Index  
