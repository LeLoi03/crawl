Write a Blog >>  ICSE 2023   Sun 14 - Sat 20 May 2023 Melbourne, Australia    
 Toggle navigation        
  Code of Conduct 
  Diversity and Inclusion Plan 
  Main Conference In-Person Presenter Instructions 
  Main Conference Virtual Presenter Instructions 
  Workshop and Co-Located Event Instructions 
  Visa Letter of Invitation 
  Social Events 
  Recruitment Opportunities at ICSE 2023 
  IEEE Computer Society Open Conference Statement 
  Travel Support 
  Childcare Support 
  Tracks | ICSE 2023 
  ICSE Keynotes 
  Social Events 
  Technical Track 
  DS - Doctoral Symposium 
  New Faculty Symposium 
  SCORE 2023 
  Showcase 
  SMeW - Student Mentoring Workshop 
  Most Influential Paper ICSE N-10 
  Student Volunteers 
  Technical Briefings 
  Submitting to ICSE2023: Q&A 
  ICSE 2023 Open Science Policies 
   Co-hosted Conferences 
  AST 
  FairWare 
  GAS 
  GE@ICSE 
  GI 
  GREENS 
  SEAMS  Research Track 
  SEAMS  Artifact Track 
  Organization | ICSE 2023 Committees 
  Organising Committee 
  Track Committees 
  DS - Doctoral Symposium 
  New Faculty Symposium 
  SCORE 2023 
  Showcase 
  SMeW - Student Mentoring Workshop | Student Mentoring Workshop 
  Mentors 
  Most Influential Paper ICSE N-10 
  Student Volunteers 
  Technical Briefings 
  FairWare | N/A - check homepage 
  GAS | N/A - check homepage 
  GE@ICSE | Program Committee 
  Organizing Committee 
  Program Committee 
  Sponsorship | Sponsors and Supporters 
  Sponsorships Opportunities 
  Program | ICSE Program 
  Your Program 
  Awards 
   Filter by Day | Sun 14 May 
  Mon 15 May 
  Tue 16 May 
  Wed 17 May 
  Thu 18 May 
  Fri 19 May 
  Sat 20 May 
  Search 
  Series | Series 
  ICSE 2024 
  ICSE 2023 
  ICSE 2022 
  Sign up 
  ICSE 2023  ( series  ) /  DeepTest 2023 ( series  ) /  DeepTest 2023  
 About 
  Previous Editions 
  Call for Papers 
  DeepTest  is a high-quality workshop for research at the intersection of Machine Learning (ML) and software engineering (SE). ML is widely adopted in modern software systems, including safety-critical domains such as autonomous cars, medical diagnosis, and aircraft collision avoidance systems. Thus, it is crucial to rigorously test such applications to ensure high dependability. However, standard notions of software quality and reliability become irrelevant when considering ML systems, due to their non-deterministic nature and the lack of a transparent understanding of the models’ semantics. ML is also expected to revolutionize software development. Indeed, ML is being applied for devising novel program analysis and software testing techniques related to malware detection, fuzzy testing, bug-finding, and type-checking.  
 The workshop will combine academia and industry in a quest for well-founded practical solutions. The aim is to bring together an international group of researchers and practitioners with both ML and SE backgrounds to discuss their research, share datasets, and generally help the field build momentum. The workshop will consist of invited talks, presentations based on research paper submissions, and one or more panel discussions, where all participants are invited to share their insights and ideas.  
   Program Display Configuration  
   The GMT offsets shown reflect the offsets at the moment of the conference  .     
 Time Band   
 ×    You're viewing the program in a time zone which is different from your device's time zone change time zone     
 Mon 15 May   
 Displayed time zone: Hobart  change      
 Call for Papers  
 NOTICE (09 Jan 2023)  : Only those who submitted by the original deadline (January 13, 2023) will be given one more week  to update their submitted papers. Please note that no new submissions will be accepted after the original deadline.   
 DeepTest is an interdisciplinary workshop targeting research at the intersection of software engineering and deep learning. This workshop will explore issues related to:  
 Deep Learning applied to Software Engineering (DL4SE) 
 Full research papers | up to 8-page papers (including references) describing original and unpublished results related to the workshop topics; 
  Short papers | up to 4-page papers (including references) describing both preliminary work, new insights in previous work, or demonstrations of testing-related tools and prototypes. 
  All submissions must conform to the ICSE 2023 formatting instructions. All submissions must be in PDF. The page limit is strict.  
 Submissions must conform to the IEEE formatting instructions IEEE Conference Proceedings Formatting Guidelines  (title in 24pt font and full text in 10pt type, LaTeX users must use \documentclass[10pt,conference]{IEEEtran}  without including the compsoc  or compsocconf  options).  
 DeepTest 2023 will employ a double-blind  review process. Thus, no submission may reveal its authors’ identities. The authors must make every effort to honor the double-blind review process. In particular, the authors’ names must be omitted from the submission, and references to their prior work should be in the third person.  
 The official publication date of accepted papers is the date the proceedings are made available in the ACM or IEEE Digital Libraries. This date may be up to two weeks prior to the first day of ICSE 2023. The official publication date affects the deadline for any patent filings related to published work. Purchases of additional pages in the proceedings is not allowed.  
 If you have any questions or wonder whether your submission is in scope, please do not hesitate to contact the organizers.  
 Important Dates   
 Paper Submission: January 13, 2023 (AoE) | (NEW: You can update your submitted papers until January 20  only if the initial submission is made before January 13) 
  Acceptance Notification: February 24, 2023 (AoE) 
  Camera Ready: March 17, 2023 (AoE) 
  Workshop Date: May 15, 2023 
  Submission System   
 Special Issue   
 Authors of DeepTest 2023 papers are encouraged to submit revised, extended versions of their manuscripts for the special issue in the Empirical Software Engineering (EMSE) journal, edited by Springer (details will follow). The call is also open to non-DeepTest 2023 authors.  
 Organizers   
 Matteo Biagiola, Università della Svizzera italiana, Switzerland 
 Keynotes  
 DeepTest 2023 will feature two keynotes from the following distinguished speakers.  
 Keynote 1 - Testing Autonomous Driving Systems   
 Speaker   
 Baishakhi Ray  | Associate Professor, Columbia University  
 Abstract   
 Recent years have seen rapid progress in Autonomous Driving Systems (ADSs). To ensure the safety and reliability of these systems, extensive testing is required. However, direct testing on the road is incredibly expensive and unrealistic to cover all critical scenarios. A popular alternative is to evaluate an ADS’s performance in some well-designed challenging scenarios, a.k.a. scenario-based testing. Such test cases must possess several desirable properties (e.g., failure-inducing, realistic, etc.) to be useful. However, the search space of such test cases can be huge due to the temporal nature of traffic scenarios. In this talk, I will cover our recent efforts in efficiently generating testing scenarios: 1) AutoFuzz, a grammar-based, learning-guided black-box fuzzing technique to generate failure-inducing scenarios for ADSs; 2) FusED, an evolutionary and causality-based domain-specific grey-box fuzzing framework to generate failure-inducing scenarios for fusion component of ADSs; and 3) CTG, a Signal Temporal Logic (STL) guided conditional diffusion model that generates realistic and user-controllable scenarios for ADSs.  
 Bio   
 Baishakhi Ray is an Associate Professor in the Department of Computer Science at Columbia University, NY, USA. She has received the prestigious IEEE TCSE Rising star award and NSF CAREER award. Baishakhi’s research interest is in the intersection of Software Engineering and Machine Learning. Her research has been acknowledged by many Distinguished Paper awards and has also been published in CACM Research Highlights, and has been widely covered in trade media.  
 Keynote 2 - Testing Generative Large Language Model: Mission Impossible or Where Lies the Path?   
 Speaker   
 Zhenchang Xing  | Associate Professor, Australian National University  
 Abstract   
 OpenAI’s ChatGPT, a generative language model, has attracted widespread attention from industry, academia, and the public for its impressive natural language processing capabilities. Although we know how to train such generative language models, we do not know how these models can solve such a diverse range of open-ended tasks. Every time we “prompt program” a large language model to complete a task, we create a customized version of the language model, which exhibits different abilities and outputs than other customized versions. Some people believe that the emergent capabilities of large language models are turning AI from engineering into natural science, as it is hard to think of these models as being designed for a specific purpose in the traditional sense. As our focus shifts from ensuring design and construction correctness to trying to explore and understand un-designed AI products and behaviors, we need to consider the methodological challenges posed by this transformation. For example, will differential testing, metamorphic testing, and adversarial testing, which are effective for testing discriminative models in specific tasks, no longer be the saviors of open-ended task testing for large language models? How can we test and correct ethical issues and hallucinations in generative AI? Due to the emergent capabilities of large language models, which are customized through in-context learning, will we face similar problems to the Schrödinger’s cat problem in quantum physics? If observation and measurement have a fundamental impact on the observed object, can we still fully test the essence of large language models, or can we only test the appearances of a specific customized version? Large language models are changing the way humans interact with AI, what adjustments do we need to make to our existing data and algorithm-centric MLOps? There may be many unknown problems. In this talk, I will share my thoughts (or even confusion) on these questions and some thoughts of actions (likely be wrong), hoping to inspire the community to explore the feasibility and methodology of testing generative large language models.  
 Bio   
 Important Dates   AoE (UTC-12h)     
 Mon 15 May 2023  
  Workshop Date 
 Fri 17 Mar 2023  
  Camera Ready 
 Fri 24 Feb 2023  
  Acceptance Notification 
 Fri 13 Jan 2023  
  Paper Submission (Soft Deadline) 
 Submission Link   
  ICSE 2023   
  contact form    
 Tracks  
 ICSE Keynotes   
  Social Events   
  Technical Track   
  DS - Doctoral Symposium   
  New Faculty Symposium   
  SCORE 2023   
  Showcase   
  SMeW - Student Mentoring Workshop   
  Most Influential Paper ICSE N-10   
  Student Volunteers   
  Technical Briefings   
  Submitting to ICSE2023: Q&A   
  ICSE 2023 Open Science Policies    
 Co-hosted Conferences  
 AST 2023   
  CAIN 2023   
  CHASE 2023   
  FormaliSE 2023   
  ICPC 2023   
  ICSSP 2023   
  MOBILESoft 2023   
  MSR 2023   
  TechDebt 2023   
  Workshops  
 AIOps 2023   
  APR 2023   
  BotSE 2023   
  DeepTest 2023   
  EnCyCriS 2023   
  FairWare 2023   
  GAS 2023   
  GE@ICSE 2023   
  GI 2023   
  GREENS 2023   
  InnerSoft 2023   
  InteNSE 2023   
  MET 2023   
  NLBSE 2023   
  Q-SE 2023   
  RoSE 2023   
  SBFT 2023   
  SEENG 2023   
  SERP4IoT 2023   
  SESoS 2023   
  SVM 2023   
  WETSEB 2023   
  Co-hosted Symposia  
 SEAMS 2023    
 Attending  
  Code of Conduct   
  Diversity and Inclusion Plan   
  Main Conference In-Person Presenter Instructions   
  Main Conference Virtual Presenter Instructions   
  Workshop and Co-Located Event Instructions   
  Visa Letter of Invitation   
  Social Events   
  Recruitment Opportunities at ICSE 2023   
  IEEE Computer Society Open Conference Statement   
  Travel Support   
