 This book constitutes the refereed proceedings of the 20th International Conference on The Semantic Web, ESWC 2023, held  
 Author / Uploaded 
  Claude Frasson 
  Phivos Mylonas 
  6 Discussion and Future Work  
  References  
  Teaching Cardiovascular Physiology with a Minigame-Based ITS  
  1 Introduction  
  2 Methodology  
  3.1 The Deteriorating Patient Application (DPA)  
  3.2 ADAptive COmpanion for Museum and Cultural Heritage Sites (ADACO)  
  3.3 DPA and ADACO in the Context of Its and Adaptive Learning Technologies Research  
  4 Characteristics of Domain Experts  
  5 Design Recommendations for Expert-Centered Design of Authoring Tools  
  5 Conclusion  
  References  
  Using the ITS Components in Improving the Q-Learning Policy for Instructional Sequencing  
  1 Introduction  
  2 Reinforcement Learning  
  3.1 Requirements Specification  
  3.2 Structural Model  
  4 Final Considerations  
  References  
  Toward a Smart Tool for Supporting Programming Lab Work  
  5.1 Teachers' Dashboard  
  5.2 Students' Dashboard  
  5.3 Student's Final Report  
  6 Early Experiment  
  6.1 Results and Discussion  
  5 Discussion and Conclusions  
  References  
  Author Index   
 Citation preview   
  Claude Frasson Phivos Mylonas Christos Troussas (Eds.)  
  Augmented Intelligence and Intelligent Tutoring Systems 19th International Conference, ITS 2023 Corfu, Greece, June 2–5, 2023 Proceedings  
  Lecture Notes in Computer Science Founding Editors Gerhard Goos Juris Hartmanis  
  Claude Frasson · Phivos Mylonas · Christos Troussas Editors  
  Augmented Intelligence and Intelligent Tutoring Systems 19th International Conference, ITS 2023 Corfu, Greece, June 2–5, 2023 Proceedings  
  Editors Claude Frasson University of Montreal Montreal, Canada  
  Preface  
  The 19th International Conference on Intelligent Tutoring Systems (ITS 2023) was held in Corfu, Greece, from June 2 to June 5, 2023. This year, ITS evolved to a new concept of Artificial Intelligence which can be found in various disciplines and can serve to promote human education and well-being. This new concept is named: AUGMENTED INTELLIGENCE. Augmented Intelligence concerns any system, technique, architecture, method, or tools which can be used to enhance HUMAN intelligence, cognitive capacities, memory, or learning. Instead of trying to reproduce human behavior or recognize human traits using artificial intelligence techniques or learning analytics, Augmented Intelligence provides means to increase human cognitive potential. The conference supported the following tracks in which the concepts, mentioned above, contribute to the increase of intelligence: T1: Augmented Intelligence in Tutoring Systems. The goal of this track was to show how new techniques inspired by artificial intelligence and new methods in education can improve learning and teaching, and augment the capacity for knowledge acquisition. The track included the following topics: augmented learning strategies, distance education, learning analytics for tutoring systems, deep learning and machine learning for tutoring systems, online and distance learning, augmented learner model, emotion recognition, human machine interaction, case-based reasoning, cognitive modeling, open learning, authoring systems, cultural learning, and adaptive learning. T2: Augmented Intelligence in Healthcare Informatics. The goal of this track was to show the progress of AI tools for increasing the propagation of healthcare techniques and their efficiency. Informatics provides means to improve the prediction, analysis, and treatment of disease and control of patients over their own care. The track included the following topics: AI and telemedicine, medical image processing, and virtual systems for healthcare T3: Augmented Intelligence in Games, Serious Games, and Virtual Reality. The goal of this track was to show the progress of interactive games using augmented intelligent techniques. Intelligent games can adapt to the characteristics of the player and can be used to enhance learning, skills, memory, cognitive capacities, and strategic decisions. They can be used in various applications (education, healthcare, group management, decision support systems, and industrial control). T4: Neural Networks and Data Mining The track included the following topics: supervised machine learning, genetic algorithms, Markovian regulation, smart sensor networks, determinate regulation, games and strategies, fuzzy systems, web information processing, applications of data mining in social sciences, data-driven reasoning, deep learning and statistical methods for data mining, big data mining, algorithms for data mining, ethical data analytics, data mining for recommendation, and uncertain reasoning. T5: Augmented Intelligence and the Metaverse The track included the following topics: technology and creativity around the Metaverse, gaming and interactivity, mixed  
  vi  
  vii  
  We would also like to acknowledge the Institute of Intelligent Systems (IIS), which acted as the conference organizer, particularly Kitty Panourgia and her excellent team, and the Ionian University, being the hosting institution. April 2023  
  Claude Frasson Phivos Mylonas Christos Troussas  
  Gamification, i.e., the use of game design elements in non-game contexts, has been successfully used to design better (virtual) learning environments aiming to increase positive experiences such as motivation, engagement, satisfaction, meaningful social interactions, self-efficacy, and flow. Recent advances highlight the importance of tailoring gamification design in education to maximize its benefits to students and reduce its potential negative effects. Nevertheless, the process of adapting and personalizing gamification for educational purposes requires knowledge about gamification design and how these elements influence students’ flow state. This influence may differ according to the context (learning materials, pedagogical approaches, feedback, etc) and the individuals’ characteristics (culture, age, user type, etc). Thus, in the past 10+ years, my research group has studied the factors that influence gamification design and use artificial intelligence techniques to augment human capabilities to better personalize gamification in educational contexts, particularly for STEM (Science, Technology, Engineering, and Mathematics) learning. To discuss the personalization of gamification in education, we will first discuss some of the positive and negative effects of gamification based on recent literature reviews. Then, a series of experiments carried out by my group will be presented to show how different contextual variables (e.g., culture, educational content, time on task, students’ interests, etc.) affect the potential benefits of gamification in education, particularly in the context of Computer Science Education. Finally, using these findings, we will present a taxonomy and data-driven framework to assist teachers in making decisions to design personalized gamified experiences. Keywords: Artificial Intelligence in Education · tailored gamification · educational technology.  
  Designing Immersive Information Systems in the ERA of Artificial Intelligence  
  Panos Kourouthanassis Department of Informatics, Ionian University, Greece Abstract. Immersive information systems may shape end users’ perceptions of reality. Immersive information systems employ such information and communication technologies as augmented reality (AR), virtual reality (VR), and gamification [2]. Scholars have identified the application potential of AR/ VR in several fields that range from medical applications [4], education [5], manufacturing [1], and retail [6]. The keynote speech will discuss the design challenges of immersive information systems from both engineering/ technological and user adoption examination stances. Furthermore, the keynote speech will discuss how extant information systems design science research perspectives (e.g. information systems design theories) may be employed for capturing the design elements of immersive information systems by emphasizing on the design of AR/ mobile-AR applications [3] and, in general, AR/ VR augmented intelligence immersive systems.  
  If we interpret a student’s answer to a question as a match between the student and question, the ERS can be used to estimate learners’ proficiency and question difficulty. As the rating score is updated by a heuristic rule, this is simple, robust, and effective for adaptive educational systems [28].  
  3 Methodology 3.1 Language Proficiency-Enhanced Knowledge Tracing The Elo rating score, calculated from the Korean problem-solving data, was used to estimate the students’ LP. A time window feature was used to reflect the time at which the Elo rating score was updated, based on the method of Lindsey et al. [20]. The reason for considering the timing information of the Elo rating score update is that students’ LP may change over time [5]. Because the students’ LP in this study was measured using data from Korean problem solving, if the student had not recently participated in Korean problem solving, the student’s Elo rating score would be fixed for a while. Therefore, by including a time window feature that contains information on the student’s Korean problem-solving by period, the possibility of a change in the student’s LP can be considered. The time window included information on the number of times the student attempted Korean problems and the number of correct answers by month, week, day, and hour. In addition, sentence length information from mathematical problems was used. Problem length was defined as the word count of each problem. Figure 1 shows the structure of the LP-enhanced KT model proposed in this study. qT1 , qT2 , · · · , qTn indicate the questions of main activities, the math problem-solving event, whereas lt1 , lt2 , · · · , lts indicate the questions of language activities, which is the Korean problem-solving event. T1 , T2 , · · · , Tn represent the timestamps of the main activities and t1 , t2 , · · · , ts represent the timestamps of the language activities. The Elo rating score calculated from the results of language activities up to Tn is used for timestamp Tn . Compatibility with existing models was considered when incorporating the LP information into the model. Because most KT models utilize question embedding and/or interaction embedding, LP information was incorporated into the model as in Eq. 3. qlp = W T1 [qwc], ilp = W T2 [iwcelotw]  
  (3)  
  Fig. 1. The illustration of language proficiency enhanced knowledge tracing.  
  Final prediction and loss function are as follows: aTˆ n+1 = σ (Architecture(qlpT1:n , ilpT1:n ))  
  (4)  
  Related Work  
  Computerized adaptive assessment methods in well-structured domains like mathematics have a long tradition of selecting tasks according to the student’s ability [15], where structured task description schemes allowed for a detailed analysis of student’s errors and on-demand generation of task instances facilitated independent student work. During the recent Corona crisis, professional rule-based adaptive learning systems like bettermarks1 were very popular. Recent machine learning approaches address the DDA issue also in other domains if there is a signiﬁcant question bank and users with diﬀerent competencies [18], considering even individual diﬃculty levels. This method can be applied when three conditions are met: a discrete action space exists, a feedback signal is a quantitative measure of diﬃculty, and a target performance value is selected. DDA can be achieved using statistical models such as IRT [5]. IRT estimates a learner’s proﬁciency based on their responses to a set of items and has been applied in various educational contexts [7]. However, traditional recommendation approaches may not be suitable in educational settings where a student’s learning potential changes over time. Reinforcement Learning (RL) addresses this issue by optimizing task recommendations based on the student’s past performance and progress [14]. In recent years, the combination of IRT and RL has been proposed as a solution for recommendation in mathematics and cognitive domains. For example, the authors in [8] suggested using an RL system to recommend items based on the student’s ability estimates from an IRT model to improve algebra abilities. Also, the study mentioned earlier [18] used IRT to estimate the student’s knowledge and RL to adjust task diﬃculty. This work is distinct from the previous approaches in recommender systems that combine RL and IRT. It utilizes IRT to estimate the diﬃculty of items based on the student’s past performance and uses this information to compute the expected total score threshold distribution for mathematical modules. This relevant information allowed to integrate into an RL system of the learner’s goal to make recommendations that align with the student’s objectives.  
  3  
  Background  
  In Reinforcement Learning (RL), an agent learns to make decisions by interacting with its environment and receiving feedback through rewards or penalties. The agent’s goal is to learn a policy mapping from states to actions that maximize the expected cumulative reward over time [14]. In the present work, we used and compared the performances of two popular RL algorithms: the Proximal Policy Optimization (PPO) [12], and the synchronous, deterministic variant (A2C) of the Asynchronous Advantage Actor Critic (A3C) [10]. PPO is designed to improve the stability and eﬃciency of policy gradient methods. It is an actorcritic algorithm that uses a value function to estimate the expected cumulative 1  
  19  
  reward for a given policy, and it uses a trust region method to optimize the policy. The basic idea of PPO is to optimize the procedure so that the new policy is close to the previous one but with improved expected cumulative reward [12]. The variant of A3C combines the actor-critic method with the advantage function. The actor-critic process separates the policy, which generates the actions, from the value function, which estimates the expected cumulative reward for a given policy. The advantage function estimates the improvement of taking a given action compared to the average action. The term “synchronous” refers to the method of updating the parameters of the actor and critic networks. All agents update their parameters simultaneously using the same synchronous data. In contrast, in the original asynchronous version, each agent updates its parameters independently using its data [10].  
  4  
  Diﬃculty Level  
  In the present study, an IRT approach is used to estimate the diﬃculty of items presented to students in a course each week and to create diﬀerent thresholds based on the sigmoid distribution of the estimated total score (ETS) of the winning IRT model. It allows us to consider the learners’ objectives for that particular module. IRT is a statistical procedure that allows for the discovery of a learner’s latent trait for a speciﬁc concept and the estimation of diﬀerent parameters (diﬃculty, discrimination, and guessing) embedded within the item according to the chosen IRT model. Three other IRT models (1PL, 2PL, 3PL) were compared, and the best one was selected using metrics such as the Akaike Information Criterion (AIC), Bayesian Information Criterion (BIC), and loglikelihood. The values of these metrics are summarized in Table 1. Table 1. AIC (Akaike Information Criteria), BIC (Bayesian Information Criterion), and LL (Log Likelihood). In bold, the models for each module that reached the significant level p < .05 among others. * It has not been possible to estimate the parameters due to too few degrees of freedom. Module 1PL AIC  
  2PL AIC  
  Universit´e du Qu´ebec ` a Montr´eal, Montr´eal, Canada [email protected]  , [email protected]  2 ´ Ecole de technologie sup´erieure, Montr´eal, Canada nyamen tato.angea [email protected]   
  Abstract. Intelligent educational systems currently use ontological knowledge modeling for their expert component. The associated semantics of the ontological languages allow for capturing highly complex domain knowledge. However, the automatic manipulation of knowledge to support the execution of a complex task by humans is a current research issue. This paper presents a solution for interpreting a complex ontological knowledge formalization about aircraft piloting procedures. This speciﬁc task is accomplished by human actors where multiple biases may compromise the safe execution. We are developing a solution to support pilots in their tasks’ execution. The domain theory interpretation must allow the reference model’s automatic execution in a complex environment. A reference model of the domain theory has been formalized with ontological language, a task ontology for the execution taxonomy, and a domain ontology containing the knowledge about the execution environment have also been previously developed. In this work, we propose an interpretor capable of manipulating the reference knowledge of the execution taxonomy within a simulation environment. Semantic rules are used to evaluate environmental constraints, task precondition, and execution to allow this automatic manipulation and execution. Once the solution is connected to a simulation environment, a reasoner manipulates the knowledge in order to evaluate the environment and autonomously execute the required tasks. This work is an intermediary step for providing a complete solution for supporting pilots’ execution of reference procedures in a simulation environment. Keywords: Ontology · Task Ontology Tutoring Systems · Piloting procedures  
  1  
  The Reference Model  
  Our reference model ontology comprises two main parts and is formalized with Web Ontology Language (OWL) [20]. The ﬁrst part is the domain ontology which is the terminological set related to the execution environment. The main objective is to support the execution within the complex environment. The other part is the task ontology, a general taxonomy of the execution domain speciﬁc to aviation procedures. Both ontologies are highly related, and multiple semantic connections are formalized between parts of both ontologies, making the execution model anchored to the context. Before being formalized within the ontologies, expert pilots must decompose and validate the procedure. With this objective in mind, normal and abnormal procedures commonly encountered during takeoﬀ have been decomposed with a standardized visual tool. The statechart diagram from the Uniﬁed Modeling Language (UML) [10] has been selected for its capability of capturing knowledge speciﬁc to workﬂow sequence. This choice has been supported by its characteristic of being simple and easily manipulated by domain experts with no prior experience with ontology. Many works have used the UML as a standard for decomposing procedural knowledge in the aviation domain. The Aviation Scenario Deﬁnition Language (ASDL), in its context, is a language that shows the possibility of formalizing aircraft navigation scenarios within the environment where multiple actors are involved [6]. However, the ASDL has not demonstrated its eﬀectiveness for modeling the task speciﬁcally accomplished by the pilots. Figure 1 shows an excerpt of the abnormal procedure where one engine is inoperative during the takeoﬀ and above the decision speed. Following the UML standard, each box is a speciﬁc state of the aircraft and the arrows are a change imposed in the environment by the pilots.  
  Fig. 1. Except of the engine failure procedure after decision speed.  
  (4)  
  These rules are highly related to the task ontology (see Fig. 3). By following this speciﬁc taxonomy, we ensure that by adding production rules in the future, they will be fully supported by the execution model. We can also note that each of the rules set has to make a speciﬁc link between the task and domain ontologies. The speciﬁc links are formalized in the task ontology and evaluated or executed during the execution of the model. In order to let the interpretor execute the rules automatically, we have to use a reasoner supporting OWL knowledge and SWRL rules. In other words, the reasoner is activating the rules allowing the automatic manipulation of the knowledge. Pellet has been selected for its ability to support the description logic associated with OWL, and the individuals with its ability to support SWRL rules [18]. Multiple reasoners are available, but the ability to reason over the individuals by using the SWRL rules makes Pellet an eﬃcient choice. According to Abburu and Sunitha [1], the following reasoner supports SWRL rules and individuals: RACER, SWRL-IQ, or HermiT. 4.2  
  The Execution Process  
  Conclusion  
  In this paper, we proposed an interpretor capable of manipulating the knowledge about the reference procedures for piloting an aircraft. The task and domain taxonomies and their speciﬁc characteristics for the execution have been presented. Semantic links between those two ontologies make the execution model highly related to the execution environment. The interpretor is presented as a set of SWRL rules capable of manipulating the knowledge in order to execute the reference model autonomously. Diﬀerent groups of rules allow a complete execution strategy: constraint evaluation, precondition evaluation, and execution. Since the model has to be executed within a simulation environment, we suggested a library for using the model with a well-known programming language. This work is an intermediary step for a solution that will follow the execution of the procedures of a human pilot within a simulation environment. Future work will focus on the task of monitoring the execution of the normal and abnormal  
  The popularity of inclusive education has grown in recent years. Most children with blindness, and especially low vision children, now start their education in mainstream schools [4]. This trend has been confirmed by the European Agency Statistics on Inclusive Education (EASIE) [7]. The statistics tracked the placement of children/learners with recognized special educational needs (SEN) in inclusive or special settings for almost all European countries over the last decade. They showed that the number of students with SEN educated in mainstream (pre-)schools as compared to special (pre-) schools has been growing year by year [7]. Despite the mentioned advantages, inclusive education encounters many problems and obstacles. A systematic review on inclusive education of students with visual impairment focused on two aspects: perceptions of general education teachers, and challenges faced by students with blindness [1]. Research shows that teachers and students need effective teaching-learning tools and access to learning materials [5, 8]. The teachers must consider the barriers faced by blind students when designing instructional methods for them. In the context of classroom activities, students with blindness may encounter difficulties related to school activities [2]. These challenges inspired us to develop a tool and method to support inclusive mathematics education for people with blindness while learning science subjects (our study focuses on learning mathematics). The method assists both the teacher and student while simultaneously supporting the teaching process. This paper presents our math tutoring platform designed to teach sighted and blind students in inclusive education using audio-tactile graphics. The platform uses augmented learning strategies to adapt the presentation of math exercises to meet the needs and overcome the limitations of students with blindness. It allows students with blindness to solve the same exercises as those solved by sighted students, while remotely supervised by a teacher. Educators using the platform can identify students’ difficulties by monitoring their progress while solving exercises, as well as track how students with blindness explore images.  
  2 Related Works In recent years, there has been rapid development of tools such as educational software, e-learning platforms, and assistive technologies. The latter include screen readers and magnifiers, which allow everyone to use digital materials. The basic source of information in the humanities is text, which can be easily scanned, recognized, and read using speech synthesizers. People who are blind process cognitive information in the same way as sighted students. However, they must assemble information through haptic or auditory channels, which as other researchers have noted [9, 10], can be a disadvantage. Although the modes of information collection are clearly different between blind and sighted students, their cognitive structures and operation process are the same [11]. It is necessary to prepare materials, media, or techniques that help all students accomplish learning goals. Teachers should provide various assessment methods, materials on how to teach students with blindness, and other aids to ensure equal access to the learning process for all students [5, 12].  
  M. Ma´ckowski et al.  
  Despite the rapid development of information technologies, inequality persists in the access to information for sighted students and those who are blind. This disparity is especially apparent in the case of multimedia platforms or technical data including specific symbols, diagrams, or other formats inaccessible to blind people. In other words, extant technologies in many ways are not capable of automatically transforming such data into forms accessible to those who are blind [13]. Mathematics and math science face this problem. Both presenting such information to blind students and gauging their understanding of the material remains challenging. Images play a significant role in science subjects, as the presentation of information is mainly visual and contains many formulas, charts, and diagrams. Thus, two questions present themselves: how to present such materials to people who are blind, and how to assess their learning progress [14, 15]? A literature review identified many studies that described alternative methods of presenting graphical information to blind students, especially in interactive audio-tactile form [16–18]. These papers presented several methods for identifying elements of a picture that a blind user selects by touch to provide a description. Several tools have been developed to provide alternative presentations of mathematical formulas and expressions for blind students. For example, one approach is to automatically convert a mathematical expression into an audio description or mathematical Braille notation describing its structure [19, 20]. Methods for automatic conversion of expressions using, e.g., MathML, are known [21]. Other researchers suggested ways of implementing math notation in electronic form using special tools such as Lambda editor, InftyEditor, and Duxbury Braille Translator [22, 23]. Creation of new mathematical notations are based on extensions to already established software products such as BlindMoose and Math Type for Microsoft Word, odt2braille for Open/Libre Office Writer, and the MathML extension of the DAISY format. Another group of solutions uses alternative means to present graphics used in science education. These include touch tablets with dedicated software such as Talking Tactile Tablet produced by Touch Graphics and the IVEO by ViewPlus2 [24, 25]. Other researchers showed how to use popular tablets with a large diagonal together with proprietary software for interactive audio and touch presentation of graphic information [26]. Moreover, in paper [27] User-Centered Design approach was used to develop an effective solution for visually impaired students. In many such solutions, mathematical objects such as formulas and images are supplemented with text or audio descriptions, which is a form of Augmented Reality (AR) [19]. The aforementioned solutions allow teachers to share tailored learning materials with students during lessons, but they fail to assess the student’s work progress when solving exercises. The teacher must spend extra time conversing with the student to monitor their progress or identify problems the student is experiencing. Such solutions work best in special schools or in integration classes where the main teacher is supported by an assistant in accessible education. Such an assistant should have experience preparing adapted educational materials (tactile images, alternative descriptions, etc.) and the use of Braille notebooks. However, the foregoing solutions are ineffective and often insufficient for inclusive education. Students in the classroom should be treated equally and must not feel  
  Method and Tools to Supporting Math Learning  
  disrespected. We developed a multimedia platform enabling joint learning of sighted and blind students in mainstream mathematics classes as a response to the previously identified problems in inclusive education [2–4, 6, 10, 28]. Our contribution is to develop a proposed method and provide tools supporting math learning in inclusive education of blind students. The platform includes a mechanism for indirect assessment of student skills by combining the vector of knowledge metric with logged information about mistakes made while solving exercises. Next, we proposed audio-tactile descriptions with different levels of detail to manage the increasing number of terms occurring in audio description (cognitive load problem).  
  3 Materials and Methods 3.1 Proposed Solution The developed platform uses a client-server architecture. The server application stores and distributes educational materials and mediates communication between the teacher and the student during class. The server application also allows the teacher to monitor the student’s work while solving exercises. The platform is equipped with a web application responsible for managing the learning process (learning management system) and preparing educational materials in the form of SVG audio-tactile images. A detailed description of the platform are presented in authors’ prior papers [29, 30]. In the previous study we demonstrated improvements in learning effectiveness using the developed platform [31]. Using a dedicated client application on a mobile tablet, the student could solve exercises using audio-tactile images and solve tests whose results were sent to the server. Using a web application, the teacher could view the list of exercises solved by the student along with completed tests-the principle of operation was based on the asynchronous mode of work between the teacher and the student. Prior to its use in integration classes, the system was quantitatively and qualitatively evaluated for functionality and usefulness in special schools for blind students. The system’s impact on learning efficiency in comparison with traditional Braille books and relief drawings was studied. The evaluation was carried out on 2 groups of students: 20 from primary school and 24 from high school. The number of mistakes made while solving exercises with and without the system were recorded. The exercises concerned the properties of geometric figures and the properties of functions based on their graphs. In both cases, the number of errors made and the time needed to complete the exercises decreased by a statistically significant amount. Details can be found in an earlier publication [29, 31]. The present study concerns an extension of the existing platform with mobile client modules. These are mobile applications dedicated to both sighted and blind students as well as teachers. The teacher’s application allows for ongoing (synchronous) observation of student progress while solving exercises. This feature makes it possible to use the system in inclusive education. Figure 1 shows a schematic for solving the same exercise by both sighted students and those students who are blind in our developed solution. First, the teacher selects an exercise from a previously prepared set. This exercise is displayed on tablets (phones) of sighted students via a graphical user interface. The  
  M. Ma´ckowski et al.  
  student results was rated relatively low. This result was caused by the limited time for evaluation of the tool (1 semester), which made it impossible to assess the durability of acquired knowledge in the form of skills their application to other areas of life. Students with blindness rated the ergonomics of the audio-tactile interface and the possibility of cooperation with peers the highest. They rated the possibility of selflearning relatively low. Self-study requires overcoming all the barriers mentioned in the introduction and changing one’s attitude. This is the hardest goal to achieve for less skilled students. It was observed that lower values in this category correlate with the test score averages. Sighted students rated the possibility of cooperation with blind peers the highest. They scored the lowest on usability, which may indicate that they perform at a similar level when solving exercises in the traditional way.  
  Fig. 4. Questionary research results using Likert scale.  
  possibility of learning together and the possibility of consolidating their knowledge by helping students with blindness learn. Easy to implement and integrate the system while learning Teachers emphasized the relative ease of implementing the tool on a ready-made set of sample exercises. However, they remarked that preparing new exercises required considerable effort. This result suggests that future work include the development of a wide, generally available set of exercises and the development of tools for semiautomated preparation of new exercises. Completeness of the system – strengths and weaknesses Currently, the method requires quite a lot of involvement from the teacher when using the system (e.g., in exercise selection). In the future, more individual reports on the student and the selection of homework tailored to the kinds of errors made could occur automatically by using the knowledge vector and the error vector.  
  Fig. 2. Recommendation interface for the chapter Statistics (9th grade) for the revision strategy: on the left from the quiz failed entry point, in the middle for the path interrupted, on the right at the end of the path. Grade levels are displayed in parenthesis. Common notions between chapters are displayed in orange. (Color ﬁgure online)  
  our recommendation system as Recommendation interface viewed, Recommendation chosen, Recommendation interface left, but also more generic activities as Connection to the app, Quiz started, Course read, with associated context information (learner grade level, content discipline, working session identiﬁer, date and time, etc). Learners are anonymized to respect data privacy. In the following sections we present the results observed between September 2022 and January 2023.  
  3  
  Conclusion  
  In this paper, we introduce a cognitive agent based on the ACT-R cognitive architecture that utilizes an ontological reference model to perform tasks in the aviation domain. The declarative memory of the agent captures and formalizes knowledge from the domain ontology, which represents the internal and external environments and aircraft navigation systems, and the task ontology, which captures and formalizes piloting procedures. Using a class diagram, we modeled the complex structure of a task and the relationships between its components. When executing a task, the cognitive agent searches the knowledge formalized by the reference model to perform the task. We presented its behavior and interactions with other components using a sequence diagram. Our simulations demonstrated the cognitive execution cycle of a complex piloting task, and the results showed that the agent executed the task similarly to a human pilot. As the reference model continues to incorporate the cognitive dimension associated with each task, a second perspective is to develop a version of the cognitive agent that integrates parameters such as the pilot’s attention or emotions. Additionally, since cognition is embodied, social, and situated, a third perspective is to immerse the cognitive agent in a simulator such as Xplane or other ﬂight simulators with suitable adaptations. Finally, a fourth perspective is to use the cognitive agent to manage deviations in a cockpit. Acknowledgement. We acknowledge the support of CRIAQ, the Natural Sciences and Engineering Research Council of Canada (NSERC), CAE, Bombardier, and BMU.  
  Abstract. One of the important features of intelligent tutoring systems is providing feedback so that the learners who have problems can understand and ﬁx their errors. Two popular approaches to implementing it are demonstrating worked examples and providing explanatory feedback about the errors the learner made. Pedagogical questions - small, speciﬁc questions aimed at the thought process required to make the correct conclusion are often overlooked. Generating pedagogical questions to help the learner is beneﬁcial because answering questions stimulates information retrieval and thinking. It also gives the tutoring system detailed information about the learner’s misconceptions. However, creating systems of pedagogical questions manually requires a lot of eﬀort, even in relatively simple domains. In this paper, we propose four kinds of pedagogical questions that can be generated from a formal description of the taught skill, provide examples of pedagogical questions, and discuss the advantages and disadvantages of their use. Keywords: Pedagogical questions Intelligent tutoring systems  
  1  
  O. Sychev and M. Gumerov  
  Generating smaller questions is a less-used approach. Razzaq and Heﬀerman [19] describe a technique of using scaﬀolding questions and prove it eﬃciency, but they do not go farther than breaking the problematic problem-solving step into smaller steps and do not provide a technique for identifying of generating scaﬀolding questions. Pedagogical questions can do more by assessing the line of reasoning required to perform a step correctly. Small questions about the knowledge necessary to solve the task at hand stimulate thinking and information retrieval and can lead to realizations and better absorbing information than hints, simply telling the student what is true. Pedagogical questions can turn interactions with the learning system into a dialogue with the tutoring agent which brings it closer to human communications. However, the question-generating strategy must be optimized to avoid repeatedly asking dull, trivial questions until the student reveals that their knowledge is poor enough for these questions to be useful. Software engineering education is a good domain to implement pedagogical questions because it includes learning a signiﬁcant number of well-deﬁned thought processes that must be learned precisely: from understanding an expression to designing databases and applications. In the previous work [7], we developed a method of building sets of reasoning errors that are possible when solving a learning problem based on the formal description of the line of thought required to solve the problem. In this paper, we propose a subsystem of automatically generating pedagogical question sequences that determine which errors are factually made based on the same data.  
  2  
  [14] systems feature exercises, built upon the program’s visualization by making students interact with data structure’s visual representations, manipulating them to match the way a computer will execute the given program. This can be enhanced by pop-up multiple choice questions, as it is done in VILLE [18] – a program visualization system where an exercise author can create pop-up questions to appear at certain states of program visualization. These approaches are good to engage learners and integrate knowledge about program execution, but the only form of feedback they give is visualizing the current program state and its changes. If the learner does not know what to do next, they need a way to understand it step by step. Another approach to automated tutoring is represented by the Problets series of automatic tutor developed by A. Kumar [5]. They concentrate on diﬀerent aspects of programming, allowing students to learn diﬀerent topics one by one instead of showing the entire process of program execution. These tutors split the answer to a learning problem into smaller sub-answers (steps) that the learner can enter [9,13]. Immediate feedback is provided by color-coding answers to steps based on their correctness [12,13]: correct, incorrect or incomplete [3,12], sometimes accompanied by text messages, telling the learner what was wrong. An on-demand feedback option is also often present [9,12], providing detailed description of the correct way to solve a problem, serving as a worked example. 2.2  
  Scaﬀolding in Tutoring Systems  
  Question Generation  
  Writing a big amount of scaﬀolding questions manually is undesirable because of high labour costs, the complex structure of dependencies between scaﬀolding questions (see Fig. 11 in [22]), and the diﬃculty of keeping generated questions systematic. These problems can be solved by automatic question generation. Myller proposed a method of automatic generation of prediction questions for Jeliot 3 [16], which is similar to O’Rourke’s approach to explaining TPL code. Myller’s approach relies on assigning static (as opposed to O’Rourke’s dynamically constructed) questions to statements of Java code visualized using Jeliot. As the java code is executed, the system can check if a question for the current instruction is deﬁned and, if found, display it to the user. The system creates a list of answers for the question consisting of a correct answer, which is the outcome of the line’s execution, and several randomly chosen distractors. These questions concern solving the problem (predicting results of code execution) but not the thought process required to solve the problem. Another question-generation approach is described in a paper by Zavala and Mendoza [23]. In this work, a question is an independent exercise (not a step within a larger learning problem) and is deﬁned by question text (stem), a list of answer options if the question is multi-choice and a generator script. Both the stem and the answer options use embedded variables that act like placeholders for problem-speciﬁc values. The generator script is used to generate the values for embedded variables as well as the correct answer if the answer is textual. The use of a generator script allows for more variety when creating an exercise. While  
  Generating Pedagogical Questions to Help Students Learn  
  this method allows the creation of several similar questions from a template, the question templates, including the generator scripts, deﬁning kinds and structure of questions for each new learning situation must be deﬁned by the author. There is a lot of work on question generation from natural-language texts (e.g., [4]), but this approach is most suitable for verifying if the learner read the text. The number and precision of the generated questions are not enough to ensure that the learner mastered the technique, described in the text. Given the current state of question generation, the only viable way of generating scaﬀolding questions is using a description of the thought process required to solve the problem in some formal language (e.g., TPL [17]).  
  3  
  Kinds of Pedagogical Questions  
  We identiﬁed several kinds of pedagogical questions that can be generated automatically based on the Thought Process model. The questions are asked in a particular learning situation, including problem formulation, the current problem-solving step, variable values, and correct reasoning path according to the tree. The learning situation can describe a learner’s error (Verifying Tree is used) or the situation when the learner does not understand what to do next (Hinting Tree is used). These questions are multiple choice questions with a single or multiple correct answers, so that each answer variant can lead to the next question (depending on the answer) or explanation (if the learner’s problem was identiﬁed), shown to the learner. – Variable value questions: “What is the value of ?”. A set of possible answers is based on what kind of objects from the learning situation the variable in question can hold. This kind of question allows to check if the learner performs actions correctly. – Final node questions: “Which determines the outcome in the current situation?”. These questions allow the system to quickly check what made the learner make a wrong move during problem-solving and to adapt the questioning strategy. These are single-choice questions whose sets of possible answers are formed from the nodes of the current branch of the decision tree. – Node questions: asks the learner about the results in a particular node given the current learning situation. They are mostly used for question nodes because action nodes are covered by the variable value questions. The set of answers is deﬁned by possible answers to question in the given node (labeled at its outgoing edges). These questions can identify reasoning errors when the learner asked the right question but gave a wrong answer to it because they did not know relevant facts of the subject domain. For independent branching nodes these questions ask for the results of the whole node, which can be followed by the questions about particular branches. For logical aggregation, node questions contains two parts: it asks for the aggregation results and for results for each branch. Iteration nodes produce three kinds of node questions: the question about aggregation results, the set of iterated objects, and individual results for each object. – Structural questions: concern the edges of the decision tree “Given the what should you do next?”. These questions concern situations when the learner answered the question correctly but does not understand the consequences of this answer, i.e. the algorithm of reasoning. The set of answers is created from the decision-tree nodes that use variables known at this point. 3.3  
  Generating Question and Answer Formulations  
  Algorithm 1. Strategy of asking pedagogical questions 1: Determine Deciding Variables: a set of variables which receive values in the correct reasoning path through the Thought Process and whose values are used at least once later in the correct reasoning path. 2: if Deciding Variables isn’t empty then 3: Perform a Faulty Variable Search on a list of Deciding Variables. 4: end if 5: Determine Final Nodes: ﬁnal nodes are the nodes that have at least one outcome linking them to a conclusion node for the current Thought Branch. The correct ﬁnal node is the ﬁnal node that lies on the correct reasoning path — i.e., the reasoning step determining the ﬁnal decision in this situation. 6: if Final Nodes contain at least two nodes then 7: Ask a Final Node question with Final Nodes as the set of answers to determine the learner’s chosen ﬁnal node. 8: else 9: Assume that the learner chose the correct ﬁnal node. 10: end if 11: Determine the lowest common ancestor (LCA) of the learner’s chosen ﬁnal node and the correct ﬁnal node. 12: if LCA is not the learner’s chosen ﬁnal node then 13: Ask a Structural question about the outcome leading to the LCA. 14: end if 15: Start with the current node being LCA 16: while No learner’s error is found do  Do a step-by-step questioning to ﬁx the learner’s understanding of the Thought process structure 17: Ask a Node question about the current node. 18: Ask a Structural question about the current node’s correct outcome. 19: Move to the node following the current node’s correct outcome. 20: end while  
  We can implement diﬀerent strategies of generating pedagogical questions using the same thought-process model; their eﬃciency must be compared experimentally. We propose one possible algorithm (see Algorithm 1) of using pedagogical questions which tries to ﬁnd balance between precision (asking the learner about everything necessary to solve the task to ﬁnd the ﬁrst error) and the number of questions asked (ﬁrst nodes of the decision tree are often trivial). To understand this strategy of questioning, it is necessary to keep in mind the fact that many of the nodes in the decision tree use variables whose values were determined before, and these values are mentioned in the question text, so it is unfeasible to ask node and structural questions concerning these nodes until we are sure that the learner calculated the required variable correctly. So questions verifying variable values should, typically, come ﬁrst. Also, questions about required nodes allow quick surveying the learner’s line of thought and so can be used to detect reasoning errors quicker when used at the beginning. In this strategy, Faulty Variable Search and checking the understanding of the structure of the Thought Process can be performed linearly (from the start of the correct reasoning path; this method asks a lot of questions but allows  
  M. Ghaderi et al.  
  aviation professionals must maintain a high level of situational awareness and attention to detail. Pilots must pay close attention in the cockpit to monitor and change a variety of flight factors, such as airspeed, altitude, heading, and navigation. In order to maintain situational awareness and react to potential threats and hazards, and respond in emergency situations, they must also continuously monitor flight instruments and scan the surrounding environment. Visual information is an essential aspect of the process of acquiring and transmitting information to the brain. The visual system is responsible for processing information from the environment through the eyes and sending it to the brain for further analysis and interpretation [5]. This allows the brain to prioritize the most important visual information and process it more efficiently, leading to better perception and understanding of the environment. In order to attend to visual information, the brain must first detect and recognize relevant visual stimuli. The photoreceptors—specialized cells that capture light and transmit signals to the brain via the optic nerve—start this process in the retina. After entering the brain, visual information is processed in a number of steps, requiring different of processing and interpretation levels [6]. Eye tracking technology involves detecting the movements and gaze of a person’s eyes to determine what they are looking at or paying attention to. In the context of flight, eye-tracking technology can be used in several ways, such as piloting, flight simulation, and cabin management. Eye tracking can be used to control the movement of aircraft or to monitor the visual attention of pilots to detect signs of stress or fatigue. Furthermore, eye tracking can be utilized to control pilot attention and comfort levels to improve cabin design and services. In addition, eye tracking can be used in flight simulators to track a pilot’s gaze and determine where they are directing their attention. For example, acquired information from eye tracking can be used to modify and control various elements in the simulation, such as bringing up information relevant to the object the pilot is looking at or changing the view in the cockpit. Finally, the aim of using eye tracking in flight simulators is to increase realism and give pilots a more immersive training environment. To measure a pilot’s attention during a flight, eye tracking devices must first follow the pilot’s gaze and locate where they are looking. These data can then be used to calculate how much time the pilot spent looking at various components in the cockpit, such as instruments, controls, or the aircraft’s exterior. In addition, the eye tracking devices may also measure other parameters such as pupil dilation and position, fixation, saccade, and blink rate which may provide additional insight into the level of attention and engagement of the pilot. Eye tracking can provide useful insights into a pilot’s attention for training and performance evaluation. Generally, eye tracking technology could improve comfort, safety, and effectiveness in a variety of flight operations applications. A brief description of the related works is presented in Sect. 2. Section 3 focuses on the experimental process, including the structure and steps of the experiments. The relationship between attention and eye tracking is explained in Sect. 4. In Sect. 5, we present an analysis of the experiment, and in Sect. 6, we discuss the results of the experiment. The conclusion and future directions of research are presented in Sect. 7.  
  Attention Assessment of Aircraft Pilots Using Eye Tracking  
  M. Ghaderi et al.  
  In eye tracking, a person’s gaze is tracked as he or she looks at a visual display, such as a computer screen or a poster. Eye tracking records where and how long people look in a scene, giving insight into what they find salient. As a result of this information, it is possible to understand how visual factors in a scene are related to object saliency. Thus, an eye-tracking system can link visual factors and visual saliency. The main eye-tracking indexes which can be used to determine the relationship between the eye tracking index and visual attention [6], and their specific meaning are presented based on the gaze point documentation: • Fixation POG: By using the internal fixation filter, POG (Point of Gaze) data determines the user’s point-of-gaze, expressed as FPOGX and FPOGY. In other words, Fixation Point of Gaze (POG) refers to the specific location where a person’s eyes are focused on when they are observing a visual display. • FPOGS: POG start times which are expressed in seconds since system initialization. Using the FPOGS in eye tracking can provide insight into the initial focus of attention, which can be used to identify the most salient or noticeable features. • FPOGD: The fixation POG duration in seconds. • FPOGID: Number associated with the fixation POG. As mentioned earlier, pixels (pixel as the smallest unit), can be used to divide the target screen into areas of interest (AOI). We divided the screen into 5 areas of interest based on area of pixels. point in a coordinate is named by its ordered pair of the form of (x, y). The first number corresponds to the x-coordinates and the second to the y-coordinate. For screen coordinates, the origin is the upper-left corner of the screen. Usually, the full position of a window is represented as a rectangle with two points defining its upper-left and lower-right corners. Each window coordinate, which consists of four numbers separated by commas or spaces, defines the boundaries of each area of interest. Two points on the screen are represented by these four numbers. “X” and “Y” coordinates of the first point are indicated by the first two numbers, while “X” and “Y” coordinates of the second point are indicated by the final two numbers. The screen’s upper-left corner is marked by “0,0,” while its lower-right corner is marked by “1,1.” The screen’s centre is marked by [0.5,0.5]. By using these two points, we can define the position and size of a window. Specifically, the first point defines the upper-left corner of the window, while the second point defines the lower-right corner. It is possible to define a window’s position and size using these two points. The boundaries of each area of interest are as follows: • • • • • •  
  Fig. 3. Distribution of fixation duration across AOIs Related to Pilot 6 and 5  
  6 Discussion and Results As shown in the figure below (Fig. 4), the duration of the fixation POG at each Area of Interest is shown in seconds, 3 s before and after the engine failure. The figure on the right represents the 6th participant, and the figure on the left represents the 5th participant. In the 3 s leading up to the engine failure, the 6th participant looked at the primary flight display and the most at the runway and had everything under control. The pilot’s attention was only focused on the front window (Runway) once the engine failed, so he could keep the plane on its course by controlling the pedals. However, the figure on the left shows that before the engine failure, the 5th participant mostly looked at the primary flight display and the front window (Runway), failing to pay attention enough to the other runway, which is very critical at the time of failure. Additionally, he was not only focused on the runway at the time of the engine failure  
  Attention Assessment of Aircraft Pilots Using Eye Tracking  
  Introduction  
  People exchange or gain knowledge using languages, images, symbols, and other communication tools. Eﬃcient communication or knowledge exchange depends on one’s ability to convey information clearly and accurately so that its receiver can easily understand or decode it. Similarly, machines interpret and process natural language only if it is machine-readable. The automatic conversion from unstructured data into structured one is known as knowledge extraction, which can be arduous due to polysemy, free word order, complex morphology, etc. Artiﬁcial Intelligence researchers have developed various natural language processing (NLP) techniques to allow machines to read, understand and derive meaning from a human language. Natural language processing (NLP) is a subﬁeld of computer science, linguistics, and artiﬁcial intelligence that studies the interaction between computers and natural languages. NLP tasks include natural language understanding (NLU, transforming human language into a machine-readable format) and natural language generation (NLG, converting information from computer representations into human-readable text). NLP techniques can be applied to several modules of an Intelligent Tutoring System, such as knowledge representation, user modelling, feedback and assessment, and dialogue management. This can enable the system to provide a more personalized and engaging learning experience by better understanding learners’ needs and interactions. The KEMMRL converts natural language text into a semantic hypergraph using standard deep learning techniques in the natural language processing phase and specially deﬁned rules in the knowledge extraction phase. We created knowledge extraction rules that convert syntactic annotations into speciﬁc labels to be embedded in the semantic hypergraph [18]. Compared to other methods for semantic parsing in [8], KEMMRL allows diﬀerent natural language processing (NLP) and natural language generation (NLG) tasks. It provides mechanisms for natural language inference, co-reference resolution, topic modelling, etc. The advantage of using a semantic hypergraph to represent knowledge is that it allows the reconstruction of a sentence in its original form and the creation of new concepts from existing ones. However, its main disadvantage is its inability to reduce vagueness in automatic knowledge inference. The motivation behind this research is to apply semantic hypergraph in an Intelligent Tutoring System (ITS) [22] more precisely in its communication module designed for question-answer pair generation. The hypergraph can help the system identify relevant concepts and associations that may be overlooked by traditional keyword-based approaches and other similar approaches, resulting in more accurate and comprehensive answers to learner queries. Our main contributions are as follows: – We designed a model for knowledge extraction and semantic hypergraphbased knowledge representation. – The KEMMRL ﬂexibility and extensibility allow researchers of similar languages to adapt the model to their requirements.  
  Semantic Hypergraph-Based Knowledge Representation  
  As mentioned before, the output of the knowledge extraction is knowledge represented in the form of a semantic hypergraph. It is a graph whose vertices and hyperedges have speciﬁc labels representing the roles of hyperedges in the sentence. They also determine the semantics of the event expressed in it. The semantic hypergraph used in this research is an ordered recursive hypergraph. Its ordering property is as essential as the word order in the sentence. The recursive property allows hyperedges to connect with other hyperedges similar to sentence building blocks. These properties make an ordered recursive hypergraph an ideal structure for knowledge representation.  : V → Uv⊆V π(v) for every vertex v ∈ V Let V = {v1 , ..., vn }, the function associates all permutations of set π(v). π(v) =  
   n!  {v} | v is not a set πi (v)| v is a set, πi (v) ith per. of v  
  The HRtagger and HRparser showed the best results in measuring the structural similarity of hypergraphs. They used an algorithm for comparing the similarity of the adjacency matrices of two hypergraphs. As expected the method with the best parsing accuracy (due to a dependency tree-based structure) obtained the best results in measuring the structural similarity of hypergraphs. We also evaluated the percentage of semantic roles and labels of hyperedge vertices that the HRtagger and HRparser successfully identiﬁed. The α evaluation method checked the quality of knowledge extracted using HRtagger and HRparser methods. Table 4 shows the results of the α evaluation method, using Precision, Recall and F1 metrics. Table 4. Results indicating the percentage of correctly identiﬁed semantic roles and labels in the SemCro corpus. Method  
  Precision Recall  
  Siberian Federal University, Zheleznogorsk, Russia [email protected]  Volgograd State Technical University, Volgograd, Russia  
  Abstract. The paper deals with the problem of synthesizing texts that explain decisions of an Intelligent Tutoring System for the learner. Solving this problem is important for increasing human trust in the ITS decisions by ﬁnding eﬀective arguments and synthesizing explanatory texts. We describe an approach to preparing and concentrating raw data that is similar to the process used for mapping. The texts explaining the system’s decisions are generated using the method of parametric maps, which are visualized as Cognitive Maps of Knowledge Diagnosis: the transition from particular maps to the combined map and the development of a system of arguments based on these data. We show the structure of an explanatory text and the accompanying visualization of a cognitive map. We demonstrate the explanation synthesis on the example of a graduate student in the course “Simulation modeling”. The explanation consists of the text and supporting visualization. Preliminary analysis has shown signiﬁcant student interest in receiving explanations, containing verbal and non-verbal (cognitive maps) components, from the Intelligent Tutoring System about its decisions. Keywords: Intelligent Tutoring Systems · cognitive visualization · decision making · explainable AI · explanatory text · Cognitive Maps of Knowledge Diagnosis  
  1  
  V. Uglev and O. Sychev  
  learn more about the reasons for the ITS decisions while the system can update the learner model using the information acquired through the explanatory dialogue. Dialogue in ITS can be divided into two chief categories: dialogue related to the studied material (content-related dialogue) and dialogue related to learning process (didactic dialogue). Some ITS use static content-related dialogue entered by authors or teachers (e.g., in the form of scaﬀolding questions [11]). It can be dynamically generated based on ontologies of subject domains (e.g., [10,17,24]). But developing speciﬁc subject-domain models is very time-consuming and their usage is limited to the courses teaching the relevant subject domain. Didactic dialogue is more generalizable because decisions making and explanatory text synthesis in ITS can by uniﬁed if the course speciﬁcs are described in general terms by a learning-process ontology (e.g., [5]) or using other methods of learning-unit organization (e.g., [22,25]). So we can develop a generalized method of generating explanations which allow answering questions like “Why and how this decision was made?” or “Why do I need this?”. Let’s call this kind of dialogue a didactic dialogue. It can be useful in forming personalised learning collections and personalised learning trajectories when showing hints and recommendations about topics to study next, during an assessment of the learning situation, and while discussing the situation [19]. The dialogue mode can be initiated by the learner or by the ITS. The topic of didactic dialogue can be either a part of a course (e.g., a term, assignment, learning unit, topic, course or curriculum) or other learning entities (e.g., competencies, standards, methods of grading and decision-making, learner’s actions). This makes it important to use both verbal and non-verbal (e.g., cognitive maps) methods of supporting the dialogue. The didactic dialogue starts from a well-reasoned explanatory text which starts the dialogue. In this paper, we consider the problem of synthesizing explanatory texts that start didactic dialogues with an ITS. Table 1 shows a comparative analysis of modern ITS with developed explanatory text capabilities. They mostly lack complex solutions using ﬂexible (for different entities) support of the didactic dialogue process with explanations and supporting cognitive visualization. No ITS has “Yes” in all the columns. So further research in this ﬁeld is relevant. In this paper, we consider an approach to explaining didactic decisions in ITS based on the information concentrated for cognitive maps (including their visualization). We brieﬂy sketch the technology of concentrating and mapping data, describe the stages of synthesizing explanatory text and the templates used, consider a case study of didactic explanation and formulate recommendations for developing and using the explainable AI approach for ITS.  
  2 2.1  
  Method of Synthesizing Explanatory Text Data Concentration and Mapping  
  Consider the model of an e-learning course, consisting of course elements, connections between them, and supporting entities. ITS logs (as a digital learning  
  Synthesizing Didactic Explanatory Texts ITS  
  Table 1. Comparison of didactic-explanation characteristics of diﬀerent ITS System  
  Interdisciplinary connections  
  Yes  
  ITS with knowledge graphs [18]  
  No  
  No  
  footprint) time and frequency data concerning working with course elements, answers to tests and assignments, and survey data. These data require generalization (concentration) both for determining the control action and synthesizing its explanation. For this, a chain of concentration is used: statistical concentrations → metric concentration → semantic concentration → logical concentration. At the stage of metric concentrations, mapping techniques are used: the basic model of the e-learning course in the Cognitive Map of Knowledge Diagnosis (CMKD) notation (see Fig. 1a) is overlaid with the digital footprint data regarding the chosen analysis aspect, time dynamics and decision-making level (see the visualized example of a cognitive map for competency aspect in Fig. 1b; it is explained in detail in [20]). These cognitive maps will be discussed in Sect. 3 during a case study.  
  Fig. 1. Basic CMKD for the course “Simulation modeling” (a) and its individualized variants for the competence (b) and course (c) aspects.  
  2.2  
  Explanatory Form  
  Explanatory form is shown as the ITS reaction to an event (e.g., passing a control point in the course) or at the learner’s initiative (e.g., by pressing the button  
  V. Uglev and O. Sychev  
  to ask for explanation while watching learning material). Further in this paper, we will consider using the explanatory form to explain the system’s decision as a reaction to an event which is the most important case. Didactic explanation combines verbal (text) and non-verbal (cognitive map in the visualized form) parts. The basic explanatory text generated by ITS must include the following: – the sentence of qualitative evaluation of learner’s actions or the learning situation α; – sentences, brieﬂy describing the current situation, emphasizing 1–3 relevant parameters βj ; – sentences γk , formulating recommendations for further work with the course elements (mentioning the expected result regarding the learner’s goals) for furthering pedagogical intervention and increasing the learner’s motivation; – the sentence that invites the learner for further explanatory dialogue δ. The non-verbal part of the explanation is shown as a CMKD (basic, extended, or simpliﬁed), focusing attention on the subject matter. It is oriented at convincing the learner in the potential usefulness of following the system recommendations. The invitation to continue dialogue is supplemented with the necessary controls (request constructor). According to our method, to generate the verbal part of the explanatory form, ITS should perform the following actions, based on the cross-cutting approach to decision-making on the course level [22]: 1. statistic concentration of data regarding the chosen (by ITS) pedagogical intervention for each learning unit ui with overlaying of these data on the individualized course map for each relevant aspect (the relevant aspects are selected according to the current learning problems as shown in [20]); 2. uniting all the problematic elements ui ' in the combined parametric map, characterizing the situation as a whole, which can be extended by inserting additional entities (competences, learner’s goals, etc., which can be semantically linked to the relevant units ui '); 3. evaluation of the signiﬁcance of the learning problems using expert-systems methods and sorting values in ui ' according to their signiﬁcance; 4. simplifying the combined map by removing the less-signiﬁcant elements, emphasizing the elements ui '', which are most signiﬁcant for achieving the result of the pedagogical intervention; 5. selecting 1–2 key problems from ui '' and synthesizing the sentence α according to them; 6. iterating over ui '' and synthesizing sentences βj , reﬂecting the evaluation of mastering learning units or their groups, indicating the found causes of problems in learning and the linked entities; 7. iterating over ui '' and synthesizing (for each problematic unit or their group) 1–3 sentences δk , mentioning the learner’s action that will have the best eﬀect according to the ITS estimation: these sentences include didactic evaluation  
  Synthesizing Didactic Explanatory Texts ITS  
  of learning units (their groups) stating found causes of problems and the relevant entities, enhanced with personally-oriented arguments according to the learner’s model; 8. showing the sentences α, βj and δk ; 9. selecting the most relevant analysis aspect according to the goal of pedagogical intervention and showing the relevant CMKD (typically, in the simpliﬁed form); 10. showing the invitation to continue dialogue δ and request constructor. The method shown above is based on the ITS ability to concentrate data into CMKDs and give the learner an option to interact with the map. The learner, after reviewing the content of the explanatory form, can initiate dialogue (ask to synthesize a new form by their request), jump to one of the mentioned learning units using its hyperlink, return to one of the previous forms (later during the dialogue), start the process of clarifying their preferences (correcting personal goals), or close the explanatory form. 2.3  
  Text Synthesis  
  In the developed ITS AESU, we employed the template-based text synthesis technique. Didactic texts use dictionaries of user-created learning entities which are entered when a course is published in the tutoring system. Teachers cannot aﬀect the general structure of the explanation and its sentences; they can only enter a textual description of entities in their courses. The text is synthesized according to the speciﬁcs of a particular learning situation and the learner’s goals. Let us consider the generation of each block of explanatory text in the situation when the system formulates recommendations on further study of the course after the mid-term exam. The ﬁrst block of explanatory text (α) consists of three parts: statement of the facts (grade) and generalized problem; quality of the learner’s work when studying the course, and a brief listing of the learned objects which are recommended for further study. Grade and Generalized Problem. This sentence is generated according to the following template (translated to English): Your learning results have P1.1 dynamics (the current grade is P1.2 % If1 { and it P1.3 by P1.4 % in comparison with the previous results}) If2 {, but P1.5 problems arise because of inadequate absorption of some elements of the previously studied material}. The parameters P and conditions If are determined as follows: – P1.1 is a qualitative estimate, calculated using fuzzy-logic methods (see [23]) from quantitative grades for the current and previous exams and can be one of the following: {highly positive, positive, slightly positive, slightly negative, negative, highly negative};  
  V. Uglev and O. Sychev  
  – P1.2 and P1.4 are calculated from the grades in the digital learning footprint; – P1.3 is an evaluation of the diﬀerence between the latest and previous grade, which takes a value from the following set {increased, same, decreased}; – P1.5 is a fuzzy estimate of the level of problems in the current learning situation, calculated by an expert system, and can be one of the following {no, some, signiﬁcant, very signiﬁcant}; – the block If1 is shown only if P1.1 is “slightly positive”; – the block If2 is shown only if P1.1 is not “highly positive”. The usage of quantitative fuzzy estimates allows making the explanatory text closer to natural-language dialogue and stimulates the learner to ask for further clariﬁcation of the summarized statements made by the ITS. Quality of the Learner’s Work. This part uses the following template: Your intensity of learning is estimated as P2.1 , while your intention to achieve your stated goals is estimated as P2.2 . Both qualitative parameters of this sentence are estimated by the ITS based on the data in the digital learning footprint, including the data concentrated for the combined CMKD. Intensity of learning is based on the evaluating the frequency of using learning materials in the ITS and time spent learning; the method of estimating the intent to achieve student’s stated goals is described in [19]. The values of P2.1 and P2.2 can be one of the following: {low, average, high}. Recommendation for Further Study. If there are problems in the learning situation (i.e., the value of P1.5 is diﬀerent from “no problems”), the explanatory message is enhanced with the sentence, recommending the learning units that, according to the system estimates, can help with solving the learning problems most. The following sentence template is used: Please, If3 {ﬁrst of all} pay more attention to If1 {P3.1 , P3.2 }. The parameters P and the output condition If are determined as follows: – P3.2 is the list of the most signiﬁcant learning units from ui“ , which were detected during analysis of the combined CMKD (1–3 units), which are joined by commas and the conjunction “and” depending on their number; – P3.1 changes depending on the number of recommended units (i.e., singular “learning unit” or plural “learning units” depending on the number of elements in P3.2 ); – the block If3 is shown if ui“ contains more than 3 values for P3.2 . Russian is a synthetic language [6] so it has more diverse morphology than partly analytical languages like English. The template method of text synthesis allowed us to avoid problems with word form changes. The user-depending words and collocations are entered in the system dictionaries in the required case; an eﬀort was made to formulate all the template phrases so that each user-depending parameter is used in one case only.  
  Synthesizing Didactic Explanatory Texts ITS  
  3  
  Synthesizing Didactic Explanatory Texts ITS  
  V. Uglev and O. Sychev  
  7. the sentences δk were synthesised for each element of ui '' to describe the recommended actions and their expected outcomes as in the following example for the unit u6 (the lower block of the explanatory text in Fig. 3): In the topic 2 “Distributions of pseudo-random variables and their simulation” (t5 ) you should work more on the learning unit “Random variables and their characteristics” (u6 ), which will allow to better develop the competences ‘Can estimate modes of operation of IT-subsystems of space systems and take them into account during development” (PK-7) and “Can analyse professional information, highlight the most important, structure, draw up documents, and present with well-grounded conclusions and recommendations”(OK-3) which are important for you, and also let you better understand the problematic unit “Formalizing transaction streams in queueing models” (u11 ). This recommendation is given to you for the second time! 8. the text α, βj and δk is shown to the student; 9. the most important analysis aspect for the recommendations in α was identiﬁed as the course aspect (for u11 and u12 ), which allowed to generate the simpliﬁed CMKD (see Fig. 3), emphasizing the necessary cause-eﬀect links by red colour, to enhance the generated text; 10. the sentence δ was shown to invite the student to discuss the system to get more information about the ITS decision: see the lower part of the window in Fig. 3 with the request constructor (see Fig. 4) that is collapsed for now to let the student concentrate on the explanation ﬁrst.  
  Fig. 4. Request constructor form in ITS AESU with ﬁlled ﬁelds (translated from Russian).  
  Synthesizing Didactic Explanatory Texts ITS  
  V. Uglev and O. Sychev  
  for making automatic decisions in the learning situation and explaining these decisions. The advantage is applying a uniﬁed approach of analysing learning situations to a wide range of courses. In our experience, an experienced teacher can specify a new course and gather personal preferences using ITS services without spending too much time: a course can be parameterized in 1–1.5 h, while formalization of the existing bank of assignments and tests requires 1–2 working days. The data for CMKD is concentrated automatically and can be used to generate textual explanations according to our method, which makes explanatory forms enhancement of existing decision-supporting techniques which does not require additional input from the teacher.  
  5  
  Synthesizing Didactic Explanatory Texts ITS  
  Abstract. In this paper, we aim to optimize the sequencing of learning activities using the Q-learning, a reinforcement learning method. The Q-learning agent decides each time which activity to propose to the student. The sequencing policy we propose is guided by the aim to improve eﬃciently the student knowledge state. Thus, the Q-learning learns a mapping of the student knowledge states to the optimal activity to perform in that state. In this paper, we tackle two main issues in implementing the Qlearning oﬀ-policy: the combinatorial explosion of the student knowledge states and the deﬁnition of the reward function allowing to improve eﬃciently the student knowledge state. We rely on the student model and the domain model to answer these two challenges. We carried out a study to evaluate the approach we propose on simulated students. We show that our approach is more eﬃcient since it achieves better learning gain with fewer activities than a random policy or an expert based policy. Keywords: Instructional Sequencing · Sequencing policy · Reinforcement learning · Q-learning · student model · domain model Intelligent tutoring system  
  1  
  A. Yessad  
  in ITS since the adaptation process depends on several dimensions of the student (knowledge state, emotional state, motivation, etc.) often hidden and not directly observable by the systems. Several research [2,5,6] have shown the interest of reinforcement learning (RL) for instructional policies, as RL models can learn complex and latent relationships between instructional tasks, students actions, and knowledge outcomes. Given the importance of sequential student-teacher interactions in education, there is a real interest in applying RL to improve the state-of-the-art technology for ITS. In particular, the problem of sequencing the learning activities according to the student characteristics ﬁts well a RL problem [2]. Unlike supervised learning and unsupervised learning, a RL agent learns from direct interaction with its environment. RL is suitable for systems where the agent needs to learn a policy on what to do in diﬀerent situations to maximize a long-term utility [9]. Concretely, it is for an agent to learn how to map states to actions. Often, instructional sequencing approaches rely on a student model that is a partially observable Markov decision process (POMDP) [10]. POMDP models the fact that the student’s knowledge state is a latent variable inferred from some observation function which maps states to probability distributions of observations (student answers). The Bayesian knowledge tracing model (BKT) [4] is a POMDP which has been used to implement cognitive mastery learning in intelligent tutoring systems. Surprisingly, BKT is not considered in the RL framework, because a reward function is not explicitly speciﬁed [5]. We propose in this research to connect the BKT to a RL agent by explicitely deﬁning a reward function. Using the RL raises two challenging tasks: the deﬁnition of the environment state as an input of the RL agent and the deﬁnition of the reward function guiding the learning of the optimal policy. Several model-Based Policies [8] and model-free policies [3] were proposed in the state of the art. In this research, we propose to use the Q-learning [14], a model-free algorithm to learn a sequencing policy. The Q-learning seems to be a good method since we haven’t any explicit model of the optimal decision. We hypothesize that the optimal polocy can be reached through a trial and error strategy. In this research, we rely on the two main components of an ITS, the student model and the domain model to improve the training process of the Q-learning algorithm. On the one hand, the student model is used to infer the student knowledge state each time the student performs a learning activity. The Qlearning learns a mapping of the student knowledge states to a learning activity to recommend in that state. In this paper, we consider only the knowledge state of the student as input to the Q-learning agent. The objective is to learn a sequencing policy that improves eﬃciently the knowledge state of the students. It is well known that the student’s knowledge state may be a complicated function of the history of activities and estimating the parameters of the student model may require enormous amount of data [5]. But we make the assumption that the  
  Instructional Sequencing for ITS  
  student model, when available, allows the convergence of the Q-learning to an eﬃcient sequencing policy. Moreover, we propose a reward function that quantiﬁes the student learning gain according to the student knowledge states inferred by the BKT model [4]. More precisely, we deﬁne the student’s learning gain as the number of new knowledge components acquired by the student since the last recommended learning activity. The reward function we propose aims to maximize the expectation of future learning gains. On the other hand, the domain model allows us to reduce the combinatorial explosion of the number of student knowledge states. RL models need to be trained on student historical data to converge to a good sequencing policy [7]. However, in education, policy evaluation becomes challenging because of the experience is scarce and expensive and the data are sometimes unavailable. In this paper, we answer the issue of data availability by carrying out a ﬁrst study on simulated students. We ﬁrst formalise the problem of instructional sequencing by deﬁning the main elements of the Q-learning policy and the BKT student model. Then, we present our apporoach and focus on the contributions of the domain experts to reduce, on the one hand the combinatorial explosion of the student knowledge states and on the other hand to deﬁne the reward function. Finally, we present the study we carried out to evaluate the proposed approach and its results.  
  2  
  A. Yessad Maximum predicted reward, given new state s’ and all its possible actions a’  
  NewQ(s, a) = Q(s, a) + α [ R(s, a) +         Immediate reward New Q-Value learning rate  
  BKT Model  
  The BKT model [4] is a student modeling method. It is a two state hidden Markov model (see Fig. 1) that is used to infer the student’s mastery of a knowledge component (KC). The BKT assumes that student knowledge is represented as a set of binary variables - one per KC (the skill is either mastered by the student or not). Observations in BKT are also binary: a student gets a problem (or a problem step) either right or wrong [15]. A student has an initial mastery parameter L0 and at every practice opportunity (or observation), a student who has not mastered the KC has some probability of attaining mastery (the parameter T ). If a student has mastered a KC, they will answer a question correctly unless they “slip” with some probability (the parameter S), and if the student has not mastered the KC, they can only guess correctly with some probability (the parameter G). In BKT, each KC is modeled separately without considering any relationships between KCs. Other work on individualized BKT models [15] describes diﬀerent approaches for deﬁning and learning student-speciﬁc parameters. In this reserach, we use the Individualized BKT with student-speciﬁc p(L0) and p(T) [4]. These speciﬁc parameters depend on the KC complexity and the student class (see 7.2). The inference model of the BKT gives us a vector of real values (comprise between 0 and 1)—each value represents the probability of mastery for a KC. In the rest of the paper, this vector related to a student is named the knowledge state of the student.  
  4  
  In this work, we aim to learn a sequencing policy that assigns learning activities to students in order to maximize their learning gains. Our contributions are the following:  
  Instructional Sequencing for ITS  
  Fig. 1. The BKT model and its parameters T, S and G  
  1. we propose a domain-based method to reduce the risk of combinatorial explosion of the number of students’ knowledge states, 2. we deﬁne a reward function that relies on the knowledge states inferred by the BKT model, 3. we evaluate the sequencing policy we propose by comparing it with two baseline approaches  
  Contributions of Human Expertise to the Q-Learning Function Approximation  
  In this section, we present the contributions of domain experts to the Q-learning function approximation. In our case, we identify two major issues that can prevent the convergence of the Q-learning: the combinatorial explosion of the number of the Q-table states (usually called curse of dimensionality) and the deﬁnition of an irrelevant reward function. On the one hand, when the state-action space is small enough, the iterative approximation of the Q-learning algorithm is proved to converge to the true Q-values [13]. However, the combinatorial explosion of the number of possible states in even a modest-size environment makes this table based implementation of Q-learning unfeasible. In our case, we can observe that there is a risk of combinatorial explosion of the number of the Q-table states when the number of the KCs increases. For example, if we have n KCs in the domain model and for each KC we consider a binary random variable representing its mastery (1 if the KC is mastered by the student, 0 otherwise), we obtain 2n knowledge states. Thus, the number of states increases considerably with the number of KC. To answer this issue, we propose an approach based on the domain model. On the other hand, the deﬁnition of a relevant reward function is a challenged task because it guides the sequencing policy towards the objective [11], in our case, achieving eﬃciently the mastering the domain KCs by the students. 5.1  
  Competence Structure  
  The Q-learning agent performs an iterative process until reaching the knowledge state where all the KC are mastered by the student. In each learning episode, the Q-Leaning selects a learning activity to present to the student, based on the  
  Instructional Sequencing for ITS  
  Instructional Sequencing for ITS  
  7.3  
  The results show that the Q-learning policy is in average the most eﬃcient even if it has a standard-deviation greater than the expert-based approach. This is explained by the random initialisations of the Q-table where some ones make longuer the convergence time of the learning process. As expected, the random policy gives the worst results, the standarddeviation between the executions shows a big variations between the executions. The expert based approach is less eﬃcient to the Q-learning policy but close. This result is interesting because it gives us insight into whether RL-based policies lead to better instructional sequences than relying on experts for sequencing. However, we could also explain it that the expert policy is less eﬃcient because certain prerequisite KCs are not necessary to master some KCs and increase thus the mean number for the expert approach. But, we know that is quite hard to have a consensus on the domain model. T-test on these results showed a signiﬁcant diﬀerence between the Q-learning policy and both the Expert-based policy (p = 0.02) and the Random policy (p = 0.03). Moreover, we observe clearly in the learned Q-table that the Q-learning reproduces most of the prerequisite relationships between the KC. This observation is interesting because it may provide a solution to the cold-start issue of the Qlearning when the system interacts with real students. Indeed, we can initialize the Q-table with a dataset of simulated students before using the Q-learning on real data.  
  8  
  Sciences, Amsterdam, The Netherlands [email protected]  2 Faculty of Science, Informatics Institute, University of Amsterdam, Amsterdam, The Netherlands 3 Faculty of Science, API/NOVA, University of Amsterdam, Amsterdam, The Netherlands 4 Department of Astrophysics/IMAPP, Radboud University Nijmegen, Nijmegen, The Netherlands  
  Abstract. We present the Stargazing Live! program comprising a planetarium experience and supporting lesson activities for pre-university physics education. The mobile planetarium aims to inspire and motivate learners using real telescope data during the experience. Learners then consolidate their learning by creating conceptual models in the DynaLearn software. During development of the program, content experts and stakeholders were consulted. Three conceptual model lesson activities have been created: star properties, star states and the fusion-gravity balance. The present paper evaluates the planetarium experience plus the star properties lesson activity in nine grade 11 and 12 classes across three secondary schools in the Netherlands. Learners are very positive about the planetarium experience, but they are less able to link the topics in the planetarium to the curriculum. The conceptual modelling activity improves the learners understanding of the causal relationship between the various stellar properties. Future work includes classroom testing of the star states and fusion-gravity balance lessons. Keywords: Education · Physics education · Planetarium · Conceptual modelling  
  B. Bredeweg et al.  
  the main sequence. Secondly, the quantities may refer to features at different moments during the life span of stars. As such, Pressure and Temperature (of the Core) refer to the features that led to the nuclear fusion starting, while Temperature and Gas pressure (of the Surface) refer to features that result from the nuclear fusion being active. Pilot. A pilot version of the lesson activity star properties was tested by two astrophysics master students, taking about 1 h to complete. Students reflected on the activity and suggested improvements to the workbooks. The models remained unchanged. Model Construction. During the lesson activity each learner starts with an empty canvas and creates the complete model. The task is divided into four steps: (i) the Star with Mass and Gravity, (ii) the Core with Pressure, Temperature and Fusion-Energy, and their relationships with the ingredients in the previous step, (iii) the Surface with Temperature, Wavelength and Luminosity and their relationships with the ingredients in the previous steps, and (iv) discovering the still missing quantities (Gas pressure, Radius and Life span), add those and relate them to the rest of the model.  
  Abstract. Students of a foreign language need help to study vocabulary usually housed in foreign language textbooks. This need can be supported by an artificial vocabulary learning assistant, i.e., software that can ask relevant questions and reliably evaluate the answers. In this work, we present an assistant based on a combination of traditional dialogue generation technology with the latest technology of Generative Pre-trained Transformers. Moreover, we test our software and get admirable results that encourage us to continue our research in this direction. Keywords: Vocabulary tutor · GPT-3 · dialogue system · natural language interface  
  1 Introduction In foreign language learning books, vocabulary sections are often included, i.e., areas that have the structure of a dictionary. More specifically, these sections include a series of terms. For each term, they give its definition, usage examples, explanation, translation in the student’s language and other information, such as what part of speech the term is, etc. When studying such a vocabulary, students often need someone to help them. Typically, the assistant’s role is to hold the book and ask questions of the type: Give me the definition of the term X or an example of its use. After each question, the assistant assesses the student’s answers. In this work, we present such an assistant, which is nevertheless artificial and performs its tasks with admirable reliability. The assistant we propose is based on various technologies with the GPT-3 language model prominent [1], and we call it GPT Vocabulary Tutor or GPT-VT for short. GPT-VT communicates with the learner through natural language and directs the dialogue towards learning specific vocabulary, which can be defined by the learner himself or the learner’s human teacher. GPT-VT also follows basic pedagogical principles. Our contribution consists of the following: 1. In the construction and delivery of a novel artificial vocabulary-learning assistant. The GPT-VT differs substantially from any previous construct intended to aid vocabulary learning.  
  2. We present an architecture that combines the traditional rule-based and patternmatching technology of natural dialogues with modern technology based on the sophisticated transformer neural network [2] and, more specifically, on the GPT3 language model. We manage with this architecture to limit GPT-3, which is an open-domain dialogue system, exclusively to vocabulary learning. 3. We study the effectiveness and weaknesses of GPT-VT, which is at the same time a study of the efficacy and deficiencies of GPT-3 underline technology about the specific tasks of evaluating definitions of terms and examples of their use.  
  2 Intelligent Vocabulary Tutors Intelligent tutoring systems are pretty widespread. You can find a lot of information about them in reviews [3, 4]. Some of them deal with helping students learn vocabulary. Paper [5] presents a small French vocabulary tutor for the World Wide Web, which helps students learn new French words and their pronunciation through words, pictures, and sounds. This work does not support a natural language interface. The work in [6] presents the Web-based Intelligent Learning Environment (WILE) framework as a solution. WILE includes four essential components: a communication module, a pedagogical module, a student model and an expert module, deployed over a client-server architecture. The article also mentions the emergence of mobile learning (mLearning) as an alternative to eLearning, and its advantages and constraints, such as the display of large content. It also does not support a natural language interface. Paper [7] proposes a mobile-based vocabulary tutor and examines its use. The presented tutor allows learners to complete vocabulary activities through mobile phones or computers and tracks their progress. The system creates a profile of each learner based on the vocabulary they have difficulty with and provides more practice for those words. The study analysed the learners’ usage patterns and surveyed them at the end of the project to gather their perspectives on the system. It also does not support a natural language interface. A web-based system aiming at learning vocabulary through personalised word association games is presented by [8]. This work focuses on personalising the learning process and game-based learning to make language learning more attractive to students. It does not support a natural language interface. The study [9] examines the impact of sociocultural factors on using a web-based tool for learning English vocabulary. Other works relative to vocabulary acquisition include: STI-DICO [10] is an Intelligent Tutoring System (ITS) that incorporates a Learning Management System (LMS) as its learning interface. It aims to help future French primary school teachers acquire the knowledge and skills to use the French dictionary. It uses authentic learning scenarios to allow learners to develop the skills and knowledge needed for the classroom. A web-based training platform for those who struggle with acquiring German orthography is presented by [11]. On this platform, students can write, publish and correct texts supported by a feature that gives feedback automatically and is called the intelligent dictionary.  
  A systematic review of AI-based language learning tools is presented in [12] for more information. Finally, specifications for a vocabulary learning assistant based on a natural language interface are given in [13], while in [14], vocabulary structure recognition is attempted to be utilised in such an artificial teacher.  
  3 Architecture, Functionality and Technology None of the efforts mentioned above yielded a satisfactory solution to the following question. How can we reliably evaluate the student’s response that will be given in natural language? Then, transformer neural networks appeared, and GPT-3, a transformer-based language model, solved the question. GPT-3 (Generative Pre-trained Transformer 3) is a state-of-the-art language generation model developed by OpenAI. It is trained on a massive dataset of text data and can generate human-like text on a wide range of topics. It can perform various natural language processing tasks, such as language translation, text summarisation, question-answering and text generation. It is considered one of the most advanced language models currently available, with the ability to generate highly coherent and fluent text, and can be fine-tuned for specific tasks. GPT-3 is also notable for its ability to generate text independently without being prompted with a particular task, making it a powerful tool for chatbots implementing natural language application interfaces. However, GPT-3 cannot be used directly to play the role of a vocabulary assistant. This is because GPT-3 is an open-domain system, i.e. it can enter into dialogues on various issues. This functionality does not serve the GPT-VT, which requires exchanges to be directed solely at learning a specific vocabulary at a time. Therefore, the solution we propose is the cooperation of Chatscript with GPT-3. ChatScript is a free, open-source platform for creating natural language processing (NLP) tasks [15]. It uses a combination of pattern matching and rule-based processing to understand the context and respond accordingly. The platform features a patternmatching system that allows it to understand a wide range of inputs, a scripting language for creating custom rules, and a built-in dialogue management system that enables the creation of complex multi-turn conversations. In Fig. 1, we present GPT-VT’s abstract architecture. Then we analyse each component. • Dictionary: The Dictionary is a data pool where vocabulary entries are stored as JSON records. Currently, two types of such records are supported: definition and usage. The definition type causes the guiding module to ask the user for an explanation of the term, while the usage type questions for a usage example. An example of each type follows. – {term: “chair”, type:”definition”, response:”a piece of furniture with a raised surface supported by legs, commonly used to seat a single person”} – {term: “chair”, type:”usage”, response:”he pulled out a chair from the dining table and sat down for dinner”}  
  A GPT-Based Vocabulary Tutor  
  Fig. 1. GPT-VT’s abstract architecture  
  This arrangement enables the human teacher to precisely determine the type of questions to be asked of the student and the terms these questions will include by simply loading an appropriate JSON file. However, a facility is also provided to load definition entries automatically from the Cambridge Dictionary1 . • Guiding module: Based on an entry from the Dictionary, the guiding module constructs the question for the user. Within the guiding module, Chatscript operates, which combines data from the Dictionary with its pattern-matching rules to differentiate the questions to the user making the dialogue more human-like. So, we have two main types of questions, one on the definition and one on usage. However, its role is not limited to query formulation based on the Dictionary. Its remaining functions are described below when describing the functionality of the remaining components. • User Interface: The user interface design is inspired by the interface of bot LIA [16]. Figure 2 provides a view of the user interface design. It features a student’s sketch on the right side communicating with a computer, a moving robot on the left side, and a dialogue box between them. The robot is labelled as the GPT-VT, and when the student gives their name, it appears as a tag on the student’s sketch. The purpose is to identify the student with the corresponding image and create the perception that the student is talking to a robot. The interface supports text-based dialogues but also includes ASR (Automatic Speech Recognition) and TTS (Text-to-Speech) interfaces that can be controlled by voice and microphone icons. The microphone can be activated automatically when the GPT-VT expects a student’s response, and it will be maintained for a short time or until the student completes their phrase. If the student does not speak, the microphone can be turned on by clicking the microphone icon. This practice aims to achieve seamless voice communication between the student and the GPT-VT. Its operation consists of the following: It sends the question to the user and receives the answer. Often, in studying a particular vocabulary, students know the answer as it is in the response field. If the student’s answer is identical to JSON’s response field, the  
  If the user’s answer is identified to be correct, the Guiding module proceeds to the next JSON record. Suppose the user’s response is recognised as incorrect. In that case, the Guiding module informs the student of the GPT’s evaluation and asks if they would like a second attempt with the same term to facilitate the student to consolidate the term. The Guiding module also recognises students based on their name and IP address. These credentials were chosen so the system can be accessed by young students who may be troubled by the login process. However, this is an option that can easily be changed. In addition to these functions, the Guiding module keeps the history of GPT-VT interaction with the student. Therefore, it enables the system to continue the study of a vocabulary even in different sessions while maintaining information that can be used to evaluate the student. Besides, when a cycle with the dictionary terms is completed, the Guiding module repeats questions that only address the words that were not answered correctly. The vocabulary study is completed when the student has answered correctly at least once for each Dictionary term. The technology that supports the described architecture includes Chatscript for the Guiding module, HTML, CSS, Javascript and Ajax for the User Interface, PHP for the API gateway and Python for the GPT3 API. It follows an example dialogue between GPT-VT and a human reviewer. GPT-VT User GPT-VT User GPT-VT  
  : Hello George! Do you want to practice vocabulary? : yes : Can you explain to me what chair mean? : a piece of furniture made of steel with two legs : No, the correct definition for the term chair is a piece of furniture for one person to sit on, typically with four legs and a back. Your example was not quite accurate. Do you want to try again with the same lemma? User : yes GPT-VT : Okay, let’s try again. What’s your definition? User : a furniture you can sit on GPT-VT : Yes, a chair is a piece of furniture designed for a person to sit on. Ok, you are good so let’s move to the next one! Give me a usage example of the term chair. User : I got tired of standing for so many hours. I urgently need a chair. GPT-VT : Yes, this is a correct usage example for the term “chair”. Another correct usage example is: “I went to the store to buy a chair for my office.” Ok, so let’s move to the next one! What does record mean?  
  4 Pedagogical Principles The GPT-VT was designed from the author’s experience as their children often give them a foreign language book and ask for help practising vocabulary. However, it follows some basic pedagogical principles: • Active learning [17]: The use of GPT-VT demands interaction with the student. Furthermore, it supports self-directed learning allowing the student to load vocabulary of their liking using an appropriate JSON file.  
  The specificity that reflects the GPT-VT’s ability to identify incorrect user responses correctly is also relatively high. However, it is lower than sensitivity, which means that GPT-VT is better at identifying correct than wrong user answers. Precision reflects how many of the answers detected as correct are actually correct. Accuracy is considered a measure of the overall performance of a model. F1 Score measures a model’s performance and balances precision and recall. It is calculated as the harmonic mean of precision and recall. All the above measures take values from 0 to 1. Matthews Correlation Coefficient differs; its lowest value is −1, and its highest is 1. It computes the correlation between observed and predicted binary classifications and is considered a robust metric of binary classification performance. The general picture from the measurements in Table 2 is that GPT-VT performs significantly well. However, the deviation from optimal performance raises questions analysed in Sect. 5.2. 5.2 Analysis of the Results Analysing the results, we identified three different types of GPT-VT errors. The first type concerns the definitions of the terms. In this case, they were evaluated as incorrect user responses, whereas they were correct. Both terms for which we had such a result were homonyms. So GPT-VT compared the definition we gave it with another meaning. We call this type of error the homonym error. An example of a homonym error is shown next. – Query: Is the phrase “the power and ability to be physically and mentally active “ a correct definition for “energy”? Start your answer with yes or no and include a proper explanation. – Response: No, this is not a correct definition for “energy.” Energy is defined as the ability to do work or cause change. It is the capacity to cause motion or create change.  
  G. Zografos and L. Moussiades  
  This phrase describes the ability to be physically and mentally active, but does not address the capacity to cause motion or create change. The remaining two error types concern the usage examples, and we call them conceptual and metaphorical errors. Conceptual errors refer to phrases that are syntactically correct but could not be considered appropriate examples of the use of the term. For example, – Query: Is the phrase “What is your car’s opinion?” a representative example of “opinion”? Start your answer with yes or no and include a good usage example. – Response: Yes, “What is your car’s opinion?” is a representative example of “opinion”. For example, you could ask a friend, “What is your opinion on the new movie?” The metaphorical errors concern usage examples that are linguistically correct but do not adequately convey the term’s literal meaning. At the same time, however, they could be considered useful examples in a metaphorical sense of the term. Here is an example of a metaphorical error. – Query: Is the phrase “The conclusion of the story was its beginning.” a representative example of “conclusion”? Start your answer with yes or no and include a good usage example. – Response: Yes, this phrase is a representative example of “conclusion”. For example, the conclusion of the novel was that the protagonist had to go back to the moment when the story began in order to resolve the conflict. Table 3 presents statistics for the three types of errors. Table 3. Statistics of three types of Errors. Homonym Error  
  Conceptual Error  
  6 Conclusions This paper presents an artificial vocabulary tutor based on GPT-3. Its overall performance is shown by the measurements in Table 2. The cases where GPT-VT fails to evaluate correctly, we believe, can be largely mitigated. As for homonym errors, the question to GPT-3 could be formatted to include the term’s meaning along with the user’s answer. This may limit, perhaps even eliminate, homonym errors. For the other types of errors, more investigation is needed. Apparently, GPT-3 takes examples that make metaphorical use of a term primarily as correct ones. On the other hand, conceptual errors are sometimes considered correct and sometimes incorrect. Also, it should be noted that the temperature parameter plays a significant role in shaping the results. We intend to do experiments with more conditions, with varying temperature values and, of course, with better statistical processing of the results. Also, we intend to compare our model using GPT-3 and ChatGPT. Moreover, our work should be extended to investigate the effect of the vocabulary tutor on the student’s knowledge acquisition. Although there is a lot to do, the results so far show us that the road to such reliable applications is wide open as long as we take it. Acknowledgements. This work was supported by the MPhil program “Advanced Technologies in Informatics and Computers”, hosted by the Department of Computer Science, International Hellenic University, Greece.  
  [email protected]  , [email protected]  2 Federal University of Pampa-UNIPAMPA, Alegrete, Brazil [email protected]   
  Abstract. The growing popularization of Artificial Intelligence (AI) technologies to support most different human activities, including education, has been a subject of research and concern among researchers in the area. In this sense, how to translate ethical principles into computational models; how to avoid biases; how to make intelligent systems accountable; and how to make them more predictable and able to explain their actions are among the main issues raised. Such questions also extend to the Education area, where it is necessary to address this matter with the same seriousness. Despite this, few proposals in ethics by design have been observed for the Education area. To help fill this gap, this work presents a proposal for an Artificial Moral Agent (AMA) to aid in collaborative learning. The proposed AMA implements a hybrid approach between deontological and utilitarian ethical frameworks, using the Belief, Desire, and Intention (BDI) architecture. For this, through Agent-Oriented Software Engineering (AOSE) techniques, which is the focus of this paper, the functional requirements of the proposed AMA will be described, as well as its structural model. Keywords: Artificial Intelligence · Ethics · Education · Software Design  
  P. R. Córdova et al.  
  models, how to avoid data bias, how to make intelligent systems accountable for their decisions, among others [9]. This set of questions gave rise to the development of a special type of artificial agent capable of demonstrating behaviors considered ethical: the Artificial Moral Agent. This kind of agents must be capable of demonstrating moral behavior or preventing immoral behavior [4]. Despite the importance and the clear need to search for solutions in ethics by design, few initiatives have been observed in Education area. To help fill this gap, this article proposes and describes an AMA model to support collaborative learning using AgentOriented Software Engineering (AOSE) techniques. About this proposal, one can see previous results in [5] and [6]. The aim of this research is to investigate how to make more ethical use of AI in education area. To test our proposal, presented in more details in [5] and [6], we chose a collaborative learning scenario. In this sense, to understand how computer systems have been used to support collaborative learning, one can resort to Computer Supported Collaborative Learning (CSCL), a branch of learning science concerned about investigating how people can learn together by being aided by computers [11]. We have addressed this topic and its relation to this work and presented a conceptual outline of the AMA described in this paper, including scenarios and examples of application in [5]. Finally, to allow understanding of the proposed model, the functional requirements of the proposed AMA will first be described and, subsequently, its structural model will be presented.  
  2 Methodology In this work, different methodologies and modeling languages are used for different stages of the proposed MAS project. This way, for the specification of requirements, the Multi-Agent Systems Requirements Modeling Language (MASRML), a domain-specific language based on the Unified Modeling Language (UML) for modeling requirements in Multi-Agent Systems (MAS) projects [8], was applied. Regarding the structural aspect of the proposed MAS, the Multi-Agent System Modeling Language MAS-ML will be applied. This language can represent the essential static and dynamic aspects of the MAS, emphasizing a clear representation of their concepts and relationships [10].  
  In this way, the proposed solution is constituted by an environment in which there are two agent roles named Monitor and Tutor. The first one aims to fetch and organize the interactions carried out by the students and registered in the forum’s database. Such a fetch will temporally take place and once the Monitor has the interactions data, it will have as its plan to distribute the information, sending it to the Tutor agent. The Tutor agent, by its turn, is an AMA that follows the top-down approach [1] and aims to analyze the need for intervention by the agent in the students’ interactions in the forum. This approach was chosen, as it is understood that learning ethical behavior is inappropriate for the classroom environment [6]. Therefore, the Ethoschool needs to follow rules derived from some of the ethical principles established by [12], in some characteristics of CSCL systems, and in some collaborative learning assumptions. These rules and their relationship with the principles proposed by [12] were described in [5]. Table 1 shows the rules that the Tutor ought to follow. Table 1. Rules the Tutor Ought to Follow. ID  
  Priority  
  Avoid exposing the student to peers in the group  
  The imposing character of the rules presented in Table 1, as described in more detail in [5], is directed to the Tutor agent, who must seek to satisfy them, even if it is not always possible, given the environmental variables. The contradictions, as well as the prioritization between the presented rules in order to mitigate possible conflicts are further explained in [5]. Regarding the other functional requirements of the Tutor agent, its perception is limited to perceiving the messages sent by the Monitor agent containing the compiled data from the interactions carried out by the students in the forum. Inside the Tutor’s plan is included the analysis of this data, and the actions resulting from this analysis must be executed under environmental conditions. In this sense, in [5] are described the complexity of the environment, as well as the fourth scenario modeled to explain in more detail the behavior of the proposed MAS.  
  Perceive message from Monitor Perception Tutor Describes the probing for possible Monitor Agent’s messages. The internal use case Goal "Check the need for intervention" must be in execution. Initial Beliefs Message received from Monitor = false. Main Scenario AgentRoleActor Actions 1. Probe the environment to verify the occurrence of a new message sent from the Monitor containing the data of the students’ interactions in the forum. Alternative Scenario - Monitor message sent AgentRoleActor Actions 1. Come to believe that Student data was sent. 2. Receive Student Data.  
  3.2 Structural Model During the design phase, we used the MAS-ML language [7] to model the structure of the Ethoschool. As one can see, MASRML [8] and MAS-ML complement each other in describing software characteristics. Structural models help to illustrate the physical or logical composition of software from its components. In this sense, structural modeling establishes the boundary between the software being modeled and the environment in which it must operate [2]. This way, Fig. 2 was produced, presenting a structural model in the form of a MASML organizational diagram, which allows identifying the types of agents supported by the system and the roles that they can assume in its organization. In this diagram, there are two types of agents and two agent roles that can be assumed. Thus, when looking at Fig. 2, we can see that Ethosschool supports the Monitor and Tutor agent roles, which are interpreted by the Assistant and Ethical agents, which, in turn, are agent classes. The Assistant AgentRole has the purpose of checking the forum to verify students’ interactions. In addition, it also has a protocol to communicate the interactions performed by the students to the tutor. The Monitor agent has the plan to distribute information to the agent that assumes the Tutor role. This plan will only be executed when the check forum goal becomes an intention. The Assistant agent also has the beliefs through which it believes or not that the students are interacting properly and whether or not the students have started a new task on the forum. Tutor AgentRole, in turn, aims to verify the need for intervention to encourage students’ participation by analyzing the forum interaction data sent by the agent that assumes the Monitor role and perceiving the receipt of new messages sent by him. This role has also protocols for sending encouraging messages to the students, as well as the duty of saving the decision made and the data used to make it. For this, the analysis of the students’ interactions data is materialized in the form of an agent’s plan, which is triggered when the goal of verifying the need for intervention  
  ETHOSCHOOL: An Artificial Moral Agent Model  
  of the Tutor AgentRole becomes an intention. This agent also has beliefs determining whether or not it is necessary to execute the need for intervention analysis and whether or not a message has been received from the Monitor.  
  4 Final Considerations Solutions for a more responsible, explainable, predictable, and therefore, reliable AI are an important contemporary demand. In this sense, one can say that in the teaching and learning context, it is an even more sensitive issue, as AI technologies can direct, with greater or lesser autonomy, the directions of a classroom. Aiming to help fill some gaps in this research area, this work proposes a hybrid solution based on the deontological and utilitarian ethical frameworks. Such a solution uses the BDI model to construct a MAS capable to guide students in a collaborative learning group interacting through a forum. During the requirements engineering phase of the proposed solution, we applied the MASRML language to identify and represent the functional requirements of the  
  Fig. 2. MASML Class Diagram  
  Ethoschool. In addition, the structural design was produced by applying the MASML language. The model was designed to guide its decisions on ethical principles based on UNESCO’s proposal for ethics in AI and to be able to deal with ethical dilemmas. This is possible due to its structure that embraces a Monitor Agent, responsible for monitoring the forum searching for students’ interaction data and sending them to the Tutor Agent. The late is an AMA, responsible for processing data from students’ interactions in the forum and deciding if, how, and when to intervene in student interactions. Such a solution can bring at least two advantages: as agents based on the BDI model are guided by intentions, it is more intuitive for the end-user to understand why an agent made a certain decision; and the use of ethical frameworks already validated by a community of research, such as ethical principles and the use of reasoning capabilities to solve ethical dilemmas can make the decisions made by intelligent systems more predictable [5]. These features help to construct an AI solution able to meet an important requirement for ethics in AI, named explainability. Thus, we believe that this solution can help make AI more reliable, especially in the education field, in which, more than relating to people, AI can drive learning processes playing an important impact on human formation and in society. For these reasons, the model proposed in this work can contribute to a more ethical AI in Education area. Acknowledgements. This study was financed in part by the Coordenação de Aperfeiçoamento de Pessoal de Nível Superior – Brasil (CAPES) – Finance Code 001.  
  ETHOSCHOOL: An Artificial Moral Agent Model  
  La Rochelle University, La Rochelle, France {anis.bey,ronan.champagnat}@univ-lr.fr Higher School of Management Sciences, Annaba, Algeria  
  Abstract. In a lab work session, students may spend an inordinate amount of time attempting to correct simple errors, repeatedly revisiting and repeating the same errors due to the limited access to the tutor. Instructors, on the other hand, frequently find themselves explaining the same errors. This tool is designed to improve the educational environment in the computer lab for both students and instructors. The first experiment did not show that the tool improves learning programming, but it showed some insights about students that use the tool only in face-to-face sessions and students that use it only with the training mode compared to a control group. Keywords: Smart lab · Introductory programming Tutoring System · Feedback · Learning Analytics  
  1  
  submitting their work rather than for their work on programming activities in lab classes. This paper presents the main functionalities of Smart Lab technology for introductory programming computer laboratories and the early results of the ﬁrst experiment. We addressed two research questions : RQ1: Are there any signiﬁcant diﬀerences in the ﬁnal course score between groups of students that did not use the tool, students who used only the smart lab with a teacher, and students that have been logged in, and practicing by solving some exercises freely? RQ2: Is there any signiﬁcant diﬀerence in the ﬁnal course score between students in terms of the number of solved exercises? This paper is organized as follows. Section 2 shows some solutions to address the diﬃculties faced by programming students and the Smart Lab environment, with a presentation of a new Smart Lab described in Sect. 3, followed by Sect. 4, which presents a general workﬂow of how the tool works. Section 5 gives the leading indicators of students’ and teachers’ dashboard. In Sect. 6, details of the result of the ﬁrst experiment of the tool are provided, followed by a discussion, conclusion, and guidelines for future work.  
  2  
  Teachers’ Dashboard  
  Teachers have a dashboard built with some indicators about the performance of students. We ﬁnd the following indicators: – Number of students: Total number of signed up students. – Number of active students: Total number of students that have submit at least one submission during the last week. – Number of submissions: Total number of submissions made by students. – Percentage of each type of submission: Correct, Erroneous, In Progress, Compilation Error. – Average percentage of Indentation, Comments, Expression, Variable, Repetition (see Sect. 5.3 for more information) – Distribution of submissions’ types per student. – Number and type of submissions (correct, in-progress, correct, compilation Error) per day. 5.2  
  Students’ Dashboard  
  Students’ dashboard is described and composed of the following indicators : – – – –  
  The rank of students in terms of solved exercises. Number of solved exercises. Number of remaining exercises. Percentage of each type of submission: Correct, Erroneous, In Progress, Compilation Errors. – Average percentage of each feature: indentation, comments, expression, variable, repetition (see Sect. 5.3 for more information). 5.3  
  Student’s Final Report  
  Whether in the smart lab mode with teacher or in the practicing mode, when a student submits a solution for a given exercise, the tool gives a report in the form of three parts: Output. In this space, the student will see if there is a syntactical error in his codes; otherwise, the number of successful IO tests. Feedback. The submitted code is evaluated in this part of the report according to ﬁve features: – Comments: to check if the submission is well commented. – Expressions: to evaluate expression complexity, we just look at compound expressions and long-expression lines. – Indentation: to evaluate indentation/formatting consistency. – Repetition: Repeating code is probably the top indicator of poor abstraction. – Variables: to evaluate if some variable names have meaningful lengths and are scoped within loops.  
  Conclusion and Future Works  
  This research resulted in using smart classroom technology in introductory programming lab works. The Smart Lab system was successfully implemented and met its intended goal of providing instructors with speciﬁc, timely, and detailed information about their student’s performance on programming tasks during lab class sessions. The Smart Lab improved the overall eﬀectiveness of the lab session in achieving the learning objectives by facilitating communication between tutors and their students in the lab. This tool allows teachers to understand their students’ programming strategies and compiling behaviors and identify the progress made by each student in solving the programming exercises. In terms of future works, the most important functionality that could be very helpful for both teachers and students is to implement an algorithm to capitalize on recurrent errors made by students. Also, this tool could be extended by adding automated feedback for students about the errors they make and the actions they miss.  
  Towards Embodied Wearable Intelligent Tutoring Systems Injila Rasul(B) , Francisco Castro, and Ivon Arroyo University of Massachusetts Amherst, Amherst, USA [email protected]  , {fcastro,ivon}@cs.umass.edu  
  Abstract. Embodied cognition posits that human-environment interaction positively impacts thinking and learning, making it a valuable pedagogical tool. Technology in teaching and learning has seen tremendous maturation, such as the development of Intelligent Tutoring Systems (ITS). However, most ITS provide static learning experiences that do not incorporate embodiment, movement, and interaction with the space around the learner. This paper examines the results of using an embodied tutoring system across three case studies with diﬀerent dimensions of embodiment. In all cases, we found trends highlighting how embodied tutoring systems can support learning. We also discuss diﬀerent ways to incorporate embodiment into future research on ITS. Keywords: Embodied Cognition Math  
  1  
  Related Work  
  Embodied Cognition and Pedagogy. Embodied cognition is the idea that perception of the environment, and the body’s interactions with elements within it, inﬂuence cognition [2,16]. Embodied learning emphasizes that learning is supported and bolstered when the deep connection between the mind and the body [12] is employed as a pedagogical tool [16]. A key aspect of embodied cognition is spatial cognition, the cognitive process involved in spatial reasoning and problemsolving. Spatial cognition is signiﬁcant to STEM pedagogy because concepts in mathematics and science incorporate ideas from the physical world around us, such as position, direction, relative speed, and spatial perception, among others. Prior research has shown gains in STEM performance when leveraging spatial cognition as a pedagogical tool [14,16], which supports the case for instruction that incorporates spatial cognition, such as visuospatial skills (the ability to recognize visual and spatial relationships among objects [16]), as a means to improve conceptual understanding in STEM education. Making the Abstract Concrete. The potential of embodied learning leads to the question: how can embodiment be incorporated into ITS eﬀectively to support STEM learning? Weisberg and Newcombe [16] presented a framework that outlines mechanisms through which this is possible: (a) linking sensorimotor information with abstract concepts, (b) using gestures as a cognitive tool, (c) developing cognitive skills such as spatial cognition, (d) oﬄoading onto the body/environment to free up cognitive processing, and (e) creating and understanding visual representations. Oﬄoading refers to storing information in the environment/body without further burdening their mental resources, focusing cognitive capacity on problem-solving, inference-making, and communicating ideas [16]. An example is a student oﬄoading a shape’s mental rotation onto a physical object’s rotation to retain a visual representation of its direction and orientation, enabling them to move on to another part of the problem. Creating visual representations is also critical in communicating ideas and seeing the bigger picture while problem-solving. Additionally, analogy-building between sensorimotor and abstract concepts (such as moving along a number line while adding numbers; a number line does not concretely exist in the natural world) and visual representations (i.e., a number line drawn on the ﬂoor) supports the learning of abstract concepts, using the physical world around learners [10,16]. Embodiment as Support for Mathematical Ideas. Tools and manipulatives can illustrate, communicate, and test concepts and serve as testing grounds for emerging mathematical ideas, where the mind can impose mathematical relationships on the objects [15]. According to Walle, there are ﬁve ways to represent mathematical ideas: (1) manipulative models, (2) pictures, (3) real-world  
  I. Rasul et al.  
  situations, (4) written symbols, and (5) translations between and within representations. These representations help develop new mathematical concepts [15]. Prior research suggests that mathematics learning is embodied, based on perception and action, grounded in the physical environment and that diﬀerent gestures suggest diﬀerent types of thinking [6,10]. Gestures with hands and body, which are “inherently spatial” because they are expressed in the space that a person occupies/perceives [16], become mechanisms through which cognition is communicated and information is encoded [2]. Prior work suggests that gestures are evidence of involvement in mathematical thinking [2] and may be a vital aspect of learning as students work with their peers and around physical objects. Intelligent Tutoring Systems and Embodied Cognition. Given the impact of embodied pedagogy on STEM learning, designing ITS to incorporate embodiment is a good path forward for improving ITS [6,7]. Technology that can support and enhance active learning environments has been studied previously, with increased learning gains compared to control groups [7]. However, most ITS are currently largely screen-based and do not incorporate movement. The ones that do often focus heavily on gesture-based movements rather than engaging the entire body [7]. It is crucial to re-conceptualize how ITS can provide embodied pedagogical support for STEM classrooms.  
  3  
  The WearableLearning Platform and Embodied Games  
  Our team developed WL1 a web-based platform that enables users to play physically active, embodied, educational math games using mobile devices that students carry [3]. Thus, WL games can be situated within physical classrooms and incorporate movement, physical manipulations, and teamwork. Within the WL interface (Fig. 1), students can input answers to question prompts to receive feedback, request hints, and proceed through the game. Students can be organized into multiplayer teams, with each member taking on a speciﬁc role throughout the game, which may be complementary to other team members. 3.1  
  WearableLearning Case Studies  
  Explanatory Didactic Dialogue in the ITS  
  Abstract. The paper considers the problem associated with the possibility of functional programming of intelligent systems, which are based on the definition of intelligence as the ability to model the environment around the system in order to use this model to form the specified behavior of the system in this environment. Such behavior is considered as the result of a consistent solution of intermediate tasks, into which the general task is divided, determined by the goal set for the system. In the variant under consideration, the environment model is built on the basis of knowledge collected by the system or obtained from its knowledge base. Separate knowledge has a multi-element representation, making available for the user several tools for solving problems. The options proposed in his paper are: sets of properties, logical and ontological representations of individual components of the environment surrounding the system, and related associations of these components. It should be noted that various variants of logics can be incorporated into the system, including non-classical ones, on which the system builds its conclusions. In addition, the system can use various variants of mathematical structures that are stored in its knowledge base when building a model. When developing an intelligent system, the methods and tools of functional design can be applied as a way to develop a specific system. In this work, this approach is applied on the example of the development of an intelligent military robot that operates in a specific subject area and solves the problem of defending and attacking a specific enemy. Keywords: intelligence · modeling · intelligent system · knowledge representation · intelligent robots  
  2 Intelligent systems Intelligence, considered as a property of a subject or system, is determined by the ability using some logic, firstly, to model the subject area (SbA) in which this subject (system) operates, and, secondly, on the basis of this model, to effectively solve the tasks assigned to this subject (system) [5, 6]. A system with intelligence is hereinafter referred to as an intelligent system (IS). There are many different ways of modeling SbA [5, 9, 10], as well as approaches to solving problems in these models. In [6–8] it was proposed to use various logics to describe the tasks themselves, and options for drawing conclusions from the logical description of the problem condition to its solution. In this paper, we consider the problem of applying functional programming representations to the development of IS. In this case, it is necessary to use an approach, which is based on the original definition of intelligence, to the creation of IS. This approach  
  Functional Programming of Intelligent Systems  
  will serve as the basis for developing a programming representation. It is assumed that the system has a set of organs that allow it to perceive the environment, and on the basis of this perception and the initial knowledge existing in the system, build a model of the environment. This model contains in advance the rules and structures related to the SbA in which it is supposed to use the IS or to customize its actions for the finished system. Unlike universal IS, which allow an independent choice of the method of modeling the environment, in the case under consideration, some forms of the SbA representation are predetermined, and a specific version of the IS is selected based on the information that it can collect. In other words, a certain class of SbA is built for IS, from which the system selects a specific environment, focusing on the information that it collects or that it previously receives from auxiliary sources. This approach narrows the scope of IS, limiting the class of SbA in which the system operates, but increases the level of its efficiency, reducing the time spent on the detailed process of modeling and checking the model’s compliance with the reality in which the system is located. For example, if an IS is the “brain” of a robot, then the conditions characteristic of the environment in which the robot must operate, that is, solve problems, are pre-set in it. Also, the means that the robot can use and which are included in its structure are also associated with this environment. The intelligent robot does not create these tools, but only chooses from what it already has to solve its problems. In this case, the modeling process is divided into two parts. The first is the creation of a knowledge base that contains a description of the possible constituent elements of the simulated SbA, at the level of individual features and logical relationships between them, as well as the impact of these elements on other elements included in the modeled area. The base includes a description of the possible structures included in the SbA that determine the links between the elements of the domain, the assignment of links between the elements and structures. A separate component of the IS knowledge base are mathematical models that can be used in modeling the SbA and solving problems in it. At the same time, it is assumed that at the level of such a model, the internal “skeleton” of the considered SbA and the connections that exist in it can be represented. When an IS enters the SbA, it first orients itself in it, highlighting individual elements and structures based on the collected features, and then turns to its knowledge base (KB), in which it looks for matches with the elements and structures identified by it in the environment. There is a process of recognition and identification of these elements and structures, as a result of which the SbA modeling is performed, which combines the perception of the IS and information from its knowledge base. The process of recognition of the observed components and components of the KB is usually based on the selection of a group of observed features that are compared to a separate component, the formation of a neighborhood of these features that correspond to some generalized image and the search in the KB for a prototype whose features fit into the constructed neighborhood. If there are several such elements, then an extended (multiple) representation of the SbA is constructed, which is refined in the process of interaction between the IS and the SbA. The constructed SbA model further serves as the basis for solving problems that may arise or be put before the IS. It is assumed that when developing an IS, the range of tasks that this system should solve in the SbA is also outlined in advance. Designing a set of tasks to be solved is one of  
  V. Meitus and C. S. de Blas  
  the common problems that IS solves. It is quite acceptable that the IS performs its actions on the basis of some general principles. But this is the next level of IS construction. For example, in the stories of A. Azimov, the behavior of robots was limited to three general principles that forbade robots from performing certain actions. A simpler variant can be specified under conditions when the range of tasks to be solved is defined for the IS, and the sequence of possible actions of the IS is specified for each task. Such program descriptions are a separate part of the knowledge base, which is associated with the IS. Note that the solution of a specific problem may be associated with a certain sequence of actions, but, at the same time, such a solution may include some general algorithm for analyzing the situation, and only then a specific program of actions associated with this situation. Moreover, the algorithm of behavior may involve the choice of some optimal sequence of actions, which is based on an analysis of the situation. Thus, the functional programming of an IS with this approach is divided into two parts: the first is the functional programming of a set of knowledge and operating with it, which provides modeling of the SbA. And the second part is the functional programming of the operational space of the IS, determined by the possibilities of solving the problems of the IS. Let us now consider the formal representation of each part separately. In the formalization of representations in the future, we will use the concepts of the Python programming language without additional references [11, 12]. In this work, the SbA and the tasks solved in it are considered on the example of the development of an IS that controls a military robot. 2.1 Subject Area Modeling As discussed above, the intellectual behavior of the subject in the SbA is determined by two main factors that form the intellect of the subject interacting with the SbA: firstly, by its ability to model the environment – the SbA in which it is located, and, secondly, by its ability to based on this model to solve problems related to this environment. The work [5] considered the modeling of the SbA based on the knowledge that the subject collects and accumulates, perceiving and analyzing this environment. Currently, there are various approaches to the use of knowledge in systems related to artificial intelligence. An example is different versions of knowledge-based systems [13, 14]. In this work, firstly, knowledge serves as the basis used in the process of modeling the SbA. They build a model in which problems are solved. And, secondly, this knowledge has a rather complex structure that combines various forms – descriptive, functional, logical and ontological – in a single knowledge, which makes it possible to build an SbA model in a representation which focused on multilateral problem solving. This property is characteristic of the intellect of a person who usually evaluates the problem being solved from different angles. The process of forming knowledge about the elements of the SbA is the first intellectual component of the general modeling process, because the subject must, on the basis of this knowledge, recognize the object and link it with the ontology representing the SbA. At the same time, for an object, its links with other objects in the given SbA are indicated. At the same time, it is assumed that the subject in the SbA can single out its separate parts, which are considered as generalized objects of this area, and these parts are also  
  Functional Programming of Intelligent Systems  
  characterized by a certain knowledge system, including features, connections, ontology. Separate features are associated primarily with the senses of the subject, or are derived from individual tuples or sets of features. A structured list of such features is the first component of knowledge about an object. The second component of knowledge is a logical expression that describes the object in the logic used by the subject to represent objects and to draw his conclusions in the process of solving problems in the SbA. The third component of knowledge about an object from an SbA is a set of connections that exist and are found by the subject in the course of his perception and subsequent analysis of the object. These links define some neighborhood of the object, defining its interaction with other objects of the SbA. Connections and their compositions are a necessary condition for solving problems by the subject. From them, a solution to the problem is compiled, as a path connecting the condition of the problem with the expected result. Finally, the fourth component of knowledge about an object is its ontological description, which assumes that information about individual objects of the SbA exists and is represented in some general catalog of possible objects. Such a catalog contains more detailed information that the subject may not find or obtain using only his senses. For example, a robot can observe individual elements of a tank in the SbA, which allow it to give an external characteristic of the observed object. But he will get a number of other characteristics if he can find the necessary prototype in the knowledge base and determine what type of tank he observes and what are its properties and capabilities, or means of protection. It depends on whether the robot will be able to destroy the tank with the weapons it has. These four components of knowledge give some characteristic of the SbA object that is static in time. But this is not enough for ordinary real conditions, in which, for example, an unmanned vehicle or an aircraft, a robot or an autonomous control complex, a tank, a tractor, which are equipped with a control device and operate in a variable environment, are considered as an object, changing their position and their performance. Therefore, a pure function environment is needed, where stable, consistent, and predictable outcomes are given. Only for the case new data are given, new variable environment must be created. In order to represent possible dynamic changes in knowledge, it is necessary to add at least one more component to them, which includes a set of operators (1 , …, n ), potentially transforming the observed state of a particular object at each moment of time. In other words, operators set the dynamics of the individual components of the object, which the subject must take into account when solving the tasks assigned to him. For example, with the help of an operator, it is possible to describe the movement of a car in the form of a change in a part of the features associated with it or in the neighborhood in the SbA, which is determined by the car object. The fifth, operator component of knowledge allows a more complete representation of the SbA model, reflecting its potential dynamics and, consequently, expanding the range of tasks that an intellectual subject (ISb) can solve. This component can be enriched with the aggregation rules for the set of operators (1 , …, n ). The knowledge collected by the subject is only one part that is related to the general task of modeling the SbA. The second part consists of a body of knowledge containing information about the areas in which the subject can act and the possible components  
  V. Meitus and C. S. de Blas  
  that these areas consist of. This knowledge contains the accumulated experience that reflects the possible scenarios that a subject may encounter when entering a particular environment (see Fig. 1). For example, a person who is going to visit another country usually first gets acquainted with the rules, traditions, features of his stay in this country, which may differ from the same features of his own place of stay.  
  Fig. 1. Representation of model of subject area.  
  And if the ISb has to model some environment, then it is desirable that it has preliminary information about what type of environment it may encounter. For example, if a robot has to simulate a forest, then it needs one piece of information, and if it ends up in a desert, in a field, in a city, then another. Of course, one could consider the possibility of the robot independently forming its own idea of the environment. But, firstly, it would take additional time, and in conditions where the environment is not favorable for the robot, it could pose a threat to its existence. Secondly, in order to adapt to different environments in conditions when the necessary information needs to be collected, analyzed and built in different models, a sufficiently high level of intelligence and the ability to restructure one’s perception are required. And this is due to a longer general period of training and adaptation of the robot to the SbA. Therefore, if it is possible to preselect the main environment model from the knowledge base, then this should be used to ensure that the robot is quickly configured for a specific environment. Such a model includes the main elements that ISb can meet under the conditions during consideration, as well as a certain formal organization of these elements at the level of some mathematical structure [5]. And the further modeling process consists in setting up the selected main model, for example, a city, forest, steppe, jungle, desert, mountains, for specific conditions and objects in this main model, detailing this model, with the transition to solving already specific problems. Naturally, the choice of the main model also narrows the class of possible objects that the subject will put into the model based on his perception, and reduces the time required to develop the SbA model. It is assumed that the ISb is located on our planet, but can fall into different climatic zones and at different times of the year, operate in different environments – on the  
  Functional Programming of Intelligent Systems  
  ground, in the air, under water, and has equipment for perceiving the environment and solving the tasks assigned to the subject. The main advantage of the subject (robot) is in a variety of means of perceiving the environment: the possibility of using a wide range from infrared to ultrasonic, the possibility of sensing the environment in various ways, obtaining information from flying drones and satellites. For example, a drone can be an integral part of a robot, which allows expanding its ability to obtain additional information about the SbA for each specific situation. In other words, such robots can collect information and build SbA models in more detail and perfection than a human does. 2.2 Functional Representation of the Modeling Process Assuming that the robot has already collected data about its environment, transformed it into knowledge about individual objects, and it is given tasks that need to be solved based on this information, the SbA modeling process itself can be considered as the process of constructing and using a function that displays these knowledge into a structural model of the environment surrounding the robot. To formalize the representation of the description of the environment, we use the concepts of the Python programming language. This can be easily generalized to other functional programming languages. In this case, knowledge about the individual components of the SbA and its structures is specified in the form of lists and named dictionaries. At the same time, the dictionaries include names derived from the ontology, which is included in the knowledge and is associated with this area. For an SbA, there is a knowledge base that the robot can use to build knowledge based on its perception. If knowledge about the object is incomplete, for example, it was not possible to fully identify the object based on the collected features, then the model for this object saves the collected information, and the process of knowledge formation is stretched in time. Based on the collected data, the robot can make several assumptions about what the analyzed object is. It may turn out that an exact classification of the object is not needed to solve the problem. The dictionary associated with an individual object (Fig. 2) includes, firstly, information about the position of the object in the SbA and its main characteristics that determine this position. Secondly, possible external links with other, mostly neighboring objects. Thirdly, the proposed structure of the object and possible internal and external subobjects that are combined with this object of the SbA, but allow their independent existence and behavior. Fourth, the possible dynamic characteristics of internal subobjects, reflecting, for example, the movement of internal objects in the structure of the original object. Fifth, a possible assessment of the value of the object, which is given by the robot in relation to the SbA. As a subobject, we consider some structure, which is considered as part of the original object. For example, in the course of military operations, people who take shelter in this building, or observation and firing points with which the building is equipped, or some structures with which the building is supplemented, can be considered as a subobject of a building. The model itself is defined as a multi-layer system of maps, starting with maps that indicate the relative position of objects with varying degrees of their detail in the  
  a set of methods for solving such a task. In this case, the result of the decision depends only on specific data. This approach can be used in the development of robots. Besides, other problem resolution strategies, such as non structure decision making, heuristic approaches or unsupervised learning requires a combination of fact based data analysis and highly subjective and even intuitive judgements about aspects of the problem. Therefore, when developing an IS, especially in the form of robotic systems, it is desirable to build it in such a way that, under the conditions of using the given SbA, it would be possible to first formulate the classes of problems that such a system should solve. For example, considering the behavior of a military intelligent robot, we simultaneously assume that it must solve a given range of tasks for which this robot is built. One and the same task can be solved under different specific conditions and with different possibilities of interaction with the enemy. The intelligence of the robot is manifested in the fact that it manages to find a good solution to the task assigned to it for these conditions, when the general nature of the desired solution is known, but adaptation to the specific features of the environment is determined by the intelligence of the robot. This intelligence is manifested in the fact that, based on the general principles and classes of tasks known to the robot, it must select and solve a problem in a specific environment, based on these principles, using the methods of solution and optimization already known to it. In many respects, this approach is determined by the fact that in the conditions of interaction with the enemy, the time for solving the problem is limited by the actions of the enemy. The robot does not have time to look for a variety of original solutions, while simultaneously collecting the necessary information that it lacks, analyzing numerous options for possible solutions, and looking for new options. On the other hand, the conditions for solving a problem always remain incompletely defined. Therefore, it is impossible to put one ready-made solution into the robot’s memory in advance, removing the intellectual component for it. For example, considering a military robot of the simplest structure – an intelligent agent with organs of perception and execution – we can formulate the following tasks. The task of reconnaissance of the situation on the line of contact with the enemy or in his rear, in the face of possible opposition from the enemy; the task of destroying military or technical means, logistics, warehouses, command posts, personnel, in conditions where there are several goals and means of defense against attack; the task of countering offensive and reconnaissance actions of the enemy; the task of protecting personnel and equipment in an attack. These are classes of possible problems that may have different solutions depending on the specific conditions of the SbA. Accordingly, the real range of specific tasks and their solutions that are available to such a robot is much wider. It is important that when solving problems, the robot can use methods and tools that are inaccessible to humans under similar conditions. At the same time, the robot goes through numerous solutions, uses mathematical models and a large amount of memory, which stores the experience of successful solutions. A situation arises, known in modern chess, when a person who owns a computer plus a high-speed computer with a large memory defeats a professional grandmaster. Modern chess experience shows that in order to solve a narrow class of problems, it is always possible to create a computer that, after training in a certain SbA, will solve  
  V. Meitus and C. S. de Blas  
  these problems in it more efficiently than a person does. A similar situation occurs when playing poker, in which a trained computer beats a human. The learning process that determines the creation of an SbA model is an integral part of the process of developing an intelligent robot. Under certain conditions, tasks can be combined with each other into some common complexes. For example, countering enemy reconnaissance activities can be considered as a task of sequentially solving two subtasks: first, the subtask of recognizing and finding enemy assets used for reconnaissance – radar stations, drones and unmanned devices, and other modern technical reconnaissance equipment. This subtask is a component of the main task of reconnaissance of the enemy. Based on the information collected by the first subtask, the second subtask is solved – the choice of means and the destruction (or incapacitation) of enemy reconnaissance means: disruption or destruction of radar stations with special anti-radar missiles, destruction of drones and drones with missiles or a robot laser, data transmission to other complexes combating enemy reconnaissance assets. This may also include the destruction of command posts for collecting intelligence information with the help of missiles and firepower of the robot. Note that the second subtask can be considered as a component of other classes of problems identified above. 3.1 Functional Programming of Problem Solving The development of an intelligent robot implies the possibility of programming for it the processes of solving problems that the robot must solve in the course of its activity. In particular, such programming can be performed at the functional level. In this case, for each task, its own function is constructed, which transforms the condition of the tasks into some result, considered as a solution to this task. Let’s consider how the functions associated with the above task classes are created. Based on the fact that the robot has built a system of knowledge about the SbA and modeled this area using its knowledge and the modeling method based on this knowledge, any task from the classes of problems considered above is solved as a task of constructing a function that maps the data from the SbA model to the data corresponding to conditions that are determined by the corresponding class of problems. The collection of intelligence information by a robot assumes that using the SbA model it is possible to find the military and technical means of the enemy, which the robot recognized in the SbA. If the model information is presented in the form of a database consisting of named tuples or dictionaries, then we build a function that selects those names that are recognized as enemy assets. At the same time, we bind the found objects to the map of the area. The resulting map is considered as the result of exploration. The second class of tasks is the destruction of control systems, technical means, enemy logistics or means that are installed on the robot and controlled by it, or by other military or technical means, but based on information received by the robot. This task, if solved by the robot, is divided into subtasks: • select those enemy assets that need to be destroyed; • choose their own means, which the robot uses to strike independently or to call stationary means of attack – artillery, missiles, aircraft, drones;  
  Functional Programming of Intelligent Systems  
  • determine the optimal order of strikes, based on the selected targets; • calculate the order of actions and movements of the robot, providing it with safety. It should be noted that when modeling an SbA on the basis of the information received by the robot, not only the formation of features takes place, but also the recognition of objects to which these features correspond. After recognizing an object, its ontology is formed, with which the assessment of this object is associated in the form of an object weight that characterizes the value of the object. It is assumed that the higher the weight, the higher the need to destroy the object. In addition, as an element of the ontology, the robot can specify the choice of means by which the object can be disabled. After that, a situational graph is built, the vertices of which are the objects that the robot needs to hit, and the directed arcs from the vertex x determine the objects that the robot can hit next. See Fig. 3 for an example of situational graph for a military target.  
  Fig. 3. Situational graph for a military target.  
  The situational graph is used to construct a behavior graph representing the optimal order in which the robot performs its tasks (see Fig. 4). When constructing this graph, an algorithm is used to select the next object, depending on the weight of the next object and the ability of the robot to reduce the time of the next strike. This possibility depends on the robot control system – capturing a new target, choosing a possible means of destruction, assessing the degree of enemy opposition, and moving on to the analysis of the next object. Note that as separate conditions for constructing a behavior graph, it is necessary to take into account the possibility of moving the robot either to create favorable conditions for the next strike, or to ensure its own safety. The function of constructing a behavior graph – static, in which the robot remains in place while solving its task – delivering successive strikes, or dynamic – in which the position of the robot changes after performing several individual strikes, is the main function used in solving this problem. At the same time, the robot can deliver several  
  Fig. 4. Behavior graph  
  blows to the same target, separated by time intervals, during which the robot performs other actions. The following classes of tasks of countering the enemy and protecting people and military support are built as a combination of applying the solutions that were obtained for the intelligence and attack classes. At this level, both the behavior of an individual robot and the combination of several robots to solve one common task can be considered. In this case, the situational graph is represented as the sum of situational graphs of either individual robots or situational graphs in which several robots act synchronously, inflicting joint strikes on enemy objects. In this case, some generalized robot can be formally considered, consisting of several interconnected robots operating in parallel with each other. The task of functional description is similar to the previous one, with the difference that the number of damaging agents (multiplied by the number of robots included in the association) that such a generalized robot disposes of is increased several times. True, in this case, another problem arises – a generalized robot can be divided into several smaller generalized ones of a smaller size, each of which solves its own separate tasks.  
  4 Conclusion An intelligent system is a system that uses intelligence to shape its behavior in its environment. This intelligence is determined by two main factors: the first factor is the ability to model the environment, and the second is the use of this model to successfully solve problems that determine the behavior of the system in the environment. Environment modeling is based on the use of knowledge about the environment and its components. The system collects this knowledge using its sensors and sense organs, as well as the knowledge base, which stores information previously collected or incorporated during the development of the system. In particular, this information may include various forms of mathematical structures that form the basis of the environmental model. When solving problems, previous experience collected in the knowledge base can also be applied, simultaneously with a logical conclusion, based on the logic embedded in the intelligent system during its development. Creating an intelligent system, you can apply functional programming methods. First, by using programming language structures to represent individual knowledge and knowledge bases. Secondly, by developing functions that transform this knowledge  
  Functional Programming of Intelligent Systems  
  Fig. 1. Example of collaborative concept mapping. The details of the activities are shown in our previous paper [9]  
  The challenge of our study is to explore model-based support in an openended domain. In the past, model-based support has usually provided hints to learners solving problems with speciﬁc correct answers, such as programming or mathematics problems (e.g., [3]). In contrast, concept mapping has been applied to activities for which it is hard to deﬁne one correct solution, such as exploring the causes of natural, social, or psychological phenomena [11,15] or summarizing academic papers [9]. In this paper, we describe a cognitive model for constructing concept maps as well as the ideas and challenges of modeling this activity in the Adaptive Control of Thought-Rational (ACT-R) cognitive architecture [2], in particular for realizing interventions based on the computational cognitive model. Before presenting our models and supports, we brieﬂy introduce this cognitive architecture.  
  2  
  In this research project, we introduce a mixed reality system, where the user is guided by a remote expert in performing ﬁrst aid (Fig. 1). Our RGBD cameras allow for three-dimensional visual information that helps the user through the steps. Within this project, we conducted an evaluation with 30 participants separated into two groups. Both groups were given the same tasks. They had to give ﬁrst aid to a lifeless person, bring the person into the recovery position and start with CPR after the person stopped breathing. We compared instruction via the mixed reality (MR) approach (group A) with video-based communication (group B). We analyzed objective metrics of CPR quality recorded by the CPR mannequin, and data from users including workload surveys and interviews. We conclude our main contributions as follows: 1. We introduce an MR communication system designed for remote ﬁrst aid assistance. 2. We conducted a comparison between MR communication technology and video-based communication. 3. The project team measured workload and performance when giving assisted ﬁrst aid in MR and videoconferencing. The paper is structured as follows: Sect. 2 gives an overview of past research of Extended Reality (XR) applications for ﬁrst aid assistance. In Sect. 3, we discuss the design of the MR communication system, focusing on the diﬀerent views and their interaction with each other and the devices and software that were used. We evaluate the presented MR communication system in a research study described in Sect. 4. After introducing the study procedure, we present and discuss the results that were obtained. In the end, we summarize the work and give an outlook on future work.  
  2  
  Nr of prior MR experiences  
  CPR Performance. Data for 25 learners (13 video and 12 MR) was included; 5 data samples were removed due to mannequin malfunction. There was no significant diﬀerence in CPR performance when comparing video and MR conditions for any CPR performance category (2 sample, 2 tailed t test with signiﬁcance of α = 0.05). The data is presented in Table 2.  
  CPR Emergency Assistance Through Mixed Reality Communication  
  Ventilation Score [%] Number of ventilations [n] Ventilation Adequate ventiliation [%] Hyperventilation [%]  
  Workload. We illustrate the overall results of both workload surveys, NASATLX and SIM-TLX, for ﬁrst responders and the expert in Table 3. The expert reported a lower overall workload for both surveys when using the MR technology compared to videoconferencing. The ﬁrst responders reported similar workload between the two technologies. A two-sample two-tailed t-test was not able to show a signiﬁcant diﬀerence (α = 0.05) between the groups. The mean overall workload is similar when comparing the two technologies. We present the per-category workload results for ﬁrst responders in Fig. 5 to give a more in-depth insight. The physical demand was the highest during the ﬁrst aid emergency. We posit that this is related to the physical exertion during chest compressions. The SIM-TLX signals three interesting trends. The video-assisted ﬁrst responders reported higher frustration but lower distraction and perceptual strain than the MR communications group. We propose that the higher frustration with video results from two factors. First, instructions involving physical space must be communicated via 2D video and voice, which must then be translated into actions, rather than by using virtual objects to provide visual demonstration of the necessary action. Secondly, the ﬁrst responders must switch gaze from the task at hand to the video, in order to compare their own progress with the instructor’s directions. In MR, visual communication is more similar to in-person because the views are aligned, and pointing gestures and augmented object demonstrations can be used. The higher perceptual strain reported by the MR group may also be due to the relative increase in visual information presented to and processed by the learner in the MR mode. Higher  
  30  
  distraction ratings in the MR group may result from the limited ﬁeld of view (FOV) of the Hololens 2 headset, and the need to locate or track instructor input outside the FOV. We argue that this can be improved by only showing them the remote hands when necessary, for example when the remote expert decides to point or gesture actively. Mixed Reality Survey. The ﬁrst responders noted in the open-ended questions that they especially liked the gestural communication including pointing by the remote expert. They highlighted the importance of visual communication in stressful situations. When asked about problems with the MR system, some participants noted that the visual instructions were not always given at the best position such that  
  CPR Emergency Assistance Through Mixed Reality Communication  
  they had to look around to see the augmented instructions. When asked about what they liked about the experience, the expert reported: “I really liked the possibility to have additional holograms illustrating hand positions or rescue positions. This helped to provide faster help and spend less time with instructions. Additionally, the diﬀerent camera perspectives were great for evaluating the quality of the CPR (chest compressions and ventilation).” The negative aspects were: “The initial setup of the 2D and 3D areas was sometimes a bit cumbersome. When moving the cube (a handle for moving the location of the visual feeds) the area did not move adequately. Sometimes the connection got lost due to some reason but restarting the system was not a big deal.” The expert was also asked about features that could be added: “Some participants complained that audio and visual instructions can be a bit overwhelming. Therefore, a visual way to show the frequency of chest compressions would be great. Especially for the rescue position, a 3D object with movable joints (knee, arm, etc.) would be helpful to show how to bring a person to the rescue position (instead of an object of the already correct position).” Discussion. Although the application of MR devices seem to be futuristic within the context of emergency situations, it enables interesting perspectives. Many countries have successfully implemented guided ﬁrst aid instructions over an emergency call. A (3D) video channel could provide additional information to the emergency call center regarding the set measures and their quality. Although the MR and video groups did not diﬀer signiﬁcantly in terms of CPR performance in this study, use of MR with truly novice ﬁrst responders may be more beneﬁcial during complex maneuvers, for instance to evaluate and demonstrate head tilt-chin lift for ventilation. Similar to AEDs, which are usually close by to an emergency situation in urban areas, MR devices could be co-located with them to initiate an emergency call or request for additional support from the emergency call center. Analyzing the combined performance and workload results, we conclude that the technology is well suited for emergencies because the usage is intuitive. The remote expert only required brief guidance on how the MR technology works. Furthermore, the ﬁrst responders put on their HMD only about 30 s before the actual simulation started. Moreover, assuming that the technology has a learning curve, better MR results can be expected after using the technology longer or more frequently. Broader Impact. MR technologies are used for communication across industries. Since ﬁrst aid emergencies are stressful and complex procedures, we believe that the technology can not only be used for other medical procedures including medical training, but also across domains. An example could be remote repair emergencies where a local operator needs to receive guidance from a remote expert to complete the task as quickly and accurately as possible. Similar to giving CPR, spatial information and visual communication including pointing, gestures, and augmented objects seem invaluable.  
  learning or problem-solving. Cognitive engagement involves specific learning-oriented strategies [5]. Effectively facilitating behavioral and cognitive engagement in SRL yields optimal learning performance. Nevertheless, limited studies have investigated the patterns of behavioral and cognitive engagement within SRL processes and their effects on learning performance. Particularly, to our knowledge, no study has examined the relative importance of behavioral and cognitive engagement to task performance in SRL with an ITS. In this study, we explored medical students’ cognitive and behavioral engagement in different SRL phases as they solved clinical reasoning tasks with an ITS. We attempted to understand the relative importance of behavioral and cognitive engagement, as they occurred in each phase of SRL, to student performance. In line with the literature, we conceptualized behavioral engagement as on-task behaviors. We used think-aloud protocols to capture students’ thinking and reasoning activities in clinical reasoning, based on which we calculated students’ cognitive engagement in SRL phases. We will explain the measurement of behavioral and cognitive engagement further in the method section. In sum, the overarching goal of this study is to unravel the relationships among SRL, behavioral engagement, cognitive engagement, and task performance as students solved clinical reasoning problems with an ITS. We also look into how task complexity affects those relationships. This study has practical and methodological implications. This study also informs the design of augmented intelligence in intelligent tutoring systems.  
  2 Theoretical Framework SRL is an active, constructive process through which students monitor, regulate, and control their learning efforts in both external and internal dimensions [6]. SRL is a cyclical process consisting of three phases [7]: forethought, performance, and self-reflection. In the forethought phase, students set goals and plan the strategies and effort to achieve their goals. The performance phase involves self-observation and self-control, whereby students monitor and control their actions to approach their goals. In the self-reflection phase, students reflect on their learning trajectories and progresses, based on which they make adaptations towards desired outcomes. In technology-rich environments (e.g., ITS), SRL is pivotal to better performance, higher achievement, and a satisfied learner experience [8, 9]. Engagement was first defined in school contexts as a multidimensional concept consisting of behavioral, cognitive, emotional, and psychological components [5]. In this study, we were particularly interested in the behavioral and cognitive aspects of engagement. The differentiation between behavioral and cognitive engagement helps understand student effort in learning. Behavioral engagement is the observable behaviors of students in completing a learning task, whereas cognitive engagement shows the amount of mental effort students investigate in working on the task [5]. Researchers have reached a consensus that both behavioral and cognitive engagement is positively related to task performance. Instructors should design strategies or scaffoldings to promote behavioral and cognitive engagement. Nevertheless, rarely the relative importance of behavioral and cognitive engagement to task performance is studied. The research is  
  X. Huang et al.  
  even more scarce when it comes to the context of self-regulated learning. Researchers have investigated the relationships between SRL and engagement in various contexts, e.g., collaborative learning [2], and flipped classroom [3]. For instance, findings from a qualitative study indicated that engagement varied across an SRL cycle [10]. However, no studies have compared the relative importance of the two types of engagement (i.e., behavioral engagement and cognitive engagement) within the SRL process. It is also noteworthy that the concepts of engagement and SRL could sometimes be less welldefined, which may lead to ambiguous interpretations [11]. The boundaries between behavioral and cognitive engagement are blurred. In this study, we make a clear distinction between the two constructs, and we compare their relative importance to task performance in SRL with an ITS. We situate this study in clinical reasoning, a complex problem-solving setting that requires critical thinking and reasoning skills. In clinical reasoning, medical practitioners diagnose patients (or virtual patients) by inquiring about a patient’s symptoms and life experience, performing medical tests, seeking for guidance, proposing diagnostic hypotheses, assessing the probability of each hypothesis, and making a final decision. As such, clinical reasoning asks medical practitioners to be behaviorally and cognitively engaged during diagnostic processes. Meanwhile, clinical reasoning consists of forethought, performance, and self-reflection activities. Therefore, clinical reasoning represents a good example of studying the relationships between engagement, SLR, and task performance. Specifically, this study aims to answer the following two research questions: (1) What is the relative importance of cognitive and behavioral engagement in the three SRL phases (i.e., forethought, performance, and self-reflection) to clinical reasoning performance? (2) Does task complexity affect the relative importance of cognitive and behavioral engagement to clinical reasoning performance?  
  3.2 Learning Contexts and Task BioWorld is an intelligent tutoring system designed to assist medical students in practicing clinical reasoning skills in a simulated learning environment [12, 13] (see Fig. 1). Each case in BioWorld begins with a description of a virtual patient and pertinent symptoms. Students select useful evidence based on the presented case facts by recalling their prior knowledge of the disease. Then, students formulate one or more hypotheses. To validate or refute their findings, students can order medical lab tests or search an embedded medical library for additional explanations. After providing a final diagnosis, students are required to assess the relevance of the collected evidence to their hypotheses, justify the probability of each hypothesis, and summarize their clinical reasoning processes. In this study, participants were assigned to resolve the Amy and Cynthia patient cases in BioWorld. The accurate diagnoses for the two cases were Type 1 diabetes and pheochromocytoma, respectively. The Amy case was designed to be simple, whereas the Cynthia case was designed to be difficult.  
  Fig. 1. The main interface of BioWorld [12, 14].  
  Self-satisfaction involves perceptions of satisfaction or dissatisfaction and associated affect regarding one’s performance  
  In terms of student diagnostic performance, we calculated the match between a participant and experts’ solutions. It is worth mention that experts’ solutions, including useful evidence items, medical tests needed for diagnosis, and a correct diagnosis, are prefigured in the BioWorld system. Once a participant submit their final diagnosis, the system will generate the performance score for the participant [3]. 3.5 Data Analysis We used a relative importance analytic method [18] to compare the relative importance of students’ behavioral and cognitive engagement in the three SRL phases (i.e., forethought, performance, and self-reflection) to task performance. In other words, there were six predictive variables, i.e., two types of engagement in the three SRL phases. The relative-weight analysis deals with predictor intercorrelations using a variable transformation approach [19]. It is an alternative to the multiple regression technique, tackles the multicollinearity issue, and helps to determine the variables’ rank in importance. It helps answer the question “which variable is the most essential and ranks variables based on their R-Square contribution.“ Relative importance weights are estimated for each predictor variable and offer a complete decomposition of the total predicted variance to the model R2 [19, 20]. This method is promising to deal with multiple predictors when determining which predictor is more important or useful than others to predict an outcome variable. The data analysis is conducted in R using the package “relaimpo” [21].  
  The Relative Importance of Cognitive and Behavioral Engagement  
  Note. FT: the forethought phase of SRL, PE: the performance phase of SRL, RN: the self-reflection phase of SRL  
  5 Discussions and Conclusions In this study, we compared the relative importance of cognitive and behavioral engagement in the three SRL phases (i.e., forethought, performance, self-reflection) to diagnostic performance in clinical reasoning with an ITS. Findings from this study suggested that the effects of behavioral and cognitive engagement on student performance depends  
  The Relative Importance of Cognitive and Behavioral Engagement  
  Emotional Impact of Cognitive Priming on Alzheimer’s Disease Hamdi Ben Abdessalem(B) and Claude Frasson Département d’Informatique et de Recherche Opérationnelle, Université de Montréal, Montréal H3C 3J7, Canada [email protected]  , [email protected]   
  Abstract. Subjective cognitive decline (SCD) is an early state of Alzheimer’s Disease. As this disease continues to spread, there is still no efficient pharmacological treatment to stop it. Non-pharmacological treatment may be effective to slow down the progression of the disease. We propose in this paper a cognitive priming system which projects the name of forgotten celebrity names in a very fast way (29 ms) so only the subconscious part of the patients’ brain can intercept it. Experiments with different SCD patients have been realized divided into 2 groups. The first group was to investigate the impact of the cognitive priming system, and the second one was to serve as a control group. Results show that SCD patients’ frustration decreased when the cognitive priming system projected the missing information. In addition, results show that their memory performance increased when the system performed the cognitive priming technique. Thus, cognitive priming can reduce negative emotion and improve memory performance. Keywords: Cognitive Priming · Alzheimer’s Disease · Negative Emotions · EEG · Behavior and Cognition · Health Care · Wellbeing  
  Another non-pharmacological technique which could be used to improve the memory of SCD patients, is the cognitive priming method. The principle of cognitive priming is to project information very quickly so the conscious part of the brain cannot receive it, but the subconscious part can intercept it [9]. We believe that this technique could help restore forgotten memory of AD patients. Is there a link with the reduction of negative emotions? In this goal we conducted experiments with SCD participants to verify the following research questions. Q1: Can cognitive priming reduce negative emotions of SCD patients? Q2: Is there a relation between the effect of cognitive priming on memory performance and its effect on negative emotions? The rest of this paper is organized as follows. In Sect. 2 we present an overview of the related work. Section 3 presents our methodology. In Sect. 4 we present the experiments. Finally, in Sect. 5 we present and discuss the obtained results.  
  2 Related Work 2.1 Non-pharmacological Treatment for Alzheimer’s Disease Several researchers utilized non-pharmacological approaches to treat AD patients. One of these approaches is Animal Assisted Therapy (AAT). AAT is a treatment that concentrates on psychosocial stimulation and human-animal interactions for therapeutic purposes. AD patients can have difficulties interacting with other people. The nonverbal action of a dog can be easily interpreted. Animals can play a role as transitional objects, allowing humans to first establish a connection with them and then extend that connection with other humans. AAT has a relaxing effect on patients with dementia and Alzheimer’s disease [10], particularly as therapy with dogs. Virtual Reality Zoo Therapy [6] incorporates the theory of AAT in addition to virtual reality to maximize its effect with immersion. Furthermore, another relaxing approach used for therapeutic reasons is music. It is commonly used for different conditions, such as autism, brain injury, and dementia [11–13]. Byrns et al. proved that they can reduce AD patients’ negative emotions by combining music therapy with EEG brain assessment in a virtual environment [7]. 2.2 Cognitive Priming Other than relaxing environment, cognitive priming could be an alternative solution to improve memory performances. In fact, priming is defined as an unconscious form of human memory. It affects the perceptual identification of words and objects and has been recognized as separate from other forms of memory or memory system [9]. Cognitive priming is a type of priming which aims to enhance specific cognitive processes such as decision-making toward the goal of indirectly enhancing knowledge acquisition [14]. Del Cul et al. were the first to utilize cognitive priming [15]. In addition, DeVaul used cognitive priming to better associate names to faces [16]. Moreover, Lowery et al. showed that cognitive priming can increase performance on midterm exams compared to neutral primes and that subliminal priming may have long-term effects on real-world behavior [17]. Finally, Chalfoun and Frasson used these techniques and discovered a clear memory and cognitive improvement [18].  
  Fig. 6. Performance improvement per participant using cognitive priming. (Color figure online)  
  improvement comparing the improvement observed in Fig. 6. For the control group without the cognitive priming, most participants’ memory did not improve. Consequently, these results confirm that the use of cognitive priming technique can reduce negative emotions and improve memory performance. We believe that this reduction of negative emotions is due to memory performance improvement and satisfaction. As the participants retrieved missing information in their memory, they became less frustrated, and their negative emotions were reduced. These results encourage us to use our cognitive priming system with learning applications. Since learners experience negative emotions such as stress, we believe that the use of our method to help them acquire missing information, can reduce their negative  
  Emotional Impact of Cognitive Priming on Alzheimer’s Disease  
  emotions and thus improve their learning capabilities. For instance, in the case of learning medical applications, medical students try to solve a medical case by reading the symptoms, performing analysis, choosing a diagnosis, and performing medical actions. We can modify our system to perform cognitive priming of the missing information when it detects that their negative emotions are increasing.  
  6 Conclusion In this paper, we introduced a novel approach which uses cognitive priming as a nonpharmacological treatment for SCD patients. Thus, we created a cognitive priming system for SCD patients aiming to investigate the effect of the cognitive priming technique on their emotions and memory. The experiments were divided into two groups. For the first group, the system performed the cognitive priming technique. The second group was our control group, so the system did not perform cognitive priming. Results showed that our system can increase memory performance using cognitive priming. In addition, results showed that cognitive priming system can reduce negative emotions. Besides SCD treatment, this system could be used to help reduce learners’ negative emotions by performing cognitive priming of their missing information. Acknowledgment. We acknowledge NSERC-CRD (National Science and Engineering Research Council Cooperative Research Development), PROMPT, and Beam Me Up for funding this work. Thanks to Alexie Byrns who contributed to the experiments. We also acknowledge the contributions of Sylvie Belleville and Marc Cuesta from IUGM (Institut Universitaire de Gériatrie de Montréal).  
  long run. Desirable Difficulties or a considerable but desirable amount of effort in the initial learning period is a research-based principle for teaching and learning, leading to improved long-term performance [5, 6]. This difficulty level should involve a small investment of time and effort in spaced activities, calling for generation and self-testing through feedback to translate into significant learning gains identified as a desirable level of difficulty opening a window of learning opportunity [20]. It also looks like the information processing theory and the descriptive theory of skill acquisition align with the Challenge Point Framework (CPF) [21] and desirable difficulties [9]. I.e., challenges in a learning environment should match learners’ abilities. The CPF, coined by Guadagnoli and Lee [14], helps in the effects of various practice conditions’ conceptualization in motor learning by relating practice variables to the individual’s skill level, task difficulty, and information theory concepts. Hence, any raises in task difficulty may considerably impact learning potential with a reverse impact on performance, i.e., maximizing learning while minimizing any harm to performance in practice determines the optimal challenge point (OCP). It is believed that such a learning environment can create a model of success in which learning becomes inherently rewarding and enjoyable. However, “students may not engage in retrieval practice in their natural educational settings due to lacking metacognitive awareness of the mnemonic benefits of testing.“ Retrieval information practice through testing the latter positively impacts long-term retention and learning [19, 25]. In different terminology, Metcalfe’s [20] Region of Proximal Learning, Hitchcock and Mcallister’s [17] OCP, and both Hartwig and Dunlosky’s [16] Zone of Proximal Development (ZPD) and Desirable Difficulties refer to a similar concept, that students engage in independent learning and practice, which should be pretty tricky, but at an acceptable level. Students are challenged enough to maintain their focus, and they can learn new concepts with guided assistance and scaffolding. Then, as the learning proceeds, the support structure is slowly removed. While Verenikina [30] refers to the ZPD as scaffolding’s theoretical foundations, De Guerrero and Villamil [15] refer to scaffolding as ZPD’s metaphor. ZPD and scaffolding also seem synonymous in that they both suggest learning with adult guidance or more capable peers’ collaboration exceeds independent learning. The ZPD, or OCP, is a tool instructor can use to make complex decisions about when to give extra scaffolding. Reiser [23, 24] points out that scaffolding is possible by structuring and problematizing and argues the interest in taking advantage of software tools to scaffold learners’ complex tasks. These software tools can be used in structuring learning tasks while guiding learners through critical elements that support their planning and performance. Since learning strategies creating desirable difficulties in the learning environment are most effective for learning outcomes’ long run, Biwer et al. [4] demonstrated that these findings are reliable for practical students’ training in higher education (i.e., positive effects on knowledge about effective learning strategies and increased practice testing use). Finally, beyond OCPs’ potential maximizing for surgical training, Gofton and Regehr [13] also stress the irreplaceable value of a mentor. These approaches – i.e., OCP, desirable difficulties, scaffolding, and ZPD – seem related and should not be considered separately for their application in a medical or  
  Y. S. Nkulu-Ily  
  progress and improve both long-term memory and transfer of learning. It is essential for motivation and efficiency of learning to keep challenge and ability in lockstep. Otherwise, people get bored or intimidated by the tasks being too challenging, both of which result in the individual losing motivation to complete the training. Using the CPF adds variability in guidance that can be helpful to the learner. CPF simulations can be used to provide training examples so that the AI model can be trained. After training the AI model, the simulation may incorporate the model to show how well the AI model would work. Simulation is based on some formulas and assumptions, but actual operations from learners can be any type and in the wilderness/real-world (i.e., they are not controlled, and many unexpected operations/scenarios may occur). OCPs should be determined for each level of the learner. Each surgical skill or task will have its own learning curve that will be individualized for every learner. A decision should be made about where the limits of simulation are. The setback is that, at some point, the OCPs will require actual patient encounters; learning in the simulation will be asymptotic and a waste of time. Fortunately, deliberate practice, when used in addition to mentorship, is an excellent method to improve learner performance while shortening the growth phase of the learning curve [7, 12]. 4.1 How Will the AI Determine a Failure or Successful Event? In terms of how the AI will determine a failure or successful event, it may be helpful to define specific criteria or metrics that the AI can use to evaluate performance. These criteria or metrics could involve using data on the user’s movements and actions within the simulation, as well as other relevant factors such as time taken to complete the task or the accuracy of the user’s actions (e.g., through imitation by labeling images/videos and comparing “Ghost images” vs. “Real-world images,” [11]). However, generally speaking, AI is only “intelligent” in finding patterns in data. With the right AI algorithm, good training data, and optimal parameters, the AI could effectively be trained to recognize a “failure” or “success” event by seeing enough examples of each event. I.e., DL will need to be trained on hundreds of hours of video labeled by experts. Good refers to quality, right relates to functionality, and optimal refers to a balance between different attributes, such as performance vs. safety. The alternative would be that, rather than using a proper “AI,” the designer/programmer could manually determine a set of rules or heuristics that a program can use to determine failure or success. AI systems are generally based on goal functions (also called utility functions or the results from “criteria or metrics”). To know how to react (no matter if the AI learns or reacts), the AI system must compare alternative “actions” or picks to make decisions. Even in some expert systems, where no goal functions seem to be implemented, there are goal functions in place, but they are binary (generate true or false values for each step). Most of the work could go into the design of such a function. Most code in a chess computer player is based on the chess rules, which is the foundation of how the goal function can assess each “game position.” The AI could then use this information to provide feedback to the user and assess their performance. It may also be helpful to consider how the AI can be integrated into the XR application in a way that is seamless and intuitive for users. Whether the trained AI evaluator eventually is to be built into the XR application would reduce friction (i.e.,  
  Combining XR and AI for Integrating the Best Pedagogical Approach  
  Y. S. Nkulu-Ily  
  first level (or scale) to go to the next one. In each part of the experience, a decision must be made on what constitutes success and if the user can repeat the level to achieve a higher score. Users will be evaluated on a scale of 5 (skilled) to 1 (novice). However, scaling is dynamic according to needs, so any scaling method can be used depending on the AI system design. The same scale or different scales can be used. An attractive alternative could be to use raw data as input for the AI machinery to estimate probabilistic states [28]. A continuous variable would be used instead of a Likert one. However, if different scales are used, they must be rescaled to keep values consistent, i.e., the AI scale must be mapped with the one used in XR. Realism and Sophisticated Behaviors Based on a Likert scale measurement, how much fidelity would be needed? The question of how much fidelity is needed is hard to answer because the measurement of performance or learning is pretty blunt (1–5 categorization). Many things are being learned: anatomy, clinical knowledge, motor skills, procedures, and problem-solving. These can all be measured more precisely than 1–5 categorization. Each stage has specific goals (say, instrument familiarization and location in the training device). Moreover, there is no quick fix to design for anyone to capture and analyze sophisticated behaviors in real time for skill training. Learning is influenced by teaching methods provided in the media or by a live teacher with the same amount and type of learning. Teaching is complex, though, and no ‘best practice’ can be transferred from one situation to another. Expert teachers intuitively assess each learner’s current cognitive knowledge and affective state through engagement with the learner. How will this complexity be addressed? The app, through the ACSS, will automatically use the ZPD or OCP to make complex decisions about when to give extra scaffolding. Given that teaching is complex, what useful strategies could then be used to design the application to capture and analyze sophisticated behaviors in real-time? To design the application to capture and analyze sophisticated behaviors in real-time, high-speed videography and motion capture technology may be considered to replicate a tactile experience with real haptic feedback. The preceding reasoning could also involve using 3D assets and hardware that provide haptic feedback to the user, such as haptic gloves or other wearable devices. However, haptic feedback devices are very cool. Unfortunately, this technology is still in its infancy to date, and therefore, there are not yet any well-supported, commercially available haptic feedback devices that would work for this kind of app. Moreover, AI models cannot currently learn these sophisticated and tacit processes. The only way forward is to develop AI-human interfaces that help teachers and/or learners with these complex interactions. AI will catch the behavior of the user and see if the behavior is at or close to the right move. DL part will also require a lot of labeled data with many example videos (perhaps hundreds of hours) labeled by experts. There are commercial entities actually working on this aspect. With computer vision, movements can be tracked; the most significant issues obviously come with occlusion and the use of instruments. Some companies are working on overcoming these. The most successful applications (like Proximie) use video feeds from endoscopies and robotic surgery where only instruments are tracked, not the hands. The preceding is a precious  
  Combining XR and AI for Integrating the Best Pedagogical Approach  
  line of research, in any case. To allow anyone to capture, equipment and setting must be standardized. This is why laparoscopy and robotics are the first areas to look at this. An attractive alternative would be to add educational games with stealth assessment and built-in learning dashboards for instructors to provide real-time feedback [27]. The continuous interaction with stealth assessment produces rich sequences of actions as data points that the stealth assessment captures in log files. Stealth assessment rubrics automatically score these aggregated data in real-time by Bayesian networks (or other statistical models). This process shows evolving mastery levels on targeted competencies [27]. 4.3 AI-Human Interfaces or Educational Games’ Best Pedagogical Practices In determining the best pedagogical practices for these AI-human interfaces or educational games, the best practice is scaffolding the learner depending on their abilities and performance. The best application will keep them engaged at the edge of their abilities and increase the difficulty over time. The best formative will give them subtle feedback, and the experience guide them in what is right and wrong (similar to video games). Real-time feedback has to be immediate, succinct, actionable, and straightforward. Education around performing the task should be embedded in the experience. Summative performance data should delineate their skill level in separate domains (e.g., accuracy, efficiency, etc.). In learning applications, pedagogical agents are usually used. I.e., some characters communicate with each other with the user. This agent will also provide feedback later. In some applications, for example, a teacher or scientist character guides the user. AI needs to learn from each domain of the skill the novice’s delta from an expert. For example, they may be accurate but not efficient. This information needs to be communicated in some way to both the AI to evaluate and feedback to the user. In terms of using AI to provide feedback for reinforcement and assessment, it would also be essential to consider what information is most relevant and valuable for the users to receive. It may also be that showing/not showing this information is more appropriate/valuable at different stages in the educational pipeline. This decision may depend on the stage of learning and the specific skills being trained [26]. However, formative feedback is best served immediately and summative after each experience or set of experiences. For example, novice learners may benefit more from detailed explanations of how to perform a task, while more experienced learners may benefit more from feedback on their specific performance. It may also be helpful to consider different ways of communicating feedback to users, such as through visual or auditory cues within the simulation or more detailed reports or analyses provided later. Feedback should be multimodal (sounds, lights, vibrations, etc.) and nearly immediate. There are UX guidebooks on best practices. It should not distract from the experience but be very clear and succinct to the user, as in video games. At first, it would be desirable to try to make it accessible later. If it is built within the simulation, then only with sufficient data can the AI model tell if anything is wrong on the fly – the goal is to correct behaviors in real-time. Likely all the information listed will  
  Y. S. Nkulu-Ily  
  be needed, which means the context is leaning towards game design and user experience theory and concepts here—like a car racing simulator or Game, such as Forza 7. Regarding the relevance of the Game’s use, a few points must be considered carefully. Though serious games for medical education and surgical skills training can apply here, there are several concepts related to using games in medical learning. These concepts include: 1. The use of games in medical practice is still limited, and their use is only limited as a companion to the leading learning media. The understanding is that only AR and Virtual Reality (VR) expose medical models, and only a few have interactions (such as surgical practice). 2. Referring to the articles on JMIR Serious Games, the use of games is still limited to understanding the material, not the practice of surgical operations. 3. There are several VR applications with educational content on human anatomy, but there are still very few specifically related to surgery. 4. There are some medical games, but they are only for fun, not entirely educational games. 5. The experience must be embedded in an environment that reinforces skills through the gameplay without blindly putting on badges, scoring, and leaderboards. These should be meaningful to the experience. 6. Game-based stealth assessment seems valid, reliable, and improves learning [27]. 7. For DL, medical expert systems are suitable, and Ripple-Down Rules (RDR) may be more relevant [10]. I.e., combining ML and RDR, particularly RDR systems that recognize a case outside their competence. RDR is easier to implement on insufficient data than AI. 4.4 A Pedagogical Approach to Errors in a Simulated Environment Educators teach students about errors to help avoid them. Residents can make mistakes in the simulated environment since that is how they learn, so they should fail in a simulated environment rather than in real life. However, in general, the understanding of the research is that teaching about errors tends to increase the mistakes, not decrease them. In medicine, many (some say most) errors are due to missed condition/action situations. For example, forgetting to do something, and the second most frequent error is “doing something wrong,” missing steps in a procedure, or implementing the wrong approach for the conditions. In both cases, the error is sometimes due to the instructor skipping over a step or steps in a procedure/assessment that misses the student’s failure to remember the actions or process. Adequate instruction, practice, and corrective feedback should help avoid future errors. In some cases of coaxers, students become distracted and cause errors despite solid education. 4.5 Multi-device Considerations When Designing/Developing the App When developing an app. to be used for multi-devices, then one consideration that should be taken into account is whether this app can be available for multiple devices or require XR devices. The only natural way to understand it is to actually trial it since these  
  Combining XR and AI for Integrating the Best Pedagogical Approach  
  Y. S. Nkulu-Ily  
  groups of expertise, objective feedback based on proficiency benchmarks, and instructor input, the force sensor (i.e., using the support vector machine learning model) [22], SmartForceps data app [3], and tool-tissue forces in Newton (i.e., using deep neural networks) [1] can help improve training in orthopedic surgery and allow avoidance of these errors and resulting complications. The latest deep learning models (i.e., deep neural networks) can capture more parameters for performance metrics and perform more realistic simulations. 4.8 Learning Experiences in Healthcare Return on Investment (ROI) for Education – Measure “The level of expertise of surgeons performing procedures should be reported” to determine whether the technique or surgeon’s poor execution – of the technique – led to poor results. Not only is comparing results between surgeons with significantly different levels of expertise invalid, but this critical information is also generally missing from published articles. [29] A well-defined expertise definition includes (1) Non-specialist, (2) Specialist – less experienced, (3) Specialist – experienced, (4) Specialist – highly experienced, and (5) Expert [29]. Whether expertise or performance is measured, performance is usually measured by OSATs. However, surgical procedures’ performance and improved learning curves are rarely measured [7]. The technology vs. human comparison is a ‘teaching method one vs. teaching method 2’ study of the kind Clark [8] discouraged many years ago – on the ground, such comparisons are confounded, always. In this case, the question is: how does the feedback differ between the two conditions (other than the delivery via machine vs. human)? If the feedback has the same information, frequency, and structure, there should be no difference in outcomes. If they are different in any of these regards, those differences presumably underlie the results. If, for example, the machine can provide more or more frequent feedback and/or practice, then this is perhaps the basis of the difference, not the circumstance of machine vs. human. A suggestion to make the subsystem more “intelligent” would be by noting residents’ responses to individual cases in a way previously done for students learning computer programming [18]. Their system records every student interaction with it, providing a rich data set for analysis. Then, statistical pattern recognition and ML techniques automatically identify the “common mistakes” for each type of case. This improved subsystem should respond appropriately to a more comprehensive range of resident errors, including the possibility of mistakes that even an experienced tutor may not have anticipated.  
  5 Conclusion This qualitative interview is not a general survey, and these are complicated questions that require either substantial experience in this area of research or research investigation in their own right. Many of them are complex and not necessarily “solved” – many are thesis topics on their own that are probably better answered by someone with a background in education (i.e., educational technology or medical education).  
  12. 13. 14. 15. 16. 17.  
  How can I design for anyone to capture and analyze sophisticated behaviors in realtime in applying the field of high-speed videography of movement and its analysis by DL algorithms to skill training? Data format or transfer process: Users are evaluated on a scale of 5 (skilled) to 1 (novice). Should that be the same scale used in values sent to the AI? Would it be better for the trained AI evaluator eventually be built into the XR application? What is the best practice regarding pedagogy here? I’m also not sure exactly what information I will have to show the users - is it information on how to perform the task, their performance in the task, or something else? Would it be advisable that this information be shown to the users within the simulation, or would it be better if it is accessible later? How will AI be used in application development to provide feedback for reinforcement and assessment? What is the best pedagogical approach to providing feedback, and how best to communicate that feedback? How will AI determine a failure or successful event since AI needs some guidance for the kind of feedback that will be provided? Which “serious games” for medical education and surgical skills training would apply here, please? What type of data do you think will be helpful for my study, and what collection method would you recommend? Additionally, can you outline the development process for producing XR/AI materials, please? I want the app to be available for Smartphones, Tablet, PC / MAC (desktop/Laptop), moreover, will also require the use of VR devices such as a Head-Mounted Device (HMD) like the Oculus Rift, HTC Vive, or Google Cardboard. What could be the potential issues with my preferences, please? Please outline the development process for producing materials using the Challenge Point Framework (CPF) (graph or diagram). Or can you please share some practical applications of the CPF to simulation-based medical education and training? For example: How can this framework be incorporated into a simulation? What are some of its potential limitations, and how can we address them? What 3D- assets, Motion capture technology, and hardware are there that could be implemented to replicate a tactile experience with real haptic feedback? Using a technology-authoring environment, how can you mock-up or storyboard a prototype for a type of learning experience you may envision learners going through to answer a research question related to AR/VR, please? (i.e., an Example or Sample in any aspect of surgery to give me an idea of such a prototype)  
  Combining XR and AI for Integrating the Best Pedagogical Approach  
  B. Shankar and C. A. Hargreaves  
  classification [5], EEG signal interpretation [6], medical image segmentation [7], among many other sub-domains in healthcare [4]. All of these advances in machine learning and AI were driven by advances in Deep Learning Architectures built to handle modalities of data such as images and text, increased compute capacity due to the advent of GPUs (and more recently, TPUs), as well as the aforementioned increase in publicly available medical data. 1.1 Need for Patient Representation However, EHR data presents a unique challenge for machine-learning models. EHR data often is high-dimensional, temporal, sparse, multimodal, heterogeneous, filled with null values, and often is extremely large scale. This presents issues for machine learning algorithms of all types. Thus, we need some way to condense all the information in the EHR into a dense, mathematical representation of the data. That way, downstream predictive models can use that dense representation of the data, instead of the raw patient data. This problem is known as the problem of patient representation [8]. A good patient representation should ideally be usable for downstream predictive tasks, and the representation should be meaningful. A meaningful representation implies that similar patients should have similar representations. Ideally, we would also want each individual feature to be semantically meaningful – i.e. – it corresponds to a real-world concept. This leads to why patient representation matters to healthcare workers. Trust is an important factor in the adoption of any system in any industry, especially the healthcare industry. Explainability, i.e., being able to explain why a certain decision was made by a Machine Learning model in terms understandable to healthcare workers is key in encouraging the adoption of Machine Learning systems, as well as to help eliminate any biases or errors that may exist in the model. Unfortunately, the explainability of any model is inversely proportional to its complexity. This gets even worse when dealing with deep learning models, which are often considered to be black boxes. A semantically meaningful patient representation offers us a way to both leverage the unparalleled feature extraction capacity of neural nets, as well as being able to offer some level of explainability for any output of the model, thus offering the best of both worlds. 1.2 Past Work Past work in the field of patient representation has leveraged many different forms of neural nets, and varied mathematical objects to embody it. The first studies in this area used artificial neural networks to extract patient representations from data as seen in Che et al. [9]. However, basic Artificial Neural Networks do not handle temporality, sequential data, nor unstructured data very well. This then necessitated a change in approach. We then saw autoencoder-based models, which consist of an encoder-decoder pair come into use for patient representation. Miotto et al. [10] used a stacked autoencoder (Multiple autoencoders stacked on each other) to come up with a general patient representation.  
  Adversarial Learning for Improved Patient Representations  
  B. Shankar and C. A. Hargreaves  
  both adversarial learning and multimodal fusion on patient data, which is the gap that the following paper attempts to mediate.  
  Fig. 1. A representation of a patient as a sparse time series.  
  2.3 Model Time2Vec When examining the original transformer architecture, we see that we need to provide each input token vector with a positional encoding vector [14]. In the original paper on transformers, the positional encoding was derived from a function of the index. However, in our case, that positional encoding can no longer use the indices, due to the irregularly spaced nature of the time series. Thus, we need a way to convert the timestamp of the  
  Adversarial Learning for Improved Patient Representations  
  observation to a position embedding. The key insight of Time2Vec [28] is recognizing that the positional embedding is just that: a representation of the position of the token with respect to others. Hence, the timestamp is used to calculate the embedding as seen below: vt (x) = sin(Wx + b) where W and b are learnable parameters, x is the timestamp and vt is the vector representation of the timestamp. STraTS Out of all 7 modalities of data considered, 4 of them were of the form (variable, value, timestamp). We needed a way to consider both the value and variable being measured at each time stamp. Thus, we used a variant of STraTS [29] to encode the time series. STraTS is a method of using transformers to encode time series of differing lengths. STraTS encodes (variable, value, timestamp) triplets as 3 separate vectors by passing a numerical representation of each through a linear unit. We then add each of these 3 vectors element wise, which becomes the initial triplet embedding. We then pass these embeddings into multiple attention layers, followed by feed forward and norm layers. These allow for each of the individual embedding vectors to be considered in the context of the other embedding vectors, thus recovering multiple contextual embedding vectors. Finally, we fuse the embedding vectors using an attention fusion network, to recover a final embedding that represents the sparse time series as a whole. For the attention fusion layer, we consider vectors v1 , v2 ,…,vn as being the vector representation of each time point in the sparse time series. To get the weights α1 , α2 ,…,αn for each of the vectors, we pass them through a soft-maxed feedforward layer. The final fused vector is then vemb = α1 v1 + α2 v2 +…+αn vn (Fig. 2).  
  Fig. 2. A Description of a STraTS encoder  
  J. Wang et al.  
  various groups, learning sign language has emerged as a major research area in education. The majority of the most recent approaches to the teaching of sign languages [9,10,16] employ predeﬁned gestures, while approaches based on user-deﬁned interaction technology are more sparse in the literature. For example, Adamo et al. [1] proposed the development of a new immersive 3D learning environment to increase the mathematical skills of deaf children by teaching mathematical concepts and American Sign Language (ASL) math terminology through user interaction with fantasy 3D virtual signers and traditional interaction environments. Schioppo et al. [20] proposed a sign language recognition method using features extracted from data acquired by a Leap Motion controller from an egocentric view. The method was tested on the 26 letters of the ASL alphabet. In a related development, Phan et al. [17] used motion tracking to trial a number of diﬀerent methods for providing user feedback in a sign language learning system. Regarding research on the processes by which users can deﬁne themselves a vocabulary of hand gestures, Piumsomboon et al. [18] conducted research on hand gesture guessability in an Augmented Reality (AR) environment. They invited users to make gestures corresponding to certain tasks, and created userdeﬁned gesture sets to guide the designers in implementing user-centred hand gestures for AR. To the best of our knowledge, there are no studies on learning ASL through user-deﬁned interaction techniques. Hence, the purpose of this paper is to investigate if user-deﬁned interaction techniques can enhance users’ learning of ASL. We believe that this is an important research topic since most such systems use hand gestures created by system designers, which do not always reﬂect user intention. To accomplish our research goals, we developed a simple system with a userdeﬁned gesture interface for learning static ASL. In the system design, we have identiﬁed and taken into account shortcomings of prior systems, including the small data sets used to train the gesture recognizer, the absence of a realistic environment, and most importantly, the user’s diﬃculty in engaging with the system for an extended period of time. With inspiration from Bragg’s ASL Sea Battle [5], a sign language game created to help gather user data, we created and integrated a Whack-a-Mole style game with a user-deﬁned hand gesture interface into the system, aiming at boosting user motivation. Finally, we conducted a user study based on a survey designed according to Schrepp’s [21] recommendations and concentrated on user experience analysis. Summarising, the main research question motivating our work, “Can userdefined interaction techniques enhance user motivation to learn static ASL?”, was looked into within the context of a gamiﬁed environment for learning static ASL. Our main contributions are as follows: 1. We implemented a user-deﬁned hand gesture interface for ASL learning with a Whack-a-Mole type of game. 2. We conducted a user study to examine if user-deﬁned interaction aﬀected users’ experience. The initial results indicate a positive user attitude towards gamiﬁed learning environments and a strong interest of the users in userdeﬁned interactions.  
  Sign Language Learning  
  The rest of this paper is organised as follows. The prior work on technologyassisted sign language learning is reviewed in Sect. 2. The basic design and the features of the proposed sign language learning environment are presented in Sect. 3. The design of the user study is described in Sect. 4, while the results are presented and analysed in Sect. 5. We discuss the main ﬁndings in Sect. 6 and brieﬂy conclude in Sect. 7.  
  2  
  Sign Language Detection and Recognition  
  Real-time detection of dynamic hand gestures from video streams is a challenging task since: (i) there is no indication when a hand gesture starts and ends in the video; (ii) a performed hand gesture should only be recognized once; and (iii) the entire system should be designed considering memory and computational power constraints. Bheda et al. [3] proposed a method based on deep convolutional neural networks (CNNs) to recognize images of the letters and digits in ASL. Kim et al. [13] proposed a novel sign language recognition method, which employs an object detection network for a region of interest segmentation to preprocess the input data. Battistoni et al. [2] described a method for ASL alphabet recognition based on CNNs, which allows for monitoring the users’ learning progress. Jiang et al. [12] proposed a novel ﬁngerspelling identiﬁcation method for Chinese Sign Language via AlexNet-based transfer learning and evaluated four diﬀerent methods of transfer learning. Camgoz et al. [6] introduced a novel transformerbased architecture that jointly learns Continuous Sign Language Recognition and Translation while being trainable in an end-to-end manner. Zhang et al. [25] proposed MediaPipe Hands, a real-time on-device hand tracking pipeline to compute hand landmark positions from a single RGB camera frame for AR/VR applications. Goswami et al. [11] created a new dataset for ASL recognition and used it to train a CNN-based model for hand gesture recognition and classiﬁcation. Finally, Pallavi et al. [15] presented a deep learning model based on the YOLOv3 architecture, reporting high recognition rates on the ASL alphabet. Having reviewed the existing work on sign language recognition, we concluded that Mediapipe is the most suitable tool for the purposes of this paper, and thus, we used it for sign language recognition, beneﬁting from its highly accurate, real-time detection of hand landmark points. Moreover, as an open-source hand gesture detection framework from Google, it is well-documented and supported.  
  Fig. 3. (a) The Whack-a-Mole game for ASL learning; (b) the user deﬁned interface.  
  the user has picked their special skills, they may start playing the game again by clicking “Start” on the game screen, and they can use their newly acquired special game skill. The workﬂow of the user-deﬁned hand gesture interface is shown in Fig. 4. Notice that the special mole sequence must match the last digit of the remaining play time for the user interface to be activated. In addition, the user must be able to recognise the special mole’s number at a speciﬁc moment. When both requirements are satisﬁed, the user-deﬁned interface will be displayed and the user will be awarded their special game skill.  
  Special mole = last digit of remaining time  
  Fig. 3. Distributions of urgent posts (A) Number of words per urgent posts - (B) Number of characters per urgent posts.  
  Finally, to find out which words were most frequently used by learners in urgent posts, we calculate the top 30 frequency words in these posts, after removing stopwords; see Fig. 4. 3.3 Prediction Models The input of these models is the post from each learner and the output is the classification: if this post needs intervention or not, according to its urgency (binary prediction). We represent words as numerical forms (word embedding) using word2vec, as in [23], which converts words into vectors that depict semantics; and BERT, as in [13], which generates contextual representations for each words. We implement two different training models, which are as follows: (1) with word-based input. (2) with character-based  
  Personalized Feedback Enhanced by Natural Language Processing in Intelligent Tutoring Systems Christos Troussas(B) , Christos Papakostas , Akrivi Krouska , Phivos Mylonas , and Cleo Sgouropoulou Department of Informatics and Computer Engineering, University of West Attica, Egaleo, Greece {ctrouss,cpapakostas,akrouska,mylonasf,csgouro}@uniwa.gr  
  Abstract. This paper proposes a novel approach for enhancing feedback in intelligent tutoring systems (ITSs) for Java programming using natural language processing (NLP). The proposed approach overcomes the limitations of traditional rule-based feedback generation systems and provides more personalized and relevant feedback to learners. The architecture includes three main components: a natural language parser (that takes as input comments and/or questions of the user that can be inserted through a text box in the user interface.), a feedback generator, and a feedback evaluator. The natural language parser is responsible for converting the unstructured text input of the learner into structured data, which can be analyzed for generating feedback. The feedback generator component then processes this data and generates personalized feedback for the learner based on their specific needs. Finally, the feedback evaluator component assesses the quality of the generated feedback and determines its helpfulness to the learner. The evaluation results are promising, indicating that using NLP techniques can improve the overall performance of intelligent tutoring systems and provide a more personalized learning experience for students. Keywords: natural language processing · intelligent tutoring systems · feedback parser · feedback generator · feedback evaluator  
  C. Troussas et al.  
  have shown great potential in improving learning outcomes and providing personalized instruction to learners. As technology continues to advance, ITSs are expected to become more sophisticated and effective in providing feedback and guidance to learners. Recent advances in natural language processing (NLP) have greatly improved the feedback generation process in intelligent tutoring systems (ITS) [10–13]. NLP can help to analyze and understand the natural language input provided by learners, such as their code comments in a computer programming course or explanations of their problemsolving approach, and use that information to provide more personalized and relevant feedback. Leveraging state-of-the-art NLP techniques to analyze the learners’ natural language input and generate personalized feedback is a promising way to enhance the feedback generation module in ITS, especially for complex domains such as programming languages. By using NLP techniques, the system can provide feedback that is tailored to learners’ specific needs and level of understanding, leading to more effective learning outcomes. In view of the above, in this paper, we propose three components incorporated in our intelligent tutoring system for Java programming to support the process of feedback delivery to learners: the natural language parser, feedback generator, and feedback evaluator. These components work together to provide a comprehensive and effective learning experience for the learner, as follows: • The natural language parser is responsible for analyzing the learner’s natural language input, such as their code comments or explanations of their problem-solving approach, and extracting relevant information. This information is then passed on to the feedback generator, which uses this information to generate personalized feedback that is tailored to the learner’s specific needs and level of understanding. • The feedback generator takes into account various factors, such as the learner’s past performance, their learning objectives, and their preferred learning style, to generate feedback that is relevant, engaging, and useful. • The feedback evaluator then assesses the effectiveness of the feedback and provides feedback to the feedback generator, allowing it to adjust its approach and improve the quality of feedback provided to the learner. • The synergy between these three components is crucial for the success of the intelligent tutoring system. By leveraging the power of natural language processing, the natural language parser can extract valuable information from the learner’s input, allowing the feedback generator to generate personalized and relevant feedback. The feedback evaluator then assesses the quality of this feedback, allowing the system to continually improve and provide more effective feedback to the learner. The three components of the intelligent tutoring system work together in a synergistic manner to provide a more effective and personalized learning experience for the learner, ultimately improving their understanding and proficiency in Java programming. Our approach has several advantages over traditional feedback generation approaches in ITSs. Firstly, the use of natural language processing techniques allows for more tailored feedback that is better suited to each learner’s specific needs and level of understanding. Finally, by providing more useful and actionable feedback, this approach can  
  Personalized Feedback Enhanced by Natural Language Processing  
  help to improve the overall effectiveness of the ITS. This can lead to better learning outcomes for the learners and can help them to achieve their educational and professional goals.  
  2 Related Work The traditional rule-based approach for providing feedback in ITSs has limitations, as it relies on pre-defined rules and does not take into account the nuances of the students’ response or the context in which it was provided [14–16]. This can lead to generic and unhelpful feedback that does not address the students’ specific needs. In recent years, there has been a growing interest in using NLP techniques to analyze student responses and provide personalized feedback in ITSs. By analyzing the students’ natural language input, more relevant and targeted feedback can be provided. Recent research has shown promising results in using deep learning techniques, such as Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), for natural language understanding in ITS for computer programming education [17]. In [18], the authors presented computer-assisted system for creating customized multiplechoice questions with different levels of difficulty and covering various types of skills such as vocabulary, grammar, and reading comprehension. In [19], the authors have introduced a novel technique to automatically offer feedback for basic programming exercises. The presented system determines the smallest possible modifications required to rectify the errors in a student’s incorrect solution, giving them an accurate understanding of the extent to which their solution was incorrect and informing them about their mistakes. Analyzing further the related literature, in [20], the authors investigate the possibility of utilizing Artificial Intelligence (AI) and natural language processing in a teaching assistant role to produce an experience of interaction that is close to that with a human, and to also offer a way for teachers to understand the learning progress of each student.. In [21], the authors introduce an intelligent tutor that utilizes AI to respond to programming inquiries from students. By incorporating a feedback evaluation component, the proposed approach can provide a more comprehensive and accurate assessment of the quality of the feedback generated by the system. This can help to ensure that the feedback provided is not only personalized and relevant but also effective in improving the learner’s understanding of Java programming. This is an important addition to the existing literature and can contribute significantly to the development of more effective and efficient ITS.  
  3 Methods and Architecture The proposed system is designed for an intelligent tutoring system for Java programming, but the approach can be adapted for other programming languages or domains, if adequately altered. The system is intended to help learners improve their programming skills by providing them with personalized feedback that addresses their specific weakness. The system includes three mane components, i.e. the Natural Language Parser, the Feedback Generator and the Feedback Evaluator.  
  C. Troussas et al.  
  3.1 Natural Language Parser The natural language parser component can use various NLP techniques such as tokenization, part-of-speech tagging, and dependency parsing to analyze the learners’ comments. It can identify the main topic of the comment, extract key concepts, and understand the relationships between different words in the comment. This information can then be used to generate personalized feedback for the learner. The natural language parser component can also take into account the learners’ background knowledge, learning history, and other contextual information to provide more relevant and effective feedback. The natural language parser component is crucial in understanding the learner’s input and extracting the relevant information needed for generating personalized feedback. In the case of Java programming, the parser needs to identify the code snippet or concept being referred to by the learner’s input and interpret it in a way that the feedback generator can use to provide accurate and helpful feedback. For example, the learner may ask “What is the purpose of the ‘public static void main (String[] args)’ method in Java?” or “Why is my code not compiling?”. The natural language parser component can then analyze these comments and extract information, such as the concept or code snippet being referred to, and use this information to generate appropriate feedback. The user interface is an important component of the ITS, as it is the primary point of interaction between the learner and the system. The text box provided for the learner to input their comments or questions is prominently displayed and labeled clearly.. The architecture of this component typically involves several sub-components that work together to analyze the text and identify important features. The natural language parser is responsible for analyzing the natural language input provided by the student and extracting relevant information that can be used by the tutoring system to provide feedback. The process typically involves several steps: • Tokenization: A tokenizer is the first step in the process, which breaks the text into individual tokens or words. The input text is broken down into individual words or tokens, which are held for further processing. • Part-of-speech tagging: The part-of-speech (POS) tagger then labels each token with its corresponding part of speech, such as noun, verb, adjective, etc. This helps the system identify the function of each word in the input text. • Named-entity recognition: The named-entity recognizer (NER) is used to identify and classify named entities, such as person names, organization names, and location names. • Dependency parsing: The dependency parser analyzes the relationships between words in the sentence and creates a tree structure that represents the syntactic structure of the sentence. This can help the system understand the meaning of the sentence and extract relevant information. These sub-components work together to enable the natural language parser component to understand the meaning of the text and extract important information from it.  
  Personalized Feedback Enhanced by Natural Language Processing  
  Initialization Tokenize the input text into a list of words Apply part-of-speech tagging to the list of words Apply named-entity recognition to the list of words Apply dependency parsing to the list of words Extract relevant information, such as the main topic and key concepts, of the response Return the extracted information  
  3.2 Feedback Generator The Feedback Generator component is responsible for generating feedback based on the output of the natural language parser. It uses this output to provide additional resources or examples to help the student better understand that concept. The process typically involves the following steps: • Analysis of the input information: The feedback generator analyzes the information extracted by the natural language parser to identify the key concepts and ideas inserted by the learner. • Identification of strengths and weaknesses: Based on the analysis of the input information, the feedback generator identifies areas where the student has demonstrated a strong understanding of the material, as well as areas where the student may need further clarification or explanation. For example, if the learner has demonstrated a good understanding of object-oriented programming concepts but struggles with Java syntax, the feedback generator might provide additional resources or examples to help the learner improve their syntax skills. Similarly, if the learner has demonstrated good problem-solving skills but struggles with debugging code, the feedback generator might provide additional examples or resources on debugging techniques. • Generation of feedback: Using the information gathered in the previous steps, the feedback generator generates feedback that is tailored to the learner’s specific needs and level of understanding. The feedback may include suggestions for improvement, examples to illustrate key concepts, or explanations of difficult concepts. The feedback can take various forms, such as textual explanations, examples, or links to additional resources. The feedback generator may also provide positive reinforcement to the learner, highlighting areas where they are doing well and encouraging them to continue to build on their strengths. Once the feedback has been generated, it can be evaluated by the feedback evaluator component. In view of the above, the steps that can be made by the Feedback Generator is as follows: 1. Initialization  
  C. Troussas et al.  
  2. Receive the extracted information from the natural language parser 3. Use a rule-based system to generate personalized feedback for the student 4. Return the generated feedback 3.3 Feedback Evaluator The feedback evaluator component is crucial for improving the overall effectiveness of the intelligent tutoring system. By collecting feedback from the learner and analyzing the quality of the feedback provided, the system can make adjustments to its approach to better meet the needs of the student. This helps to ensure that the feedback provided is effective and helpful, ultimately leading to improved learning outcomes. For example, in case of an unhelpful feedback, the system can adjust its approach for providing better feedback on that topic in the future. The process involves several steps: • Collection of feedback: This process involves collecting feedback from the student on the feedback provided by the system. This can be done through various methods such as surveys, questionnaires, or direct feedback in the user interface of the intelligent tutoring system. The feedback collected can include the learner’s opinion on the usefulness of the feedback, whether it addressed their needs, and suggestions for improvement. • Evaluation of feedback: The feedback evaluator evaluates the quality of the feedback using a predefined metric. This helps the system identify areas where the feedback could be improved. • Incorporation of feedback: Based on the results of the evaluation, the feedback evaluator makes improvements to the system, such as adding new examples, clarifying explanations, or modifying the feedback generation algorithm. • Iteration: It refers to the process of revising and improving the feedback evaluator’s recommendations. This process typically involves re-analyzing the input information, identifying any additional strengths and weaknesses, and generating new feedback that addresses the student’s individual needs more effectively. By continually evaluating and improving the feedback provided by the system, the feedback evaluator helps to ensure that the system is effective in helping students learn and master the material. In view of the above, the steps that can be made by the Feedback Evaluator is as follows: 1. Initialization 2. Collect feedback from the student on the effectiveness of the feedback provided by the system 3. Evaluate the quality of the feedback using a predefined metric 4. Use the feedback and evaluation results to identify areas for improvement 5. Incorporate the feedback and evaluation results into the system to improve the quality of future feedback 6. Return the updated system  
  Personalized Feedback Enhanced by Natural Language Processing  
  C. Troussas et al.  
  of gender and age were derived from a randomly selected sample and did not have an impact on our research findings. The population was equally divided by the instructors in two groups, each of which had equal number of students. The first group, namely the experimental group, were asked to use the ITS using NLP techniques, while the second group, namely the control group, did not take advantage of the feedback generation module. User satisfaction is an important metric for evaluating the effectiveness of an intelligent tutoring system that incorporates personalized feedback using natural language processing. To this direction, a questionnaire was used to measure users’ perceptions of the system’s effectiveness, ease of use, and overall satisfaction. A t-test analysis was used to compare the mean scores of the two groups of students in order to determine if there is a statistically significant difference in user satisfaction between learners who have used the ITS that incorporates personalized feedback using NLP and those who have not. The t-test analysis involved the following steps: 1. Selection of the participants: the two groups were similar in terms of their demographic characteristics and academic background. 2. Survey administration: we administered a questionnaire to both groups of learners to measure their perceptions of the system’s effectiveness, ease of use, and overall satisfaction. 3. Mean scores computation: we calculated the mean scores for each group on each of the survey questions. 4. Conduction of the t-test: we conducted a two-sample t-test to determine if there is a statistically significant difference in the mean scores between the two groups. The t-test provided a p-value that indicated the probability of observing the difference in mean scores by chance alone. 5. Interpretation of the results: If the p-value is less than the significance level (set at .05), then there is evidence to suggest that the difference in mean scores between the two groups is statistically significant. This would indicate that the ITS is more effective at improving user satisfaction than traditional learning methods. Overall, the t-test analysis provides valuable insights into the effectiveness of an ITS that incorporates personalized feedback using NLP by comparing user satisfaction between learners who have used the system and those who have not. However, it’s important to note that the results of the t-test should be interpreted in conjunction with other metrics such as learning outcomes and engagement metrics to provide a more comprehensive evaluation of the system’s effectiveness. After the completion of the course at the end of the semester, the two groups, experimental and control group, were asked to answer a questionnaire, based on a 7-point Likert scale ranging from (1) strongly disagree to (7) strongly agree (Table 1). The responses to the aforementioned questions provide valuable insights into the user experience of the ITS and help identify areas for improvement. User satisfaction provides valuable feedback on the usability, effectiveness, and overall satisfaction of the system, which can be used to improve the system’s design and functionality. A statistical hypothesis test was used to assess the proposed system more thoroughly. The 2-tailed t-test results are presented in Table 2.  
  Personalized Feedback Enhanced by Natural Language Processing  
  It is recorded a significant difference between the mean values of all the six questions. The results are somehow expected as the ITS incorporates NLP techniques, and students realized improved learning outcomes. Since t-Test values for the six questions are greater than the critical t, the results suggest that our system had a significant positive effect on the students’ satisfaction.  
  C. Troussas et al.  
  6 Conclusions This paper proposes a natural language processing-based approach to enhance feedback in intelligent tutoring systems for Java programming education. The proposed approach consists of three main components: a natural language parser, a feedback generator, and a feedback evaluator. The natural language parser converts learner comments into structured data that can be analyzed, while the feedback generator uses this data to generate personalized feedback for the learner. The feedback evaluator component then assesses the quality of the generated feedback and determines its helpfulness to the learner. The proposed approach was demonstrated through example of operation and was assessed by real students. Future research can further explore the use of natural language processing techniques in intelligent tutoring systems for programming education. One potential area of exploration is the use of more advanced natural language processing technique to further enhance the feedback generation process. Additionally, the proposed feedback evaluation component could be further refined to better assess the quality of the generated feedback.  
  SC Question Categorization  
  Due to the arbitrary number of blanks and tokens in the ESL SC tasks, questions in SC-Ques are categorized into the following categories according to the blank numbers and tokens numbers and the examples of each category are illustrated in Table 2. – C1: One-blank and one-token. Questions have one to-be-ﬁlled blank and the longest candidate option has one token. – C2: One-blank and many-token. Questions have one to-be-ﬁlled blank and the longest candidate option has multiple tokens. – C3: Many-blank and one-token. Questions have more than one to-beﬁlled blanks and the longest candidate option has one token. – C4: Many-blank and many-token. Questions have more than one to-beﬁlled blanks and the longest candidate option has multiple tokens.  
  SC-Ques: A Sentence Completion Question Dataset  
  be his. He hates black color.  
  (A) can; can’t (B) may; needn’t (C) must; mustn’t (D) must; can’t C4  
  We have  
  Q. Liu et al.  
  cates DeBERTaV3 has better generalization performance among all the selected pre-trained LMs which may be due to the eﬀective token detection task to discriminate whether the corrupted token is original or replaced by a generator in DeBERTaV3. When comparing the prediction performance of all the methods on C1, C2, C3 and C4, we can see that C3 and C4 have better performance than C1 and C2, we think the reason is that C1 and C2 have only one blank, the diﬀerence of the completed sentences of each option are quite similar which makes the models hard to distinguish this subtle diﬀerence. We run the pairwise t-test for each possible pair from these methods and all of them are statistically signiﬁcantly diﬀerent at 0.01 level.  
  Fig. 3. Accuracy on diﬀerent categories of SC-Ques.  
  the model performance curve, when the length of the questions is larger than 10, the models’ performances drop sharply. This indicates that after exceeding a certain length, questions become more diﬃcult with the increase of the context length. The reason may be that the model is diﬃcult to capture the contextual information in such a long distance. What is interesting is that if the length of the question is less than 3, the models also show slightly poor performance, which indicates that it is hard for the model to distinguish diﬀerent options once there is not enough context information. More speciﬁcally, the performance of DeBERTaV3 is less than the performance of BART when the length of the question is less than 7. With the increasing sequence length, DeBERTaV3 outperforms other models. We believe the reason is that DeBERTaV3 is trained as a discriminator to detect whether the token is original, the longer sequences provide relatively eﬀective information to make DeBERTaV3 discriminate the tokens, so they can get higher prediction results of SC compared to other models. Impacts of Diﬀerent Numbers of Words in Candidate Options. We also study the performance impacts in terms of the length of candidate options. We focus on the questions which have only one blank and two blanks. As shown in Table 3, we can see that the trend is similar to the diﬀerent lengths of the questions, DeBERTaV3 achieves the best performance in all lengths of candidate options. If the length of the candidate options is too short or too long, the performance would be a little worse. Table 3. Accuracy on diﬀerent lengths of the longest option in the questions which have one blank and two blanks. Methods  
  one blank  
  Precision-Recall Trade-oﬀ Analysis. When deploying the model in practice, a wrong answer may give bad guidance to students. In order to reduce such problems, we may refuse to solve some diﬃcult questions and improve the precision of more solvable questions. The models in our benchmark will output the correct probability for each option, for each question, we use a softmax function with temperature 0.1 for the probabilities of all options, the ﬁnal highest probability can also be viewed as the problem-solvable conﬁdence score. After that, we set a threshold to the correct probability of the model’s selected option and accept the above-the-threshold questions as our solvable questions. The recall score is computed as (the number of solvable questions)/(the number of all test questions), and the precision score is calculated as (the number of both solvable and  
  [email protected]   
  Abstract. Design is a highly creative and challenging task and research has already explored possible ways for using conversational agents (CAs) to support humans participating in co-design sessions. However, research reports that a) humans in these sessions expect more essential support from CAs, and b) it is important to develop CAs that continually learn from communication -like humans do- and not simply from labeled datasets. Addressing the above needs, this paper explores the specific question of how to extract useful knowledge from human dialogues observed during co-design sessions and make this knowledge available through a CA supporting humans in similar design activities. In our approach we explore the potential of the GPT-3 Large Language Model (LLM) to provide useful output extracted from unstructured data such as free dialogues. We provide evidence that by implementing an appropriate “extraction task” on the LLM it is possible to efficiently (and without human-in-the-loop) extract knowledge that can then be embedded in the cognitive base of a CA. We identify at least four major steps/assumptions in this process that need to be further researched, namely: A1) Knowledge modeling, A2) Extraction task, A3) LLM-based facilitation, and A4) Humans’ benefit. We provide demonstrations of the extraction and facilitation steps using the GPT-3 model and we also identify and comment on various worth exploring open research questions. Keywords: Conversational agent · Large language model (LLM) · Design thinking  
  S. Demetriadis and Y. Dimitriadis  
  However, users’ expectations regarding CAs supporting humans in design work, prescribe a type of agent capable of delivering almost human-like supportive interventions (e.g. [7]). CA technology needs to advance well beyond its current state-of-the-art (SOTA) to provide for this high level of agent capacity, one important advanced level functionality being agent’s learning ability. Similar to humans who learn to a great extent from conversational interactions (e.g. [8]) and “distill” their experiences in some form of knowledge transferable also in other contexts, this option should certainly be explored also for CA learning. Following this line of thinking we focus on the question of how to extract useful knowledge from human dialogues in co-design sessions and embed it next in the cognitive base of a CA to support humans in sessions of similar perspective. In this paper we explore the hypothesis that current Large Language Models (LLMs) may provide an innovative answer to this question; an answer that may open new perspectives in conceptualizing Human-AI interaction and offer significant research opportunities. We present a relevant conceptual framework and a sequence of four methodological steps labelled as “assumptions” to indicate that their feasibility, efficiency, and exact form of implementation need to be backed up by future research concrete evidence. Currently we demonstrate the feasibility of using GPT-3 in these steps but without any further evaluation of outcomes. We also highlight opportunities for further exploration of key relevant research questions. The rest of the paper is structured as follows: In Sect. 2 we provide a concise review of SOTA advances in the LLMs and CAs domain, reporting also on the use of CAs to support design thinking. In Sect. 3 we present the four methodological steps demonstrating -where applicable- their feasibility with examples realized in the GPT-3 environment [9]. In Sect. 4 we propose an architecture for a CA implementing the aforementioned steps. We conclude by providing a nonexhaustive list of open research questions.  
  2 Background 2.1 Large Language Models and Conversational Agents Artificial intelligence (AI) is “the ability of a digital computer or computer-controlled robot to perform tasks commonly associated with intelligent beings” [10]. Using AI artifacts to perform various tasks can be conceptualized as an “augmentation” of human cognitive abilities [11] and this certainly includes large language models and conversational agents in the natural language processing domain. A language model is typically described as a probability distribution over language tokens (words or parts of words) that provides a basis to computer software in performing text predictive modelling tasks [12]. With the rise of ANNs it is possible to develop complex LLMs making use of transformer architecture enhanced also with attention mechanisms [13] (for example, BERT and GPT families of LLMs). After the initial “pre-training”, methods of LLM metalearning (known mainly as “transfer learning”) can be applied to render the model more effective in downstream tasks. Of great importance, because of their effort efficiency, are the K-shot learning methods (ibid.), where “shot” refers to the training examples offered to the model to adjust it for the new task. Versions of this method include “zero-shot” (no training example at all), “one-shot” (one training example), or “few-shot” (more than one examples) [14].  
  CAs typically identify the user’s intent (and relevant entities) in user’s text input and provide an appropriate reply (for details the reader is directed to relevant publications such as [1, 15]). In general, agents employing AI-based methods are either “retrievalbased” or “generative” [1]. Mixed approaches are also possible combining benefits of the two worlds (e.g. [16]). An agent can further “learn” by improving its accuracy in identifying user’s intent and by expanding its knowledge base, thus being able to provide ever more accurate and useful replies to user prompts. Research has mostly focused on agent’s learning from training sets of labeled data but seldom on learning through conversational interactions with humans (e.g. [17]). 2.2 Conversational Agents and Design Thinking “Design thinking is a human-centered approach to innovation that draws from the designer’s toolkit to integrate the needs of people, the possibilities of technology, and the requirements for business success” [18]. In this paper, we use the term “co-design” session [19] to refer to the type of sessions being design-focused and full of social interactions (either onsite or online). Along with other researchers we also maintain that CAs can productively participate in co-design sessions and enhance the efficiency of humans to work collaboratively and accomplish the design objective (e.g. [7]). A review by Debowski et al. [5] distinguishes five main orientations relevant to CAs’ possible contribution in design thinking sessions (with emphasis on remotely conducted sessions). Overall, the review reports evidence that interacting with a CA may improve a human co-designer’s performance and the authors call for further research in the area. Interestingly, Bittner et al. [7] report that users expect an “almost human agent” that provides “helpful and not frustrating input”, can be used in “combination with human facilitator”, and may also have beneficial “impact on team collaboration”. Research also has nevertheless provided evidence that the effectiveness of digital facilitation can be comparable to that of humans, although it appears to be significantly worse in “subjectively perceived helpfulness” [6]. To further improve CAs performance and acceptance we argue that research should explore the development of a continually learning CA for design thinking. This type of agent would learn in a way similar to humans, by integrating in its knowledge base useful information and knowledge distilled from available dialogue data from previous co-design sessions. We proceed to further explore this perspective in the next sections.  
  3 Learning from Co-designers’ Dialogues 3.1 Extracting Information and Knowledge from Human Dialogues The problem of extracting knowledge from human dialogues can be considered as a special case of the general problem of extracting structured information from highly unstructured text [20]. Research so far has explored different solutions to various versions of this problem and methods developed for extracting specific information from dialogues have also been reported (e.g. [21, 22]). Evidence also is available that LLMs can report on the quality of a conversation as there exists a positive correlation between the output of the language models and human-assigned dialogue scores [23].  
  S. Demetriadis and Y. Dimitriadis  
  Based on the above and other relevant evidence we argue that LLMs can offer a viable solution for the combined problem of “extracting from dialogues” and “embedding to CA facilitators” the knowledge that can be helpful for human designers. To further model the problem we state and analyse the four assumptions that follow. 3.2 A1: “Knowledge Modelling” Assumption Knowledge embedded in dialogues can/should be modelled in a way that facilitates its extraction and further processing. “Knowledge is best shared through conversation” [24] and modeling this knowledge is important in developing highly efficient dialogue systems (e.g., [25]). In human dialogues extracted from co-design sessions we expect to find knowledge expressed with various degrees of context-dependency and also using more than one modalities (typically language and visuals). Therefore, we assume that a useful initial modelling of interlocutors’ utterances can be based on these two key features: their “context-dependency” and “modality”. “Context-dependency” refers to the degree that an utterance explicates a piece of knowledge in a clear and well understood way (for example a clear rule statement) or requires to be connected to other pieces of information (available or not in the dialogue) in order to become meaningful. Please note that this distinction is not necessarily relevant to the commonly discussed “tacit vs. explicit” knowledge distinction (e.g. [26]), since tacit and explicit knowledge can both be expressed with a varied degree of context-dependency in human dialogues. “Modality” refers to discussants using one or more modalities to convey information, such as spoken/written language and pictorial information (images, graphs, etc.) or face expressions, body posture/gestures, etc. We emphasize here the need for efficiently modelling the dialogue content from the context/modality perspective and possibly from other perspectives too. 3.3 A2: “Extraction Task” Assumption Useful knowledge embedded in co-design dialogues can be extracted by implementing some efficient LLM-based extraction task. Humans typically learn by generalizing from their experiences in a form of deeper (abstract) representation that usually can be also expressed in language-based form, for example, a summary or concluding statement. Similarly, we suggest that a LLM can extract useful knowledge from authentic human co-design dialogues in some appropriately structured form. Figure 1 presents: a) a description of one possible extraction GPT-3 LLM task, b) one-shot training of the GPT-3, also modelling the expected reply and (c) after the one-shot training, the LLM can be used to provide similar “Topic and Conclusion” task extractions from other dialogues (as demonstrated in Fig. 2). Please note that the dialogues in Figs. 1 and 2 are synthesized based on the material (cards) published by the "Build a Bot" design workshop [27]. Specifically, the suggestion that discussant B makes regarding the design issue under consideration is based on material included in the design cards of the aforementioned workshop.  
  Conversational Agents and Language Models  
  Fig. 3. One-shot training of the GPT-3 for the “LLM-based facilitation” task.  
  1. The “Previous sessions” section (item b in Fig. 3) includes outcomes of the [Topic and Conclusion] extraction task (knowledge extracted from human dialogues) to be used as training material of the LLM. The [Topic and Conclusion] tag is not really necessary but it is used to help the reader’s understanding. “Previous sessions” may include numerous useful outcomes and be integrated to the LLM through API code, so technically its size can be significantly larger than demonstrated here. 2. The “Example” section (item c in Fig. 3) presents a hypothetical dialogue between a Human and an AI-facilitator. The AI-facilitator utterance is modelled to fit a scenario where advice is required on the data storage issue. Note that “fine tuning” the LLM with a considerable amount of extracted data would also be an option but requires much more invested effort and is beyond the scope of this paper. After the above one-shot training, the GPT-3 is able to function as AI-facilitator providing appropriate replies to relevant prompts of human co-designers. In Fig. 4 we present the advice of the AI-facilitator (green highlight) to the issue of “Selecting the name of the bot” introduced by the Human Facilitator in an also hypothetical scenario. The trained LLM provides an advice based on the knowledge extracted in step A2 and integrated as learning material in the “Previous sessions” section of its one-shot training setting.  
  Fig. 4. Advice by the GPT-3-based AI-facilitator (Color figure online)  
  3.5 A4: “Humans’ Benefit” Assumption Human co-designers may benefit in their work when interacting with an agent that is continually learning by integrating knowledge extracted from available dialogues. We have demonstrated so far that by using GPT-3 it is possible to successfully perform the extraction task (step A2) and the facilitation task (step A3). However, it is not self-evident that human co-designers will reap any benefits when interacting with an agent with these functional features. Research has identified several human-agent interaction issues that go beyond the simple agent developmental level and touch the deeper socio-psychological dimensions of the interaction [28]. It is important to moderate and regulate human-agent interaction in order to establish a productive co-operation between humans and the AI-facilitator [7]. Of equal importance are issues such as enhancing an intellectually positive attitude in humans for leveraging the AI-facilitator capacity, empowering humans with control over the AI presence and also, inspiring humans how not to unproductively rely on AI but use it as a tool for deeper productive exploration of design issues (e.g. [29]). Overall, we believe there exists a major research opportunity regarding the multifaceted human-agent interactions in co-design sessions relevant also to the augmentation of human cognitive abilities through the use of AI tools and we call for further research in this area.  
  4 A Proposed Architecture for an LLM-Based AI-Facilitator In this section we integrate the steps and procedure described so far into a coherent CA architecture able to operate as an LLM-based AI-facilitator that learns form available human designers’ conversations (Fig. 5). As described, human dialogue data can be appropriately modeled and used as training data of the LLM (A1 in Fig. 5) to perform the “extraction” task (A2) with useful knowledge as A2 output. When co-designers (A4) interact with the CA a “User Message Analysis” component provides necessary information to the “Router” component to decide whether the human’s prompt: a) should be answered by retrieving a predefined response (for example, when a user asks for information strictly relevant to the specific activity, e.g. the activity timetable), or b) it is a request for AI-facilitator’s advice which should be directed to the LLM for a reply (dotted arrows) (A3), where the LLM now uses “useful knowledge” as input data to provide relevant advice. Finally a “Composer” component can produce a synthesis of the responses obtained from the two routes (predefined and LLM-based) to be sent back to users (A4).  
  Author Index  
  Author Index  
  Author Index  
