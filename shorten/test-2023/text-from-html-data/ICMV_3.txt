  Individual Subscriptions 
  Conference Proceedings | Conference Content Publication Services 
  SPIE Press Books | Book Author Information 
  Book Manuscript Guidelines 
  Submit a Book Proposal 
  Spotlights Call for Authors 
  Field Guide Author Guidelines 
  New Books from SPIE Press | Titles include "Optics using Python" and "Designing Optics Using Zemax OpticStudio" | Visit the Bookstore | Home 
  Publications Home 
  SPIE Press Books | SPIE Press Books | Publications 
  SPIE Press Books 
  Book Author Information 
  Book Manuscript Guidelines 
  Submit a Book Proposal 
  Spotlights Call for Authors 
  Field Guide Author Guidelines 
   New Books from SPIE Press  Titles include "Optics using Python" and "Designing Optics Using Zemax OpticStudio"  Visit the Bookstore 
  Membership | Membership | Membership Home 
  Photonics Focus 
  Optics.org 
  Latest Issue of Photonics Focus | Nov/Dec issue examines the past, present, and future of the laser. | Nov-Dec 2024 | Home 
  News Home | News Home | News 
  News Home 
  Photonics Focus 
  Optics.org 
   Latest Issue of Photonics Focus  Nov/Dec issue examines the past, present, and future of the laser.  Nov-Dec 2024 
  About | About | About SPIE Home 
  About the Society | Mission and Vision 
  SPIE Press Books | Publications 
  SPIE Press Books 
  Book Author Information 
  Book Manuscript Guidelines 
  Submit a Book Proposal 
  Spotlights Call for Authors 
  Field Guide Author Guidelines 
 Publications    Bookstore    Conference Proceedings    
 Sixteenth International Conference on Machine Vision (ICMV 2023)  
 Wolfgang Osten     
 Sixteenth International Conference on Machine Vision (ICMV 2023)  
 Wolfgang Osten     
 Date Published: 4 April 2024   
 Conference: Sixteenth International Conference on Machine Vision (ICMV 2023) 2023   
 Quantization method for bipolar morphological neural networks  Elena Limonova  ,  Michael Zingerenko  ,  Dmitry Nikolaev  ,  et al.    
 Show abstract   
 In the paper, we present a quantization method for bipolar morphological neural networks. Bipolar morphological neural networks use only addition, subtraction, and maximum operations inside the neuron and exponent and logarithm as activation functions of the layers. These operations allow fast and compact gate implementation for FPGA and ASIC, which makes these networks a promising solution for embedded devices. Quantization allows us to reach an additional increase in computational efficiency and reduce the complexity of hardware implementation by using integer values of low bitwidth for computations. We propose an 8-bit quantization scheme based on integer maximum, addition, and lookup tables for non-linear functions and experimentally demonstrate that basic models for image classification can be quantized without noticeable accuracy loss. More advanced models still provide high recognition accuracy but would benefit from further fine-tuning.   
 Fast keypoint filtering for feature-based identity documents classification on complex background  Nargiza Z. Valishina  ,  Alexander V. Gayer  ,  Natalya S. Skoryukina  ,  et al.    
 Segmentation of human olfactory bulb glomeruli on its phase-contrast tomographic images with neural networks  Aleksandr Smolin  ,  Marina Chukalina  ,  Inna Bukreeva  ,  et al.    
 Show abstract   
 The human olfactory bulb (OB), an important part of the brain responsible for the sense of smell, is a complex structure composed of multiple layers and cell types. Studying the OB morphological structure is essential for understanding the decline in olfactory function related to aging, neurodegenerative disorders, and other pathologies. Traditional microscopy methods in which slices are stained with solutions to contrast individual elements of the morphological structure are destructive. Non-destructive high-resolution technique is the X-ray phase-contrast tomography. However, manual segmentation of the reconstructed images are time-consuming due to large amount of data and prone to errors. U-Net-based model to optimize the segmentation of OB morphological structures, focusing specifically on glomeruli, in tomographic images of the human OB is proposed. The strategy to address overfitting and enhance the model's accuracy is described. This method addresses the challenges posed by complex limited data containing abundant details, similar grayscale levels between soft tissues, and blurry image details. Additionally, it successfully overcomes the limitations of a small dataset containing images with extremely dense point clouds, preventing the models from overfitting.   
 CattleDeSegNet: a joint approach to cattle denoising and interpretable segmentation  Sivaji Retta  ,  Ramarajulu Srinivasan  ,  Shawn Tan     
 Show abstract   
 In modern agriculture, livestock monitoring plays a vital role in ensuring animal health, welfare, and production efficiency. Leveraging computer vision and deep learning, this paper presents an innovative framework aimed at enhancing livestock monitoring. Specifically, we address two crucial challenges: denoising and segmentation of cattle in livestock images. The denoising task is fundamental in preprocessing noisy images affected by adverse environmental conditions and equipment limitations. To tackle this, we introduce an encoder-decoder model that effectively denoises cattle images while preserving critical anatomical details. Our framework incorporates a segmentation module inspired by the U-Net architecture. Notably, both denoising and segmentation tasks share a common encoder, optimizing computational efficiency. The segmentation model employs hybrid loss functions and leverages the Grad-CAM technique to provide interpretable insights into the decision-making process. Our approach stands as one of the pioneering joint solutions for cattle denoising and segmentation, particularly focusing on top-view cattle images.   
 Pattern Recognition   
 Building an optimal document authentication system  A. D. Bursikov  ,  S. A. Usilin  ,  I. A. Kunina     
 Show abstract   
 In this work, a probabilistic approach to assessing the quality of a system for determining the authenticity of documents in the images is considered. The considered system is based on the aggregation of responses of various checks of the security elements of the document. We propose a probabilistic model of the document authentication system and the functional for evaluating the quality of the system. Based on them, we offer an approach for assessing the quality of the separate part and the whole system. Finally, the approach to constructing an optimal function of making a final decision is obtained.   
 Multilanguage ID document images synthesis for testing recognition pipelines  Yulia S. Chernyshova  ,  Konstantin K. Suloev  ,  Vladimir V. Arlazarov     
 Enhanced multiple-instance pruning for learning soft cascade detectors  Daniil P. Matalov  ,  Vladimir V. Arlazarov     
 Show abstract   
 Object detection is one of the most common problems solved by computer vision systems. Even though neural network methods have become a standard tool for solving the problems, these methods have many disadvantages, which include high computational power requirements both for training and inference stages and tremendous training sets. This paper considers such a classical method for object detection as the Viola and Jones method and proposes an enhanced soft cascade calibration method based on Multiple-Instance Pruning to increase detection performance. The proposed method considers a response of the classifier to an image region as a random variable and follows a statistical approach to provide robust detectors. In addition, the paper addresses the problem of non-conformity of detection parameters at training and inference stages and studies performance decline. The performance of the proposed methods is demonstrated in a variety of practical tasks, including identity document detection and document fraud detection.   
 Limitations of anomaly detection: beyond which size defects can be reliably recognized  Jan Lehr  ,  Martin Pape  ,  Jan Philipps  ,  et al.    
 L-shape fitting algorithm for 3D object detection in bird’s-eye-view in an autonomous driving system  Mikhail O. Chekanov  ,  Oleg S. Shipitko     
 Show abstract   
 The ability of autonomous vehicles (AVs) to detect three-dimensional objects is crucial for motion planning, object tracking and safe driving. This task is especially challenging for systems using only monocular cameras, for which depth estimation presents special difficulties. In this paper, we discuss the subsystem of 3D object detection in bird’s-eye-view (BEV) for a single camera in an AV system. The subsystem consists of two parts. First, it estimates the contour of the object’s projection polygon in BEV based on 2D detection and drivable area segmentation (a planar ground model is used). Second, it simplifies the object’s projection by fitting the obtained polygon to a rotated bounding box. For this part we propose a new L-shape model-based fitting algorithm. It assumes that the vertices of the input polygon belong to two adjacent sides of the fitted bounding box. We compared this algorithm with a naive approach which minimizes the bounding box’s area and with adaptations of algorithms from a paper solving a similar problem with LiDAR point clouds. The L-shape algorithm outperformed the alternatives.   
 False positive elimination in object detection methods for videos  Shubham Kumar Dubey  ,  J. V. Satyanarayana  ,  C. Krishna Mohan     
 Incremental one-class learning using regularized null-space training for industrial defect detection  Matthias Hermann  ,  Georg Umlauf  ,  Bastian Goldlücke  ,  et al.    
 Show abstract   
 One-class incremental learning is a special case of class-incremental learning, where only a single novel class is incrementally added to an existing classifier instead of multiple classes. This case is relevant in industrial defect detection scenarios, where novel defects usually appear during operation. Existing rolled-out classifiers must be updated incrementally in this scenario with only a few novel examples. In addition, it is often required that the base classifier must not be altered due to approval and warranty restrictions. While simple finetuning often gives the best performance across old and new classes, it comes with the drawback of potentially losing performance on the base classes (catastrophic forgetting [1]). Simple prototype approaches [2] work without changing existing weights and perform very well when the classes are well separated but fail dramatically when not. In theory, null-space training (NSCL) [3] should retain the basis classifier entirely, as parameter updates are restricted to the null space of the network with respect to existing classes. However, as we show, this technique promotes overfitting in the case of one-class incremental learning. In our experiments, we found that unconstrained weight growth in null space is the underlying issue, leading us to propose a regularization term (R-NSCL) that penalizes the magnitude of amplification. The regularization term is added to the standard classification loss and stabilizes null-space training in the one-class scenario by counteracting overfitting. We test the method’s capabilities on two industrial datasets, namely AITEX and MVTec, and compare the performance to state-of-the-art algorithms for class-incremental learning.   
 Detection of fingers in document images captured in uncontrolled environment  L. S. Tolstenko  ,  I. A. Kunina     
 Methods for non-intrusive out-of-distribution images detection  Anastasiia V. Vlasova  ,  Aleksandr Yu. Shkanaev  ,  Dmitry L. Sholomov     
 Show abstract   
 Selecting representative data is a key factor in improving the performance of machine learning algorithms. In this paper we focus on out-of-distribution (OoD) methods evaluation, which can be integrated into ML project lifecycle in a nonintrusive way, without changing a model architecture. Considered methods are applicable to image classification datasets analysis. In addition to commonly used AUROC metric, we evaluate the number of out-of-distribution samples misclassified with high confidence. Case studies were conducted on benchmark and production datasets. As a result, we provide practical guidance for data evaluation and recommendations on which method to use to detect different types of OoD images.   
 Image edge detection using pseudo-Boolean polynomials  Tendai Mapungwana Chikake  ,  Boris Goldengorin     
 Show abstract   
 We introduce a novel approach for image edge detection based on calculating pseudo-Boolean polynomials on image patches whose resulting polynomial degrees determine whether a patch lies over an edge or a blob. In this paper we show that patches covering edge regions  within the image result in pseudo-Boolean polynomials of higher degrees compared to patches that cover blob  regions. The proposed approach is based on reduction  of polynomial degree and equivalence  properties of penalty-based pseudo-Boolean polynomials.   
 Specialized indoor and outdoor scene-specific object detection models  Mahtab Jamali  ,  Paul Davidsson  ,  Reza Khoshkangini  ,  et al.    
 Point scene understanding via points-to-mesh reconstruction and multi-level utilization of proposals  Mengxiang Hao  ,  Hang Wu  ,  Ruchong Fu  ,  et al.    
 Show abstract   
 Semantic scene reconstruction from sparse and incomplete point clouds is a critical task for point scene understanding. It aims to recognize semantic labels for objects and recover their complete shapes as meshes. Existing methods often fail to realize high-quality instance reconstruction due to inadequate shape representation and underutilization of proposal point clouds. To address these issues, we optimize the previous BSP/occupancy-to-mesh reconstruction framework to points-to-mesh and accomplish multi-level utilization of proposals. We chose point cloud as the representation of completion to reduce the difficulty of restoring curved shallow parts. Benefiting from the optimization, we can match and merge proposal point clouds with the restored ones, avoiding missing parts existing in inputs. We design an effective pose normalization module to extract point-based features from normalized proposals, which are fused with features extracted from voxelized proposals, avoiding the detailed geometry lost in voxelization and enhancing the reconstruction's robustness to different input postures. The suitable points-to-mesh reconstruction framework and full utilization of proposals make our method improve reconstruction results efficiently. Detailed experiments on the challenging ScanNet dataset of the semantic scene reconstruction benchmark show that our network outperforms state-of-the-art methods in both completion and mapping metrics.   
 Search for image quality metrics suitable for assessing images specially precompensated for users with refractive errors  Nafe B. Alkzir  ,  Ilya P. Nikolaev  ,  Dmitry P. Nikolaev     
 Spectral filters design for a better hyperspectral reconstruction  Daniil Reutskii  ,  Egor Ershov     
 Show abstract   
 Spectral reconstruction (recovering spectra from RGB measurements) is a vital problem of computational photography. As a matter of curiosity, modern mobile devices open a new opportunity to improve the quality of spectral reconstruction by utilizing images from several cameras at once. This leads to the idea of creating a mobile hyperspectral camera for the general public. In this paper we investigate the achievable accuracy when using several identical cameras simultaneously in combination with different spectral filters. To find optimal filters, two algorithms are proposed: one learns spectral transmittance functions simultaneously with spectral reconstruction, the other learns only spectral transmittances by information loss minimization. As a result of numerical experiments, 4 cameras and 4 filters allow us to perform spectral reconstruction two times accurately than from a single RGB image.   
 Method of color image formation taking into account the human perception features  N. A. Obukhova  ,  A. A. Motyko  ,  A. A. Pozdeev  ,  et al.    
 Distortion-aware super-resolution for planetary exploration images  N. Landro  ,  I. Gallo  ,  F. Pelosi  ,  et al.    
 Show abstract   
 Super-resolution is crucial in computer vision and digital image processing, aiming to enhance low-quality images’ resolution and visual quality. This paper focuses on correcting the distortion introduced by fisheye lenses and improving the resolution of images for better detail representation. Specifically, we propose an evaluation approach that benchmarks three state-of-the-art models in different categories: Real-ESRGAN (convolutions), SwinIR (transformers), and SR3 (diffusion). We evaluate their performance in super-resolution and distortion correction tasks using metrics such as PSNR and SSIM. To facilitate this evaluation, we create and release a new dataset of lunar surface images with fisheye distortion applied. Our experiments demonstrate the effectiveness of each model in handling distortion and improving image resolution. The results show that large models generally outperform medium models, and PSNR models achieve higher PSNR and SSIM scores than GAN models. Additionally, we evaluate the distortion correction by comparing the corrected images with ground truth. Our findings contribute to understanding different model categories and their performance in super-resolution and distortion correction tasks. The proposed dataset and evaluation approach can be valuable resources for future research.   
 Robust automatic rotation axis alignment mean projection image method in cone-beam and parallel-beam CT  Danil Kazimirov  ,  Anastasia Ingacheva  ,  Alexey Buzmakov  ,  et al.    
 Show abstract   
 The rotation axis position is an important parameter of classical reconstruction algorithms in X-ray computed tomography (CT). The use of incorrect values of the axis position parameters during the reconstruction leads to the appearance of various artifacts distorting the reconstructed image. Therefore, to obtain a reconstruction of better quality, automatic rotation axis position determination and misalignment correction methods are of use. Most of the existing high-precision automatic rotation axis position determination methods are either fast, but suitable only within a parallel-beam geometric scheme, or indifferent to the geometric scheme, but computationally laborious. In this paper, we propose a method for auto-detection of two scalar parameters of rotation axis position — axis shift and tilt in the plane parallel to the detector window plane — using a pixel-wise arithmetically averaged projection image. The described method is highly accurate within both parallel-beam and cone-beam geometric schemes whereas it is characterized by robustness to noise in projection data. The method has performed an increase in reconstruction quality when compared with some well-known and still used in practice methods both on synthetic data and on real data obtained in real laboratory conditions.   
 StereoYolo+DeepSORT: a framework to track fish from underwater stereo camera in situ  Aya Saad  ,  Stian Jakobsen  ,  Morten Bondø  ,  et al.    
 Show abstract   
 This paper presents a 3D multiple object detection and tracking framework for identifying and quantifying changes in fish behaviour through tracking the 3D position, distance and speed of fish with respect to an underwater stereo camera. The framework consists of six essential modules based on 3D object detection to identify fish and multiple object tracking algorithms to track the fish in sequential frames. In particular, the latest version of Yolo (Yolov7) is utilised for object detection and the deep SORT algorithm is used for multiple object tracking. The framework was tested using videos captured from an underwater stereo camera in an industrial-scale sea-based fish farm. The results showed that the framework was able to accurately detect and track multiple fish in 3D. The fish position, distance and speed relative to the camera were also successfully detected. The results of this study demonstrate the effectiveness of this framework in identifying and quantifying changes in fish behaviour. The proposed novel framework has the potential to greatly enhance our understanding of fish behaviour in their natural habitats, leading to new insights into fish ecology and behaviour, while at the same time, it can enable researchers to study fish behaviour in a more detailed and accurate way.   
 CADCP: a method for chromatic haze compensation on remotely sensed images  D. S. Sidorchuk  ,  M. A. Pavlova  ,  D. O. Kushchev  ,  et al.    
 Show abstract   
 Remote sensing images often suffer from different types of haze. Its presence significantly complicates remotely sensed image analysis that is crucial for monitoring of land state and precision agriculture. Currently existing remote sensing dehazing methods are designed for achromatic haze, but in cases such as smoke from fires or sandstorms, the haze may have its own pronounced coloration. In this paper we propose a new hazed image formation model that considers chromatic haze. Using this model we propose a new single image dehazing method CADCP that is based on color attenuation and dark channel priors. For quality assessment of the proposed method we generated a dataset of remotely sensed images with simulated chromatic haze. The generated dataset includes data with various haze spatial distribution and density. Quality evaluation results including qualitative and quantitative approaches demonstrated better results of the proposed method comparing with other existing methods.   
 Data-Based Intelligent Computing and Algorithm   
 A data parallel approach for distributed neural networks to achieve faster convergence  Nagaraju C.  ,  Yenda Ramesh  ,  C. Krishna Mohan     
 Show abstract   
 The availability of large datasets has significantly contributed to recent advancements in deep Convolutional Neural Network (CNN) models. However, training a large CNN model using such datasets is a time-consuming task. This issue has been addressed by the parallelization and distribution of data/model during the training process. There are two ways to implement distributed deep learning processes: data parallelism and model parallelism. Data parallelism involves distributing the dataset across multiple workers, allowing them to process different portions simultaneously. While increasing the number of workers can reduce computation time, it also introduces additional communication time. In some cases, the increased communication time can outweigh the benefits gained from reduced computation time. In this paper, our focus is on reducing the overall computation time of data parallel approach by employing two strategies. First, we emphasize the preservation of dataset distribution across all workers, ensuring that each worker has access to representative data. Second, we explore the localization of parameters and the quantization of gradients to three levels: {-1, 0, 1} to reduce communication delays between the server and workers, as well as between workers themselves. By adopting these two strategies, we aim to enhance the performance of data parallel approach in the distributed deep learning processes. As a result of preserving the distribution of the data while sampling the entire data, each partition retains a similar mean and variance (capturing important first and second-order statistics). This approach guarantees that all worker machines train their local models on uniformly distributed data instead of random distribution. Additionally, localizing parameters limits the communication between the server and workers to gradients only. Furthermore, by quantizing gradients to 2-bits, we successfully achieve our objective of reducing computation time by enabling faster convergence without compromising test or validation accuracy. The experimental results demonstrate that employing these strategies in distributed deep learning effectively reduces communication overhead and leads to faster convergence when compared to methods that utilize random data sampling. These improvements were observed across multiple datasets such as MNIST, CIFAR-10, and Tiny ImageNet.   
 Quantum time series forecasting  Prashant Gohel  ,  Manjunath Joshi     
 CG-MER: a card game-based multimodal dataset for emotion recognition  Nisrine Farhat  ,  Amine Bohi  ,  Leila Ben Letaifa  ,  et al.    
 Show abstract   
 The field of affective computing has seen significant advancements in exploring the relationship between emotions and emerging technologies. This paper presents a novel and valuable contribution to this field with the introduction of a comprehensive French multimodal dataset designed specifically for emotion recognition. The dataset encompasses three primary modalities: facial expressions, speech, and gestures, providing a holistic perspective on emotions. Moreover, the dataset has the potential to incorporate additional modalities, such as Natural Language Processing (NLP) to expand the scope of emotion recognition research. The dataset was curated through engaging participants in card game sessions, where they were prompted to express a range of emotions while responding to diverse questions. The study included 10 sessions with 20 participants (9 females and 11 males). The dataset serves as a valuable resource for furthering research in emotion recognition and provides an avenue for exploring the intricate connections between human emotions and digital technologies.   
 ABOUT 
